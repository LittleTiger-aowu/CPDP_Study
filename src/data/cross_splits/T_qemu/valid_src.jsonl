{"project": "FFmpeg", "commit_id": "39bb30f6640fe1faf4bbc779a79786028febc95d", "target": 1, "func": "static int mxf_read_content_storage(MXFContext *mxf, ByteIOContext *pb, int tag)\n\n{\n\n    switch (tag) {\n\n    case 0x1901:\n\n        mxf->packages_count = get_be32(pb);\n\n        if (mxf->packages_count >= UINT_MAX / sizeof(UID))\n\n            return -1;\n\n        mxf->packages_refs = av_malloc(mxf->packages_count * sizeof(UID));\n\n        if (!mxf->packages_refs)\n\n            return -1;\n\n        url_fskip(pb, 4); /* useless size of objects, always 16 according to specs */\n\n        get_buffer(pb, (uint8_t *)mxf->packages_refs, mxf->packages_count * sizeof(UID));\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 125, "_split": "valid", "_hash": "9f9d18980ab8d6589361dd2896792aec"}
{"project": "FFmpeg", "commit_id": "c3e6e8f06c42499bd020fd0b37f9542150e6067b", "target": 0, "func": "int av_reallocp_array(void *ptr, size_t nmemb, size_t size)\n\n{\n\n    void **ptrptr = ptr;\n\n    void *ret;\n\n    if (size <= 0 || nmemb >= INT_MAX / size)\n\n        return AVERROR(ENOMEM);\n\n    if (nmemb <= 0) {\n\n        av_freep(ptr);\n\n        return 0;\n\n    }\n\n    ret = av_realloc(*ptrptr, nmemb * size);\n\n    if (!ret) {\n\n        av_freep(ptr);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    *ptrptr = ret;\n\n    return 0;\n\n}\n", "idx": 127, "_split": "valid", "_hash": "db300d5d9aacb42424783c2956639874"}
{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "void ff_put_h264_qpel16_mc31_msa(uint8_t *dst, const uint8_t *src,\n\n                                 ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_16w_msa(src - 2,\n\n                            src - (stride * 2) +\n\n                            sizeof(uint8_t), stride, dst, stride, 16);\n\n}\n", "idx": 137, "_split": "valid", "_hash": "692bda5b7355fa1e9cf422934916750a"}
{"project": "FFmpeg", "commit_id": "bc488ec28aec4bc91ba47283c49c9f7f25696eaa", "target": 1, "func": "static int bit8x8_c(MpegEncContext *s, uint8_t *src1, uint8_t *src2,\n\n                    ptrdiff_t stride, int h)\n\n{\n\n    const uint8_t *scantable = s->intra_scantable.permutated;\n\n    LOCAL_ALIGNED_16(int16_t, temp, [64]);\n\n    int i, last, run, bits, level, start_i;\n\n    const int esc_length = s->ac_esc_length;\n\n    uint8_t *length, *last_length;\n\n\n\n    av_assert2(h == 8);\n\n\n\n    s->pdsp.diff_pixels(temp, src1, src2, stride);\n\n\n\n    s->block_last_index[0 /* FIXME */] =\n\n    last                               =\n\n        s->fast_dct_quantize(s, temp, 0 /* FIXME */, s->qscale, &i);\n\n\n\n    bits = 0;\n\n\n\n    if (s->mb_intra) {\n\n        start_i     = 1;\n\n        length      = s->intra_ac_vlc_length;\n\n        last_length = s->intra_ac_vlc_last_length;\n\n        bits       += s->luma_dc_vlc_length[temp[0] + 256]; // FIXME: chroma\n\n    } else {\n\n        start_i     = 0;\n\n        length      = s->inter_ac_vlc_length;\n\n        last_length = s->inter_ac_vlc_last_length;\n\n    }\n\n\n\n    if (last >= start_i) {\n\n        run = 0;\n\n        for (i = start_i; i < last; i++) {\n\n            int j = scantable[i];\n\n            level = temp[j];\n\n\n\n            if (level) {\n\n                level += 64;\n\n                if ((level & (~127)) == 0)\n\n                    bits += length[UNI_AC_ENC_INDEX(run, level)];\n\n                else\n\n                    bits += esc_length;\n\n                run = 0;\n\n            } else\n\n                run++;\n\n        }\n\n        i = scantable[last];\n\n\n\n        level = temp[i] + 64;\n\n\n\n        av_assert2(level - 64);\n\n\n\n        if ((level & (~127)) == 0)\n\n            bits += last_length[UNI_AC_ENC_INDEX(run, level)];\n\n        else\n\n            bits += esc_length;\n\n    }\n\n\n\n    return bits;\n\n}\n", "idx": 146, "_split": "valid", "_hash": "b83752278f7520993f2598de745184a3"}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static inline void mix_2f_1r_to_dolby(AC3DecodeContext *ctx)\n\n{\n\n    int i;\n\n    float (*output)[256] = ctx->audio_block.block_output;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        output[1][i] -= output[3][i];\n\n        output[2][i] += output[3][i];\n\n    }\n\n    memset(output[3], 0, sizeof(output[3]));\n\n}\n", "idx": 183, "_split": "valid", "_hash": "67d7cd8b55486158c816e8099efc008f"}
{"project": "FFmpeg", "commit_id": "d2a2b08cfe2ab382a4ad756c0a08ff78eb284ef9", "target": 0, "func": "static int config_props(AVFilterLink *outlink)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    AVFilterLink *inlink = outlink->src->inputs[0];\n\n    ScaleContext *scale = ctx->priv;\n\n    int64_t w, h;\n\n\n\n    if (!(w = scale->w))\n\n        w = inlink->w;\n\n    if (!(h = scale->h))\n\n        h = inlink->h;\n\n    if (w == -1)\n\n        w = av_rescale(h, inlink->w, inlink->h);\n\n    if (h == -1)\n\n        h = av_rescale(w, inlink->h, inlink->w);\n\n\n\n    if (w > INT_MAX || h > INT_MAX ||\n\n        (h * inlink->w) > INT_MAX  ||\n\n        (w * inlink->h) > INT_MAX)\n\n        av_log(ctx, AV_LOG_ERROR, \"Rescaled value for width or height is too big.\\n\");\n\n\n\n    outlink->w = w;\n\n    outlink->h = h;\n\n\n\n    /* TODO: make algorithm configurable */\n\n    scale->sws = sws_getContext(inlink ->w, inlink ->h, inlink ->format,\n\n                                outlink->w, outlink->h, outlink->format,\n\n                                SWS_BILINEAR, NULL, NULL, NULL);\n\n\n\n    av_log(ctx, AV_LOG_INFO, \"w:%d h:%d fmt:%s\\n\",\n\n           outlink->w, outlink->h, av_pix_fmt_descriptors[outlink->format].name);\n\n\n\n    scale->input_is_pal = inlink->format == PIX_FMT_PAL8      ||\n\n                          inlink->format == PIX_FMT_BGR4_BYTE ||\n\n                          inlink->format == PIX_FMT_RGB4_BYTE ||\n\n                          inlink->format == PIX_FMT_BGR8      ||\n\n                          inlink->format == PIX_FMT_RGB8;\n\n\n\n    return !scale->sws;\n\n}\n", "idx": 188, "_split": "valid", "_hash": "7847e96eb5344b70f0ff22a92ff22484"}
{"project": "FFmpeg", "commit_id": "b754978a3b0aa17e7794f64c69bf4491762797fd", "target": 0, "func": "static int find_stream_index(AVFormatContext *s)\n\n{\n\n    int i;\n\n    AVStream *st;\n\n\n\n    if (s->nb_streams <= 0)\n\n        return -1;\n\n    for(i = 0; i < s->nb_streams; i++) {\n\n        st = s->streams[i];\n\n        if (st->codec.codec_type == CODEC_TYPE_VIDEO) {\n\n            return i;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 253, "_split": "valid", "_hash": "8c08393570e2e4b8d65c845ca1101f20"}
{"project": "FFmpeg", "commit_id": "d0d8a9b1384ba3cd465d6ef3439f3979d4518b4b", "target": 1, "func": "void ff_rtsp_undo_setup(AVFormatContext *s)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    int i;\n\n\n\n    for (i = 0; i < rt->nb_rtsp_streams; i++) {\n\n        RTSPStream *rtsp_st = rt->rtsp_streams[i];\n\n        if (!rtsp_st)\n\n            continue;\n\n        if (rtsp_st->transport_priv) {\n\n            if (s->oformat) {\n\n                AVFormatContext *rtpctx = rtsp_st->transport_priv;\n\n                av_write_trailer(rtpctx);\n\n                if (rt->lower_transport == RTSP_LOWER_TRANSPORT_TCP) {\n\n                    uint8_t *ptr;\n\n                    url_close_dyn_buf(rtpctx->pb, &ptr);\n\n                    av_free(ptr);\n\n                } else {\n\n                    url_fclose(rtpctx->pb);\n\n                }\n\n                av_metadata_free(&rtpctx->streams[0]->metadata);\n\n                av_metadata_free(&rtpctx->metadata);\n\n\n                av_free(rtpctx->streams[0]);\n\n                av_free(rtpctx);\n\n            } else if (rt->transport == RTSP_TRANSPORT_RDT && CONFIG_RTPDEC)\n\n                ff_rdt_parse_close(rtsp_st->transport_priv);\n\n            else if (CONFIG_RTPDEC)\n\n                rtp_parse_close(rtsp_st->transport_priv);\n\n        }\n\n        rtsp_st->transport_priv = NULL;\n\n        if (rtsp_st->rtp_handle)\n\n            url_close(rtsp_st->rtp_handle);\n\n        rtsp_st->rtp_handle = NULL;\n\n    }\n\n}", "idx": 268, "_split": "valid", "_hash": "a502f27b23566716594791afd9551006"}
{"project": "FFmpeg", "commit_id": "69e7daf6ce2a5893936ba18572c58180b29d67f9", "target": 1, "func": "static void generate_offset_lut(DiracGolombLUT *lut, int off)\n\n{\n\n    int idx;\n\n    for (idx = 0; idx < LUT_SIZE; idx++) {\n\n        DiracGolombLUT *l = &lut[idx];\n\n\n\n        INIT_RESIDUE(res);\n\n        SET_RESIDUE(res, idx, LUT_BITS);\n\n\n\n        l->preamble      = CONVERT_TO_RESIDUE(res >> (RSIZE_BITS - off), off);\n\n        l->preamble_bits = off;\n\n        l->sign = ((l->preamble >> (RSIZE_BITS - l->preamble_bits)) & 1) ? -1 : +1;\n\n\n\n        search_for_golomb(l, res << off, LUT_BITS - off);\n\n    }\n\n}\n", "idx": 342, "_split": "valid", "_hash": "a66b3dd5e8ab8513db706931247f60e2"}
{"project": "FFmpeg", "commit_id": "1e4eb387d4768089cfe8db0141ccc23089694fce", "target": 1, "func": "static int msrle_decode_8_16_24_32(AVCodecContext *avctx, AVPicture *pic, int depth,\n\n                                    const uint8_t *data, int srcsize)\n\n{\n\n    uint8_t *output, *output_end;\n\n    const uint8_t* src = data;\n\n    int p1, p2, line=avctx->height, pos=0, i;\n\n    uint16_t pix16;\n\n    uint32_t pix32;\n\n\n\n    output = pic->data[0] + (avctx->height - 1) * pic->linesize[0];\n\n    output_end = pic->data[0] + (avctx->height) * pic->linesize[0];\n\n    while(src < data + srcsize) {\n\n        p1 = *src++;\n\n        if(p1 == 0) { //Escape code\n\n            p2 = *src++;\n\n            if(p2 == 0) { //End-of-line\n\n                output = pic->data[0] + (--line) * pic->linesize[0];\n\n                if (line < 0){\n\n                    av_log(avctx, AV_LOG_ERROR, \"Next line is beyond picture bounds\\n\");\n\n                    return -1;\n\n                }\n\n                pos = 0;\n\n                continue;\n\n            } else if(p2 == 1) { //End-of-picture\n\n                return 0;\n\n            } else if(p2 == 2) { //Skip\n\n                p1 = *src++;\n\n                p2 = *src++;\n\n                line -= p2;\n\n                if (line < 0){\n\n                    av_log(avctx, AV_LOG_ERROR, \"Skip beyond picture bounds\\n\");\n\n                    return -1;\n\n                }\n\n                pos += p1;\n\n                output = pic->data[0] + line * pic->linesize[0] + pos * (depth >> 3);\n\n                continue;\n\n            }\n\n            // Copy data\n\n            if (output + p2 * (depth >> 3) > output_end) {\n\n                src += p2 * (depth >> 3);\n\n                continue;\n\n            }\n\n            if ((depth == 8) || (depth == 24)) {\n\n                for(i = 0; i < p2 * (depth >> 3); i++) {\n\n                    *output++ = *src++;\n\n                }\n\n                // RLE8 copy is actually padded - and runs are not!\n\n                if(depth == 8 && (p2 & 1)) {\n\n                    src++;\n\n                }\n\n            } else if (depth == 16) {\n\n                for(i = 0; i < p2; i++) {\n\n                    pix16 = AV_RL16(src);\n\n                    src += 2;\n\n                    *(uint16_t*)output = pix16;\n\n                    output += 2;\n\n                }\n\n            } else if (depth == 32) {\n\n                for(i = 0; i < p2; i++) {\n\n                    pix32 = AV_RL32(src);\n\n                    src += 4;\n\n                    *(uint32_t*)output = pix32;\n\n                    output += 4;\n\n                }\n\n            }\n\n            pos += p2;\n\n        } else { //Run of pixels\n\n            uint8_t pix[3]; //original pixel\n\n            switch(depth){\n\n            case  8: pix[0] = *src++;\n\n                     break;\n\n            case 16: pix16 = AV_RL16(src);\n\n                     src += 2;\n\n                     break;\n\n            case 24: pix[0] = *src++;\n\n                     pix[1] = *src++;\n\n                     pix[2] = *src++;\n\n                     break;\n\n            case 32: pix32 = AV_RL32(src);\n\n                     src += 4;\n\n                     break;\n\n            }\n\n            if (output + p1 * (depth >> 3) > output_end)\n\n                continue;\n\n            for(i = 0; i < p1; i++) {\n\n                switch(depth){\n\n                case  8: *output++ = pix[0];\n\n                         break;\n\n                case 16: *(uint16_t*)output = pix16;\n\n                         output += 2;\n\n                         break;\n\n                case 24: *output++ = pix[0];\n\n                         *output++ = pix[1];\n\n                         *output++ = pix[2];\n\n                         break;\n\n                case 32: *(uint32_t*)output = pix32;\n\n                         output += 4;\n\n                         break;\n\n                }\n\n            }\n\n            pos += p1;\n\n        }\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_WARNING, \"MS RLE warning: no End-of-picture code\\n\");\n\n    return 0;\n\n}\n", "idx": 355, "_split": "valid", "_hash": "c13c70f3e78a57d686a93daa9634a570"}
{"project": "FFmpeg", "commit_id": "a165b53daa8a3a526d2328ca72c4aa9e7f163045", "target": 1, "func": "static void RENAME(vertical_compose53iL0)(uint8_t *_b0, uint8_t *_b1, uint8_t *_b2,\n\n                                          int width)\n\n{\n\n    int i;\n\n    TYPE *b0 = (TYPE *)_b0;\n\n    TYPE *b1 = (TYPE *)_b1;\n\n    TYPE *b2 = (TYPE *)_b2;\n\n    for (i = 0; i < width; i++)\n\n        b1[i] -= (b0[i] + b2[i] + 2) >> 2;\n\n}\n", "idx": 368, "_split": "valid", "_hash": "0b4d24f428f52d97cd66321066b90ef8"}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static int fourxm_read_packet(AVFormatContext *s,\n\n                              AVPacket *pkt)\n\n{\n\n    FourxmDemuxContext *fourxm = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    unsigned int fourcc_tag;\n\n    unsigned int size, out_size;\n\n    int ret = 0;\n\n    int track_number;\n\n    int packet_read = 0;\n\n    unsigned char header[8];\n\n    int64_t pts_inc;\n\n    int audio_frame_count;\n\n\n\n    while (!packet_read) {\n\n\n\n        if ((ret = get_buffer(&s->pb, header, 8)) < 0)\n\n            return ret;\n\n        fourcc_tag = LE_32(&header[0]);\n\n        size = LE_32(&header[4]);\n\n        if (url_feof(pb))\n\n            return AVERROR_IO;\n\n        switch (fourcc_tag) {\n\n\n\n        case LIST_TAG:\n\n            /* this is a good time to bump the video pts */\n\n            fourxm->video_pts += fourxm->video_pts_inc;\n\n\n\n            /* skip the LIST-* tag and move on to the next fourcc */\n\n            get_le32(pb);\n\n            break;\n\n\n\n        case ifrm_TAG:\n\n        case pfrm_TAG:\n\n        case cfrm_TAG:{\n\n\n\n            /* allocate 8 more bytes than 'size' to account for fourcc\n\n             * and size */\n\n            if (av_new_packet(pkt, size + 8))\n\n                return AVERROR_IO;\n\n            pkt->stream_index = fourxm->video_stream_index;\n\n            pkt->pts = fourxm->video_pts;\n\n            memcpy(pkt->data, header, 8);\n\n            ret = get_buffer(&s->pb, &pkt->data[8], size);\n\n\n\n            if (ret < 0)\n\n                av_free_packet(pkt);\n\n            else\n\n                packet_read = 1;\n\n            break;\n\n        }\n\n\n\n        case snd__TAG:\n\n            track_number = get_le32(pb);\n\n            out_size= get_le32(pb);\n\n            size-=8;\n\n\n\n            if (track_number == fourxm->selected_track) {\n\n                if (av_new_packet(pkt, size))\n\n                    return AVERROR_IO;\n\n                pkt->stream_index = \n\n                    fourxm->tracks[fourxm->selected_track].stream_index;\n\n                pkt->pts = fourxm->audio_pts;\n\n                ret = get_buffer(&s->pb, pkt->data, size);\n\n                if (ret < 0)\n\n                    av_free_packet(pkt);\n\n                else\n\n                    packet_read = 1;\n\n\n\n                /* pts accounting */\n\n                audio_frame_count = size;\n\n                if (fourxm->tracks[fourxm->selected_track].adpcm)\n\n                    audio_frame_count -= \n\n                        2 * (fourxm->tracks[fourxm->selected_track].channels);\n\n                audio_frame_count /=\n\n                      fourxm->tracks[fourxm->selected_track].channels;\n\n                if (fourxm->tracks[fourxm->selected_track].adpcm)\n\n                    audio_frame_count *= 2;\n\n                else \n\n                    audio_frame_count /=\n\n                    (fourxm->tracks[fourxm->selected_track].bits / 8);\n\n                pts_inc = audio_frame_count;\n\n                pts_inc *= 90000;\n\n                pts_inc /= fourxm->tracks[fourxm->selected_track].sample_rate;\n\n                fourxm->audio_pts += pts_inc;\n\n\n\n            } else {\n\n                url_fseek(pb, size, SEEK_CUR);\n\n            }\n\n            break;\n\n\n\n        default:\n\n            url_fseek(pb, size, SEEK_CUR);\n\n            break;\n\n        }\n\n    }\n\n    return ret;\n\n}\n", "idx": 395, "_split": "valid", "_hash": "d88c92aed09812ad4a849a13fa25ccb4"}
{"project": "FFmpeg", "commit_id": "a8d67efa53dae1d14614e3a7bd4e77e4eab066ab", "target": 0, "func": "static int count_paired_channels(uint8_t (*layout_map)[3], int tags, int pos, int *current) {\n\n    int num_pos_channels = 0;\n\n    int first_cpe = 0;\n\n    int sce_parity = 0;\n\n    int i;\n\n    for (i = *current; i < tags; i++) {\n\n        if (layout_map[i][2] != pos)\n\n            break;\n\n        if (layout_map[i][0] == TYPE_CPE) {\n\n            if (sce_parity) {\n\n                if (pos == AAC_CHANNEL_FRONT || !first_cpe) {\n\n                    sce_parity = 0;\n\n                } else {\n\n                    return -1;\n\n                }\n\n            }\n\n            num_pos_channels += 2;\n\n            first_cpe = 1;\n\n        } else {\n\n            num_pos_channels++;\n\n            sce_parity ^= 1;\n\n        }\n\n    }\n\n    if (sce_parity &&\n\n        ((pos == AAC_CHANNEL_FRONT && first_cpe) || pos == AAC_CHANNEL_SIDE))\n\n            return -1;\n\n    *current = i;\n\n    return num_pos_channels;\n\n}\n", "idx": 420, "_split": "valid", "_hash": "7e1b9efb355464c1f63b929fe579df70"}
{"project": "FFmpeg", "commit_id": "bbe26eff2235dc2d1c79a5a1e25b46d8d7f0fe08", "target": 1, "func": "static int decode_slice(struct AVCodecContext *avctx, void *arg)\n\n{\n\n    H264Context *h = *(void **)arg;\n\n    int lf_x_start = h->mb_x;\n\n\n\n    h->mb_skip_run = -1;\n\n\n\n    av_assert0(h->block_offset[15] == (4 * ((scan8[15] - scan8[0]) & 7) << h->pixel_shift) + 4 * h->linesize * ((scan8[15] - scan8[0]) >> 3));\n\n\n\n    h->is_complex = FRAME_MBAFF(h) || h->picture_structure != PICT_FRAME ||\n\n                    avctx->codec_id != AV_CODEC_ID_H264 ||\n\n                    (CONFIG_GRAY && (h->flags & CODEC_FLAG_GRAY));\n\n\n\n    if (!(h->avctx->active_thread_type & FF_THREAD_SLICE) && h->picture_structure == PICT_FRAME) {\n\n        const int start_i  = av_clip(h->resync_mb_x + h->resync_mb_y * h->mb_width, 0, h->mb_num - 1);\n\n        if (start_i) {\n\n            int prev_status = h->er.error_status_table[h->er.mb_index2xy[start_i - 1]];\n\n            prev_status &= ~ VP_START;\n\n            if (prev_status != (ER_MV_END | ER_DC_END | ER_AC_END))\n\n                h->er.error_occurred = 1;\n\n        }\n\n    }\n\n\n\n    if (h->pps.cabac) {\n\n        /* realign */\n\n        align_get_bits(&h->gb);\n\n\n\n        /* init cabac */\n\n        ff_init_cabac_decoder(&h->cabac,\n\n                              h->gb.buffer + get_bits_count(&h->gb) / 8,\n\n                              (get_bits_left(&h->gb) + 7) / 8);\n\n\n\n        ff_h264_init_cabac_states(h);\n\n\n\n        for (;;) {\n\n            // START_TIMER\n\n            int ret = ff_h264_decode_mb_cabac(h);\n\n            int eos;\n\n            // STOP_TIMER(\"decode_mb_cabac\")\n\n\n\n            if (ret >= 0)\n\n                ff_h264_hl_decode_mb(h);\n\n\n\n            // FIXME optimal? or let mb_decode decode 16x32 ?\n\n            if (ret >= 0 && FRAME_MBAFF(h)) {\n\n                h->mb_y++;\n\n\n\n                ret = ff_h264_decode_mb_cabac(h);\n\n\n\n                if (ret >= 0)\n\n                    ff_h264_hl_decode_mb(h);\n\n                h->mb_y--;\n\n            }\n\n            eos = get_cabac_terminate(&h->cabac);\n\n\n\n            if ((h->workaround_bugs & FF_BUG_TRUNCATED) &&\n\n                h->cabac.bytestream > h->cabac.bytestream_end + 2) {\n\n                er_add_slice(h, h->resync_mb_x, h->resync_mb_y, h->mb_x - 1,\n\n                                h->mb_y, ER_MB_END);\n\n                if (h->mb_x >= lf_x_start)\n\n                    loop_filter(h, lf_x_start, h->mb_x + 1);\n\n                return 0;\n\n            }\n\n            if (h->cabac.bytestream > h->cabac.bytestream_end + 2 )\n\n                av_log(h->avctx, AV_LOG_DEBUG, \"bytestream overread %td\\n\", h->cabac.bytestream_end - h->cabac.bytestream);\n\n            if (ret < 0 || h->cabac.bytestream > h->cabac.bytestream_end + 4) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"error while decoding MB %d %d, bytestream (%td)\\n\",\n\n                       h->mb_x, h->mb_y,\n\n                       h->cabac.bytestream_end - h->cabac.bytestream);\n\n                er_add_slice(h, h->resync_mb_x, h->resync_mb_y, h->mb_x,\n\n                                h->mb_y, ER_MB_ERROR);\n\n                return -1;\n\n            }\n\n\n\n            if (++h->mb_x >= h->mb_width) {\n\n                loop_filter(h, lf_x_start, h->mb_x);\n\n                h->mb_x = lf_x_start = 0;\n\n                decode_finish_row(h);\n\n                ++h->mb_y;\n\n                if (FIELD_OR_MBAFF_PICTURE(h)) {\n\n                    ++h->mb_y;\n\n                    if (FRAME_MBAFF(h) && h->mb_y < h->mb_height)\n\n                        predict_field_decoding_flag(h);\n\n                }\n\n            }\n\n\n\n            if (eos || h->mb_y >= h->mb_height) {\n\n                tprintf(h->avctx, \"slice end %d %d\\n\",\n\n                        get_bits_count(&h->gb), h->gb.size_in_bits);\n\n                er_add_slice(h, h->resync_mb_x, h->resync_mb_y, h->mb_x - 1,\n\n                                h->mb_y, ER_MB_END);\n\n                if (h->mb_x > lf_x_start)\n\n                    loop_filter(h, lf_x_start, h->mb_x);\n\n                return 0;\n\n            }\n\n        }\n\n    } else {\n\n        for (;;) {\n\n            int ret = ff_h264_decode_mb_cavlc(h);\n\n\n\n            if (ret >= 0)\n\n                ff_h264_hl_decode_mb(h);\n\n\n\n            // FIXME optimal? or let mb_decode decode 16x32 ?\n\n            if (ret >= 0 && FRAME_MBAFF(h)) {\n\n                h->mb_y++;\n\n                ret = ff_h264_decode_mb_cavlc(h);\n\n\n\n                if (ret >= 0)\n\n                    ff_h264_hl_decode_mb(h);\n\n                h->mb_y--;\n\n            }\n\n\n\n            if (ret < 0) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"error while decoding MB %d %d\\n\", h->mb_x, h->mb_y);\n\n                er_add_slice(h, h->resync_mb_x, h->resync_mb_y, h->mb_x,\n\n                                h->mb_y, ER_MB_ERROR);\n\n                return -1;\n\n            }\n\n\n\n            if (++h->mb_x >= h->mb_width) {\n\n                loop_filter(h, lf_x_start, h->mb_x);\n\n                h->mb_x = lf_x_start = 0;\n\n                decode_finish_row(h);\n\n                ++h->mb_y;\n\n                if (FIELD_OR_MBAFF_PICTURE(h)) {\n\n                    ++h->mb_y;\n\n                    if (FRAME_MBAFF(h) && h->mb_y < h->mb_height)\n\n                        predict_field_decoding_flag(h);\n\n                }\n\n                if (h->mb_y >= h->mb_height) {\n\n                    tprintf(h->avctx, \"slice end %d %d\\n\",\n\n                            get_bits_count(&h->gb), h->gb.size_in_bits);\n\n\n\n                    if (   get_bits_left(&h->gb) == 0\n\n                        || get_bits_left(&h->gb) > 0 && !(h->avctx->err_recognition & AV_EF_AGGRESSIVE)) {\n\n                        er_add_slice(h, h->resync_mb_x, h->resync_mb_y,\n\n                                        h->mb_x - 1, h->mb_y,\n\n                                        ER_MB_END);\n\n\n\n                        return 0;\n\n                    } else {\n\n                        er_add_slice(h, h->resync_mb_x, h->resync_mb_y,\n\n                                        h->mb_x, h->mb_y,\n\n                                        ER_MB_END);\n\n\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (get_bits_left(&h->gb) <= 0 && h->mb_skip_run <= 0) {\n\n                tprintf(h->avctx, \"slice end %d %d\\n\",\n\n                        get_bits_count(&h->gb), h->gb.size_in_bits);\n\n                if (get_bits_left(&h->gb) == 0) {\n\n                    er_add_slice(h, h->resync_mb_x, h->resync_mb_y,\n\n                                    h->mb_x - 1, h->mb_y,\n\n                                    ER_MB_END);\n\n                    if (h->mb_x > lf_x_start)\n\n                        loop_filter(h, lf_x_start, h->mb_x);\n\n\n\n                    return 0;\n\n                } else {\n\n                    er_add_slice(h, h->resync_mb_x, h->resync_mb_y, h->mb_x,\n\n                                    h->mb_y, ER_MB_ERROR);\n\n\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 443, "_split": "valid", "_hash": "bf0da83438760f91ab7c2e1757dbee6a"}
{"project": "FFmpeg", "commit_id": "5b0ad91b996506632708dcefc22d2835d04a4dba", "target": 1, "func": "static int img_read_packet(AVFormatContext *s1, AVPacket *pkt)\n\n{\n\n    VideoData *s = s1->priv_data;\n\n    char filename[1024];\n\n    int ret;\n\n    ByteIOContext f1, *f;\n\n\n\n    if (get_frame_filename(filename, sizeof(filename),\n\n                           s->path, s->img_number) < 0)\n\n        return -EIO;\n\n    \n\n    if (!s->is_pipe) {\n\n        f = &f1;\n\n        if (url_fopen(f, filename, URL_RDONLY) < 0)\n\n            return -EIO;\n\n    } else {\n\n        f = &s1->pb;\n\n        if (url_feof(f))\n\n            return -EIO;\n\n    }\n\n\n\n    av_new_packet(pkt, s->img_size);\n\n    pkt->stream_index = 0;\n\n\n\n    switch(s->img_fmt) {\n\n    case IMGFMT_PGMYUV:\n\n        ret = pgm_read(s, f, pkt->data, pkt->size, 1);\n\n        break;\n\n    case IMGFMT_PGM:\n\n        ret = pgm_read(s, f, pkt->data, pkt->size, 0);\n\n        break;\n\n    case IMGFMT_YUV:\n\n        ret = yuv_read(s, filename, pkt->data, pkt->size);\n\n        break;\n\n    case IMGFMT_PPM:\n\n        ret = ppm_read(s, f, pkt->data, pkt->size);\n\n        break;\n\n    default:\n\n        return -EIO;\n\n    }\n\n    \n\n    if (!s->is_pipe) {\n\n        url_fclose(f);\n\n    }\n\n\n\n    if (ret < 0) {\n\n        av_free_packet(pkt);\n\n        return -EIO; /* signal EOF */\n\n    } else {\n\n        s->img_number++;\n\n        return 0;\n\n    }\n\n}\n", "idx": 446, "_split": "valid", "_hash": "34318efda394c3194a8ebde0115e3e9f"}
{"project": "FFmpeg", "commit_id": "82dd7d0dec29ee59af91ce18c29eb151b363ff37", "target": 0, "func": "static int motion_inter_4v_block (bit_buffer_t *bitbuf,\n\n\t\t\t\t  uint8_t *current, uint8_t *previous, int pitch,\n\n\t\t\t\t  svq1_pmv_t *motion,int x, int y) {\n\n  uint8_t    *src;\n\n  uint8_t    *dst;\n\n  svq1_pmv_t  mv;\n\n  svq1_pmv_t *pmv[4];\n\n  int\t      i, result;\n\n\n\n  /* predict and decode motion vector (0) */\n\n  pmv[0] = &motion[0];\n\n  pmv[1] = &motion[(x / 8) + 2];\n\n  pmv[2] = &motion[(x / 8) + 4];\n\n\n\n  if (y == 0) {\n\n    pmv[1] = pmv[0];\n\n    pmv[2] = pmv[0];\n\n  }\n\n\n\n  result = decode_motion_vector (bitbuf, &mv, pmv);\n\n\n\n  if (result != 0)\n\n    return result;\n\n\n\n  /* predict and decode motion vector (1) */\n\n  pmv[0] = &mv;\n\n  pmv[1] = &motion[(x / 8) + 3];\n\n\n\n  if (y == 0) {\n\n    pmv[1] = pmv[0];\n\n    pmv[2] = pmv[0];\n\n  }\n\n\n\n  result = decode_motion_vector (bitbuf, &motion[0], pmv);\n\n\n\n  if (result != 0)\n\n    return result;\n\n\n\n  /* predict and decode motion vector (2) */\n\n  pmv[1] = &motion[0];\n\n  pmv[2] = &motion[(x / 8) + 1];\n\n\n\n  result = decode_motion_vector (bitbuf, &motion[(x / 8) + 2], pmv);\n\n\n\n  if (result != 0)\n\n    return result;\n\n\n\n  /* predict and decode motion vector (3) */\n\n  pmv[2] = &motion[(x / 8) + 2];\n\n  pmv[3] = &motion[(x / 8) + 3];\n\n\n\n  result = decode_motion_vector (bitbuf, pmv[3], pmv);\n\n\n\n  if (result != 0)\n\n    return result;\n\n\n\n  /* form predictions */\n\n  for (i=0; i < 4; i++) {\n\n    src = &previous[(x + (pmv[i]->x >> 1)) + (y + (pmv[i]->y >> 1))*pitch];\n\n    dst = current;\n\n\n\n    put_pixels_tab[((pmv[i]->y & 1) << 1) | (pmv[i]->x & 1)](dst,src,pitch,8);\n\n\n\n    /* select next block */\n\n    if (i & 1) {\n\n      current  += 8*(pitch - 1);\n\n      previous += 8*(pitch - 1);\n\n    } else {\n\n      current  += 8;\n\n      previous += 8;\n\n    }\n\n  }\n\n\n\n  return 0;\n\n}\n", "idx": 452, "_split": "valid", "_hash": "72c194071eb8df0900b29c37575aeff9"}
{"project": "FFmpeg", "commit_id": "34aeb5dbc4fe7267df5f0ebe2ec84c5a8d36a896", "target": 0, "func": "static int xmv_read_header(AVFormatContext *s)\n\n{\n\n    XMVDemuxContext *xmv = s->priv_data;\n\n    AVIOContext     *pb  = s->pb;\n\n\n\n    uint32_t file_version;\n\n    uint32_t this_packet_size;\n\n    uint16_t audio_track;\n\n    int ret;\n\n\n\n    s->ctx_flags |= AVFMTCTX_NOHEADER;\n\n\n\n    avio_skip(pb, 4); /* Next packet size */\n\n\n\n    this_packet_size = avio_rl32(pb);\n\n\n\n    avio_skip(pb, 4); /* Max packet size */\n\n    avio_skip(pb, 4); /* \"xobX\" */\n\n\n\n    file_version = avio_rl32(pb);\n\n    if ((file_version != 4) && (file_version != 2))\n\n        avpriv_request_sample(s, \"Uncommon version %\"PRIu32\"\", file_version);\n\n\n\n    /* Video tracks */\n\n\n\n    xmv->video_width    = avio_rl32(pb);\n\n    xmv->video_height   = avio_rl32(pb);\n\n    xmv->video_duration = avio_rl32(pb);\n\n\n\n    /* Audio tracks */\n\n\n\n    xmv->audio_track_count = avio_rl16(pb);\n\n\n\n    avio_skip(pb, 2); /* Unknown (padding?) */\n\n\n\n    xmv->audio = av_mallocz_array(xmv->audio_track_count, sizeof(XMVAudioPacket));\n\n    if (!xmv->audio) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    for (audio_track = 0; audio_track < xmv->audio_track_count; audio_track++) {\n\n        XMVAudioPacket *packet = &xmv->audio[audio_track];\n\n\n\n        packet->compression     = avio_rl16(pb);\n\n        packet->channels        = avio_rl16(pb);\n\n        packet->sample_rate     = avio_rl32(pb);\n\n        packet->bits_per_sample = avio_rl16(pb);\n\n        packet->flags           = avio_rl16(pb);\n\n\n\n        packet->bit_rate      = packet->bits_per_sample *\n\n                                packet->sample_rate *\n\n                                packet->channels;\n\n        packet->block_align   = XMV_BLOCK_ALIGN_SIZE * packet->channels;\n\n        packet->block_samples = 64;\n\n        packet->codec_id      = ff_wav_codec_get_id(packet->compression,\n\n                                                    packet->bits_per_sample);\n\n\n\n        packet->stream_index = -1;\n\n\n\n        packet->frame_size  = 0;\n\n        packet->block_count = 0;\n\n\n\n        /* TODO: ADPCM'd 5.1 sound is encoded in three separate streams.\n\n         *       Those need to be interleaved to a proper 5.1 stream. */\n\n        if (packet->flags & XMV_AUDIO_ADPCM51)\n\n            av_log(s, AV_LOG_WARNING, \"Unsupported 5.1 ADPCM audio stream \"\n\n                                      \"(0x%04X)\\n\", packet->flags);\n\n\n\n        if (!packet->channels || !packet->sample_rate ||\n\n             packet->channels >= UINT16_MAX / XMV_BLOCK_ALIGN_SIZE) {\n\n            av_log(s, AV_LOG_ERROR, \"Invalid parameters for audio track %\"PRIu16\".\\n\",\n\n                   audio_track);\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n\n\n    /* Initialize the packet context */\n\n\n\n    xmv->next_packet_offset = avio_tell(pb);\n\n    xmv->next_packet_size   = this_packet_size - xmv->next_packet_offset;\n\n    xmv->stream_count       = xmv->audio_track_count + 1;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    xmv_read_close(s);\n\n    return ret;\n\n}\n", "idx": 514, "_split": "valid", "_hash": "e36bb25540e57a3af6033b4750f54b60"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int ffv1_encode_init(AVCodecContext *avctx)\n\n{\n\n    FFV1Context *s = avctx->priv_data;\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    int i, j, k, m, ret;\n\n\n\n    ffv1_common_init(avctx);\n\n\n\n    s->version = 0;\n\n\n\n    if ((avctx->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2)) ||\n\n        avctx->slices > 1)\n\n        s->version = FFMAX(s->version, 2);\n\n\n\n    if (avctx->level == 3) {\n\n        s->version = 3;\n\n    }\n\n\n\n    if (s->ec < 0) {\n\n        s->ec = (s->version >= 3);\n\n    }\n\n\n\n    if (s->version >= 2 &&\n\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Version %d requested, please set -strict experimental in \"\n\n               \"order to enable it\\n\",\n\n               s->version);\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    s->ac = avctx->coder_type > 0 ? 2 : 0;\n\n\n\n    s->plane_count = 3;\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_YUV444P9:\n\n    case AV_PIX_FMT_YUV422P9:\n\n    case AV_PIX_FMT_YUV420P9:\n\n        if (!avctx->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 9;\n\n    case AV_PIX_FMT_YUV444P10:\n\n    case AV_PIX_FMT_YUV420P10:\n\n    case AV_PIX_FMT_YUV422P10:\n\n        s->packed_at_lsb = 1;\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 10;\n\n    case AV_PIX_FMT_GRAY16:\n\n    case AV_PIX_FMT_YUV444P16:\n\n    case AV_PIX_FMT_YUV422P16:\n\n    case AV_PIX_FMT_YUV420P16:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample) {\n\n            s->bits_per_raw_sample = 16;\n\n        } else if (!s->bits_per_raw_sample) {\n\n            s->bits_per_raw_sample = avctx->bits_per_raw_sample;\n\n        }\n\n        if (s->bits_per_raw_sample <= 8) {\n\n            av_log(avctx, AV_LOG_ERROR, \"bits_per_raw_sample invalid\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (!s->ac && avctx->coder_type == -1) {\n\n            av_log(avctx, AV_LOG_INFO,\n\n                   \"bits_per_raw_sample > 8, forcing coder 1\\n\");\n\n            s->ac = 2;\n\n        }\n\n        if (!s->ac) {\n\n            av_log(\n\n                avctx, AV_LOG_ERROR,\n\n                \"bits_per_raw_sample of more than 8 needs -coder 1 currently\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->version = FFMAX(s->version, 1);\n\n    case AV_PIX_FMT_GRAY8:\n\n    case AV_PIX_FMT_YUV444P:\n\n    case AV_PIX_FMT_YUV440P:\n\n    case AV_PIX_FMT_YUV422P:\n\n    case AV_PIX_FMT_YUV420P:\n\n    case AV_PIX_FMT_YUV411P:\n\n    case AV_PIX_FMT_YUV410P:\n\n        s->chroma_planes = desc->nb_components < 3 ? 0 : 1;\n\n        s->colorspace    = 0;\n\n        break;\n\n    case AV_PIX_FMT_YUVA444P:\n\n    case AV_PIX_FMT_YUVA422P:\n\n    case AV_PIX_FMT_YUVA420P:\n\n        s->chroma_planes = 1;\n\n        s->colorspace    = 0;\n\n        s->transparency  = 1;\n\n        break;\n\n    case AV_PIX_FMT_RGB32:\n\n        s->colorspace   = 1;\n\n        s->transparency = 1;\n\n        break;\n\n    case AV_PIX_FMT_GBRP9:\n\n        if (!avctx->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 9;\n\n    case AV_PIX_FMT_GBRP10:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 10;\n\n    case AV_PIX_FMT_GBRP16:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 16;\n\n        else if (!s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = avctx->bits_per_raw_sample;\n\n        s->colorspace    = 1;\n\n        s->chroma_planes = 1;\n\n        s->version       = FFMAX(s->version, 1);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"format not supported\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (s->transparency) {\n\n        av_log(\n\n            avctx, AV_LOG_WARNING,\n\n            \"Storing alpha plane, this will require a recent FFV1 decoder to playback!\\n\");\n\n    }\n\n    if (avctx->context_model > 1U) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Invalid context model %d, valid values are 0 and 1\\n\",\n\n               avctx->context_model);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (s->ac > 1)\n\n        for (i = 1; i < 256; i++)\n\n            s->state_transition[i] = ffv1_ver2_state[i];\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        s->quant_table_count = 2;\n\n        if (s->bits_per_raw_sample <= 8) {\n\n            s->quant_tables[0][0][i] = ffv1_quant11[i];\n\n            s->quant_tables[0][1][i] = ffv1_quant11[i] * 11;\n\n            s->quant_tables[0][2][i] = ffv1_quant11[i] * 11 * 11;\n\n            s->quant_tables[1][0][i] = ffv1_quant11[i];\n\n            s->quant_tables[1][1][i] = ffv1_quant11[i] * 11;\n\n            s->quant_tables[1][2][i] = ffv1_quant5[i]  * 11 * 11;\n\n            s->quant_tables[1][3][i] = ffv1_quant5[i]  *  5 * 11 * 11;\n\n            s->quant_tables[1][4][i] = ffv1_quant5[i]  *  5 *  5 * 11 * 11;\n\n        } else {\n\n            s->quant_tables[0][0][i] = ffv1_quant9_10bit[i];\n\n            s->quant_tables[0][1][i] = ffv1_quant9_10bit[i] * 11;\n\n            s->quant_tables[0][2][i] = ffv1_quant9_10bit[i] * 11 * 11;\n\n            s->quant_tables[1][0][i] = ffv1_quant9_10bit[i];\n\n            s->quant_tables[1][1][i] = ffv1_quant9_10bit[i] * 11;\n\n            s->quant_tables[1][2][i] = ffv1_quant5_10bit[i] * 11 * 11;\n\n            s->quant_tables[1][3][i] = ffv1_quant5_10bit[i] *  5 * 11 * 11;\n\n            s->quant_tables[1][4][i] = ffv1_quant5_10bit[i] *  5 *  5 * 11 * 11;\n\n        }\n\n    }\n\n    s->context_count[0] = (11 * 11 * 11        + 1) / 2;\n\n    s->context_count[1] = (11 * 11 * 5 * 5 * 5 + 1) / 2;\n\n    memcpy(s->quant_table, s->quant_tables[avctx->context_model],\n\n           sizeof(s->quant_table));\n\n\n\n    for (i = 0; i < s->plane_count; i++) {\n\n        PlaneContext *const p = &s->plane[i];\n\n\n\n        memcpy(p->quant_table, s->quant_table, sizeof(p->quant_table));\n\n        p->quant_table_index = avctx->context_model;\n\n        p->context_count     = s->context_count[p->quant_table_index];\n\n    }\n\n\n\n    if ((ret = ffv1_allocate_initial_states(s)) < 0)\n\n        return ret;\n\n\n\n    avctx->coded_frame = av_frame_alloc();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    if (!s->transparency)\n\n        s->plane_count = 2;\n\n\n\n    av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_h_shift,\n\n                                     &s->chroma_v_shift);\n\n\n\n    s->picture_number = 0;\n\n\n\n    if (avctx->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2)) {\n\n        for (i = 0; i < s->quant_table_count; i++) {\n\n            s->rc_stat2[i] = av_mallocz(s->context_count[i] *\n\n                                        sizeof(*s->rc_stat2[i]));\n\n            if (!s->rc_stat2[i])\n\n                return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n    if (avctx->stats_in) {\n\n        char *p = avctx->stats_in;\n\n        uint8_t best_state[256][256];\n\n        int gob_count = 0;\n\n        char *next;\n\n\n\n        av_assert0(s->version >= 2);\n\n\n\n        for (;; ) {\n\n            for (j = 0; j < 256; j++)\n\n                for (i = 0; i < 2; i++) {\n\n                    s->rc_stat[j][i] = strtol(p, &next, 0);\n\n                    if (next == p) {\n\n                        av_log(avctx, AV_LOG_ERROR,\n\n                               \"2Pass file invalid at %d %d [%s]\\n\", j, i, p);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    p = next;\n\n                }\n\n            for (i = 0; i < s->quant_table_count; i++)\n\n                for (j = 0; j < s->context_count[i]; j++) {\n\n                    for (k = 0; k < 32; k++)\n\n                        for (m = 0; m < 2; m++) {\n\n                            s->rc_stat2[i][j][k][m] = strtol(p, &next, 0);\n\n                            if (next == p) {\n\n                                av_log(avctx, AV_LOG_ERROR,\n\n                                       \"2Pass file invalid at %d %d %d %d [%s]\\n\",\n\n                                       i, j, k, m, p);\n\n                                return AVERROR_INVALIDDATA;\n\n                            }\n\n                            p = next;\n\n                        }\n\n                }\n\n            gob_count = strtol(p, &next, 0);\n\n            if (next == p || gob_count <= 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"2Pass file invalid\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            p = next;\n\n            while (*p == '\\n' || *p == ' ')\n\n                p++;\n\n            if (p[0] == 0)\n\n                break;\n\n        }\n\n        sort_stt(s, s->state_transition);\n\n\n\n        find_best_state(best_state, s->state_transition);\n\n\n\n        for (i = 0; i < s->quant_table_count; i++) {\n\n            for (j = 0; j < s->context_count[i]; j++)\n\n                for (k = 0; k < 32; k++) {\n\n                    double p = 128;\n\n                    if (s->rc_stat2[i][j][k][0] + s->rc_stat2[i][j][k][1]) {\n\n                        p = 256.0 * s->rc_stat2[i][j][k][1] /\n\n                            (s->rc_stat2[i][j][k][0] + s->rc_stat2[i][j][k][1]);\n\n                    }\n\n                    s->initial_states[i][j][k] =\n\n                        best_state[av_clip(round(p), 1, 255)][av_clip((s->rc_stat2[i][j][k][0] +\n\n                                                                       s->rc_stat2[i][j][k][1]) /\n\n                                                                      gob_count, 0, 255)];\n\n                }\n\n        }\n\n    }\n\n\n\n    if (s->version > 1) {\n\n        for (s->num_v_slices = 2; s->num_v_slices < 9; s->num_v_slices++)\n\n            for (s->num_h_slices = s->num_v_slices;\n\n                 s->num_h_slices < 2 * s->num_v_slices; s->num_h_slices++)\n\n                if (avctx->slices == s->num_h_slices * s->num_v_slices &&\n\n                    avctx->slices <= 64 || !avctx->slices)\n\n                    goto slices_ok;\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Unsupported number %d of slices requested, please specify a \"\n\n               \"supported number with -slices (ex:4,6,9,12,16, ...)\\n\",\n\n               avctx->slices);\n\n        return AVERROR(ENOSYS);\n\nslices_ok:\n\n        write_extradata(s);\n\n    }\n\n\n\n    if ((ret = ffv1_init_slice_contexts(s)) < 0)\n\n        return ret;\n\n    if ((ret = init_slices_state(s)) < 0)\n\n        return ret;\n\n\n\n#define STATS_OUT_SIZE 1024 * 1024 * 6\n\n    if (avctx->flags & CODEC_FLAG_PASS1) {\n\n        avctx->stats_out = av_mallocz(STATS_OUT_SIZE);\n\n        for (i = 0; i < s->quant_table_count; i++)\n\n            for (j = 0; j < s->slice_count; j++) {\n\n                FFV1Context *sf = s->slice_context[j];\n\n                av_assert0(!sf->rc_stat2[i]);\n\n                sf->rc_stat2[i] = av_mallocz(s->context_count[i] *\n\n                                             sizeof(*sf->rc_stat2[i]));\n\n                if (!sf->rc_stat2[i])\n\n                    return AVERROR(ENOMEM);\n\n            }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 534, "_split": "valid", "_hash": "391aff3f78f1896a8d67478a95baae79"}
{"project": "FFmpeg", "commit_id": "955aec3c7c7be39b659197e1ec379a09f2b7c41c", "target": 0, "func": "static int mp3lame_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                                const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    LAMEContext *s = avctx->priv_data;\n\n    MPADecodeHeader hdr;\n\n    int len, ret, ch;\n\n    int lame_result;\n\n    uint32_t h;\n\n\n\n    if (frame) {\n\n        switch (avctx->sample_fmt) {\n\n        case AV_SAMPLE_FMT_S16P:\n\n            ENCODE_BUFFER(lame_encode_buffer, int16_t, frame->data);\n\n            break;\n\n        case AV_SAMPLE_FMT_S32P:\n\n            ENCODE_BUFFER(lame_encode_buffer_int, int32_t, frame->data);\n\n            break;\n\n        case AV_SAMPLE_FMT_FLTP:\n\n            if (frame->linesize[0] < 4 * FFALIGN(frame->nb_samples, 8)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"inadequate AVFrame plane padding\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n            for (ch = 0; ch < avctx->channels; ch++) {\n\n                s->fdsp.vector_fmul_scalar(s->samples_flt[ch],\n\n                                           (const float *)frame->data[ch],\n\n                                           32768.0f,\n\n                                           FFALIGN(frame->nb_samples, 8));\n\n            }\n\n            ENCODE_BUFFER(lame_encode_buffer_float, float, s->samples_flt);\n\n            break;\n\n        default:\n\n            return AVERROR_BUG;\n\n        }\n\n    } else {\n\n        lame_result = lame_encode_flush(s->gfp, s->buffer + s->buffer_index,\n\n                                        s->buffer_size - s->buffer_index);\n\n    }\n\n    if (lame_result < 0) {\n\n        if (lame_result == -1) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"lame: output buffer too small (buffer index: %d, free bytes: %d)\\n\",\n\n                   s->buffer_index, s->buffer_size - s->buffer_index);\n\n        }\n\n        return -1;\n\n    }\n\n    s->buffer_index += lame_result;\n\n    ret = realloc_buffer(s);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"error reallocating output buffer\\n\");\n\n        return ret;\n\n    }\n\n\n\n    /* add current frame to the queue */\n\n    if (frame) {\n\n        if ((ret = ff_af_queue_add(&s->afq, frame)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    /* Move 1 frame from the LAME buffer to the output packet, if available.\n\n       We have to parse the first frame header in the output buffer to\n\n       determine the frame size. */\n\n    if (s->buffer_index < 4)\n\n        return 0;\n\n    h = AV_RB32(s->buffer);\n\n    if (ff_mpa_check_header(h) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid mp3 header at start of buffer\\n\");\n\n        return AVERROR_BUG;\n\n    }\n\n    if (avpriv_mpegaudio_decode_header(&hdr, h)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"free format output not supported\\n\");\n\n        return -1;\n\n    }\n\n    len = hdr.frame_size;\n\n    ff_dlog(avctx, \"in:%d packet-len:%d index:%d\\n\", avctx->frame_size, len,\n\n            s->buffer_index);\n\n    if (len <= s->buffer_index) {\n\n        if ((ret = ff_alloc_packet(avpkt, len))) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n\n            return ret;\n\n        }\n\n        memcpy(avpkt->data, s->buffer, len);\n\n        s->buffer_index -= len;\n\n        memmove(s->buffer, s->buffer + len, s->buffer_index);\n\n\n\n        /* Get the next frame pts/duration */\n\n        ff_af_queue_remove(&s->afq, avctx->frame_size, &avpkt->pts,\n\n                           &avpkt->duration);\n\n\n\n        avpkt->size = len;\n\n        *got_packet_ptr = 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 555, "_split": "valid", "_hash": "960e60fdc9e5c849c0d08c5caa34f2ce"}
{"project": "FFmpeg", "commit_id": "a9837b58e1b060ed31753821536de128a0deaf26", "target": 1, "func": "static int tta_decode_frame(AVCodecContext *avctx,\n\n        void *data, int *data_size,\n\n        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    TTAContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    init_get_bits(&s->gb, buf, buf_size*8);\n\n    {\n\n        int32_t predictors[s->channels];\n\n        TTAFilter filters[s->channels];\n\n        TTARice rices[s->channels];\n\n        int cur_chan = 0, framelen = s->frame_length;\n\n        int32_t *p;\n\n\n\n        // FIXME: seeking\n\n        s->total_frames--;\n\n        if (!s->total_frames && s->last_frame_length)\n\n            framelen = s->last_frame_length;\n\n\n\n        // init per channel states\n\n        for (i = 0; i < s->channels; i++) {\n\n            predictors[i] = 0;\n\n            ttafilter_init(&(filters[i]), ttafilter_configs[s->bps-1][0], ttafilter_configs[s->bps-1][1]);\n\n            rice_init(&(rices[i]), 10, 10);\n\n        }\n\n\n\n        for (p = s->decode_buffer; p < s->decode_buffer + (framelen * s->channels); p++) {\n\n            int32_t *predictor = &(predictors[cur_chan]);\n\n            TTAFilter *filter = &(filters[cur_chan]);\n\n            TTARice *rice = &(rices[cur_chan]);\n\n            uint32_t unary, depth, k;\n\n            int32_t value;\n\n\n\n            unary = tta_get_unary(&s->gb);\n\n\n\n            if (unary == 0) {\n\n                depth = 0;\n\n                k = rice->k0;\n\n            } else {\n\n                depth = 1;\n\n                k = rice->k1;\n\n                unary--;\n\n            }\n\n\n\n            if (k)\n\n                value = (unary << k) + get_bits(&s->gb, k);\n\n            else\n\n                value = unary;\n\n\n\n            // FIXME: copy paste from original\n\n            switch (depth) {\n\n            case 1:\n\n                rice->sum1 += value - (rice->sum1 >> 4);\n\n                if (rice->k1 > 0 && rice->sum1 < shift_16[rice->k1])\n\n                    rice->k1--;\n\n                else if(rice->sum1 > shift_16[rice->k1 + 1])\n\n                    rice->k1++;\n\n                value += shift_1[rice->k0];\n\n            default:\n\n                rice->sum0 += value - (rice->sum0 >> 4);\n\n                if (rice->k0 > 0 && rice->sum0 < shift_16[rice->k0])\n\n                    rice->k0--;\n\n                else if(rice->sum0 > shift_16[rice->k0 + 1])\n\n                    rice->k0++;\n\n            }\n\n\n\n            // extract coded value\n\n#define UNFOLD(x) (((x)&1) ? (++(x)>>1) : (-(x)>>1))\n\n            *p = UNFOLD(value);\n\n\n\n            // run hybrid filter\n\n            ttafilter_process(filter, p, 0);\n\n\n\n            // fixed order prediction\n\n#define PRED(x, k) (int32_t)((((uint64_t)x << k) - x) >> k)\n\n            switch (s->bps) {\n\n                case 1: *p += PRED(*predictor, 4); break;\n\n                case 2:\n\n                case 3: *p += PRED(*predictor, 5); break;\n\n                case 4: *p += *predictor; break;\n\n            }\n\n            *predictor = *p;\n\n\n\n#if 0\n\n            // extract 32bit float from last two int samples\n\n            if (s->is_float && ((p - data) & 1)) {\n\n                uint32_t neg = *p & 0x80000000;\n\n                uint32_t hi = *(p - 1);\n\n                uint32_t lo = abs(*p) - 1;\n\n\n\n                hi += (hi || lo) ? 0x3f80 : 0;\n\n                // SWAP16: swap all the 16 bits\n\n                *(p - 1) = (hi << 16) | SWAP16(lo) | neg;\n\n            }\n\n#endif\n\n\n\n            /*if ((get_bits_count(&s->gb)+7)/8 > buf_size)\n\n            {\n\n                av_log(NULL, AV_LOG_INFO, \"overread!!\\n\");\n\n                break;\n\n            }*/\n\n\n\n            // flip channels\n\n            if (cur_chan < (s->channels-1))\n\n                cur_chan++;\n\n            else {\n\n                // decorrelate in case of stereo integer\n\n                if (!s->is_float && (s->channels > 1)) {\n\n                    int32_t *r = p - 1;\n\n                    for (*p += *r / 2; r > p - s->channels; r--)\n\n                        *r = *(r + 1) - *r;\n\n                }\n\n                cur_chan = 0;\n\n            }\n\n        }\n\n\n\n        skip_bits(&s->gb, 32); // frame crc\n\n\n\n        // convert to output buffer\n\n        switch(s->bps) {\n\n            case 2: {\n\n                uint16_t *samples = data;\n\n                for (p = s->decode_buffer; p < s->decode_buffer + (framelen * s->channels); p++) {\n\n//                    *samples++ = (unsigned char)*p;\n\n//                    *samples++ = (unsigned char)(*p >> 8);\n\n                    *samples++ = *p;\n\n                }\n\n                *data_size = (uint8_t *)samples - (uint8_t *)data;\n\n                break;\n\n            }\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Error, only 16bit samples supported!\\n\");\n\n        }\n\n    }\n\n\n\n//    return get_bits_count(&s->gb)+7)/8;\n\n    return buf_size;\n\n}\n", "idx": 578, "_split": "valid", "_hash": "51074a2a2dc422a33d3124234356b383"}
{"project": "FFmpeg", "commit_id": "7cf22c79706d23d40d16cee37eb32d5797adcc2c", "target": 0, "func": "yuv2rgba64_2_c_template(SwsContext *c, const int32_t *buf[2],\n\n                       const int32_t *ubuf[2], const int32_t *vbuf[2],\n\n                       const int32_t *abuf[2], uint16_t *dest, int dstW,\n\n                       int yalpha, int uvalpha, int y,\n\n                       enum AVPixelFormat target, int hasAlpha, int eightbytes)\n\n{\n\n    const int32_t *buf0  = buf[0],  *buf1  = buf[1],\n\n                  *ubuf0 = ubuf[0], *ubuf1 = ubuf[1],\n\n                  *vbuf0 = vbuf[0], *vbuf1 = vbuf[1],\n\n                  *abuf0 = hasAlpha ? abuf[0] : NULL,\n\n                  *abuf1 = hasAlpha ? abuf[1] : NULL;\n\n    int  yalpha1 = 4096 - yalpha;\n\n    int uvalpha1 = 4096 - uvalpha;\n\n    int i;\n\n    int A1 = 0xffff<<14, A2 = 0xffff<<14;\n\n\n\n    for (i = 0; i < ((dstW + 1) >> 1); i++) {\n\n        int Y1 = (buf0[i * 2]     * yalpha1  + buf1[i * 2]     * yalpha) >> 14;\n\n        int Y2 = (buf0[i * 2 + 1] * yalpha1  + buf1[i * 2 + 1] * yalpha) >> 14;\n\n        int U  = (ubuf0[i]        * uvalpha1 + ubuf1[i]        * uvalpha + (-128 << 23)) >> 14;\n\n        int V  = (vbuf0[i]        * uvalpha1 + vbuf1[i]        * uvalpha + (-128 << 23)) >> 14;\n\n        int R, G, B;\n\n\n\n        Y1 -= c->yuv2rgb_y_offset;\n\n        Y2 -= c->yuv2rgb_y_offset;\n\n        Y1 *= c->yuv2rgb_y_coeff;\n\n        Y2 *= c->yuv2rgb_y_coeff;\n\n        Y1 += 1 << 13;\n\n        Y2 += 1 << 13;\n\n\n\n        R = V * c->yuv2rgb_v2r_coeff;\n\n        G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n        B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n        if (hasAlpha) {\n\n            A1 = (abuf0[i * 2    ] * yalpha1 + abuf1[i * 2    ] * yalpha) >> 1;\n\n            A2 = (abuf0[i * 2 + 1] * yalpha1 + abuf1[i * 2 + 1] * yalpha) >> 1;\n\n\n\n            A1 += 1 << 13;\n\n            A2 += 1 << 13;\n\n        }\n\n\n\n        output_pixel(&dest[0], av_clip_uintp2(R_B + Y1, 30) >> 14);\n\n        output_pixel(&dest[1], av_clip_uintp2(  G + Y1, 30) >> 14);\n\n        output_pixel(&dest[2], av_clip_uintp2(B_R + Y1, 30) >> 14);\n\n        if (eightbytes) {\n\n            output_pixel(&dest[3], av_clip_uintp2(A1      , 30) >> 14);\n\n            output_pixel(&dest[4], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n            output_pixel(&dest[5], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n            output_pixel(&dest[6], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n            output_pixel(&dest[7], av_clip_uintp2(A2      , 30) >> 14);\n\n            dest += 8;\n\n        } else {\n\n            output_pixel(&dest[3], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n            output_pixel(&dest[4], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n            output_pixel(&dest[5], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n            dest += 6;\n\n        }\n\n    }\n\n}\n", "idx": 583, "_split": "valid", "_hash": "5092dace0901c332918a056a8069cfa1"}
{"project": "FFmpeg", "commit_id": "330deb75923675224fb9aed311d3d6ce3ec52420", "target": 1, "func": "static void backup_duplicate_context(MpegEncContext *bak, MpegEncContext *src){\n\n#define COPY(a) bak->a= src->a\n\n    COPY(allocated_edge_emu_buffer);\n\n    COPY(edge_emu_buffer);\n\n    COPY(me.scratchpad);\n\n    COPY(me.temp);\n\n    COPY(rd_scratchpad);\n\n    COPY(b_scratchpad);\n\n    COPY(obmc_scratchpad);\n\n    COPY(me.map);\n\n    COPY(me.score_map);\n\n    COPY(blocks);\n\n    COPY(block);\n\n    COPY(start_mb_y);\n\n    COPY(end_mb_y);\n\n    COPY(me.map_generation);\n\n    COPY(pb);\n\n    COPY(dct_error_sum);\n\n    COPY(dct_count[0]);\n\n    COPY(dct_count[1]);\n\n    COPY(ac_val_base);\n\n    COPY(ac_val[0]);\n\n    COPY(ac_val[1]);\n\n    COPY(ac_val[2]);\n\n#undef COPY\n\n}\n", "idx": 646, "_split": "valid", "_hash": "9e83ed0930bdc4863e1ebe0ed80346b0"}
{"project": "FFmpeg", "commit_id": "84343dd9d3b8e19c95c0f641a9f97915efec0633", "target": 0, "func": "static av_cold void free_frame_buffers(Indeo3DecodeContext *ctx)\n\n{\n\n    int p;\n\n\n\n    ctx->width=\n\n    ctx->height= 0;\n\n\n\n    for (p = 0; p < 3; p++) {\n\n        av_freep(&ctx->planes[p].buffers[0]);\n\n        av_freep(&ctx->planes[p].buffers[1]);\n\n        ctx->planes[p].pixels[0] = ctx->planes[p].pixels[1] = 0;\n\n    }\n\n}\n", "idx": 653, "_split": "valid", "_hash": "4b6297c37c54fd9f8ef1774bd7c658a4"}
{"project": "FFmpeg", "commit_id": "a8dbe9514f865f6a8efb304a720025cb1ef9ae3f", "target": 0, "func": "static AVInputFormat *probe_input_format(AVProbeData *pd, int is_opened)\n\n{\n\n    AVInputFormat *fmt1, *fmt;\n\n    int score, score_max;\n\n\n\n    fmt = NULL;\n\n    score_max = 0;\n\n    for(fmt1 = first_iformat; fmt1 != NULL; fmt1 = fmt1->next) {\n\n        if (!is_opened && !(fmt1->flags & AVFMT_NOFILE))\n\n            continue;\n\n        score = 0;\n\n        if (fmt1->extensions) {\n\n            if (match_ext(pd->filename, fmt1->extensions)) {\n\n                score = 50;\n\n            }\n\n        } else if (fmt1->read_probe) {\n\n            score = fmt1->read_probe(pd);\n\n        }\n\n        if (score > score_max) {\n\n            score_max = score;\n\n            fmt = fmt1;\n\n        }\n\n    }\n\n    return fmt;\n\n}\n", "idx": 668, "_split": "valid", "_hash": "20264133f6d3f039ac2b0e378e8a4ebc"}
{"project": "FFmpeg", "commit_id": "69fa23961ededd725c68b188493cf2653d70f4fd", "target": 1, "func": "int av_seek_frame(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)\n\n{\n\n    int ret;\n\n    AVStream *st;\n\n\n\n    ff_read_frame_flush(s);\n\n\n\n    if(flags & AVSEEK_FLAG_BYTE)\n\n        return av_seek_frame_byte(s, stream_index, timestamp, flags);\n\n\n\n    if(stream_index < 0){\n\n        stream_index= av_find_default_stream_index(s);\n\n        if(stream_index < 0)\n\n            return -1;\n\n\n\n        st= s->streams[stream_index];\n\n       /* timestamp for default must be expressed in AV_TIME_BASE units */\n\n        timestamp = av_rescale(timestamp, st->time_base.den, AV_TIME_BASE * (int64_t)st->time_base.num);\n\n    }\n\n\n\n    /* first, we try the format specific seek */\n\n    if (s->iformat->read_seek)\n\n        ret = s->iformat->read_seek(s, stream_index, timestamp, flags);\n\n    else\n\n        ret = -1;\n\n    if (ret >= 0) {\n\n        return 0;\n\n    }\n\n\n\n    if(s->iformat->read_timestamp)\n\n        return av_seek_frame_binary(s, stream_index, timestamp, flags);\n\n    else\n\n        return av_seek_frame_generic(s, stream_index, timestamp, flags);\n\n}\n", "idx": 682, "_split": "valid", "_hash": "da10c4dd67a2307aad18a10c9d0cf9d1"}
{"project": "FFmpeg", "commit_id": "fa0f62c37d90c0760bddccba2054578e2c61ae1a", "target": 0, "func": "static int mpeg_mux_end(AVFormatContext *ctx)\n\n{\n\n    StreamInfo *stream;\n\n    int i;\n\n\n\n    /* flush each packet */\n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        stream = ctx->streams[i]->priv_data;\n\n        if (stream->buffer_ptr > 0) {\n\n            if (i == (ctx->nb_streams - 1)) \n\n                flush_packet(ctx, i, 1);\n\n            else\n\n                flush_packet(ctx, i, 0);\n\n        }\n\n    }\n\n\n\n    /* write the end header */\n\n    //put_be32(&ctx->pb, ISO_11172_END_CODE);\n\n    //put_flush_packet(&ctx->pb);\n\n\n\n    for(i=0;i<ctx->nb_streams;i++)\n\n        av_freep(&ctx->streams[i]->priv_data);\n\n\n\n    return 0;\n\n}\n", "idx": 691, "_split": "valid", "_hash": "c388319b6328c7f7a7c081d6495b636d"}
{"project": "FFmpeg", "commit_id": "ca8064d2d1b293d7a8011bf0a08005c11ae8ba67", "target": 1, "func": "static int opt_new_stream(const char *opt, const char *arg)\n\n{\n\n    AVFormatContext *oc;\n\n    if (nb_output_files <= 0) {\n\n        fprintf(stderr, \"At least one output file must be specified\\n\");\n\n        ffmpeg_exit(1);\n\n    }\n\n    oc = output_files[nb_output_files - 1];\n\n\n\n    if      (!strcmp(opt, \"newvideo\"   )) new_video_stream   (oc);\n\n    else if (!strcmp(opt, \"newaudio\"   )) new_audio_stream   (oc);\n\n    else if (!strcmp(opt, \"newsubtitle\")) new_subtitle_stream(oc);\n\n    else av_assert0(0);\n\n    return 0;\n\n}\n", "idx": 713, "_split": "valid", "_hash": "9e403955287980c5967286f2246bdb2c"}
{"project": "FFmpeg", "commit_id": "28f9ab7029bd1a02f659995919f899f84ee7361b", "target": 0, "func": "void ff_vp3_v_loop_filter_c(uint8_t *first_pixel, int stride, int *bounding_values)\n\n{\n\n    unsigned char *end;\n\n    int filter_value;\n\n    const int nstride= -stride;\n\n\n\n    for (end= first_pixel + 8; first_pixel < end; first_pixel++) {\n\n        filter_value =\n\n            (first_pixel[2 * nstride] - first_pixel[ stride])\n\n         +3*(first_pixel[0          ] - first_pixel[nstride]);\n\n        filter_value = bounding_values[(filter_value + 4) >> 3];\n\n        first_pixel[nstride] = av_clip_uint8(first_pixel[nstride] + filter_value);\n\n        first_pixel[0] = av_clip_uint8(first_pixel[0] - filter_value);\n\n    }\n\n}\n", "idx": 734, "_split": "valid", "_hash": "fa3838f312529a44449216702cbbc17b"}
{"project": "FFmpeg", "commit_id": "da55ee6ccc05efdd9006bb8c31db9012a3326857", "target": 1, "func": "void avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height, int linesize_align[4]){\n\n    int w_align= 1;\n\n    int h_align= 1;\n\n\n\n    switch(s->pix_fmt){\n\n    case PIX_FMT_YUV420P:\n\n    case PIX_FMT_YUYV422:\n\n    case PIX_FMT_UYVY422:\n\n    case PIX_FMT_YUV422P:\n\n    case PIX_FMT_YUV440P:\n\n    case PIX_FMT_YUV444P:\n\n    case PIX_FMT_GRAY8:\n\n    case PIX_FMT_GRAY16BE:\n\n    case PIX_FMT_GRAY16LE:\n\n    case PIX_FMT_YUVJ420P:\n\n    case PIX_FMT_YUVJ422P:\n\n    case PIX_FMT_YUVJ440P:\n\n    case PIX_FMT_YUVJ444P:\n\n    case PIX_FMT_YUVA420P:\n\n    case PIX_FMT_YUV420P9LE:\n\n    case PIX_FMT_YUV420P9BE:\n\n    case PIX_FMT_YUV420P10LE:\n\n    case PIX_FMT_YUV420P10BE:\n\n    case PIX_FMT_YUV422P10LE:\n\n    case PIX_FMT_YUV422P10BE:\n\n\n\n\n\n        w_align= 16; //FIXME check for non mpeg style codecs and use less alignment\n\n        h_align= 16;\n\n        if(s->codec_id == CODEC_ID_MPEG2VIDEO || s->codec_id == CODEC_ID_MJPEG || s->codec_id == CODEC_ID_AMV || s->codec_id == CODEC_ID_THP || s->codec_id == CODEC_ID_H264)\n\n            h_align= 32; // interlaced is rounded up to 2 MBs\n\n        break;\n\n    case PIX_FMT_YUV411P:\n\n    case PIX_FMT_UYYVYY411:\n\n        w_align=32;\n\n        h_align=8;\n\n        break;\n\n    case PIX_FMT_YUV410P:\n\n        if(s->codec_id == CODEC_ID_SVQ1){\n\n            w_align=64;\n\n            h_align=64;\n\n        }\n\n    case PIX_FMT_RGB555:\n\n        if(s->codec_id == CODEC_ID_RPZA){\n\n            w_align=4;\n\n            h_align=4;\n\n        }\n\n    case PIX_FMT_PAL8:\n\n    case PIX_FMT_BGR8:\n\n    case PIX_FMT_RGB8:\n\n        if(s->codec_id == CODEC_ID_SMC){\n\n            w_align=4;\n\n            h_align=4;\n\n        }\n\n        break;\n\n    case PIX_FMT_BGR24:\n\n        if((s->codec_id == CODEC_ID_MSZH) || (s->codec_id == CODEC_ID_ZLIB)){\n\n            w_align=4;\n\n            h_align=4;\n\n        }\n\n        break;\n\n    default:\n\n        w_align= 1;\n\n        h_align= 1;\n\n        break;\n\n    }\n\n\n\n    *width = FFALIGN(*width , w_align);\n\n    *height= FFALIGN(*height, h_align);\n\n    if(s->codec_id == CODEC_ID_H264 || s->lowres)\n\n        *height+=2; // some of the optimized chroma MC reads one line too much\n\n                    // which is also done in mpeg decoders with lowres > 0\n\n\n\n    linesize_align[0] =\n\n    linesize_align[1] =\n\n    linesize_align[2] =\n\n    linesize_align[3] = STRIDE_ALIGN;\n\n//STRIDE_ALIGN is 8 for SSE* but this does not work for SVQ1 chroma planes\n\n//we could change STRIDE_ALIGN to 16 for x86/sse but it would increase the\n\n//picture size unneccessarily in some cases. The solution here is not\n\n//pretty and better ideas are welcome!\n\n#if HAVE_MMX\n\n    if(s->codec_id == CODEC_ID_SVQ1 || s->codec_id == CODEC_ID_VP5 ||\n\n       s->codec_id == CODEC_ID_VP6 || s->codec_id == CODEC_ID_VP6F ||\n\n       s->codec_id == CODEC_ID_VP6A) {\n\n        linesize_align[0] =\n\n        linesize_align[1] =\n\n        linesize_align[2] = 16;\n\n    }\n\n#endif\n\n}", "idx": 747, "_split": "valid", "_hash": "e03558996e0cc37d23f5693ff7fa687c"}
{"project": "FFmpeg", "commit_id": "8d36932c8d33f93ce1afdd5c1f402e7b6655d5ae", "target": 0, "func": "static int h264_slice_header_parse(H264Context *h, H264SliceContext *sl,\n\n                                   const H2645NAL *nal)\n\n{\n\n    const SPS *sps;\n\n    const PPS *pps;\n\n    int ret;\n\n    unsigned int slice_type, tmp, i;\n\n    int field_pic_flag, bottom_field_flag;\n\n    int frame_num, droppable, picture_structure;\n\n    int mb_aff_frame = 0;\n\n\n\n    sl->first_mb_addr = get_ue_golomb(&sl->gb);\n\n\n\n    if (sl->first_mb_addr == 0) { // FIXME better field boundary detection\n\n        if (h->current_slice && h->cur_pic_ptr && FIELD_PICTURE(h)) {\n\n            ff_h264_field_end(h, sl, 1);\n\n        }\n\n\n\n        h->current_slice = 0;\n\n        if (!h->first_field) {\n\n            if (h->cur_pic_ptr && !h->droppable) {\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                          h->picture_structure == PICT_BOTTOM_FIELD);\n\n            }\n\n            h->cur_pic_ptr = NULL;\n\n        }\n\n    }\n\n\n\n    slice_type = get_ue_golomb_31(&sl->gb);\n\n    if (slice_type > 9) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"slice type %d too large at %d\\n\",\n\n               slice_type, sl->first_mb_addr);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (slice_type > 4) {\n\n        slice_type -= 5;\n\n        sl->slice_type_fixed = 1;\n\n    } else\n\n        sl->slice_type_fixed = 0;\n\n\n\n    slice_type         = ff_h264_golomb_to_pict_type[slice_type];\n\n    sl->slice_type     = slice_type;\n\n    sl->slice_type_nos = slice_type & 3;\n\n\n\n    if (nal->type  == NAL_IDR_SLICE &&\n\n        sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"A non-intra slice in an IDR NAL unit.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    sl->pps_id = get_ue_golomb(&sl->gb);\n\n    if (sl->pps_id >= MAX_PPS_COUNT) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"pps_id %u out of range\\n\", sl->pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!h->ps.pps_list[sl->pps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing PPS %u referenced\\n\",\n\n               sl->pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (h->current_slice > 0 &&\n\n        h->ps.pps != (const PPS*)h->ps.pps_list[sl->pps_id]->data) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"PPS changed between slices\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    pps = (const PPS*)h->ps.pps_list[sl->pps_id]->data;\n\n\n\n    if (!h->ps.sps_list[pps->sps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing SPS %u referenced\\n\", pps->sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sps = (const SPS*)h->ps.sps_list[pps->sps_id]->data;\n\n\n\n    frame_num = get_bits(&sl->gb, sps->log2_max_frame_num);\n\n    if (!h->setup_finished)\n\n        h->poc.frame_num = frame_num;\n\n\n\n    sl->mb_mbaff       = 0;\n\n\n\n    droppable = nal->ref_idc == 0;\n\n    if (sps->frame_mbs_only_flag) {\n\n        picture_structure = PICT_FRAME;\n\n    } else {\n\n        field_pic_flag = get_bits1(&sl->gb);\n\n        if (field_pic_flag) {\n\n            bottom_field_flag = get_bits1(&sl->gb);\n\n            picture_structure = PICT_TOP_FIELD + bottom_field_flag;\n\n        } else {\n\n            picture_structure = PICT_FRAME;\n\n            mb_aff_frame      = sps->mb_aff;\n\n        }\n\n    }\n\n    if (!h->setup_finished) {\n\n        h->mb_aff_frame      = mb_aff_frame;\n\n    }\n\n    sl->picture_structure      = picture_structure;\n\n    sl->mb_field_decoding_flag = picture_structure != PICT_FRAME;\n\n\n\n    if (h->current_slice != 0) {\n\n        if (h->picture_structure != picture_structure ||\n\n            h->droppable         != droppable) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Changing field mode (%d -> %d) between slices is not allowed\\n\",\n\n                   h->picture_structure, picture_structure);\n\n            return AVERROR_INVALIDDATA;\n\n        } else if (!h->cur_pic_ptr) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"unset cur_pic_ptr on slice %d\\n\",\n\n                   h->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    if (picture_structure == PICT_FRAME) {\n\n        h->curr_pic_num = h->poc.frame_num;\n\n        h->max_pic_num  = 1 << sps->log2_max_frame_num;\n\n    } else {\n\n        h->curr_pic_num = 2 * h->poc.frame_num + 1;\n\n        h->max_pic_num  = 1 << (sps->log2_max_frame_num + 1);\n\n    }\n\n\n\n    if (nal->type == NAL_IDR_SLICE)\n\n        get_ue_golomb(&sl->gb); /* idr_pic_id */\n\n\n\n    if (sps->poc_type == 0) {\n\n        int poc_lsb = get_bits(&sl->gb, sps->log2_max_poc_lsb);\n\n\n\n        if (!h->setup_finished)\n\n            h->poc.poc_lsb = poc_lsb;\n\n\n\n        if (pps->pic_order_present == 1 && picture_structure == PICT_FRAME) {\n\n            int delta_poc_bottom = get_se_golomb(&sl->gb);\n\n            if (!h->setup_finished)\n\n                h->poc.delta_poc_bottom = delta_poc_bottom;\n\n        }\n\n    }\n\n\n\n    if (sps->poc_type == 1 && !sps->delta_pic_order_always_zero_flag) {\n\n        int delta_poc = get_se_golomb(&sl->gb);\n\n\n\n        if (!h->setup_finished)\n\n            h->poc.delta_poc[0] = delta_poc;\n\n\n\n        if (pps->pic_order_present == 1 && picture_structure == PICT_FRAME) {\n\n            delta_poc = get_se_golomb(&sl->gb);\n\n\n\n            if (!h->setup_finished)\n\n                h->poc.delta_poc[1] = delta_poc;\n\n        }\n\n    }\n\n\n\n    if (pps->redundant_pic_cnt_present)\n\n        sl->redundant_pic_count = get_ue_golomb(&sl->gb);\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B)\n\n        sl->direct_spatial_mv_pred = get_bits1(&sl->gb);\n\n\n\n    ret = ff_h264_parse_ref_count(&sl->list_count, sl->ref_count,\n\n                                  &sl->gb, pps, sl->slice_type_nos,\n\n                                  picture_structure);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n       ret = ff_h264_decode_ref_pic_list_reordering(h, sl);\n\n       if (ret < 0) {\n\n           sl->ref_count[1] = sl->ref_count[0] = 0;\n\n           return ret;\n\n       }\n\n    }\n\n\n\n    sl->pwt.use_weight = 0;\n\n    for (i = 0; i < 2; i++) {\n\n        sl->pwt.luma_weight_flag[i]   = 0;\n\n        sl->pwt.chroma_weight_flag[i] = 0;\n\n    }\n\n    if ((pps->weighted_pred && sl->slice_type_nos == AV_PICTURE_TYPE_P) ||\n\n        (pps->weighted_bipred_idc == 1 &&\n\n         sl->slice_type_nos == AV_PICTURE_TYPE_B))\n\n        ff_h264_pred_weight_table(&sl->gb, sps, sl->ref_count,\n\n                                  sl->slice_type_nos, &sl->pwt);\n\n\n\n    sl->explicit_ref_marking = 0;\n\n    if (nal->ref_idc) {\n\n        ret = ff_h264_decode_ref_pic_marking(h, sl, &sl->gb);\n\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I && pps->cabac) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"cabac_init_idc %u overflow\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->cabac_init_idc = tmp;\n\n    }\n\n\n\n    sl->last_qscale_diff = 0;\n\n    tmp = pps->init_qp + get_se_golomb(&sl->gb);\n\n    if (tmp > 51 + 6 * (sps->bit_depth_luma - 8)) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"QP %u out of range\\n\", tmp);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sl->qscale       = tmp;\n\n    sl->chroma_qp[0] = get_chroma_qp(pps, 0, sl->qscale);\n\n    sl->chroma_qp[1] = get_chroma_qp(pps, 1, sl->qscale);\n\n    // FIXME qscale / qp ... stuff\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP)\n\n        get_bits1(&sl->gb); /* sp_for_switch_flag */\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP ||\n\n        sl->slice_type == AV_PICTURE_TYPE_SI)\n\n        get_se_golomb(&sl->gb); /* slice_qs_delta */\n\n\n\n    sl->deblocking_filter     = 1;\n\n    sl->slice_alpha_c0_offset = 0;\n\n    sl->slice_beta_offset     = 0;\n\n    if (pps->deblocking_filter_parameters_present) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"deblocking_filter_idc %u out of range\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->deblocking_filter = tmp;\n\n        if (sl->deblocking_filter < 2)\n\n            sl->deblocking_filter ^= 1;  // 1<->0\n\n\n\n        if (sl->deblocking_filter) {\n\n            sl->slice_alpha_c0_offset = get_se_golomb(&sl->gb) * 2;\n\n            sl->slice_beta_offset     = get_se_golomb(&sl->gb) * 2;\n\n            if (sl->slice_alpha_c0_offset >  12 ||\n\n                sl->slice_alpha_c0_offset < -12 ||\n\n                sl->slice_beta_offset >  12     ||\n\n                sl->slice_beta_offset < -12) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"deblocking filter parameters %d %d out of range\\n\",\n\n                       sl->slice_alpha_c0_offset, sl->slice_beta_offset);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 754, "_split": "valid", "_hash": "9d0ec2538f24ae4277232d7345a03d2f"}
{"project": "FFmpeg", "commit_id": "12ba1b2b4d5592c0e27b0fcc83db929e8d6a8eee", "target": 0, "func": "static inline void mct_decode(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile)\n\n{\n\n    int i, csize = 1;\n\n    void *src[3];\n\n\n\n    for (i = 1; i < 3; i++)\n\n        if (tile->codsty[0].transform != tile->codsty[i].transform) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Transforms mismatch, MCT not supported\\n\");\n\n            return;\n\n        }\n\n\n\n    for (i = 0; i < 3; i++)\n\n        if (tile->codsty[0].transform == FF_DWT97)\n\n            src[i] = tile->comp[i].f_data;\n\n        else\n\n            src[i] = tile->comp[i].i_data;\n\n\n\n    for (i = 0; i < 2; i++)\n\n        csize *= tile->comp[0].coord[i][1] - tile->comp[0].coord[i][0];\n\n\n\n    s->dsp.mct_decode[tile->codsty[0].transform](src[0], src[1], src[2], csize);\n\n}\n", "idx": 757, "_split": "valid", "_hash": "88fe4f0dec184bcdc86333f574286991"}
{"project": "FFmpeg", "commit_id": "a37fd7f9578d2dfbe20a109aae91e5f0a4b58874", "target": 1, "func": "static inline void RENAME(rgb2rgb_init)(void)\n\n{\n\n#if !COMPILE_TEMPLATE_SSE2\n\n#if !COMPILE_TEMPLATE_AMD3DNOW\n\n    rgb15to16          = RENAME(rgb15to16);\n\n    rgb15tobgr24       = RENAME(rgb15tobgr24);\n\n    rgb15to32          = RENAME(rgb15to32);\n\n    rgb16tobgr24       = RENAME(rgb16tobgr24);\n\n    rgb16to32          = RENAME(rgb16to32);\n\n    rgb16to15          = RENAME(rgb16to15);\n\n    rgb24tobgr16       = RENAME(rgb24tobgr16);\n\n    rgb24tobgr15       = RENAME(rgb24tobgr15);\n\n    rgb24tobgr32       = RENAME(rgb24tobgr32);\n\n    rgb32to16          = RENAME(rgb32to16);\n\n    rgb32to15          = RENAME(rgb32to15);\n\n    rgb32tobgr24       = RENAME(rgb32tobgr24);\n\n    rgb24to15          = RENAME(rgb24to15);\n\n    rgb24to16          = RENAME(rgb24to16);\n\n    rgb24tobgr24       = RENAME(rgb24tobgr24);\n\n    shuffle_bytes_2103 = RENAME(shuffle_bytes_2103);\n\n    rgb32tobgr16       = RENAME(rgb32tobgr16);\n\n    rgb32tobgr15       = RENAME(rgb32tobgr15);\n\n    yv12toyuy2         = RENAME(yv12toyuy2);\n\n    yv12touyvy         = RENAME(yv12touyvy);\n\n    yuv422ptoyuy2      = RENAME(yuv422ptoyuy2);\n\n    yuv422ptouyvy      = RENAME(yuv422ptouyvy);\n\n    yuy2toyv12         = RENAME(yuy2toyv12);\n\n    vu9_to_vu12        = RENAME(vu9_to_vu12);\n\n    yvu9_to_yuy2       = RENAME(yvu9_to_yuy2);\n\n    uyvytoyuv422       = RENAME(uyvytoyuv422);\n\n    yuyvtoyuv422       = RENAME(yuyvtoyuv422);\n\n#endif /* !COMPILE_TEMPLATE_AMD3DNOW */\n\n\n\n#if COMPILE_TEMPLATE_MMXEXT || COMPILE_TEMPLATE_AMD3DNOW\n\n    planar2x           = RENAME(planar2x);\n\n#endif /* COMPILE_TEMPLATE_MMXEXT || COMPILE_TEMPLATE_AMD3DNOW */\n\n    rgb24toyv12        = RENAME(rgb24toyv12);\n\n\n\n    yuyvtoyuv420       = RENAME(yuyvtoyuv420);\n\n    uyvytoyuv420       = RENAME(uyvytoyuv420);\n\n#endif /* !COMPILE_TEMPLATE_SSE2 */\n\n\n\n#if !COMPILE_TEMPLATE_AMD3DNOW\n\n    interleaveBytes    = RENAME(interleaveBytes);\n\n#endif /* !COMPILE_TEMPLATE_AMD3DNOW */\n\n}\n", "idx": 768, "_split": "valid", "_hash": "c35525f433e5706bec2456a97359c187"}
{"project": "FFmpeg", "commit_id": "3193b13aa1e271f6d2dd68de67d448c08aef3c00", "target": 1, "func": "static int hls_write_header(AVFormatContext *s)\n\n{\n\n    HLSContext *hls = s->priv_data;\n\n    int ret, i;\n\n    char *p;\n\n    const char *pattern = \"%d.ts\";\n\n    int basename_size = strlen(s->filename) + strlen(pattern);\n\n\n\n    hls->number      = 0;\n\n\n\n    hls->recording_time = hls->time * 1000000;\n\n    hls->start_pts      = AV_NOPTS_VALUE;\n\n\n\n    for (i = 0; i < s->nb_streams; i++)\n\n        hls->has_video +=\n\n            s->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO;\n\n\n\n    if (hls->has_video > 1)\n\n        av_log(s, AV_LOG_WARNING,\n\n               \"More than a single video stream present, \"\n\n               \"expect issues decoding it.\\n\");\n\n\n\n    hls->oformat = av_guess_format(\"mpegts\", NULL, NULL);\n\n\n\n    if (!hls->oformat) {\n\n        ret = AVERROR_MUXER_NOT_FOUND;\n\n        goto fail;\n\n    }\n\n\n\n    hls->basename = av_malloc(basename_size);\n\n\n\n    if (!hls->basename) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    strcpy(hls->basename, s->filename);\n\n\n\n    p = strrchr(hls->basename, '.');\n\n\n\n    if (p)\n\n        *p = '\\0';\n\n\n\n    av_strlcat(hls->basename, \"%d.ts\", basename_size);\n\n\n\n    if ((ret = hls_mux_init(s)) < 0)\n\n        goto fail;\n\n\n\n    if ((ret = hls_start(s)) < 0)\n\n        goto fail;\n\n\n\n    if ((ret = avformat_write_header(hls->avf, NULL)) < 0)\n\n        return ret;\n\n\n\n\n\nfail:\n\n    if (ret) {\n\n        av_free(hls->basename);\n\n        if (hls->avf)\n\n            avformat_free_context(hls->avf);\n\n    }\n\n    return ret;\n\n}\n", "idx": 771, "_split": "valid", "_hash": "979829a29bdca0400453a320abd1c49f"}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(bgr24ToY)(uint8_t *dst, uint8_t *src, long width)\n\n{\n\n#ifdef HAVE_MMX\n\n\tasm volatile(\n\n\t\t\"mov %2, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(bgr2YCoeff)\", %%mm6\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(w1111)\", %%mm5\t\t\\n\\t\"\n\n\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_d\"\\n\\t\"\n\n\t\tASMALIGN(4)\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\tPREFETCH\" 64(%0, %%\"REG_d\")\t\\n\\t\"\n\n\t\t\"movd (%0, %%\"REG_d\"), %%mm0\t\\n\\t\"\n\n\t\t\"movd 3(%0, %%\"REG_d\"), %%mm1\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\"movd 6(%0, %%\"REG_d\"), %%mm2\t\\n\\t\"\n\n\t\t\"movd 9(%0, %%\"REG_d\"), %%mm3\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm1\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm3\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\"packssdw %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm0\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm2\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm2, %%mm0\t\t\\n\\t\"\n\n\t\t\"psraw $7, %%mm0\t\t\\n\\t\"\n\n\n\n\t\t\"movd 12(%0, %%\"REG_d\"), %%mm4\t\\n\\t\"\n\n\t\t\"movd 15(%0, %%\"REG_d\"), %%mm1\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\"movd 18(%0, %%\"REG_d\"), %%mm2\t\\n\\t\"\n\n\t\t\"movd 21(%0, %%\"REG_d\"), %%mm3\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm4\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm1\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm6, %%mm3\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\"psrad $8, %%mm4\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\"packssdw %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\"pmaddwd %%mm5, %%mm2\t\t\\n\\t\"\n\n\t\t\"add $24, %%\"REG_d\"\t\t\\n\\t\"\n\n\t\t\"packssdw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\"psraw $7, %%mm4\t\t\\n\\t\"\n\n\n\n\t\t\"packuswb %%mm4, %%mm0\t\t\\n\\t\"\n\n\t\t\"paddusb \"MANGLE(bgr2YOffset)\", %%mm0\t\\n\\t\"\n\n\n\n\t\t\"movq %%mm0, (%1, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t: : \"r\" (src+width*3), \"r\" (dst+width), \"g\" (-width)\n\n\t\t: \"%\"REG_a, \"%\"REG_d\n\n\t);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tint b= src[i*3+0];\n\n\t\tint g= src[i*3+1];\n\n\t\tint r= src[i*3+2];\n\n\n\n\t\tdst[i]= ((RY*r + GY*g + BY*b + (33<<(RGB2YUV_SHIFT-1)) )>>RGB2YUV_SHIFT);\n\n\t}\n\n#endif\n\n}\n", "idx": 772, "_split": "valid", "_hash": "1e18287686b5c287db97aedb9b374a50"}
{"project": "FFmpeg", "commit_id": "25a6666f6c07c6ac8449a63d7fbce0dfd29c54cd", "target": 0, "func": "static int ivi_mc(ivi_mc_func mc, int16_t *buf, const int16_t *ref_buf,\n\n                  int offs, int mv_x, int mv_y, uint32_t pitch,\n\n                  int mc_type)\n\n{\n\n    int ref_offs = offs + mv_y * pitch + mv_x;\n\n\n\n    if (offs < 0 || ref_offs < 0 || !ref_buf)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    mc(buf + offs, ref_buf + ref_offs, pitch, mc_type);\n\n\n\n    return 0;\n\n}\n", "idx": 795, "_split": "valid", "_hash": "55f0a7d94b8e3e1eb6d07bfe53730f64"}
{"project": "FFmpeg", "commit_id": "cfec0d64752509f8ac798acca6225df630fa5284", "target": 1, "func": "static int cllc_decode_frame(AVCodecContext *avctx, void *data,\n                             int *got_picture_ptr, AVPacket *avpkt)\n{\n    CLLCContext *ctx = avctx->priv_data;\n    AVFrame *pic = data;\n    ThreadFrame frame = { .f = data };\n    uint8_t *src = avpkt->data;\n    uint32_t info_tag, info_offset;\n    int data_size;\n    GetBitContext gb;\n    int coding_type, ret;\n    if (avpkt->size < 4 + 4) {\n        av_log(avctx, AV_LOG_ERROR, \"Frame is too small %d.\\n\", avpkt->size);\n    }\n    info_offset = 0;\n    info_tag    = AV_RL32(src);\n    if (info_tag == MKTAG('I', 'N', 'F', 'O')) {\n        info_offset = AV_RL32(src + 4);\n        if (info_offset > UINT32_MAX - 8 || info_offset + 8 > avpkt->size) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Invalid INFO header offset: 0x%08\"PRIX32\" is too large.\\n\",\n                   info_offset);\n        }\n        ff_canopus_parse_info_tag(avctx, src + 8, info_offset);\n        info_offset += 8;\n        src         += info_offset;\n    }\n    data_size = (avpkt->size - info_offset) & ~1;\n    /* Make sure our bswap16'd buffer is big enough */\n    av_fast_padded_malloc(&ctx->swapped_buf,\n                          &ctx->swapped_buf_size, data_size);\n    if (!ctx->swapped_buf) {\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate swapped buffer.\\n\");\n        return AVERROR(ENOMEM);\n    }\n    /* bswap16 the buffer since CLLC's bitreader works in 16-bit words */\n    ctx->bdsp.bswap16_buf((uint16_t *) ctx->swapped_buf, (uint16_t *) src,\n                          data_size / 2);\n    if ((ret = init_get_bits8(&gb, ctx->swapped_buf, data_size)) < 0)\n        return ret;\n    /*\n     * Read in coding type. The types are as follows:\n     *\n     * 0 - YUY2\n     * 1 - BGR24 (Triples)\n     * 2 - BGR24 (Quads)\n     * 3 - BGRA\n     */\n    coding_type = (AV_RL32(src) >> 8) & 0xFF;\n    av_log(avctx, AV_LOG_DEBUG, \"Frame coding type: %d\\n\", coding_type);\n    switch (coding_type) {\n    case 0:\n        avctx->pix_fmt             = AV_PIX_FMT_YUV422P;\n        avctx->bits_per_raw_sample = 8;\n        if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0)\n            return ret;\n        ret = decode_yuv_frame(ctx, &gb, pic);\n        if (ret < 0)\n            return ret;\n        break;\n    case 1:\n    case 2:\n        avctx->pix_fmt             = AV_PIX_FMT_RGB24;\n        avctx->bits_per_raw_sample = 8;\n        if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0)\n            return ret;\n        ret = decode_rgb24_frame(ctx, &gb, pic);\n        if (ret < 0)\n            return ret;\n        break;\n    case 3:\n        avctx->pix_fmt             = AV_PIX_FMT_ARGB;\n        avctx->bits_per_raw_sample = 8;\n        if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0)\n            return ret;\n        ret = decode_argb_frame(ctx, &gb, pic);\n        if (ret < 0)\n            return ret;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"Unknown coding type: %d.\\n\", coding_type);\n    }\n    pic->key_frame = 1;\n    pic->pict_type = AV_PICTURE_TYPE_I;\n    *got_picture_ptr = 1;\n    return avpkt->size;\n}", "idx": 838, "_split": "valid", "_hash": "8da754894a3cc62fd7471cc525a653e2"}
{"project": "FFmpeg", "commit_id": "4f5eaf0b5956e492ee5023929669b1d09aaf6299", "target": 1, "func": "static av_always_inline void decode_dc_coeffs(GetBitContext *gb, int16_t *out,\n\n                                              int blocks_per_slice)\n\n{\n\n    int16_t prev_dc;\n\n    int code, i, sign;\n\n\n\n    OPEN_READER(re, gb);\n\n\n\n    DECODE_CODEWORD(code, FIRST_DC_CB);\n\n    prev_dc = TOSIGNED(code);\n\n    out[0] = prev_dc;\n\n\n\n    out += 64; // dc coeff for the next block\n\n\n\n    code = 5;\n\n    sign = 0;\n\n    for (i = 1; i < blocks_per_slice; i++, out += 64) {\n\n        DECODE_CODEWORD(code, dc_codebook[FFMIN(code, 6U)]);\n\n        if(code) sign ^= -(code & 1);\n\n        else     sign  = 0;\n\n        prev_dc += (((code + 1) >> 1) ^ sign) - sign;\n\n        out[0] = prev_dc;\n\n    }\n\n    CLOSE_READER(re, gb);\n\n}\n", "idx": 850, "_split": "valid", "_hash": "19c7c01f7e948cdc6d46d9a0fb7bcccc"}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "static void avc_luma_midh_qrt_and_aver_dst_8w_msa(const uint8_t *src,\n\n                                                  int32_t src_stride,\n\n                                                  uint8_t *dst,\n\n                                                  int32_t dst_stride,\n\n                                                  int32_t height,\n\n                                                  uint8_t horiz_offset)\n\n{\n\n    uint32_t multiple8_cnt;\n\n\n\n    for (multiple8_cnt = 2; multiple8_cnt--;) {\n\n        avc_luma_midh_qrt_and_aver_dst_4w_msa(src, src_stride, dst, dst_stride,\n\n                                              height, horiz_offset);\n\n\n\n        src += 4;\n\n        dst += 4;\n\n    }\n\n}\n", "idx": 854, "_split": "valid", "_hash": "c19d11d220196855de8e423fea989c37"}
{"project": "FFmpeg", "commit_id": "f1cd9b03f3fa875eb5e394281b4b688cec611658", "target": 1, "func": "static av_cold OMXContext *omx_init(void *logctx, const char *libname, const char *prefix)\n\n{\n\n    static const char * const libnames[] = {\n\n        \"libOMX_Core.so\",\n\n        \"libOmxCore.so\",\n\n        NULL\n\n    };\n\n    const char* const* nameptr;\n\n    int ret = AVERROR_ENCODER_NOT_FOUND;\n\n    OMXContext *omx_context;\n\n\n\n    omx_context = av_mallocz(sizeof(*omx_context));\n\n    if (!omx_context)\n\n        return NULL;\n\n    if (libname) {\n\n        ret = omx_try_load(omx_context, logctx, libname, prefix);\n\n        if (ret < 0) {\n\n            av_free(omx_context);\n\n            return NULL;\n\n        }\n\n    } else {\n\n        for (nameptr = libnames; *nameptr; nameptr++)\n\n            if (!(ret = omx_try_load(omx_context, logctx, *nameptr, prefix)))\n\n                break;\n\n        if (!*nameptr) {\n\n            av_free(omx_context);\n\n            return NULL;\n\n        }\n\n    }\n\n\n\n    omx_context->ptr_Init();\n\n    return omx_context;\n\n}\n", "idx": 863, "_split": "valid", "_hash": "09dcbb9528ad3fecb40fde1e428460a5"}
{"project": "FFmpeg", "commit_id": "cc276c85d15272df6e44fb3252657a43cbd49555", "target": 0, "func": "int av_get_channel_layout_nb_channels(int64_t channel_layout)\n\n{\n\n    int count;\n\n    uint64_t x = channel_layout;\n\n    for (count = 0; x; count++)\n\n        x &= x-1; // unset lowest set bit\n\n    return count;\n\n}\n", "idx": 867, "_split": "valid", "_hash": "29ca0cf903fdce9820cc6a47a08d8b7c"}
{"project": "FFmpeg", "commit_id": "f1a4dd5e480932ee580fb686988599d46bb71637", "target": 1, "func": "static int decode0(GetByteContext *gb, RangeCoder *rc, unsigned cumFreq, unsigned freq, unsigned total_freq)\n\n{\n\n    int t;\n\n\n\n    if (total_freq == 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    t = rc->range * (uint64_t)cumFreq / total_freq;\n\n\n\n    rc->code1 += t + 1;\n\n    rc->range = rc->range * (uint64_t)(freq + cumFreq) / total_freq - (t + 1);\n\n\n\n    while (rc->range < TOP && bytestream2_get_bytes_left(gb) > 0) {\n\n        unsigned byte = bytestream2_get_byte(gb);\n\n        rc->code = (rc->code << 8) | byte;\n\n        rc->code1 <<= 8;\n\n        rc->range <<= 8;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 1003, "_split": "valid", "_hash": "c22d79e6155425477716229e4a0255c6"}
{"project": "FFmpeg", "commit_id": "c8cfbc6629c1fe5755b59a3bcfd95ad08b843a07", "target": 1, "func": "static int hevc_decode_frame(AVCodecContext *avctx, void *data, int *got_output,\n\n                             AVPacket *avpkt)\n\n{\n\n    int ret;\n\n    int new_extradata_size;\n\n    uint8_t *new_extradata;\n\n    HEVCContext *s = avctx->priv_data;\n\n\n\n    if (!avpkt->size) {\n\n        ret = ff_hevc_output_frame(s, data, 1);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        *got_output = ret;\n\n        return 0;\n\n    }\n\n\n\n    new_extradata = av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA,\n\n                                            &new_extradata_size);\n\n    if (new_extradata && new_extradata_size > 0) {\n\n        ret = hevc_decode_extradata(s, new_extradata, new_extradata_size);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    s->ref = NULL;\n\n    ret    = decode_nal_units(s, avpkt->data, avpkt->size);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (avctx->hwaccel) {\n\n        if (s->ref && (ret = avctx->hwaccel->end_frame(avctx)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"hardware accelerator failed to decode picture\\n\");\n\n            ff_hevc_unref_frame(s, s->ref, ~0);\n\n            return ret;\n\n        }\n\n    } else {\n\n        /* verify the SEI checksum */\n\n        if (avctx->err_recognition & AV_EF_CRCCHECK && s->is_decoded &&\n\n            s->sei.picture_hash.is_md5) {\n\n            ret = verify_md5(s, s->ref->frame);\n\n            if (ret < 0 && avctx->err_recognition & AV_EF_EXPLODE) {\n\n                ff_hevc_unref_frame(s, s->ref, ~0);\n\n                return ret;\n\n            }\n\n        }\n\n    }\n\n    s->sei.picture_hash.is_md5 = 0;\n\n\n\n    if (s->is_decoded) {\n\n        av_log(avctx, AV_LOG_DEBUG, \"Decoded frame with POC %d.\\n\", s->poc);\n\n        s->is_decoded = 0;\n\n    }\n\n\n\n    if (s->output_frame->buf[0]) {\n\n        av_frame_move_ref(data, s->output_frame);\n\n        *got_output = 1;\n\n    }\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 1018, "_split": "valid", "_hash": "8e662d9238855d9d2a77d06ed5d69f64"}
{"project": "FFmpeg", "commit_id": "1bab6f852c7ca433285d19f65c701885fa69cc57", "target": 1, "func": "static void RENAME(yuv2bgr24_1)(SwsContext *c, const int16_t *buf0,\n\n                                const int16_t *ubuf[2], const int16_t *bguf[2],\n\n                                const int16_t *abuf0, uint8_t *dest,\n\n                                int dstW, int uvalpha, int y)\n\n{\n\n    const int16_t *ubuf0 = ubuf[0], *ubuf1 = ubuf[1];\n\n    const int16_t *buf1= buf0; //FIXME needed for RGB1/BGR1\n\n\n\n    if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB1(%%REGBP, %5)\n\n            \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n            WRITEBGR24(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n    } else {\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB1b(%%REGBP, %5)\n\n            \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n            WRITEBGR24(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n    }\n\n}\n", "idx": 1021, "_split": "valid", "_hash": "69c93aaf41dee4f5438580b3088bfae3"}
{"project": "FFmpeg", "commit_id": "6e1a167c5564085385488b4f579e9efb987d4bfa", "target": 1, "func": "static int dx2_decode_slice_410(GetBitContext *gb, AVFrame *frame,\n\n                                int line, int left,\n\n                                uint8_t lru[3][8])\n\n{\n\n    int x, y, i, j;\n\n    int width   = frame->width;\n\n\n\n    int ystride = frame->linesize[0];\n\n    int ustride = frame->linesize[1];\n\n    int vstride = frame->linesize[2];\n\n\n\n    uint8_t *Y  = frame->data[0] + ystride * line;\n\n    uint8_t *U  = frame->data[1] + (ustride >> 2) * line;\n\n    uint8_t *V  = frame->data[2] + (vstride >> 2) * line;\n\n\n\n    for (y = 0; y < left - 3 && get_bits_left(gb) > 16; y += 4) {\n\n        for (x = 0; x < width; x += 4) {\n\n            for (j = 0; j < 4; j++)\n\n                for (i = 0; i < 4; i++)\n\n                    Y[x + i + j * ystride] = decode_sym(gb, lru[0]);\n\n            U[x >> 2] = decode_sym(gb, lru[1]) ^ 0x80;\n\n            V[x >> 2] = decode_sym(gb, lru[2]) ^ 0x80;\n\n        }\n\n\n\n        Y += ystride << 2;\n\n        U += ustride;\n\n        V += vstride;\n\n    }\n\n\n\n    return y;\n\n}\n", "idx": 1042, "_split": "valid", "_hash": "b12ec63496a7b6670235ed2d7afd47fd"}
{"project": "FFmpeg", "commit_id": "91abb473fb8432226918da4fe03365ebaf688978", "target": 0, "func": "static void put_no_rnd_pixels_y2_mmx( UINT8  *block, const UINT8 *pixels, int line_size, int h)\n\n{\n\n  UINT8  *p;\n\n  const UINT8 *pix;\n\n  p = block;\n\n  pix = pixels;\n\n  MOVQ_ZERO(mm7);\n\n  JUMPALIGN();\n\n  do {\n\n    __asm __volatile(\n\n\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\"movq\t%2, %%mm1\\n\\t\"\n\n\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\"movq\t%%mm1, %%mm3\\n\\t\"\n\n\t\"punpcklbw %%mm7, %%mm0\\n\\t\"\n\n\t\"punpcklbw %%mm7, %%mm1\\n\\t\"\n\n\t\"punpckhbw %%mm7, %%mm2\\n\\t\"\n\n\t\"punpckhbw %%mm7, %%mm3\\n\\t\"\n\n\t\"paddusw %%mm1, %%mm0\\n\\t\"\n\n\t\"paddusw %%mm3, %%mm2\\n\\t\"\n\n\t\"psrlw\t$1, %%mm0\\n\\t\"\n\n\t\"psrlw\t$1, %%mm2\\n\\t\"\n\n\t\"packuswb  %%mm2, %%mm0\\n\\t\"\n\n\t\"movq\t%%mm0, %0\\n\\t\"\n\n\t:\"=m\"(*p)\n\n\t:\"m\"(*pix),\n\n\t \"m\"(*(pix+line_size))\n\n\t:\"memory\");\n\n   pix += line_size;\n\n   p +=   line_size;\n\n  } while(--h);\n\n}\n", "idx": 1065, "_split": "valid", "_hash": "5240674d66dd76d4f50cde4b7440e0cc"}
{"project": "FFmpeg", "commit_id": "b92dfb56d4582633571db18c3d904f8602eaa2a6", "target": 0, "func": "static int encode_frame(AVCodecContext * avctx, AVPacket *pkt,\n\n                        const AVFrame *pict, int *got_packet)\n\n{\n\n    TiffEncoderContext *s = avctx->priv_data;\n\n    AVFrame *const p = &s->picture;\n\n    int i;\n\n    uint8_t *ptr;\n\n    uint8_t *offset;\n\n    uint32_t strips;\n\n    uint32_t *strip_sizes = NULL;\n\n    uint32_t *strip_offsets = NULL;\n\n    int bytes_per_row;\n\n    uint32_t res[2] = { 72, 1 };        // image resolution (72/1)\n\n    uint16_t bpp_tab[] = { 8, 8, 8, 8 };\n\n    int ret;\n\n    int is_yuv = 0;\n\n    uint8_t *yuv_line = NULL;\n\n    int shift_h, shift_v;\n\n    const AVPixFmtDescriptor* pfd;\n\n\n\n    s->avctx = avctx;\n\n\n\n    *p = *pict;\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n    p->key_frame = 1;\n\n    avctx->coded_frame= &s->picture;\n\n\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n    s->subsampling[0] = 1;\n\n    s->subsampling[1] = 1;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case PIX_FMT_RGB48LE:\n\n    case PIX_FMT_GRAY16LE:\n\n    case PIX_FMT_RGB24:\n\n    case PIX_FMT_GRAY8:\n\n    case PIX_FMT_PAL8:\n\n        pfd = &av_pix_fmt_descriptors[avctx->pix_fmt];\n\n        s->bpp = av_get_bits_per_pixel(pfd);\n\n        if (pfd->flags & PIX_FMT_PAL) {\n\n            s->photometric_interpretation = 3;\n\n        } else if (pfd->flags & PIX_FMT_RGB) {\n\n            s->photometric_interpretation = 2;\n\n        } else {\n\n            s->photometric_interpretation = 1;\n\n        }\n\n        s->bpp_tab_size = pfd->nb_components;\n\n        for (i = 0; i < s->bpp_tab_size; i++) {\n\n            bpp_tab[i] = s->bpp / s->bpp_tab_size;\n\n        }\n\n        break;\n\n    case PIX_FMT_MONOBLACK:\n\n        s->bpp = 1;\n\n        s->photometric_interpretation = 1;\n\n        s->bpp_tab_size = 0;\n\n        break;\n\n    case PIX_FMT_MONOWHITE:\n\n        s->bpp = 1;\n\n        s->photometric_interpretation = 0;\n\n        s->bpp_tab_size = 0;\n\n        break;\n\n    case PIX_FMT_YUV420P:\n\n    case PIX_FMT_YUV422P:\n\n    case PIX_FMT_YUV444P:\n\n    case PIX_FMT_YUV410P:\n\n    case PIX_FMT_YUV411P:\n\n        s->photometric_interpretation = 6;\n\n        avcodec_get_chroma_sub_sample(avctx->pix_fmt,\n\n                &shift_h, &shift_v);\n\n        s->bpp = 8 + (16 >> (shift_h + shift_v));\n\n        s->subsampling[0] = 1 << shift_h;\n\n        s->subsampling[1] = 1 << shift_v;\n\n        s->bpp_tab_size = 3;\n\n        is_yuv = 1;\n\n        break;\n\n    default:\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"This colors format is not supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->compr == TIFF_DEFLATE || s->compr == TIFF_ADOBE_DEFLATE || s->compr == TIFF_LZW)\n\n        //best choose for DEFLATE\n\n        s->rps = s->height;\n\n    else\n\n        s->rps = FFMAX(8192 / (((s->width * s->bpp) >> 3) + 1), 1);     // suggest size of strip\n\n    s->rps = ((s->rps - 1) / s->subsampling[1] + 1) * s->subsampling[1]; // round rps up\n\n\n\n    strips = (s->height - 1) / s->rps + 1;\n\n\n\n    if (!pkt->data &&\n\n        (ret = av_new_packet(pkt, avctx->width * avctx->height * s->bpp * 2 +\n\n                                  avctx->height * 4 + FF_MIN_BUFFER_SIZE)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n\n        return ret;\n\n    }\n\n    ptr          = pkt->data;\n\n    s->buf_start = pkt->data;\n\n    s->buf       = &ptr;\n\n    s->buf_size  = pkt->size;\n\n\n\n    if (check_size(s, 8))\n\n        goto fail;\n\n\n\n    // write header\n\n    bytestream_put_le16(&ptr, 0x4949);\n\n    bytestream_put_le16(&ptr, 42);\n\n\n\n    offset = ptr;\n\n    bytestream_put_le32(&ptr, 0);\n\n\n\n    strip_sizes = av_mallocz(sizeof(*strip_sizes) * strips);\n\n    strip_offsets = av_mallocz(sizeof(*strip_offsets) * strips);\n\n\n\n    bytes_per_row = (((s->width - 1)/s->subsampling[0] + 1) * s->bpp\n\n                    * s->subsampling[0] * s->subsampling[1] + 7) >> 3;\n\n    if (is_yuv){\n\n        yuv_line = av_malloc(bytes_per_row);\n\n        if (yuv_line == NULL){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Not enough memory\\n\");\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n#if CONFIG_ZLIB\n\n    if (s->compr == TIFF_DEFLATE || s->compr == TIFF_ADOBE_DEFLATE) {\n\n        uint8_t *zbuf;\n\n        int zlen, zn;\n\n        int j;\n\n\n\n        zlen = bytes_per_row * s->rps;\n\n        zbuf = av_malloc(zlen);\n\n        strip_offsets[0] = ptr - pkt->data;\n\n        zn = 0;\n\n        for (j = 0; j < s->rps; j++) {\n\n            if (is_yuv){\n\n                pack_yuv(s, yuv_line, j);\n\n                memcpy(zbuf + zn, yuv_line, bytes_per_row);\n\n                j += s->subsampling[1] - 1;\n\n            }\n\n            else\n\n                memcpy(zbuf + j * bytes_per_row,\n\n                       p->data[0] + j * p->linesize[0], bytes_per_row);\n\n            zn += bytes_per_row;\n\n        }\n\n        ret = encode_strip(s, zbuf, ptr, zn, s->compr);\n\n        av_free(zbuf);\n\n        if (ret < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n\n            goto fail;\n\n        }\n\n        ptr += ret;\n\n        strip_sizes[0] = ptr - pkt->data - strip_offsets[0];\n\n    } else\n\n#endif\n\n    {\n\n        if(s->compr == TIFF_LZW)\n\n            s->lzws = av_malloc(ff_lzw_encode_state_size);\n\n        for (i = 0; i < s->height; i++) {\n\n            if (strip_sizes[i / s->rps] == 0) {\n\n                if(s->compr == TIFF_LZW){\n\n                    ff_lzw_encode_init(s->lzws, ptr, s->buf_size - (*s->buf - s->buf_start),\n\n                                       12, FF_LZW_TIFF, put_bits);\n\n                }\n\n                strip_offsets[i / s->rps] = ptr - pkt->data;\n\n            }\n\n            if (is_yuv){\n\n                 pack_yuv(s, yuv_line, i);\n\n                 ret = encode_strip(s, yuv_line, ptr, bytes_per_row, s->compr);\n\n                 i += s->subsampling[1] - 1;\n\n            }\n\n            else\n\n                ret = encode_strip(s, p->data[0] + i * p->linesize[0],\n\n                        ptr, bytes_per_row, s->compr);\n\n            if (ret < 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Encode strip failed\\n\");\n\n                goto fail;\n\n            }\n\n            strip_sizes[i / s->rps] += ret;\n\n            ptr += ret;\n\n            if(s->compr == TIFF_LZW && (i==s->height-1 || i%s->rps == s->rps-1)){\n\n                ret = ff_lzw_encode_flush(s->lzws, flush_put_bits);\n\n                strip_sizes[(i / s->rps )] += ret ;\n\n                ptr += ret;\n\n            }\n\n        }\n\n        if(s->compr == TIFF_LZW)\n\n            av_free(s->lzws);\n\n    }\n\n\n\n    s->num_entries = 0;\n\n\n\n    add_entry1(s,TIFF_SUBFILE,           TIFF_LONG,             0);\n\n    add_entry1(s,TIFF_WIDTH,             TIFF_LONG,             s->width);\n\n    add_entry1(s,TIFF_HEIGHT,            TIFF_LONG,             s->height);\n\n\n\n    if (s->bpp_tab_size)\n\n    add_entry(s, TIFF_BPP,               TIFF_SHORT,    s->bpp_tab_size, bpp_tab);\n\n\n\n    add_entry1(s,TIFF_COMPR,             TIFF_SHORT,            s->compr);\n\n    add_entry1(s,TIFF_INVERT,            TIFF_SHORT,            s->photometric_interpretation);\n\n    add_entry(s, TIFF_STRIP_OFFS,        TIFF_LONG,     strips, strip_offsets);\n\n\n\n    if (s->bpp_tab_size)\n\n    add_entry1(s,TIFF_SAMPLES_PER_PIXEL, TIFF_SHORT,            s->bpp_tab_size);\n\n\n\n    add_entry1(s,TIFF_ROWSPERSTRIP,      TIFF_LONG,             s->rps);\n\n    add_entry(s, TIFF_STRIP_SIZE,        TIFF_LONG,     strips, strip_sizes);\n\n    add_entry(s, TIFF_XRES,              TIFF_RATIONAL, 1,      res);\n\n    add_entry(s, TIFF_YRES,              TIFF_RATIONAL, 1,      res);\n\n    add_entry1(s,TIFF_RES_UNIT,          TIFF_SHORT,            2);\n\n\n\n    if(!(avctx->flags & CODEC_FLAG_BITEXACT))\n\n    add_entry(s, TIFF_SOFTWARE_NAME,     TIFF_STRING,\n\n              strlen(LIBAVCODEC_IDENT) + 1, LIBAVCODEC_IDENT);\n\n\n\n    if (avctx->pix_fmt == PIX_FMT_PAL8) {\n\n        uint16_t pal[256 * 3];\n\n        for (i = 0; i < 256; i++) {\n\n            uint32_t rgb = *(uint32_t *) (p->data[1] + i * 4);\n\n            pal[i]       = ((rgb >> 16) & 0xff) * 257;\n\n            pal[i + 256] = ((rgb >> 8 ) & 0xff) * 257;\n\n            pal[i + 512] = ( rgb        & 0xff) * 257;\n\n        }\n\n        add_entry(s, TIFF_PAL, TIFF_SHORT, 256 * 3, pal);\n\n    }\n\n    if (is_yuv){\n\n        /** according to CCIR Recommendation 601.1 */\n\n        uint32_t refbw[12] = {15, 1, 235, 1, 128, 1, 240, 1, 128, 1, 240, 1};\n\n        add_entry(s, TIFF_YCBCR_SUBSAMPLING, TIFF_SHORT,    2, s->subsampling);\n\n        add_entry(s, TIFF_REFERENCE_BW,      TIFF_RATIONAL, 6, refbw);\n\n    }\n\n    bytestream_put_le32(&offset, ptr - pkt->data);    // write offset to dir\n\n\n\n    if (check_size(s, 6 + s->num_entries * 12)) {\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n    bytestream_put_le16(&ptr, s->num_entries);  // write tag count\n\n    bytestream_put_buffer(&ptr, s->entries, s->num_entries * 12);\n\n    bytestream_put_le32(&ptr, 0);\n\n\n\n    pkt->size   = ptr - pkt->data;\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n\n\nfail:\n\n    av_free(strip_sizes);\n\n    av_free(strip_offsets);\n\n    av_free(yuv_line);\n\n    return ret;\n\n}\n", "idx": 1076, "_split": "valid", "_hash": "2033b5c64acd4e6dbc53d29f4f5d4837"}
{"project": "FFmpeg", "commit_id": "682b6db706a561de0241339f6674e59581ac1330", "target": 1, "func": "static int mxf_parse_structural_metadata(MXFContext *mxf)\n\n{\n\n    MXFPackage *material_package = NULL;\n\n    MXFPackage *temp_package = NULL;\n\n    int i, j, k;\n\n\n\n    av_dlog(mxf->fc, \"metadata sets count %d\\n\", mxf->metadata_sets_count);\n\n    /* TODO: handle multiple material packages (OP3x) */\n\n    for (i = 0; i < mxf->packages_count; i++) {\n\n        material_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[i], MaterialPackage);\n\n        if (material_package) break;\n\n    }\n\n    if (!material_package) {\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"no material package found\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    for (i = 0; i < material_package->tracks_count; i++) {\n\n        MXFPackage *source_package = NULL;\n\n        MXFTrack *material_track = NULL;\n\n        MXFTrack *source_track = NULL;\n\n        MXFTrack *temp_track = NULL;\n\n        MXFDescriptor *descriptor = NULL;\n\n        MXFStructuralComponent *component = NULL;\n\n        UID *essence_container_ul = NULL;\n\n        const MXFCodecUL *codec_ul = NULL;\n\n        const MXFCodecUL *container_ul = NULL;\n\n        AVStream *st;\n\n\n\n        if (!(material_track = mxf_resolve_strong_ref(mxf, &material_package->tracks_refs[i], Track))) {\n\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track strong ref\\n\");\n\n            continue;\n\n        }\n\n\n\n        if (!(material_track->sequence = mxf_resolve_strong_ref(mxf, &material_track->sequence_ref, Sequence))) {\n\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve material track sequence strong ref\\n\");\n\n            continue;\n\n        }\n\n\n\n        /* TODO: handle multiple source clips */\n\n        for (j = 0; j < material_track->sequence->structural_components_count; j++) {\n\n            /* TODO: handle timecode component */\n\n            component = mxf_resolve_strong_ref(mxf, &material_track->sequence->structural_components_refs[j], SourceClip);\n\n            if (!component)\n\n                continue;\n\n\n\n            for (k = 0; k < mxf->packages_count; k++) {\n\n                temp_package = mxf_resolve_strong_ref(mxf, &mxf->packages_refs[k], SourcePackage);\n\n                if (!temp_package)\n\n                    continue;\n\n                if (!memcmp(temp_package->package_uid, component->source_package_uid, 16)) {\n\n                    source_package = temp_package;\n\n                    break;\n\n                }\n\n            }\n\n            if (!source_package) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: no corresponding source package found\\n\", material_track->track_id);\n\n                break;\n\n            }\n\n            for (k = 0; k < source_package->tracks_count; k++) {\n\n                if (!(temp_track = mxf_resolve_strong_ref(mxf, &source_package->tracks_refs[k], Track))) {\n\n                    av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track strong ref\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                if (temp_track->track_id == component->source_track_id) {\n\n                    source_track = temp_track;\n\n                    break;\n\n                }\n\n            }\n\n            if (!source_track) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"material track %d: no corresponding source track found\\n\", material_track->track_id);\n\n                break;\n\n            }\n\n        }\n\n        if (!source_track)\n\n            continue;\n\n\n\n        st = avformat_new_stream(mxf->fc, NULL);\n\n        if (!st) {\n\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not allocate stream\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        st->id = source_track->track_id;\n\n        st->priv_data = source_track;\n\n        st->duration = component->duration;\n\n        if (st->duration == -1)\n\n            st->duration = AV_NOPTS_VALUE;\n\n        st->start_time = component->start_position;\n\n        avpriv_set_pts_info(st, 64, material_track->edit_rate.num, material_track->edit_rate.den);\n\n\n\n        if (!(source_track->sequence = mxf_resolve_strong_ref(mxf, &source_track->sequence_ref, Sequence))) {\n\n            av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve source track sequence strong ref\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        PRINT_KEY(mxf->fc, \"data definition   ul\", source_track->sequence->data_definition_ul);\n\n        codec_ul = mxf_get_codec_ul(ff_mxf_data_definition_uls, &source_track->sequence->data_definition_ul);\n\n        st->codec->codec_type = codec_ul->id;\n\n\n\n        source_package->descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor_ref, AnyType);\n\n        if (source_package->descriptor) {\n\n            if (source_package->descriptor->type == MultipleDescriptor) {\n\n                for (j = 0; j < source_package->descriptor->sub_descriptors_count; j++) {\n\n                    MXFDescriptor *sub_descriptor = mxf_resolve_strong_ref(mxf, &source_package->descriptor->sub_descriptors_refs[j], Descriptor);\n\n\n\n                    if (!sub_descriptor) {\n\n                        av_log(mxf->fc, AV_LOG_ERROR, \"could not resolve sub descriptor strong ref\\n\");\n\n                        continue;\n\n                    }\n\n                    if (sub_descriptor->linked_track_id == source_track->track_id) {\n\n                        descriptor = sub_descriptor;\n\n                        break;\n\n                    }\n\n                }\n\n            } else if (source_package->descriptor->type == Descriptor)\n\n                descriptor = source_package->descriptor;\n\n        }\n\n        if (!descriptor) {\n\n            av_log(mxf->fc, AV_LOG_INFO, \"source track %d: stream %d, no descriptor found\\n\", source_track->track_id, st->index);\n\n            continue;\n\n        }\n\n        PRINT_KEY(mxf->fc, \"essence codec     ul\", descriptor->essence_codec_ul);\n\n        PRINT_KEY(mxf->fc, \"essence container ul\", descriptor->essence_container_ul);\n\n        essence_container_ul = &descriptor->essence_container_ul;\n\n        /* HACK: replacing the original key with mxf_encrypted_essence_container\n\n         * is not allowed according to s429-6, try to find correct information anyway */\n\n        if (IS_KLV_KEY(essence_container_ul, mxf_encrypted_essence_container)) {\n\n            av_log(mxf->fc, AV_LOG_INFO, \"broken encrypted mxf file\\n\");\n\n            for (k = 0; k < mxf->metadata_sets_count; k++) {\n\n                MXFMetadataSet *metadata = mxf->metadata_sets[k];\n\n                if (metadata->type == CryptoContext) {\n\n                    essence_container_ul = &((MXFCryptoContext *)metadata)->source_container_ul;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n        /* TODO: drop PictureEssenceCoding and SoundEssenceCompression, only check EssenceContainer */\n\n        codec_ul = mxf_get_codec_ul(ff_mxf_codec_uls, &descriptor->essence_codec_ul);\n\n        st->codec->codec_id = codec_ul->id;\n\n        if (descriptor->extradata) {\n\n            st->codec->extradata = descriptor->extradata;\n\n            st->codec->extradata_size = descriptor->extradata_size;\n\n        }\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            container_ul = mxf_get_codec_ul(mxf_essence_container_uls, essence_container_ul);\n\n            if (st->codec->codec_id == CODEC_ID_NONE)\n\n                st->codec->codec_id = container_ul->id;\n\n            st->codec->width = descriptor->width;\n\n            st->codec->height = descriptor->height;\n\n            if (st->codec->codec_id == CODEC_ID_RAWVIDEO)\n\n                st->codec->pix_fmt = descriptor->pix_fmt;\n\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n        } else if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            container_ul = mxf_get_codec_ul(mxf_essence_container_uls, essence_container_ul);\n\n            if (st->codec->codec_id == CODEC_ID_NONE)\n\n                st->codec->codec_id = container_ul->id;\n\n            st->codec->channels = descriptor->channels;\n\n            st->codec->bits_per_coded_sample = descriptor->bits_per_sample;\n\n            st->codec->sample_rate = descriptor->sample_rate.num / descriptor->sample_rate.den;\n\n            /* TODO: implement CODEC_ID_RAWAUDIO */\n\n            if (st->codec->codec_id == CODEC_ID_PCM_S16LE) {\n\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n\n                    st->codec->codec_id = CODEC_ID_PCM_S24LE;\n\n                else if (descriptor->bits_per_sample == 32)\n\n                    st->codec->codec_id = CODEC_ID_PCM_S32LE;\n\n            } else if (st->codec->codec_id == CODEC_ID_PCM_S16BE) {\n\n                if (descriptor->bits_per_sample > 16 && descriptor->bits_per_sample <= 24)\n\n                    st->codec->codec_id = CODEC_ID_PCM_S24BE;\n\n                else if (descriptor->bits_per_sample == 32)\n\n                    st->codec->codec_id = CODEC_ID_PCM_S32BE;\n\n            } else if (st->codec->codec_id == CODEC_ID_MP2) {\n\n                st->need_parsing = AVSTREAM_PARSE_FULL;\n\n            }\n\n        }\n\n        if (st->codec->codec_type != AVMEDIA_TYPE_DATA && (*essence_container_ul)[15] > 0x01) {\n\n            av_log(mxf->fc, AV_LOG_WARNING, \"only frame wrapped mappings are correctly supported\\n\");\n\n            st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 1088, "_split": "valid", "_hash": "30430017eabf72a095b83ee70de93f7a"}
{"project": "FFmpeg", "commit_id": "7f6e05cdfd1242a6774e89283b6e2cefde191590", "target": 1, "func": "static inline int sym_quant(int c, int e, int levels)\n\n{\n\n    int v = ((((levels * c) >> (24 - e)) + 1) >> 1) + (levels >> 1);\n\n    av_assert2(v >= 0 && v < levels);\n\n    return v;\n\n}\n", "idx": 1090, "_split": "valid", "_hash": "7431745cefec8bf40e4104a705f4c42e"}
{"project": "FFmpeg", "commit_id": "60819e694ee5733741da91ebc237b20621de5bc3", "target": 1, "func": "void av_cold ff_ivi_free_buffers(IVIPlaneDesc *planes)\n\n{\n\n    int p, b, t;\n\n\n\n    for (p = 0; p < 3; p++) {\n\n        for (b = 0; b < planes[p].num_bands; b++) {\n\n            av_freep(&planes[p].bands[b].bufs[0]);\n\n            av_freep(&planes[p].bands[b].bufs[1]);\n\n            av_freep(&planes[p].bands[b].bufs[2]);\n\n\n\n\n\n            for (t = 0; t < planes[p].bands[b].num_tiles; t++)\n\n                av_freep(&planes[p].bands[b].tiles[t].mbs);\n\n            av_freep(&planes[p].bands[b].tiles);\n\n        }\n\n        av_freep(&planes[p].bands);\n\n    }\n\n}", "idx": 1132, "_split": "valid", "_hash": "7f15775499c55e077249a49beb980adc"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static void RENAME(extract_odd2avg)(const uint8_t *src0, const uint8_t *src1, uint8_t *dst0, uint8_t *dst1, x86_reg count)\n\n{\n\n    dst0 +=   count;\n\n    dst1 +=   count;\n\n    src0 += 4*count;\n\n    src1 += 4*count;\n\n    count= - count;\n\n#ifdef PAVGB\n\n    if(count <= -8) {\n\n        count += 7;\n\n        __asm__ volatile(\n\n            \"pcmpeqw        %%mm7, %%mm7        \\n\\t\"\n\n            \"psrlw             $8, %%mm7        \\n\\t\"\n\n            \"1:                                \\n\\t\"\n\n            \"movq  -28(%1, %0, 4), %%mm0        \\n\\t\"\n\n            \"movq  -20(%1, %0, 4), %%mm1        \\n\\t\"\n\n            \"movq  -12(%1, %0, 4), %%mm2        \\n\\t\"\n\n            \"movq   -4(%1, %0, 4), %%mm3        \\n\\t\"\n\n            PAVGB\" -28(%2, %0, 4), %%mm0        \\n\\t\"\n\n            PAVGB\" -20(%2, %0, 4), %%mm1        \\n\\t\"\n\n            PAVGB\" -12(%2, %0, 4), %%mm2        \\n\\t\"\n\n            PAVGB\" - 4(%2, %0, 4), %%mm3        \\n\\t\"\n\n            \"psrlw             $8, %%mm0        \\n\\t\"\n\n            \"psrlw             $8, %%mm1        \\n\\t\"\n\n            \"psrlw             $8, %%mm2        \\n\\t\"\n\n            \"psrlw             $8, %%mm3        \\n\\t\"\n\n            \"packuswb       %%mm1, %%mm0        \\n\\t\"\n\n            \"packuswb       %%mm3, %%mm2        \\n\\t\"\n\n            \"movq           %%mm0, %%mm1        \\n\\t\"\n\n            \"movq           %%mm2, %%mm3        \\n\\t\"\n\n            \"psrlw             $8, %%mm0        \\n\\t\"\n\n            \"psrlw             $8, %%mm2        \\n\\t\"\n\n            \"pand           %%mm7, %%mm1        \\n\\t\"\n\n            \"pand           %%mm7, %%mm3        \\n\\t\"\n\n            \"packuswb       %%mm2, %%mm0        \\n\\t\"\n\n            \"packuswb       %%mm3, %%mm1        \\n\\t\"\n\n            MOVNTQ\"         %%mm0,- 7(%4, %0)   \\n\\t\"\n\n            MOVNTQ\"         %%mm1,- 7(%3, %0)   \\n\\t\"\n\n            \"add               $8, %0           \\n\\t\"\n\n            \" js 1b                            \\n\\t\"\n\n            : \"+r\"(count)\n\n            : \"r\"(src0), \"r\"(src1), \"r\"(dst0), \"r\"(dst1)\n\n        );\n\n        count -= 7;\n\n    }\n\n#endif\n\n    src0++;\n\n    src1++;\n\n    while(count<0) {\n\n        dst0[count]= (src0[4*count+0]+src1[4*count+0])>>1;\n\n        dst1[count]= (src0[4*count+2]+src1[4*count+2])>>1;\n\n        count++;\n\n    }\n\n}\n", "idx": 1138, "_split": "valid", "_hash": "a8f540fe12706279eaafe234769fc4b9"}
{"project": "FFmpeg", "commit_id": "840c3c05316a59c70a7470ed27aaa9c2f3ba410a", "target": 1, "func": "static int pix_norm1_altivec(uint8_t *pix, int line_size)\n\n{\n\n    int i, s = 0;\n\n    const vector unsigned int zero =\n\n        (const vector unsigned int) vec_splat_u32(0);\n\n    vector unsigned int sv = (vector unsigned int) vec_splat_u32(0);\n\n    vector signed int sum;\n\n\n\n    for (i = 0; i < 16; i++) {\n\n        /* Read the potentially unaligned pixels. */\n\n        //vector unsigned char pixl = vec_ld(0,  pix);\n\n        //vector unsigned char pixr = vec_ld(15, pix);\n\n        //vector unsigned char pixv = vec_perm(pixl, pixr, perm);\n\n        vector unsigned char pixv = vec_vsx_ld(0,  pix);\n\n\n\n        /* Square the values, and add them to our sum. */\n\n        sv = vec_msum(pixv, pixv, sv);\n\n\n\n        pix += line_size;\n\n    }\n\n    /* Sum up the four partial sums, and put the result into s. */\n\n    sum = vec_sums((vector signed int) sv, (vector signed int) zero);\n\n    sum = vec_splat(sum, 3);\n\n    vec_vsx_st(sum, 0, &s);\n\n    return s;\n\n}\n", "idx": 1151, "_split": "valid", "_hash": "c460c77950155af729a0c21d74c1b031"}
{"project": "FFmpeg", "commit_id": "d7a762553c6f6c422adb6632354bcc4ff577b701", "target": 0, "func": "static int mxf_write_header(AVFormatContext *s)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    int i, ret;\n\n    uint8_t present[FF_ARRAY_ELEMS(mxf_essence_container_uls)] = {0};\n\n    const MXFSamplesPerFrame *spf = NULL;\n\n    AVDictionaryEntry *t;\n\n    int64_t timestamp = 0;\n\n\n\n    if (!s->nb_streams)\n\n        return -1;\n\n\n\n    if (s->oformat == &ff_mxf_opatom_muxer && s->nb_streams !=1){\n\n        av_log(s, AV_LOG_ERROR, \"there must be exactly one stream for mxf opatom\\n\");\n\n        return -1;\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        MXFStreamContext *sc = av_mallocz(sizeof(*sc));\n\n        if (!sc)\n\n            return AVERROR(ENOMEM);\n\n        st->priv_data = sc;\n\n\n\n        if (((i == 0) ^ (st->codec->codec_type == AVMEDIA_TYPE_VIDEO)) && s->oformat != &ff_mxf_opatom_muxer) {\n\n            av_log(s, AV_LOG_ERROR, \"there must be exactly one video stream and it must be the first one\\n\");\n\n            return -1;\n\n        }\n\n\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            const AVPixFmtDescriptor *pix_desc = av_pix_fmt_desc_get(st->codec->pix_fmt);\n\n            // TODO: should be avg_frame_rate\n\n            AVRational rate, tbc = st->time_base;\n\n            // Default component depth to 8\n\n            sc->component_depth = 8;\n\n            sc->h_chroma_sub_sample = 2;\n\n            sc->color_siting = 0xFF;\n\n\n\n            if (pix_desc) {\n\n                sc->component_depth     = pix_desc->comp[0].depth_minus1 + 1;\n\n                sc->h_chroma_sub_sample = 1 << pix_desc->log2_chroma_w;\n\n            }\n\n            switch (ff_choose_chroma_location(s, st)) {\n\n            case AVCHROMA_LOC_TOPLEFT: sc->color_siting = 0; break;\n\n            case AVCHROMA_LOC_LEFT:    sc->color_siting = 6; break;\n\n            case AVCHROMA_LOC_TOP:     sc->color_siting = 1; break;\n\n            case AVCHROMA_LOC_CENTER:  sc->color_siting = 3; break;\n\n            }\n\n\n\n            mxf->timecode_base = (tbc.den + tbc.num/2) / tbc.num;\n\n            spf = ff_mxf_get_samples_per_frame(s, tbc);\n\n            if (!spf) {\n\n                av_log(s, AV_LOG_ERROR, \"Unsupported video frame rate %d/%d\\n\",\n\n                       tbc.den, tbc.num);\n\n                return AVERROR(EINVAL);\n\n            }\n\n            mxf->time_base = spf->time_base;\n\n            rate = av_inv_q(mxf->time_base);\n\n            avpriv_set_pts_info(st, 64, mxf->time_base.num, mxf->time_base.den);\n\n            if((ret = mxf_init_timecode(s, st, rate)) < 0)\n\n                return ret;\n\n\n\n            sc->video_bit_rate = st->codec->bit_rate ? st->codec->bit_rate : st->codec->rc_max_rate;\n\n            if (s->oformat == &ff_mxf_d10_muxer) {\n\n                if (sc->video_bit_rate == 50000000) {\n\n                    if (mxf->time_base.den == 25) sc->index = 3;\n\n                    else                          sc->index = 5;\n\n                } else if (sc->video_bit_rate == 40000000) {\n\n                    if (mxf->time_base.den == 25) sc->index = 7;\n\n                    else                          sc->index = 9;\n\n                } else if (sc->video_bit_rate == 30000000) {\n\n                    if (mxf->time_base.den == 25) sc->index = 11;\n\n                    else                          sc->index = 13;\n\n                } else {\n\n                    av_log(s, AV_LOG_ERROR, \"error MXF D-10 only support 30/40/50 mbit/s\\n\");\n\n                    return -1;\n\n                }\n\n\n\n                mxf->edit_unit_byte_count = KAG_SIZE; // system element\n\n                mxf->edit_unit_byte_count += 16 + 4 + (uint64_t)sc->video_bit_rate *\n\n                    mxf->time_base.num / (8*mxf->time_base.den);\n\n                mxf->edit_unit_byte_count += klv_fill_size(mxf->edit_unit_byte_count);\n\n                mxf->edit_unit_byte_count += 16 + 4 + 4 + spf->samples_per_frame[0]*8*4;\n\n                mxf->edit_unit_byte_count += klv_fill_size(mxf->edit_unit_byte_count);\n\n\n\n                sc->signal_standard = 1;\n\n            }\n\n        } else if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (st->codec->sample_rate != 48000) {\n\n                av_log(s, AV_LOG_ERROR, \"only 48khz is implemented\\n\");\n\n                return -1;\n\n            }\n\n            avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n            if (s->oformat == &ff_mxf_d10_muxer) {\n\n                if (st->index != 1) {\n\n                    av_log(s, AV_LOG_ERROR, \"MXF D-10 only support one audio track\\n\");\n\n                    return -1;\n\n                }\n\n                if (st->codec->codec_id != AV_CODEC_ID_PCM_S16LE &&\n\n                    st->codec->codec_id != AV_CODEC_ID_PCM_S24LE) {\n\n                    av_log(s, AV_LOG_ERROR, \"MXF D-10 only support 16 or 24 bits le audio\\n\");\n\n                }\n\n                sc->index = ((MXFStreamContext*)s->streams[0]->priv_data)->index + 1;\n\n            } else if (s->oformat == &ff_mxf_opatom_muxer) {\n\n                AVRational tbc = av_inv_q(mxf->audio_edit_rate);\n\n\n\n                if (st->codec->codec_id != AV_CODEC_ID_PCM_S16LE &&\n\n                    st->codec->codec_id != AV_CODEC_ID_PCM_S24LE) {\n\n                    av_log(s, AV_LOG_ERROR, \"Only pcm_s16le and pcm_s24le audio codecs are implemented\\n\");\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n                if (st->codec->channels != 1) {\n\n                    av_log(s, AV_LOG_ERROR, \"MXF OPAtom only supports single channel audio\\n\");\n\n                    return AVERROR(EINVAL);\n\n                }\n\n\n\n                spf = ff_mxf_get_samples_per_frame(s, tbc);\n\n                if (!spf){\n\n                    av_log(s, AV_LOG_ERROR, \"Unsupported timecode frame rate %d/%d\\n\", tbc.den, tbc.num);\n\n                    return AVERROR(EINVAL);\n\n                }\n\n\n\n                mxf->time_base = st->time_base;\n\n                if((ret = mxf_init_timecode(s, st, av_inv_q(spf->time_base))) < 0)\n\n                    return ret;\n\n\n\n                mxf->timecode_base = (tbc.den + tbc.num/2) / tbc.num;\n\n                mxf->edit_unit_byte_count = (av_get_bits_per_sample(st->codec->codec_id) * st->codec->channels) >> 3;\n\n                sc->index = 2;\n\n            } else {\n\n                mxf->slice_count = 1;\n\n            }\n\n        }\n\n\n\n        if (!sc->index) {\n\n            sc->index = mxf_get_essence_container_ul_index(st->codec->codec_id);\n\n            if (sc->index == -1) {\n\n                av_log(s, AV_LOG_ERROR, \"track %d: could not find essence container ul, \"\n\n                       \"codec not currently supported in container\\n\", i);\n\n                return -1;\n\n            }\n\n        }\n\n\n\n        sc->codec_ul = &mxf_essence_container_uls[sc->index].codec_ul;\n\n\n\n        memcpy(sc->track_essence_element_key, mxf_essence_container_uls[sc->index].element_ul, 15);\n\n        sc->track_essence_element_key[15] = present[sc->index];\n\n        PRINT_KEY(s, \"track essence element key\", sc->track_essence_element_key);\n\n\n\n        if (!present[sc->index])\n\n            mxf->essence_container_count++;\n\n        present[sc->index]++;\n\n    }\n\n\n\n    if (s->oformat == &ff_mxf_d10_muxer || s->oformat == &ff_mxf_opatom_muxer) {\n\n        mxf->essence_container_count = 1;\n\n    }\n\n\n\n    if (!(s->flags & AVFMT_FLAG_BITEXACT))\n\n        mxf_gen_umid(s);\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        MXFStreamContext *sc = s->streams[i]->priv_data;\n\n        // update element count\n\n        sc->track_essence_element_key[13] = present[sc->index];\n\n        if (!memcmp(sc->track_essence_element_key, mxf_essence_container_uls[15].element_ul, 13)) // DV\n\n            sc->order = (0x15 << 24) | AV_RB32(sc->track_essence_element_key+13);\n\n        else\n\n            sc->order = AV_RB32(sc->track_essence_element_key+12);\n\n    }\n\n\n\n    if (t = av_dict_get(s->metadata, \"creation_time\", NULL, 0))\n\n        timestamp = ff_iso8601_to_unix_time(t->value);\n\n    if (timestamp)\n\n        mxf->timestamp = mxf_parse_timestamp(timestamp);\n\n    mxf->duration = -1;\n\n\n\n    mxf->timecode_track = av_mallocz(sizeof(*mxf->timecode_track));\n\n    if (!mxf->timecode_track)\n\n        return AVERROR(ENOMEM);\n\n    mxf->timecode_track->priv_data = av_mallocz(sizeof(MXFStreamContext));\n\n    if (!mxf->timecode_track->priv_data)\n\n        return AVERROR(ENOMEM);\n\n    mxf->timecode_track->index = -1;\n\n\n\n    if (!spf)\n\n        spf = ff_mxf_get_samples_per_frame(s, (AVRational){ 1, 25 });\n\n\n\n    if (ff_audio_interleave_init(s, spf->samples_per_frame, mxf->time_base) < 0)\n\n        return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 1226, "_split": "valid", "_hash": "1aa78a355d9b084209db8538ed3744ca"}
{"project": "FFmpeg", "commit_id": "57d77b3963ce1023eaf5ada8cba58b9379405cc8", "target": 0, "func": "int av_opencl_register_kernel_code(const char *kernel_code)\n\n{\n\n    int i, ret = 0;\n\n    LOCK_OPENCL;\n\n    if (gpu_env.kernel_code_count >= MAX_KERNEL_CODE_NUM) {\n\n        av_log(&openclutils, AV_LOG_ERROR,\n\n         \"Could not register kernel code, maximum number of registered kernel code %d already reached\\n\",\n\n         MAX_KERNEL_CODE_NUM);\n\n        ret = AVERROR(EINVAL);\n\n        goto end;\n\n    }\n\n    for (i = 0; i < gpu_env.kernel_code_count; i++) {\n\n        if (gpu_env.kernel_code[i].kernel_string == kernel_code) {\n\n            av_log(&openclutils, AV_LOG_WARNING, \"Same kernel code has been registered\\n\");\n\n            goto end;\n\n        }\n\n    }\n\n    gpu_env.kernel_code[gpu_env.kernel_code_count].kernel_string = kernel_code;\n\n    gpu_env.kernel_code[gpu_env.kernel_code_count].is_compiled = 0;\n\n    gpu_env.kernel_code_count++;\n\nend:\n\n    UNLOCK_OPENCL;\n\n    return ret;\n\n}\n", "idx": 1274, "_split": "valid", "_hash": "932368046a27c14f428105f15b14fdeb"}
{"project": "FFmpeg", "commit_id": "25e3e53d4092e7b69a4d681824fa0f7b2731bb1e", "target": 1, "func": "static void compute_stats(HTTPContext *c)\n\n{\n\n    HTTPContext *c1;\n\n    FFStream *stream;\n\n    char *p;\n\n    time_t ti;\n\n    int i, len;\n\n    ByteIOContext pb1, *pb = &pb1;\n\n\n\n    if (url_open_dyn_buf(pb) < 0) {\n\n        /* XXX: return an error ? */\n\n        c->buffer_ptr = c->buffer;\n\n        c->buffer_end = c->buffer;\n\n        return;\n\n    }\n\n\n\n    url_fprintf(pb, \"HTTP/1.0 200 OK\\r\\n\");\n\n    url_fprintf(pb, \"Content-type: %s\\r\\n\", \"text/html\");\n\n    url_fprintf(pb, \"Pragma: no-cache\\r\\n\");\n\n    url_fprintf(pb, \"\\r\\n\");\n\n\n\n    url_fprintf(pb, \"<HEAD><TITLE>FFServer Status</TITLE>\\n\");\n\n    if (c->stream->feed_filename)\n\n        url_fprintf(pb, \"<link rel=\\\"shortcut icon\\\" href=\\\"%s\\\">\\n\", c->stream->feed_filename);\n\n    url_fprintf(pb, \"</HEAD>\\n<BODY>\");\n\n    url_fprintf(pb, \"<H1>FFServer Status</H1>\\n\");\n\n    /* format status */\n\n    url_fprintf(pb, \"<H2>Available Streams</H2>\\n\");\n\n    url_fprintf(pb, \"<TABLE cellspacing=0 cellpadding=4>\\n\");\n\n    url_fprintf(pb, \"<TR><Th valign=top>Path<th align=left>Served<br>Conns<Th><br>bytes<Th valign=top>Format<Th>Bit rate<br>kbits/s<Th align=left>Video<br>kbits/s<th><br>Codec<Th align=left>Audio<br>kbits/s<th><br>Codec<Th align=left valign=top>Feed\\n\");\n\n    stream = first_stream;\n\n    while (stream != NULL) {\n\n        char sfilename[1024];\n\n        char *eosf;\n\n\n\n        if (stream->feed != stream) {\n\n            av_strlcpy(sfilename, stream->filename, sizeof(sfilename) - 10);\n\n            eosf = sfilename + strlen(sfilename);\n\n            if (eosf - sfilename >= 4) {\n\n                if (strcmp(eosf - 4, \".asf\") == 0)\n\n                    strcpy(eosf - 4, \".asx\");\n\n                else if (strcmp(eosf - 3, \".rm\") == 0)\n\n                    strcpy(eosf - 3, \".ram\");\n\n                else if (!strcmp(stream->fmt->name, \"rtp\")) {\n\n                    /* generate a sample RTSP director if\n\n                       unicast. Generate an SDP redirector if\n\n                       multicast */\n\n                    eosf = strrchr(sfilename, '.');\n\n                    if (!eosf)\n\n                        eosf = sfilename + strlen(sfilename);\n\n                    if (stream->is_multicast)\n\n                        strcpy(eosf, \".sdp\");\n\n                    else\n\n                        strcpy(eosf, \".rtsp\");\n\n                }\n\n            }\n\n\n\n            url_fprintf(pb, \"<TR><TD><A HREF=\\\"/%s\\\">%s</A> \",\n\n                         sfilename, stream->filename);\n\n            url_fprintf(pb, \"<td align=right> %d <td align=right> \",\n\n                        stream->conns_served);\n\n            fmt_bytecount(pb, stream->bytes_served);\n\n            switch(stream->stream_type) {\n\n            case STREAM_TYPE_LIVE:\n\n                {\n\n                    int audio_bit_rate = 0;\n\n                    int video_bit_rate = 0;\n\n                    const char *audio_codec_name = \"\";\n\n                    const char *video_codec_name = \"\";\n\n                    const char *audio_codec_name_extra = \"\";\n\n                    const char *video_codec_name_extra = \"\";\n\n\n\n                    for(i=0;i<stream->nb_streams;i++) {\n\n                        AVStream *st = stream->streams[i];\n\n                        AVCodec *codec = avcodec_find_encoder(st->codec->codec_id);\n\n                        switch(st->codec->codec_type) {\n\n                        case CODEC_TYPE_AUDIO:\n\n                            audio_bit_rate += st->codec->bit_rate;\n\n                            if (codec) {\n\n                                if (*audio_codec_name)\n\n                                    audio_codec_name_extra = \"...\";\n\n                                audio_codec_name = codec->name;\n\n                            }\n\n                            break;\n\n                        case CODEC_TYPE_VIDEO:\n\n                            video_bit_rate += st->codec->bit_rate;\n\n                            if (codec) {\n\n                                if (*video_codec_name)\n\n                                    video_codec_name_extra = \"...\";\n\n                                video_codec_name = codec->name;\n\n                            }\n\n                            break;\n\n                        case CODEC_TYPE_DATA:\n\n                            video_bit_rate += st->codec->bit_rate;\n\n                            break;\n\n                        default:\n\n                            abort();\n\n                        }\n\n                    }\n\n                    url_fprintf(pb, \"<TD align=center> %s <TD align=right> %d <TD align=right> %d <TD> %s %s <TD align=right> %d <TD> %s %s\",\n\n                                 stream->fmt->name,\n\n                                 stream->bandwidth,\n\n                                 video_bit_rate / 1000, video_codec_name, video_codec_name_extra,\n\n                                 audio_bit_rate / 1000, audio_codec_name, audio_codec_name_extra);\n\n                    if (stream->feed)\n\n                        url_fprintf(pb, \"<TD>%s\", stream->feed->filename);\n\n                    else\n\n                        url_fprintf(pb, \"<TD>%s\", stream->feed_filename);\n\n                    url_fprintf(pb, \"\\n\");\n\n                }\n\n                break;\n\n            default:\n\n                url_fprintf(pb, \"<TD align=center> - <TD align=right> - <TD align=right> - <td><td align=right> - <TD>\\n\");\n\n                break;\n\n            }\n\n        }\n\n        stream = stream->next;\n\n    }\n\n    url_fprintf(pb, \"</TABLE>\\n\");\n\n\n\n    stream = first_stream;\n\n    while (stream != NULL) {\n\n        if (stream->feed == stream) {\n\n            url_fprintf(pb, \"<h2>Feed %s</h2>\", stream->filename);\n\n            if (stream->pid) {\n\n                url_fprintf(pb, \"Running as pid %d.\\n\", stream->pid);\n\n\n\n#if defined(linux) && !defined(CONFIG_NOCUTILS)\n\n                {\n\n                    FILE *pid_stat;\n\n                    char ps_cmd[64];\n\n\n\n                    /* This is somewhat linux specific I guess */\n\n                    snprintf(ps_cmd, sizeof(ps_cmd),\n\n                             \"ps -o \\\"%%cpu,cputime\\\" --no-headers %d\",\n\n                             stream->pid);\n\n\n\n                    pid_stat = popen(ps_cmd, \"r\");\n\n                    if (pid_stat) {\n\n                        char cpuperc[10];\n\n                        char cpuused[64];\n\n\n\n                        if (fscanf(pid_stat, \"%10s %64s\", cpuperc,\n\n                                   cpuused) == 2) {\n\n                            url_fprintf(pb, \"Currently using %s%% of the cpu. Total time used %s.\\n\",\n\n                                         cpuperc, cpuused);\n\n                        }\n\n                        fclose(pid_stat);\n\n                    }\n\n                }\n\n#endif\n\n\n\n                url_fprintf(pb, \"<p>\");\n\n            }\n\n            url_fprintf(pb, \"<table cellspacing=0 cellpadding=4><tr><th>Stream<th>type<th>kbits/s<th align=left>codec<th align=left>Parameters\\n\");\n\n\n\n            for (i = 0; i < stream->nb_streams; i++) {\n\n                AVStream *st = stream->streams[i];\n\n                AVCodec *codec = avcodec_find_encoder(st->codec->codec_id);\n\n                const char *type = \"unknown\";\n\n                char parameters[64];\n\n\n\n                parameters[0] = 0;\n\n\n\n                switch(st->codec->codec_type) {\n\n                case CODEC_TYPE_AUDIO:\n\n                    type = \"audio\";\n\n                    snprintf(parameters, sizeof(parameters), \"%d channel(s), %d Hz\", st->codec->channels, st->codec->sample_rate);\n\n                    break;\n\n                case CODEC_TYPE_VIDEO:\n\n                    type = \"video\";\n\n                    snprintf(parameters, sizeof(parameters), \"%dx%d, q=%d-%d, fps=%d\", st->codec->width, st->codec->height,\n\n                                st->codec->qmin, st->codec->qmax, st->codec->time_base.den / st->codec->time_base.num);\n\n                    break;\n\n                default:\n\n                    abort();\n\n                }\n\n                url_fprintf(pb, \"<tr><td align=right>%d<td>%s<td align=right>%d<td>%s<td>%s\\n\",\n\n                        i, type, st->codec->bit_rate/1000, codec ? codec->name : \"\", parameters);\n\n            }\n\n            url_fprintf(pb, \"</table>\\n\");\n\n\n\n        }\n\n        stream = stream->next;\n\n    }\n\n\n\n#if 0\n\n    {\n\n        float avg;\n\n        AVCodecContext *enc;\n\n        char buf[1024];\n\n\n\n        /* feed status */\n\n        stream = first_feed;\n\n        while (stream != NULL) {\n\n            url_fprintf(pb, \"<H1>Feed '%s'</H1>\\n\", stream->filename);\n\n            url_fprintf(pb, \"<TABLE>\\n\");\n\n            url_fprintf(pb, \"<TR><TD>Parameters<TD>Frame count<TD>Size<TD>Avg bitrate (kbits/s)\\n\");\n\n            for(i=0;i<stream->nb_streams;i++) {\n\n                AVStream *st = stream->streams[i];\n\n                FeedData *fdata = st->priv_data;\n\n                enc = st->codec;\n\n\n\n                avcodec_string(buf, sizeof(buf), enc);\n\n                avg = fdata->avg_frame_size * (float)enc->rate * 8.0;\n\n                if (enc->codec->type == CODEC_TYPE_AUDIO && enc->frame_size > 0)\n\n                    avg /= enc->frame_size;\n\n                url_fprintf(pb, \"<TR><TD>%s <TD> %d <TD> %\"PRId64\" <TD> %0.1f\\n\",\n\n                             buf, enc->frame_number, fdata->data_count, avg / 1000.0);\n\n            }\n\n            url_fprintf(pb, \"</TABLE>\\n\");\n\n            stream = stream->next_feed;\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* connection status */\n\n    url_fprintf(pb, \"<H2>Connection Status</H2>\\n\");\n\n\n\n    url_fprintf(pb, \"Number of connections: %d / %d<BR>\\n\",\n\n                 nb_connections, nb_max_connections);\n\n\n\n    url_fprintf(pb, \"Bandwidth in use: %dk / %dk<BR>\\n\",\n\n                 current_bandwidth, max_bandwidth);\n\n\n\n    url_fprintf(pb, \"<TABLE>\\n\");\n\n    url_fprintf(pb, \"<TR><th>#<th>File<th>IP<th>Proto<th>State<th>Target bits/sec<th>Actual bits/sec<th>Bytes transferred\\n\");\n\n    c1 = first_http_ctx;\n\n    i = 0;\n\n    while (c1 != NULL) {\n\n        int bitrate;\n\n        int j;\n\n\n\n        bitrate = 0;\n\n        if (c1->stream) {\n\n            for (j = 0; j < c1->stream->nb_streams; j++) {\n\n                if (!c1->stream->feed)\n\n                    bitrate += c1->stream->streams[j]->codec->bit_rate;\n\n                else if (c1->feed_streams[j] >= 0)\n\n                    bitrate += c1->stream->feed->streams[c1->feed_streams[j]]->codec->bit_rate;\n\n            }\n\n        }\n\n\n\n        i++;\n\n        p = inet_ntoa(c1->from_addr.sin_addr);\n\n        url_fprintf(pb, \"<TR><TD><B>%d</B><TD>%s%s<TD>%s<TD>%s<TD>%s<td align=right>\",\n\n                    i,\n\n                    c1->stream ? c1->stream->filename : \"\",\n\n                    c1->state == HTTPSTATE_RECEIVE_DATA ? \"(input)\" : \"\",\n\n                    p,\n\n                    c1->protocol,\n\n                    http_state[c1->state]);\n\n        fmt_bytecount(pb, bitrate);\n\n        url_fprintf(pb, \"<td align=right>\");\n\n        fmt_bytecount(pb, compute_datarate(&c1->datarate, c1->data_count) * 8);\n\n        url_fprintf(pb, \"<td align=right>\");\n\n        fmt_bytecount(pb, c1->data_count);\n\n        url_fprintf(pb, \"\\n\");\n\n        c1 = c1->next;\n\n    }\n\n    url_fprintf(pb, \"</TABLE>\\n\");\n\n\n\n    /* date */\n\n    ti = time(NULL);\n\n    p = ctime(&ti);\n\n    url_fprintf(pb, \"<HR size=1 noshade>Generated at %s\", p);\n\n    url_fprintf(pb, \"</BODY>\\n</HTML>\\n\");\n\n\n\n    len = url_close_dyn_buf(pb, &c->pb_buffer);\n\n    c->buffer_ptr = c->pb_buffer;\n\n    c->buffer_end = c->pb_buffer + len;\n\n}\n", "idx": 1275, "_split": "valid", "_hash": "b109e0dacc3a4350e347b7ca095f1645"}
{"project": "FFmpeg", "commit_id": "5bca5f87d1a32669e0357790e0d0ad8a5c9c998b", "target": 0, "func": "av_cold void ff_videodsp_init_x86(VideoDSPContext *ctx, int bpc)\n\n{\n\n#if HAVE_YASM\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n#if ARCH_X86_32\n\n    if (EXTERNAL_MMX(cpu_flags) && bpc <= 8) {\n\n        ctx->emulated_edge_mc = emulated_edge_mc_mmx;\n\n    }\n\n    if (EXTERNAL_AMD3DNOW(cpu_flags)) {\n\n        ctx->prefetch = ff_prefetch_3dnow;\n\n    }\n\n#endif /* ARCH_X86_32 */\n\n    if (EXTERNAL_MMXEXT(cpu_flags)) {\n\n        ctx->prefetch = ff_prefetch_mmxext;\n\n#if ARCH_X86_32\n\n        if (bpc <= 8)\n\n            ctx->emulated_edge_mc = emulated_edge_mc_mmxext;\n\n#endif /* ARCH_X86_32 */\n\n    }\n\n#if ARCH_X86_32\n\n    if (EXTERNAL_SSE(cpu_flags) && bpc <= 8) {\n\n        ctx->emulated_edge_mc = emulated_edge_mc_sse;\n\n    }\n\n#endif /* ARCH_X86_32 */\n\n    if (EXTERNAL_SSE2(cpu_flags) && bpc <= 8) {\n\n        ctx->emulated_edge_mc = emulated_edge_mc_sse2;\n\n    }\n\n#endif /* HAVE_YASM */\n\n}\n", "idx": 1324, "_split": "valid", "_hash": "135cdbfaaa3be2d45b30e01d13b25cd6"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static av_always_inline void decode_cabac_luma_residual(const H264Context *h, H264SliceContext *sl,\n\n                                                        const uint8_t *scan, const uint8_t *scan8x8,\n\n                                                        int pixel_shift, int mb_type, int cbp, int p)\n\n{\n\n    static const uint8_t ctx_cat[4][3] = {{0,6,10},{1,7,11},{2,8,12},{5,9,13}};\n\n    const uint32_t *qmul;\n\n    int i8x8, i4x4;\n\n    int qscale = p == 0 ? sl->qscale : sl->chroma_qp[p - 1];\n\n    if( IS_INTRA16x16( mb_type ) ) {\n\n        AV_ZERO128(sl->mb_luma_dc[p]+0);\n\n        AV_ZERO128(sl->mb_luma_dc[p]+8);\n\n        AV_ZERO128(sl->mb_luma_dc[p]+16);\n\n        AV_ZERO128(sl->mb_luma_dc[p]+24);\n\n        decode_cabac_residual_dc(h, sl, sl->mb_luma_dc[p], ctx_cat[0][p], LUMA_DC_BLOCK_INDEX+p, scan, 16);\n\n\n\n        if( cbp&15 ) {\n\n            qmul = h->dequant4_coeff[p][qscale];\n\n            for( i4x4 = 0; i4x4 < 16; i4x4++ ) {\n\n                const int index = 16*p + i4x4;\n\n                decode_cabac_residual_nondc(h, sl, sl->mb + (16*index << pixel_shift), ctx_cat[1][p], index, scan + 1, qmul, 15);\n\n            }\n\n        } else {\n\n            fill_rectangle(&sl->non_zero_count_cache[scan8[16*p]], 4, 4, 8, 0, 1);\n\n        }\n\n    } else {\n\n        int cqm = (IS_INTRA( mb_type ) ? 0:3) + p;\n\n        for( i8x8 = 0; i8x8 < 4; i8x8++ ) {\n\n            if( cbp & (1<<i8x8) ) {\n\n                if( IS_8x8DCT(mb_type) ) {\n\n                    const int index = 16*p + 4*i8x8;\n\n                    decode_cabac_residual_nondc(h, sl, sl->mb + (16*index << pixel_shift), ctx_cat[3][p], index,\n\n                                                scan8x8, h->dequant8_coeff[cqm][qscale], 64);\n\n                } else {\n\n                    qmul = h->dequant4_coeff[cqm][qscale];\n\n                    for( i4x4 = 0; i4x4 < 4; i4x4++ ) {\n\n                        const int index = 16*p + 4*i8x8 + i4x4;\n\n//START_TIMER\n\n                        decode_cabac_residual_nondc(h, sl, sl->mb + (16*index << pixel_shift), ctx_cat[2][p], index, scan, qmul, 16);\n\n//STOP_TIMER(\"decode_residual\")\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[4*i8x8+16*p]], 2, 2, 8, 0, 1);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 1356, "_split": "valid", "_hash": "8aff58ac56c30768ad45ad752fa50b06"}
{"project": "FFmpeg", "commit_id": "083d0f6be8a22ce936c4be6f17977104e516434f", "target": 1, "func": "static void filter_samples(AVFilterLink *inlink, AVFilterBufferRef *samplesref)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    int i;\n\n\n\n    for (i = 0; i < ctx->nb_outputs; i++)\n\n        ff_filter_samples(inlink->dst->outputs[i],\n\n                          avfilter_ref_buffer(samplesref, ~AV_PERM_WRITE));\n\n\n}", "idx": 1372, "_split": "valid", "_hash": "0619bd19bfbbb220ad99cc1c13cf4eab"}
{"project": "FFmpeg", "commit_id": "9f06c1c61e876e930753da200bfe835817e30a53", "target": 1, "func": "static inline int decode_residual_inter(AVSContext *h) {\n\n    int block;\n\n\n\n    /* get coded block pattern */\n\n    int cbp= get_ue_golomb(&h->s.gb);\n\n    if(cbp > 63){\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"illegal inter cbp\\n\");\n\n        return -1;\n\n    }\n\n    h->cbp = cbp_tab[cbp][1];\n\n\n\n    /* get quantizer */\n\n    if(h->cbp && !h->qp_fixed)\n\n        h->qp = (h->qp + get_se_golomb(&h->s.gb)) & 63;\n\n    for(block=0;block<4;block++)\n\n        if(h->cbp & (1<<block))\n\n            decode_residual_block(h,&h->s.gb,ff_cavs_inter_dec,0,h->qp,\n\n                                  h->cy + h->luma_scan[block], h->l_stride);\n\n    decode_residual_chroma(h);\n\n\n\n    return 0;\n\n}\n", "idx": 1388, "_split": "valid", "_hash": "1cc28025ff3f632f2a34c9277bebeb6d"}
{"project": "FFmpeg", "commit_id": "87f29996415ad2c06ab00583d709fa03b5185305", "target": 1, "func": "static int gif_image_write_header(AVFormatContext *s, int width, int height,\n\n                                  int loop_count, uint32_t *palette)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVRational sar = s->streams[0]->codec->sample_aspect_ratio;\n\n    int i, aspect = 0;\n\n\n\n    if (sar.num > 0 && sar.den > 0) {\n\n        aspect = sar.num * 64 / sar.den - 15;\n\n        if (aspect < 0 || aspect > 255)\n\n            aspect = 0;\n\n    }\n\n\n\n    avio_write(pb, \"GIF\", 3);\n\n    avio_write(pb, \"89a\", 3);\n\n    avio_wl16(pb, width);\n\n    avio_wl16(pb, height);\n\n\n\n    if (palette) {\n\n        avio_w8(pb, 0xf7); /* flags: global clut, 256 entries */\n\n        avio_w8(pb, 0x1f); /* background color index */\n\n        avio_w8(pb, aspect);\n\n        for (i = 0; i < 256; i++) {\n\n            const uint32_t v = palette[i] & 0xffffff;\n\n            avio_wb24(pb, v);\n\n        }\n\n    } else {\n\n        avio_w8(pb, 0); /* flags */\n\n        avio_w8(pb, 0); /* background color index */\n\n        avio_w8(pb, aspect);\n\n    }\n\n\n\n\n\n    if (loop_count >= 0 ) {\n\n        /* \"NETSCAPE EXTENSION\" for looped animation GIF */\n\n        avio_w8(pb, 0x21); /* GIF Extension code */\n\n        avio_w8(pb, 0xff); /* Application Extension Label */\n\n        avio_w8(pb, 0x0b); /* Length of Application Block */\n\n        avio_write(pb, \"NETSCAPE2.0\", sizeof(\"NETSCAPE2.0\") - 1);\n\n        avio_w8(pb, 0x03); /* Length of Data Sub-Block */\n\n        avio_w8(pb, 0x01);\n\n        avio_wl16(pb, (uint16_t)loop_count);\n\n        avio_w8(pb, 0x00); /* Data Sub-block Terminator */\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 1422, "_split": "valid", "_hash": "b8a533466d647aa5c4273b7e163647be"}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0xA(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char P[4];\n\n    int flags = 0;\n\n\n\n    /* 4-color encoding for each 4x4 quadrant, or 4-color encoding on\n\n     * either top and bottom or left and right halves */\n\n    CHECK_STREAM_PTR(24);\n\n\n\n    if (s->stream_ptr[0] <= s->stream_ptr[1]) {\n\n\n\n        /* 4-color encoding for each quadrant; need 32 bytes */\n\n        CHECK_STREAM_PTR(32);\n\n\n\n        for (y = 0; y < 16; y++) {\n\n            // new values for each 4x4 block\n\n            if (!(y & 3)) {\n\n                memcpy(P, s->stream_ptr, 4);\n\n                s->stream_ptr += 4;\n\n                flags = bytestream_get_le32(&s->stream_ptr);\n\n            }\n\n\n\n            for (x = 0; x < 4; x++, flags >>= 2)\n\n                *s->pixel_ptr++ = P[flags & 0x03];\n\n\n\n            s->pixel_ptr += s->stride - 4;\n\n            // switch to right half\n\n            if (y == 7) s->pixel_ptr -= 8 * s->stride - 4;\n\n        }\n\n\n\n    } else {\n\n        // vertical split?\n\n        int vert = s->stream_ptr[12] <= s->stream_ptr[13];\n\n        uint64_t flags = 0;\n\n\n\n        /* 4-color encoding for either left and right or top and bottom\n\n         * halves */\n\n\n\n        for (y = 0; y < 16; y++) {\n\n            // load values for each half\n\n            if (!(y & 7)) {\n\n                memcpy(P, s->stream_ptr, 4);\n\n                s->stream_ptr += 4;\n\n                flags = bytestream_get_le64(&s->stream_ptr);\n\n            }\n\n\n\n            for (x = 0; x < 4; x++, flags >>= 2)\n\n                *s->pixel_ptr++ = P[flags & 0x03];\n\n\n\n            if (vert) {\n\n                s->pixel_ptr += s->stride - 4;\n\n                // switch to right half\n\n                if (y == 7) s->pixel_ptr -= 8 * s->stride - 4;\n\n            } else if (y & 1) s->pixel_ptr += s->line_inc;\n\n        }\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 1441, "_split": "valid", "_hash": "5e22099376d346c0516e96f3bdcc2bb3"}
{"project": "FFmpeg", "commit_id": "6a276c46b119d47e1d473e0813893820a9393562", "target": 0, "func": "static inline void dv_decode_video_segment(DVVideoContext *s,\n\n                                           const uint8_t *buf_ptr1,\n\n                                           const uint16_t *mb_pos_ptr)\n\n{\n\n    int quant, dc, dct_mode, class1, j;\n\n    int mb_index, mb_x, mb_y, v, last_index;\n\n    int y_stride, i;\n\n    DCTELEM *block, *block1;\n\n    int c_offset;\n\n    uint8_t *y_ptr;\n\n    const uint8_t *buf_ptr;\n\n    PutBitContext pb, vs_pb;\n\n    GetBitContext gb;\n\n    BlockInfo mb_data[5 * DV_MAX_BPM], *mb, *mb1;\n\n    DECLARE_ALIGNED_16(DCTELEM, sblock[5*DV_MAX_BPM][64]);\n\n    DECLARE_ALIGNED_8(uint8_t, mb_bit_buffer[80 + 4]); /* allow some slack */\n\n    DECLARE_ALIGNED_8(uint8_t, vs_bit_buffer[5 * 80 + 4]); /* allow some slack */\n\n    const int log2_blocksize= 3-s->avctx->lowres;\n\n    int is_field_mode[5];\n\n\n\n    assert((((int)mb_bit_buffer)&7)==0);\n\n    assert((((int)vs_bit_buffer)&7)==0);\n\n\n\n    memset(sblock, 0, sizeof(sblock));\n\n\n\n    /* pass 1 : read DC and AC coefficients in blocks */\n\n    buf_ptr = buf_ptr1;\n\n    block1 = &sblock[0][0];\n\n    mb1 = mb_data;\n\n    init_put_bits(&vs_pb, vs_bit_buffer, 5 * 80);\n\n    for(mb_index = 0; mb_index < 5; mb_index++, mb1 += s->sys->bpm, block1 += s->sys->bpm * 64) {\n\n        /* skip header */\n\n        quant = buf_ptr[3] & 0x0f;\n\n        buf_ptr += 4;\n\n        init_put_bits(&pb, mb_bit_buffer, 80);\n\n        mb = mb1;\n\n        block = block1;\n\n        is_field_mode[mb_index] = 0;\n\n        for(j = 0;j < s->sys->bpm; j++) {\n\n            last_index = s->sys->block_sizes[j];\n\n            init_get_bits(&gb, buf_ptr, last_index);\n\n\n\n            /* get the dc */\n\n            dc = get_sbits(&gb, 9);\n\n            dct_mode = get_bits1(&gb);\n\n            class1 = get_bits(&gb, 2);\n\n            if (DV_PROFILE_IS_HD(s->sys)) {\n\n                mb->idct_put = s->idct_put[0];\n\n                mb->scan_table = s->dv_zigzag[0];\n\n                mb->factor_table = s->dv100_idct_factor[((s->sys->height == 720)<<1)|(j >= 4)][class1][quant];\n\n                is_field_mode[mb_index] |= !j && dct_mode;\n\n            } else {\n\n                mb->idct_put = s->idct_put[dct_mode && log2_blocksize==3];\n\n                mb->scan_table = s->dv_zigzag[dct_mode];\n\n                mb->factor_table = s->dv_idct_factor[class1 == 3][dct_mode]\n\n                    [quant + dv_quant_offset[class1]];\n\n            }\n\n            dc = dc << 2;\n\n            /* convert to unsigned because 128 is not added in the\n\n               standard IDCT */\n\n            dc += 1024;\n\n            block[0] = dc;\n\n            buf_ptr += last_index >> 3;\n\n            mb->pos = 0;\n\n            mb->partial_bit_count = 0;\n\n\n\n#ifdef VLC_DEBUG\n\n            printf(\"MB block: %d, %d \", mb_index, j);\n\n#endif\n\n            dv_decode_ac(&gb, mb, block);\n\n\n\n            /* write the remaining bits  in a new buffer only if the\n\n               block is finished */\n\n            if (mb->pos >= 64)\n\n                bit_copy(&pb, &gb);\n\n\n\n            block += 64;\n\n            mb++;\n\n        }\n\n\n\n        /* pass 2 : we can do it just after */\n\n#ifdef VLC_DEBUG\n\n        printf(\"***pass 2 size=%d MB#=%d\\n\", put_bits_count(&pb), mb_index);\n\n#endif\n\n        block = block1;\n\n        mb = mb1;\n\n        init_get_bits(&gb, mb_bit_buffer, put_bits_count(&pb));\n\n        flush_put_bits(&pb);\n\n        for(j = 0;j < s->sys->bpm; j++, block += 64, mb++) {\n\n            if (mb->pos < 64 && get_bits_left(&gb) > 0) {\n\n                dv_decode_ac(&gb, mb, block);\n\n                /* if still not finished, no need to parse other blocks */\n\n                if (mb->pos < 64)\n\n                    break;\n\n            }\n\n        }\n\n        /* all blocks are finished, so the extra bytes can be used at\n\n           the video segment level */\n\n        if (j >= s->sys->bpm)\n\n            bit_copy(&vs_pb, &gb);\n\n    }\n\n\n\n    /* we need a pass other the whole video segment */\n\n#ifdef VLC_DEBUG\n\n    printf(\"***pass 3 size=%d\\n\", put_bits_count(&vs_pb));\n\n#endif\n\n    block = &sblock[0][0];\n\n    mb = mb_data;\n\n    init_get_bits(&gb, vs_bit_buffer, put_bits_count(&vs_pb));\n\n    flush_put_bits(&vs_pb);\n\n    for(mb_index = 0; mb_index < 5; mb_index++) {\n\n        for(j = 0;j < s->sys->bpm; j++) {\n\n            if (mb->pos < 64) {\n\n#ifdef VLC_DEBUG\n\n                printf(\"start %d:%d\\n\", mb_index, j);\n\n#endif\n\n                dv_decode_ac(&gb, mb, block);\n\n            }\n\n            if (mb->pos >= 64 && mb->pos < 127)\n\n                av_log(NULL, AV_LOG_ERROR, \"AC EOB marker is absent pos=%d\\n\", mb->pos);\n\n            block += 64;\n\n            mb++;\n\n        }\n\n    }\n\n\n\n    /* compute idct and place blocks */\n\n    block = &sblock[0][0];\n\n    mb = mb_data;\n\n    for(mb_index = 0; mb_index < 5; mb_index++) {\n\n        v = *mb_pos_ptr++;\n\n        mb_x = v & 0xff;\n\n        mb_y = v >> 8;\n\n        /* We work with 720p frames split in half. The odd half-frame (chan==2,3) is displaced :-( */\n\n        if (s->sys->height == 720 && !(s->buf[1]&0x0C)) {\n\n               mb_y -= (mb_y>17)?18:-72; /* shifting the Y coordinate down by 72/2 macroblocks */\n\n        }\n\n\n\n        /* idct_put'ting luminance */\n\n        if ((s->sys->pix_fmt == PIX_FMT_YUV420P) ||\n\n            (s->sys->pix_fmt == PIX_FMT_YUV411P && mb_x >= (704 / 8)) ||\n\n            (s->sys->height >= 720 && mb_y != 134)) {\n\n            y_stride = (s->picture.linesize[0]<<((!is_field_mode[mb_index])*log2_blocksize)) - (2<<log2_blocksize);\n\n        } else {\n\n            y_stride = 0;\n\n        }\n\n        y_ptr = s->picture.data[0] + ((mb_y * s->picture.linesize[0] + mb_x)<<log2_blocksize);\n\n        for(j = 0; j < 2; j++, y_ptr += y_stride) {\n\n            for (i=0; i<2; i++, block += 64, mb++, y_ptr += (1<<log2_blocksize))\n\n                 if (s->sys->pix_fmt == PIX_FMT_YUV422P && s->sys->width == 720 && i)\n\n                     y_ptr -= (1<<log2_blocksize);\n\n                 else\n\n                     mb->idct_put(y_ptr, s->picture.linesize[0]<<is_field_mode[mb_index], block);\n\n        }\n\n\n\n        /* idct_put'ting chrominance */\n\n        c_offset = (((mb_y>>(s->sys->pix_fmt == PIX_FMT_YUV420P)) * s->picture.linesize[1] +\n\n                     (mb_x>>((s->sys->pix_fmt == PIX_FMT_YUV411P)?2:1)))<<log2_blocksize);\n\n        for(j=2; j; j--) {\n\n            uint8_t *c_ptr = s->picture.data[j] + c_offset;\n\n            if (s->sys->pix_fmt == PIX_FMT_YUV411P && mb_x >= (704 / 8)) {\n\n                  uint64_t aligned_pixels[64/8];\n\n                  uint8_t *pixels = (uint8_t*)aligned_pixels;\n\n                  uint8_t *c_ptr1, *ptr1;\n\n                  int x, y;\n\n                  mb->idct_put(pixels, 8, block);\n\n                  for(y = 0; y < (1<<log2_blocksize); y++, c_ptr += s->picture.linesize[j], pixels += 8) {\n\n                      ptr1= pixels + (1<<(log2_blocksize-1));\n\n                      c_ptr1 = c_ptr + (s->picture.linesize[j]<<log2_blocksize);\n\n                      for(x=0; x < (1<<(log2_blocksize-1)); x++) {\n\n                          c_ptr[x]= pixels[x];\n\n                          c_ptr1[x]= ptr1[x];\n\n                      }\n\n                  }\n\n                  block += 64; mb++;\n\n            } else {\n\n                  y_stride = (mb_y == 134) ? (1<<log2_blocksize) :\n\n                                             s->picture.linesize[j]<<((!is_field_mode[mb_index])*log2_blocksize);\n\n                  for (i=0; i<(1<<(s->sys->bpm==8)); i++, block += 64, mb++, c_ptr += y_stride)\n\n                       mb->idct_put(c_ptr, s->picture.linesize[j]<<is_field_mode[mb_index], block);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 1447, "_split": "valid", "_hash": "ae9125355184199dfe48bb3951f7672c"}
{"project": "FFmpeg", "commit_id": "3ba105029279bf43e6338849f360f1ce9a2973a0", "target": 1, "func": "static void imc_get_coeffs(AVCodecContext *avctx,\n\n                           IMCContext *q, IMCChannel *chctx)\n\n{\n\n    int i, j, cw_len, cw;\n\n\n\n    for (i = 0; i < BANDS; i++) {\n\n        if (!chctx->sumLenArr[i])\n\n            continue;\n\n        if (chctx->bandFlagsBuf[i] || chctx->bandWidthT[i]) {\n\n            for (j = band_tab[i]; j < band_tab[i + 1]; j++) {\n\n                cw_len = chctx->CWlengthT[j];\n\n                cw = 0;\n\n\n\n                if (cw_len && (!chctx->bandFlagsBuf[i] || !chctx->skipFlags[j])) {\n\n                    if (get_bits_count(&q->gb) + cw_len > 512) {\n\n                        av_log(avctx, AV_LOG_WARNING,\n\n                            \"Potential problem on band %i, coefficient %i\"\n\n                            \": cw_len=%i\\n\", i, j, cw_len);\n\n                    }\n\n\n\n                    cw = get_bits(&q->gb, cw_len);\n\n                }\n\n\n\n                chctx->codewords[j] = cw;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 1459, "_split": "valid", "_hash": "9a32ee164d301ce1f4593cb81862915a"}
{"project": "FFmpeg", "commit_id": "9d8bb0318a0bc59a04c71555a3c575f8146eab41", "target": 0, "func": "static int unpack_dct_coeffs(Vp3DecodeContext *s, GetBitContext *gb)\n\n{\n\n    int i;\n\n    int dc_y_table;\n\n    int dc_c_table;\n\n    int ac_y_table;\n\n    int ac_c_table;\n\n    int residual_eob_run = 0;\n\n\n\n    /* fetch the DC table indexes */\n\n    dc_y_table = get_bits(gb, 4);\n\n    dc_c_table = get_bits(gb, 4);\n\n\n\n    /* unpack the Y plane DC coefficients */\n\n    residual_eob_run = unpack_vlcs(s, gb, &s->dc_vlc[dc_y_table], 0,\n\n        1, residual_eob_run);\n\n\n\n    /* reverse prediction of the Y-plane DC coefficients */\n\n    reverse_dc_prediction(s, 0, s->fragment_width, s->fragment_height);\n\n\n\n    /* unpack the C plane DC coefficients */\n\n    residual_eob_run = unpack_vlcs(s, gb, &s->dc_vlc[dc_c_table], 0,\n\n        0, residual_eob_run);\n\n\n\n    /* reverse prediction of the C-plane DC coefficients */\n\n    if (!(s->avctx->flags & CODEC_FLAG_GRAY))\n\n    {\n\n        reverse_dc_prediction(s, s->fragment_start[1],\n\n            s->fragment_width / 2, s->fragment_height / 2);\n\n        reverse_dc_prediction(s, s->fragment_start[2],\n\n            s->fragment_width / 2, s->fragment_height / 2);\n\n    }\n\n\n\n    /* fetch the AC table indexes */\n\n    ac_y_table = get_bits(gb, 4);\n\n    ac_c_table = get_bits(gb, 4);\n\n\n\n    /* unpack the group 1 AC coefficients (coeffs 1-5) */\n\n    for (i = 1; i <= 5; i++) {\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_1[ac_y_table], i,\n\n            1, residual_eob_run);\n\n\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_1[ac_c_table], i,\n\n            0, residual_eob_run);\n\n    }\n\n\n\n    /* unpack the group 2 AC coefficients (coeffs 6-14) */\n\n    for (i = 6; i <= 14; i++) {\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_2[ac_y_table], i,\n\n            1, residual_eob_run);\n\n\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_2[ac_c_table], i,\n\n            0, residual_eob_run);\n\n    }\n\n\n\n    /* unpack the group 3 AC coefficients (coeffs 15-27) */\n\n    for (i = 15; i <= 27; i++) {\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_3[ac_y_table], i,\n\n            1, residual_eob_run);\n\n\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_3[ac_c_table], i,\n\n            0, residual_eob_run);\n\n    }\n\n\n\n    /* unpack the group 4 AC coefficients (coeffs 28-63) */\n\n    for (i = 28; i <= 63; i++) {\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_4[ac_y_table], i,\n\n            1, residual_eob_run);\n\n\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_4[ac_c_table], i,\n\n            0, residual_eob_run);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 1571, "_split": "valid", "_hash": "d43478d644e7255f111b90b3137a0c2a"}
{"project": "FFmpeg", "commit_id": "c9f6eab184cac379c7a44d5899979165798d45d4", "target": 1, "func": "static int ac3_decode_frame(AVCodecContext * avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    AC3DecodeContext *s = avctx->priv_data;\n\n    int16_t *out_samples = (int16_t *)data;\n\n    int blk, ch, err;\n\n    const uint8_t *channel_map;\n\n    const float *output[AC3_MAX_CHANNELS];\n\n\n\n    /* initialize the GetBitContext with the start of valid AC-3 Frame */\n\n    if (s->input_buffer) {\n\n        /* copy input buffer to decoder context to avoid reading past the end\n\n           of the buffer, which can be caused by a damaged input stream. */\n\n        memcpy(s->input_buffer, buf, FFMIN(buf_size, AC3_FRAME_BUFFER_SIZE));\n\n        init_get_bits(&s->gbc, s->input_buffer, buf_size * 8);\n\n    } else {\n\n        init_get_bits(&s->gbc, buf, buf_size * 8);\n\n    }\n\n\n\n    /* parse the syncinfo */\n\n    *data_size = 0;\n\n    err = parse_frame_header(s);\n\n\n\n    if (err) {\n\n        switch(err) {\n\n            case AAC_AC3_PARSE_ERROR_SYNC:\n\n                av_log(avctx, AV_LOG_ERROR, \"frame sync error\\n\");\n\n                return -1;\n\n            case AAC_AC3_PARSE_ERROR_BSID:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid bitstream id\\n\");\n\n                break;\n\n            case AAC_AC3_PARSE_ERROR_SAMPLE_RATE:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid sample rate\\n\");\n\n                break;\n\n            case AAC_AC3_PARSE_ERROR_FRAME_SIZE:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid frame size\\n\");\n\n                break;\n\n            case AAC_AC3_PARSE_ERROR_FRAME_TYPE:\n\n                /* skip frame if CRC is ok. otherwise use error concealment. */\n\n                /* TODO: add support for substreams and dependent frames */\n\n                if(s->frame_type == EAC3_FRAME_TYPE_DEPENDENT || s->substreamid) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"unsupported frame type : skipping frame\\n\");\n\n                    return s->frame_size;\n\n                } else {\n\n                    av_log(avctx, AV_LOG_ERROR, \"invalid frame type\\n\");\n\n                }\n\n                break;\n\n            default:\n\n                av_log(avctx, AV_LOG_ERROR, \"invalid header\\n\");\n\n                break;\n\n        }\n\n    } else {\n\n        /* check that reported frame size fits in input buffer */\n\n        if (s->frame_size > buf_size) {\n\n            av_log(avctx, AV_LOG_ERROR, \"incomplete frame\\n\");\n\n            err = AAC_AC3_PARSE_ERROR_FRAME_SIZE;\n\n        } else if (avctx->error_recognition >= FF_ER_CAREFUL) {\n\n            /* check for crc mismatch */\n\n            if (av_crc(av_crc_get_table(AV_CRC_16_ANSI), 0, &buf[2], s->frame_size-2)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"frame CRC mismatch\\n\");\n\n                err = AAC_AC3_PARSE_ERROR_CRC;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* if frame is ok, set audio parameters */\n\n    if (!err) {\n\n        avctx->sample_rate = s->sample_rate;\n\n        avctx->bit_rate = s->bit_rate;\n\n\n\n        /* channel config */\n\n        s->out_channels = s->channels;\n\n        s->output_mode = s->channel_mode;\n\n        if(s->lfe_on)\n\n            s->output_mode |= AC3_OUTPUT_LFEON;\n\n        if (avctx->request_channels > 0 && avctx->request_channels <= 2 &&\n\n                avctx->request_channels < s->channels) {\n\n            s->out_channels = avctx->request_channels;\n\n            s->output_mode  = avctx->request_channels == 1 ? AC3_CHMODE_MONO : AC3_CHMODE_STEREO;\n\n            s->channel_layout = ff_ac3_channel_layout_tab[s->output_mode];\n\n        }\n\n        avctx->channels = s->out_channels;\n\n        avctx->channel_layout = s->channel_layout;\n\n\n\n        /* set downmixing coefficients if needed */\n\n        if(s->channels != s->out_channels && !((s->output_mode & AC3_OUTPUT_LFEON) &&\n\n                s->fbw_channels == s->out_channels)) {\n\n            set_downmix_coeffs(s);\n\n        }\n\n    } else if (!s->out_channels) {\n\n        s->out_channels = avctx->channels;\n\n        if(s->out_channels < s->channels)\n\n            s->output_mode  = s->out_channels == 1 ? AC3_CHMODE_MONO : AC3_CHMODE_STEREO;\n\n    }\n\n\n\n    /* decode the audio blocks */\n\n    channel_map = ff_ac3_dec_channel_map[s->output_mode & ~AC3_OUTPUT_LFEON][s->lfe_on];\n\n    for (ch = 0; ch < s->out_channels; ch++)\n\n        output[ch] = s->output[channel_map[ch]];\n\n    for (blk = 0; blk < s->num_blocks; blk++) {\n\n        if (!err && decode_audio_block(s, blk)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"error decoding the audio block\\n\");\n\n            err = 1;\n\n        }\n\n        s->fmt_conv.float_to_int16_interleave(out_samples, output, 256, s->out_channels);\n\n        out_samples += 256 * s->out_channels;\n\n    }\n\n    *data_size = s->num_blocks * 256 * avctx->channels * sizeof (int16_t);\n\n    return FFMIN(buf_size, s->frame_size);\n\n}\n", "idx": 1642, "_split": "valid", "_hash": "f9bb88e713c3c2dede618fc197646f20"}
{"project": "FFmpeg", "commit_id": "91767360d86ac786571593ab11c7291010ab3829", "target": 0, "func": "static int a64multi_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                                 const AVFrame *pict, int *got_packet)\n\n{\n\n    A64Context *c = avctx->priv_data;\n\n    AVFrame *const p = avctx->coded_frame;\n\n\n\n    int frame;\n\n    int x, y;\n\n    int b_height;\n\n    int b_width;\n\n\n\n    int req_size, ret;\n\n    uint8_t *buf;\n\n\n\n    int *charmap     = c->mc_charmap;\n\n    uint8_t *colram  = c->mc_colram;\n\n    uint8_t *charset = c->mc_charset;\n\n    int *meta        = c->mc_meta_charset;\n\n    int *best_cb     = c->mc_best_cb;\n\n\n\n    int charset_size = 0x800 * (INTERLACED + 1);\n\n    int colram_size  = 0x100 * c->mc_use_5col;\n\n    int screen_size;\n\n\n\n    if(CROP_SCREENS) {\n\n        b_height = FFMIN(avctx->height,C64YRES) >> 3;\n\n        b_width  = FFMIN(avctx->width ,C64XRES) >> 3;\n\n        screen_size = b_width * b_height;\n\n    } else {\n\n        b_height = C64YRES >> 3;\n\n        b_width  = C64XRES >> 3;\n\n        screen_size = 0x400;\n\n    }\n\n\n\n    /* no data, means end encoding asap */\n\n    if (!pict) {\n\n        /* all done, end encoding */\n\n        if (!c->mc_lifetime) return 0;\n\n        /* no more frames in queue, prepare to flush remaining frames */\n\n        if (!c->mc_frame_counter) {\n\n            c->mc_lifetime = 0;\n\n        }\n\n        /* still frames in queue so limit lifetime to remaining frames */\n\n        else c->mc_lifetime = c->mc_frame_counter;\n\n    /* still new data available */\n\n    } else {\n\n        /* fill up mc_meta_charset with data until lifetime exceeds */\n\n        if (c->mc_frame_counter < c->mc_lifetime) {\n\n            *p = *pict;\n\n            p->pict_type = AV_PICTURE_TYPE_I;\n\n            p->key_frame = 1;\n\n            to_meta_with_crop(avctx, p, meta + 32000 * c->mc_frame_counter);\n\n            c->mc_frame_counter++;\n\n            if (c->next_pts == AV_NOPTS_VALUE)\n\n                c->next_pts = pict->pts;\n\n            /* lifetime is not reached so wait for next frame first */\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    /* lifetime reached so now convert X frames at once */\n\n    if (c->mc_frame_counter == c->mc_lifetime) {\n\n        req_size = 0;\n\n        /* any frames to encode? */\n\n        if (c->mc_lifetime) {\n\n            req_size = charset_size + c->mc_lifetime*(screen_size + colram_size);\n\n            if ((ret = ff_alloc_packet(pkt, req_size)) < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Error getting output packet of size %d.\\n\", req_size);\n\n                return ret;\n\n            }\n\n            buf = pkt->data;\n\n\n\n            /* calc optimal new charset + charmaps */\n\n            ret = ff_init_elbg(meta, 32, 1000 * c->mc_lifetime, best_cb,\n\n                               CHARSET_CHARS, 50, charmap, &c->randctx);\n\n            if (ret < 0)\n\n                return ret;\n\n            ret = ff_do_elbg(meta, 32, 1000 * c->mc_lifetime, best_cb,\n\n                             CHARSET_CHARS, 50, charmap, &c->randctx);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            /* create colorram map and a c64 readable charset */\n\n            render_charset(avctx, charset, colram);\n\n\n\n            /* copy charset to buf */\n\n            memcpy(buf, charset, charset_size);\n\n\n\n            /* advance pointers */\n\n            buf      += charset_size;\n\n            charset  += charset_size;\n\n        }\n\n\n\n        /* write x frames to buf */\n\n        for (frame = 0; frame < c->mc_lifetime; frame++) {\n\n            /* copy charmap to buf. buf is uchar*, charmap is int*, so no memcpy here, sorry */\n\n            for (y = 0; y < b_height; y++) {\n\n                for (x = 0; x < b_width; x++) {\n\n                    buf[y * b_width + x] = charmap[y * b_width + x];\n\n                }\n\n            }\n\n            /* advance pointers */\n\n            buf += screen_size;\n\n            req_size += screen_size;\n\n\n\n            /* compress and copy colram to buf */\n\n            if (c->mc_use_5col) {\n\n                a64_compress_colram(buf, charmap, colram);\n\n                /* advance pointers */\n\n                buf += colram_size;\n\n                req_size += colram_size;\n\n            }\n\n\n\n            /* advance to next charmap */\n\n            charmap += 1000;\n\n        }\n\n\n\n        AV_WB32(avctx->extradata + 4,  c->mc_frame_counter);\n\n        AV_WB32(avctx->extradata + 8,  charset_size);\n\n        AV_WB32(avctx->extradata + 12, screen_size + colram_size);\n\n\n\n        /* reset counter */\n\n        c->mc_frame_counter = 0;\n\n\n\n        pkt->pts = pkt->dts = c->next_pts;\n\n        c->next_pts         = AV_NOPTS_VALUE;\n\n\n\n        pkt->size   = req_size;\n\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\n        *got_packet = !!req_size;\n\n    }\n\n    return 0;\n\n}\n", "idx": 1706, "_split": "valid", "_hash": "27dca184daa15bd6ad775ba517a0ea46"}
{"project": "FFmpeg", "commit_id": "0dbb48d91e9e97c7eb11f4ebc03c4ff4b6f5b692", "target": 1, "func": "static int mpegps_read_packet(AVFormatContext *s,\n\n                              AVPacket *pkt)\n\n{\n\n    AVStream *st;\n\n    int len, startcode, i, type, codec_id;\n\n    int64_t pts, dts;\n\n\n\n redo:\n\n    len = mpegps_read_pes_header(s, NULL, &startcode, &pts, &dts, 1);\n\n    if (len < 0)\n\n        return len;\n\n    \n\n    /* now find stream */\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        st = s->streams[i];\n\n        if (st->id == startcode)\n\n            goto found;\n\n    }\n\n    if (startcode >= 0x1e0 && startcode <= 0x1ef) {\n\n        type = CODEC_TYPE_VIDEO;\n\n        codec_id = CODEC_ID_MPEG1VIDEO;\n\n    } else if (startcode >= 0x1c0 && startcode <= 0x1df) {\n\n        type = CODEC_TYPE_AUDIO;\n\n        codec_id = CODEC_ID_MP2;\n\n    } else if (startcode >= 0x80 && startcode <= 0x9f) {\n\n        type = CODEC_TYPE_AUDIO;\n\n        codec_id = CODEC_ID_AC3;\n\n    } else if (startcode >= 0xa0 && startcode <= 0xbf) {\n\n        type = CODEC_TYPE_AUDIO;\n\n        codec_id = CODEC_ID_PCM_S16BE;\n\n    } else {\n\n    skip:\n\n        /* skip packet */\n\n        url_fskip(&s->pb, len);\n\n        goto redo;\n\n    }\n\n    /* no stream found: add a new stream */\n\n    st = av_new_stream(s, startcode);\n\n    if (!st) \n\n        goto skip;\n\n    st->codec.codec_type = type;\n\n    st->codec.codec_id = codec_id;\n\n    if (codec_id != CODEC_ID_PCM_S16BE)\n\n        st->need_parsing = 1;\n\n found:\n\n    if (startcode >= 0xa0 && startcode <= 0xbf) {\n\n        int b1, freq;\n\n        static const int lpcm_freq_tab[4] = { 48000, 96000, 44100, 32000 };\n\n\n\n        /* for LPCM, we just skip the header and consider it is raw\n\n           audio data */\n\n        if (len <= 3)\n\n            goto skip;\n\n        get_byte(&s->pb); /* emphasis (1), muse(1), reserved(1), frame number(5) */\n\n        b1 = get_byte(&s->pb); /* quant (2), freq(2), reserved(1), channels(3) */\n\n        get_byte(&s->pb); /* dynamic range control (0x80 = off) */\n\n        len -= 3;\n\n        freq = (b1 >> 4) & 3;\n\n        st->codec.sample_rate = lpcm_freq_tab[freq];\n\n        st->codec.channels = 1 + (b1 & 7);\n\n        st->codec.bit_rate = st->codec.channels * st->codec.sample_rate * 2;\n\n    }\n\n    av_new_packet(pkt, len);\n\n    get_buffer(&s->pb, pkt->data, pkt->size);\n\n    pkt->pts = pts;\n\n    pkt->dts = dts;\n\n    pkt->stream_index = st->index;\n\n#if 0\n\n    printf(\"%d: pts=%0.3f dts=%0.3f\\n\",\n\n           pkt->stream_index, pkt->pts / 90000.0, pkt->dts / 90000.0);\n\n#endif\n\n    return 0;\n\n}\n", "idx": 1776, "_split": "valid", "_hash": "8b714058b7e914c77d4d689218a5ebb9"}
{"project": "FFmpeg", "commit_id": "afb2bac48d0d044718c2da3d34a97bee244be2e3", "target": 1, "func": "static int flic_decode_frame_8BPP(AVCodecContext *avctx,\n\n                                  void *data, int *data_size,\n\n                                  const uint8_t *buf, int buf_size)\n\n{\n\n    FlicDecodeContext *s = avctx->priv_data;\n\n\n\n    int stream_ptr = 0;\n\n    int pixel_ptr;\n\n    int palette_ptr;\n\n    unsigned char palette_idx1;\n\n    unsigned char palette_idx2;\n\n\n\n    unsigned int frame_size;\n\n    int num_chunks;\n\n\n\n    unsigned int chunk_size;\n\n    int chunk_type;\n\n\n\n    int i, j;\n\n\n\n    int color_packets;\n\n    int color_changes;\n\n    int color_shift;\n\n    unsigned char r, g, b;\n\n\n\n    int lines;\n\n    int compressed_lines;\n\n    int starting_line;\n\n    signed short line_packets;\n\n    int y_ptr;\n\n    int byte_run;\n\n    int pixel_skip;\n\n    int pixel_countdown;\n\n    unsigned char *pixels;\n\n    unsigned int pixel_limit;\n\n\n\n    s->frame.reference = 3;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pixels = s->frame.data[0];\n\n    pixel_limit = s->avctx->height * s->frame.linesize[0];\n\n\n\n    if (buf_size < 16 || buf_size > INT_MAX - (3 * 256 + FF_INPUT_BUFFER_PADDING_SIZE))\n\n        return AVERROR_INVALIDDATA;\n\n    frame_size = AV_RL32(&buf[stream_ptr]);\n\n    if (frame_size > buf_size)\n\n        frame_size = buf_size;\n\n    stream_ptr += 6;  /* skip the magic number */\n\n    num_chunks = AV_RL16(&buf[stream_ptr]);\n\n    stream_ptr += 10;  /* skip padding */\n\n\n\n    frame_size -= 16;\n\n\n\n    /* iterate through the chunks */\n\n    while ((frame_size >= 6) && (num_chunks > 0)) {\n\n        int stream_ptr_after_chunk;\n\n        chunk_size = AV_RL32(&buf[stream_ptr]);\n\n        if (chunk_size > frame_size) {\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"Invalid chunk_size = %u > frame_size = %u\\n\", chunk_size, frame_size);\n\n            chunk_size = frame_size;\n\n        }\n\n        stream_ptr_after_chunk = stream_ptr + chunk_size;\n\n\n\n        stream_ptr += 4;\n\n        chunk_type = AV_RL16(&buf[stream_ptr]);\n\n        stream_ptr += 2;\n\n\n\n        switch (chunk_type) {\n\n        case FLI_256_COLOR:\n\n        case FLI_COLOR:\n\n            /* check special case: If this file is from the Magic Carpet\n\n             * game and uses 6-bit colors even though it reports 256-color\n\n             * chunks in a 0xAF12-type file (fli_type is set to 0xAF13 during\n\n             * initialization) */\n\n            if ((chunk_type == FLI_256_COLOR) && (s->fli_type != FLC_MAGIC_CARPET_SYNTHETIC_TYPE_CODE))\n\n                color_shift = 0;\n\n            else\n\n                color_shift = 2;\n\n            /* set up the palette */\n\n            color_packets = AV_RL16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            palette_ptr = 0;\n\n            for (i = 0; i < color_packets; i++) {\n\n                /* first byte is how many colors to skip */\n\n                palette_ptr += buf[stream_ptr++];\n\n\n\n                /* next byte indicates how many entries to change */\n\n                color_changes = buf[stream_ptr++];\n\n\n\n                /* if there are 0 color changes, there are actually 256 */\n\n                if (color_changes == 0)\n\n                    color_changes = 256;\n\n\n\n                if (stream_ptr + color_changes * 3 > stream_ptr_after_chunk)\n\n                    break;\n\n\n\n                for (j = 0; j < color_changes; j++) {\n\n                    unsigned int entry;\n\n\n\n                    /* wrap around, for good measure */\n\n                    if ((unsigned)palette_ptr >= 256)\n\n                        palette_ptr = 0;\n\n\n\n                    r = buf[stream_ptr++] << color_shift;\n\n                    g = buf[stream_ptr++] << color_shift;\n\n                    b = buf[stream_ptr++] << color_shift;\n\n                    entry = 0xFF << 24 | r << 16 | g << 8 | b;\n\n                    if (color_shift == 2)\n\n                        entry |= entry >> 6 & 0x30303;\n\n                    if (s->palette[palette_ptr] != entry)\n\n                        s->new_palette = 1;\n\n                    s->palette[palette_ptr++] = entry;\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_DELTA:\n\n            y_ptr = 0;\n\n            compressed_lines = AV_RL16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                if (stream_ptr + 2 > stream_ptr_after_chunk)\n\n                    break;\n\n                line_packets = AV_RL16(&buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n                if ((line_packets & 0xC000) == 0xC000) {\n\n                    // line skip opcode\n\n                    line_packets = -line_packets;\n\n                    y_ptr += line_packets * s->frame.linesize[0];\n\n                } else if ((line_packets & 0xC000) == 0x4000) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Undefined opcode (%x) in DELTA_FLI\\n\", line_packets);\n\n                } else if ((line_packets & 0xC000) == 0x8000) {\n\n                    // \"last byte\" opcode\n\n                    pixel_ptr= y_ptr + s->frame.linesize[0] - 1;\n\n                    CHECK_PIXEL_PTR(0);\n\n                    pixels[pixel_ptr] = line_packets & 0xff;\n\n                } else {\n\n                    compressed_lines--;\n\n                    pixel_ptr = y_ptr;\n\n                    CHECK_PIXEL_PTR(0);\n\n                    pixel_countdown = s->avctx->width;\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        if (stream_ptr + 2 > stream_ptr_after_chunk)\n\n                            break;\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += pixel_skip;\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = (signed char)(buf[stream_ptr++]);\n\n                        if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            palette_idx2 = buf[stream_ptr++];\n\n                            CHECK_PIXEL_PTR(byte_run * 2);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                                pixels[pixel_ptr++] = palette_idx2;\n\n                            }\n\n                        } else {\n\n                            CHECK_PIXEL_PTR(byte_run * 2);\n\n                            if (stream_ptr + byte_run * 2 > stream_ptr_after_chunk)\n\n                                break;\n\n                            for (j = 0; j < byte_run * 2; j++, pixel_countdown--) {\n\n                                palette_idx1 = buf[stream_ptr++];\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    y_ptr += s->frame.linesize[0];\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_LC:\n\n            /* line compressed */\n\n            starting_line = AV_RL16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            y_ptr = 0;\n\n            y_ptr += starting_line * s->frame.linesize[0];\n\n\n\n            compressed_lines = AV_RL16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                pixel_ptr = y_ptr;\n\n                CHECK_PIXEL_PTR(0);\n\n                pixel_countdown = s->avctx->width;\n\n                line_packets = buf[stream_ptr++];\n\n                if (stream_ptr + 2 * line_packets > stream_ptr_after_chunk)\n\n                    break;\n\n                if (line_packets > 0) {\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += pixel_skip;\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = (signed char)(buf[stream_ptr++]);\n\n                        if (byte_run > 0) {\n\n                            CHECK_PIXEL_PTR(byte_run);\n\n                            if (stream_ptr + byte_run > stream_ptr_after_chunk)\n\n                                break;\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                palette_idx1 = buf[stream_ptr++];\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        } else if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            CHECK_PIXEL_PTR(byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n                compressed_lines--;\n\n            }\n\n            break;\n\n\n\n        case FLI_BLACK:\n\n            /* set the whole frame to color 0 (which is usually black) */\n\n            memset(pixels, 0,\n\n                s->frame.linesize[0] * s->avctx->height);\n\n            break;\n\n\n\n        case FLI_BRUN:\n\n            /* Byte run compression: This chunk type only occurs in the first\n\n             * FLI frame and it will update the entire frame. */\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                stream_ptr++;\n\n                pixel_countdown = s->avctx->width;\n\n                while (pixel_countdown > 0) {\n\n                    if (stream_ptr + 1 > stream_ptr_after_chunk)\n\n                        break;\n\n                    byte_run = (signed char)(buf[stream_ptr++]);\n\n                    if (byte_run > 0) {\n\n                        palette_idx1 = buf[stream_ptr++];\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    } else {  /* copy bytes if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        if (stream_ptr + byte_run > stream_ptr_after_chunk)\n\n                            break;\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_COPY:\n\n            /* copy the chunk (uncompressed frame) */\n\n            if (chunk_size - 6 != s->avctx->width * s->avctx->height) {\n\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n\n                       \"has incorrect size, skipping chunk\\n\", chunk_size - 6);\n\n            } else {\n\n                for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;\n\n                     y_ptr += s->frame.linesize[0]) {\n\n                    memcpy(&pixels[y_ptr], &buf[stream_ptr],\n\n                        s->avctx->width);\n\n                    stream_ptr += s->avctx->width;\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_MINI:\n\n            /* some sort of a thumbnail? disregard this chunk... */\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n\n            break;\n\n        }\n\n\n\n        stream_ptr = stream_ptr_after_chunk;\n\n\n\n        frame_size -= chunk_size;\n\n        num_chunks--;\n\n    }\n\n\n\n    /* by the end of the chunk, the stream ptr should equal the frame\n\n     * size (minus 1, possibly); if it doesn't, issue a warning */\n\n    if ((stream_ptr != buf_size) && (stream_ptr != buf_size - 1))\n\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n\n               \"and final chunk ptr = %d\\n\", buf_size, stream_ptr);\n\n\n\n    /* make the palette available on the way out */\n\n    memcpy(s->frame.data[1], s->palette, AVPALETTE_SIZE);\n\n    if (s->new_palette) {\n\n        s->frame.palette_has_changed = 1;\n\n        s->new_palette = 0;\n\n    }\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 1800, "_split": "valid", "_hash": "d9ca24bf29662a347688c8080412426f"}
{"project": "FFmpeg", "commit_id": "b0a043f51b8cc3b420dc3ceaa38fe9aa344799aa", "target": 1, "func": "static int dcstr_read_header(AVFormatContext *s)\n\n{\n\n    unsigned codec, align;\n\n    AVStream *st;\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n\n    st->codecpar->channels    = avio_rl32(s->pb);\n\n    st->codecpar->sample_rate = avio_rl32(s->pb);\n\n    codec                  = avio_rl32(s->pb);\n\n    align                  = avio_rl32(s->pb);\n\n    avio_skip(s->pb, 4);\n\n    st->duration           = avio_rl32(s->pb);\n\n    st->codecpar->channels   *= avio_rl32(s->pb);\n\n    if (!align || align > INT_MAX / st->codecpar->channels)\n\n        return AVERROR_INVALIDDATA;\n\n    st->codecpar->block_align = align * st->codecpar->channels;\n\n\n\n    switch (codec) {\n\n    case  4: st->codecpar->codec_id = AV_CODEC_ID_ADPCM_AICA;       break;\n\n    case 16: st->codecpar->codec_id = AV_CODEC_ID_PCM_S16LE_PLANAR; break;\n\n    default: avpriv_request_sample(s, \"codec %X\", codec);\n\n             return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    avio_skip(s->pb, 0x800 - avio_tell(s->pb));\n\n    avpriv_set_pts_info(st, 64, 1, st->codecpar->sample_rate);\n\n\n\n    return 0;\n\n}\n", "idx": 1826, "_split": "valid", "_hash": "594dec6c9eb8a44ab49ab34e0696160c"}
{"project": "FFmpeg", "commit_id": "b7c77912b62163b3b46ce93fe42fff3c83604c82", "target": 1, "func": "int ff_oss_audio_open(AVFormatContext *s1, int is_output,\n\n                      const char *audio_device)\n\n{\n\n    OSSAudioData *s = s1->priv_data;\n\n    int audio_fd;\n\n    int tmp, err;\n\n    char *flip = getenv(\"AUDIO_FLIP_LEFT\");\n\n\n\n    if (is_output)\n\n        audio_fd = avpriv_open(audio_device, O_WRONLY);\n\n    else\n\n        audio_fd = avpriv_open(audio_device, O_RDONLY);\n\n    if (audio_fd < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"%s: %s\\n\", audio_device, strerror(errno));\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    if (flip && *flip == '1') {\n\n        s->flip_left = 1;\n\n    }\n\n\n\n    /* non blocking mode */\n\n    if (!is_output)\n\n        fcntl(audio_fd, F_SETFL, O_NONBLOCK);\n\n\n\n    s->frame_size = OSS_AUDIO_BLOCK_SIZE;\n\n\n\n    /* select format : favour native format */\n\n    err = ioctl(audio_fd, SNDCTL_DSP_GETFMTS, &tmp);\n\n\n\n#if HAVE_BIGENDIAN\n\n    if (tmp & AFMT_S16_BE) {\n\n        tmp = AFMT_S16_BE;\n\n    } else if (tmp & AFMT_S16_LE) {\n\n        tmp = AFMT_S16_LE;\n\n    } else {\n\n        tmp = 0;\n\n    }\n\n#else\n\n    if (tmp & AFMT_S16_LE) {\n\n        tmp = AFMT_S16_LE;\n\n    } else if (tmp & AFMT_S16_BE) {\n\n        tmp = AFMT_S16_BE;\n\n    } else {\n\n        tmp = 0;\n\n    }\n\n#endif\n\n\n\n    switch(tmp) {\n\n    case AFMT_S16_LE:\n\n        s->codec_id = AV_CODEC_ID_PCM_S16LE;\n\n        break;\n\n    case AFMT_S16_BE:\n\n        s->codec_id = AV_CODEC_ID_PCM_S16BE;\n\n        break;\n\n    default:\n\n        av_log(s1, AV_LOG_ERROR, \"Soundcard does not support 16 bit sample format\\n\");\n\n        close(audio_fd);\n\n        return AVERROR(EIO);\n\n    }\n\n    err=ioctl(audio_fd, SNDCTL_DSP_SETFMT, &tmp);\n\n    if (err < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"SNDCTL_DSP_SETFMT: %s\\n\", strerror(errno));\n\n        goto fail;\n\n    }\n\n\n\n    tmp = (s->channels == 2);\n\n    err = ioctl(audio_fd, SNDCTL_DSP_STEREO, &tmp);\n\n    if (err < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"SNDCTL_DSP_STEREO: %s\\n\", strerror(errno));\n\n        goto fail;\n\n    }\n\n\n\n    tmp = s->sample_rate;\n\n    err = ioctl(audio_fd, SNDCTL_DSP_SPEED, &tmp);\n\n    if (err < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"SNDCTL_DSP_SPEED: %s\\n\", strerror(errno));\n\n        goto fail;\n\n    }\n\n    s->sample_rate = tmp; /* store real sample rate */\n\n    s->fd = audio_fd;\n\n\n\n    return 0;\n\n fail:\n\n    close(audio_fd);\n\n    return AVERROR(EIO);\n\n}\n", "idx": 1830, "_split": "valid", "_hash": "94a6f54cca52db5cc988f625b3fc409b"}
{"project": "FFmpeg", "commit_id": "75084e47ffc24bede7acaf00c5e092ca46f52bbc", "target": 0, "func": "static int RENAME(swScale)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,\n\n                           int srcSliceH, uint8_t* dst[], int dstStride[])\n\n{\n\n    /* load a few things into local vars to make the code more readable? and faster */\n\n    const int srcW= c->srcW;\n\n    const int dstW= c->dstW;\n\n    const int dstH= c->dstH;\n\n    const int chrDstW= c->chrDstW;\n\n    const int chrSrcW= c->chrSrcW;\n\n    const int lumXInc= c->lumXInc;\n\n    const int chrXInc= c->chrXInc;\n\n    const enum PixelFormat dstFormat= c->dstFormat;\n\n    const enum PixelFormat srcFormat= c->srcFormat;\n\n    const int flags= c->flags;\n\n    int16_t *vLumFilterPos= c->vLumFilterPos;\n\n    int16_t *vChrFilterPos= c->vChrFilterPos;\n\n    int16_t *hLumFilterPos= c->hLumFilterPos;\n\n    int16_t *hChrFilterPos= c->hChrFilterPos;\n\n    int16_t *vLumFilter= c->vLumFilter;\n\n    int16_t *vChrFilter= c->vChrFilter;\n\n    int16_t *hLumFilter= c->hLumFilter;\n\n    int16_t *hChrFilter= c->hChrFilter;\n\n    int32_t *lumMmxFilter= c->lumMmxFilter;\n\n    int32_t *chrMmxFilter= c->chrMmxFilter;\n\n    int32_t *alpMmxFilter= c->alpMmxFilter;\n\n    const int vLumFilterSize= c->vLumFilterSize;\n\n    const int vChrFilterSize= c->vChrFilterSize;\n\n    const int hLumFilterSize= c->hLumFilterSize;\n\n    const int hChrFilterSize= c->hChrFilterSize;\n\n    int16_t **lumPixBuf= c->lumPixBuf;\n\n    int16_t **chrPixBuf= c->chrPixBuf;\n\n    int16_t **alpPixBuf= c->alpPixBuf;\n\n    const int vLumBufSize= c->vLumBufSize;\n\n    const int vChrBufSize= c->vChrBufSize;\n\n    uint8_t *formatConvBuffer= c->formatConvBuffer;\n\n    const int chrSrcSliceY= srcSliceY >> c->chrSrcVSubSample;\n\n    const int chrSrcSliceH= -((-srcSliceH) >> c->chrSrcVSubSample);\n\n    int lastDstY;\n\n    uint32_t *pal=c->pal_yuv;\n\n\n\n    /* vars which will change and which we need to store back in the context */\n\n    int dstY= c->dstY;\n\n    int lumBufIndex= c->lumBufIndex;\n\n    int chrBufIndex= c->chrBufIndex;\n\n    int lastInLumBuf= c->lastInLumBuf;\n\n    int lastInChrBuf= c->lastInChrBuf;\n\n\n\n    if (isPacked(c->srcFormat)) {\n\n        src[0]=\n\n        src[1]=\n\n        src[2]=\n\n        src[3]= src[0];\n\n        srcStride[0]=\n\n        srcStride[1]=\n\n        srcStride[2]=\n\n        srcStride[3]= srcStride[0];\n\n    }\n\n    srcStride[1]<<= c->vChrDrop;\n\n    srcStride[2]<<= c->vChrDrop;\n\n\n\n    DEBUG_BUFFERS(\"swScale() %p[%d] %p[%d] %p[%d] %p[%d] -> %p[%d] %p[%d] %p[%d] %p[%d]\\n\",\n\n                  src[0], srcStride[0], src[1], srcStride[1], src[2], srcStride[2], src[3], srcStride[3],\n\n                  dst[0], dstStride[0], dst[1], dstStride[1], dst[2], dstStride[2], dst[3], dstStride[3]);\n\n    DEBUG_BUFFERS(\"srcSliceY: %d srcSliceH: %d dstY: %d dstH: %d\\n\",\n\n                   srcSliceY,    srcSliceH,    dstY,    dstH);\n\n    DEBUG_BUFFERS(\"vLumFilterSize: %d vLumBufSize: %d vChrFilterSize: %d vChrBufSize: %d\\n\",\n\n                   vLumFilterSize,    vLumBufSize,    vChrFilterSize,    vChrBufSize);\n\n\n\n    if (dstStride[0]%8 !=0 || dstStride[1]%8 !=0 || dstStride[2]%8 !=0 || dstStride[3]%8 != 0) {\n\n        static int warnedAlready=0; //FIXME move this into the context perhaps\n\n        if (flags & SWS_PRINT_INFO && !warnedAlready) {\n\n            av_log(c, AV_LOG_WARNING, \"Warning: dstStride is not aligned!\\n\"\n\n                   \"         ->cannot do aligned memory accesses anymore\\n\");\n\n            warnedAlready=1;\n\n        }\n\n    }\n\n\n\n    /* Note the user might start scaling the picture in the middle so this\n\n       will not get executed. This is not really intended but works\n\n       currently, so people might do it. */\n\n    if (srcSliceY ==0) {\n\n        lumBufIndex=0;\n\n        chrBufIndex=0;\n\n        dstY=0;\n\n        lastInLumBuf= -1;\n\n        lastInChrBuf= -1;\n\n    }\n\n\n\n    lastDstY= dstY;\n\n\n\n    for (;dstY < dstH; dstY++) {\n\n        unsigned char *dest =dst[0]+dstStride[0]*dstY;\n\n        const int chrDstY= dstY>>c->chrDstVSubSample;\n\n        unsigned char *uDest=dst[1]+dstStride[1]*chrDstY;\n\n        unsigned char *vDest=dst[2]+dstStride[2]*chrDstY;\n\n        unsigned char *aDest=(CONFIG_SWSCALE_ALPHA && alpPixBuf) ? dst[3]+dstStride[3]*dstY : NULL;\n\n\n\n        const int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n        const int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n        int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n        int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n        int enough_lines;\n\n\n\n        //handle holes (FAST_BILINEAR & weird filters)\n\n        if (firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n        if (firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n        assert(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1);\n\n        assert(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1);\n\n\n\n        // Do we have enough lines in this slice to output the dstY line\n\n        enough_lines = lastLumSrcY < srcSliceY + srcSliceH && lastChrSrcY < -((-srcSliceY - srcSliceH)>>c->chrSrcVSubSample);\n\n        if (!enough_lines) {\n\n            lastLumSrcY = srcSliceY + srcSliceH - 1;\n\n            lastChrSrcY = chrSrcSliceY + chrSrcSliceH - 1;\n\n        }\n\n\n\n        DEBUG_BUFFERS(\"dstY: %d\\n\", dstY);\n\n        DEBUG_BUFFERS(\"\\tfirstLumSrcY: %d lastLumSrcY: %d lastInLumBuf: %d\\n\",\n\n                         firstLumSrcY,    lastLumSrcY,    lastInLumBuf);\n\n        DEBUG_BUFFERS(\"\\tfirstChrSrcY: %d lastChrSrcY: %d lastInChrBuf: %d\\n\",\n\n                         firstChrSrcY,    lastChrSrcY,    lastInChrBuf);\n\n\n\n        //Do horizontal scaling\n\n        while(lastInLumBuf < lastLumSrcY) {\n\n            uint8_t *src1= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n            uint8_t *src2= src[3]+(lastInLumBuf + 1 - srcSliceY)*srcStride[3];\n\n            lumBufIndex++;\n\n            DEBUG_BUFFERS(\"\\t\\tlumBufIndex %d: lastInLumBuf: %d\\n\",\n\n                               lumBufIndex,    lastInLumBuf);\n\n            assert(lumBufIndex < 2*vLumBufSize);\n\n            assert(lastInLumBuf + 1 - srcSliceY < srcSliceH);\n\n            assert(lastInLumBuf + 1 - srcSliceY >= 0);\n\n            RENAME(hyscale)(c, lumPixBuf[ lumBufIndex ], dstW, src1, srcW, lumXInc,\n\n                            flags, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                            c->srcFormat, formatConvBuffer,\n\n                            pal, 0);\n\n            if (CONFIG_SWSCALE_ALPHA && alpPixBuf)\n\n                RENAME(hyscale)(c, alpPixBuf[ lumBufIndex ], dstW, src2, srcW, lumXInc,\n\n                                flags, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n                                c->srcFormat, formatConvBuffer,\n\n                                pal, 1);\n\n            lastInLumBuf++;\n\n        }\n\n        while(lastInChrBuf < lastChrSrcY) {\n\n            uint8_t *src1= src[1]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[1];\n\n            uint8_t *src2= src[2]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[2];\n\n            chrBufIndex++;\n\n            DEBUG_BUFFERS(\"\\t\\tchrBufIndex %d: lastInChrBuf: %d\\n\",\n\n                               chrBufIndex,    lastInChrBuf);\n\n            assert(chrBufIndex < 2*vChrBufSize);\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY < (chrSrcSliceH));\n\n            assert(lastInChrBuf + 1 - chrSrcSliceY >= 0);\n\n            //FIXME replace parameters through context struct (some at least)\n\n\n\n            if (!(isGray(srcFormat) || isGray(dstFormat)))\n\n                RENAME(hcscale)(c, chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, chrSrcW, chrXInc,\n\n                                flags, hChrFilter, hChrFilterPos, hChrFilterSize,\n\n                                c->srcFormat, formatConvBuffer,\n\n                                pal);\n\n            lastInChrBuf++;\n\n        }\n\n        //wrap buf index around to stay inside the ring buffer\n\n        if (lumBufIndex >= vLumBufSize) lumBufIndex-= vLumBufSize;\n\n        if (chrBufIndex >= vChrBufSize) chrBufIndex-= vChrBufSize;\n\n        if (!enough_lines)\n\n            break; //we can't output a dstY line so let's try with the next slice\n\n\n\n#if COMPILE_TEMPLATE_MMX\n\n        c->blueDither= ff_dither8[dstY&1];\n\n        if (c->dstFormat == PIX_FMT_RGB555 || c->dstFormat == PIX_FMT_BGR555)\n\n            c->greenDither= ff_dither8[dstY&1];\n\n        else\n\n            c->greenDither= ff_dither4[dstY&1];\n\n        c->redDither= ff_dither8[(dstY+1)&1];\n\n#endif\n\n        if (dstY < dstH-2) {\n\n            const int16_t **lumSrcPtr= (const int16_t **) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n            const int16_t **chrSrcPtr= (const int16_t **) chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n\n#if COMPILE_TEMPLATE_MMX\n\n            int i;\n\n            if (flags & SWS_ACCURATE_RND) {\n\n                int s= APCK_SIZE / 8;\n\n                for (i=0; i<vLumFilterSize; i+=2) {\n\n                    *(void**)&lumMmxFilter[s*i              ]= lumSrcPtr[i  ];\n\n                    *(void**)&lumMmxFilter[s*i+APCK_PTR2/4  ]= lumSrcPtr[i+(vLumFilterSize>1)];\n\n                              lumMmxFilter[s*i+APCK_COEF/4  ]=\n\n                              lumMmxFilter[s*i+APCK_COEF/4+1]= vLumFilter[dstY*vLumFilterSize + i    ]\n\n                        + (vLumFilterSize>1 ? vLumFilter[dstY*vLumFilterSize + i + 1]<<16 : 0);\n\n                    if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n\n                        *(void**)&alpMmxFilter[s*i              ]= alpSrcPtr[i  ];\n\n                        *(void**)&alpMmxFilter[s*i+APCK_PTR2/4  ]= alpSrcPtr[i+(vLumFilterSize>1)];\n\n                                  alpMmxFilter[s*i+APCK_COEF/4  ]=\n\n                                  alpMmxFilter[s*i+APCK_COEF/4+1]= lumMmxFilter[s*i+APCK_COEF/4  ];\n\n                    }\n\n                }\n\n                for (i=0; i<vChrFilterSize; i+=2) {\n\n                    *(void**)&chrMmxFilter[s*i              ]= chrSrcPtr[i  ];\n\n                    *(void**)&chrMmxFilter[s*i+APCK_PTR2/4  ]= chrSrcPtr[i+(vChrFilterSize>1)];\n\n                              chrMmxFilter[s*i+APCK_COEF/4  ]=\n\n                              chrMmxFilter[s*i+APCK_COEF/4+1]= vChrFilter[chrDstY*vChrFilterSize + i    ]\n\n                        + (vChrFilterSize>1 ? vChrFilter[chrDstY*vChrFilterSize + i + 1]<<16 : 0);\n\n                }\n\n            } else {\n\n                for (i=0; i<vLumFilterSize; i++) {\n\n                    lumMmxFilter[4*i+0]= (int32_t)lumSrcPtr[i];\n\n                    lumMmxFilter[4*i+1]= (uint64_t)lumSrcPtr[i] >> 32;\n\n                    lumMmxFilter[4*i+2]=\n\n                    lumMmxFilter[4*i+3]=\n\n                        ((uint16_t)vLumFilter[dstY*vLumFilterSize + i])*0x10001;\n\n                    if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n\n                        alpMmxFilter[4*i+0]= (int32_t)alpSrcPtr[i];\n\n                        alpMmxFilter[4*i+1]= (uint64_t)alpSrcPtr[i] >> 32;\n\n                        alpMmxFilter[4*i+2]=\n\n                        alpMmxFilter[4*i+3]= lumMmxFilter[4*i+2];\n\n                    }\n\n                }\n\n                for (i=0; i<vChrFilterSize; i++) {\n\n                    chrMmxFilter[4*i+0]= (int32_t)chrSrcPtr[i];\n\n                    chrMmxFilter[4*i+1]= (uint64_t)chrSrcPtr[i] >> 32;\n\n                    chrMmxFilter[4*i+2]=\n\n                    chrMmxFilter[4*i+3]=\n\n                        ((uint16_t)vChrFilter[chrDstY*vChrFilterSize + i])*0x10001;\n\n                }\n\n            }\n\n#endif\n\n            if (dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21) {\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if (dstY&chrSkipMask) uDest= NULL; //FIXME split functions in lumi / chromi\n\n                c->yuv2nv12X(c,\n\n                             vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                             vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                             dest, uDest, dstW, chrDstW, dstFormat);\n\n            } else if (isPlanarYUV(dstFormat) || dstFormat==PIX_FMT_GRAY8) { //YV12 like\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if ((dstY&chrSkipMask) || isGray(dstFormat)) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n                if (is16BPS(dstFormat)) {\n\n                    yuv2yuvX16inC(\n\n                                  vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                  vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                  alpSrcPtr, (uint16_t *) dest, (uint16_t *) uDest, (uint16_t *) vDest, (uint16_t *) aDest, dstW, chrDstW,\n\n                                  dstFormat);\n\n                } else if (vLumFilterSize == 1 && vChrFilterSize == 1) { // unscaled YV12\n\n                    int16_t *lumBuf = lumSrcPtr[0];\n\n                    int16_t *chrBuf= chrSrcPtr[0];\n\n                    int16_t *alpBuf= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? alpSrcPtr[0] : NULL;\n\n                    c->yuv2yuv1(c, lumBuf, chrBuf, alpBuf, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n                } else { //General YV12\n\n                    c->yuv2yuvX(c,\n\n                                vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                alpSrcPtr, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n                }\n\n            } else {\n\n                assert(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n                assert(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n                if (vLumFilterSize == 1 && vChrFilterSize == 2) { //unscaled RGB\n\n                    int chrAlpha= vChrFilter[2*dstY+1];\n\n                    if(flags & SWS_FULL_CHR_H_INT) {\n\n                        yuv2rgbXinC_full(c, //FIXME write a packed1_full function\n\n                                         vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                         vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                         alpSrcPtr, dest, dstW, dstY);\n\n                    } else {\n\n                        c->yuv2packed1(c, *lumSrcPtr, *chrSrcPtr, *(chrSrcPtr+1),\n\n                                       alpPixBuf ? *alpSrcPtr : NULL,\n\n                                       dest, dstW, chrAlpha, dstFormat, flags, dstY);\n\n                    }\n\n                } else if (vLumFilterSize == 2 && vChrFilterSize == 2) { //bilinear upscale RGB\n\n                    int lumAlpha= vLumFilter[2*dstY+1];\n\n                    int chrAlpha= vChrFilter[2*dstY+1];\n\n                    lumMmxFilter[2]=\n\n                    lumMmxFilter[3]= vLumFilter[2*dstY   ]*0x10001;\n\n                    chrMmxFilter[2]=\n\n                    chrMmxFilter[3]= vChrFilter[2*chrDstY]*0x10001;\n\n                    if(flags & SWS_FULL_CHR_H_INT) {\n\n                        yuv2rgbXinC_full(c, //FIXME write a packed2_full function\n\n                                         vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                         vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                         alpSrcPtr, dest, dstW, dstY);\n\n                    } else {\n\n                        c->yuv2packed2(c, *lumSrcPtr, *(lumSrcPtr+1), *chrSrcPtr, *(chrSrcPtr+1),\n\n                                       alpPixBuf ? *alpSrcPtr : NULL, alpPixBuf ? *(alpSrcPtr+1) : NULL,\n\n                                       dest, dstW, lumAlpha, chrAlpha, dstY);\n\n                    }\n\n                } else { //general RGB\n\n                    if(flags & SWS_FULL_CHR_H_INT) {\n\n                        yuv2rgbXinC_full(c,\n\n                                         vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                         vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                         alpSrcPtr, dest, dstW, dstY);\n\n                    } else {\n\n                        c->yuv2packedX(c,\n\n                                       vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                       vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                       alpSrcPtr, dest, dstW, dstY);\n\n                    }\n\n                }\n\n            }\n\n        } else { // hmm looks like we can't use MMX here without overwriting this array's tail\n\n            const int16_t **lumSrcPtr= (const int16_t **)lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n            const int16_t **chrSrcPtr= (const int16_t **)chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n            const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **)alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n\n            if (dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21) {\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if (dstY&chrSkipMask) uDest= NULL; //FIXME split functions in lumi / chromi\n\n                yuv2nv12XinC(\n\n                             vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                             vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                             dest, uDest, dstW, chrDstW, dstFormat);\n\n            } else if (isPlanarYUV(dstFormat) || dstFormat==PIX_FMT_GRAY8) { //YV12\n\n                const int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n                if ((dstY&chrSkipMask) || isGray(dstFormat)) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n                if (is16BPS(dstFormat)) {\n\n                    yuv2yuvX16inC(\n\n                                  vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                  vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                  alpSrcPtr, (uint16_t *) dest, (uint16_t *) uDest, (uint16_t *) vDest, (uint16_t *) aDest, dstW, chrDstW,\n\n                                  dstFormat);\n\n                } else {\n\n                    yuv2yuvXinC(\n\n                                vLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n                                vChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                alpSrcPtr, dest, uDest, vDest, aDest, dstW, chrDstW);\n\n                }\n\n            } else {\n\n                assert(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n                assert(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n                if(flags & SWS_FULL_CHR_H_INT) {\n\n                    yuv2rgbXinC_full(c,\n\n                                     vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                     vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                     alpSrcPtr, dest, dstW, dstY);\n\n                } else {\n\n                    yuv2packedXinC(c,\n\n                                   vLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n                                   vChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n                                   alpSrcPtr, dest, dstW, dstY);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if ((dstFormat == PIX_FMT_YUVA420P) && !alpPixBuf)\n\n        fillPlane(dst[3], dstStride[3], dstW, dstY-lastDstY, lastDstY, 255);\n\n\n\n#if COMPILE_TEMPLATE_MMX\n\n    if (flags & SWS_CPU_CAPS_MMX2 )  __asm__ volatile(\"sfence\":::\"memory\");\n\n    /* On K6 femms is faster than emms. On K7 femms is directly mapped to emms. */\n\n    if (flags & SWS_CPU_CAPS_3DNOW)  __asm__ volatile(\"femms\" :::\"memory\");\n\n    else                             __asm__ volatile(\"emms\"  :::\"memory\");\n\n#endif\n\n    /* store changed local vars back in the context */\n\n    c->dstY= dstY;\n\n    c->lumBufIndex= lumBufIndex;\n\n    c->chrBufIndex= chrBufIndex;\n\n    c->lastInLumBuf= lastInLumBuf;\n\n    c->lastInChrBuf= lastInChrBuf;\n\n\n\n    return dstY - lastDstY;\n\n}\n", "idx": 1836, "_split": "valid", "_hash": "d4e868b6c249f6f301f8b3f806241bc4"}
{"project": "FFmpeg", "commit_id": "7992814920d3a07a0bacfe45abd2183e81ef95f9", "target": 0, "func": "static char *value_string(char *buf, int buf_size, struct unit_value uv)\n\n{\n\n    double vald;\n\n    int show_float = 0;\n\n\n\n    if (uv.unit == unit_second_str) {\n\n        vald = uv.val.d;\n\n        show_float = 1;\n\n    } else {\n\n        vald = uv.val.i;\n\n    }\n\n\n\n    if (uv.unit == unit_second_str && use_value_sexagesimal_format) {\n\n        double secs;\n\n        int hours, mins;\n\n        secs  = vald;\n\n        mins  = (int)secs / 60;\n\n        secs  = secs - mins * 60;\n\n        hours = mins / 60;\n\n        mins %= 60;\n\n        snprintf(buf, buf_size, \"%d:%02d:%09.6f\", hours, mins, secs);\n\n    } else {\n\n        const char *prefix_string = \"\";\n\n        int l;\n\n\n\n        if (use_value_prefix && vald > 1) {\n\n            long long int index;\n\n\n\n            if (uv.unit == unit_byte_str && use_byte_value_binary_prefix) {\n\n                index = (long long int) (log2(vald)) / 10;\n\n                index = av_clip(index, 0, FF_ARRAY_ELEMS(binary_unit_prefixes) - 1);\n\n                vald /= exp2(index * 10);\n\n                prefix_string = binary_unit_prefixes[index];\n\n            } else {\n\n                index = (long long int) (log10(vald)) / 3;\n\n                index = av_clip(index, 0, FF_ARRAY_ELEMS(decimal_unit_prefixes) - 1);\n\n                vald /= pow(10, index * 3);\n\n                prefix_string = decimal_unit_prefixes[index];\n\n            }\n\n        }\n\n\n\n        if (show_float || (use_value_prefix && vald != (long long int)vald))\n\n            l = snprintf(buf, buf_size, \"%f\", vald);\n\n        else\n\n            l = snprintf(buf, buf_size, \"%lld\", (long long int)vald);\n\n        snprintf(buf+l, buf_size-l, \"%s%s%s\", *prefix_string || show_value_unit ? \" \" : \"\",\n\n                 prefix_string, show_value_unit ? uv.unit : \"\");\n\n    }\n\n\n\n    return buf;\n\n}\n", "idx": 1871, "_split": "valid", "_hash": "2611a34704e9e93abe1041970c79c42b"}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "static int mjpeg_decode_dht(MJpegDecodeContext *s)\n\n{\n\n    int len, index, i, class, n, v, code_max;\n\n    uint8_t bits_table[17];\n\n    uint8_t val_table[256];\n\n    \n\n    len = get_bits(&s->gb, 16) - 2;\n\n\n\n    while (len > 0) {\n\n        if (len < 17)\n\n            return -1;\n\n        class = get_bits(&s->gb, 4);\n\n        if (class >= 2)\n\n            return -1;\n\n        index = get_bits(&s->gb, 4);\n\n        if (index >= 4)\n\n            return -1;\n\n        n = 0;\n\n        for(i=1;i<=16;i++) {\n\n            bits_table[i] = get_bits(&s->gb, 8);\n\n            n += bits_table[i];\n\n        }\n\n        len -= 17;\n\n        if (len < n || n > 256)\n\n            return -1;\n\n\n\n        code_max = 0;\n\n        for(i=0;i<n;i++) {\n\n            v = get_bits(&s->gb, 8);\n\n            if (v > code_max)\n\n                code_max = v;\n\n            val_table[i] = v;\n\n        }\n\n        len -= n;\n\n\n\n        /* build VLC and flush previous vlc if present */\n\n        free_vlc(&s->vlcs[class][index]);\n\n        dprintf(\"class=%d index=%d nb_codes=%d\\n\",\n\n               class, index, code_max + 1);\n\n        if(build_vlc(&s->vlcs[class][index], bits_table, val_table, code_max + 1) < 0){\n\n            return -1;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 1872, "_split": "valid", "_hash": "cc45e68248785dbb2369e7db0652950b"}
{"project": "FFmpeg", "commit_id": "d74c471a39db2919a0e1db9666df725cbcb83d86", "target": 1, "func": "static int oma_read_header(AVFormatContext *s)\n\n{\n\n    int     ret, framesize, jsflag, samplerate;\n\n    uint32_t codec_params, channel_id;\n\n    int16_t eid;\n\n    uint8_t buf[EA3_HEADER_SIZE];\n\n    uint8_t *edata;\n\n    AVStream *st;\n\n    ID3v2ExtraMeta *extra_meta = NULL;\n\n    OMAContext *oc = s->priv_data;\n\n\n\n    ff_id3v2_read(s, ID3v2_EA3_MAGIC, &extra_meta, 0);\n\n    ret = avio_read(s->pb, buf, EA3_HEADER_SIZE);\n\n    if (ret < EA3_HEADER_SIZE)\n\n        return -1;\n\n\n\n    if (memcmp(buf, ((const uint8_t[]){'E', 'A', '3'}), 3) ||\n\n        buf[4] != 0 || buf[5] != EA3_HEADER_SIZE) {\n\n        av_log(s, AV_LOG_ERROR, \"Couldn't find the EA3 header !\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    oc->content_start = avio_tell(s->pb);\n\n\n\n    /* encrypted file */\n\n    eid = AV_RB16(&buf[6]);\n\n    if (eid != -1 && eid != -128 && decrypt_init(s, extra_meta, buf) < 0) {\n\n        ff_id3v2_free_extra_meta(&extra_meta);\n\n        return -1;\n\n    }\n\n\n\n    ff_id3v2_free_extra_meta(&extra_meta);\n\n\n\n    codec_params = AV_RB24(&buf[33]);\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->start_time = 0;\n\n    st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codecpar->codec_tag  = buf[32];\n\n    st->codecpar->codec_id   = ff_codec_get_id(ff_oma_codec_tags,\n\n                                               st->codecpar->codec_tag);\n\n\n\n    switch (buf[32]) {\n\n    case OMA_CODECID_ATRAC3:\n\n        samplerate = ff_oma_srate_tab[(codec_params >> 13) & 7] * 100;\n\n        if (!samplerate) {\n\n            av_log(s, AV_LOG_ERROR, \"Unsupported sample rate\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (samplerate != 44100)\n\n            avpriv_request_sample(s, \"Sample rate %d\", samplerate);\n\n\n\n        framesize = (codec_params & 0x3FF) * 8;\n\n\n\n        /* get stereo coding mode, 1 for joint-stereo */\n\n        jsflag = (codec_params >> 17) & 1;\n\n\n\n        st->codecpar->channels    = 2;\n\n        st->codecpar->channel_layout = AV_CH_LAYOUT_STEREO;\n\n        st->codecpar->sample_rate = samplerate;\n\n        st->codecpar->bit_rate    = st->codecpar->sample_rate * framesize * 8 / 1024;\n\n\n\n        /* fake the ATRAC3 extradata\n\n         * (wav format, makes stream copy to wav work) */\n\n        if (ff_alloc_extradata(st->codecpar, 14))\n\n            return AVERROR(ENOMEM);\n\n\n\n        edata = st->codecpar->extradata;\n\n        AV_WL16(&edata[0],  1);             // always 1\n\n        AV_WL32(&edata[2],  samplerate);    // samples rate\n\n        AV_WL16(&edata[6],  jsflag);        // coding mode\n\n        AV_WL16(&edata[8],  jsflag);        // coding mode\n\n        AV_WL16(&edata[10], 1);             // always 1\n\n        // AV_WL16(&edata[12], 0);          // always 0\n\n\n\n        avpriv_set_pts_info(st, 64, 1, st->codecpar->sample_rate);\n\n        break;\n\n    case OMA_CODECID_ATRAC3P:\n\n        channel_id = (codec_params >> 10) & 7;\n\n        if (!channel_id) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"Invalid ATRAC-X channel id: %\"PRIu32\"\\n\", channel_id);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        st->codecpar->channel_layout = ff_oma_chid_to_native_layout[channel_id - 1];\n\n        st->codecpar->channels       = ff_oma_chid_to_num_channels[channel_id - 1];\n\n        framesize = ((codec_params & 0x3FF) * 8) + 8;\n\n        samplerate = ff_oma_srate_tab[(codec_params >> 13) & 7] * 100;\n\n        if (!samplerate) {\n\n            av_log(s, AV_LOG_ERROR, \"Unsupported sample rate\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        st->codecpar->sample_rate = samplerate;\n\n        st->codecpar->bit_rate    = samplerate * framesize * 8 / 2048;\n\n        avpriv_set_pts_info(st, 64, 1, samplerate);\n\n        break;\n\n    case OMA_CODECID_MP3:\n\n        st->need_parsing = AVSTREAM_PARSE_FULL_RAW;\n\n        framesize = 1024;\n\n        break;\n\n    case OMA_CODECID_LPCM:\n\n        /* PCM 44.1 kHz 16 bit stereo big-endian */\n\n        st->codecpar->channels = 2;\n\n        st->codecpar->channel_layout = AV_CH_LAYOUT_STEREO;\n\n        st->codecpar->sample_rate = 44100;\n\n        framesize = 1024;\n\n        /* bit rate = sample rate x PCM block align (= 4) x 8 */\n\n        st->codecpar->bit_rate = st->codecpar->sample_rate * 32;\n\n        st->codecpar->bits_per_coded_sample =\n\n            av_get_bits_per_sample(st->codecpar->codec_id);\n\n        avpriv_set_pts_info(st, 64, 1, st->codecpar->sample_rate);\n\n        break;\n\n    default:\n\n        av_log(s, AV_LOG_ERROR, \"Unsupported codec %d!\\n\", buf[32]);\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    st->codecpar->block_align = framesize;\n\n\n\n    return 0;\n\n}\n", "idx": 1960, "_split": "valid", "_hash": "27c307f04363483e60993067bdd5548e"}
{"project": "FFmpeg", "commit_id": "79a60c8e779242b5ba4c531b2c706c871e8e6420", "target": 0, "func": "static int temporal_luma_motion_vector(HEVCContext *s, int x0, int y0,\n\n                                       int nPbW, int nPbH, int refIdxLx,\n\n                                       Mv *mvLXCol, int X)\n\n{\n\n    MvField *tab_mvf;\n\n    MvField temp_col;\n\n    int x, y, x_pu, y_pu;\n\n    int min_pu_width = s->sps->min_pu_width;\n\n    int availableFlagLXCol = 0;\n\n    int colPic;\n\n\n\n    HEVCFrame *ref = s->ref->collocated_ref;\n\n\n\n    if (!ref)\n\n        return 0;\n\n\n\n    tab_mvf = ref->tab_mvf;\n\n    colPic  = ref->poc;\n\n\n\n    //bottom right collocated motion vector\n\n    x = x0 + nPbW;\n\n    y = y0 + nPbH;\n\n\n\n    if (tab_mvf &&\n\n        (y0 >> s->sps->log2_ctb_size) == (y >> s->sps->log2_ctb_size) &&\n\n        y < s->sps->height &&\n\n        x < s->sps->width) {\n\n        x                 &= ~15;\n\n        y                 &= ~15;\n\n        ff_thread_await_progress(&ref->tf, y, 0);\n\n        x_pu               = x >> s->sps->log2_min_pu_size;\n\n        y_pu               = y >> s->sps->log2_min_pu_size;\n\n        temp_col           = TAB_MVF(x_pu, y_pu);\n\n        availableFlagLXCol = DERIVE_TEMPORAL_COLOCATED_MVS;\n\n    }\n\n\n\n    // derive center collocated motion vector\n\n    if (tab_mvf && !availableFlagLXCol) {\n\n        x                  = x0 + (nPbW >> 1);\n\n        y                  = y0 + (nPbH >> 1);\n\n        x                 &= ~15;\n\n        y                 &= ~15;\n\n        ff_thread_await_progress(&ref->tf, y, 0);\n\n        x_pu               = x >> s->sps->log2_min_pu_size;\n\n        y_pu               = y >> s->sps->log2_min_pu_size;\n\n        temp_col           = TAB_MVF(x_pu, y_pu);\n\n        availableFlagLXCol = DERIVE_TEMPORAL_COLOCATED_MVS;\n\n    }\n\n    return availableFlagLXCol;\n\n}\n", "idx": 1963, "_split": "valid", "_hash": "c21c48d87f68d1d2e1b7fa1605f75bb7"}
{"project": "FFmpeg", "commit_id": "7f46a641bf2540b8cf1293d5e50c0c0e34264254", "target": 1, "func": "static int decode_audio_specific_config(AACContext *ac,\n\n                                        AVCodecContext *avctx,\n\n                                        MPEG4AudioConfig *m4ac,\n\n                                        const uint8_t *data, int bit_size,\n\n                                        int sync_extension)\n\n{\n\n    GetBitContext gb;\n\n    int i, ret;\n\n\n\n    ff_dlog(avctx, \"audio specific config size %d\\n\", bit_size >> 3);\n\n    for (i = 0; i < bit_size >> 3; i++)\n\n        ff_dlog(avctx, \"%02x \", data[i]);\n\n    ff_dlog(avctx, \"\\n\");\n\n\n\n    if ((ret = init_get_bits(&gb, data, bit_size)) < 0)\n\n        return ret;\n\n\n\n    if ((i = avpriv_mpeg4audio_get_config(m4ac, data, bit_size,\n\n                                          sync_extension)) < 0)\n\n        return AVERROR_INVALIDDATA;\n\n    if (m4ac->sampling_index > 12) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"invalid sampling rate index %d\\n\",\n\n               m4ac->sampling_index);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (m4ac->object_type == AOT_ER_AAC_LD &&\n\n        (m4ac->sampling_index < 3 || m4ac->sampling_index > 7)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"invalid low delay sampling rate index %d\\n\",\n\n               m4ac->sampling_index);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    skip_bits_long(&gb, i);\n\n\n\n    switch (m4ac->object_type) {\n\n    case AOT_AAC_MAIN:\n\n    case AOT_AAC_LC:\n\n    case AOT_AAC_LTP:\n\n    case AOT_ER_AAC_LC:\n\n    case AOT_ER_AAC_LD:\n\n        if ((ret = decode_ga_specific_config(ac, avctx, &gb,\n\n                                            m4ac, m4ac->chan_config)) < 0)\n\n            return ret;\n\n        break;\n\n    case AOT_ER_AAC_ELD:\n\n        if ((ret = decode_eld_specific_config(ac, avctx, &gb,\n\n                                              m4ac, m4ac->chan_config)) < 0)\n\n            return ret;\n\n        break;\n\n    default:\n\n        avpriv_report_missing_feature(avctx,\n\n                                      \"Audio object type %s%d\",\n\n                                      m4ac->sbr == 1 ? \"SBR+\" : \"\",\n\n                                      m4ac->object_type);\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    ff_dlog(avctx,\n\n            \"AOT %d chan config %d sampling index %d (%d) SBR %d PS %d\\n\",\n\n            m4ac->object_type, m4ac->chan_config, m4ac->sampling_index,\n\n            m4ac->sample_rate, m4ac->sbr,\n\n            m4ac->ps);\n\n\n\n    return get_bits_count(&gb);\n\n}\n", "idx": 1973, "_split": "valid", "_hash": "b58c9830c7329b6b5a291dde8809bef7"}
{"project": "FFmpeg", "commit_id": "68f8d33becbd73b4d0aa277f472a6e8e72ea6849", "target": 0, "func": "static inline int get_symbol_inline(RangeCoder *c, uint8_t *state, int is_signed){\n\n    if(get_rac(c, state+0))\n\n        return 0;\n\n    else{\n\n        int i, e, a;\n\n        e= 0;\n\n        while(get_rac(c, state+1 + e) && e<9){ //1..10\n\n            e++;\n\n        }\n\n\n\n        a= 1;\n\n        for(i=e-1; i>=0; i--){\n\n            a += a + get_rac(c, state+22 + i); //22..31\n\n        }\n\n\n\n        e= -(is_signed && get_rac(c, state+11 + e)); //11..21\n\n        return (a^e)-e;\n\n    }\n\n}\n", "idx": 2017, "_split": "valid", "_hash": "0c96d2404bb61164ac1d37c7b054045e"}
{"project": "FFmpeg", "commit_id": "5d0450461ff729be5f531d333d29754155e406c5", "target": 0, "func": "static int idcin_read_packet(AVFormatContext *s,\n\n                             AVPacket *pkt)\n\n{\n\n    int ret;\n\n    unsigned int command;\n\n    unsigned int chunk_size;\n\n    IdcinDemuxContext *idcin = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int i;\n\n    int palette_scale;\n\n    unsigned char r, g, b;\n\n    unsigned char palette_buffer[768];\n\n    uint32_t palette[256];\n\n\n\n    if (s->pb->eof_reached)\n\n        return AVERROR(EIO);\n\n\n\n    if (idcin->next_chunk_is_video) {\n\n        command = avio_rl32(pb);\n\n        if (command == 2) {\n\n            return AVERROR(EIO);\n\n        } else if (command == 1) {\n\n            /* trigger a palette change */\n\n            if (avio_read(pb, palette_buffer, 768) != 768)\n\n                return AVERROR(EIO);\n\n            /* scale the palette as necessary */\n\n            palette_scale = 2;\n\n            for (i = 0; i < 768; i++)\n\n                if (palette_buffer[i] > 63) {\n\n                    palette_scale = 0;\n\n                    break;\n\n                }\n\n\n\n            for (i = 0; i < 256; i++) {\n\n                r = palette_buffer[i * 3    ] << palette_scale;\n\n                g = palette_buffer[i * 3 + 1] << palette_scale;\n\n                b = palette_buffer[i * 3 + 2] << palette_scale;\n\n                palette[i] = (r << 16) | (g << 8) | (b);\n\n            }\n\n        }\n\n\n\n        chunk_size = avio_rl32(pb);\n\n        if (chunk_size < 4 || chunk_size > INT_MAX - 4) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid chunk size: %u\\n\", chunk_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        /* skip the number of decoded bytes (always equal to width * height) */\n\n        avio_skip(pb, 4);\n\n        chunk_size -= 4;\n\n        ret= av_get_packet(pb, pkt, chunk_size);\n\n        if (ret < 0)\n\n            return ret;\n\n        if (command == 1) {\n\n            uint8_t *pal;\n\n\n\n            pal = av_packet_new_side_data(pkt, AV_PKT_DATA_PALETTE,\n\n                                          AVPALETTE_SIZE);\n\n            if (ret < 0)\n\n                return ret;\n\n            memcpy(pal, palette, AVPALETTE_SIZE);\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n        }\n\n        pkt->stream_index = idcin->video_stream_index;\n\n        pkt->duration     = 1;\n\n    } else {\n\n        /* send out the audio chunk */\n\n        if (idcin->current_audio_chunk)\n\n            chunk_size = idcin->audio_chunk_size2;\n\n        else\n\n            chunk_size = idcin->audio_chunk_size1;\n\n        ret= av_get_packet(pb, pkt, chunk_size);\n\n        if (ret < 0)\n\n            return ret;\n\n        pkt->stream_index = idcin->audio_stream_index;\n\n        pkt->duration     = chunk_size / idcin->block_align;\n\n\n\n        idcin->current_audio_chunk ^= 1;\n\n    }\n\n\n\n    if (idcin->audio_present)\n\n        idcin->next_chunk_is_video ^= 1;\n\n\n\n    return ret;\n\n}\n", "idx": 2082, "_split": "valid", "_hash": "6397c0d3ac5f5fe997507fe26eb60480"}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "void avcodec_register_all(void)\n\n{\n\n    static int initialized;\n\n\n\n    if (initialized)\n\n        return;\n\n    initialized = 1;\n\n\n\n    /* hardware accelerators */\n\n    REGISTER_HWACCEL(H263_VAAPI,        h263_vaapi);\n\n    REGISTER_HWACCEL(H264_D3D11VA,      h264_d3d11va);\n\n    REGISTER_HWACCEL(H264_DXVA2,        h264_dxva2);\n\n    REGISTER_HWACCEL(H264_MMAL,         h264_mmal);\n\n    REGISTER_HWACCEL(H264_QSV,          h264_qsv);\n\n    REGISTER_HWACCEL(H264_VAAPI,        h264_vaapi);\n\n    REGISTER_HWACCEL(H264_VDA,          h264_vda);\n\n    REGISTER_HWACCEL(H264_VDA_OLD,      h264_vda_old);\n\n    REGISTER_HWACCEL(H264_VDPAU,        h264_vdpau);\n\n    REGISTER_HWACCEL(HEVC_D3D11VA,      hevc_d3d11va);\n\n    REGISTER_HWACCEL(HEVC_DXVA2,        hevc_dxva2);\n\n    REGISTER_HWACCEL(HEVC_QSV,          hevc_qsv);\n\n    REGISTER_HWACCEL(HEVC_VAAPI,        hevc_vaapi);\n\n    REGISTER_HWACCEL(HEVC_VDPAU,        hevc_vdpau);\n\n    REGISTER_HWACCEL(MPEG1_VDPAU,       mpeg1_vdpau);\n\n    REGISTER_HWACCEL(MPEG2_D3D11VA,     mpeg2_d3d11va);\n\n    REGISTER_HWACCEL(MPEG2_DXVA2,       mpeg2_dxva2);\n\n    REGISTER_HWACCEL(MPEG2_MMAL,        mpeg2_mmal);\n\n    REGISTER_HWACCEL(MPEG2_QSV,         mpeg2_qsv);\n\n    REGISTER_HWACCEL(MPEG2_VAAPI,       mpeg2_vaapi);\n\n    REGISTER_HWACCEL(MPEG2_VDPAU,       mpeg2_vdpau);\n\n    REGISTER_HWACCEL(MPEG4_VAAPI,       mpeg4_vaapi);\n\n    REGISTER_HWACCEL(MPEG4_VDPAU,       mpeg4_vdpau);\n\n    REGISTER_HWACCEL(VC1_D3D11VA,       vc1_d3d11va);\n\n    REGISTER_HWACCEL(VC1_DXVA2,         vc1_dxva2);\n\n    REGISTER_HWACCEL(VC1_QSV,           vc1_qsv);\n\n    REGISTER_HWACCEL(VC1_VAAPI,         vc1_vaapi);\n\n    REGISTER_HWACCEL(VC1_VDPAU,         vc1_vdpau);\n\n    REGISTER_HWACCEL(VC1_MMAL,          vc1_mmal);\n\n    REGISTER_HWACCEL(VP8_QSV,           vp8_qsv);\n\n    REGISTER_HWACCEL(VP8_VAAPI,         vp8_vaapi);\n\n    REGISTER_HWACCEL(WMV3_D3D11VA,      wmv3_d3d11va);\n\n    REGISTER_HWACCEL(WMV3_DXVA2,        wmv3_dxva2);\n\n    REGISTER_HWACCEL(WMV3_VAAPI,        wmv3_vaapi);\n\n    REGISTER_HWACCEL(WMV3_VDPAU,        wmv3_vdpau);\n\n\n\n    /* video codecs */\n\n    REGISTER_ENCODER(A64MULTI,          a64multi);\n\n    REGISTER_ENCODER(A64MULTI5,         a64multi5);\n\n    REGISTER_DECODER(AASC,              aasc);\n\n    REGISTER_DECODER(AIC,               aic);\n\n    REGISTER_ENCDEC (ALIAS_PIX,         alias_pix);\n\n    REGISTER_DECODER(AMV,               amv);\n\n    REGISTER_DECODER(ANM,               anm);\n\n    REGISTER_DECODER(ANSI,              ansi);\n\n    REGISTER_ENCDEC (ASV1,              asv1);\n\n    REGISTER_ENCDEC (ASV2,              asv2);\n\n    REGISTER_DECODER(AURA,              aura);\n\n    REGISTER_DECODER(AURA2,             aura2);\n\n    REGISTER_DECODER(AVS,               avs);\n\n    REGISTER_DECODER(BETHSOFTVID,       bethsoftvid);\n\n    REGISTER_DECODER(BFI,               bfi);\n\n    REGISTER_DECODER(BINK,              bink);\n\n    REGISTER_ENCDEC (BMP,               bmp);\n\n    REGISTER_DECODER(BMV_VIDEO,         bmv_video);\n\n    REGISTER_DECODER(BRENDER_PIX,       brender_pix);\n\n    REGISTER_DECODER(C93,               c93);\n\n    REGISTER_DECODER(CAVS,              cavs);\n\n    REGISTER_DECODER(CDGRAPHICS,        cdgraphics);\n\n    REGISTER_DECODER(CDXL,              cdxl);\n\n    REGISTER_DECODER(CFHD,              cfhd);\n\n    REGISTER_DECODER(CINEPAK,           cinepak);\n\n    REGISTER_ENCDEC (CLJR,              cljr);\n\n    REGISTER_DECODER(CLLC,              cllc);\n\n    REGISTER_ENCDEC (COMFORTNOISE,      comfortnoise);\n\n    REGISTER_DECODER(CSCD,              cscd);\n\n    REGISTER_DECODER(CYUV,              cyuv);\n\n    REGISTER_DECODER(DDS,               dds);\n\n    REGISTER_DECODER(DFA,               dfa);\n\n    REGISTER_ENCDEC (DNXHD,             dnxhd);\n\n    REGISTER_ENCDEC (DPX,               dpx);\n\n    REGISTER_DECODER(DSICINVIDEO,       dsicinvideo);\n\n    REGISTER_ENCDEC (DVVIDEO,           dvvideo);\n\n    REGISTER_DECODER(DXA,               dxa);\n\n    REGISTER_DECODER(DXTORY,            dxtory);\n\n    REGISTER_DECODER(DXV,               dxv);\n\n    REGISTER_DECODER(EACMV,             eacmv);\n\n    REGISTER_DECODER(EAMAD,             eamad);\n\n    REGISTER_DECODER(EATGQ,             eatgq);\n\n    REGISTER_DECODER(EATGV,             eatgv);\n\n    REGISTER_DECODER(EATQI,             eatqi);\n\n    REGISTER_DECODER(EIGHTBPS,          eightbps);\n\n    REGISTER_DECODER(EIGHTSVX_EXP,      eightsvx_exp);\n\n    REGISTER_DECODER(EIGHTSVX_FIB,      eightsvx_fib);\n\n    REGISTER_DECODER(ESCAPE124,         escape124);\n\n    REGISTER_DECODER(ESCAPE130,         escape130);\n\n    REGISTER_DECODER(EXR,               exr);\n\n    REGISTER_ENCDEC (FFV1,              ffv1);\n\n    REGISTER_ENCDEC (FFVHUFF,           ffvhuff);\n\n    REGISTER_DECODER(FIC,               fic);\n\n    REGISTER_ENCDEC (FLASHSV,           flashsv);\n\n    REGISTER_DECODER(FLASHSV2,          flashsv2);\n\n    REGISTER_DECODER(FLIC,              flic);\n\n    REGISTER_ENCDEC (FLV,               flv);\n\n    REGISTER_DECODER(FOURXM,            fourxm);\n\n    REGISTER_DECODER(FRAPS,             fraps);\n\n    REGISTER_DECODER(FRWU,              frwu);\n\n    REGISTER_DECODER(G2M,               g2m);\n\n    REGISTER_ENCDEC (GIF,               gif);\n\n    REGISTER_ENCDEC (H261,              h261);\n\n    REGISTER_ENCDEC (H263,              h263);\n\n    REGISTER_DECODER(H263I,             h263i);\n\n    REGISTER_ENCODER(H263P,             h263p);\n\n    REGISTER_DECODER(H264,              h264);\n\n    REGISTER_DECODER(H264_MMAL,         h264_mmal);\n\n    REGISTER_DECODER(H264_QSV,          h264_qsv);\n\n    REGISTER_ENCDEC (HAP,               hap);\n\n    REGISTER_DECODER(HEVC,              hevc);\n\n    REGISTER_DECODER(HEVC_QSV,          hevc_qsv);\n\n    REGISTER_DECODER(HNM4_VIDEO,        hnm4_video);\n\n    REGISTER_DECODER(HQ_HQA,            hq_hqa);\n\n    REGISTER_DECODER(HQX,               hqx);\n\n    REGISTER_ENCDEC (HUFFYUV,           huffyuv);\n\n    REGISTER_DECODER(IDCIN,             idcin);\n\n    REGISTER_DECODER(IFF_BYTERUN1,      iff_byterun1);\n\n    REGISTER_DECODER(IFF_ILBM,          iff_ilbm);\n\n    REGISTER_DECODER(INDEO2,            indeo2);\n\n    REGISTER_DECODER(INDEO3,            indeo3);\n\n    REGISTER_DECODER(INDEO4,            indeo4);\n\n    REGISTER_DECODER(INDEO5,            indeo5);\n\n    REGISTER_DECODER(INTERPLAY_VIDEO,   interplay_video);\n\n    REGISTER_DECODER(JPEG2000,          jpeg2000);\n\n    REGISTER_ENCDEC (JPEGLS,            jpegls);\n\n    REGISTER_DECODER(JV,                jv);\n\n    REGISTER_DECODER(KGV1,              kgv1);\n\n    REGISTER_DECODER(KMVC,              kmvc);\n\n    REGISTER_DECODER(LAGARITH,          lagarith);\n\n    REGISTER_ENCODER(LJPEG,             ljpeg);\n\n    REGISTER_DECODER(LOCO,              loco);\n\n    REGISTER_DECODER(MAGICYUV,          magicyuv);\n\n    REGISTER_DECODER(MDEC,              mdec);\n\n    REGISTER_DECODER(MIMIC,             mimic);\n\n    REGISTER_ENCDEC (MJPEG,             mjpeg);\n\n    REGISTER_DECODER(MJPEGB,            mjpegb);\n\n    REGISTER_DECODER(MMVIDEO,           mmvideo);\n\n    REGISTER_DECODER(MOTIONPIXELS,      motionpixels);\n\n#if FF_API_XVMC\n\n    REGISTER_DECODER(MPEG_XVMC,         mpeg_xvmc);\n\n#endif /* FF_API_XVMC */\n\n    REGISTER_ENCDEC (MPEG1VIDEO,        mpeg1video);\n\n    REGISTER_ENCDEC (MPEG2VIDEO,        mpeg2video);\n\n    REGISTER_DECODER(MPEG2_MMAL,        mpeg2_mmal);\n\n    REGISTER_DECODER(MPEG2_QSV,         mpeg2_qsv);\n\n    REGISTER_ENCDEC (MPEG4,             mpeg4);\n\n    REGISTER_DECODER(MSA1,              msa1);\n\n    REGISTER_DECODER(MSMPEG4V1,         msmpeg4v1);\n\n    REGISTER_ENCDEC (MSMPEG4V2,         msmpeg4v2);\n\n    REGISTER_ENCDEC (MSMPEG4V3,         msmpeg4v3);\n\n    REGISTER_DECODER(MSRLE,             msrle);\n\n    REGISTER_DECODER(MSS1,              mss1);\n\n    REGISTER_DECODER(MSS2,              mss2);\n\n    REGISTER_DECODER(MSVIDEO1,          msvideo1);\n\n    REGISTER_DECODER(MSZH,              mszh);\n\n    REGISTER_DECODER(MTS2,              mts2);\n\n    REGISTER_DECODER(MVC1,              mvc1);\n\n    REGISTER_DECODER(MVC2,              mvc2);\n\n    REGISTER_DECODER(MXPEG,             mxpeg);\n\n    REGISTER_DECODER(NUV,               nuv);\n\n    REGISTER_DECODER(PAF_VIDEO,         paf_video);\n\n    REGISTER_ENCDEC (PAM,               pam);\n\n    REGISTER_ENCDEC (PBM,               pbm);\n\n    REGISTER_ENCDEC (PCX,               pcx);\n\n    REGISTER_ENCDEC (PGM,               pgm);\n\n    REGISTER_ENCDEC (PGMYUV,            pgmyuv);\n\n    REGISTER_DECODER(PICTOR,            pictor);\n\n    REGISTER_DECODER(PIXLET,            pixlet);\n\n    REGISTER_ENCDEC (PNG,               png);\n\n    REGISTER_ENCDEC (PPM,               ppm);\n\n    REGISTER_ENCDEC (PRORES,            prores);\n\n    REGISTER_DECODER(PTX,               ptx);\n\n    REGISTER_DECODER(QDRAW,             qdraw);\n\n    REGISTER_DECODER(QPEG,              qpeg);\n\n    REGISTER_ENCDEC (QTRLE,             qtrle);\n\n    REGISTER_DECODER(R10K,              r10k);\n\n    REGISTER_DECODER(R210,              r210);\n\n    REGISTER_ENCDEC (RAWVIDEO,          rawvideo);\n\n    REGISTER_DECODER(RL2,               rl2);\n\n    REGISTER_ENCDEC (ROQ,               roq);\n\n    REGISTER_DECODER(RPZA,              rpza);\n\n    REGISTER_DECODER(RSCC,              rscc);\n\n    REGISTER_ENCDEC (RV10,              rv10);\n\n    REGISTER_ENCDEC (RV20,              rv20);\n\n    REGISTER_DECODER(RV30,              rv30);\n\n    REGISTER_DECODER(RV40,              rv40);\n\n    REGISTER_DECODER(S302M,             s302m);\n\n    REGISTER_DECODER(SANM,              sanm);\n\n    REGISTER_DECODER(SCREENPRESSO,      screenpresso);\n\n    REGISTER_ENCDEC (SGI,               sgi);\n\n    REGISTER_DECODER(SGIRLE,            sgirle);\n\n    REGISTER_DECODER(SMACKER,           smacker);\n\n    REGISTER_DECODER(SMC,               smc);\n\n    REGISTER_DECODER(SP5X,              sp5x);\n\n    REGISTER_ENCDEC (SUNRAST,           sunrast);\n\n    REGISTER_ENCDEC (SVQ1,              svq1);\n\n    REGISTER_DECODER(SVQ3,              svq3);\n\n    REGISTER_ENCDEC (TARGA,             targa);\n\n    REGISTER_DECODER(TDSC,              tdsc);\n\n    REGISTER_DECODER(THEORA,            theora);\n\n    REGISTER_DECODER(THP,               thp);\n\n    REGISTER_DECODER(TIERTEXSEQVIDEO,   tiertexseqvideo);\n\n    REGISTER_ENCDEC (TIFF,              tiff);\n\n    REGISTER_DECODER(TMV,               tmv);\n\n    REGISTER_DECODER(TRUEMOTION1,       truemotion1);\n\n    REGISTER_DECODER(TRUEMOTION2,       truemotion2);\n\n    REGISTER_DECODER(TRUEMOTION2RT,     truemotion2rt);\n\n    REGISTER_DECODER(TSCC,              tscc);\n\n    REGISTER_DECODER(TSCC2,             tscc2);\n\n    REGISTER_DECODER(TXD,               txd);\n\n    REGISTER_DECODER(ULTI,              ulti);\n\n    REGISTER_ENCDEC (UTVIDEO,           utvideo);\n\n    REGISTER_ENCDEC (V210,              v210);\n\n    REGISTER_DECODER(V210X,             v210x);\n\n    REGISTER_ENCDEC (V410,              v410);\n\n    REGISTER_DECODER(VB,                vb);\n\n    REGISTER_DECODER(VBLE,              vble);\n\n    REGISTER_DECODER(VC1,               vc1);\n\n    REGISTER_DECODER(VC1IMAGE,          vc1image);\n\n    REGISTER_DECODER(VC1_MMAL,          vc1_mmal);\n\n    REGISTER_DECODER(VC1_QSV,           vc1_qsv);\n\n    REGISTER_DECODER(VCR1,              vcr1);\n\n    REGISTER_DECODER(VMDVIDEO,          vmdvideo);\n\n    REGISTER_DECODER(VMNC,              vmnc);\n\n    REGISTER_DECODER(VP3,               vp3);\n\n    REGISTER_DECODER(VP5,               vp5);\n\n    REGISTER_DECODER(VP6,               vp6);\n\n    REGISTER_DECODER(VP6A,              vp6a);\n\n    REGISTER_DECODER(VP6F,              vp6f);\n\n    REGISTER_DECODER(VP7,               vp7);\n\n    REGISTER_DECODER(VP8,               vp8);\n\n    REGISTER_DECODER(VP8_QSV,           vp8_qsv);\n\n    REGISTER_DECODER(VP9,               vp9);\n\n    REGISTER_DECODER(VQA,               vqa);\n\n    REGISTER_DECODER(WEBP,              webp);\n\n    REGISTER_ENCODER(WRAPPED_AVFRAME,   wrapped_avframe);\n\n    REGISTER_ENCDEC (WMV1,              wmv1);\n\n    REGISTER_ENCDEC (WMV2,              wmv2);\n\n    REGISTER_DECODER(WMV3,              wmv3);\n\n    REGISTER_DECODER(WMV3IMAGE,         wmv3image);\n\n    REGISTER_DECODER(WNV1,              wnv1);\n\n    REGISTER_DECODER(XAN_WC3,           xan_wc3);\n\n    REGISTER_DECODER(XAN_WC4,           xan_wc4);\n\n    REGISTER_ENCDEC (XBM,               xbm);\n\n    REGISTER_DECODER(XL,                xl);\n\n    REGISTER_ENCDEC (XWD,               xwd);\n\n    REGISTER_DECODER(YOP,               yop);\n\n    REGISTER_DECODER(ZEROCODEC,         zerocodec);\n\n    REGISTER_ENCDEC (ZLIB,              zlib);\n\n    REGISTER_ENCDEC (ZMBV,              zmbv);\n\n\n\n    /* audio codecs */\n\n    REGISTER_ENCDEC (AAC,               aac);\n\n    REGISTER_DECODER(AAC_LATM,          aac_latm);\n\n    REGISTER_ENCDEC (AC3,               ac3);\n\n    REGISTER_ENCODER(AC3_FIXED,         ac3_fixed);\n\n    REGISTER_ENCDEC (ALAC,              alac);\n\n    REGISTER_DECODER(ALS,               als);\n\n    REGISTER_DECODER(AMRNB,             amrnb);\n\n    REGISTER_DECODER(AMRWB,             amrwb);\n\n    REGISTER_DECODER(APE,               ape);\n\n    REGISTER_DECODER(ATRAC1,            atrac1);\n\n    REGISTER_DECODER(ATRAC3,            atrac3);\n\n    REGISTER_DECODER(ATRAC3P,           atrac3p);\n\n    REGISTER_DECODER(BINKAUDIO_DCT,     binkaudio_dct);\n\n    REGISTER_DECODER(BINKAUDIO_RDFT,    binkaudio_rdft);\n\n    REGISTER_DECODER(BMV_AUDIO,         bmv_audio);\n\n    REGISTER_DECODER(COOK,              cook);\n\n    REGISTER_DECODER(DCA,               dca);\n\n    REGISTER_DECODER(DSICINAUDIO,       dsicinaudio);\n\n    REGISTER_DECODER(DSS_SP,            dss_sp);\n\n    REGISTER_ENCDEC (EAC3,              eac3);\n\n    REGISTER_ENCDEC (FLAC,              flac);\n\n    REGISTER_ENCDEC (G723_1,            g723_1);\n\n    REGISTER_DECODER(GSM,               gsm);\n\n    REGISTER_DECODER(GSM_MS,            gsm_ms);\n\n    REGISTER_DECODER(IAC,               iac);\n\n    REGISTER_DECODER(IMC,               imc);\n\n    REGISTER_DECODER(MACE3,             mace3);\n\n    REGISTER_DECODER(MACE6,             mace6);\n\n    REGISTER_DECODER(METASOUND,         metasound);\n\n    REGISTER_DECODER(MLP,               mlp);\n\n    REGISTER_DECODER(MP1,               mp1);\n\n    REGISTER_DECODER(MP1FLOAT,          mp1float);\n\n    REGISTER_ENCDEC (MP2,               mp2);\n\n    REGISTER_DECODER(MP2FLOAT,          mp2float);\n\n    REGISTER_DECODER(MP3,               mp3);\n\n    REGISTER_DECODER(MP3FLOAT,          mp3float);\n\n    REGISTER_DECODER(MP3ADU,            mp3adu);\n\n    REGISTER_DECODER(MP3ADUFLOAT,       mp3adufloat);\n\n    REGISTER_DECODER(MP3ON4,            mp3on4);\n\n    REGISTER_DECODER(MP3ON4FLOAT,       mp3on4float);\n\n    REGISTER_DECODER(MPC7,              mpc7);\n\n    REGISTER_DECODER(MPC8,              mpc8);\n\n    REGISTER_ENCDEC (NELLYMOSER,        nellymoser);\n\n    REGISTER_DECODER(ON2AVC,            on2avc);\n\n    REGISTER_DECODER(OPUS,              opus);\n\n    REGISTER_DECODER(PAF_AUDIO,         paf_audio);\n\n    REGISTER_DECODER(QCELP,             qcelp);\n\n    REGISTER_DECODER(QDM2,              qdm2);\n\n    REGISTER_ENCDEC (RA_144,            ra_144);\n\n    REGISTER_DECODER(RA_288,            ra_288);\n\n    REGISTER_DECODER(RALF,              ralf);\n\n    REGISTER_DECODER(SHORTEN,           shorten);\n\n    REGISTER_DECODER(SIPR,              sipr);\n\n    REGISTER_DECODER(SMACKAUD,          smackaud);\n\n    REGISTER_DECODER(TAK,               tak);\n\n    REGISTER_DECODER(TRUEHD,            truehd);\n\n    REGISTER_DECODER(TRUESPEECH,        truespeech);\n\n    REGISTER_DECODER(TTA,               tta);\n\n    REGISTER_DECODER(TWINVQ,            twinvq);\n\n    REGISTER_DECODER(VMDAUDIO,          vmdaudio);\n\n    REGISTER_ENCDEC (VORBIS,            vorbis);\n\n    REGISTER_DECODER(WAVPACK,           wavpack);\n\n    REGISTER_DECODER(WMALOSSLESS,       wmalossless);\n\n    REGISTER_DECODER(WMAPRO,            wmapro);\n\n    REGISTER_ENCDEC (WMAV1,             wmav1);\n\n    REGISTER_ENCDEC (WMAV2,             wmav2);\n\n    REGISTER_DECODER(WMAVOICE,          wmavoice);\n\n    REGISTER_DECODER(WS_SND1,           ws_snd1);\n\n\n\n    /* PCM codecs */\n\n    REGISTER_ENCDEC (PCM_ALAW,          pcm_alaw);\n\n    REGISTER_DECODER(PCM_BLURAY,        pcm_bluray);\n\n    REGISTER_DECODER(PCM_DVD,           pcm_dvd);\n\n    REGISTER_ENCDEC (PCM_F32BE,         pcm_f32be);\n\n    REGISTER_ENCDEC (PCM_F32LE,         pcm_f32le);\n\n    REGISTER_ENCDEC (PCM_F64BE,         pcm_f64be);\n\n    REGISTER_ENCDEC (PCM_F64LE,         pcm_f64le);\n\n    REGISTER_DECODER(PCM_LXF,           pcm_lxf);\n\n    REGISTER_ENCDEC (PCM_MULAW,         pcm_mulaw);\n\n    REGISTER_ENCDEC (PCM_S8,            pcm_s8);\n\n    REGISTER_DECODER(PCM_S8_PLANAR,     pcm_s8_planar);\n\n    REGISTER_ENCDEC (PCM_S16BE,         pcm_s16be);\n\n    REGISTER_DECODER(PCM_S16BE_PLANAR,  pcm_s16be_planar);\n\n    REGISTER_ENCDEC (PCM_S16LE,         pcm_s16le);\n\n    REGISTER_DECODER(PCM_S16LE_PLANAR,  pcm_s16le_planar);\n\n    REGISTER_ENCDEC (PCM_S24BE,         pcm_s24be);\n\n    REGISTER_ENCDEC (PCM_S24DAUD,       pcm_s24daud);\n\n    REGISTER_ENCDEC (PCM_S24LE,         pcm_s24le);\n\n    REGISTER_DECODER(PCM_S24LE_PLANAR,  pcm_s24le_planar);\n\n    REGISTER_ENCDEC (PCM_S32BE,         pcm_s32be);\n\n    REGISTER_ENCDEC (PCM_S32LE,         pcm_s32le);\n\n    REGISTER_DECODER(PCM_S32LE_PLANAR,  pcm_s32le_planar);\n\n    REGISTER_ENCDEC (PCM_U8,            pcm_u8);\n\n    REGISTER_ENCDEC (PCM_U16BE,         pcm_u16be);\n\n    REGISTER_ENCDEC (PCM_U16LE,         pcm_u16le);\n\n    REGISTER_ENCDEC (PCM_U24BE,         pcm_u24be);\n\n    REGISTER_ENCDEC (PCM_U24LE,         pcm_u24le);\n\n    REGISTER_ENCDEC (PCM_U32BE,         pcm_u32be);\n\n    REGISTER_ENCDEC (PCM_U32LE,         pcm_u32le);\n\n    REGISTER_DECODER(PCM_ZORK ,         pcm_zork);\n\n\n\n    /* DPCM codecs */\n\n    REGISTER_DECODER(INTERPLAY_DPCM,    interplay_dpcm);\n\n    REGISTER_ENCDEC (ROQ_DPCM,          roq_dpcm);\n\n    REGISTER_DECODER(SOL_DPCM,          sol_dpcm);\n\n    REGISTER_DECODER(XAN_DPCM,          xan_dpcm);\n\n\n\n    /* ADPCM codecs */\n\n    REGISTER_DECODER(ADPCM_4XM,         adpcm_4xm);\n\n    REGISTER_ENCDEC (ADPCM_ADX,         adpcm_adx);\n\n    REGISTER_DECODER(ADPCM_CT,          adpcm_ct);\n\n    REGISTER_DECODER(ADPCM_EA,          adpcm_ea);\n\n    REGISTER_DECODER(ADPCM_EA_MAXIS_XA, adpcm_ea_maxis_xa);\n\n    REGISTER_DECODER(ADPCM_EA_R1,       adpcm_ea_r1);\n\n    REGISTER_DECODER(ADPCM_EA_R2,       adpcm_ea_r2);\n\n    REGISTER_DECODER(ADPCM_EA_R3,       adpcm_ea_r3);\n\n    REGISTER_DECODER(ADPCM_EA_XAS,      adpcm_ea_xas);\n\n    REGISTER_ENCDEC (ADPCM_G722,        adpcm_g722);\n\n    REGISTER_ENCDEC (ADPCM_G726,        adpcm_g726);\n\n    REGISTER_DECODER(ADPCM_IMA_AMV,     adpcm_ima_amv);\n\n    REGISTER_DECODER(ADPCM_IMA_APC,     adpcm_ima_apc);\n\n    REGISTER_DECODER(ADPCM_IMA_DK3,     adpcm_ima_dk3);\n\n    REGISTER_DECODER(ADPCM_IMA_DK4,     adpcm_ima_dk4);\n\n    REGISTER_DECODER(ADPCM_IMA_EA_EACS, adpcm_ima_ea_eacs);\n\n    REGISTER_DECODER(ADPCM_IMA_EA_SEAD, adpcm_ima_ea_sead);\n\n    REGISTER_DECODER(ADPCM_IMA_ISS,     adpcm_ima_iss);\n\n    REGISTER_ENCDEC (ADPCM_IMA_QT,      adpcm_ima_qt);\n\n    REGISTER_DECODER(ADPCM_IMA_SMJPEG,  adpcm_ima_smjpeg);\n\n    REGISTER_ENCDEC (ADPCM_IMA_WAV,     adpcm_ima_wav);\n\n    REGISTER_DECODER(ADPCM_IMA_WS,      adpcm_ima_ws);\n\n    REGISTER_ENCDEC (ADPCM_MS,          adpcm_ms);\n\n    REGISTER_DECODER(ADPCM_SBPRO_2,     adpcm_sbpro_2);\n\n    REGISTER_DECODER(ADPCM_SBPRO_3,     adpcm_sbpro_3);\n\n    REGISTER_DECODER(ADPCM_SBPRO_4,     adpcm_sbpro_4);\n\n    REGISTER_ENCDEC (ADPCM_SWF,         adpcm_swf);\n\n    REGISTER_DECODER(ADPCM_THP,         adpcm_thp);\n\n    REGISTER_DECODER(ADPCM_VIMA,        adpcm_vima);\n\n    REGISTER_DECODER(ADPCM_XA,          adpcm_xa);\n\n    REGISTER_ENCDEC (ADPCM_YAMAHA,      adpcm_yamaha);\n\n\n\n    /* subtitles */\n\n    REGISTER_ENCDEC (ASS,               ass);\n\n    REGISTER_ENCDEC (DVBSUB,            dvbsub);\n\n    REGISTER_ENCDEC (DVDSUB,            dvdsub);\n\n    REGISTER_DECODER(PGSSUB,            pgssub);\n\n    REGISTER_DECODER(SRT,               srt);\n\n    REGISTER_ENCDEC (XSUB,              xsub);\n\n\n\n    /* external libraries */\n\n    REGISTER_DECODER(LIBDCADEC,         libdcadec)\n\n    REGISTER_ENCODER(LIBFAAC,           libfaac);\n\n    REGISTER_ENCDEC (LIBFDK_AAC,        libfdk_aac);\n\n    REGISTER_ENCDEC (LIBGSM,            libgsm);\n\n    REGISTER_ENCDEC (LIBGSM_MS,         libgsm_ms);\n\n    REGISTER_ENCDEC (LIBILBC,           libilbc);\n\n    REGISTER_ENCODER(LIBMP3LAME,        libmp3lame);\n\n    REGISTER_ENCDEC (LIBOPENCORE_AMRNB, libopencore_amrnb);\n\n    REGISTER_DECODER(LIBOPENCORE_AMRWB, libopencore_amrwb);\n\n    REGISTER_ENCDEC (LIBOPENJPEG,       libopenjpeg);\n\n    REGISTER_ENCDEC (LIBOPUS,           libopus);\n\n    REGISTER_ENCDEC (LIBSCHROEDINGER,   libschroedinger);\n\n    REGISTER_ENCDEC (LIBSPEEX,          libspeex);\n\n    REGISTER_ENCODER(LIBTHEORA,         libtheora);\n\n    REGISTER_ENCODER(LIBTWOLAME,        libtwolame);\n\n    REGISTER_ENCODER(LIBVO_AACENC,      libvo_aacenc);\n\n    REGISTER_ENCODER(LIBVO_AMRWBENC,    libvo_amrwbenc);\n\n    REGISTER_ENCODER(LIBVORBIS,         libvorbis);\n\n    REGISTER_ENCDEC (LIBVPX_VP8,        libvpx_vp8);\n\n    REGISTER_ENCDEC (LIBVPX_VP9,        libvpx_vp9);\n\n    REGISTER_ENCODER(LIBWAVPACK,        libwavpack);\n\n    REGISTER_ENCODER(LIBWEBP,           libwebp);\n\n    REGISTER_ENCODER(LIBX262,           libx262);\n\n    REGISTER_ENCODER(LIBX264,           libx264);\n\n    REGISTER_ENCODER(LIBX265,           libx265);\n\n    REGISTER_ENCODER(LIBXAVS,           libxavs);\n\n    REGISTER_ENCODER(LIBXVID,           libxvid);\n\n\n\n    /* external libraries, that shouldn't be used by default if one of the\n\n     * above is available */\n\n    REGISTER_ENCDEC (LIBOPENH264,       libopenh264);\n\n    REGISTER_ENCODER(H264_NVENC,        h264_nvenc);\n\n    REGISTER_ENCODER(H264_OMX,          h264_omx);\n\n    REGISTER_ENCODER(H264_QSV,          h264_qsv);\n\n    REGISTER_ENCODER(H264_VAAPI,        h264_vaapi);\n\n    REGISTER_ENCODER(LIBKVAZAAR,        libkvazaar);\n\n    REGISTER_ENCODER(HEVC_NVENC,        hevc_nvenc);\n\n    REGISTER_ENCODER(HEVC_QSV,          hevc_qsv);\n\n    REGISTER_ENCODER(HEVC_VAAPI,        hevc_vaapi);\n\n    REGISTER_ENCODER(MJPEG_VAAPI,       mjpeg_vaapi);\n\n    REGISTER_ENCODER(MPEG2_QSV,         mpeg2_qsv);\n\n    REGISTER_ENCODER(MPEG2_VAAPI,       mpeg2_vaapi);\n\n    REGISTER_ENCODER(MPEG4_OMX,         mpeg4_omx);\n\n#if FF_API_NVENC_OLD_NAME\n\n    REGISTER_ENCODER(NVENC_H264,        nvenc_h264);\n\n    REGISTER_ENCODER(NVENC_HEVC,        nvenc_hevc);\n\n#endif\n\n    REGISTER_ENCODER(VP8_VAAPI,         vp8_vaapi);\n\n\n\n    /* parsers */\n\n    REGISTER_PARSER(AAC,                aac);\n\n    REGISTER_PARSER(AAC_LATM,           aac_latm);\n\n    REGISTER_PARSER(AC3,                ac3);\n\n    REGISTER_PARSER(ADX,                adx);\n\n    REGISTER_PARSER(BMP,                bmp);\n\n    REGISTER_PARSER(CAVSVIDEO,          cavsvideo);\n\n    REGISTER_PARSER(COOK,               cook);\n\n    REGISTER_PARSER(DCA,                dca);\n\n    REGISTER_PARSER(DIRAC,              dirac);\n\n    REGISTER_PARSER(DNXHD,              dnxhd);\n\n    REGISTER_PARSER(DPX,                dpx);\n\n    REGISTER_PARSER(DVBSUB,             dvbsub);\n\n    REGISTER_PARSER(DVDSUB,             dvdsub);\n\n    REGISTER_PARSER(FLAC,               flac);\n\n    REGISTER_PARSER(GSM,                gsm);\n\n    REGISTER_PARSER(H261,               h261);\n\n    REGISTER_PARSER(H263,               h263);\n\n    REGISTER_PARSER(H264,               h264);\n\n    REGISTER_PARSER(HEVC,               hevc);\n\n    REGISTER_PARSER(MJPEG,              mjpeg);\n\n    REGISTER_PARSER(MLP,                mlp);\n\n    REGISTER_PARSER(MPEG4VIDEO,         mpeg4video);\n\n    REGISTER_PARSER(MPEGAUDIO,          mpegaudio);\n\n    REGISTER_PARSER(MPEGVIDEO,          mpegvideo);\n\n    REGISTER_PARSER(OPUS,               opus);\n\n    REGISTER_PARSER(PNG,                png);\n\n    REGISTER_PARSER(PNM,                pnm);\n\n    REGISTER_PARSER(RV30,               rv30);\n\n    REGISTER_PARSER(RV40,               rv40);\n\n    REGISTER_PARSER(TAK,                tak);\n\n    REGISTER_PARSER(VC1,                vc1);\n\n    REGISTER_PARSER(VORBIS,             vorbis);\n\n    REGISTER_PARSER(VP3,                vp3);\n\n    REGISTER_PARSER(VP8,                vp8);\n\n}\n", "idx": 2091, "_split": "valid", "_hash": "3f5d3ea718410805efc5ec01a2f1c2b2"}
{"project": "FFmpeg", "commit_id": "11db644a8e54f02e54d2eaad343a87fcb697c15e", "target": 0, "func": "int ff_audio_convert(AudioConvert *ac, AudioData *out, AudioData *in)\n\n{\n\n    int use_generic = 1;\n\n    int len         = in->nb_samples;\n\n    int p;\n\n\n\n    if (ac->dc) {\n\n        /* dithered conversion */\n\n        av_dlog(ac->avr, \"%d samples - audio_convert: %s to %s (dithered)\\n\",\n\n                len, av_get_sample_fmt_name(ac->in_fmt),\n\n                av_get_sample_fmt_name(ac->out_fmt));\n\n\n\n        return ff_convert_dither(ac->dc, out, in);\n\n    }\n\n\n\n    /* determine whether to use the optimized function based on pointer and\n\n       samples alignment in both the input and output */\n\n    if (ac->has_optimized_func) {\n\n        int ptr_align     = FFMIN(in->ptr_align,     out->ptr_align);\n\n        int samples_align = FFMIN(in->samples_align, out->samples_align);\n\n        int aligned_len   = FFALIGN(len, ac->samples_align);\n\n        if (!(ptr_align % ac->ptr_align) && samples_align >= aligned_len) {\n\n            len = aligned_len;\n\n            use_generic = 0;\n\n        }\n\n    }\n\n    av_dlog(ac->avr, \"%d samples - audio_convert: %s to %s (%s)\\n\", len,\n\n            av_get_sample_fmt_name(ac->in_fmt),\n\n            av_get_sample_fmt_name(ac->out_fmt),\n\n            use_generic ? ac->func_descr_generic : ac->func_descr);\n\n\n\n    if (ac->apply_map) {\n\n        ChannelMapInfo *map = &ac->avr->ch_map_info;\n\n\n\n        if (!av_sample_fmt_is_planar(ac->out_fmt)) {\n\n            av_log(ac->avr, AV_LOG_ERROR, \"cannot remap packed format during conversion\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        if (map->do_remap) {\n\n            if (av_sample_fmt_is_planar(ac->in_fmt)) {\n\n                conv_func_flat *convert = use_generic ? ac->conv_flat_generic :\n\n                                                        ac->conv_flat;\n\n\n\n                for (p = 0; p < ac->planes; p++)\n\n                    if (map->channel_map[p] >= 0)\n\n                        convert(out->data[p], in->data[map->channel_map[p]], len);\n\n            } else {\n\n                uint8_t *data[AVRESAMPLE_MAX_CHANNELS];\n\n                conv_func_deinterleave *convert = use_generic ?\n\n                                                  ac->conv_deinterleave_generic :\n\n                                                  ac->conv_deinterleave;\n\n\n\n                for (p = 0; p < ac->channels; p++)\n\n                    data[map->input_map[p]] = out->data[p];\n\n\n\n                convert(data, in->data[0], len, ac->channels);\n\n            }\n\n        }\n\n        if (map->do_copy || map->do_zero) {\n\n            for (p = 0; p < ac->planes; p++) {\n\n                if (map->channel_copy[p])\n\n                    memcpy(out->data[p], out->data[map->channel_copy[p]],\n\n                           len * out->stride);\n\n                else if (map->channel_zero[p])\n\n                    av_samples_set_silence(&out->data[p], 0, len, 1, ac->out_fmt);\n\n            }\n\n        }\n\n    } else {\n\n        switch (ac->func_type) {\n\n        case CONV_FUNC_TYPE_FLAT: {\n\n            if (!in->is_planar)\n\n                len *= in->channels;\n\n            if (use_generic) {\n\n                for (p = 0; p < ac->planes; p++)\n\n                    ac->conv_flat_generic(out->data[p], in->data[p], len);\n\n            } else {\n\n                for (p = 0; p < ac->planes; p++)\n\n                    ac->conv_flat(out->data[p], in->data[p], len);\n\n            }\n\n            break;\n\n        }\n\n        case CONV_FUNC_TYPE_INTERLEAVE:\n\n            if (use_generic)\n\n                ac->conv_interleave_generic(out->data[0], in->data, len,\n\n                                            ac->channels);\n\n            else\n\n                ac->conv_interleave(out->data[0], in->data, len, ac->channels);\n\n            break;\n\n        case CONV_FUNC_TYPE_DEINTERLEAVE:\n\n            if (use_generic)\n\n                ac->conv_deinterleave_generic(out->data, in->data[0], len,\n\n                                              ac->channels);\n\n            else\n\n                ac->conv_deinterleave(out->data, in->data[0], len,\n\n                                      ac->channels);\n\n            break;\n\n        }\n\n    }\n\n\n\n    out->nb_samples = in->nb_samples;\n\n    return 0;\n\n}\n", "idx": 2120, "_split": "valid", "_hash": "5b3a1a5b9d875805b5fce90d4c120023"}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_2f_1r_to_stereo(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += samples[i + 512];\n\n        samples[i + 256] += samples[i + 512];\n\n        samples[i + 512] = 0;\n\n    }\n\n}\n", "idx": 2158, "_split": "valid", "_hash": "4e03ff2d054b6acb035f14be28d03b96"}
{"project": "FFmpeg", "commit_id": "202a6697ba54293235ce2d7bd5724f4f461e417f", "target": 0, "func": "static PayloadContext *h264_new_extradata(void)\n\n{\n\n    PayloadContext *data =\n\n        av_mallocz(sizeof(PayloadContext) +\n\n                   FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    if (data) {\n\n        data->cookie = MAGIC_COOKIE;\n\n    }\n\n\n\n    return data;\n\n}\n", "idx": 2160, "_split": "valid", "_hash": "3550c221f448784c280f340389e6189f"}
{"project": "FFmpeg", "commit_id": "a06b0b1295c51d100101e0ca0434e199ad6de6b5", "target": 1, "func": "static int decode_init_thread_copy(AVCodecContext *avctx)\n\n{\n\n    H264Context *h = avctx->priv_data;\n\n\n\n    if (!avctx->internal->is_copy)\n\n        return 0;\n\n    memset(h->sps_buffers, 0, sizeof(h->sps_buffers));\n\n    memset(h->pps_buffers, 0, sizeof(h->pps_buffers));\n\n\n\n\n    h->rbsp_buffer[0]      = NULL;\n\n    h->rbsp_buffer[1]      = NULL;\n\n    h->rbsp_buffer_size[0] = 0;\n\n    h->rbsp_buffer_size[1] = 0;\n\n    h->context_initialized = 0;\n\n\n\n    return 0;\n\n}", "idx": 2235, "_split": "valid", "_hash": "20d3143dbfc5ac479da2bc4a21a55fd2"}
{"project": "FFmpeg", "commit_id": "c842aa378db6c9da156bd245b8f8d05d889e3d7e", "target": 1, "func": "static int dvvideo_decode_frame(AVCodecContext *avctx,\n\n                                 void *data, int *data_size,\n\n                                 uint8_t *buf, int buf_size)\n\n{\n\n    DVVideoContext *s = avctx->priv_data;\n\n\n\n    s->sys = dv_frame_profile(buf);\n\n    if (!s->sys || buf_size < s->sys->frame_size)\n\n        return -1; /* NOTE: we only accept several full frames */\n\n\n\n    if(s->picture.data[0])\n\n        avctx->release_buffer(avctx, &s->picture);\n\n\n\n    s->picture.reference = 0;\n\n    s->picture.key_frame = 1;\n\n    s->picture.pict_type = FF_I_TYPE;\n\n    avctx->pix_fmt = s->sys->pix_fmt;\n\n    avcodec_set_dimensions(avctx, s->sys->width, s->sys->height);\n\n    if(avctx->get_buffer(avctx, &s->picture) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n    s->picture.interlaced_frame = 1;\n\n    s->picture.top_field_first = 0;\n\n\n\n    s->buf = buf;\n\n    avctx->execute(avctx, dv_decode_mt, (void**)&dv_anchor[0], NULL,\n\n                   s->sys->difseg_size * 27);\n\n\n\n    emms_c();\n\n\n\n    /* return image */\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data= s->picture;\n\n\n\n    return s->sys->frame_size;\n\n}\n", "idx": 2238, "_split": "valid", "_hash": "85b588e5a089bf6b2e75a01b7e877b08"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static void mpeg_er_decode_mb(void *opaque, int ref, int mv_dir, int mv_type,\n\n                              int (*mv)[2][4][2],\n\n                              int mb_x, int mb_y, int mb_intra, int mb_skipped)\n\n{\n\n    MpegEncContext *s = opaque;\n\n\n\n    s->mv_dir     = mv_dir;\n\n    s->mv_type    = mv_type;\n\n    s->mb_intra   = mb_intra;\n\n    s->mb_skipped = mb_skipped;\n\n    s->mb_x       = mb_x;\n\n    s->mb_y       = mb_y;\n\n    memcpy(s->mv, mv, sizeof(*mv));\n\n\n\n    ff_init_block_index(s);\n\n    ff_update_block_index(s);\n\n\n\n    s->dsp.clear_blocks(s->block[0]);\n\n\n\n    s->dest[0] = s->current_picture.f.data[0] + (s->mb_y *  16                       * s->linesize)   + s->mb_x *  16;\n\n    s->dest[1] = s->current_picture.f.data[1] + (s->mb_y * (16 >> s->chroma_y_shift) * s->uvlinesize) + s->mb_x * (16 >> s->chroma_x_shift);\n\n    s->dest[2] = s->current_picture.f.data[2] + (s->mb_y * (16 >> s->chroma_y_shift) * s->uvlinesize) + s->mb_x * (16 >> s->chroma_x_shift);\n\n\n\n    assert(ref == 0);\n\n    ff_MPV_decode_mb(s, s->block);\n\n}\n", "idx": 2260, "_split": "valid", "_hash": "ebfb47377184017866f5e98a7e5b54bb"}
{"project": "FFmpeg", "commit_id": "0cbff0275b0cff4021e7026ba6060594225fcab5", "target": 1, "func": "int av_find_stream_info(AVFormatContext *ic)\n\n{\n\n    int i, count, ret, read_size, j;\n\n    AVStream *st;\n\n    AVPacket pkt1, *pkt;\n\n    AVPacketList *pktl=NULL, **ppktl;\n\n    int64_t last_dts[MAX_STREAMS];\n\n    int duration_count[MAX_STREAMS]={0};\n\n    double duration_error[MAX_STREAMS][MAX_STD_TIMEBASES]={{0}}; //FIXME malloc()?\n\n    offset_t old_offset = url_ftell(&ic->pb);\n\n\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        st = ic->streams[i];\n\n        if(st->codec->codec_type == CODEC_TYPE_VIDEO){\n\n/*            if(!st->time_base.num)\n\n                st->time_base= */\n\n            if(!st->codec->time_base.num)\n\n                st->codec->time_base= st->time_base;\n\n        }\n\n        //only for the split stuff\n\n        if (!st->parser) {\n\n            st->parser = av_parser_init(st->codec->codec_id);\n\n            if(st->need_parsing == 2 && st->parser){\n\n                st->parser->flags |= PARSER_FLAG_COMPLETE_FRAMES;\n\n            }\n\n        }\n\n    }\n\n\n\n    for(i=0;i<MAX_STREAMS;i++){\n\n        last_dts[i]= AV_NOPTS_VALUE;\n\n    }\n\n\n\n    count = 0;\n\n    read_size = 0;\n\n    ppktl = &ic->packet_buffer;\n\n    for(;;) {\n\n        /* check if one codec still needs to be handled */\n\n        for(i=0;i<ic->nb_streams;i++) {\n\n            st = ic->streams[i];\n\n            if (!has_codec_parameters(st->codec))\n\n                break;\n\n            /* variable fps and no guess at the real fps */\n\n            if(   st->codec->time_base.den >= 101LL*st->codec->time_base.num\n\n               && duration_count[i]<20 && st->codec->codec_type == CODEC_TYPE_VIDEO)\n\n                break;\n\n            if(st->parser && st->parser->parser->split && !st->codec->extradata)\n\n                break;\n\n        }\n\n        if (i == ic->nb_streams) {\n\n            /* NOTE: if the format has no header, then we need to read\n\n               some packets to get most of the streams, so we cannot\n\n               stop here */\n\n            if (!(ic->ctx_flags & AVFMTCTX_NOHEADER)) {\n\n                /* if we found the info for all the codecs, we can stop */\n\n                ret = count;\n\n                break;\n\n            }\n\n        }\n\n        /* we did not get all the codec info, but we read too much data */\n\n        if (read_size >= MAX_READ_SIZE) {\n\n            ret = count;\n\n            break;\n\n        }\n\n\n\n        /* NOTE: a new stream can be added there if no header in file\n\n           (AVFMTCTX_NOHEADER) */\n\n        ret = av_read_frame_internal(ic, &pkt1);\n\n        if (ret < 0) {\n\n            /* EOF or error */\n\n            ret = -1; /* we could not have all the codec parameters before EOF */\n\n            for(i=0;i<ic->nb_streams;i++) {\n\n                st = ic->streams[i];\n\n                if (!has_codec_parameters(st->codec)){\n\n                    char buf[256];\n\n                    avcodec_string(buf, sizeof(buf), st->codec, 0);\n\n                    av_log(ic, AV_LOG_INFO, \"Could not find codec parameters (%s)\\n\", buf);\n\n                } else {\n\n                    ret = 0;\n\n                }\n\n            }\n\n            break;\n\n        }\n\n\n\n        pktl = av_mallocz(sizeof(AVPacketList));\n\n        if (!pktl) {\n\n            ret = AVERROR_NOMEM;\n\n            break;\n\n        }\n\n\n\n        /* add the packet in the buffered packet list */\n\n        *ppktl = pktl;\n\n        ppktl = &pktl->next;\n\n\n\n        pkt = &pktl->pkt;\n\n        *pkt = pkt1;\n\n\n\n        /* duplicate the packet */\n\n        if (av_dup_packet(pkt) < 0) {\n\n            ret = AVERROR_NOMEM;\n\n            break;\n\n        }\n\n\n\n        read_size += pkt->size;\n\n\n\n        st = ic->streams[pkt->stream_index];\n\n        if(st->codec_info_nb_frames>1) //FIXME move codec_info_nb_frames and codec_info_duration from AVStream into this func\n\n            st->codec_info_duration += pkt->duration;\n\n        if (pkt->duration != 0)\n\n            st->codec_info_nb_frames++;\n\n\n\n        {\n\n            int index= pkt->stream_index;\n\n            int64_t last= last_dts[index];\n\n            int64_t duration= pkt->dts - last;\n\n\n\n            if(pkt->dts != AV_NOPTS_VALUE && last != AV_NOPTS_VALUE && duration>0){\n\n                double dur= duration * av_q2d(st->time_base);\n\n\n\n//                if(st->codec->codec_type == CODEC_TYPE_VIDEO)\n\n//                    av_log(NULL, AV_LOG_ERROR, \"%f\\n\", dur);\n\n                if(duration_count[index] < 2)\n\n                    memset(duration_error, 0, sizeof(duration_error));\n\n                for(i=1; i<MAX_STD_TIMEBASES; i++){\n\n                    int framerate= get_std_framerate(i);\n\n                    int ticks= lrintf(dur*framerate/(1001*12));\n\n                    double error= dur - ticks*1001*12/(double)framerate;\n\n                    duration_error[index][i] += error*error;\n\n                }\n\n                duration_count[index]++;\n\n\n\n                if(st->codec_info_nb_frames == 0 && 0)\n\n                    st->codec_info_duration += duration;\n\n            }\n\n            if(last == AV_NOPTS_VALUE || duration_count[index]<=1)\n\n                last_dts[pkt->stream_index]= pkt->dts;\n\n        }\n\n        if(st->parser && st->parser->parser->split && !st->codec->extradata){\n\n            int i= st->parser->parser->split(st->codec, pkt->data, pkt->size);\n\n            if(i){\n\n                st->codec->extradata_size= i;\n\n                st->codec->extradata= av_malloc(st->codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                memcpy(st->codec->extradata, pkt->data, st->codec->extradata_size);\n\n                memset(st->codec->extradata + i, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n            }\n\n        }\n\n\n\n        /* if still no information, we try to open the codec and to\n\n           decompress the frame. We try to avoid that in most cases as\n\n           it takes longer and uses more memory. For MPEG4, we need to\n\n           decompress for Quicktime. */\n\n        if (!has_codec_parameters(st->codec) /*&&\n\n            (st->codec->codec_id == CODEC_ID_FLV1 ||\n\n             st->codec->codec_id == CODEC_ID_H264 ||\n\n             st->codec->codec_id == CODEC_ID_H263 ||\n\n             st->codec->codec_id == CODEC_ID_H261 ||\n\n             st->codec->codec_id == CODEC_ID_VORBIS ||\n\n             st->codec->codec_id == CODEC_ID_MJPEG ||\n\n             st->codec->codec_id == CODEC_ID_PNG ||\n\n             st->codec->codec_id == CODEC_ID_PAM ||\n\n             st->codec->codec_id == CODEC_ID_PGM ||\n\n             st->codec->codec_id == CODEC_ID_PGMYUV ||\n\n             st->codec->codec_id == CODEC_ID_PBM ||\n\n             st->codec->codec_id == CODEC_ID_PPM ||\n\n             st->codec->codec_id == CODEC_ID_SHORTEN ||\n\n             (st->codec->codec_id == CODEC_ID_MPEG4 && !st->need_parsing))*/)\n\n            try_decode_frame(st, pkt->data, pkt->size);\n\n\n\n        if (av_rescale_q(st->codec_info_duration, st->time_base, AV_TIME_BASE_Q) >= ic->max_analyze_duration) {\n\n            break;\n\n        }\n\n        count++;\n\n    }\n\n\n\n    // close codecs which where opened in try_decode_frame()\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        st = ic->streams[i];\n\n        if(st->codec->codec)\n\n            avcodec_close(st->codec);\n\n    }\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        st = ic->streams[i];\n\n        if (st->codec->codec_type == CODEC_TYPE_VIDEO) {\n\n            if(st->codec->codec_id == CODEC_ID_RAWVIDEO && !st->codec->codec_tag && !st->codec->bits_per_sample)\n\n                st->codec->codec_tag= avcodec_pix_fmt_to_codec_tag(st->codec->pix_fmt);\n\n\n\n            if(duration_count[i]\n\n               && (st->codec->time_base.num*101LL <= st->codec->time_base.den || st->codec->codec_id == CODEC_ID_MPEG2VIDEO) /*&&\n\n               //FIXME we should not special case mpeg2, but this needs testing with non mpeg2 ...\n\n               st->time_base.num*duration_sum[i]/duration_count[i]*101LL > st->time_base.den*/){\n\n                double best_error= 2*av_q2d(st->time_base);\n\n                best_error= best_error*best_error*duration_count[i]*1000*12*30;\n\n\n\n                for(j=1; j<MAX_STD_TIMEBASES; j++){\n\n                    double error= duration_error[i][j] * get_std_framerate(j);\n\n//                    if(st->codec->codec_type == CODEC_TYPE_VIDEO)\n\n//                        av_log(NULL, AV_LOG_ERROR, \"%f %f\\n\", get_std_framerate(j) / 12.0/1001, error);\n\n                    if(error < best_error){\n\n                        best_error= error;\n\n                        av_reduce(&st->r_frame_rate.num, &st->r_frame_rate.den, get_std_framerate(j), 12*1001, INT_MAX);\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (!st->r_frame_rate.num){\n\n                if(    st->codec->time_base.den * (int64_t)st->time_base.num\n\n                    <= st->codec->time_base.num * (int64_t)st->time_base.den){\n\n                    st->r_frame_rate.num = st->codec->time_base.den;\n\n                    st->r_frame_rate.den = st->codec->time_base.num;\n\n                }else{\n\n                    st->r_frame_rate.num = st->time_base.den;\n\n                    st->r_frame_rate.den = st->time_base.num;\n\n                }\n\n            }\n\n        }else if(st->codec->codec_type == CODEC_TYPE_AUDIO) {\n\n            if(!st->codec->bits_per_sample)\n\n                st->codec->bits_per_sample= av_get_bits_per_sample(st->codec->codec_id);\n\n        }\n\n    }\n\n\n\n    av_estimate_timings(ic, old_offset);\n\n#if 0\n\n    /* correct DTS for b frame streams with no timestamps */\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        st = ic->streams[i];\n\n        if (st->codec->codec_type == CODEC_TYPE_VIDEO) {\n\n            if(b-frames){\n\n                ppktl = &ic->packet_buffer;\n\n                while(ppkt1){\n\n                    if(ppkt1->stream_index != i)\n\n                        continue;\n\n                    if(ppkt1->pkt->dts < 0)\n\n                        break;\n\n                    if(ppkt1->pkt->pts != AV_NOPTS_VALUE)\n\n                        break;\n\n                    ppkt1->pkt->dts -= delta;\n\n                    ppkt1= ppkt1->next;\n\n                }\n\n                if(ppkt1)\n\n                    continue;\n\n                st->cur_dts -= delta;\n\n            }\n\n        }\n\n    }\n\n#endif\n\n    return ret;\n\n}\n", "idx": 2335, "_split": "valid", "_hash": "91ad73c494db51c93f56ecd2b60761ba"}
{"project": "FFmpeg", "commit_id": "be8d812c9635f31f69c30dff9ebf565a07a7dab7", "target": 1, "func": "static void create_vorbis_context(vorbis_enc_context *venc,\n\n                                  AVCodecContext *avccontext)\n\n{\n\n    vorbis_enc_floor   *fc;\n\n    vorbis_enc_residue *rc;\n\n    vorbis_enc_mapping *mc;\n\n    int i, book;\n\n\n\n    venc->channels    = avccontext->channels;\n\n    venc->sample_rate = avccontext->sample_rate;\n\n    venc->log2_blocksize[0] = venc->log2_blocksize[1] = 11;\n\n\n\n    venc->ncodebooks = FF_ARRAY_ELEMS(cvectors);\n\n    venc->codebooks  = av_malloc(sizeof(vorbis_enc_codebook) * venc->ncodebooks);\n\n\n\n    // codebook 0..14 - floor1 book, values 0..255\n\n    // codebook 15 residue masterbook\n\n    // codebook 16..29 residue\n\n    for (book = 0; book < venc->ncodebooks; book++) {\n\n        vorbis_enc_codebook *cb = &venc->codebooks[book];\n\n        int vals;\n\n        cb->ndimentions = cvectors[book].dim;\n\n        cb->nentries    = cvectors[book].real_len;\n\n        cb->min         = cvectors[book].min;\n\n        cb->delta       = cvectors[book].delta;\n\n        cb->lookup      = cvectors[book].lookup;\n\n        cb->seq_p       = 0;\n\n\n\n        cb->lens      = av_malloc(sizeof(uint8_t)  * cb->nentries);\n\n        cb->codewords = av_malloc(sizeof(uint32_t) * cb->nentries);\n\n        memcpy(cb->lens, cvectors[book].clens, cvectors[book].len);\n\n        memset(cb->lens + cvectors[book].len, 0, cb->nentries - cvectors[book].len);\n\n\n\n        if (cb->lookup) {\n\n            vals = cb_lookup_vals(cb->lookup, cb->ndimentions, cb->nentries);\n\n            cb->quantlist = av_malloc(sizeof(int) * vals);\n\n            for (i = 0; i < vals; i++)\n\n                cb->quantlist[i] = cvectors[book].quant[i];\n\n        } else {\n\n            cb->quantlist = NULL;\n\n        }\n\n        ready_codebook(cb);\n\n    }\n\n\n\n    venc->nfloors = 1;\n\n    venc->floors  = av_malloc(sizeof(vorbis_enc_floor) * venc->nfloors);\n\n\n\n    // just 1 floor\n\n    fc = &venc->floors[0];\n\n    fc->partitions         = NUM_FLOOR_PARTITIONS;\n\n    fc->partition_to_class = av_malloc(sizeof(int) * fc->partitions);\n\n    fc->nclasses           = 0;\n\n    for (i = 0; i < fc->partitions; i++) {\n\n        static const int a[] = {0, 1, 2, 2, 3, 3, 4, 4};\n\n        fc->partition_to_class[i] = a[i];\n\n        fc->nclasses = FFMAX(fc->nclasses, fc->partition_to_class[i]);\n\n    }\n\n    fc->nclasses++;\n\n    fc->classes = av_malloc(sizeof(vorbis_enc_floor_class) * fc->nclasses);\n\n    for (i = 0; i < fc->nclasses; i++) {\n\n        vorbis_enc_floor_class * c = &fc->classes[i];\n\n        int j, books;\n\n        c->dim        = floor_classes[i].dim;\n\n        c->subclass   = floor_classes[i].subclass;\n\n        c->masterbook = floor_classes[i].masterbook;\n\n        books         = (1 << c->subclass);\n\n        c->books      = av_malloc(sizeof(int) * books);\n\n        for (j = 0; j < books; j++)\n\n            c->books[j] = floor_classes[i].nbooks[j];\n\n    }\n\n    fc->multiplier = 2;\n\n    fc->rangebits  = venc->log2_blocksize[0] - 1;\n\n\n\n    fc->values = 2;\n\n    for (i = 0; i < fc->partitions; i++)\n\n        fc->values += fc->classes[fc->partition_to_class[i]].dim;\n\n\n\n    fc->list = av_malloc(sizeof(vorbis_floor1_entry) * fc->values);\n\n    fc->list[0].x = 0;\n\n    fc->list[1].x = 1 << fc->rangebits;\n\n    for (i = 2; i < fc->values; i++) {\n\n        static const int a[] = {\n\n             93, 23,372,  6, 46,186,750, 14, 33, 65,\n\n            130,260,556,  3, 10, 18, 28, 39, 55, 79,\n\n            111,158,220,312,464,650,850\n\n        };\n\n        fc->list[i].x = a[i - 2];\n\n    }\n\n    ff_vorbis_ready_floor1_list(fc->list, fc->values);\n\n\n\n    venc->nresidues = 1;\n\n    venc->residues  = av_malloc(sizeof(vorbis_enc_residue) * venc->nresidues);\n\n\n\n    // single residue\n\n    rc = &venc->residues[0];\n\n    rc->type            = 2;\n\n    rc->begin           = 0;\n\n    rc->end             = 1600;\n\n    rc->partition_size  = 32;\n\n    rc->classifications = 10;\n\n    rc->classbook       = 15;\n\n    rc->books           = av_malloc(sizeof(*rc->books) * rc->classifications);\n\n    {\n\n        static const int8_t a[10][8] = {\n\n            { -1, -1, -1, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 16, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 17, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 18, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 19, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 20, -1, -1, -1, -1, -1, },\n\n            { -1, -1, 21, -1, -1, -1, -1, -1, },\n\n            { 22, 23, -1, -1, -1, -1, -1, -1, },\n\n            { 24, 25, -1, -1, -1, -1, -1, -1, },\n\n            { 26, 27, 28, -1, -1, -1, -1, -1, },\n\n        };\n\n        memcpy(rc->books, a, sizeof a);\n\n    }\n\n    ready_residue(rc, venc);\n\n\n\n    venc->nmappings = 1;\n\n    venc->mappings  = av_malloc(sizeof(vorbis_enc_mapping) * venc->nmappings);\n\n\n\n    // single mapping\n\n    mc = &venc->mappings[0];\n\n    mc->submaps = 1;\n\n    mc->mux     = av_malloc(sizeof(int) * venc->channels);\n\n    for (i = 0; i < venc->channels; i++)\n\n        mc->mux[i] = 0;\n\n    mc->floor   = av_malloc(sizeof(int) * mc->submaps);\n\n    mc->residue = av_malloc(sizeof(int) * mc->submaps);\n\n    for (i = 0; i < mc->submaps; i++) {\n\n        mc->floor[i]   = 0;\n\n        mc->residue[i] = 0;\n\n    }\n\n    mc->coupling_steps = venc->channels == 2 ? 1 : 0;\n\n    mc->magnitude      = av_malloc(sizeof(int) * mc->coupling_steps);\n\n    mc->angle          = av_malloc(sizeof(int) * mc->coupling_steps);\n\n    if (mc->coupling_steps) {\n\n        mc->magnitude[0] = 0;\n\n        mc->angle[0]     = 1;\n\n    }\n\n\n\n    venc->nmodes = 1;\n\n    venc->modes  = av_malloc(sizeof(vorbis_enc_mode) * venc->nmodes);\n\n\n\n    // single mode\n\n    venc->modes[0].blockflag = 0;\n\n    venc->modes[0].mapping   = 0;\n\n\n\n    venc->have_saved = 0;\n\n    venc->saved      = av_malloc(sizeof(float) * venc->channels * (1 << venc->log2_blocksize[1]) / 2);\n\n    venc->samples    = av_malloc(sizeof(float) * venc->channels * (1 << venc->log2_blocksize[1]));\n\n    venc->floor      = av_malloc(sizeof(float) * venc->channels * (1 << venc->log2_blocksize[1]) / 2);\n\n    venc->coeffs     = av_malloc(sizeof(float) * venc->channels * (1 << venc->log2_blocksize[1]) / 2);\n\n\n\n    venc->win[0] = ff_vorbis_vwin[venc->log2_blocksize[0] - 6];\n\n    venc->win[1] = ff_vorbis_vwin[venc->log2_blocksize[1] - 6];\n\n\n\n    ff_mdct_init(&venc->mdct[0], venc->log2_blocksize[0], 0, 1.0);\n\n    ff_mdct_init(&venc->mdct[1], venc->log2_blocksize[1], 0, 1.0);\n\n}\n", "idx": 2336, "_split": "valid", "_hash": "a4fbf05f7c30780a72d960b0113f0b17"}
{"project": "FFmpeg", "commit_id": "90da2b50865549e086d4491cbb2bdc54af38ea4f", "target": 1, "func": "static void opt_frame_pix_fmt(const char *arg)\n\n{\n\n    if (strcmp(arg, \"list\"))\n\n        frame_pix_fmt = avcodec_get_pix_fmt(arg);\n\n    else {\n\n        list_fmts(avcodec_pix_fmt_string, PIX_FMT_NB);\n\n        av_exit(0);\n\n    }\n\n}\n", "idx": 2385, "_split": "valid", "_hash": "3507f40b29c3d3edcab21eed5708e6e7"}
{"project": "FFmpeg", "commit_id": "c51c08e0e70c186971385bdbb225f69edd4e3375", "target": 0, "func": "static int scan_mmco_reset(AVCodecParserContext *s)\n\n{\n\n    H264ParseContext *p = s->priv_data;\n\n    H264Context      *h = &p->h;\n\n    H264SliceContext *sl = &h->slice_ctx[0];\n\n\n\n    sl->slice_type_nos = s->pict_type & 3;\n\n\n\n    if (h->pps.redundant_pic_cnt_present)\n\n        get_ue_golomb(&sl->gb); // redundant_pic_count\n\n\n\n    if (ff_set_ref_count(h, sl) < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        int list;\n\n        for (list = 0; list < sl->list_count; list++) {\n\n            if (get_bits1(&sl->gb)) {\n\n                int index;\n\n                for (index = 0; ; index++) {\n\n                    unsigned int reordering_of_pic_nums_idc = get_ue_golomb_31(&sl->gb);\n\n\n\n                    if (reordering_of_pic_nums_idc < 3)\n\n                        get_ue_golomb(&sl->gb);\n\n                    else if (reordering_of_pic_nums_idc > 3) {\n\n                        av_log(h->avctx, AV_LOG_ERROR,\n\n                               \"illegal reordering_of_pic_nums_idc %d\\n\",\n\n                               reordering_of_pic_nums_idc);\n\n                        return AVERROR_INVALIDDATA;\n\n                    } else\n\n                        break;\n\n\n\n                    if (index >= sl->ref_count[list]) {\n\n                        av_log(h->avctx, AV_LOG_ERROR,\n\n                               \"reference count %d overflow\\n\", index);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if ((h->pps.weighted_pred && sl->slice_type_nos == AV_PICTURE_TYPE_P) ||\n\n        (h->pps.weighted_bipred_idc == 1 && sl->slice_type_nos == AV_PICTURE_TYPE_B))\n\n        ff_pred_weight_table(h, sl);\n\n\n\n    if (get_bits1(&sl->gb)) { // adaptive_ref_pic_marking_mode_flag\n\n        int i;\n\n        for (i = 0; i < MAX_MMCO_COUNT; i++) {\n\n            MMCOOpcode opcode = get_ue_golomb_31(&sl->gb);\n\n            if (opcode > (unsigned) MMCO_LONG) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"illegal memory management control operation %d\\n\",\n\n                       opcode);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (opcode == MMCO_END)\n\n               return 0;\n\n            else if (opcode == MMCO_RESET)\n\n                return 1;\n\n\n\n            if (opcode == MMCO_SHORT2UNUSED || opcode == MMCO_SHORT2LONG)\n\n                get_ue_golomb(&sl->gb);\n\n            if (opcode == MMCO_SHORT2LONG || opcode == MMCO_LONG2UNUSED ||\n\n                opcode == MMCO_LONG || opcode == MMCO_SET_MAX_LONG)\n\n                get_ue_golomb_31(&sl->gb);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 2399, "_split": "valid", "_hash": "e3fac858ceb4c91f815469e2e2e6c73c"}
{"project": "FFmpeg", "commit_id": "a4893bafd8b303c7933c2f4badedcf95d088c212", "target": 1, "func": "static int qdm2_decode_init(AVCodecContext *avctx)\n\n{\n\n    QDM2Context *s = avctx->priv_data;\n\n    uint8_t *extradata;\n\n    int extradata_size;\n\n    int tmp_val, tmp, size;\n\n    int i;\n\n    float alpha;\n\n    \n\n    /* extradata parsing\n\n    \n\n    Structure:\n\n    wave {\n\n        frma (QDM2)\n\n        QDCA\n\n        QDCP\n\n    }\n\n    \n\n    32  size (including this field)\n\n    32  tag (=frma)\n\n    32  type (=QDM2 or QDMC)\n\n    \n\n    32  size (including this field, in bytes)\n\n    32  tag (=QDCA) // maybe mandatory parameters\n\n    32  unknown (=1)\n\n    32  channels (=2)\n\n    32  samplerate (=44100)\n\n    32  bitrate (=96000)\n\n    32  block size (=4096)\n\n    32  frame size (=256) (for one channel)\n\n    32  packet size (=1300)\n\n    \n\n    32  size (including this field, in bytes)\n\n    32  tag (=QDCP) // maybe some tuneable parameters\n\n    32  float1 (=1.0)\n\n    32  zero ?\n\n    32  float2 (=1.0)\n\n    32  float3 (=1.0)\n\n    32  unknown (27)\n\n    32  unknown (8)\n\n    32  zero ?\n\n    */\n\n\n\n    if (!avctx->extradata || (avctx->extradata_size < 48)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"extradata missing or truncated\\n\");\n\n        return -1;\n\n    }\n\n\n\n    extradata = avctx->extradata;\n\n    extradata_size = avctx->extradata_size;\n\n\n\n    while (extradata_size > 7) {\n\n        if (!memcmp(extradata, \"frmaQDM\", 7))\n\n            break;\n\n        extradata++;\n\n        extradata_size--;\n\n    }\n\n\n\n    if (extradata_size < 12) {\n\n        av_log(avctx, AV_LOG_ERROR, \"not enough extradata (%i)\\n\",\n\n               extradata_size);\n\n        return -1;\n\n    }\n\n\n\n    if (memcmp(extradata, \"frmaQDM\", 7)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid headers, QDM? not found\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (extradata[7] == 'C') {\n\n//        s->is_qdmc = 1;\n\n        av_log(avctx, AV_LOG_ERROR, \"stream is QDMC version 1, which is not supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    extradata += 8;\n\n    extradata_size -= 8;\n\n\n\n    size = BE_32(extradata);\n\n\n\n    if(size > extradata_size){\n\n        av_log(avctx, AV_LOG_ERROR, \"extradata size too small, %i < %i\\n\",\n\n               extradata_size, size);\n\n        return -1;\n\n    }\n\n\n\n    extradata += 4;\n\n    av_log(avctx, AV_LOG_DEBUG, \"size: %d\\n\", size);\n\n    if (BE_32(extradata) != MKBETAG('Q','D','C','A')) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid extradata, expecting QDCA\\n\");\n\n        return -1;\n\n    }\n\n\n\n    extradata += 8;\n\n\n\n    avctx->channels = s->nb_channels = s->channels = BE_32(extradata);\n\n    extradata += 4;\n\n\n\n    avctx->sample_rate = BE_32(extradata);\n\n    extradata += 4;\n\n\n\n    avctx->bit_rate = BE_32(extradata);\n\n    extradata += 4;\n\n\n\n    s->group_size = BE_32(extradata);\n\n    extradata += 4;\n\n\n\n    s->fft_size = BE_32(extradata);\n\n    extradata += 4;\n\n\n\n    s->checksum_size = BE_32(extradata);\n\n    extradata += 4;\n\n\n\n    s->fft_order = av_log2(s->fft_size) + 1;\n\n    s->fft_frame_size = 2 * s->fft_size; // complex has two floats\n\n\n\n    // something like max decodable tones\n\n    s->group_order = av_log2(s->group_size) + 1;\n\n    s->frame_size = s->group_size / 16; // 16 iterations per super block\n\n\n\n    if (s->fft_order == 8)\n\n        s->sub_sampling = 1;\n\n    else\n\n        s->sub_sampling = 2;\n\n    s->frequency_range = 255 / (1 << (2 - s->sub_sampling));\n\n    \n\n    switch ((s->sub_sampling * 2 + s->channels - 1)) {\n\n        case 0: tmp = 40; break;\n\n        case 1: tmp = 48; break;\n\n        case 2: tmp = 56; break;\n\n        case 3: tmp = 72; break;\n\n        case 4: tmp = 80; break;\n\n        case 5: tmp = 100;break;\n\n        default: tmp=s->sub_sampling; break;\n\n    }\n\n    tmp_val = 0;\n\n    if ((tmp * 1000) < avctx->bit_rate)  tmp_val = 1;\n\n    if ((tmp * 1440) < avctx->bit_rate)  tmp_val = 2;\n\n    if ((tmp * 1760) < avctx->bit_rate)  tmp_val = 3;\n\n    if ((tmp * 2240) < avctx->bit_rate)  tmp_val = 4;\n\n    s->cm_table_select = tmp_val;\n\n\n\n    if (s->sub_sampling == 0)\n\n        tmp = 16000;\n\n    else\n\n        tmp = ((-(s->sub_sampling -1)) & 8000) + 20000;\n\n    /*\n\n    0: 16000 -> 1\n\n    1: 20000 -> 2\n\n    2: 28000 -> 2\n\n    */\n\n    if (tmp < 8000)\n\n        s->coeff_per_sb_select = 0;\n\n    else if (tmp <= 16000)\n\n        s->coeff_per_sb_select = 1;\n\n    else\n\n        s->coeff_per_sb_select = 2;\n\n\n\n    if (s->fft_order != 8 && s->fft_order != 9)\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown FFT order (%d), contact the developers!\\n\", s->fft_order);\n\n\n\n    ff_fft_init(&s->fft_ctx, s->fft_order - 1, 1);\n\n\n\n    for (i = 1; i < (1 << (s->fft_order - 2)); i++) {\n\n        alpha = 2 * M_PI * (float)i / (float)(1 << (s->fft_order - 1));\n\n        s->exptab[i].re = cos(alpha);\n\n        s->exptab[i].im = sin(alpha);\n\n    }\n\n\n\n    qdm2_init(s);\n\n    \n\n//    dump_context(s);\n\n    return 0;\n\n}\n", "idx": 2411, "_split": "valid", "_hash": "7e370538b9e1eadaf1d6aee9b6e0b392"}
{"project": "FFmpeg", "commit_id": "ca8064d2d1b293d7a8011bf0a08005c11ae8ba67", "target": 1, "func": "static void new_audio_stream(AVFormatContext *oc)\n\n{\n\n    AVStream *st;\n\n    AVCodec *codec= NULL;\n\n    AVCodecContext *audio_enc;\n\n    enum CodecID codec_id;\n\n\n\n    st = av_new_stream(oc, oc->nb_streams < nb_streamid_map ? streamid_map[oc->nb_streams] : 0);\n\n    if (!st) {\n\n        fprintf(stderr, \"Could not alloc stream\\n\");\n\n        ffmpeg_exit(1);\n\n    }\n\n\n\n    output_codecs = grow_array(output_codecs, sizeof(*output_codecs), &nb_output_codecs, nb_output_codecs + 1);\n\n    if(!audio_stream_copy){\n\n        if (audio_codec_name) {\n\n            codec_id = find_codec_or_die(audio_codec_name, AVMEDIA_TYPE_AUDIO, 1,\n\n                                         avcodec_opts[AVMEDIA_TYPE_AUDIO]->strict_std_compliance);\n\n            codec = avcodec_find_encoder_by_name(audio_codec_name);\n\n            output_codecs[nb_output_codecs-1] = codec;\n\n        } else {\n\n            codec_id = av_guess_codec(oc->oformat, NULL, oc->filename, NULL, AVMEDIA_TYPE_AUDIO);\n\n            codec = avcodec_find_encoder(codec_id);\n\n        }\n\n    }\n\n\n\n    avcodec_get_context_defaults3(st->codec, codec);\n\n\n\n    bitstream_filters[nb_output_files] =\n\n        grow_array(bitstream_filters[nb_output_files],\n\n                   sizeof(*bitstream_filters[nb_output_files]),\n\n                   &nb_bitstream_filters[nb_output_files], oc->nb_streams);\n\n    bitstream_filters[nb_output_files][oc->nb_streams - 1]= audio_bitstream_filters;\n\n    audio_bitstream_filters= NULL;\n\n\n\n    avcodec_thread_init(st->codec, thread_count);\n\n\n\n    audio_enc = st->codec;\n\n    audio_enc->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n    if(audio_codec_tag)\n\n        audio_enc->codec_tag= audio_codec_tag;\n\n\n\n    if (oc->oformat->flags & AVFMT_GLOBALHEADER) {\n\n        audio_enc->flags |= CODEC_FLAG_GLOBAL_HEADER;\n\n        avcodec_opts[AVMEDIA_TYPE_AUDIO]->flags|= CODEC_FLAG_GLOBAL_HEADER;\n\n    }\n\n    if (audio_stream_copy) {\n\n        st->stream_copy = 1;\n\n        audio_enc->channels = audio_channels;\n\n        audio_enc->sample_rate = audio_sample_rate;\n\n    } else {\n\n        audio_enc->codec_id = codec_id;\n\n        set_context_opts(audio_enc, avcodec_opts[AVMEDIA_TYPE_AUDIO], AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_ENCODING_PARAM, codec);\n\n\n\n        if (audio_qscale > QSCALE_NONE) {\n\n            audio_enc->flags |= CODEC_FLAG_QSCALE;\n\n            audio_enc->global_quality = st->quality = FF_QP2LAMBDA * audio_qscale;\n\n        }\n\n        audio_enc->channels = audio_channels;\n\n        audio_enc->sample_fmt = audio_sample_fmt;\n\n        audio_enc->sample_rate = audio_sample_rate;\n\n        audio_enc->channel_layout = channel_layout;\n\n        if (avcodec_channel_layout_num_channels(channel_layout) != audio_channels)\n\n            audio_enc->channel_layout = 0;\n\n        choose_sample_fmt(st, codec);\n\n        choose_sample_rate(st, codec);\n\n    }\n\n    audio_enc->time_base= (AVRational){1, audio_sample_rate};\n\n    if (audio_language) {\n\n        av_metadata_set2(&st->metadata, \"language\", audio_language, 0);\n\n        av_freep(&audio_language);\n\n    }\n\n\n\n    /* reset some key parameters */\n\n    audio_disable = 0;\n\n    av_freep(&audio_codec_name);\n\n    audio_stream_copy = 0;\n\n}\n", "idx": 2414, "_split": "valid", "_hash": "3b6716132233114708df42968bfead54"}
{"project": "FFmpeg", "commit_id": "5ae484e350e4f1b20b31802dac59ca3519627c0a", "target": 0, "func": "static void frame_erasure(EVRCContext *e, float *samples)\n\n{\n\n    float ilspf[FILTER_ORDER], ilpc[FILTER_ORDER], idelay[NB_SUBFRAMES],\n\n          tmp[SUBFRAME_SIZE + 6], f;\n\n    int i, j;\n\n\n\n    for (i = 0; i < FILTER_ORDER; i++) {\n\n        if (e->bitrate != RATE_QUANT)\n\n            e->lspf[i] = e->prev_lspf[i] * 0.875 + 0.125 * (i + 1) * 0.048;\n\n        else\n\n            e->lspf[i] = e->prev_lspf[i];\n\n    }\n\n\n\n    if (e->prev_error_flag)\n\n        e->avg_acb_gain *= 0.75;\n\n    if (e->bitrate == RATE_FULL)\n\n        memcpy(e->pitch_back, e->pitch, ACB_SIZE * sizeof(float));\n\n    if (e->last_valid_bitrate == RATE_QUANT)\n\n        e->bitrate = RATE_QUANT;\n\n    else\n\n        e->bitrate = RATE_FULL;\n\n\n\n    if (e->bitrate == RATE_FULL || e->bitrate == RATE_HALF) {\n\n        e->pitch_delay = e->prev_pitch_delay;\n\n    } else {\n\n        float sum = 0;\n\n\n\n        idelay[0] = idelay[1] = idelay[2] = MIN_DELAY;\n\n\n\n        for (i = 0; i < NB_SUBFRAMES; i++)\n\n            sum += evrc_energy_quant[e->prev_energy_gain][i];\n\n        sum /= (float) NB_SUBFRAMES;\n\n        sum  = pow(10, sum);\n\n        for (i = 0; i < NB_SUBFRAMES; i++)\n\n            e->energy_vector[i] = sum;\n\n    }\n\n\n\n    if (fabs(e->pitch_delay - e->prev_pitch_delay) > 15)\n\n        e->prev_pitch_delay = e->pitch_delay;\n\n\n\n    for (i = 0; i < NB_SUBFRAMES; i++) {\n\n        int subframe_size = subframe_sizes[i];\n\n        int pitch_lag;\n\n\n\n        interpolate_lsp(ilspf, e->lspf, e->prev_lspf, i);\n\n\n\n        if (e->bitrate != RATE_QUANT) {\n\n            if (e->avg_acb_gain < 0.3) {\n\n                idelay[0] = estimation_delay[i];\n\n                idelay[1] = estimation_delay[i + 1];\n\n                idelay[2] = estimation_delay[i + 2];\n\n            } else {\n\n                interpolate_delay(idelay, e->pitch_delay, e->prev_pitch_delay, i);\n\n            }\n\n        }\n\n\n\n        pitch_lag = lrintf((idelay[1] + idelay[0]) / 2.0);\n\n        decode_predictor_coeffs(ilspf, ilpc);\n\n\n\n        if (e->bitrate != RATE_QUANT) {\n\n            acb_excitation(e, e->pitch + ACB_SIZE,\n\n                           e->avg_acb_gain, idelay, subframe_size);\n\n            for (j = 0; j < subframe_size; j++)\n\n                e->pitch[ACB_SIZE + j] *= e->fade_scale;\n\n            e->fade_scale = FFMAX(e->fade_scale - 0.05, 0.0);\n\n        } else {\n\n            for (j = 0; j < subframe_size; j++)\n\n                e->pitch[ACB_SIZE + j] = e->energy_vector[i];\n\n        }\n\n\n\n        memcpy(e->pitch, e->pitch + subframe_size, ACB_SIZE * sizeof(float));\n\n\n\n        if (e->bitrate != RATE_QUANT && e->avg_acb_gain < 0.4) {\n\n            f = 0.1 * e->avg_fcb_gain;\n\n            for (j = 0; j < subframe_size; j++)\n\n                e->pitch[ACB_SIZE + j] += f;\n\n        } else if (e->bitrate == RATE_QUANT) {\n\n            for (j = 0; j < subframe_size; j++)\n\n                e->pitch[ACB_SIZE + j] = e->energy_vector[i];\n\n        }\n\n\n\n        synthesis_filter(e->pitch + ACB_SIZE, ilpc,\n\n                         e->synthesis, subframe_size, tmp);\n\n        postfilter(e, tmp, ilpc, samples, pitch_lag,\n\n                   &postfilter_coeffs[e->bitrate], subframe_size);\n\n\n\n        samples += subframe_size;\n\n    }\n\n}\n", "idx": 2431, "_split": "valid", "_hash": "875554b9cb48b73e7e79ff53a3e5b972"}
{"project": "FFmpeg", "commit_id": "770c934fa1635f4fadf5db4fc5cc5ad15d82455a", "target": 1, "func": "void ff_mdct_calcw_c(FFTContext *s, FFTDouble *out, const FFTSample *input)\n\n{\n\n    int i, j, n, n8, n4, n2, n3;\n\n    FFTDouble re, im;\n\n    const uint16_t *revtab = s->revtab;\n\n    const FFTSample *tcos = s->tcos;\n\n    const FFTSample *tsin = s->tsin;\n\n    FFTComplex *x = s->tmp_buf;\n\n    FFTDComplex *o = (FFTDComplex *)out;\n\n\n\n    n = 1 << s->mdct_bits;\n\n    n2 = n >> 1;\n\n    n4 = n >> 2;\n\n    n8 = n >> 3;\n\n    n3 = 3 * n4;\n\n\n\n    /* pre rotation */\n\n    for(i=0;i<n8;i++) {\n\n        re = RSCALE(-input[2*i+n3] - input[n3-1-2*i]);\n\n        im = RSCALE(-input[n4+2*i] + input[n4-1-2*i]);\n\n        j = revtab[i];\n\n        CMUL(x[j].re, x[j].im, re, im, -tcos[i], tsin[i]);\n\n\n\n        re = RSCALE( input[2*i]    - input[n2-1-2*i]);\n\n        im = RSCALE(-input[n2+2*i] - input[ n-1-2*i]);\n\n        j = revtab[n8 + i];\n\n        CMUL(x[j].re, x[j].im, re, im, -tcos[n8 + i], tsin[n8 + i]);\n\n    }\n\n\n\n    s->fft_calc(s, x);\n\n\n\n    /* post rotation */\n\n    for(i=0;i<n8;i++) {\n\n        FFTDouble r0, i0, r1, i1;\n\n        CMULL(i1, r0, x[n8-i-1].re, x[n8-i-1].im, -tsin[n8-i-1], -tcos[n8-i-1]);\n\n        CMULL(i0, r1, x[n8+i  ].re, x[n8+i  ].im, -tsin[n8+i  ], -tcos[n8+i  ]);\n\n        o[n8-i-1].re = r0;\n\n        o[n8-i-1].im = i0;\n\n        o[n8+i  ].re = r1;\n\n        o[n8+i  ].im = i1;\n\n    }\n\n}\n", "idx": 2450, "_split": "valid", "_hash": "e96007c9afa4f305944b3c13be28f34f"}
{"project": "FFmpeg", "commit_id": "7c7e7464e3f49e9a1fa98b06c4261e75ce71290b", "target": 1, "func": "static int mmap_read_frame(struct video_data *s, void *frame, int64_t *ts)\n\n{\n\n    struct v4l2_buffer buf;\n\n    int res;\n\n\n\n    memset(&buf, 0, sizeof(struct v4l2_buffer));\n\n    buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;\n\n    buf.memory = V4L2_MEMORY_MMAP;\n\n\n\n    /* FIXME: Some special treatment might be needed in case of loss of signal... */\n\n    while ((res = ioctl(s->fd, VIDIOC_DQBUF, &buf)) < 0 &&\n\n           ((errno == EAGAIN) || (errno == EINTR)));\n\n    if (res < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"ioctl(VIDIOC_DQBUF): %s\\n\", strerror(errno));\n\n\n\n        return -1;\n\n    }\n\n    assert (buf.index < s->buffers);\n\n    assert(buf.bytesused == s->frame_size);\n\n    /* Image is at s->buff_start[buf.index] */\n\n    memcpy(frame, s->buf_start[buf.index], buf.bytesused);\n\n    *ts = buf.timestamp.tv_sec * int64_t_C(1000000) + buf.timestamp.tv_usec;\n\n\n\n    res = ioctl (s->fd, VIDIOC_QBUF, &buf);\n\n    if (res < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"ioctl(VIDIOC_QBUF)\\n\");\n\n\n\n        return -1;\n\n    }\n\n\n\n    return s->buf_len[buf.index];\n\n}\n", "idx": 2496, "_split": "valid", "_hash": "684d4c15b456ce2e1c5ecf9dcf75f69e"}
{"project": "FFmpeg", "commit_id": "e549933a270dd2cfc36f2cf9bb6b29acf3dc6d08", "target": 0, "func": "static void avc_luma_midh_qrt_4w_msa(const uint8_t *src, int32_t src_stride,\n\n                                     uint8_t *dst, int32_t dst_stride,\n\n                                     int32_t height, uint8_t horiz_offset)\n\n{\n\n    uint32_t row;\n\n    v16i8 src0, src1, src2, src3, src4, src5, src6;\n\n    v8i16 vt_res0, vt_res1, vt_res2, vt_res3;\n\n    v4i32 hz_res0, hz_res1;\n\n    v8i16 dst0, dst1;\n\n    v8i16 shf_vec0, shf_vec1, shf_vec2, shf_vec3, shf_vec4, shf_vec5;\n\n    v8i16 mask0 = { 0, 5, 1, 6, 2, 7, 3, 8 };\n\n    v8i16 mask1 = { 1, 4, 2, 5, 3, 6, 4, 7 };\n\n    v8i16 mask2 = { 2, 3, 3, 4, 4, 5, 5, 6 };\n\n    v8i16 minus5h = __msa_ldi_h(-5);\n\n    v8i16 plus20h = __msa_ldi_h(20);\n\n    v8i16 zeros = { 0 };\n\n    v16u8 out;\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n\n\n    for (row = (height >> 1); row--;) {\n\n        LD_SB2(src, src_stride, src5, src6);\n\n        src += (2 * src_stride);\n\n\n\n        XORI_B2_128_SB(src5, src6);\n\n        AVC_CALC_DPADD_B_6PIX_2COEFF_SH(src0, src1, src2, src3, src4, src5,\n\n                                        vt_res0, vt_res1);\n\n        AVC_CALC_DPADD_B_6PIX_2COEFF_SH(src1, src2, src3, src4, src5, src6,\n\n                                        vt_res2, vt_res3);\n\n        VSHF_H3_SH(vt_res0, vt_res1, vt_res0, vt_res1, vt_res0, vt_res1,\n\n                   mask0, mask1, mask2, shf_vec0, shf_vec1, shf_vec2);\n\n        VSHF_H3_SH(vt_res2, vt_res3, vt_res2, vt_res3, vt_res2, vt_res3,\n\n                   mask0, mask1, mask2, shf_vec3, shf_vec4, shf_vec5);\n\n        hz_res0 = __msa_hadd_s_w(shf_vec0, shf_vec0);\n\n        DPADD_SH2_SW(shf_vec1, shf_vec2, minus5h, plus20h, hz_res0, hz_res0);\n\n        hz_res1 = __msa_hadd_s_w(shf_vec3, shf_vec3);\n\n        DPADD_SH2_SW(shf_vec4, shf_vec5, minus5h, plus20h, hz_res1, hz_res1);\n\n\n\n        SRARI_W2_SW(hz_res0, hz_res1, 10);\n\n        SAT_SW2_SW(hz_res0, hz_res1, 7);\n\n\n\n        dst0 = __msa_srari_h(shf_vec2, 5);\n\n        dst1 = __msa_srari_h(shf_vec5, 5);\n\n\n\n        SAT_SH2_SH(dst0, dst1, 7);\n\n\n\n        if (horiz_offset) {\n\n            dst0 = __msa_ilvod_h(zeros, dst0);\n\n            dst1 = __msa_ilvod_h(zeros, dst1);\n\n        } else {\n\n            ILVEV_H2_SH(dst0, zeros, dst1, zeros, dst0, dst1);\n\n        }\n\n\n\n        hz_res0 = __msa_aver_s_w(hz_res0, (v4i32) dst0);\n\n        hz_res1 = __msa_aver_s_w(hz_res1, (v4i32) dst1);\n\n        dst0 = __msa_pckev_h((v8i16) hz_res1, (v8i16) hz_res0);\n\n\n\n        out = PCKEV_XORI128_UB(dst0, dst0);\n\n        ST4x2_UB(out, dst, dst_stride);\n\n\n\n        dst += (2 * dst_stride);\n\n\n\n        src0 = src2;\n\n        src1 = src3;\n\n        src2 = src4;\n\n        src3 = src5;\n\n        src4 = src6;\n\n    }\n\n}\n", "idx": 2503, "_split": "valid", "_hash": "6c8516a2830be6d5bb39e0df01240ae0"}
{"project": "FFmpeg", "commit_id": "fe66671bd5f446f8d0a9c70968ba8fe891efe028", "target": 0, "func": "static void print_codec(const AVCodec *c)\n\n{\n\n    int encoder = av_codec_is_encoder(c);\n\n\n\n    printf(\"%s %s [%s]:\\n\", encoder ? \"Encoder\" : \"Decoder\", c->name,\n\n           c->long_name ? c->long_name : \"\");\n\n\n\n    printf(\"    General capabilities: \");\n\n    if (c->capabilities & AV_CODEC_CAP_DRAW_HORIZ_BAND)\n\n        printf(\"horizband \");\n\n    if (c->capabilities & AV_CODEC_CAP_DR1)\n\n        printf(\"dr1 \");\n\n    if (c->capabilities & AV_CODEC_CAP_TRUNCATED)\n\n        printf(\"trunc \");\n\n    if (c->capabilities & AV_CODEC_CAP_DELAY)\n\n        printf(\"delay \");\n\n    if (c->capabilities & AV_CODEC_CAP_SMALL_LAST_FRAME)\n\n        printf(\"small \");\n\n    if (c->capabilities & AV_CODEC_CAP_SUBFRAMES)\n\n        printf(\"subframes \");\n\n    if (c->capabilities & AV_CODEC_CAP_EXPERIMENTAL)\n\n        printf(\"exp \");\n\n    if (c->capabilities & AV_CODEC_CAP_CHANNEL_CONF)\n\n        printf(\"chconf \");\n\n    if (c->capabilities & AV_CODEC_CAP_PARAM_CHANGE)\n\n        printf(\"small \");\n\n    if (c->capabilities & AV_CODEC_CAP_PARAM_CHANGE)\n\n        printf(\"variable \");\n\n    if (c->capabilities & (AV_CODEC_CAP_FRAME_THREADS |\n\n                           AV_CODEC_CAP_SLICE_THREADS |\n\n                           AV_CODEC_CAP_AUTO_THREADS))\n\n        printf(\"threads \");\n\n    if (!c->capabilities)\n\n        printf(\"none\");\n\n    printf(\"\\n\");\n\n\n\n    if (c->type == AVMEDIA_TYPE_VIDEO) {\n\n        printf(\"    Threading capabilities: \");\n\n        switch (c->capabilities & (AV_CODEC_CAP_FRAME_THREADS |\n\n                                   AV_CODEC_CAP_SLICE_THREADS |\n\n                                   AV_CODEC_CAP_AUTO_THREADS)) {\n\n        case AV_CODEC_CAP_FRAME_THREADS |\n\n             AV_CODEC_CAP_SLICE_THREADS: printf(\"frame and slice\"); break;\n\n        case AV_CODEC_CAP_FRAME_THREADS: printf(\"frame\");           break;\n\n        case AV_CODEC_CAP_SLICE_THREADS: printf(\"slice\");           break;\n\n        case AV_CODEC_CAP_AUTO_THREADS : printf(\"auto\");            break;\n\n        default:                         printf(\"none\");            break;\n\n        }\n\n        printf(\"\\n\");\n\n    }\n\n\n\n    if (c->supported_framerates) {\n\n        const AVRational *fps = c->supported_framerates;\n\n\n\n        printf(\"    Supported framerates:\");\n\n        while (fps->num) {\n\n            printf(\" %d/%d\", fps->num, fps->den);\n\n            fps++;\n\n        }\n\n        printf(\"\\n\");\n\n    }\n\n    PRINT_CODEC_SUPPORTED(c, pix_fmts, enum AVPixelFormat, \"pixel formats\",\n\n                          AV_PIX_FMT_NONE, GET_PIX_FMT_NAME);\n\n    PRINT_CODEC_SUPPORTED(c, supported_samplerates, int, \"sample rates\", 0,\n\n                          GET_SAMPLE_RATE_NAME);\n\n    PRINT_CODEC_SUPPORTED(c, sample_fmts, enum AVSampleFormat, \"sample formats\",\n\n                          AV_SAMPLE_FMT_NONE, GET_SAMPLE_FMT_NAME);\n\n    PRINT_CODEC_SUPPORTED(c, channel_layouts, uint64_t, \"channel layouts\",\n\n                          0, GET_CH_LAYOUT_DESC);\n\n\n\n    if (c->priv_class) {\n\n        show_help_children(c->priv_class,\n\n                           AV_OPT_FLAG_ENCODING_PARAM |\n\n                           AV_OPT_FLAG_DECODING_PARAM);\n\n    }\n\n}\n", "idx": 2609, "_split": "valid", "_hash": "73eae2298b3ed45eada584ff1d3fabcc"}
{"project": "FFmpeg", "commit_id": "f4ebbda566f73952a721c367877b1527ba697e7a", "target": 1, "func": "static int init_processing_chain(AVFilterContext *ctx, int in_width, int in_height,\n\n                                 int out_width, int out_height)\n\n{\n\n    NPPScaleContext *s = ctx->priv;\n\n\n\n    AVHWFramesContext *in_frames_ctx;\n\n\n\n    enum AVPixelFormat in_format;\n\n    enum AVPixelFormat out_format;\n\n    enum AVPixelFormat in_deinterleaved_format;\n\n    enum AVPixelFormat out_deinterleaved_format;\n\n\n\n    int i, ret, last_stage = -1;\n\n\n\n    /* check that we have a hw context */\n\n    if (!ctx->inputs[0]->hw_frames_ctx) {\n\n        av_log(ctx, AV_LOG_ERROR, \"No hw context provided on input\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    in_frames_ctx = (AVHWFramesContext*)ctx->inputs[0]->hw_frames_ctx->data;\n\n    in_format     = in_frames_ctx->sw_format;\n\n    out_format    = (s->format == AV_PIX_FMT_NONE) ? in_format : s->format;\n\n\n\n    if (!format_is_supported(in_format)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Unsupported input format: %s\\n\",\n\n               av_get_pix_fmt_name(in_format));\n\n        return AVERROR(ENOSYS);\n\n    }\n\n    if (!format_is_supported(out_format)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Unsupported output format: %s\\n\",\n\n               av_get_pix_fmt_name(out_format));\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    in_deinterleaved_format  = get_deinterleaved_format(in_format);\n\n    out_deinterleaved_format = get_deinterleaved_format(out_format);\n\n    if (in_deinterleaved_format  == AV_PIX_FMT_NONE ||\n\n        out_deinterleaved_format == AV_PIX_FMT_NONE)\n\n        return AVERROR_BUG;\n\n\n\n    /* figure out which stages need to be done */\n\n    if (in_width != out_width || in_height != out_height ||\n\n        in_deinterleaved_format != out_deinterleaved_format) {\n\n        s->stages[STAGE_RESIZE].stage_needed = 1;\n\n\n\n        if (s->interp_algo == NPPI_INTER_SUPER &&\n\n            (out_width > in_width && out_height > in_height)) {\n\n            s->interp_algo = NPPI_INTER_LANCZOS;\n\n            av_log(ctx, AV_LOG_WARNING, \"super-sampling not supported for output dimensions, using lanczos instead.\\n\");\n\n        }\n\n        if (s->interp_algo == NPPI_INTER_SUPER &&\n\n            !(out_width < in_width && out_height < in_height)) {\n\n            s->interp_algo = NPPI_INTER_CUBIC;\n\n            av_log(ctx, AV_LOG_WARNING, \"super-sampling not supported for output dimensions, using cubic instead.\\n\");\n\n        }\n\n    }\n\n\n\n    if (!s->stages[STAGE_RESIZE].stage_needed && in_format == out_format)\n\n        s->passthrough = 1;\n\n\n\n    if (!s->passthrough) {\n\n        if (in_format != in_deinterleaved_format)\n\n            s->stages[STAGE_DEINTERLEAVE].stage_needed = 1;\n\n        if (out_format != out_deinterleaved_format)\n\n            s->stages[STAGE_INTERLEAVE].stage_needed = 1;\n\n    }\n\n\n\n    s->stages[STAGE_DEINTERLEAVE].in_fmt              = in_format;\n\n    s->stages[STAGE_DEINTERLEAVE].out_fmt             = in_deinterleaved_format;\n\n    s->stages[STAGE_DEINTERLEAVE].planes_in[0].width  = in_width;\n\n    s->stages[STAGE_DEINTERLEAVE].planes_in[0].height = in_height;\n\n\n\n    s->stages[STAGE_RESIZE].in_fmt               = in_deinterleaved_format;\n\n    s->stages[STAGE_RESIZE].out_fmt              = out_deinterleaved_format;\n\n    s->stages[STAGE_RESIZE].planes_in[0].width   = in_width;\n\n    s->stages[STAGE_RESIZE].planes_in[0].height  = in_height;\n\n    s->stages[STAGE_RESIZE].planes_out[0].width  = out_width;\n\n    s->stages[STAGE_RESIZE].planes_out[0].height = out_height;\n\n\n\n    s->stages[STAGE_INTERLEAVE].in_fmt              = out_deinterleaved_format;\n\n    s->stages[STAGE_INTERLEAVE].out_fmt             = out_format;\n\n    s->stages[STAGE_INTERLEAVE].planes_in[0].width  = out_width;\n\n    s->stages[STAGE_INTERLEAVE].planes_in[0].height = out_height;\n\n\n\n    /* init the hardware contexts */\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->stages); i++) {\n\n        if (!s->stages[i].stage_needed)\n\n            continue;\n\n\n\n        ret = init_stage(&s->stages[i], in_frames_ctx->device_ref);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        last_stage = i;\n\n    }\n\n\n\n    if (last_stage < 0)\n\n    {\n\n        ctx->outputs[0]->hw_frames_ctx = av_buffer_ref(ctx->inputs[0]->hw_frames_ctx);\n\n        return 0;\n\n    }\n\n\n\n    ctx->outputs[0]->hw_frames_ctx = av_buffer_ref(s->stages[last_stage].frames_ctx);\n\n    if (!ctx->outputs[0]->hw_frames_ctx)\n\n        return AVERROR(ENOMEM);\n\n\n\n    return 0;\n\n}\n", "idx": 2671, "_split": "valid", "_hash": "49f01c6c7134ab707095d4e61d8a2758"}
{"project": "FFmpeg", "commit_id": "4cd0bdae9a62d1f0366e60603222762af31e5289", "target": 1, "func": "static int read_uncompressed_sgi(unsigned char* out_buf, uint8_t* out_end,\n\n                const uint8_t *in_buf, const uint8_t *in_end, SgiState* s)\n\n{\n\n    int x, y, z;\n\n    const uint8_t *ptr;\n\n    unsigned int offset = s->height * s->width * s->bytes_per_channel;\n\n\n\n    /* Test buffer size. */\n\n    if (offset * s->depth > in_end - in_buf) {\n\n       return -1;\n\n    }\n\n\n\n    for (y = s->height - 1; y >= 0; y--) {\n\n        out_end = out_buf + (y * s->linesize);\n\n        for (x = s->width; x > 0; x--) {\n\n            ptr = in_buf += s->bytes_per_channel;\n\n            for(z = 0; z < s->depth; z ++) {\n\n                memcpy(out_end, ptr, s->bytes_per_channel);\n\n                out_end += s->bytes_per_channel;\n\n                ptr += offset;\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 2676, "_split": "valid", "_hash": "f8f298eef9f32382a4be0172a694bbfa"}
{"project": "FFmpeg", "commit_id": "8cb7b7b461b52898765b38e3eff68c0ce88347f3", "target": 1, "func": "int ff_mov_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    MOVMuxContext *mov = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    MOVTrack *trk = &mov->tracks[pkt->stream_index];\n\n    AVCodecContext *enc = trk->enc;\n\n    unsigned int samples_in_chunk = 0;\n\n    int size = pkt->size;\n\n    uint8_t *reformatted_data = NULL;\n\n\n\n    if (mov->flags & FF_MOV_FLAG_FRAGMENT) {\n\n        int ret;\n\n        if (mov->fragments > 0) {\n\n            if (!trk->mdat_buf) {\n\n                if ((ret = avio_open_dyn_buf(&trk->mdat_buf)) < 0)\n\n                    return ret;\n\n            }\n\n            pb = trk->mdat_buf;\n\n        } else {\n\n            if (!mov->mdat_buf) {\n\n                if ((ret = avio_open_dyn_buf(&mov->mdat_buf)) < 0)\n\n                    return ret;\n\n            }\n\n            pb = mov->mdat_buf;\n\n        }\n\n    }\n\n\n\n    if (enc->codec_id == AV_CODEC_ID_AMR_NB) {\n\n        /* We must find out how many AMR blocks there are in one packet */\n\n        static uint16_t packed_size[16] =\n\n            {13, 14, 16, 18, 20, 21, 27, 32, 6, 0, 0, 0, 0, 0, 0, 1};\n\n        int len = 0;\n\n\n\n        while (len < size && samples_in_chunk < 100) {\n\n            len += packed_size[(pkt->data[len] >> 3) & 0x0F];\n\n            samples_in_chunk++;\n\n        }\n\n        if (samples_in_chunk > 1) {\n\n            av_log(s, AV_LOG_ERROR, \"fatal error, input is not a single packet, implement a AVParser for it\\n\");\n\n            return -1;\n\n        }\n\n    } else if (trk->sample_size)\n\n        samples_in_chunk = size / trk->sample_size;\n\n    else\n\n        samples_in_chunk = 1;\n\n\n\n    /* copy extradata if it exists */\n\n    if (trk->vos_len == 0 && enc->extradata_size > 0) {\n\n        trk->vos_len  = enc->extradata_size;\n\n        trk->vos_data = av_malloc(trk->vos_len);\n\n        memcpy(trk->vos_data, enc->extradata, trk->vos_len);\n\n    }\n\n\n\n    if (enc->codec_id == AV_CODEC_ID_H264 && trk->vos_len > 0 && *(uint8_t *)trk->vos_data != 1) {\n\n        /* from x264 or from bytestream h264 */\n\n        /* nal reformating needed */\n\n        if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams) {\n\n            ff_avc_parse_nal_units_buf(pkt->data, &reformatted_data,\n\n                                       &size);\n\n            avio_write(pb, reformatted_data, size);\n\n        } else {\n\n            size = ff_avc_parse_nal_units(pb, pkt->data, pkt->size);\n\n        }\n\n    } else if (enc->codec_id == AV_CODEC_ID_HEVC && trk->vos_len > 6 &&\n\n               (AV_RB24(trk->vos_data) == 1 || AV_RB32(trk->vos_data) == 1)) {\n\n        /* extradata is Annex B, assume the bitstream is too and convert it */\n\n        if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams) {\n\n            ff_hevc_annexb2mp4_buf(pkt->data, &reformatted_data, &size, 0, NULL);\n\n            avio_write(pb, reformatted_data, size);\n\n        } else {\n\n            size = ff_hevc_annexb2mp4(pb, pkt->data, pkt->size, 0, NULL);\n\n        }\n\n    } else {\n\n        avio_write(pb, pkt->data, size);\n\n    }\n\n\n\n    if ((enc->codec_id == AV_CODEC_ID_DNXHD ||\n\n         enc->codec_id == AV_CODEC_ID_AC3) && !trk->vos_len) {\n\n        /* copy frame to create needed atoms */\n\n        trk->vos_len  = size;\n\n        trk->vos_data = av_malloc(size);\n\n        if (!trk->vos_data)\n\n            return AVERROR(ENOMEM);\n\n        memcpy(trk->vos_data, pkt->data, size);\n\n    }\n\n\n\n    if (trk->entry >= trk->cluster_capacity) {\n\n        unsigned new_capacity = 2 * (trk->entry + MOV_INDEX_CLUSTER_SIZE);\n\n        if (av_reallocp_array(&trk->cluster, new_capacity,\n\n                              sizeof(*trk->cluster)))\n\n            return AVERROR(ENOMEM);\n\n        trk->cluster_capacity = new_capacity;\n\n    }\n\n\n\n    trk->cluster[trk->entry].pos              = avio_tell(pb) - size;\n\n    trk->cluster[trk->entry].samples_in_chunk = samples_in_chunk;\n\n    trk->cluster[trk->entry].size             = size;\n\n    trk->cluster[trk->entry].entries          = samples_in_chunk;\n\n    trk->cluster[trk->entry].dts              = pkt->dts;\n\n    if (!trk->entry && trk->start_dts != AV_NOPTS_VALUE) {\n\n        /* First packet of a new fragment. We already wrote the duration\n\n         * of the last packet of the previous fragment based on track_duration,\n\n         * which might not exactly match our dts. Therefore adjust the dts\n\n         * of this packet to be what the previous packets duration implies. */\n\n        trk->cluster[trk->entry].dts = trk->start_dts + trk->track_duration;\n\n    }\n\n    if (!trk->entry && trk->start_dts == AV_NOPTS_VALUE && !mov->use_editlist &&\n\n        s->avoid_negative_ts == AVFMT_AVOID_NEG_TS_MAKE_ZERO) {\n\n        /* Not using edit lists and shifting the first track to start from zero.\n\n         * If the other streams start from a later timestamp, we won't be able\n\n         * to signal the difference in starting time without an edit list.\n\n         * Thus move the timestamp for this first sample to 0, increasing\n\n         * its duration instead. */\n\n        trk->cluster[trk->entry].dts = trk->start_dts = 0;\n\n    }\n\n    if (trk->start_dts == AV_NOPTS_VALUE) {\n\n        trk->start_dts = pkt->dts;\n\n        if (pkt->dts && mov->flags & FF_MOV_FLAG_EMPTY_MOOV)\n\n            av_log(s, AV_LOG_WARNING,\n\n                   \"Track %d starts with a nonzero dts %\"PRId64\". This \"\n\n                   \"currently isn't handled correctly in combination with \"\n\n                   \"empty_moov.\\n\", pkt->stream_index, pkt->dts);\n\n    }\n\n    trk->track_duration = pkt->dts - trk->start_dts + pkt->duration;\n\n\n\n    if (pkt->pts == AV_NOPTS_VALUE) {\n\n        av_log(s, AV_LOG_WARNING, \"pts has no value\\n\");\n\n        pkt->pts = pkt->dts;\n\n    }\n\n    if (pkt->dts != pkt->pts)\n\n        trk->flags |= MOV_TRACK_CTTS;\n\n    trk->cluster[trk->entry].cts   = pkt->pts - pkt->dts;\n\n    trk->cluster[trk->entry].flags = 0;\n\n    if (enc->codec_id == AV_CODEC_ID_VC1) {\n\n        mov_parse_vc1_frame(pkt, trk, mov->fragments);\n\n    } else if (pkt->flags & AV_PKT_FLAG_KEY) {\n\n        if (mov->mode == MODE_MOV && enc->codec_id == AV_CODEC_ID_MPEG2VIDEO &&\n\n            trk->entry > 0) { // force sync sample for the first key frame\n\n            mov_parse_mpeg2_frame(pkt, &trk->cluster[trk->entry].flags);\n\n            if (trk->cluster[trk->entry].flags & MOV_PARTIAL_SYNC_SAMPLE)\n\n                trk->flags |= MOV_TRACK_STPS;\n\n        } else {\n\n            trk->cluster[trk->entry].flags = MOV_SYNC_SAMPLE;\n\n        }\n\n        if (trk->cluster[trk->entry].flags & MOV_SYNC_SAMPLE)\n\n            trk->has_keyframes++;\n\n    }\n\n    trk->entry++;\n\n    trk->sample_count += samples_in_chunk;\n\n    mov->mdat_size    += size;\n\n\n\n    if (trk->hint_track >= 0 && trk->hint_track < mov->nb_streams)\n\n        ff_mov_add_hinted_packet(s, pkt, trk->hint_track, trk->entry,\n\n                                 reformatted_data, size);\n\n    av_free(reformatted_data);\n\n    return 0;\n\n}\n", "idx": 2681, "_split": "valid", "_hash": "aa4b06606280235fe090204ee941627d"}
{"project": "FFmpeg", "commit_id": "398f015f077c6a2406deffd9e37ff34b9c7bb3bc", "target": 0, "func": "static void do_video_out(AVFormatContext *s,\n\n                         OutputStream *ost,\n\n                         AVFrame *in_picture,\n\n                         int *frame_size)\n\n{\n\n    int ret, format_video_sync;\n\n    AVPacket pkt;\n\n    AVCodecContext *enc = ost->enc_ctx;\n\n\n\n    *frame_size = 0;\n\n\n\n    format_video_sync = video_sync_method;\n\n    if (format_video_sync == VSYNC_AUTO)\n\n        format_video_sync = (s->oformat->flags & AVFMT_NOTIMESTAMPS) ? VSYNC_PASSTHROUGH :\n\n                            (s->oformat->flags & AVFMT_VARIABLE_FPS) ? VSYNC_VFR : VSYNC_CFR;\n\n    if (format_video_sync != VSYNC_PASSTHROUGH &&\n\n        ost->frame_number &&\n\n        in_picture->pts != AV_NOPTS_VALUE &&\n\n        in_picture->pts < ost->sync_opts) {\n\n        nb_frames_drop++;\n\n        av_log(NULL, AV_LOG_WARNING,\n\n               \"*** dropping frame %d from stream %d at ts %\"PRId64\"\\n\",\n\n               ost->frame_number, ost->st->index, in_picture->pts);\n\n        return;\n\n    }\n\n\n\n    if (in_picture->pts == AV_NOPTS_VALUE)\n\n        in_picture->pts = ost->sync_opts;\n\n    ost->sync_opts = in_picture->pts;\n\n\n\n\n\n    if (!ost->frame_number)\n\n        ost->first_pts = in_picture->pts;\n\n\n\n    av_init_packet(&pkt);\n\n    pkt.data = NULL;\n\n    pkt.size = 0;\n\n\n\n    if (ost->frame_number >= ost->max_frames)\n\n        return;\n\n\n\n    if (enc->flags & (AV_CODEC_FLAG_INTERLACED_DCT | AV_CODEC_FLAG_INTERLACED_ME) &&\n\n        ost->top_field_first >= 0)\n\n        in_picture->top_field_first = !!ost->top_field_first;\n\n\n\n    in_picture->quality = enc->global_quality;\n\n    in_picture->pict_type = 0;\n\n    if (ost->forced_kf_index < ost->forced_kf_count &&\n\n        in_picture->pts >= ost->forced_kf_pts[ost->forced_kf_index]) {\n\n        in_picture->pict_type = AV_PICTURE_TYPE_I;\n\n        ost->forced_kf_index++;\n\n    }\n\n\n\n    ost->frames_encoded++;\n\n\n\n    ret = avcodec_send_frame(enc, in_picture);\n\n    if (ret < 0)\n\n        goto error;\n\n\n\n    /*\n\n     * For video, there may be reordering, so we can't throw away frames on\n\n     * encoder flush, we need to limit them here, before they go into encoder.\n\n     */\n\n    ost->frame_number++;\n\n\n\n    while (1) {\n\n        ret = avcodec_receive_packet(enc, &pkt);\n\n        if (ret == AVERROR(EAGAIN))\n\n            break;\n\n        if (ret < 0)\n\n            goto error;\n\n\n\n        av_packet_rescale_ts(&pkt, enc->time_base, ost->st->time_base);\n\n        output_packet(s, &pkt, ost);\n\n        *frame_size = pkt.size;\n\n\n\n        /* if two pass, output log */\n\n        if (ost->logfile && enc->stats_out) {\n\n            fprintf(ost->logfile, \"%s\", enc->stats_out);\n\n        }\n\n\n\n        ost->sync_opts++;\n\n    }\n\n\n\n    return;\n\nerror:\n\n    av_assert0(ret != AVERROR(EAGAIN) && ret != AVERROR_EOF);\n\n    av_log(NULL, AV_LOG_FATAL, \"Video encoding failed\\n\");\n\n    exit_program(1);\n\n}\n", "idx": 2753, "_split": "valid", "_hash": "4baa975ac01586e32eebfbe0767f7ecb"}
{"project": "FFmpeg", "commit_id": "53c8443ad2376a50c76e5d7c69435bd01b0abc42", "target": 0, "func": "static int decode_frame_mp3on4(AVCodecContext * avctx,\n\n                        void *data, int *data_size,\n\n                        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MP3On4DecodeContext *s = avctx->priv_data;\n\n    MPADecodeContext *m;\n\n    int fsize, len = buf_size, out_size = 0;\n\n    uint32_t header;\n\n    OUT_INT *out_samples = data;\n\n    OUT_INT *outptr, *bp;\n\n    int fr, j, n;\n\n\n\n    if(*data_size < MPA_FRAME_SIZE * MPA_MAX_CHANNELS * s->frames * sizeof(OUT_INT))\n\n        return -1;\n\n\n\n    *data_size = 0;\n\n    // Discard too short frames\n\n    if (buf_size < HEADER_SIZE)\n\n        return -1;\n\n\n\n    // If only one decoder interleave is not needed\n\n    outptr = s->frames == 1 ? out_samples : s->decoded_buf;\n\n\n\n    avctx->bit_rate = 0;\n\n\n\n    for (fr = 0; fr < s->frames; fr++) {\n\n        fsize = AV_RB16(buf) >> 4;\n\n        fsize = FFMIN3(fsize, len, MPA_MAX_CODED_FRAME_SIZE);\n\n        m = s->mp3decctx[fr];\n\n        assert (m != NULL);\n\n\n\n        header = (AV_RB32(buf) & 0x000fffff) | s->syncword; // patch header\n\n\n\n        if (ff_mpa_check_header(header) < 0) // Bad header, discard block\n\n            break;\n\n\n\n        avpriv_mpegaudio_decode_header((MPADecodeHeader *)m, header);\n\n        out_size += mp_decode_frame(m, outptr, buf, fsize);\n\n        buf += fsize;\n\n        len -= fsize;\n\n\n\n        if(s->frames > 1) {\n\n            n = m->avctx->frame_size*m->nb_channels;\n\n            /* interleave output data */\n\n            bp = out_samples + s->coff[fr];\n\n            if(m->nb_channels == 1) {\n\n                for(j = 0; j < n; j++) {\n\n                    *bp = s->decoded_buf[j];\n\n                    bp += avctx->channels;\n\n                }\n\n            } else {\n\n                for(j = 0; j < n; j++) {\n\n                    bp[0] = s->decoded_buf[j++];\n\n                    bp[1] = s->decoded_buf[j];\n\n                    bp += avctx->channels;\n\n                }\n\n            }\n\n        }\n\n        avctx->bit_rate += m->bit_rate;\n\n    }\n\n\n\n    /* update codec info */\n\n    avctx->sample_rate = s->mp3decctx[0]->sample_rate;\n\n\n\n    *data_size = out_size;\n\n    return buf_size;\n\n}\n", "idx": 2789, "_split": "valid", "_hash": "e5d2760fe004e6d218451159cbce53f8"}
{"project": "FFmpeg", "commit_id": "46428ea332d8afa3f598d6a9d660716a4f90da6d", "target": 1, "func": "int ff_mpv_common_frame_size_change(MpegEncContext *s)\n\n{\n\n    int i, err = 0;\n\n\n\n    if (!s->context_initialized)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (s->slice_context_count > 1) {\n\n        for (i = 0; i < s->slice_context_count; i++) {\n\n            free_duplicate_context(s->thread_context[i]);\n\n        }\n\n        for (i = 1; i < s->slice_context_count; i++) {\n\n            av_freep(&s->thread_context[i]);\n\n        }\n\n    } else\n\n        free_duplicate_context(s);\n\n\n\n    free_context_frame(s);\n\n\n\n    if (s->picture)\n\n        for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n                s->picture[i].needs_realloc = 1;\n\n        }\n\n\n\n    s->last_picture_ptr         =\n\n    s->next_picture_ptr         =\n\n    s->current_picture_ptr      = NULL;\n\n\n\n    // init\n\n    if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO && !s->progressive_sequence)\n\n        s->mb_height = (s->height + 31) / 32 * 2;\n\n    else\n\n        s->mb_height = (s->height + 15) / 16;\n\n\n\n    if ((s->width || s->height) &&\n\n        (err = av_image_check_size(s->width, s->height, 0, s->avctx)) < 0)\n\n        goto fail;\n\n\n\n    if ((err = init_context_frame(s)))\n\n        goto fail;\n\n\n\n    memset(s->thread_context, 0, sizeof(s->thread_context));\n\n    s->thread_context[0]   = s;\n\n\n\n    if (s->width && s->height) {\n\n        int nb_slices = s->slice_context_count;\n\n        if (nb_slices > 1) {\n\n            for (i = 0; i < nb_slices; i++) {\n\n                if (i) {\n\n                    s->thread_context[i] = av_malloc(sizeof(MpegEncContext));\n\n                    memcpy(s->thread_context[i], s, sizeof(MpegEncContext));\n\n                }\n\n                if ((err = init_duplicate_context(s->thread_context[i])) < 0)\n\n                    goto fail;\n\n                    s->thread_context[i]->start_mb_y =\n\n                        (s->mb_height * (i) + nb_slices / 2) / nb_slices;\n\n                    s->thread_context[i]->end_mb_y   =\n\n                        (s->mb_height * (i + 1) + nb_slices / 2) / nb_slices;\n\n            }\n\n        } else {\n\n            err = init_duplicate_context(s);\n\n            if (err < 0)\n\n                goto fail;\n\n            s->start_mb_y = 0;\n\n            s->end_mb_y   = s->mb_height;\n\n        }\n\n        s->slice_context_count = nb_slices;\n\n    }\n\n\n\n    return 0;\n\n fail:\n\n    ff_mpv_common_end(s);\n\n    return err;\n\n}\n", "idx": 2943, "_split": "valid", "_hash": "a38f67f17eddb137773fa31905ee3244"}
{"project": "FFmpeg", "commit_id": "debf4d6e67dfb29f3d71683add429c588828f8e8", "target": 0, "func": "static int dvbsub_parse_display_definition_segment(AVCodecContext *avctx,\n\n                                                   const uint8_t *buf,\n\n                                                   int buf_size)\n\n{\n\n    DVBSubContext *ctx = avctx->priv_data;\n\n    DVBSubDisplayDefinition *display_def = ctx->display_definition;\n\n    int dds_version, info_byte;\n\n\n\n    if (buf_size < 5)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    info_byte   = bytestream_get_byte(&buf);\n\n    dds_version = info_byte >> 4;\n\n    if (display_def && display_def->version == dds_version)\n\n        return 0; // already have this display definition version\n\n\n\n    if (!display_def) {\n\n        display_def             = av_mallocz(sizeof(*display_def));\n\n        if (!display_def)\n\n            return AVERROR(ENOMEM);\n\n        ctx->display_definition = display_def;\n\n    }\n\n\n\n    display_def->version = dds_version;\n\n    display_def->x       = 0;\n\n    display_def->y       = 0;\n\n    display_def->width   = bytestream_get_be16(&buf) + 1;\n\n    display_def->height  = bytestream_get_be16(&buf) + 1;\n\n    if (!avctx->width || !avctx->height) {\n\n        avctx->width  = display_def->width;\n\n        avctx->height = display_def->height;\n\n    }\n\n\n\n    if (buf_size < 13)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (info_byte & 1<<3) { // display_window_flag\n\n        display_def->x = bytestream_get_be16(&buf);\n\n        display_def->width  = bytestream_get_be16(&buf) - display_def->x + 1;\n\n        display_def->y = bytestream_get_be16(&buf);\n\n        display_def->height = bytestream_get_be16(&buf) - display_def->y + 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 2964, "_split": "valid", "_hash": "88b70e52885ed07d31459d551200594b"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static void init_scan_tables(H264Context *h)\n\n{\n\n    int i;\n\n    for (i = 0; i < 16; i++) {\n\n#define TRANSPOSE(x) (x >> 2) | ((x << 2) & 0xF)\n\n        h->zigzag_scan[i] = TRANSPOSE(ff_zigzag_scan[i]);\n\n        h->field_scan[i]  = TRANSPOSE(field_scan[i]);\n\n#undef TRANSPOSE\n\n    }\n\n    for (i = 0; i < 64; i++) {\n\n#define TRANSPOSE(x) (x >> 3) | ((x & 7) << 3)\n\n        h->zigzag_scan8x8[i]       = TRANSPOSE(ff_zigzag_direct[i]);\n\n        h->zigzag_scan8x8_cavlc[i] = TRANSPOSE(zigzag_scan8x8_cavlc[i]);\n\n        h->field_scan8x8[i]        = TRANSPOSE(field_scan8x8[i]);\n\n        h->field_scan8x8_cavlc[i]  = TRANSPOSE(field_scan8x8_cavlc[i]);\n\n#undef TRANSPOSE\n\n    }\n\n    if (h->sps.transform_bypass) { // FIXME same ugly\n\n        h->zigzag_scan_q0          = ff_zigzag_scan;\n\n        h->zigzag_scan8x8_q0       = ff_zigzag_direct;\n\n        h->zigzag_scan8x8_cavlc_q0 = zigzag_scan8x8_cavlc;\n\n        h->field_scan_q0           = field_scan;\n\n        h->field_scan8x8_q0        = field_scan8x8;\n\n        h->field_scan8x8_cavlc_q0  = field_scan8x8_cavlc;\n\n    } else {\n\n        h->zigzag_scan_q0          = h->zigzag_scan;\n\n        h->zigzag_scan8x8_q0       = h->zigzag_scan8x8;\n\n        h->zigzag_scan8x8_cavlc_q0 = h->zigzag_scan8x8_cavlc;\n\n        h->field_scan_q0           = h->field_scan;\n\n        h->field_scan8x8_q0        = h->field_scan8x8;\n\n        h->field_scan8x8_cavlc_q0  = h->field_scan8x8_cavlc;\n\n    }\n\n}\n", "idx": 3105, "_split": "valid", "_hash": "85b4454b204065a33bc059edefaf5e1a"}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void avg_pixels8_altivec(uint8_t * block, const uint8_t * pixels, int line_size, int h)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_avg_pixels8_num, 1);\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\n    int i;\n\nPOWERPC_TBL_START_COUNT(altivec_avg_pixels8_num, 1);\n\n    for (i = 0; i < h; i++) {\n\n        *((uint32_t *) (block)) =\n\n            (((*((uint32_t *) (block))) |\n\n              ((((const struct unaligned_32 *) (pixels))->l))) -\n\n             ((((*((uint32_t *) (block))) ^\n\n                ((((const struct unaligned_32 *) (pixels))->\n\n                  l))) & 0xFEFEFEFEUL) >> 1));\n\n        *((uint32_t *) (block + 4)) =\n\n            (((*((uint32_t *) (block + 4))) |\n\n              ((((const struct unaligned_32 *) (pixels + 4))->l))) -\n\n             ((((*((uint32_t *) (block + 4))) ^\n\n                ((((const struct unaligned_32 *) (pixels +\n\n                                                  4))->\n\n                  l))) & 0xFEFEFEFEUL) >> 1));\n\n        pixels += line_size;\n\n        block += line_size;\n\n    }\n\nPOWERPC_TBL_STOP_COUNT(altivec_avg_pixels8_num, 1);\n\n\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n    register vector unsigned char pixelsv1, pixelsv2, pixelsv, blockv;\n\n    int i;\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_avg_pixels8_num, 1);\n\n \n\n   for (i = 0; i < h; i++) {\n\n     /*\n\n       block is 8 bytes-aligned, so we're either in the\n\n       left block (16 bytes-aligned) or in the right block (not)\n\n     */\n\n     int rightside = ((unsigned long)block & 0x0000000F);\n\n     \n\n     blockv = vec_ld(0, block);\n\n     pixelsv1 = vec_ld(0, (unsigned char*)pixels);\n\n     pixelsv2 = vec_ld(16, (unsigned char*)pixels);\n\n     pixelsv = vec_perm(pixelsv1, pixelsv2, vec_lvsl(0, pixels));\n\n     \n\n     if (rightside)\n\n     {\n\n       pixelsv = vec_perm(blockv, pixelsv, vcprm(0,1,s0,s1));\n\n     }\n\n     else\n\n     {\n\n       pixelsv = vec_perm(blockv, pixelsv, vcprm(s0,s1,2,3));\n\n     }\n\n     \n\n     blockv = vec_avg(blockv, pixelsv);\n\n\n\n     vec_st(blockv, 0, block);\n\n     \n\n     pixels += line_size;\n\n     block += line_size;\n\n   }\n\n   \n\nPOWERPC_TBL_STOP_COUNT(altivec_avg_pixels8_num, 1);\n\n \n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n}\n", "idx": 3106, "_split": "valid", "_hash": "9016278fb26207e736988931ddf7f728"}
{"project": "FFmpeg", "commit_id": "5331773cc33ba26b9e26ace643d926219e46a17b", "target": 0, "func": "int avformat_open_input(AVFormatContext **ps, const char *filename,\n\n                        AVInputFormat *fmt, AVDictionary **options)\n\n{\n\n    AVFormatContext *s = *ps;\n\n    int ret = 0;\n\n    AVDictionary *tmp = NULL;\n\n    ID3v2ExtraMeta *id3v2_extra_meta = NULL;\n\n\n\n    if (!s && !(s = avformat_alloc_context()))\n\n        return AVERROR(ENOMEM);\n\n    if (!s->av_class) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Input context has not been properly allocated by avformat_alloc_context() and is not NULL either\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if (fmt)\n\n        s->iformat = fmt;\n\n\n\n    if (options)\n\n        av_dict_copy(&tmp, *options, 0);\n\n\n\n    if ((ret = av_opt_set_dict(s, &tmp)) < 0)\n\n        goto fail;\n\n\n\n    if ((ret = init_input(s, filename, &tmp)) < 0)\n\n        goto fail;\n\n    s->probe_score = ret;\n\n    avio_skip(s->pb, s->skip_initial_bytes);\n\n\n\n    /* Check filename in case an image number is expected. */\n\n    if (s->iformat->flags & AVFMT_NEEDNUMBER) {\n\n        if (!av_filename_number_test(filename)) {\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    s->duration = s->start_time = AV_NOPTS_VALUE;\n\n    av_strlcpy(s->filename, filename ? filename : \"\", sizeof(s->filename));\n\n\n\n    /* Allocate private data. */\n\n    if (s->iformat->priv_data_size > 0) {\n\n        if (!(s->priv_data = av_mallocz(s->iformat->priv_data_size))) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        if (s->iformat->priv_class) {\n\n            *(const AVClass **) s->priv_data = s->iformat->priv_class;\n\n            av_opt_set_defaults(s->priv_data);\n\n            if ((ret = av_opt_set_dict(s->priv_data, &tmp)) < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    /* e.g. AVFMT_NOFILE formats will not have a AVIOContext */\n\n    if (s->pb)\n\n        ff_id3v2_read(s, ID3v2_DEFAULT_MAGIC, &id3v2_extra_meta);\n\n\n\n    if (!(s->flags&AVFMT_FLAG_PRIV_OPT) && s->iformat->read_header)\n\n        if ((ret = s->iformat->read_header(s)) < 0)\n\n            goto fail;\n\n\n\n    if (id3v2_extra_meta) {\n\n        if (!strcmp(s->iformat->name, \"mp3\") || !strcmp(s->iformat->name, \"aac\") ||\n\n            !strcmp(s->iformat->name, \"tta\")) {\n\n            if ((ret = ff_id3v2_parse_apic(s, &id3v2_extra_meta)) < 0)\n\n                goto fail;\n\n        } else\n\n            av_log(s, AV_LOG_DEBUG, \"demuxer does not support additional id3 data, skipping\\n\");\n\n    }\n\n    ff_id3v2_free_extra_meta(&id3v2_extra_meta);\n\n\n\n    if ((ret = avformat_queue_attached_pictures(s)) < 0)\n\n        goto fail;\n\n\n\n    if (!(s->flags&AVFMT_FLAG_PRIV_OPT) && s->pb && !s->data_offset)\n\n        s->data_offset = avio_tell(s->pb);\n\n\n\n    s->raw_packet_buffer_remaining_size = RAW_PACKET_BUFFER_SIZE;\n\n\n\n    if (options) {\n\n        av_dict_free(options);\n\n        *options = tmp;\n\n    }\n\n    *ps = s;\n\n    return 0;\n\n\n\nfail:\n\n    ff_id3v2_free_extra_meta(&id3v2_extra_meta);\n\n    av_dict_free(&tmp);\n\n    if (s->pb && !(s->flags & AVFMT_FLAG_CUSTOM_IO))\n\n        avio_close(s->pb);\n\n    avformat_free_context(s);\n\n    *ps = NULL;\n\n    return ret;\n\n}\n", "idx": 3124, "_split": "valid", "_hash": "a862217afd14a201653ad995e291eb41"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static av_always_inline void hl_decode_mb_predict_luma(const H264Context *h,\n\n                                                       H264SliceContext *sl,\n\n                                                       int mb_type, int simple,\n\n                                                       int transform_bypass,\n\n                                                       int pixel_shift,\n\n                                                       const int *block_offset,\n\n                                                       int linesize,\n\n                                                       uint8_t *dest_y, int p)\n\n{\n\n    void (*idct_add)(uint8_t *dst, int16_t *block, int stride);\n\n    void (*idct_dc_add)(uint8_t *dst, int16_t *block, int stride);\n\n    int i;\n\n    int qscale = p == 0 ? sl->qscale : sl->chroma_qp[p - 1];\n\n    block_offset += 16 * p;\n\n    if (IS_INTRA4x4(mb_type)) {\n\n        if (IS_8x8DCT(mb_type)) {\n\n            if (transform_bypass) {\n\n                idct_dc_add =\n\n                idct_add    = h->h264dsp.h264_add_pixels8_clear;\n\n            } else {\n\n                idct_dc_add = h->h264dsp.h264_idct8_dc_add;\n\n                idct_add    = h->h264dsp.h264_idct8_add;\n\n            }\n\n            for (i = 0; i < 16; i += 4) {\n\n                uint8_t *const ptr = dest_y + block_offset[i];\n\n                const int dir      = sl->intra4x4_pred_mode_cache[scan8[i]];\n\n                if (transform_bypass && h->sps.profile_idc == 244 && dir <= 1) {\n\n                    h->hpc.pred8x8l_add[dir](ptr, sl->mb + (i * 16 + p * 256 << pixel_shift), linesize);\n\n                } else {\n\n                    const int nnz = sl->non_zero_count_cache[scan8[i + p * 16]];\n\n                    h->hpc.pred8x8l[dir](ptr, (sl->topleft_samples_available << i) & 0x8000,\n\n                                         (sl->topright_samples_available << i) & 0x4000, linesize);\n\n                    if (nnz) {\n\n                        if (nnz == 1 && dctcoef_get(sl->mb, pixel_shift, i * 16 + p * 256))\n\n                            idct_dc_add(ptr, sl->mb + (i * 16 + p * 256 << pixel_shift), linesize);\n\n                        else\n\n                            idct_add(ptr, sl->mb + (i * 16 + p * 256 << pixel_shift), linesize);\n\n                    }\n\n                }\n\n            }\n\n        } else {\n\n            if (transform_bypass) {\n\n                idct_dc_add  =\n\n                idct_add     = h->h264dsp.h264_add_pixels4_clear;\n\n            } else {\n\n                idct_dc_add = h->h264dsp.h264_idct_dc_add;\n\n                idct_add    = h->h264dsp.h264_idct_add;\n\n            }\n\n            for (i = 0; i < 16; i++) {\n\n                uint8_t *const ptr = dest_y + block_offset[i];\n\n                const int dir      = sl->intra4x4_pred_mode_cache[scan8[i]];\n\n\n\n                if (transform_bypass && h->sps.profile_idc == 244 && dir <= 1) {\n\n                    h->hpc.pred4x4_add[dir](ptr, sl->mb + (i * 16 + p * 256 << pixel_shift), linesize);\n\n                } else {\n\n                    uint8_t *topright;\n\n                    int nnz, tr;\n\n                    uint64_t tr_high;\n\n                    if (dir == DIAG_DOWN_LEFT_PRED || dir == VERT_LEFT_PRED) {\n\n                        const int topright_avail = (sl->topright_samples_available << i) & 0x8000;\n\n                        assert(sl->mb_y || linesize <= block_offset[i]);\n\n                        if (!topright_avail) {\n\n                            if (pixel_shift) {\n\n                                tr_high  = ((uint16_t *)ptr)[3 - linesize / 2] * 0x0001000100010001ULL;\n\n                                topright = (uint8_t *)&tr_high;\n\n                            } else {\n\n                                tr       = ptr[3 - linesize] * 0x01010101u;\n\n                                topright = (uint8_t *)&tr;\n\n                            }\n\n                        } else\n\n                            topright = ptr + (4 << pixel_shift) - linesize;\n\n                    } else\n\n                        topright = NULL;\n\n\n\n                    h->hpc.pred4x4[dir](ptr, topright, linesize);\n\n                    nnz = sl->non_zero_count_cache[scan8[i + p * 16]];\n\n                    if (nnz) {\n\n                        if (nnz == 1 && dctcoef_get(sl->mb, pixel_shift, i * 16 + p * 256))\n\n                            idct_dc_add(ptr, sl->mb + (i * 16 + p * 256 << pixel_shift), linesize);\n\n                        else\n\n                            idct_add(ptr, sl->mb + (i * 16 + p * 256 << pixel_shift), linesize);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    } else {\n\n        h->hpc.pred16x16[sl->intra16x16_pred_mode](dest_y, linesize);\n\n        if (sl->non_zero_count_cache[scan8[LUMA_DC_BLOCK_INDEX + p]]) {\n\n            if (!transform_bypass)\n\n                h->h264dsp.h264_luma_dc_dequant_idct(sl->mb + (p * 256 << pixel_shift),\n\n                                                     sl->mb_luma_dc[p],\n\n                                                     h->dequant4_coeff[p][qscale][0]);\n\n            else {\n\n                static const uint8_t dc_mapping[16] = {\n\n                     0 * 16,  1 * 16,  4 * 16,  5 * 16,\n\n                     2 * 16,  3 * 16,  6 * 16,  7 * 16,\n\n                     8 * 16,  9 * 16, 12 * 16, 13 * 16,\n\n                    10 * 16, 11 * 16, 14 * 16, 15 * 16\n\n                };\n\n                for (i = 0; i < 16; i++)\n\n                    dctcoef_set(sl->mb + (p * 256 << pixel_shift),\n\n                                pixel_shift, dc_mapping[i],\n\n                                dctcoef_get(sl->mb_luma_dc[p],\n\n                                            pixel_shift, i));\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 3187, "_split": "valid", "_hash": "29b5533e87c49161d19814265275a4b5"}
{"project": "FFmpeg", "commit_id": "308429e124b97337a768839c1d5091900e974e7e", "target": 0, "func": "static void peak_write_chunk(AVFormatContext *s)\n\n{\n\n    WAVMuxContext *wav = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *enc = s->streams[0]->codec;\n\n    int64_t peak = ff_start_tag(s->pb, \"levl\");\n\n    int64_t now0;\n\n    time_t now_secs;\n\n    char timestamp[28];\n\n\n\n    /* Peak frame of incomplete block at end */\n\n    if (wav->peak_block_pos)\n\n        peak_write_frame(s);\n\n\n\n    memset(timestamp, 0, sizeof(timestamp));\n\n    if (!(s->flags & AVFMT_FLAG_BITEXACT)) {\n\n        struct tm tmpbuf;\n\n        av_log(s, AV_LOG_INFO, \"Writing local time and date to Peak Envelope Chunk\\n\");\n\n        now0 = av_gettime();\n\n        now_secs = now0 / 1000000;\n\n        strftime(timestamp, sizeof(timestamp), \"%Y:%m:%d:%H:%M:%S:\", localtime_r(&now_secs, &tmpbuf));\n\n        av_strlcatf(timestamp, sizeof(timestamp), \"%03d\", (int)((now0 / 1000) % 1000));\n\n    }\n\n\n\n    avio_wl32(pb, 1);                           /* version */\n\n    avio_wl32(pb, wav->peak_format);            /* 8 or 16 bit */\n\n    avio_wl32(pb, wav->peak_ppv);               /* positive and negative */\n\n    avio_wl32(pb, wav->peak_block_size);        /* frames per value */\n\n    avio_wl32(pb, enc->channels);               /* number of channels */\n\n    avio_wl32(pb, wav->peak_num_frames);        /* number of peak frames */\n\n    avio_wl32(pb, wav->peak_pos_pop);           /* audio sample frame index */\n\n    avio_wl32(pb, 128);                         /* equal to size of header */\n\n    avio_write(pb, timestamp, 28);              /* ASCII time stamp */\n\n    ffio_fill(pb, 0, 60);\n\n\n\n    avio_write(pb, wav->peak_output, wav->peak_outbuf_bytes);\n\n\n\n    ff_end_tag(pb, peak);\n\n\n\n    if (!wav->data)\n\n        wav->data = peak;\n\n}\n", "idx": 3189, "_split": "valid", "_hash": "e85249f73598bc1fe0ffaded564d8bde"}
{"project": "FFmpeg", "commit_id": "6ff3f3e7cec7cd78a01d0bf76cbccfbe68dc0894", "target": 0, "func": "int ff_socket_nonblock(int socket, int enable)\n\n{\n\n#ifdef __MINGW32__\n\n   return ioctlsocket(socket, FIONBIO, &enable);\n\n#else\n\n   if (enable)\n\n      return fcntl(socket, F_SETFL, fcntl(socket, F_GETFL) | O_NONBLOCK);\n\n   else\n\n      return fcntl(socket, F_SETFL, fcntl(socket, F_GETFL) & ~O_NONBLOCK);\n\n#endif\n\n}\n", "idx": 3232, "_split": "valid", "_hash": "6ef659f2862797c7596355b6ea7cbad1"}
{"project": "FFmpeg", "commit_id": "375a0273cec41a329c9cca01fb8805e9a0dc3d72", "target": 1, "func": "static void filter(FSPPContext *p, uint8_t *dst, uint8_t *src,\n\n                   int dst_stride, int src_stride,\n\n                   int width, int height,\n\n                   uint8_t *qp_store, int qp_stride, int is_luma)\n\n{\n\n    int x, x0, y, es, qy, t;\n\n\n\n    const int stride = is_luma ? p->temp_stride : (width + 16);\n\n    const int step = 6 - p->log2_count;\n\n    const int qpsh = 4 - p->hsub * !is_luma;\n\n    const int qpsv = 4 - p->vsub * !is_luma;\n\n\n\n    DECLARE_ALIGNED(32, int32_t, block_align)[4 * 8 * BLOCKSZ + 4 * 8 * BLOCKSZ];\n\n    int16_t *block  = (int16_t *)block_align;\n\n    int16_t *block3 = (int16_t *)(block_align + 4 * 8 * BLOCKSZ);\n\n\n\n    memset(block3, 0, 4 * 8 * BLOCKSZ);\n\n\n\n    if (!src || !dst) return;\n\n\n\n    for (y = 0; y < height; y++) {\n\n        int index = 8 + 8 * stride + y * stride;\n\n        memcpy(p->src + index, src + y * src_stride, width);\n\n        for (x = 0; x < 8; x++) {\n\n            p->src[index         - x - 1] = p->src[index +         x    ];\n\n            p->src[index + width + x    ] = p->src[index + width - x - 1];\n\n        }\n\n    }\n\n\n\n    for (y = 0; y < 8; y++) {\n\n        memcpy(p->src + (     7 - y    ) * stride, p->src + (     y + 8    ) * stride, stride);\n\n        memcpy(p->src + (height + 8 + y) * stride, p->src + (height - y + 7) * stride, stride);\n\n    }\n\n    //FIXME (try edge emu)\n\n\n\n    for (y = 8; y < 24; y++)\n\n        memset(p->temp + 8 + y * stride, 0, width * sizeof(int16_t));\n\n\n\n    for (y = step; y < height + 8; y += step) {    //step= 1,2\n\n        const int y1 = y - 8 + step;                 //l5-7  l4-6;\n\n        qy = y - 4;\n\n\n\n        if (qy > height - 1) qy = height - 1;\n\n        if (qy < 0) qy = 0;\n\n\n\n        qy = (qy >> qpsv) * qp_stride;\n\n        p->row_fdct(block, p->src + y * stride + 2 - (y&1), stride, 2);\n\n\n\n        for (x0 = 0; x0 < width + 8 - 8 * (BLOCKSZ - 1); x0 += 8 * (BLOCKSZ - 1)) {\n\n            p->row_fdct(block + 8 * 8, p->src + y * stride + 8 + x0 + 2 - (y&1), stride, 2 * (BLOCKSZ - 1));\n\n\n\n            if (p->qp)\n\n                p->column_fidct((int16_t *)(&p->threshold_mtx[0]), block + 0 * 8, block3 + 0 * 8, 8 * (BLOCKSZ - 1)); //yes, this is a HOTSPOT\n\n            else\n\n                for (x = 0; x < 8 * (BLOCKSZ - 1); x += 8) {\n\n                    t = x + x0 - 2;                    //correct t=x+x0-2-(y&1), but its the same\n\n\n\n                    if (t < 0) t = 0;                   //t always < width-2\n\n\n\n                    t = qp_store[qy + (t >> qpsh)];\n\n                    t = ff_norm_qscale(t, p->qscale_type);\n\n\n\n                    if (t != p->prev_q) p->prev_q = t, p->mul_thrmat((int16_t *)(&p->threshold_mtx_noq[0]), (int16_t *)(&p->threshold_mtx[0]), t);\n\n                    p->column_fidct((int16_t *)(&p->threshold_mtx[0]), block + x * 8, block3 + x * 8, 8); //yes, this is a HOTSPOT\n\n                }\n\n            p->row_idct(block3 + 0 * 8, p->temp + (y & 15) * stride + x0 + 2 - (y & 1), stride, 2 * (BLOCKSZ - 1));\n\n            memmove(block,  block  + (BLOCKSZ - 1) * 64, 8 * 8 * sizeof(int16_t)); //cycling\n\n            memmove(block3, block3 + (BLOCKSZ - 1) * 64, 6 * 8 * sizeof(int16_t));\n\n        }\n\n\n\n        es = width + 8 - x0; //  8, ...\n\n        if (es > 8)\n\n            p->row_fdct(block + 8 * 8, p->src + y * stride + 8 + x0 + 2 - (y & 1), stride, (es - 4) >> 2);\n\n\n\n        p->column_fidct((int16_t *)(&p->threshold_mtx[0]), block, block3, es&(~1));\n\n        p->row_idct(block3 + 0 * 8, p->temp + (y & 15) * stride + x0 + 2 - (y & 1), stride, es >> 2);\n\n\n\n        if (!(y1 & 7) && y1) {\n\n            if (y1 & 8)\n\n                p->store_slice(dst + (y1 - 8) * dst_stride, p->temp + 8 + 8 * stride,\n\n                               dst_stride, stride, width, 8, 5 - p->log2_count);\n\n            else\n\n                p->store_slice2(dst + (y1 - 8) * dst_stride, p->temp + 8 + 0 * stride,\n\n                                dst_stride, stride, width, 8, 5 - p->log2_count);\n\n        }\n\n    }\n\n\n\n    if (y & 7) {  // height % 8 != 0\n\n        if (y & 8)\n\n            p->store_slice(dst + ((y - 8) & ~7) * dst_stride, p->temp + 8 + 8 * stride,\n\n                           dst_stride, stride, width, y&7, 5 - p->log2_count);\n\n        else\n\n            p->store_slice2(dst + ((y - 8) & ~7) * dst_stride, p->temp + 8 + 0 * stride,\n\n                            dst_stride, stride, width, y&7, 5 - p->log2_count);\n\n    }\n\n}\n", "idx": 3275, "_split": "valid", "_hash": "dc8f1d559036de764bfb745755af8825"}
{"project": "FFmpeg", "commit_id": "ae43c10e36197000de2f3cc99ea35727ce98a796", "target": 0, "func": "static int replaygain_export(AVStream *st,\n\n                             const uint8_t *track_gain, const uint8_t *track_peak,\n\n                             const uint8_t *album_gain, const uint8_t *album_peak)\n\n{\n\n    AVPacketSideData *sd, *tmp;\n\n    AVReplayGain *replaygain;\n\n    int32_t tg, ag;\n\n    uint32_t tp, ap;\n\n\n\n    tg = parse_value(track_gain, INT32_MIN);\n\n    ag = parse_value(album_gain, INT32_MIN);\n\n    tp = parse_value(track_peak, 0);\n\n    ap = parse_value(album_peak, 0);\n\n\n\n    if (tg == INT32_MIN && ag == INT32_MIN)\n\n        return 0;\n\n\n\n    replaygain = av_mallocz(sizeof(*replaygain));\n\n    if (!replaygain)\n\n        return AVERROR(ENOMEM);\n\n\n\n    tmp = av_realloc_array(st->side_data, st->nb_side_data + 1, sizeof(*tmp));\n\n    if (!tmp) {\n\n        av_freep(&replaygain);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    st->side_data = tmp;\n\n    st->nb_side_data++;\n\n\n\n    sd = &st->side_data[st->nb_side_data - 1];\n\n    sd->type = AV_PKT_DATA_REPLAYGAIN;\n\n    sd->data = (uint8_t*)replaygain;\n\n    sd->size = sizeof(*replaygain);\n\n\n\n    replaygain->track_gain = tg;\n\n    replaygain->track_peak = tp;\n\n    replaygain->album_gain = ag;\n\n    replaygain->album_peak = ap;\n\n\n\n    return 0;\n\n}\n", "idx": 3368, "_split": "valid", "_hash": "d2482048082293569d190603832172d4"}
{"project": "FFmpeg", "commit_id": "aaebdce3d90725ff93a31678690a306da6e12bbb", "target": 0, "func": "static int gif_read_header1(GifState *s)\n\n{\n\n    uint8_t sig[6];\n\n    int v, n;\n\n    int background_color_index;\n\n\n\n    if (bytestream2_get_bytes_left(&s->gb) < 13)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* read gif signature */\n\n    bytestream2_get_bufferu(&s->gb, sig, 6);\n\n    if (memcmp(sig, gif87a_sig, 6) != 0 &&\n\n        memcmp(sig, gif89a_sig, 6) != 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* read screen header */\n\n    s->transparent_color_index = -1;\n\n    s->screen_width = bytestream2_get_le16u(&s->gb);\n\n    s->screen_height = bytestream2_get_le16u(&s->gb);\n\n    if(   (unsigned)s->screen_width  > 32767\n\n       || (unsigned)s->screen_height > 32767){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"picture size too large\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    av_fast_malloc(&s->idx_line, &s->idx_line_size, s->screen_width);\n\n    if (!s->idx_line)\n\n        return AVERROR(ENOMEM);\n\n\n\n    v = bytestream2_get_byteu(&s->gb);\n\n    s->color_resolution = ((v & 0x70) >> 4) + 1;\n\n    s->has_global_palette = (v & 0x80);\n\n    s->bits_per_pixel = (v & 0x07) + 1;\n\n    background_color_index = bytestream2_get_byteu(&s->gb);\n\n    n = bytestream2_get_byteu(&s->gb);\n\n    if (n) {\n\n        s->avctx->sample_aspect_ratio.num = n + 15;\n\n        s->avctx->sample_aspect_ratio.den = 64;\n\n    }\n\n\n\n    av_dlog(s->avctx, \"screen_w=%d screen_h=%d bpp=%d global_palette=%d\\n\",\n\n           s->screen_width, s->screen_height, s->bits_per_pixel,\n\n           s->has_global_palette);\n\n\n\n    if (s->has_global_palette) {\n\n        s->background_color_index = background_color_index;\n\n        n = 1 << s->bits_per_pixel;\n\n        if (bytestream2_get_bytes_left(&s->gb) < n * 3)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        gif_read_palette(s, s->global_palette, n);\n\n        s->bg_color = s->global_palette[s->background_color_index];\n\n    } else\n\n        s->background_color_index = -1;\n\n\n\n    return 0;\n\n}\n", "idx": 3383, "_split": "valid", "_hash": "b38675e7585e790723269aab2f58bc92"}
{"project": "FFmpeg", "commit_id": "4c53f4aed3edfa58360c7a2a468782eae31d3176", "target": 0, "func": "static int read_header(ShortenContext *s)\n\n{\n\n    int i, ret;\n\n    int maxnlpc = 0;\n\n    /* shorten signature */\n\n    if (get_bits_long(&s->gb, 32) != AV_RB32(\"ajkg\")) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"missing shorten magic 'ajkg'\\n\");\n\n        return -1;\n\n    }\n\n\n\n    s->lpcqoffset = 0;\n\n    s->blocksize = DEFAULT_BLOCK_SIZE;\n\n    s->nmean = -1;\n\n    s->version = get_bits(&s->gb, 8);\n\n    s->internal_ftype = get_uint(s, TYPESIZE);\n\n\n\n    s->channels = get_uint(s, CHANSIZE);\n\n    if (s->channels > MAX_CHANNELS) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"too many channels: %d\\n\", s->channels);\n\n        return -1;\n\n    }\n\n    s->avctx->channels = s->channels;\n\n\n\n    /* get blocksize if version > 0 */\n\n    if (s->version > 0) {\n\n        int skip_bytes, blocksize;\n\n\n\n        blocksize = get_uint(s, av_log2(DEFAULT_BLOCK_SIZE));\n\n        if (!blocksize || blocksize > MAX_BLOCKSIZE) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"invalid or unsupported block size: %d\\n\",\n\n                   blocksize);\n\n            return AVERROR(EINVAL);\n\n        }\n\n        s->blocksize = blocksize;\n\n\n\n        maxnlpc = get_uint(s, LPCQSIZE);\n\n        s->nmean = get_uint(s, 0);\n\n\n\n        skip_bytes = get_uint(s, NSKIPSIZE);\n\n        for (i=0; i<skip_bytes; i++) {\n\n            skip_bits(&s->gb, 8);\n\n        }\n\n    }\n\n    s->nwrap = FFMAX(NWRAP, maxnlpc);\n\n\n\n    if ((ret = allocate_buffers(s)) < 0)\n\n        return ret;\n\n\n\n    if ((ret = init_offset(s)) < 0)\n\n        return ret;\n\n\n\n    if (s->version > 1)\n\n        s->lpcqoffset = V2LPCQOFFSET;\n\n\n\n    if (get_ur_golomb_shorten(&s->gb, FNSIZE) != FN_VERBATIM) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"missing verbatim section at beginning of stream\\n\");\n\n        return -1;\n\n    }\n\n\n\n    s->header_size = get_ur_golomb_shorten(&s->gb, VERBATIM_CKSIZE_SIZE);\n\n    if (s->header_size >= OUT_BUFFER_SIZE || s->header_size < CANONICAL_HEADER_SIZE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"header is wrong size: %d\\n\", s->header_size);\n\n        return -1;\n\n    }\n\n\n\n    for (i=0; i<s->header_size; i++)\n\n        s->header[i] = (char)get_ur_golomb_shorten(&s->gb, VERBATIM_BYTE_SIZE);\n\n\n\n    if (decode_wave_header(s->avctx, s->header, s->header_size) < 0)\n\n        return -1;\n\n\n\n    s->cur_chan = 0;\n\n    s->bitshift = 0;\n\n\n\n    s->got_header = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 3471, "_split": "valid", "_hash": "59ee3cf8d1053525f3bf2a24279567b3"}
{"project": "FFmpeg", "commit_id": "636ced8e1dc8248a1353b416240b93d70ad03edb", "target": 1, "func": "void parse_options(void *optctx, int argc, char **argv, const OptionDef *options,\n\n                   void (*parse_arg_function)(void *, const char*))\n\n{\n\n    const char *opt;\n\n    int optindex, handleoptions = 1, ret;\n\n\n\n    /* perform system-dependent conversions for arguments list */\n\n    prepare_app_arguments(&argc, &argv);\n\n\n\n    /* parse options */\n\n    optindex = 1;\n\n    while (optindex < argc) {\n\n        opt = argv[optindex++];\n\n\n\n        if (handleoptions && opt[0] == '-' && opt[1] != '\\0') {\n\n            if (opt[1] == '-' && opt[2] == '\\0') {\n\n                handleoptions = 0;\n\n                continue;\n\n            }\n\n            opt++;\n\n\n\n            if ((ret = parse_option(optctx, opt, argv[optindex], options)) < 0)\n\n                exit(1);\n\n            optindex += ret;\n\n        } else {\n\n            if (parse_arg_function)\n\n                parse_arg_function(optctx, opt);\n\n        }\n\n    }\n\n}\n", "idx": 3472, "_split": "valid", "_hash": "69df3aed864ca5a86527d9b9f60457a6"}
{"project": "FFmpeg", "commit_id": "7303962f1467e302906561be53ca4d51abbe5522", "target": 0, "func": "void ff_aac_search_for_ltp(AACEncContext *s, SingleChannelElement *sce,\n\n                           int common_window)\n\n{\n\n    int w, g, w2, i, start = 0, count = 0;\n\n    int saved_bits = -(15 + FFMIN(sce->ics.max_sfb, MAX_LTP_LONG_SFB));\n\n    float *C34 = &s->scoefs[128*0], *PCD = &s->scoefs[128*1];\n\n    float *PCD34 = &s->scoefs[128*2];\n\n    const int max_ltp = FFMIN(sce->ics.max_sfb, MAX_LTP_LONG_SFB);\n\n\n\n    if (sce->ics.window_sequence[0] == EIGHT_SHORT_SEQUENCE ||\n\n        !sce->ics.ltp.lag)\n\n        return;\n\n\n\n    for (w = 0; w < sce->ics.num_windows; w += sce->ics.group_len[w]) {\n\n        start = 0;\n\n        for (g = 0;  g < sce->ics.num_swb; g++) {\n\n            int bits1 = 0, bits2 = 0;\n\n            float dist1 = 0.0f, dist2 = 0.0f;\n\n            if (w*16+g > max_ltp) {\n\n                start += sce->ics.swb_sizes[g];\n\n                continue;\n\n            }\n\n            for (w2 = 0; w2 < sce->ics.group_len[w]; w2++) {\n\n                int bits_tmp1, bits_tmp2;\n\n                FFPsyBand *band = &s->psy.ch[s->cur_channel].psy_bands[(w+w2)*16+g];\n\n                for (i = 0; i < sce->ics.swb_sizes[g]; i++)\n\n                    PCD[i] = sce->coeffs[start+(w+w2)*128+i] - sce->lcoeffs[start+(w+w2)*128+i];\n\n                abs_pow34_v(C34,  &sce->coeffs[start+(w+w2)*128],  sce->ics.swb_sizes[g]);\n\n                abs_pow34_v(PCD34, PCD, sce->ics.swb_sizes[g]);\n\n                dist1 += quantize_band_cost(s, &sce->coeffs[start+(w+w2)*128], C34, sce->ics.swb_sizes[g],\n\n                                            sce->sf_idx[(w+w2)*16+g], sce->band_type[(w+w2)*16+g],\n\n                                            s->lambda/band->threshold, INFINITY, &bits_tmp1, NULL, 0);\n\n                dist2 += quantize_band_cost(s, PCD, PCD34, sce->ics.swb_sizes[g],\n\n                                            sce->sf_idx[(w+w2)*16+g],\n\n                                            sce->band_type[(w+w2)*16+g],\n\n                                            s->lambda/band->threshold, INFINITY, &bits_tmp2, NULL, 0);\n\n                bits1 += bits_tmp1;\n\n                bits2 += bits_tmp2;\n\n            }\n\n            if (dist2 < dist1 && bits2 < bits1) {\n\n                for (w2 = 0; w2 < sce->ics.group_len[w]; w2++)\n\n                    for (i = 0; i < sce->ics.swb_sizes[g]; i++)\n\n                        sce->coeffs[start+(w+w2)*128+i] -= sce->lcoeffs[start+(w+w2)*128+i];\n\n                sce->ics.ltp.used[w*16+g] = 1;\n\n                saved_bits += bits1 - bits2;\n\n                count++;\n\n            }\n\n            start += sce->ics.swb_sizes[g];\n\n        }\n\n    }\n\n\n\n    sce->ics.ltp.present = !!count && (saved_bits >= 0);\n\n    sce->ics.predictor_present = !!sce->ics.ltp.present;\n\n\n\n    /* Reset any marked sfbs */\n\n    if (!sce->ics.ltp.present && !!count) {\n\n        for (w = 0; w < sce->ics.num_windows; w += sce->ics.group_len[w]) {\n\n            start = 0;\n\n            for (g = 0;  g < sce->ics.num_swb; g++) {\n\n                if (sce->ics.ltp.used[w*16+g]) {\n\n                    for (w2 = 0; w2 < sce->ics.group_len[w]; w2++) {\n\n                        for (i = 0; i < sce->ics.swb_sizes[g]; i++) {\n\n                            sce->coeffs[start+(w+w2)*128+i] += sce->lcoeffs[start+(w+w2)*128+i];\n\n                        }\n\n                    }\n\n                }\n\n                start += sce->ics.swb_sizes[g];\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 3526, "_split": "valid", "_hash": "f944693fd5829b1cfe67b6178dabfcf9"}
{"project": "FFmpeg", "commit_id": "57d77b3963ce1023eaf5ada8cba58b9379405cc8", "target": 0, "func": "void av_opencl_buffer_release(cl_mem *cl_buf)\n\n{\n\n    cl_int status = 0;\n\n    if (!cl_buf)\n\n        return;\n\n    status = clReleaseMemObject(*cl_buf);\n\n    if (status != CL_SUCCESS) {\n\n        av_log(&openclutils, AV_LOG_ERROR, \"Could not release OpenCL buffer: %s\\n\", opencl_errstr(status));\n\n    }\n\n    memset(cl_buf, 0, sizeof(*cl_buf));\n\n}\n", "idx": 3530, "_split": "valid", "_hash": "c3a73f6391ee59198c08a2cba31d3b08"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "int ff_rv34_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *got_picture_ptr,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    RV34DecContext *r = avctx->priv_data;\n\n    MpegEncContext *s = &r->s;\n\n    AVFrame *pict = data;\n\n    SliceInfo si;\n\n    int i, ret;\n\n    int slice_count;\n\n    const uint8_t *slices_hdr = NULL;\n\n    int last = 0;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        /* special case for last picture */\n\n        if (s->low_delay==0 && s->next_picture_ptr) {\n\n            if ((ret = av_frame_ref(pict, &s->next_picture_ptr->f)) < 0)\n\n                return ret;\n\n            s->next_picture_ptr = NULL;\n\n\n\n            *got_picture_ptr = 1;\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    if(!avctx->slice_count){\n\n        slice_count = (*buf++) + 1;\n\n        slices_hdr = buf + 4;\n\n        buf += 8 * slice_count;\n\n        buf_size -= 1 + 8 * slice_count;\n\n    }else\n\n        slice_count = avctx->slice_count;\n\n\n\n    //parse first slice header to check whether this frame can be decoded\n\n    if(get_slice_offset(avctx, slices_hdr, 0) < 0 ||\n\n       get_slice_offset(avctx, slices_hdr, 0) > buf_size){\n\n        av_log(avctx, AV_LOG_ERROR, \"Slice offset is invalid\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    init_get_bits(&s->gb, buf+get_slice_offset(avctx, slices_hdr, 0), (buf_size-get_slice_offset(avctx, slices_hdr, 0))*8);\n\n    if(r->parse_slice_header(r, &r->s.gb, &si) < 0 || si.start){\n\n        av_log(avctx, AV_LOG_ERROR, \"First slice header is incorrect\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if ((!s->last_picture_ptr || !s->last_picture_ptr->f.data[0]) &&\n\n        si.type == AV_PICTURE_TYPE_B) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid decoder state: B-frame without \"\n\n               \"reference data.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if(   (avctx->skip_frame >= AVDISCARD_NONREF && si.type==AV_PICTURE_TYPE_B)\n\n       || (avctx->skip_frame >= AVDISCARD_NONKEY && si.type!=AV_PICTURE_TYPE_I)\n\n       ||  avctx->skip_frame >= AVDISCARD_ALL)\n\n        return avpkt->size;\n\n\n\n    /* first slice */\n\n    if (si.start == 0) {\n\n        if (s->mb_num_left > 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"New frame but still %d MB left.\",\n\n                   s->mb_num_left);\n\n            ff_er_frame_end(&s->er);\n\n            ff_MPV_frame_end(s);\n\n        }\n\n\n\n        if (s->width != si.width || s->height != si.height) {\n\n            int err;\n\n\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Changing dimensions to %dx%d\\n\",\n\n                   si.width, si.height);\n\n\n\n            s->width  = si.width;\n\n            s->height = si.height;\n\n\n\n            err = ff_set_dimensions(s->avctx, s->width, s->height);\n\n            if (err < 0)\n\n                return err;\n\n\n\n            if ((err = ff_MPV_common_frame_size_change(s)) < 0)\n\n                return err;\n\n            if ((err = rv34_decoder_realloc(r)) < 0)\n\n                return err;\n\n        }\n\n        s->pict_type = si.type ? si.type : AV_PICTURE_TYPE_I;\n\n        if (ff_MPV_frame_start(s, s->avctx) < 0)\n\n            return -1;\n\n        ff_mpeg_er_frame_start(s);\n\n        if (!r->tmp_b_block_base) {\n\n            int i;\n\n\n\n            r->tmp_b_block_base = av_malloc(s->linesize * 48);\n\n            for (i = 0; i < 2; i++)\n\n                r->tmp_b_block_y[i] = r->tmp_b_block_base\n\n                                      + i * 16 * s->linesize;\n\n            for (i = 0; i < 4; i++)\n\n                r->tmp_b_block_uv[i] = r->tmp_b_block_base + 32 * s->linesize\n\n                                       + (i >> 1) * 8 * s->uvlinesize\n\n                                       + (i &  1) * 16;\n\n        }\n\n        r->cur_pts = si.pts;\n\n        if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n            r->last_pts = r->next_pts;\n\n            r->next_pts = r->cur_pts;\n\n        } else {\n\n            int refdist = GET_PTS_DIFF(r->next_pts, r->last_pts);\n\n            int dist0   = GET_PTS_DIFF(r->cur_pts,  r->last_pts);\n\n            int dist1   = GET_PTS_DIFF(r->next_pts, r->cur_pts);\n\n\n\n            if(!refdist){\n\n                r->mv_weight1 = r->mv_weight2 = r->weight1 = r->weight2 = 8192;\n\n                r->scaled_weight = 0;\n\n            }else{\n\n                r->mv_weight1 = (dist0 << 14) / refdist;\n\n                r->mv_weight2 = (dist1 << 14) / refdist;\n\n                if((r->mv_weight1|r->mv_weight2) & 511){\n\n                    r->weight1 = r->mv_weight1;\n\n                    r->weight2 = r->mv_weight2;\n\n                    r->scaled_weight = 0;\n\n                }else{\n\n                    r->weight1 = r->mv_weight1 >> 9;\n\n                    r->weight2 = r->mv_weight2 >> 9;\n\n                    r->scaled_weight = 1;\n\n                }\n\n            }\n\n        }\n\n        s->mb_x = s->mb_y = 0;\n\n        ff_thread_finish_setup(s->avctx);\n\n    } else if (HAVE_THREADS &&\n\n               (s->avctx->active_thread_type & FF_THREAD_FRAME)) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Decoder needs full frames in frame \"\n\n               \"multithreading mode (start MB is %d).\\n\", si.start);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    for(i = 0; i < slice_count; i++){\n\n        int offset = get_slice_offset(avctx, slices_hdr, i);\n\n        int size;\n\n        if(i+1 == slice_count)\n\n            size = buf_size - offset;\n\n        else\n\n            size = get_slice_offset(avctx, slices_hdr, i+1) - offset;\n\n\n\n        if(offset < 0 || offset > buf_size){\n\n            av_log(avctx, AV_LOG_ERROR, \"Slice offset is invalid\\n\");\n\n            break;\n\n        }\n\n\n\n        r->si.end = s->mb_width * s->mb_height;\n\n        s->mb_num_left = r->s.mb_x + r->s.mb_y*r->s.mb_width - r->si.start;\n\n\n\n        if(i+1 < slice_count){\n\n            if (get_slice_offset(avctx, slices_hdr, i+1) < 0 ||\n\n                get_slice_offset(avctx, slices_hdr, i+1) > buf_size) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Slice offset is invalid\\n\");\n\n                break;\n\n            }\n\n            init_get_bits(&s->gb, buf+get_slice_offset(avctx, slices_hdr, i+1), (buf_size-get_slice_offset(avctx, slices_hdr, i+1))*8);\n\n            if(r->parse_slice_header(r, &r->s.gb, &si) < 0){\n\n                if(i+2 < slice_count)\n\n                    size = get_slice_offset(avctx, slices_hdr, i+2) - offset;\n\n                else\n\n                    size = buf_size - offset;\n\n            }else\n\n                r->si.end = si.start;\n\n        }\n\n        if (size < 0 || size > buf_size - offset) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Slice size is invalid\\n\");\n\n            break;\n\n        }\n\n        last = rv34_decode_slice(r, r->si.end, buf + offset, size);\n\n        if(last)\n\n            break;\n\n    }\n\n\n\n    if (s->current_picture_ptr) {\n\n        if (last) {\n\n            if(r->loop_filter)\n\n                r->loop_filter(r, s->mb_height - 1);\n\n\n\n            ret = finish_frame(avctx, pict);\n\n            if (ret < 0)\n\n                return ret;\n\n            *got_picture_ptr = ret;\n\n        } else if (HAVE_THREADS &&\n\n                   (s->avctx->active_thread_type & FF_THREAD_FRAME)) {\n\n            av_log(avctx, AV_LOG_INFO, \"marking unfished frame as finished\\n\");\n\n            /* always mark the current frame as finished, frame-mt supports\n\n             * only complete frames */\n\n            ff_er_frame_end(&s->er);\n\n            ff_MPV_frame_end(s);\n\n            s->mb_num_left = 0;\n\n            ff_thread_report_progress(&s->current_picture_ptr->tf, INT_MAX, 0);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 3560, "_split": "valid", "_hash": "d9a2ec3320d61fe057144d7c298defc8"}
{"project": "FFmpeg", "commit_id": "774239be717150909219ad2c0696bfb6a50cf2cb", "target": 0, "func": "static int get_preset_file_2(const char *preset_name, const char *codec_name, AVIOContext **s)\n\n{\n\n    int i, ret = 1;\n\n    char filename[1000];\n\n    const char *base[3] = { getenv(\"AVCONV_DATADIR\"),\n\n                            getenv(\"HOME\"),\n\n                            AVCONV_DATADIR,\n\n                            };\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(base) && ret; i++) {\n\n        if (!base[i])\n\n            continue;\n\n        if (codec_name) {\n\n            snprintf(filename, sizeof(filename), \"%s%s/%s-%s.avpreset\", base[i],\n\n                     i != 1 ? \"\" : \"/.avconv\", codec_name, preset_name);\n\n            ret = avio_open2(s, filename, AVIO_FLAG_READ, &int_cb, NULL);\n\n        }\n\n        if (ret) {\n\n            snprintf(filename, sizeof(filename), \"%s%s/%s.avpreset\", base[i],\n\n                     i != 1 ? \"\" : \"/.avconv\", preset_name);\n\n            ret = avio_open2(s, filename, AVIO_FLAG_READ, &int_cb, NULL);\n\n        }\n\n    }\n\n    return ret;\n\n}\n", "idx": 3566, "_split": "valid", "_hash": "8055125f5a141569db22be0be9de3b28"}
{"project": "FFmpeg", "commit_id": "42fb414804419c3fc269c73ad049f218f8813ed0", "target": 0, "func": "static int mov_write_mvhd_tag(ByteIOContext *pb, MOVContext *mov)\n\n{\n\n    int maxTrackID = 1, i;\n\n    int64_t maxTrackLenTemp, maxTrackLen = 0;\n\n    int version;\n\n\n\n    for (i=0; i<MAX_STREAMS; i++) {\n\n        if(mov->tracks[i].entry > 0) {\n\n            maxTrackLenTemp = av_rescale_rnd(mov->tracks[i].trackDuration, globalTimescale, mov->tracks[i].timescale, AV_ROUND_UP);\n\n            if(maxTrackLen < maxTrackLenTemp)\n\n                maxTrackLen = maxTrackLenTemp;\n\n            if(maxTrackID < mov->tracks[i].trackID)\n\n                maxTrackID = mov->tracks[i].trackID;\n\n        }\n\n    }\n\n\n\n    version = maxTrackLen < UINT32_MAX ? 0 : 1;\n\n    (version == 1) ? put_be32(pb, 120) : put_be32(pb, 108); /* size */\n\n    put_tag(pb, \"mvhd\");\n\n    put_byte(pb, version);\n\n    put_be24(pb, 0); /* flags */\n\n    if (version == 1) {\n\n        put_be64(pb, mov->time);\n\n        put_be64(pb, mov->time);\n\n    } else {\n\n        put_be32(pb, mov->time); /* creation time */\n\n        put_be32(pb, mov->time); /* modification time */\n\n    }\n\n    put_be32(pb, mov->timescale); /* timescale */\n\n    (version == 1) ? put_be64(pb, maxTrackLen) : put_be32(pb, maxTrackLen); /* duration of longest track */\n\n\n\n    put_be32(pb, 0x00010000); /* reserved (preferred rate) 1.0 = normal */\n\n    put_be16(pb, 0x0100); /* reserved (preferred volume) 1.0 = normal */\n\n    put_be16(pb, 0); /* reserved */\n\n    put_be32(pb, 0); /* reserved */\n\n    put_be32(pb, 0); /* reserved */\n\n\n\n    /* Matrix structure */\n\n    put_be32(pb, 0x00010000); /* reserved */\n\n    put_be32(pb, 0x0); /* reserved */\n\n    put_be32(pb, 0x0); /* reserved */\n\n    put_be32(pb, 0x0); /* reserved */\n\n    put_be32(pb, 0x00010000); /* reserved */\n\n    put_be32(pb, 0x0); /* reserved */\n\n    put_be32(pb, 0x0); /* reserved */\n\n    put_be32(pb, 0x0); /* reserved */\n\n    put_be32(pb, 0x40000000); /* reserved */\n\n\n\n    put_be32(pb, 0); /* reserved (preview time) */\n\n    put_be32(pb, 0); /* reserved (preview duration) */\n\n    put_be32(pb, 0); /* reserved (poster time) */\n\n    put_be32(pb, 0); /* reserved (selection time) */\n\n    put_be32(pb, 0); /* reserved (selection duration) */\n\n    put_be32(pb, 0); /* reserved (current time) */\n\n    put_be32(pb, maxTrackID+1); /* Next track id */\n\n    return 0x6c;\n\n}\n", "idx": 3568, "_split": "valid", "_hash": "2651310d851b01c9b86a1606da4d9db1"}
{"project": "FFmpeg", "commit_id": "ac7ff0963bf353ffd951ae8d51444b82b7ea69c1", "target": 0, "func": "static void apply_tns(float coef[1024], TemporalNoiseShaping *tns,\n\n                      IndividualChannelStream *ics, int decode)\n\n{\n\n    const int mmm = FFMIN(ics->tns_max_bands, ics->max_sfb);\n\n    int w, filt, m, i;\n\n    int bottom, top, order, start, end, size, inc;\n\n    float lpc[TNS_MAX_ORDER];\n\n    float tmp[TNS_MAX_ORDER];\n\n\n\n    for (w = 0; w < ics->num_windows; w++) {\n\n        bottom = ics->num_swb;\n\n        for (filt = 0; filt < tns->n_filt[w]; filt++) {\n\n            top    = bottom;\n\n            bottom = FFMAX(0, top - tns->length[w][filt]);\n\n            order  = tns->order[w][filt];\n\n            if (order == 0)\n\n                continue;\n\n\n\n            // tns_decode_coef\n\n            compute_lpc_coefs(tns->coef[w][filt], order, lpc, 0, 0, 0);\n\n\n\n            start = ics->swb_offset[FFMIN(bottom, mmm)];\n\n            end   = ics->swb_offset[FFMIN(   top, mmm)];\n\n            if ((size = end - start) <= 0)\n\n                continue;\n\n            if (tns->direction[w][filt]) {\n\n                inc = -1;\n\n                start = end - 1;\n\n            } else {\n\n                inc = 1;\n\n            }\n\n            start += w * 128;\n\n\n\n            if (decode) {\n\n                // ar filter\n\n                for (m = 0; m < size; m++, start += inc)\n\n                    for (i = 1; i <= FFMIN(m, order); i++)\n\n                        coef[start] -= coef[start - i * inc] * lpc[i - 1];\n\n            } else {\n\n                // ma filter\n\n                for (m = 0; m < size; m++, start += inc) {\n\n                    tmp[0] = coef[start];\n\n                    for (i = 1; i <= FFMIN(m, order); i++)\n\n                        coef[start] += tmp[i] * lpc[i - 1];\n\n                    for (i = order; i > 0; i--)\n\n                        tmp[i] = tmp[i - 1];\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 3569, "_split": "valid", "_hash": "b8d98944c77a66da3e6ceda4359da5b2"}
{"project": "FFmpeg", "commit_id": "821a5938d100458f4d09d634041b05c860554ce0", "target": 0, "func": "static int g2m_init_buffers(G2MContext *c)\n\n{\n\n    int aligned_height;\n\n\n\n    if (!c->framebuf || c->old_width < c->width || c->old_height < c->height) {\n\n        c->framebuf_stride = FFALIGN(c->width * 3, 16);\n\n        aligned_height     = FFALIGN(c->height,    16);\n\n        av_free(c->framebuf);\n\n        c->framebuf = av_mallocz(c->framebuf_stride * aligned_height);\n\n        if (!c->framebuf)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    if (!c->synth_tile || !c->jpeg_tile ||\n\n        c->old_tile_w < c->tile_width ||\n\n        c->old_tile_h < c->tile_height) {\n\n        c->tile_stride = FFALIGN(c->tile_width * 3, 16);\n\n        aligned_height = FFALIGN(c->tile_height,    16);\n\n        av_free(c->synth_tile);\n\n        av_free(c->jpeg_tile);\n\n        av_free(c->kempf_buf);\n\n        av_free(c->kempf_flags);\n\n        c->synth_tile  = av_mallocz(c->tile_stride      * aligned_height);\n\n        c->jpeg_tile   = av_mallocz(c->tile_stride      * aligned_height);\n\n        c->kempf_buf   = av_mallocz((c->tile_width + 1) * aligned_height\n\n                                    + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        c->kempf_flags = av_mallocz( c->tile_width      * aligned_height);\n\n        if (!c->synth_tile || !c->jpeg_tile ||\n\n            !c->kempf_buf || !c->kempf_flags)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 3585, "_split": "valid", "_hash": "50c5e854cfd6255ee57ac73252204b22"}
{"project": "FFmpeg", "commit_id": "f30a7d9861af884f352ec2484820a75d79a4e0e2", "target": 0, "func": "int ff_mpv_common_frame_size_change(MpegEncContext *s)\n\n{\n\n    int i, err = 0;\n\n\n\n    if (!s->context_initialized)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (s->slice_context_count > 1) {\n\n        for (i = 0; i < s->slice_context_count; i++) {\n\n            free_duplicate_context(s->thread_context[i]);\n\n        }\n\n        for (i = 1; i < s->slice_context_count; i++) {\n\n            av_freep(&s->thread_context[i]);\n\n        }\n\n    } else\n\n        free_duplicate_context(s);\n\n\n\n    free_context_frame(s);\n\n\n\n    if (s->picture)\n\n        for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n                s->picture[i].needs_realloc = 1;\n\n        }\n\n\n\n    s->last_picture_ptr         =\n\n    s->next_picture_ptr         =\n\n    s->current_picture_ptr      = NULL;\n\n\n\n    // init\n\n    if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO && !s->progressive_sequence)\n\n        s->mb_height = (s->height + 31) / 32 * 2;\n\n    else\n\n        s->mb_height = (s->height + 15) / 16;\n\n\n\n    if ((s->width || s->height) &&\n\n        (err = av_image_check_size(s->width, s->height, 0, s->avctx)) < 0)\n\n        goto fail;\n\n\n\n    if ((err = init_context_frame(s)))\n\n        goto fail;\n\n\n\n    s->thread_context[0]   = s;\n\n\n\n    if (s->width && s->height) {\n\n        int nb_slices = s->slice_context_count;\n\n        if (nb_slices > 1) {\n\n            for (i = 1; i < nb_slices; i++) {\n\n                s->thread_context[i] = av_malloc(sizeof(MpegEncContext));\n\n                memcpy(s->thread_context[i], s, sizeof(MpegEncContext));\n\n            }\n\n\n\n            for (i = 0; i < nb_slices; i++) {\n\n                if ((err = init_duplicate_context(s->thread_context[i])) < 0)\n\n                    goto fail;\n\n                    s->thread_context[i]->start_mb_y =\n\n                        (s->mb_height * (i) + nb_slices / 2) / nb_slices;\n\n                    s->thread_context[i]->end_mb_y   =\n\n                        (s->mb_height * (i + 1) + nb_slices / 2) / nb_slices;\n\n            }\n\n        } else {\n\n            err = init_duplicate_context(s);\n\n            if (err < 0)\n\n                goto fail;\n\n            s->start_mb_y = 0;\n\n            s->end_mb_y   = s->mb_height;\n\n        }\n\n        s->slice_context_count = nb_slices;\n\n    }\n\n\n\n    return 0;\n\n fail:\n\n    ff_mpv_common_end(s);\n\n    return err;\n\n}\n", "idx": 3616, "_split": "valid", "_hash": "797a93546f9142eeb9e5152fbeacf948"}
{"project": "FFmpeg", "commit_id": "3e0f7126b53b395d9e79df57b2e626eb99ad846b", "target": 1, "func": "void ff_snow_horizontal_compose97i_mmx(DWTELEM *b, int width){\n\n    const int w2= (width+1)>>1;\n\n    DWTELEM temp[width >> 1];\n\n    const int w_l= (width>>1);\n\n    const int w_r= w2 - 1;\n\n    int i;\n\n\n\n    { // Lift 0\n\n        DWTELEM * const ref = b + w2 - 1;\n\n\n\n        i = 1;\n\n        b[0] = b[0] - ((W_DM * 2 * ref[1]+W_DO)>>W_DS);\n\n        asm volatile(\n\n            \"pcmpeqd    %%mm7, %%mm7         \\n\\t\"\n\n            \"pslld        $31, %%mm7         \\n\\t\"\n\n            \"psrld        $29, %%mm7         \\n\\t\"\n\n           ::);\n\n        for(; i<w_l-3; i+=4){\n\n            asm volatile(\n\n                \"movq     (%1), %%mm2        \\n\\t\"\n\n                \"movq    8(%1), %%mm6        \\n\\t\"\n\n                \"paddd   4(%1), %%mm2        \\n\\t\"\n\n                \"paddd  12(%1), %%mm6        \\n\\t\"\n\n                \"movq    %%mm2, %%mm0        \\n\\t\"\n\n                \"movq    %%mm6, %%mm4        \\n\\t\"\n\n                \"paddd   %%mm2, %%mm2        \\n\\t\"\n\n                \"paddd   %%mm6, %%mm6        \\n\\t\"\n\n                \"paddd   %%mm0, %%mm2        \\n\\t\"\n\n                \"paddd   %%mm4, %%mm6        \\n\\t\"\n\n                \"paddd   %%mm7, %%mm2        \\n\\t\"\n\n                \"paddd   %%mm7, %%mm6        \\n\\t\"\n\n                \"psrad      $3, %%mm2        \\n\\t\"\n\n                \"psrad      $3, %%mm6        \\n\\t\"\n\n                \"movq     (%0), %%mm0        \\n\\t\"\n\n                \"movq    8(%0), %%mm4        \\n\\t\"\n\n                \"psubd   %%mm2, %%mm0        \\n\\t\"\n\n                \"psubd   %%mm6, %%mm4        \\n\\t\"\n\n                \"movq    %%mm0, (%0)         \\n\\t\"\n\n                \"movq    %%mm4, 8(%0)        \\n\\t\"\n\n                :: \"r\"(&b[i]), \"r\"(&ref[i])\n\n                 : \"memory\"\n\n               );\n\n        }\n\n        snow_horizontal_compose_lift_lead_out(i, b, b, ref, width, w_l, 0, W_DM, W_DO, W_DS);\n\n    }\n\n\n\n    { // Lift 1\n\n        DWTELEM * const dst = b+w2;\n\n\n\n        i = 0;\n\n        for(; i<w_r-3; i+=4){\n\n            asm volatile(\n\n                \"movq     (%1), %%mm2        \\n\\t\"\n\n                \"movq    8(%1), %%mm6        \\n\\t\"\n\n                \"paddd   4(%1), %%mm2        \\n\\t\"\n\n                \"paddd  12(%1), %%mm6        \\n\\t\"\n\n                \"movq     (%0), %%mm0        \\n\\t\"\n\n                \"movq    8(%0), %%mm4        \\n\\t\"\n\n                \"psubd   %%mm2, %%mm0        \\n\\t\"\n\n                \"psubd   %%mm6, %%mm4        \\n\\t\"\n\n                \"movq    %%mm0, (%0)         \\n\\t\"\n\n                \"movq    %%mm4, 8(%0)        \\n\\t\"\n\n                :: \"r\"(&dst[i]), \"r\"(&b[i])\n\n                 : \"memory\"\n\n               );\n\n        }\n\n        snow_horizontal_compose_lift_lead_out(i, dst, dst, b, width, w_r, 1, W_CM, W_CO, W_CS);\n\n    }\n\n\n\n    { // Lift 2\n\n        DWTELEM * const ref = b+w2 - 1;\n\n\n\n        i = 1;\n\n        b[0] = b[0] + (((2 * ref[1] + W_BO) + 4 * b[0]) >> W_BS);\n\n        asm volatile(\n\n            \"pslld          $1, %%mm7        \\n\\t\"\n\n           ::);\n\n        for(; i<w_l-3; i+=4){\n\n            asm volatile(\n\n                \"movq     (%1), %%mm0        \\n\\t\"\n\n                \"movq    8(%1), %%mm4        \\n\\t\"\n\n                \"paddd   4(%1), %%mm0        \\n\\t\"\n\n                \"paddd  12(%1), %%mm4        \\n\\t\"\n\n                \"paddd   %%mm7, %%mm0        \\n\\t\"\n\n                \"paddd   %%mm7, %%mm4        \\n\\t\"\n\n                \"psrad      $2, %%mm0        \\n\\t\"\n\n                \"psrad      $2, %%mm4        \\n\\t\"\n\n                \"movq     (%0), %%mm1        \\n\\t\"\n\n                \"movq    8(%0), %%mm5        \\n\\t\"\n\n                \"paddd   %%mm1, %%mm0        \\n\\t\"\n\n                \"paddd   %%mm5, %%mm4        \\n\\t\"\n\n                \"psrad      $2, %%mm0        \\n\\t\"\n\n                \"psrad      $2, %%mm4        \\n\\t\"\n\n                \"paddd   %%mm1, %%mm0        \\n\\t\"\n\n                \"paddd   %%mm5, %%mm4        \\n\\t\"\n\n                \"movq    %%mm0, (%0)         \\n\\t\"\n\n                \"movq    %%mm4, 8(%0)        \\n\\t\"\n\n                :: \"r\"(&b[i]), \"r\"(&ref[i])\n\n                 : \"memory\"\n\n               );\n\n        }\n\n        snow_horizontal_compose_liftS_lead_out(i, b, b, ref, width, w_l);\n\n    }\n\n\n\n    { // Lift 3\n\n        DWTELEM * const src = b+w2;\n\n        i = 0;\n\n\n\n        for(; i<w_r-3; i+=4){\n\n            asm volatile(\n\n                \"movq    4(%1), %%mm2        \\n\\t\"\n\n                \"movq   12(%1), %%mm6        \\n\\t\"\n\n                \"paddd    (%1), %%mm2        \\n\\t\"\n\n                \"paddd   8(%1), %%mm6        \\n\\t\"\n\n                \"movq     (%0), %%mm0        \\n\\t\"\n\n                \"movq    8(%0), %%mm4        \\n\\t\"\n\n                \"paddd   %%mm2, %%mm0        \\n\\t\"\n\n                \"paddd   %%mm6, %%mm4        \\n\\t\"\n\n                \"psrad      $1, %%mm2        \\n\\t\"\n\n                \"psrad      $1, %%mm6        \\n\\t\"\n\n                \"paddd   %%mm0, %%mm2        \\n\\t\"\n\n                \"paddd   %%mm4, %%mm6        \\n\\t\"\n\n                \"movq    %%mm2, (%2)         \\n\\t\"\n\n                \"movq    %%mm6, 8(%2)        \\n\\t\"\n\n                :: \"r\"(&src[i]), \"r\"(&b[i]), \"r\"(&temp[i])\n\n                 : \"memory\"\n\n               );\n\n        }\n\n        snow_horizontal_compose_lift_lead_out(i, temp, src, b, width, w_r, 1, -W_AM, W_AO+1, W_AS);\n\n    }\n\n\n\n    {\n\n        snow_interleave_line_header(&i, width, b, temp);\n\n\n\n        for (; (i & 0xE) != 0xE; i-=2){\n\n            b[i+1] = temp[i>>1];\n\n            b[i] = b[i>>1];\n\n        }\n\n        for (i-=14; i>=0; i-=16){\n\n            asm volatile(\n\n                \"movq        (%1), %%mm0       \\n\\t\"\n\n                \"movq       8(%1), %%mm2       \\n\\t\"\n\n                \"movq      16(%1), %%mm4       \\n\\t\"\n\n                \"movq      24(%1), %%mm6       \\n\\t\"\n\n                \"movq        (%1), %%mm1       \\n\\t\"\n\n                \"movq       8(%1), %%mm3       \\n\\t\"\n\n                \"movq      16(%1), %%mm5       \\n\\t\"\n\n                \"movq      24(%1), %%mm7       \\n\\t\"\n\n                \"punpckldq   (%2), %%mm0       \\n\\t\"\n\n                \"punpckldq  8(%2), %%mm2       \\n\\t\"\n\n                \"punpckldq 16(%2), %%mm4       \\n\\t\"\n\n                \"punpckldq 24(%2), %%mm6       \\n\\t\"\n\n                \"movq       %%mm0, (%0)        \\n\\t\"\n\n                \"movq       %%mm2, 16(%0)      \\n\\t\"\n\n                \"movq       %%mm4, 32(%0)      \\n\\t\"\n\n                \"movq       %%mm6, 48(%0)      \\n\\t\"\n\n                \"punpckhdq   (%2), %%mm1       \\n\\t\"\n\n                \"punpckhdq  8(%2), %%mm3       \\n\\t\"\n\n                \"punpckhdq 16(%2), %%mm5       \\n\\t\"\n\n                \"punpckhdq 24(%2), %%mm7       \\n\\t\"\n\n                \"movq       %%mm1, 8(%0)       \\n\\t\"\n\n                \"movq       %%mm3, 24(%0)      \\n\\t\"\n\n                \"movq       %%mm5, 40(%0)      \\n\\t\"\n\n                \"movq       %%mm7, 56(%0)      \\n\\t\"\n\n                :: \"r\"(&b[i]), \"r\"(&b[i>>1]), \"r\"(&temp[i>>1])\n\n                 : \"memory\"\n\n               );\n\n        }\n\n    }\n\n}\n", "idx": 3619, "_split": "valid", "_hash": "70e5ccd625ddfa30ccf31031a7f19dfc"}
{"project": "FFmpeg", "commit_id": "db9aee6ccf183508835acc325f5ad87d595eacc4", "target": 0, "func": "static int oma_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    OMAContext *oc = s->priv_data;\n\n    int packet_size = s->streams[0]->codec->block_align;\n\n    int ret = av_get_packet(s->pb, pkt, packet_size);\n\n\n\n    if (ret <= 0)\n\n        return AVERROR(EIO);\n\n\n\n    pkt->stream_index = 0;\n\n\n\n    if (oc->encrypted) {\n\n        /* previous unencrypted block saved in IV for\n\n         * the next packet (CBC mode) */\n\n        av_des_crypt(&oc->av_des, pkt->data, pkt->data,\n\n                     (packet_size >> 3), oc->iv, 1);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 3620, "_split": "valid", "_hash": "7d037704de7b969f8cab74fbce0b02a9"}
{"project": "FFmpeg", "commit_id": "c89658008705d949c319df3fa6f400c481ad73e1", "target": 0, "func": "static int rtsp_fetch_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    int ret, len;\n\n    uint8_t buf[10 * RTP_MAX_PACKET_LENGTH];\n\n    RTSPStream *rtsp_st;\n\n\n\n    /* get next frames from the same RTP packet */\n\n    if (rt->cur_transport_priv) {\n\n        if (rt->transport == RTSP_TRANSPORT_RDT)\n\n            ret = ff_rdt_parse_packet(rt->cur_transport_priv, pkt, NULL, 0);\n\n        else\n\n            ret = rtp_parse_packet(rt->cur_transport_priv, pkt, NULL, 0);\n\n        if (ret == 0) {\n\n            rt->cur_transport_priv = NULL;\n\n            return 0;\n\n        } else if (ret == 1) {\n\n            return 0;\n\n        } else {\n\n            rt->cur_transport_priv = NULL;\n\n        }\n\n    }\n\n\n\n    /* read next RTP packet */\n\n redo:\n\n    switch(rt->lower_transport) {\n\n    default:\n\n#if CONFIG_RTSP_DEMUXER\n\n    case RTSP_LOWER_TRANSPORT_TCP:\n\n        len = tcp_read_packet(s, &rtsp_st, buf, sizeof(buf));\n\n        break;\n\n#endif\n\n    case RTSP_LOWER_TRANSPORT_UDP:\n\n    case RTSP_LOWER_TRANSPORT_UDP_MULTICAST:\n\n        len = udp_read_packet(s, &rtsp_st, buf, sizeof(buf));\n\n        if (len >=0 && rtsp_st->transport_priv && rt->transport == RTSP_TRANSPORT_RTP)\n\n            rtp_check_and_send_back_rr(rtsp_st->transport_priv, len);\n\n        break;\n\n    }\n\n    if (len < 0)\n\n        return len;\n\n    if (len == 0)\n\n        return AVERROR_EOF;\n\n    if (rt->transport == RTSP_TRANSPORT_RDT)\n\n        ret = ff_rdt_parse_packet(rtsp_st->transport_priv, pkt, buf, len);\n\n    else\n\n        ret = rtp_parse_packet(rtsp_st->transport_priv, pkt, buf, len);\n\n    if (ret < 0)\n\n        goto redo;\n\n    if (ret == 1) {\n\n        /* more packets may follow, so we save the RTP context */\n\n        rt->cur_transport_priv = rtsp_st->transport_priv;\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 3637, "_split": "valid", "_hash": "64579b0082f64062b30ffdd7cbba9fdd"}
{"project": "FFmpeg", "commit_id": "c89658008705d949c319df3fa6f400c481ad73e1", "target": 0, "func": "rtsp_open_transport_ctx(AVFormatContext *s, RTSPStream *rtsp_st)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    AVStream *st = NULL;\n\n\n\n    /* open the RTP context */\n\n    if (rtsp_st->stream_index >= 0)\n\n        st = s->streams[rtsp_st->stream_index];\n\n    if (!st)\n\n        s->ctx_flags |= AVFMTCTX_NOHEADER;\n\n\n\n    if (rt->transport == RTSP_TRANSPORT_RDT)\n\n        rtsp_st->transport_priv = ff_rdt_parse_open(s, st->index,\n\n                                            rtsp_st->dynamic_protocol_context,\n\n                                            rtsp_st->dynamic_handler);\n\n    else\n\n        rtsp_st->transport_priv = rtp_parse_open(s, st, rtsp_st->rtp_handle,\n\n                                         rtsp_st->sdp_payload_type,\n\n                                         &rtsp_st->rtp_payload_data);\n\n\n\n    if (!rtsp_st->transport_priv) {\n\n         return AVERROR(ENOMEM);\n\n    } else if (rt->transport != RTSP_TRANSPORT_RDT) {\n\n        if(rtsp_st->dynamic_handler) {\n\n            rtp_parse_set_dynamic_protocol(rtsp_st->transport_priv,\n\n                                           rtsp_st->dynamic_protocol_context,\n\n                                           rtsp_st->dynamic_handler);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 3638, "_split": "valid", "_hash": "7cb1aa6e2292e170cbbc857f81505088"}
{"project": "FFmpeg", "commit_id": "c5fa42c69aeccd644fb5a42b4995602d206f168b", "target": 0, "func": "void ff_print_debug_info2(AVCodecContext *avctx, AVFrame *pict, uint8_t *mbskip_table,\n\n                         uint32_t *mbtype_table, int8_t *qscale_table, int16_t (*motion_val[2])[2],\n\n                         int *low_delay,\n\n                         int mb_width, int mb_height, int mb_stride, int quarter_sample)\n\n{\n\n    if ((avctx->flags2 & AV_CODEC_FLAG2_EXPORT_MVS) && mbtype_table && motion_val[0]) {\n\n        const int shift = 1 + quarter_sample;\n\n        const int mv_sample_log2 = avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_SVQ3 ? 2 : 1;\n\n        const int mv_stride      = (mb_width << mv_sample_log2) +\n\n                                   (avctx->codec->id == AV_CODEC_ID_H264 ? 0 : 1);\n\n        int mb_x, mb_y, mbcount = 0;\n\n\n\n        /* size is width * height * 2 * 4 where 2 is for directions and 4 is\n\n         * for the maximum number of MB (4 MB in case of IS_8x8) */\n\n        AVMotionVector *mvs = av_malloc_array(mb_width * mb_height, 2 * 4 * sizeof(AVMotionVector));\n\n        if (!mvs)\n\n            return;\n\n\n\n        for (mb_y = 0; mb_y < mb_height; mb_y++) {\n\n            for (mb_x = 0; mb_x < mb_width; mb_x++) {\n\n                int i, direction, mb_type = mbtype_table[mb_x + mb_y * mb_stride];\n\n                for (direction = 0; direction < 2; direction++) {\n\n                    if (!USES_LIST(mb_type, direction))\n\n                        continue;\n\n                    if (IS_8X8(mb_type)) {\n\n                        for (i = 0; i < 4; i++) {\n\n                            int sx = mb_x * 16 + 4 + 8 * (i & 1);\n\n                            int sy = mb_y * 16 + 4 + 8 * (i >> 1);\n\n                            int xy = (mb_x * 2 + (i & 1) +\n\n                                      (mb_y * 2 + (i >> 1)) * mv_stride) << (mv_sample_log2 - 1);\n\n                            int mx = (motion_val[direction][xy][0] >> shift) + sx;\n\n                            int my = (motion_val[direction][xy][1] >> shift) + sy;\n\n                            mbcount += add_mb(mvs + mbcount, mb_type, sx, sy, mx, my, direction);\n\n                        }\n\n                    } else if (IS_16X8(mb_type)) {\n\n                        for (i = 0; i < 2; i++) {\n\n                            int sx = mb_x * 16 + 8;\n\n                            int sy = mb_y * 16 + 4 + 8 * i;\n\n                            int xy = (mb_x * 2 + (mb_y * 2 + i) * mv_stride) << (mv_sample_log2 - 1);\n\n                            int mx = (motion_val[direction][xy][0] >> shift);\n\n                            int my = (motion_val[direction][xy][1] >> shift);\n\n\n\n                            if (IS_INTERLACED(mb_type))\n\n                                my *= 2;\n\n\n\n                            mbcount += add_mb(mvs + mbcount, mb_type, sx, sy, mx + sx, my + sy, direction);\n\n                        }\n\n                    } else if (IS_8X16(mb_type)) {\n\n                        for (i = 0; i < 2; i++) {\n\n                            int sx = mb_x * 16 + 4 + 8 * i;\n\n                            int sy = mb_y * 16 + 8;\n\n                            int xy = (mb_x * 2 + i + mb_y * 2 * mv_stride) << (mv_sample_log2 - 1);\n\n                            int mx = motion_val[direction][xy][0] >> shift;\n\n                            int my = motion_val[direction][xy][1] >> shift;\n\n\n\n                            if (IS_INTERLACED(mb_type))\n\n                                my *= 2;\n\n\n\n                            mbcount += add_mb(mvs + mbcount, mb_type, sx, sy, mx + sx, my + sy, direction);\n\n                        }\n\n                    } else {\n\n                          int sx = mb_x * 16 + 8;\n\n                          int sy = mb_y * 16 + 8;\n\n                          int xy = (mb_x + mb_y * mv_stride) << mv_sample_log2;\n\n                          int mx = (motion_val[direction][xy][0]>>shift) + sx;\n\n                          int my = (motion_val[direction][xy][1]>>shift) + sy;\n\n                          mbcount += add_mb(mvs + mbcount, mb_type, sx, sy, mx, my, direction);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        if (mbcount) {\n\n            AVFrameSideData *sd;\n\n\n\n            av_log(avctx, AV_LOG_DEBUG, \"Adding %d MVs info to frame %d\\n\", mbcount, avctx->frame_number);\n\n            sd = av_frame_new_side_data(pict, AV_FRAME_DATA_MOTION_VECTORS, mbcount * sizeof(AVMotionVector));\n\n            if (!sd) {\n\n                av_freep(&mvs);\n\n                return;\n\n            }\n\n            memcpy(sd->data, mvs, mbcount * sizeof(AVMotionVector));\n\n        }\n\n\n\n        av_freep(&mvs);\n\n    }\n\n\n\n    /* TODO: export all the following to make them accessible for users (and filters) */\n\n    if (avctx->hwaccel || !mbtype_table\n\n#if FF_API_CAP_VDPAU\n\n        || (avctx->codec->capabilities&AV_CODEC_CAP_HWACCEL_VDPAU)\n\n#endif\n\n        )\n\n        return;\n\n\n\n\n\n    if (avctx->debug & (FF_DEBUG_SKIP | FF_DEBUG_QP | FF_DEBUG_MB_TYPE)) {\n\n        int x,y;\n\n\n\n        av_log(avctx, AV_LOG_DEBUG, \"New frame, type: %c\\n\",\n\n               av_get_picture_type_char(pict->pict_type));\n\n        for (y = 0; y < mb_height; y++) {\n\n            for (x = 0; x < mb_width; x++) {\n\n                if (avctx->debug & FF_DEBUG_SKIP) {\n\n                    int count = mbskip_table ? mbskip_table[x + y * mb_stride] : 0;\n\n                    if (count > 9)\n\n                        count = 9;\n\n                    av_log(avctx, AV_LOG_DEBUG, \"%1d\", count);\n\n                }\n\n                if (avctx->debug & FF_DEBUG_QP) {\n\n                    av_log(avctx, AV_LOG_DEBUG, \"%2d\",\n\n                           qscale_table[x + y * mb_stride]);\n\n                }\n\n                if (avctx->debug & FF_DEBUG_MB_TYPE) {\n\n                    int mb_type = mbtype_table[x + y * mb_stride];\n\n                    // Type & MV direction\n\n                    if (IS_PCM(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"P\");\n\n                    else if (IS_INTRA(mb_type) && IS_ACPRED(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"A\");\n\n                    else if (IS_INTRA4x4(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"i\");\n\n                    else if (IS_INTRA16x16(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"I\");\n\n                    else if (IS_DIRECT(mb_type) && IS_SKIP(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"d\");\n\n                    else if (IS_DIRECT(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"D\");\n\n                    else if (IS_GMC(mb_type) && IS_SKIP(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"g\");\n\n                    else if (IS_GMC(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"G\");\n\n                    else if (IS_SKIP(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"S\");\n\n                    else if (!USES_LIST(mb_type, 1))\n\n                        av_log(avctx, AV_LOG_DEBUG, \">\");\n\n                    else if (!USES_LIST(mb_type, 0))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"<\");\n\n                    else {\n\n                        av_assert2(USES_LIST(mb_type, 0) && USES_LIST(mb_type, 1));\n\n                        av_log(avctx, AV_LOG_DEBUG, \"X\");\n\n                    }\n\n\n\n                    // segmentation\n\n                    if (IS_8X8(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"+\");\n\n                    else if (IS_16X8(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"-\");\n\n                    else if (IS_8X16(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"|\");\n\n                    else if (IS_INTRA(mb_type) || IS_16X16(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \" \");\n\n                    else\n\n                        av_log(avctx, AV_LOG_DEBUG, \"?\");\n\n\n\n\n\n                    if (IS_INTERLACED(mb_type))\n\n                        av_log(avctx, AV_LOG_DEBUG, \"=\");\n\n                    else\n\n                        av_log(avctx, AV_LOG_DEBUG, \" \");\n\n                }\n\n            }\n\n            av_log(avctx, AV_LOG_DEBUG, \"\\n\");\n\n        }\n\n    }\n\n\n\n    if ((avctx->debug & (FF_DEBUG_VIS_QP | FF_DEBUG_VIS_MB_TYPE)) ||\n\n        (avctx->debug_mv)) {\n\n        int mb_y;\n\n        int i;\n\n        int h_chroma_shift, v_chroma_shift, block_height;\n\n#if FF_API_VISMV\n\n        const int shift = 1 + quarter_sample;\n\n        uint8_t *ptr;\n\n        const int width          = avctx->width;\n\n        const int height         = avctx->height;\n\n#endif\n\n        const int mv_sample_log2 = avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_SVQ3 ? 2 : 1;\n\n        const int mv_stride      = (mb_width << mv_sample_log2) +\n\n                                   (avctx->codec->id == AV_CODEC_ID_H264 ? 0 : 1);\n\n\n\n        *low_delay = 0; // needed to see the vectors without trashing the buffers\n\n\n\n        avcodec_get_chroma_sub_sample(avctx->pix_fmt, &h_chroma_shift, &v_chroma_shift);\n\n\n\n        av_frame_make_writable(pict);\n\n\n\n        pict->opaque = NULL;\n\n#if FF_API_VISMV\n\n        ptr          = pict->data[0];\n\n#endif\n\n        block_height = 16 >> v_chroma_shift;\n\n\n\n        for (mb_y = 0; mb_y < mb_height; mb_y++) {\n\n            int mb_x;\n\n            for (mb_x = 0; mb_x < mb_width; mb_x++) {\n\n                const int mb_index = mb_x + mb_y * mb_stride;\n\n#if FF_API_VISMV\n\n                if ((avctx->debug_mv) && motion_val[0]) {\n\n                    int type;\n\n                    for (type = 0; type < 3; type++) {\n\n                        int direction = 0;\n\n                        switch (type) {\n\n                        case 0:\n\n                            if ((!(avctx->debug_mv & FF_DEBUG_VIS_MV_P_FOR)) ||\n\n                                (pict->pict_type!= AV_PICTURE_TYPE_P))\n\n                                continue;\n\n                            direction = 0;\n\n                            break;\n\n                        case 1:\n\n                            if ((!(avctx->debug_mv & FF_DEBUG_VIS_MV_B_FOR)) ||\n\n                                (pict->pict_type!= AV_PICTURE_TYPE_B))\n\n                                continue;\n\n                            direction = 0;\n\n                            break;\n\n                        case 2:\n\n                            if ((!(avctx->debug_mv & FF_DEBUG_VIS_MV_B_BACK)) ||\n\n                                (pict->pict_type!= AV_PICTURE_TYPE_B))\n\n                                continue;\n\n                            direction = 1;\n\n                            break;\n\n                        }\n\n                        if (!USES_LIST(mbtype_table[mb_index], direction))\n\n                            continue;\n\n\n\n                        if (IS_8X8(mbtype_table[mb_index])) {\n\n                            int i;\n\n                            for (i = 0; i < 4; i++) {\n\n                                int sx = mb_x * 16 + 4 + 8 * (i & 1);\n\n                                int sy = mb_y * 16 + 4 + 8 * (i >> 1);\n\n                                int xy = (mb_x * 2 + (i & 1) +\n\n                                          (mb_y * 2 + (i >> 1)) * mv_stride) << (mv_sample_log2 - 1);\n\n                                int mx = (motion_val[direction][xy][0] >> shift) + sx;\n\n                                int my = (motion_val[direction][xy][1] >> shift) + sy;\n\n                                draw_arrow(ptr, sx, sy, mx, my, width,\n\n                                           height, pict->linesize[0], 100, 0, direction);\n\n                            }\n\n                        } else if (IS_16X8(mbtype_table[mb_index])) {\n\n                            int i;\n\n                            for (i = 0; i < 2; i++) {\n\n                                int sx = mb_x * 16 + 8;\n\n                                int sy = mb_y * 16 + 4 + 8 * i;\n\n                                int xy = (mb_x * 2 + (mb_y * 2 + i) * mv_stride) << (mv_sample_log2 - 1);\n\n                                int mx = (motion_val[direction][xy][0] >> shift);\n\n                                int my = (motion_val[direction][xy][1] >> shift);\n\n\n\n                                if (IS_INTERLACED(mbtype_table[mb_index]))\n\n                                    my *= 2;\n\n\n\n                                draw_arrow(ptr, sx, sy, mx + sx, my + sy, width,\n\n                                           height, pict->linesize[0], 100, 0, direction);\n\n                            }\n\n                        } else if (IS_8X16(mbtype_table[mb_index])) {\n\n                            int i;\n\n                            for (i = 0; i < 2; i++) {\n\n                                int sx = mb_x * 16 + 4 + 8 * i;\n\n                                int sy = mb_y * 16 + 8;\n\n                                int xy = (mb_x * 2 + i + mb_y * 2 * mv_stride) << (mv_sample_log2 - 1);\n\n                                int mx = motion_val[direction][xy][0] >> shift;\n\n                                int my = motion_val[direction][xy][1] >> shift;\n\n\n\n                                if (IS_INTERLACED(mbtype_table[mb_index]))\n\n                                    my *= 2;\n\n\n\n                                draw_arrow(ptr, sx, sy, mx + sx, my + sy, width,\n\n                                           height, pict->linesize[0], 100, 0, direction);\n\n                            }\n\n                        } else {\n\n                              int sx= mb_x * 16 + 8;\n\n                              int sy= mb_y * 16 + 8;\n\n                              int xy= (mb_x + mb_y * mv_stride) << mv_sample_log2;\n\n                              int mx= (motion_val[direction][xy][0]>>shift) + sx;\n\n                              int my= (motion_val[direction][xy][1]>>shift) + sy;\n\n                              draw_arrow(ptr, sx, sy, mx, my, width, height, pict->linesize[0], 100, 0, direction);\n\n                        }\n\n                    }\n\n                }\n\n#endif\n\n                if ((avctx->debug & FF_DEBUG_VIS_QP)) {\n\n                    uint64_t c = (qscale_table[mb_index] * 128 / 31) *\n\n                                 0x0101010101010101ULL;\n\n                    int y;\n\n                    for (y = 0; y < block_height; y++) {\n\n                        *(uint64_t *)(pict->data[1] + 8 * mb_x +\n\n                                      (block_height * mb_y + y) *\n\n                                      pict->linesize[1]) = c;\n\n                        *(uint64_t *)(pict->data[2] + 8 * mb_x +\n\n                                      (block_height * mb_y + y) *\n\n                                      pict->linesize[2]) = c;\n\n                    }\n\n                }\n\n                if ((avctx->debug & FF_DEBUG_VIS_MB_TYPE) &&\n\n                    motion_val[0]) {\n\n                    int mb_type = mbtype_table[mb_index];\n\n                    uint64_t u,v;\n\n                    int y;\n\n#define COLOR(theta, r) \\\n\n    u = (int)(128 + r * cos(theta * 3.141592 / 180)); \\\n\n    v = (int)(128 + r * sin(theta * 3.141592 / 180));\n\n\n\n\n\n                    u = v = 128;\n\n                    if (IS_PCM(mb_type)) {\n\n                        COLOR(120, 48)\n\n                    } else if ((IS_INTRA(mb_type) && IS_ACPRED(mb_type)) ||\n\n                               IS_INTRA16x16(mb_type)) {\n\n                        COLOR(30, 48)\n\n                    } else if (IS_INTRA4x4(mb_type)) {\n\n                        COLOR(90, 48)\n\n                    } else if (IS_DIRECT(mb_type) && IS_SKIP(mb_type)) {\n\n                        // COLOR(120, 48)\n\n                    } else if (IS_DIRECT(mb_type)) {\n\n                        COLOR(150, 48)\n\n                    } else if (IS_GMC(mb_type) && IS_SKIP(mb_type)) {\n\n                        COLOR(170, 48)\n\n                    } else if (IS_GMC(mb_type)) {\n\n                        COLOR(190, 48)\n\n                    } else if (IS_SKIP(mb_type)) {\n\n                        // COLOR(180, 48)\n\n                    } else if (!USES_LIST(mb_type, 1)) {\n\n                        COLOR(240, 48)\n\n                    } else if (!USES_LIST(mb_type, 0)) {\n\n                        COLOR(0, 48)\n\n                    } else {\n\n                        av_assert2(USES_LIST(mb_type, 0) && USES_LIST(mb_type, 1));\n\n                        COLOR(300,48)\n\n                    }\n\n\n\n                    u *= 0x0101010101010101ULL;\n\n                    v *= 0x0101010101010101ULL;\n\n                    for (y = 0; y < block_height; y++) {\n\n                        *(uint64_t *)(pict->data[1] + 8 * mb_x +\n\n                                      (block_height * mb_y + y) * pict->linesize[1]) = u;\n\n                        *(uint64_t *)(pict->data[2] + 8 * mb_x +\n\n                                      (block_height * mb_y + y) * pict->linesize[2]) = v;\n\n                    }\n\n\n\n                    // segmentation\n\n                    if (IS_8X8(mb_type) || IS_16X8(mb_type)) {\n\n                        *(uint64_t *)(pict->data[0] + 16 * mb_x + 0 +\n\n                                      (16 * mb_y + 8) * pict->linesize[0]) ^= 0x8080808080808080ULL;\n\n                        *(uint64_t *)(pict->data[0] + 16 * mb_x + 8 +\n\n                                      (16 * mb_y + 8) * pict->linesize[0]) ^= 0x8080808080808080ULL;\n\n                    }\n\n                    if (IS_8X8(mb_type) || IS_8X16(mb_type)) {\n\n                        for (y = 0; y < 16; y++)\n\n                            pict->data[0][16 * mb_x + 8 + (16 * mb_y + y) *\n\n                                          pict->linesize[0]] ^= 0x80;\n\n                    }\n\n                    if (IS_8X8(mb_type) && mv_sample_log2 >= 2) {\n\n                        int dm = 1 << (mv_sample_log2 - 2);\n\n                        for (i = 0; i < 4; i++) {\n\n                            int sx = mb_x * 16 + 8 * (i & 1);\n\n                            int sy = mb_y * 16 + 8 * (i >> 1);\n\n                            int xy = (mb_x * 2 + (i & 1) +\n\n                                     (mb_y * 2 + (i >> 1)) * mv_stride) << (mv_sample_log2 - 1);\n\n                            // FIXME bidir\n\n                            int32_t *mv = (int32_t *) &motion_val[0][xy];\n\n                            if (mv[0] != mv[dm] ||\n\n                                mv[dm * mv_stride] != mv[dm * (mv_stride + 1)])\n\n                                for (y = 0; y < 8; y++)\n\n                                    pict->data[0][sx + 4 + (sy + y) * pict->linesize[0]] ^= 0x80;\n\n                            if (mv[0] != mv[dm * mv_stride] || mv[dm] != mv[dm * (mv_stride + 1)])\n\n                                *(uint64_t *)(pict->data[0] + sx + (sy + 4) *\n\n                                              pict->linesize[0]) ^= 0x8080808080808080ULL;\n\n                        }\n\n                    }\n\n\n\n                    if (IS_INTERLACED(mb_type) &&\n\n                        avctx->codec->id == AV_CODEC_ID_H264) {\n\n                        // hmm\n\n                    }\n\n                }\n\n                if (mbskip_table)\n\n                    mbskip_table[mb_index] = 0;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 3678, "_split": "valid", "_hash": "25c94a9cffde379e6c027c0f02235287"}
{"project": "FFmpeg", "commit_id": "cb036f905f6ffa7b0dfdb9c35471a8280e00214e", "target": 1, "func": "static void alloc_picture(void *opaque)\n\n{\n\n    VideoState *is = opaque;\n\n    VideoPicture *vp;\n\n\n\n    vp = &is->pictq[is->pictq_windex];\n\n\n\n    if (vp->bmp)\n\n        SDL_FreeYUVOverlay(vp->bmp);\n\n\n\n#if CONFIG_AVFILTER\n\n    if (vp->picref)\n\n        avfilter_unref_buffer(vp->picref);\n\n    vp->picref = NULL;\n\n\n\n    vp->width   = is->out_video_filter->inputs[0]->w;\n\n    vp->height  = is->out_video_filter->inputs[0]->h;\n\n    vp->pix_fmt = is->out_video_filter->inputs[0]->format;\n\n#else\n\n    vp->width   = is->video_st->codec->width;\n\n    vp->height  = is->video_st->codec->height;\n\n    vp->pix_fmt = is->video_st->codec->pix_fmt;\n\n#endif\n\n\n\n    vp->bmp = SDL_CreateYUVOverlay(vp->width, vp->height,\n\n                                   SDL_YV12_OVERLAY,\n\n                                   screen);\n\n\n\n\n\n\n\n\n\n\n\n    SDL_LockMutex(is->pictq_mutex);\n\n    vp->allocated = 1;\n\n    SDL_CondSignal(is->pictq_cond);\n\n    SDL_UnlockMutex(is->pictq_mutex);\n", "idx": 3690, "_split": "valid", "_hash": "14fdaa907f17d8959c8ed52359feae3a"}
{"project": "FFmpeg", "commit_id": "d7bebe4805193783f0b6f292f9127a75709fb7d9", "target": 0, "func": "static int decode_nal_unit(HEVCContext *s, const HEVCNAL *nal)\n\n{\n\n    HEVCLocalContext *lc = &s->HEVClc;\n\n    GetBitContext *gb    = &lc->gb;\n\n    int ctb_addr_ts, ret;\n\n\n\n    ret = init_get_bits8(gb, nal->data, nal->size);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    ret = hls_nal_unit(s);\n\n    if (ret < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid NAL unit %d, skipping.\\n\",\n\n               s->nal_unit_type);\n\n        goto fail;\n\n    } else if (!ret)\n\n        return 0;\n\n\n\n    switch (s->nal_unit_type) {\n\n    case NAL_VPS:\n\n        ret = ff_hevc_decode_nal_vps(gb, s->avctx, &s->ps);\n\n        if (ret < 0)\n\n            goto fail;\n\n        break;\n\n    case NAL_SPS:\n\n        ret = ff_hevc_decode_nal_sps(gb, s->avctx, &s->ps,\n\n                                     s->apply_defdispwin);\n\n        if (ret < 0)\n\n            goto fail;\n\n        break;\n\n    case NAL_PPS:\n\n        ret = ff_hevc_decode_nal_pps(gb, s->avctx, &s->ps);\n\n        if (ret < 0)\n\n            goto fail;\n\n        break;\n\n    case NAL_SEI_PREFIX:\n\n    case NAL_SEI_SUFFIX:\n\n        ret = ff_hevc_decode_nal_sei(s);\n\n        if (ret < 0)\n\n            goto fail;\n\n        break;\n\n    case NAL_TRAIL_R:\n\n    case NAL_TRAIL_N:\n\n    case NAL_TSA_N:\n\n    case NAL_TSA_R:\n\n    case NAL_STSA_N:\n\n    case NAL_STSA_R:\n\n    case NAL_BLA_W_LP:\n\n    case NAL_BLA_W_RADL:\n\n    case NAL_BLA_N_LP:\n\n    case NAL_IDR_W_RADL:\n\n    case NAL_IDR_N_LP:\n\n    case NAL_CRA_NUT:\n\n    case NAL_RADL_N:\n\n    case NAL_RADL_R:\n\n    case NAL_RASL_N:\n\n    case NAL_RASL_R:\n\n        ret = hls_slice_header(s);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        if (s->max_ra == INT_MAX) {\n\n            if (s->nal_unit_type == NAL_CRA_NUT || IS_BLA(s)) {\n\n                s->max_ra = s->poc;\n\n            } else {\n\n                if (IS_IDR(s))\n\n                    s->max_ra = INT_MIN;\n\n            }\n\n        }\n\n\n\n        if ((s->nal_unit_type == NAL_RASL_R || s->nal_unit_type == NAL_RASL_N) &&\n\n            s->poc <= s->max_ra) {\n\n            s->is_decoded = 0;\n\n            break;\n\n        } else {\n\n            if (s->nal_unit_type == NAL_RASL_R && s->poc > s->max_ra)\n\n                s->max_ra = INT_MIN;\n\n        }\n\n\n\n        if (s->sh.first_slice_in_pic_flag) {\n\n            ret = hevc_frame_start(s);\n\n            if (ret < 0)\n\n                return ret;\n\n        } else if (!s->ref) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"First slice in a frame missing.\\n\");\n\n            goto fail;\n\n        }\n\n\n\n        if (s->nal_unit_type != s->first_nal_type) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Non-matching NAL types of the VCL NALUs: %d %d\\n\",\n\n                   s->first_nal_type, s->nal_unit_type);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (!s->sh.dependent_slice_segment_flag &&\n\n            s->sh.slice_type != I_SLICE) {\n\n            ret = ff_hevc_slice_rpl(s);\n\n            if (ret < 0) {\n\n                av_log(s->avctx, AV_LOG_WARNING,\n\n                       \"Error constructing the reference lists for the current slice.\\n\");\n\n                goto fail;\n\n            }\n\n        }\n\n\n\n        if (s->sh.first_slice_in_pic_flag && s->avctx->hwaccel) {\n\n            ret = s->avctx->hwaccel->start_frame(s->avctx, NULL, 0);\n\n            if (ret < 0)\n\n                goto fail;\n\n        }\n\n\n\n        if (s->avctx->hwaccel) {\n\n            ret = s->avctx->hwaccel->decode_slice(s->avctx, nal->raw_data, nal->raw_size);\n\n            if (ret < 0)\n\n                goto fail;\n\n        } else {\n\n            ctb_addr_ts = hls_slice_data(s);\n\n            if (ctb_addr_ts >= (s->ps.sps->ctb_width * s->ps.sps->ctb_height)) {\n\n                s->is_decoded = 1;\n\n                if ((s->ps.pps->transquant_bypass_enable_flag ||\n\n                     (s->ps.sps->pcm.loop_filter_disable_flag && s->ps.sps->pcm_enabled_flag)) &&\n\n                    s->ps.sps->sao_enabled)\n\n                    restore_tqb_pixels(s);\n\n            }\n\n\n\n            if (ctb_addr_ts < 0) {\n\n                ret = ctb_addr_ts;\n\n                goto fail;\n\n            }\n\n        }\n\n        break;\n\n    case NAL_EOS_NUT:\n\n    case NAL_EOB_NUT:\n\n        s->seq_decode = (s->seq_decode + 1) & 0xff;\n\n        s->max_ra     = INT_MAX;\n\n        break;\n\n    case NAL_AUD:\n\n    case NAL_FD_NUT:\n\n        break;\n\n    default:\n\n        av_log(s->avctx, AV_LOG_INFO,\n\n               \"Skipping NAL unit %d\\n\", s->nal_unit_type);\n\n    }\n\n\n\n    return 0;\n\nfail:\n\n    if (s->avctx->err_recognition & AV_EF_EXPLODE)\n\n        return ret;\n\n    return 0;\n\n}\n", "idx": 3738, "_split": "valid", "_hash": "d0179eaffff431f97ef4ed7a095cea7c"}
{"project": "FFmpeg", "commit_id": "d2779ecd8b1fb9dc8a8f37a75ff8c3b077f3143e", "target": 0, "func": "static inline int vc1_i_pred_dc(MpegEncContext *s, int overlap, int pq, int n,\n\n                              int16_t **dc_val_ptr, int *dir_ptr)\n\n{\n\n    int a, b, c, wrap, pred, scale;\n\n    int16_t *dc_val;\n\n    static const uint16_t dcpred[32] = {\n\n    -1, 1024,  512,  341,  256,  205,  171,  146,  128,\n\n         114,  102,   93,   85,   79,   73,   68,   64,\n\n          60,   57,   54,   51,   49,   47,   45,   43,\n\n          41,   39,   38,   37,   35,   34,   33\n\n    };\n\n\n\n    /* find prediction - wmv3_dc_scale always used here in fact */\n\n    if (n < 4)     scale = s->y_dc_scale;\n\n    else           scale = s->c_dc_scale;\n\n\n\n    wrap = s->block_wrap[n];\n\n    dc_val= s->dc_val[0] + s->block_index[n];\n\n\n\n    /* B A\n\n     * C X\n\n     */\n\n    c = dc_val[ - 1];\n\n    b = dc_val[ - 1 - wrap];\n\n    a = dc_val[ - wrap];\n\n\n\n    if (pq < 9 || !overlap)\n\n    {\n\n        /* Set outer values */\n\n        if (!s->mb_y && (n!=2 && n!=3)) b=a=dcpred[scale];\n\n        if (s->mb_x == 0 && (n!=1 && n!=3)) b=c=dcpred[scale];\n\n    }\n\n    else\n\n    {\n\n        /* Set outer values */\n\n        if (!s->mb_y && (n!=2 && n!=3)) b=a=0;\n\n        if (s->mb_x == 0 && (n!=1 && n!=3)) b=c=0;\n\n    }\n\n\n\n    if (abs(a - b) <= abs(b - c)) {\n\n        pred = c;\n\n        *dir_ptr = 1;//left\n\n    } else {\n\n        pred = a;\n\n        *dir_ptr = 0;//top\n\n    }\n\n\n\n    /* update predictor */\n\n    *dc_val_ptr = &dc_val[0];\n\n    return pred;\n\n}\n", "idx": 3820, "_split": "valid", "_hash": "a2297b1c33d14e5cb0ec1911b775193c"}
{"project": "FFmpeg", "commit_id": "a37fd7f9578d2dfbe20a109aae91e5f0a4b58874", "target": 1, "func": "void rgb24toyv12_c(const uint8_t *src, uint8_t *ydst, uint8_t *udst,\n\n                   uint8_t *vdst, int width, int height, int lumStride,\n\n                   int chromStride, int srcStride)\n\n{\n\n    int y;\n\n    const int chromWidth = width >> 1;\n\n\n\n    for (y = 0; y < height; y += 2) {\n\n        int i;\n\n        for (i = 0; i < chromWidth; i++) {\n\n            unsigned int b = src[6 * i + 0];\n\n            unsigned int g = src[6 * i + 1];\n\n            unsigned int r = src[6 * i + 2];\n\n\n\n            unsigned int Y = ((RY * r + GY * g + BY * b) >> RGB2YUV_SHIFT) +  16;\n\n            unsigned int V = ((RV * r + GV * g + BV * b) >> RGB2YUV_SHIFT) + 128;\n\n            unsigned int U = ((RU * r + GU * g + BU * b) >> RGB2YUV_SHIFT) + 128;\n\n\n\n            udst[i]     = U;\n\n            vdst[i]     = V;\n\n            ydst[2 * i] = Y;\n\n\n\n            b = src[6 * i + 3];\n\n            g = src[6 * i + 4];\n\n            r = src[6 * i + 5];\n\n\n\n            Y = ((RY * r + GY * g + BY * b) >> RGB2YUV_SHIFT) + 16;\n\n            ydst[2 * i + 1] = Y;\n\n        }\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n\n\n        if (y+1 == height)\n\n            break;\n\n\n\n        for (i = 0; i < chromWidth; i++) {\n\n            unsigned int b = src[6 * i + 0];\n\n            unsigned int g = src[6 * i + 1];\n\n            unsigned int r = src[6 * i + 2];\n\n\n\n            unsigned int Y = ((RY * r + GY * g + BY * b) >> RGB2YUV_SHIFT) + 16;\n\n\n\n            ydst[2 * i] = Y;\n\n\n\n            b = src[6 * i + 3];\n\n            g = src[6 * i + 4];\n\n            r = src[6 * i + 5];\n\n\n\n            Y = ((RY * r + GY * g + BY * b) >> RGB2YUV_SHIFT) + 16;\n\n            ydst[2 * i + 1] = Y;\n\n        }\n\n        udst += chromStride;\n\n        vdst += chromStride;\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n    }\n\n}\n", "idx": 3873, "_split": "valid", "_hash": "3717365d5becc9a30975f7e8439fdf56"}
{"project": "FFmpeg", "commit_id": "7d09a993d14c420ce53070312e77a224dbb4bc99", "target": 1, "func": "static void sdp_parse_fmtp_config(AVCodecContext *codec, char *attr, char *value)\n\n{\n\n    switch (codec->codec_id) {\n\n        case CODEC_ID_MPEG4:\n\n        case CODEC_ID_AAC:\n\n            if (!strcmp(attr, \"config\")) {\n\n                /* decode the hexa encoded parameter */\n\n                int len = hex_to_data(NULL, value);\n\n\n\n                codec->extradata = av_mallocz(len + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!codec->extradata)\n\n                    return;\n\n                codec->extradata_size = len;\n\n                hex_to_data(codec->extradata, value);\n\n            }\n\n            break;\n\n        default:\n\n            break;\n\n    }\n\n    return;\n\n}", "idx": 3909, "_split": "valid", "_hash": "7953ce1caa185db94e61f63413b04d8b"}
{"project": "FFmpeg", "commit_id": "eea784dab00d9f123c508d3e0c6b16e4f3123bb0", "target": 0, "func": "static int mp3_header_decompress(AVBitStreamFilterContext *bsfc, AVCodecContext *avctx, const char *args,\n\n                     uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size, int keyframe){\n\n    uint32_t header;\n\n    int sample_rate= avctx->sample_rate;\n\n    int sample_rate_index=0;\n\n    int lsf, mpeg25, bitrate_index, frame_size;\n\n\n\n    header = (buf[0] << 24) | (buf[1] << 16) | (buf[2] << 8) | buf[3];\n\n    if(ff_mpa_check_header(header) >= 0){\n\n        *poutbuf= (uint8_t *) buf;\n\n        *poutbuf_size= buf_size;\n\n\n\n        return 0;\n\n    }\n\n\n\n    header= 0xFFE00000 | ((4-3)<<17) | (1<<16); //FIXME simplify\n\n\n\n    lsf     = sample_rate < (24000+32000)/2;\n\n    mpeg25  = sample_rate < (12000+16000)/2;\n\n    header |= (!mpeg25)<<20;\n\n    header |= (!lsf   )<<19;\n\n    if(sample_rate<<(lsf+mpeg25) < (44100+32000)/2)\n\n        sample_rate_index |= 2;\n\n    else if(sample_rate<<(lsf+mpeg25) > (44100+48000)/2)\n\n        sample_rate_index |= 1;\n\n\n\n    header |= sample_rate_index<<10;\n\n    sample_rate= mpa_freq_tab[sample_rate_index] >> (lsf + mpeg25); //in case sample rate is a little off\n\n\n\n    for(bitrate_index=2; bitrate_index<30; bitrate_index++){\n\n        frame_size = mpa_bitrate_tab[lsf][2][bitrate_index>>1];\n\n        frame_size = (frame_size * 144000) / (sample_rate << lsf) + (bitrate_index&1);\n\n        if(frame_size == buf_size + 4)\n\n            break;\n\n    }\n\n    if(bitrate_index == 30){\n\n        av_log(avctx, AV_LOG_ERROR, \"couldnt find bitrate_index\\n\");\n\n        return -1;\n\n    }\n\n\n\n    header |= (bitrate_index&1)<<9;\n\n    header |= (bitrate_index>>1)<<12;\n\n    header |= (avctx->channels==1 ? MPA_MONO : MPA_JSTEREO)<<6;\n\n\n\n    *poutbuf_size= buf_size + 4;\n\n    *poutbuf= av_malloc(buf_size + 4 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    memcpy(*poutbuf + 4, buf, buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    if(avctx->channels==2){\n\n        if(lsf){\n\n            FFSWAP(int, (*poutbuf)[5], (*poutbuf)[6]);\n\n            header |= ((*poutbuf)[5] & 0xC0)>>2;\n\n        }else{\n\n            header |= (*poutbuf)[5] & 0x30;\n\n        }\n\n    }\n\n\n\n    (*poutbuf)[0]= header>>24;\n\n    (*poutbuf)[1]= header>>16;\n\n    (*poutbuf)[2]= header>> 8;\n\n    (*poutbuf)[3]= header    ;\n\n\n\n    return 1;\n\n}\n", "idx": 3921, "_split": "valid", "_hash": "dca50f4f1cc56edd9385a48b074d53ae"}
{"project": "FFmpeg", "commit_id": "0b42631641d998e509cde6fa344edc6ab5cb4ac8", "target": 0, "func": "static int get_cod(Jpeg2000DecoderContext *s, Jpeg2000CodingStyle *c,\n\n                   uint8_t *properties)\n\n{\n\n    Jpeg2000CodingStyle tmp;\n\n    int compno;\n\n\n\n    if (s->buf_end - s->buf < 5)\n\n        return AVERROR(EINVAL);\n\n\n\n    tmp.log2_prec_width  =\n\n    tmp.log2_prec_height = 15;\n\n\n\n    tmp.csty = bytestream_get_byte(&s->buf);\n\n\n\n    // get progression order\n\n    tmp.prog_order = bytestream_get_byte(&s->buf);\n\n\n\n    tmp.nlayers = bytestream_get_be16(&s->buf);\n\n    tmp.mct     = bytestream_get_byte(&s->buf); // multiple component transformation\n\n\n\n    get_cox(s, &tmp);\n\n    for (compno = 0; compno < s->ncomponents; compno++)\n\n        if (!(properties[compno] & HAD_COC))\n\n            memcpy(c + compno, &tmp, sizeof(tmp));\n\n    return 0;\n\n}\n", "idx": 3969, "_split": "valid", "_hash": "c9792be4f7f6b903a9fc5afc28f00d67"}
{"project": "FFmpeg", "commit_id": "9ca16bdd3f0461b40d369080647747ae70715daf", "target": 1, "func": "static int32_t scalarproduct_and_madd_int16_c(int16_t *v1, const int16_t *v2,\n\n                                              const int16_t *v3,\n\n                                              int order, int mul)\n\n{\n\n    int res = 0;\n\n\n\n    while (order--) {\n\n        res   += *v1 * *v2++;\n\n        *v1++ += mul * *v3++;\n\n    }\n\n    return res;\n\n}\n", "idx": 3974, "_split": "valid", "_hash": "411f525e4382cbc8957428d6456e16f6"}
{"project": "FFmpeg", "commit_id": "8662900b3b19f3b2c46d572da80833a88b80ca45", "target": 0, "func": "static int avi_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    uint32_t tag, tag1, handler;\n\n    int codec_type, stream_index, frame_period, bit_rate;\n\n    unsigned int size, nb_frames;\n\n    int i, n;\n\n    AVStream *st;\n\n    AVIStream *ast = NULL;\n\n    int xan_video = 0;  /* hack to support Xan A/V */\n\n    char str_track[4];\n\n\n\n    avi->stream_index= -1;\n\n\n\n    if (get_riff(avi, pb) < 0)\n\n        return -1;\n\n\n\n    /* first list tag */\n\n    stream_index = -1;\n\n    codec_type = -1;\n\n    frame_period = 0;\n\n    for(;;) {\n\n        if (url_feof(pb))\n\n            goto fail;\n\n        tag = get_le32(pb);\n\n        size = get_le32(pb);\n\n#ifdef DEBUG\n\n        print_tag(\"tag\", tag, size);\n\n#endif\n\n\n\n        switch(tag) {\n\n        case MKTAG('L', 'I', 'S', 'T'):\n\n            /* ignored, except when start of video packets */\n\n            tag1 = get_le32(pb);\n\n#ifdef DEBUG\n\n            print_tag(\"list\", tag1, 0);\n\n#endif\n\n            if (tag1 == MKTAG('m', 'o', 'v', 'i')) {\n\n                avi->movi_list = url_ftell(pb) - 4;\n\n                if(size) avi->movi_end = avi->movi_list + size + (size & 1);\n\n                else     avi->movi_end = url_fsize(pb);\n\n#ifdef DEBUG\n\n                printf(\"movi end=%\"PRIx64\"\\n\", avi->movi_end);\n\n#endif\n\n                goto end_of_header;\n\n            }\n\n            break;\n\n        case MKTAG('d', 'm', 'l', 'h'):\n\n            avi->is_odml = 1;\n\n            url_fskip(pb, size + (size & 1));\n\n            break;\n\n        case MKTAG('a', 'v', 'i', 'h'):\n\n            /* avi header */\n\n            /* using frame_period is bad idea */\n\n            frame_period = get_le32(pb);\n\n            bit_rate = get_le32(pb) * 8;\n\n            get_le32(pb);\n\n            avi->non_interleaved |= get_le32(pb) & AVIF_MUSTUSEINDEX;\n\n\n\n            url_fskip(pb, 2 * 4);\n\n            n = get_le32(pb);\n\n            for(i=0;i<n;i++) {\n\n                AVIStream *ast;\n\n                st = av_new_stream(s, i);\n\n                if (!st)\n\n                    goto fail;\n\n\n\n                ast = av_mallocz(sizeof(AVIStream));\n\n                if (!ast)\n\n                    goto fail;\n\n                st->priv_data = ast;\n\n            }\n\n            url_fskip(pb, size - 7 * 4);\n\n            break;\n\n        case MKTAG('s', 't', 'r', 'h'):\n\n            /* stream header */\n\n            stream_index++;\n\n            tag1 = get_le32(pb);\n\n            handler = get_le32(pb); /* codec tag */\n\n#ifdef DEBUG\n\n            print_tag(\"strh\", tag1, -1);\n\n#endif\n\n            if(tag1 == MKTAG('i', 'a', 'v', 's') || tag1 == MKTAG('i', 'v', 'a', 's')){\n\n                /*\n\n                 * After some consideration -- I don't think we\n\n                 * have to support anything but DV in a type1 AVIs.\n\n                 */\n\n                if (s->nb_streams != 1)\n\n                    goto fail;\n\n\n\n                if (handler != MKTAG('d', 'v', 's', 'd') &&\n\n                    handler != MKTAG('d', 'v', 'h', 'd') &&\n\n                    handler != MKTAG('d', 'v', 's', 'l'))\n\n                   goto fail;\n\n\n\n                ast = s->streams[0]->priv_data;\n\n                av_freep(&s->streams[0]->codec->extradata);\n\n                av_freep(&s->streams[0]);\n\n                s->nb_streams = 0;\n\n                if (ENABLE_DV_DEMUXER) {\n\n                    avi->dv_demux = dv_init_demux(s);\n\n                    if (!avi->dv_demux)\n\n                        goto fail;\n\n                }\n\n                s->streams[0]->priv_data = ast;\n\n                url_fskip(pb, 3 * 4);\n\n                ast->scale = get_le32(pb);\n\n                ast->rate = get_le32(pb);\n\n                stream_index = s->nb_streams - 1;\n\n                url_fskip(pb, size - 7*4);\n\n                break;\n\n            }\n\n\n\n            if (stream_index >= s->nb_streams) {\n\n                url_fskip(pb, size - 8);\n\n                /* ignore padding stream */\n\n                if (tag1 == MKTAG('p', 'a', 'd', 's'))\n\n                    stream_index--;\n\n                break;\n\n            }\n\n            st = s->streams[stream_index];\n\n            ast = st->priv_data;\n\n            st->codec->stream_codec_tag= handler;\n\n\n\n            get_le32(pb); /* flags */\n\n            get_le16(pb); /* priority */\n\n            get_le16(pb); /* language */\n\n            get_le32(pb); /* initial frame */\n\n            ast->scale = get_le32(pb);\n\n            ast->rate = get_le32(pb);\n\n            if(ast->scale && ast->rate){\n\n            }else if(frame_period){\n\n                ast->rate = 1000000;\n\n                ast->scale = frame_period;\n\n            }else{\n\n                ast->rate = 25;\n\n                ast->scale = 1;\n\n            }\n\n            av_set_pts_info(st, 64, ast->scale, ast->rate);\n\n\n\n            ast->cum_len=get_le32(pb); /* start */\n\n            nb_frames = get_le32(pb);\n\n\n\n            st->start_time = 0;\n\n            st->duration = nb_frames;\n\n            get_le32(pb); /* buffer size */\n\n            get_le32(pb); /* quality */\n\n            ast->sample_size = get_le32(pb); /* sample ssize */\n\n            ast->cum_len *= FFMAX(1, ast->sample_size);\n\n//            av_log(NULL, AV_LOG_DEBUG, \"%d %d %d %d\\n\", ast->rate, ast->scale, ast->start, ast->sample_size);\n\n\n\n            switch(tag1) {\n\n            case MKTAG('v', 'i', 'd', 's'):\n\n                codec_type = CODEC_TYPE_VIDEO;\n\n\n\n                ast->sample_size = 0;\n\n                break;\n\n            case MKTAG('a', 'u', 'd', 's'):\n\n                codec_type = CODEC_TYPE_AUDIO;\n\n                break;\n\n            case MKTAG('t', 'x', 't', 's'):\n\n                //FIXME\n\n                codec_type = CODEC_TYPE_DATA; //CODEC_TYPE_SUB ?  FIXME\n\n                break;\n\n            case MKTAG('p', 'a', 'd', 's'):\n\n                codec_type = CODEC_TYPE_UNKNOWN;\n\n                stream_index--;\n\n                break;\n\n            default:\n\n                av_log(s, AV_LOG_ERROR, \"unknown stream type %X\\n\", tag1);\n\n                goto fail;\n\n            }\n\n            ast->frame_offset= ast->cum_len;\n\n            url_fskip(pb, size - 12 * 4);\n\n            break;\n\n        case MKTAG('s', 't', 'r', 'f'):\n\n            /* stream header */\n\n            if (stream_index >= s->nb_streams || avi->dv_demux) {\n\n                url_fskip(pb, size);\n\n            } else {\n\n                st = s->streams[stream_index];\n\n                switch(codec_type) {\n\n                case CODEC_TYPE_VIDEO:\n\n                    get_le32(pb); /* size */\n\n                    st->codec->width = get_le32(pb);\n\n                    st->codec->height = get_le32(pb);\n\n                    get_le16(pb); /* panes */\n\n                    st->codec->bits_per_sample= get_le16(pb); /* depth */\n\n                    tag1 = get_le32(pb);\n\n                    get_le32(pb); /* ImageSize */\n\n                    get_le32(pb); /* XPelsPerMeter */\n\n                    get_le32(pb); /* YPelsPerMeter */\n\n                    get_le32(pb); /* ClrUsed */\n\n                    get_le32(pb); /* ClrImportant */\n\n\n\n                    if(size > 10*4 && size<(1<<30)){\n\n                        st->codec->extradata_size= size - 10*4;\n\n                        st->codec->extradata= av_malloc(st->codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                        get_buffer(pb, st->codec->extradata, st->codec->extradata_size);\n\n                    }\n\n\n\n                    if(st->codec->extradata_size & 1) //FIXME check if the encoder really did this correctly\n\n                        get_byte(pb);\n\n\n\n                    /* Extract palette from extradata if bpp <= 8 */\n\n                    /* This code assumes that extradata contains only palette */\n\n                    /* This is true for all paletted codecs implemented in ffmpeg */\n\n                    if (st->codec->extradata_size && (st->codec->bits_per_sample <= 8)) {\n\n                        st->codec->palctrl = av_mallocz(sizeof(AVPaletteControl));\n\n#ifdef WORDS_BIGENDIAN\n\n                        for (i = 0; i < FFMIN(st->codec->extradata_size, AVPALETTE_SIZE)/4; i++)\n\n                            st->codec->palctrl->palette[i] = bswap_32(((uint32_t*)st->codec->extradata)[i]);\n\n#else\n\n                        memcpy(st->codec->palctrl->palette, st->codec->extradata,\n\n                               FFMIN(st->codec->extradata_size, AVPALETTE_SIZE));\n\n#endif\n\n                        st->codec->palctrl->palette_changed = 1;\n\n                    }\n\n\n\n#ifdef DEBUG\n\n                    print_tag(\"video\", tag1, 0);\n\n#endif\n\n                    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n                    st->codec->codec_tag = tag1;\n\n                    st->codec->codec_id = codec_get_id(codec_bmp_tags, tag1);\n\n                    if (st->codec->codec_id == CODEC_ID_XAN_WC4)\n\n                        xan_video = 1;\n\n                    st->need_parsing = 2; //only parse headers dont do slower repacketization, this is needed to get the pict type which is needed for generating correct pts\n\n//                    url_fskip(pb, size - 5 * 4);\n\n                    break;\n\n                case CODEC_TYPE_AUDIO:\n\n                    get_wav_header(pb, st->codec, size);\n\n                    if(ast->sample_size && st->codec->block_align && ast->sample_size % st->codec->block_align)\n\n                        av_log(s, AV_LOG_DEBUG, \"invalid sample size or block align detected\\n\");\n\n                    if (size%2) /* 2-aligned (fix for Stargate SG-1 - 3x18 - Shades of Grey.avi) */\n\n                        url_fskip(pb, 1);\n\n                    /* special case time: To support Xan DPCM, hardcode\n\n                     * the format if Xxan is the video codec */\n\n                    st->need_parsing = 1;\n\n                    /* ADTS header is in extradata, AAC without header must be stored as exact frames, parser not needed and it will fail */\n\n                    if (st->codec->codec_id == CODEC_ID_AAC && st->codec->extradata_size)\n\n                        st->need_parsing = 0;\n\n                    /* force parsing as several audio frames can be in\n\n                       one packet */\n\n                    if (xan_video)\n\n                        st->codec->codec_id = CODEC_ID_XAN_DPCM;\n\n                    break;\n\n                default:\n\n                    st->codec->codec_type = CODEC_TYPE_DATA;\n\n                    st->codec->codec_id= CODEC_ID_NONE;\n\n                    st->codec->codec_tag= 0;\n\n                    url_fskip(pb, size);\n\n                    break;\n\n                }\n\n            }\n\n            break;\n\n        case MKTAG('i', 'n', 'd', 'x'):\n\n            i= url_ftell(pb);\n\n            if(!url_is_streamed(pb) && !(s->flags & AVFMT_FLAG_IGNIDX)){\n\n                read_braindead_odml_indx(s, 0);\n\n            }\n\n            url_fseek(pb, i+size, SEEK_SET);\n\n            break;\n\n        case MKTAG('I', 'N', 'A', 'M'):\n\n            avi_read_tag(pb, s->title, sizeof(s->title), size);\n\n            break;\n\n        case MKTAG('I', 'A', 'R', 'T'):\n\n            avi_read_tag(pb, s->author, sizeof(s->author), size);\n\n            break;\n\n        case MKTAG('I', 'C', 'O', 'P'):\n\n            avi_read_tag(pb, s->copyright, sizeof(s->copyright), size);\n\n            break;\n\n        case MKTAG('I', 'C', 'M', 'T'):\n\n            avi_read_tag(pb, s->comment, sizeof(s->comment), size);\n\n            break;\n\n        case MKTAG('I', 'G', 'N', 'R'):\n\n            avi_read_tag(pb, s->genre, sizeof(s->genre), size);\n\n            break;\n\n        case MKTAG('I', 'P', 'R', 'D'):\n\n            avi_read_tag(pb, s->album, sizeof(s->album), size);\n\n            break;\n\n        case MKTAG('I', 'P', 'R', 'T'):\n\n            avi_read_tag(pb, str_track, sizeof(str_track), size);\n\n            sscanf(str_track, \"%d\", &s->track);\n\n            break;\n\n        default:\n\n            /* skip tag */\n\n            size += (size & 1);\n\n            url_fskip(pb, size);\n\n            break;\n\n        }\n\n    }\n\n end_of_header:\n\n    /* check stream number */\n\n    if (stream_index != s->nb_streams - 1) {\n\n    fail:\n\n        for(i=0;i<s->nb_streams;i++) {\n\n            av_freep(&s->streams[i]->codec->extradata);\n\n            av_freep(&s->streams[i]);\n\n        }\n\n        return -1;\n\n    }\n\n\n\n    if(!avi->index_loaded && !url_is_streamed(pb))\n\n        avi_load_index(s);\n\n    avi->index_loaded = 1;\n\n    avi->non_interleaved |= guess_ni_flag(s);\n\n    if(avi->non_interleaved)\n\n        clean_index(s);\n\n\n\n    return 0;\n\n}\n", "idx": 4026, "_split": "valid", "_hash": "f97c881af9345b120de1c829bf9f7281"}
{"project": "FFmpeg", "commit_id": "3cb0bec6870cf0bb7879f7bfd4119ef39a02a464", "target": 1, "func": "static int ffserver_parse_config_feed(FFServerConfig *config, const char *cmd, const char **p,\n\n                                      FFServerStream **pfeed)\n\n{\n\n    FFServerStream *feed;\n\n    char arg[1024];\n\n    av_assert0(pfeed);\n\n    feed = *pfeed;\n\n    if (!av_strcasecmp(cmd, \"<Feed\")) {\n\n        char *q;\n\n        FFServerStream *s;\n\n        feed = av_mallocz(sizeof(FFServerStream));\n\n        if (!feed)\n\n            return AVERROR(ENOMEM);\n\n        ffserver_get_arg(feed->filename, sizeof(feed->filename), p);\n\n        q = strrchr(feed->filename, '>');\n\n        if (*q)\n\n            *q = '\\0';\n\n\n\n        for (s = config->first_feed; s; s = s->next) {\n\n            if (!strcmp(feed->filename, s->filename))\n\n                ERROR(\"Feed '%s' already registered\\n\", s->filename);\n\n        }\n\n\n\n        feed->fmt = av_guess_format(\"ffm\", NULL, NULL);\n\n        /* default feed file */\n\n        snprintf(feed->feed_filename, sizeof(feed->feed_filename),\n\n                 \"/tmp/%s.ffm\", feed->filename);\n\n        feed->feed_max_size = 5 * 1024 * 1024;\n\n        feed->is_feed = 1;\n\n        feed->feed = feed; /* self feeding :-) */\n\n        *pfeed = feed;\n\n        return 0;\n\n    }\n\n    av_assert0(feed);\n\n    if (!av_strcasecmp(cmd, \"Launch\")) {\n\n        int i;\n\n\n\n        feed->child_argv = av_mallocz(64 * sizeof(char *));\n\n        if (!feed->child_argv)\n\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < 62; i++) {\n\n            ffserver_get_arg(arg, sizeof(arg), p);\n\n            if (!arg[0])\n\n                break;\n\n\n\n            feed->child_argv[i] = av_strdup(arg);\n\n            if (!feed->child_argv[i])\n\n                return AVERROR(ENOMEM);\n\n        }\n\n\n\n        feed->child_argv[i] =\n\n            av_asprintf(\"http://%s:%d/%s\",\n\n                        (config->http_addr.sin_addr.s_addr == INADDR_ANY) ? \"127.0.0.1\" :\n\n                        inet_ntoa(config->http_addr.sin_addr), ntohs(config->http_addr.sin_port),\n\n                        feed->filename);\n\n        if (!feed->child_argv[i])\n\n            return AVERROR(ENOMEM);\n\n    } else if (!av_strcasecmp(cmd, \"ACL\")) {\n\n        ffserver_parse_acl_row(NULL, feed, NULL, *p, config->filename,\n\n                config->line_num);\n\n    } else if (!av_strcasecmp(cmd, \"File\") || !av_strcasecmp(cmd, \"ReadOnlyFile\")) {\n\n        ffserver_get_arg(feed->feed_filename, sizeof(feed->feed_filename), p);\n\n        feed->readonly = !av_strcasecmp(cmd, \"ReadOnlyFile\");\n\n    } else if (!av_strcasecmp(cmd, \"Truncate\")) {\n\n        ffserver_get_arg(arg, sizeof(arg), p);\n\n        /* assume Truncate is true in case no argument is specified */\n\n        if (!arg[0]) {\n\n            feed->truncate = 1;\n\n        } else {\n\n            WARNING(\"Truncate N syntax in configuration file is deprecated, \"\n\n                    \"use Truncate alone with no arguments\\n\");\n\n            feed->truncate = strtod(arg, NULL);\n\n        }\n\n    } else if (!av_strcasecmp(cmd, \"FileMaxSize\")) {\n\n        char *p1;\n\n        double fsize;\n\n\n\n        ffserver_get_arg(arg, sizeof(arg), p);\n\n        p1 = arg;\n\n        fsize = strtod(p1, &p1);\n\n        switch(av_toupper(*p1)) {\n\n        case 'K':\n\n            fsize *= 1024;\n\n            break;\n\n        case 'M':\n\n            fsize *= 1024 * 1024;\n\n            break;\n\n        case 'G':\n\n            fsize *= 1024 * 1024 * 1024;\n\n            break;\n\n        default:\n\n            ERROR(\"Invalid file size: %s\\n\", arg);\n\n            break;\n\n        }\n\n        feed->feed_max_size = (int64_t)fsize;\n\n        if (feed->feed_max_size < FFM_PACKET_SIZE*4)\n\n            ERROR(\"Feed max file size is too small, must be at least %d\\n\",\n\n                    FFM_PACKET_SIZE*4);\n\n    } else if (!av_strcasecmp(cmd, \"</Feed>\")) {\n\n        *pfeed = NULL;\n\n    } else {\n\n        ERROR(\"Invalid entry '%s' inside <Feed></Feed>\\n\", cmd);\n\n    }\n\n    return 0;\n\n}\n", "idx": 4030, "_split": "valid", "_hash": "93f4741a0153078495f5b40575e98a3c"}
{"project": "FFmpeg", "commit_id": "ddda9cee1c4b308921c37a61efda411244152e8f", "target": 1, "func": "static void build_feed_streams(void)\n\n{\n\n    FFServerStream *stream, *feed;\n\n    int i;\n\n\n\n    /* gather all streams */\n\n    for(stream = config.first_stream; stream; stream = stream->next) {\n\n        feed = stream->feed;\n\n        if (feed) {\n\n            if (stream->is_feed) {\n\n                for(i=0;i<stream->nb_streams;i++)\n\n                    stream->feed_streams[i] = i;\n\n            } else {\n\n                /* we handle a stream coming from a feed */\n\n                for(i=0;i<stream->nb_streams;i++)\n\n                    stream->feed_streams[i] = add_av_stream(feed,\n\n                                                            stream->streams[i]);\n\n            }\n\n        }\n\n    }\n\n\n\n    /* create feed files if needed */\n\n    for(feed = config.first_feed; feed; feed = feed->next_feed) {\n\n        int fd;\n\n\n\n        if (avio_check(feed->feed_filename, AVIO_FLAG_READ) > 0) {\n\n            /* See if it matches */\n\n            AVFormatContext *s = NULL;\n\n            int matches = 0;\n\n\n\n            if (avformat_open_input(&s, feed->feed_filename, NULL, NULL) >= 0) {\n\n                /* set buffer size */\n\n                ffio_set_buf_size(s->pb, FFM_PACKET_SIZE);\n\n                /* Now see if it matches */\n\n                if (s->nb_streams == feed->nb_streams) {\n\n                    matches = 1;\n\n                    for(i=0;i<s->nb_streams;i++) {\n\n                        AVStream *sf, *ss;\n\n                        sf = feed->streams[i];\n\n                        ss = s->streams[i];\n\n\n\n                        if (sf->index != ss->index ||\n\n                            sf->id != ss->id) {\n\n                            http_log(\"Index & Id do not match for stream %d (%s)\\n\",\n\n                                   i, feed->feed_filename);\n\n                            matches = 0;\n\n                        } else {\n\n                            AVCodecContext *ccf, *ccs;\n\n\n\n                            ccf = sf->codec;\n\n                            ccs = ss->codec;\n\n#define CHECK_CODEC(x)  (ccf->x != ccs->x)\n\n\n\n                            if (CHECK_CODEC(codec_id) || CHECK_CODEC(codec_type)) {\n\n                                http_log(\"Codecs do not match for stream %d\\n\", i);\n\n                                matches = 0;\n\n                            } else if (CHECK_CODEC(bit_rate) || CHECK_CODEC(flags)) {\n\n                                http_log(\"Codec bitrates do not match for stream %d\\n\", i);\n\n                                matches = 0;\n\n                            } else if (ccf->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n                                if (CHECK_CODEC(time_base.den) ||\n\n                                    CHECK_CODEC(time_base.num) ||\n\n                                    CHECK_CODEC(width) ||\n\n                                    CHECK_CODEC(height)) {\n\n                                    http_log(\"Codec width, height and framerate do not match for stream %d\\n\", i);\n\n                                    matches = 0;\n\n                                }\n\n                            } else if (ccf->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n                                if (CHECK_CODEC(sample_rate) ||\n\n                                    CHECK_CODEC(channels) ||\n\n                                    CHECK_CODEC(frame_size)) {\n\n                                    http_log(\"Codec sample_rate, channels, frame_size do not match for stream %d\\n\", i);\n\n                                    matches = 0;\n\n                                }\n\n                            } else {\n\n                                http_log(\"Unknown codec type\\n\");\n\n                                matches = 0;\n\n                            }\n\n                        }\n\n                        if (!matches)\n\n                            break;\n\n                    }\n\n                } else\n\n                    http_log(\"Deleting feed file '%s' as stream counts differ (%d != %d)\\n\",\n\n                        feed->feed_filename, s->nb_streams, feed->nb_streams);\n\n\n\n                avformat_close_input(&s);\n\n            } else\n\n                http_log(\"Deleting feed file '%s' as it appears to be corrupt\\n\",\n\n                        feed->feed_filename);\n\n\n\n            if (!matches) {\n\n                if (feed->readonly) {\n\n                    http_log(\"Unable to delete feed file '%s' as it is marked readonly\\n\",\n\n                        feed->feed_filename);\n\n                    exit(1);\n\n                }\n\n                unlink(feed->feed_filename);\n\n            }\n\n        }\n\n        if (avio_check(feed->feed_filename, AVIO_FLAG_WRITE) <= 0) {\n\n            AVFormatContext *s = avformat_alloc_context();\n\n\n\n            if (!s) {\n\n                http_log(\"Failed to allocate context\\n\");\n\n                exit(1);\n\n            }\n\n\n\n            if (feed->readonly) {\n\n                http_log(\"Unable to create feed file '%s' as it is marked readonly\\n\",\n\n                    feed->feed_filename);\n\n                exit(1);\n\n            }\n\n\n\n            /* only write the header of the ffm file */\n\n            if (avio_open(&s->pb, feed->feed_filename, AVIO_FLAG_WRITE) < 0) {\n\n                http_log(\"Could not open output feed file '%s'\\n\",\n\n                         feed->feed_filename);\n\n                exit(1);\n\n            }\n\n            s->oformat = feed->fmt;\n\n            s->nb_streams = feed->nb_streams;\n\n            s->streams = feed->streams;\n\n            if (avformat_write_header(s, NULL) < 0) {\n\n                http_log(\"Container doesn't support the required parameters\\n\");\n\n                exit(1);\n\n            }\n\n            /* XXX: need better API */\n\n            av_freep(&s->priv_data);\n\n            avio_closep(&s->pb);\n\n            s->streams = NULL;\n\n            s->nb_streams = 0;\n\n            avformat_free_context(s);\n\n        }\n\n        /* get feed size and write index */\n\n        fd = open(feed->feed_filename, O_RDONLY);\n\n        if (fd < 0) {\n\n            http_log(\"Could not open output feed file '%s'\\n\",\n\n                    feed->feed_filename);\n\n            exit(1);\n\n        }\n\n\n\n        feed->feed_write_index = FFMAX(ffm_read_write_index(fd), FFM_PACKET_SIZE);\n\n        feed->feed_size = lseek(fd, 0, SEEK_END);\n\n        /* ensure that we do not wrap before the end of file */\n\n        if (feed->feed_max_size && feed->feed_max_size < feed->feed_size)\n\n            feed->feed_max_size = feed->feed_size;\n\n\n\n        close(fd);\n\n    }\n\n}\n", "idx": 4034, "_split": "valid", "_hash": "0098bb299778c280593954ad3eaeaafd"}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(LEToUV)(uint8_t *dstU, uint8_t *dstV, const uint8_t *src1, const uint8_t *src2, int width, uint32_t *unused)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(\n\n        \"mov                    %0, %%\"REG_a\"       \\n\\t\"\n\n        \"1:                                         \\n\\t\"\n\n        \"movq    (%1, %%\"REG_a\",2), %%mm0           \\n\\t\"\n\n        \"movq   8(%1, %%\"REG_a\",2), %%mm1           \\n\\t\"\n\n        \"movq    (%2, %%\"REG_a\",2), %%mm2           \\n\\t\"\n\n        \"movq   8(%2, %%\"REG_a\",2), %%mm3           \\n\\t\"\n\n        \"psrlw                  $8, %%mm0           \\n\\t\"\n\n        \"psrlw                  $8, %%mm1           \\n\\t\"\n\n        \"psrlw                  $8, %%mm2           \\n\\t\"\n\n        \"psrlw                  $8, %%mm3           \\n\\t\"\n\n        \"packuswb            %%mm1, %%mm0           \\n\\t\"\n\n        \"packuswb            %%mm3, %%mm2           \\n\\t\"\n\n        \"movq                %%mm0, (%3, %%\"REG_a\") \\n\\t\"\n\n        \"movq                %%mm2, (%4, %%\"REG_a\") \\n\\t\"\n\n        \"add                    $8, %%\"REG_a\"       \\n\\t\"\n\n        \" js                    1b                  \\n\\t\"\n\n        : : \"g\" ((x86_reg)-width), \"r\" (src1+width*2), \"r\" (src2+width*2), \"r\" (dstU+width), \"r\" (dstV+width)\n\n        : \"%\"REG_a\n\n    );\n\n#else\n\n    int i;\n\n    for (i=0; i<width; i++) {\n\n        dstU[i]= src1[2*i + 1];\n\n        dstV[i]= src2[2*i + 1];\n\n    }\n\n#endif\n\n}\n", "idx": 4071, "_split": "valid", "_hash": "a38735b54a608014690326a0b7d25162"}
{"project": "FFmpeg", "commit_id": "0273ceebbd01f9fd5238558e6151e0b9aa3305ab", "target": 0, "func": "static int mjpeg_decode_dht(MJpegDecodeContext *s)\n\n{\n\n    int len, index, i, class, n, v, code_max;\n\n    uint8_t bits_table[17];\n\n    uint8_t val_table[256];\n\n    \n\n    len = get_bits(&s->gb, 16) - 2;\n\n\n\n    while (len > 0) {\n\n        if (len < 17)\n\n            return -1;\n\n        class = get_bits(&s->gb, 4);\n\n        if (class >= 2)\n\n            return -1;\n\n        index = get_bits(&s->gb, 4);\n\n        if (index >= 4)\n\n            return -1;\n\n        n = 0;\n\n        for(i=1;i<=16;i++) {\n\n            bits_table[i] = get_bits(&s->gb, 8);\n\n            n += bits_table[i];\n\n        }\n\n        len -= 17;\n\n        if (len < n || n > 256)\n\n            return -1;\n\n\n\n        code_max = 0;\n\n        for(i=0;i<n;i++) {\n\n            v = get_bits(&s->gb, 8);\n\n            if (v > code_max)\n\n                code_max = v;\n\n            val_table[i] = v;\n\n        }\n\n        len -= n;\n\n\n\n        /* build VLC and flush previous vlc if present */\n\n        free_vlc(&s->vlcs[class][index]);\n\n        dprintf(\"class=%d index=%d nb_codes=%d\\n\",\n\n               class, index, code_max + 1);\n\n        build_vlc(&s->vlcs[class][index], bits_table, val_table, code_max + 1);\n\n    }\n\n    return 0;\n\n}\n", "idx": 4111, "_split": "valid", "_hash": "e2cd82294231e39cf85884289aa4c299"}
{"project": "FFmpeg", "commit_id": "a5ea623b364b8a605fc92c973a98cd66cb7e6a5d", "target": 0, "func": "int ff_mov_read_stsd_entries(MOVContext *c, AVIOContext *pb, int entries)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    int j, pseudo_stream_id;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n    sc = st->priv_data;\n\n\n\n    for (pseudo_stream_id=0; pseudo_stream_id<entries; pseudo_stream_id++) {\n\n        //Parsing Sample description table\n\n        enum AVCodecID id;\n\n        int dref_id = 1;\n\n        MOVAtom a = { AV_RL32(\"stsd\") };\n\n        int64_t start_pos = avio_tell(pb);\n\n        int size = avio_rb32(pb); /* size */\n\n        uint32_t format = avio_rl32(pb); /* data format */\n\n\n\n        if (size >= 16) {\n\n            avio_rb32(pb); /* reserved */\n\n            avio_rb16(pb); /* reserved */\n\n            dref_id = avio_rb16(pb);\n\n        }\n\n\n\n        if (st->codec->codec_tag &&\n\n            st->codec->codec_tag != format &&\n\n            (c->fc->video_codec_id ? ff_codec_get_id(ff_codec_movvideo_tags, format) != c->fc->video_codec_id\n\n                                   : st->codec->codec_tag != MKTAG('j','p','e','g'))\n\n           ){\n\n            /* Multiple fourcc, we skip JPEG. This is not correct, we should\n\n             * export it as a separate AVStream but this needs a few changes\n\n             * in the MOV demuxer, patch welcome. */\n\n        multiple_stsd:\n\n            av_log(c->fc, AV_LOG_WARNING, \"multiple fourcc not supported\\n\");\n\n            avio_skip(pb, size - (avio_tell(pb) - start_pos));\n\n            continue;\n\n        }\n\n        /* we cannot demux concatenated h264 streams because of different extradata */\n\n        if (st->codec->codec_tag && st->codec->codec_tag == AV_RL32(\"avc1\"))\n\n            goto multiple_stsd;\n\n        sc->pseudo_stream_id = st->codec->codec_tag ? -1 : pseudo_stream_id;\n\n        sc->dref_id= dref_id;\n\n\n\n        st->codec->codec_tag = format;\n\n        id = ff_codec_get_id(ff_codec_movaudio_tags, format);\n\n        if (id<=0 && ((format&0xFFFF) == 'm'+('s'<<8) || (format&0xFFFF) == 'T'+('S'<<8)))\n\n            id = ff_codec_get_id(ff_codec_wav_tags, av_bswap32(format)&0xFFFF);\n\n\n\n        if (st->codec->codec_type != AVMEDIA_TYPE_VIDEO && id > 0) {\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        } else if (st->codec->codec_type != AVMEDIA_TYPE_AUDIO && /* do not overwrite codec type */\n\n                   format && format != MKTAG('m','p','4','s')) { /* skip old asf mpeg4 tag */\n\n            id = ff_codec_get_id(ff_codec_movvideo_tags, format);\n\n            if (id <= 0)\n\n                id = ff_codec_get_id(ff_codec_bmp_tags, format);\n\n            if (id > 0)\n\n                st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n            else if (st->codec->codec_type == AVMEDIA_TYPE_DATA){\n\n                id = ff_codec_get_id(ff_codec_movsubtitle_tags, format);\n\n                if (id > 0)\n\n                    st->codec->codec_type = AVMEDIA_TYPE_SUBTITLE;\n\n            }\n\n        }\n\n\n\n        av_dlog(c->fc, \"size=%d 4CC= %c%c%c%c codec_type=%d\\n\", size,\n\n                (format >> 0) & 0xff, (format >> 8) & 0xff, (format >> 16) & 0xff,\n\n                (format >> 24) & 0xff, st->codec->codec_type);\n\n\n\n        if (st->codec->codec_type==AVMEDIA_TYPE_VIDEO) {\n\n            unsigned int color_depth, len;\n\n            int color_greyscale;\n\n            int color_table_id;\n\n\n\n            st->codec->codec_id = id;\n\n            avio_rb16(pb); /* version */\n\n            avio_rb16(pb); /* revision level */\n\n            avio_rb32(pb); /* vendor */\n\n            avio_rb32(pb); /* temporal quality */\n\n            avio_rb32(pb); /* spatial quality */\n\n\n\n            st->codec->width = avio_rb16(pb); /* width */\n\n            st->codec->height = avio_rb16(pb); /* height */\n\n\n\n            avio_rb32(pb); /* horiz resolution */\n\n            avio_rb32(pb); /* vert resolution */\n\n            avio_rb32(pb); /* data size, always 0 */\n\n            avio_rb16(pb); /* frames per samples */\n\n\n\n            len = avio_r8(pb); /* codec name, pascal string */\n\n            if (len > 31)\n\n                len = 31;\n\n            mov_read_mac_string(c, pb, len, st->codec->codec_name, 32);\n\n            if (len < 31)\n\n                avio_skip(pb, 31 - len);\n\n            /* codec_tag YV12 triggers an UV swap in rawdec.c */\n\n            if (!memcmp(st->codec->codec_name, \"Planar Y'CbCr 8-bit 4:2:0\", 25))\n\n                st->codec->codec_tag=MKTAG('I', '4', '2', '0');\n\n\n\n            st->codec->bits_per_coded_sample = avio_rb16(pb); /* depth */\n\n            color_table_id = avio_rb16(pb); /* colortable id */\n\n            av_dlog(c->fc, \"depth %d, ctab id %d\\n\",\n\n                   st->codec->bits_per_coded_sample, color_table_id);\n\n            /* figure out the palette situation */\n\n            color_depth = st->codec->bits_per_coded_sample & 0x1F;\n\n            color_greyscale = st->codec->bits_per_coded_sample & 0x20;\n\n\n\n            /* if the depth is 2, 4, or 8 bpp, file is palettized */\n\n            if ((color_depth == 2) || (color_depth == 4) ||\n\n                (color_depth == 8)) {\n\n                /* for palette traversal */\n\n                unsigned int color_start, color_count, color_end;\n\n                unsigned char r, g, b;\n\n\n\n                if (color_greyscale) {\n\n                    int color_index, color_dec;\n\n                    /* compute the greyscale palette */\n\n                    st->codec->bits_per_coded_sample = color_depth;\n\n                    color_count = 1 << color_depth;\n\n                    color_index = 255;\n\n                    color_dec = 256 / (color_count - 1);\n\n                    for (j = 0; j < color_count; j++) {\n\n                        r = g = b = color_index;\n\n                        sc->palette[j] =\n\n                            (r << 16) | (g << 8) | (b);\n\n                        color_index -= color_dec;\n\n                        if (color_index < 0)\n\n                            color_index = 0;\n\n                    }\n\n                } else if (color_table_id) {\n\n                    const uint8_t *color_table;\n\n                    /* if flag bit 3 is set, use the default palette */\n\n                    color_count = 1 << color_depth;\n\n                    if (color_depth == 2)\n\n                        color_table = ff_qt_default_palette_4;\n\n                    else if (color_depth == 4)\n\n                        color_table = ff_qt_default_palette_16;\n\n                    else\n\n                        color_table = ff_qt_default_palette_256;\n\n\n\n                    for (j = 0; j < color_count; j++) {\n\n                        r = color_table[j * 3 + 0];\n\n                        g = color_table[j * 3 + 1];\n\n                        b = color_table[j * 3 + 2];\n\n                        sc->palette[j] =\n\n                            (r << 16) | (g << 8) | (b);\n\n                    }\n\n                } else {\n\n                    /* load the palette from the file */\n\n                    color_start = avio_rb32(pb);\n\n                    color_count = avio_rb16(pb);\n\n                    color_end = avio_rb16(pb);\n\n                    if ((color_start <= 255) &&\n\n                        (color_end <= 255)) {\n\n                        for (j = color_start; j <= color_end; j++) {\n\n                            /* each R, G, or B component is 16 bits;\n\n                             * only use the top 8 bits; skip alpha bytes\n\n                             * up front */\n\n                            avio_r8(pb);\n\n                            avio_r8(pb);\n\n                            r = avio_r8(pb);\n\n                            avio_r8(pb);\n\n                            g = avio_r8(pb);\n\n                            avio_r8(pb);\n\n                            b = avio_r8(pb);\n\n                            avio_r8(pb);\n\n                            sc->palette[j] =\n\n                                (r << 16) | (g << 8) | (b);\n\n                        }\n\n                    }\n\n                }\n\n                sc->has_palette = 1;\n\n            }\n\n        } else if (st->codec->codec_type==AVMEDIA_TYPE_AUDIO) {\n\n            int bits_per_sample, flags;\n\n            uint16_t version = avio_rb16(pb);\n\n\n\n            st->codec->codec_id = id;\n\n            avio_rb16(pb); /* revision level */\n\n            avio_rb32(pb); /* vendor */\n\n\n\n            st->codec->channels = avio_rb16(pb);             /* channel count */\n\n            av_dlog(c->fc, \"audio channels %d\\n\", st->codec->channels);\n\n            st->codec->bits_per_coded_sample = avio_rb16(pb);      /* sample size */\n\n\n\n            sc->audio_cid = avio_rb16(pb);\n\n            avio_rb16(pb); /* packet size = 0 */\n\n\n\n            st->codec->sample_rate = ((avio_rb32(pb) >> 16));\n\n\n\n            //Read QT version 1 fields. In version 0 these do not exist.\n\n            av_dlog(c->fc, \"version =%d, isom =%d\\n\",version,c->isom);\n\n            if (!c->isom) {\n\n                if (version==1) {\n\n                    sc->samples_per_frame = avio_rb32(pb);\n\n                    avio_rb32(pb); /* bytes per packet */\n\n                    sc->bytes_per_frame = avio_rb32(pb);\n\n                    avio_rb32(pb); /* bytes per sample */\n\n                } else if (version==2) {\n\n                    avio_rb32(pb); /* sizeof struct only */\n\n                    st->codec->sample_rate = av_int2double(avio_rb64(pb)); /* float 64 */\n\n                    st->codec->channels = avio_rb32(pb);\n\n                    avio_rb32(pb); /* always 0x7F000000 */\n\n                    st->codec->bits_per_coded_sample = avio_rb32(pb); /* bits per channel if sound is uncompressed */\n\n                    flags = avio_rb32(pb); /* lpcm format specific flag */\n\n                    sc->bytes_per_frame = avio_rb32(pb); /* bytes per audio packet if constant */\n\n                    sc->samples_per_frame = avio_rb32(pb); /* lpcm frames per audio packet if constant */\n\n                    if (format == MKTAG('l','p','c','m'))\n\n                        st->codec->codec_id = ff_mov_get_lpcm_codec_id(st->codec->bits_per_coded_sample, flags);\n\n                }\n\n            }\n\n\n\n            switch (st->codec->codec_id) {\n\n            case AV_CODEC_ID_PCM_S8:\n\n            case AV_CODEC_ID_PCM_U8:\n\n                if (st->codec->bits_per_coded_sample == 16)\n\n                    st->codec->codec_id = AV_CODEC_ID_PCM_S16BE;\n\n                break;\n\n            case AV_CODEC_ID_PCM_S16LE:\n\n            case AV_CODEC_ID_PCM_S16BE:\n\n                if (st->codec->bits_per_coded_sample == 8)\n\n                    st->codec->codec_id = AV_CODEC_ID_PCM_S8;\n\n                else if (st->codec->bits_per_coded_sample == 24)\n\n                    st->codec->codec_id =\n\n                        st->codec->codec_id == AV_CODEC_ID_PCM_S16BE ?\n\n                        AV_CODEC_ID_PCM_S24BE : AV_CODEC_ID_PCM_S24LE;\n\n                break;\n\n            /* set values for old format before stsd version 1 appeared */\n\n            case AV_CODEC_ID_MACE3:\n\n                sc->samples_per_frame = 6;\n\n                sc->bytes_per_frame = 2*st->codec->channels;\n\n                break;\n\n            case AV_CODEC_ID_MACE6:\n\n                sc->samples_per_frame = 6;\n\n                sc->bytes_per_frame = 1*st->codec->channels;\n\n                break;\n\n            case AV_CODEC_ID_ADPCM_IMA_QT:\n\n                sc->samples_per_frame = 64;\n\n                sc->bytes_per_frame = 34*st->codec->channels;\n\n                break;\n\n            case AV_CODEC_ID_GSM:\n\n                sc->samples_per_frame = 160;\n\n                sc->bytes_per_frame = 33;\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n\n\n            bits_per_sample = av_get_bits_per_sample(st->codec->codec_id);\n\n            if (bits_per_sample) {\n\n                st->codec->bits_per_coded_sample = bits_per_sample;\n\n                sc->sample_size = (bits_per_sample >> 3) * st->codec->channels;\n\n            }\n\n        } else if (st->codec->codec_type==AVMEDIA_TYPE_SUBTITLE){\n\n            // ttxt stsd contains display flags, justification, background\n\n            // color, fonts, and default styles, so fake an atom to read it\n\n            MOVAtom fake_atom = { .size = size - (avio_tell(pb) - start_pos) };\n\n            if (format != AV_RL32(\"mp4s\")) // mp4s contains a regular esds atom\n\n                mov_read_glbl(c, pb, fake_atom);\n\n            st->codec->codec_id= id;\n\n            st->codec->width = sc->width;\n\n            st->codec->height = sc->height;\n\n        } else {\n\n            /* other codec type, just skip (rtp, mp4s, tmcd ...) */\n\n            avio_skip(pb, size - (avio_tell(pb) - start_pos));\n\n        }\n\n        /* this will read extra atoms at the end (wave, alac, damr, avcC, SMI ...) */\n\n        a.size = size - (avio_tell(pb) - start_pos);\n\n        if (a.size > 8) {\n\n            int ret;\n\n            if ((ret = mov_read_default(c, pb, a)) < 0)\n\n                return ret;\n\n        } else if (a.size > 0)\n\n            avio_skip(pb, a.size);\n\n    }\n\n\n\n    if (st->codec->codec_type==AVMEDIA_TYPE_AUDIO && st->codec->sample_rate==0 && sc->time_scale>1)\n\n        st->codec->sample_rate= sc->time_scale;\n\n\n\n    /* special codec parameters handling */\n\n    switch (st->codec->codec_id) {\n\n#if CONFIG_DV_DEMUXER\n\n    case AV_CODEC_ID_DVAUDIO:\n\n        c->dv_fctx = avformat_alloc_context();\n\n        c->dv_demux = avpriv_dv_init_demux(c->dv_fctx);\n\n        if (!c->dv_demux) {\n\n            av_log(c->fc, AV_LOG_ERROR, \"dv demux context init error\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        sc->dv_audio_container = 1;\n\n        st->codec->codec_id = AV_CODEC_ID_PCM_S16LE;\n\n        break;\n\n#endif\n\n    /* no ifdef since parameters are always those */\n\n    case AV_CODEC_ID_QCELP:\n\n        // force sample rate for qcelp when not stored in mov\n\n        if (st->codec->codec_tag != MKTAG('Q','c','l','p'))\n\n            st->codec->sample_rate = 8000;\n\n        st->codec->channels= 1; /* really needed */\n\n        break;\n\n    case AV_CODEC_ID_AMR_NB:\n\n        st->codec->channels= 1; /* really needed */\n\n        /* force sample rate for amr, stsd in 3gp does not store sample rate */\n\n        st->codec->sample_rate = 8000;\n\n        break;\n\n    case AV_CODEC_ID_AMR_WB:\n\n        st->codec->channels    = 1;\n\n        st->codec->sample_rate = 16000;\n\n        break;\n\n    case AV_CODEC_ID_MP2:\n\n    case AV_CODEC_ID_MP3:\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO; /* force type after stsd for m1a hdlr */\n\n        st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        break;\n\n    case AV_CODEC_ID_GSM:\n\n    case AV_CODEC_ID_ADPCM_MS:\n\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n\n    case AV_CODEC_ID_ILBC:\n\n        st->codec->block_align = sc->bytes_per_frame;\n\n        break;\n\n    case AV_CODEC_ID_ALAC:\n\n        if (st->codec->extradata_size == 36) {\n\n            st->codec->channels   = AV_RB8 (st->codec->extradata+21);\n\n            st->codec->sample_rate = AV_RB32(st->codec->extradata+32);\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_VC1:\n\n        st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 4202, "_split": "valid", "_hash": "9f8a9c62d97ed8d4ec66c3297d08d1c1"}
{"project": "FFmpeg", "commit_id": "431f8af8242c41ef922f9daf791b0be26dc0bba4", "target": 0, "func": "static int normalize_bits(int num, int width)\n\n{\n\n    int i = 0;\n\n    int bits = (width) ? 31 : 15;\n\n    int limit = 1 << (bits - 1);\n\n\n\n    if (num) {\n\n        if (num == -1)\n\n            return bits;\n\n        if (num < 0)\n\n            num = ~num;\n\n        for (i = 0; num < limit; i++)\n\n            num <<= 1;\n\n    }\n\n    return i;\n\n}\n", "idx": 4239, "_split": "valid", "_hash": "751df8f5eeef1ed4937e460a4515b27b"}
{"project": "FFmpeg", "commit_id": "f875a732e36786d49f3650e3235272891a820600", "target": 1, "func": "static int decode_vop_header(MpegEncContext *s, GetBitContext *gb){\n\n    int time_incr, time_increment;\n\n\n\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I;        /* pict type: I = 0 , P = 1 */\n\n    if(s->pict_type==AV_PICTURE_TYPE_B && s->low_delay && s->vol_control_parameters==0 && !(s->flags & CODEC_FLAG_LOW_DELAY)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"low_delay flag incorrectly, clearing it\\n\");\n\n        s->low_delay=0;\n\n    }\n\n\n\n    s->partitioned_frame= s->data_partitioning && s->pict_type!=AV_PICTURE_TYPE_B;\n\n    if(s->partitioned_frame)\n\n        s->decode_mb= mpeg4_decode_partitioned_mb;\n\n    else\n\n        s->decode_mb= mpeg4_decode_mb;\n\n\n\n    time_incr=0;\n\n    while (get_bits1(gb) != 0)\n\n        time_incr++;\n\n\n\n    check_marker(gb, \"before time_increment\");\n\n\n\n    if(s->time_increment_bits==0 || !(show_bits(gb, s->time_increment_bits+1)&1)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"hmm, seems the headers are not complete, trying to guess time_increment_bits\\n\");\n\n\n\n        for(s->time_increment_bits=1 ;s->time_increment_bits<16; s->time_increment_bits++){\n\n            if (    s->pict_type == AV_PICTURE_TYPE_P\n\n                || (s->pict_type == AV_PICTURE_TYPE_S && s->vol_sprite_usage==GMC_SPRITE)) {\n\n                if((show_bits(gb, s->time_increment_bits+6)&0x37) == 0x30) break;\n\n            }else\n\n                if((show_bits(gb, s->time_increment_bits+5)&0x1F) == 0x18) break;\n\n        }\n\n\n\n        av_log(s->avctx, AV_LOG_ERROR, \"my guess is %d bits ;)\\n\",s->time_increment_bits);\n\n    }\n\n\n\n    if(IS_3IV1) time_increment= get_bits1(gb); //FIXME investigate further\n\n    else time_increment= get_bits(gb, s->time_increment_bits);\n\n\n\n    if(s->pict_type!=AV_PICTURE_TYPE_B){\n\n        s->last_time_base= s->time_base;\n\n        s->time_base+= time_incr;\n\n        s->time= s->time_base*s->avctx->time_base.den + time_increment;\n\n        if(s->workaround_bugs&FF_BUG_UMP4){\n\n            if(s->time < s->last_non_b_time){\n\n                /* header is not mpeg-4-compatible, broken encoder,\n\n                 * trying to workaround */\n\n                s->time_base++;\n\n                s->time+= s->avctx->time_base.den;\n\n            }\n\n        }\n\n        s->pp_time= s->time - s->last_non_b_time;\n\n        s->last_non_b_time= s->time;\n\n    }else{\n\n        s->time= (s->last_time_base + time_incr)*s->avctx->time_base.den + time_increment;\n\n        s->pb_time= s->pp_time - (s->last_non_b_time - s->time);\n\n        if(s->pp_time <=s->pb_time || s->pp_time <= s->pp_time - s->pb_time || s->pp_time<=0){\n\n            /* messed up order, maybe after seeking? skipping current b-frame */\n\n            return FRAME_SKIPPED;\n\n        }\n\n        ff_mpeg4_init_direct_mv(s);\n\n\n\n        if(s->t_frame==0) s->t_frame= s->pb_time;\n\n        if(s->t_frame==0) s->t_frame=1; // 1/0 protection\n\n        s->pp_field_time= (  ROUNDED_DIV(s->last_non_b_time, s->t_frame)\n\n                           - ROUNDED_DIV(s->last_non_b_time - s->pp_time, s->t_frame))*2;\n\n        s->pb_field_time= (  ROUNDED_DIV(s->time, s->t_frame)\n\n                           - ROUNDED_DIV(s->last_non_b_time - s->pp_time, s->t_frame))*2;\n\n        if(!s->progressive_sequence){\n\n            if(s->pp_field_time <= s->pb_field_time || s->pb_field_time <= 1)\n\n                return FRAME_SKIPPED;\n\n        }\n\n    }\n\n\n\n    if(s->avctx->time_base.num)\n\n        s->current_picture_ptr->f.pts = (s->time + s->avctx->time_base.num / 2) / s->avctx->time_base.num;\n\n    else\n\n        s->current_picture_ptr->f.pts = AV_NOPTS_VALUE;\n\n    if(s->avctx->debug&FF_DEBUG_PTS)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"MPEG4 PTS: %\"PRId64\"\\n\",\n\n               s->current_picture_ptr->f.pts);\n\n\n\n    check_marker(gb, \"before vop_coded\");\n\n\n\n    /* vop coded */\n\n    if (get_bits1(gb) != 1){\n\n        if(s->avctx->debug&FF_DEBUG_PICT_INFO)\n\n            av_log(s->avctx, AV_LOG_ERROR, \"vop not coded\\n\");\n\n        return FRAME_SKIPPED;\n\n    }\n\n    if (s->shape != BIN_ONLY_SHAPE && ( s->pict_type == AV_PICTURE_TYPE_P\n\n                          || (s->pict_type == AV_PICTURE_TYPE_S && s->vol_sprite_usage==GMC_SPRITE))) {\n\n        /* rounding type for motion estimation */\n\n        s->no_rounding = get_bits1(gb);\n\n    } else {\n\n        s->no_rounding = 0;\n\n    }\n\n//FIXME reduced res stuff\n\n\n\n     if (s->shape != RECT_SHAPE) {\n\n         if (s->vol_sprite_usage != 1 || s->pict_type != AV_PICTURE_TYPE_I) {\n\n             skip_bits(gb, 13); /* width */\n\n             skip_bits1(gb);   /* marker */\n\n             skip_bits(gb, 13); /* height */\n\n             skip_bits1(gb);   /* marker */\n\n             skip_bits(gb, 13); /* hor_spat_ref */\n\n             skip_bits1(gb);   /* marker */\n\n             skip_bits(gb, 13); /* ver_spat_ref */\n\n         }\n\n         skip_bits1(gb); /* change_CR_disable */\n\n\n\n         if (get_bits1(gb) != 0) {\n\n             skip_bits(gb, 8); /* constant_alpha_value */\n\n         }\n\n     }\n\n//FIXME complexity estimation stuff\n\n\n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         skip_bits_long(gb, s->cplx_estimation_trash_i);\n\n         if(s->pict_type != AV_PICTURE_TYPE_I)\n\n            skip_bits_long(gb, s->cplx_estimation_trash_p);\n\n         if(s->pict_type == AV_PICTURE_TYPE_B)\n\n            skip_bits_long(gb, s->cplx_estimation_trash_b);\n\n\n\n         s->intra_dc_threshold= ff_mpeg4_dc_threshold[ get_bits(gb, 3) ];\n\n         if(!s->progressive_sequence){\n\n             s->top_field_first= get_bits1(gb);\n\n             s->alternate_scan= get_bits1(gb);\n\n         }else\n\n             s->alternate_scan= 0;\n\n     }\n\n\n\n     if(s->alternate_scan){\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n     } else{\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_zigzag_direct);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_zigzag_direct);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n     }\n\n\n\n     if(s->pict_type == AV_PICTURE_TYPE_S && (s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE)){\n\n         mpeg4_decode_sprite_trajectory(s, gb);\n\n         if(s->sprite_brightness_change) av_log(s->avctx, AV_LOG_ERROR, \"sprite_brightness_change not supported\\n\");\n\n         if(s->vol_sprite_usage==STATIC_SPRITE) av_log(s->avctx, AV_LOG_ERROR, \"static sprite not supported\\n\");\n\n     }\n\n\n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         s->chroma_qscale= s->qscale = get_bits(gb, s->quant_precision);\n\n         if(s->qscale==0){\n\n             av_log(s->avctx, AV_LOG_ERROR, \"Error, header damaged or not MPEG4 header (qscale=0)\\n\");\n\n             return -1; // makes no sense to continue, as there is nothing left from the image then\n\n         }\n\n\n\n         if (s->pict_type != AV_PICTURE_TYPE_I) {\n\n             s->f_code = get_bits(gb, 3);       /* fcode_for */\n\n             if(s->f_code==0){\n\n                 av_log(s->avctx, AV_LOG_ERROR, \"Error, header damaged or not MPEG4 header (f_code=0)\\n\");\n\n                 return -1; // makes no sense to continue, as the MV decoding will break very quickly\n\n             }\n\n         }else\n\n             s->f_code=1;\n\n\n\n         if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n             s->b_code = get_bits(gb, 3);\n\n         }else\n\n             s->b_code=1;\n\n\n\n         if(s->avctx->debug&FF_DEBUG_PICT_INFO){\n\n             av_log(s->avctx, AV_LOG_DEBUG, \"qp:%d fc:%d,%d %s size:%d pro:%d alt:%d top:%d %spel part:%d resync:%d w:%d a:%d rnd:%d vot:%d%s dc:%d ce:%d/%d/%d\\n\",\n\n                 s->qscale, s->f_code, s->b_code,\n\n                 s->pict_type == AV_PICTURE_TYPE_I ? \"I\" : (s->pict_type == AV_PICTURE_TYPE_P ? \"P\" : (s->pict_type == AV_PICTURE_TYPE_B ? \"B\" : \"S\")),\n\n                 gb->size_in_bits,s->progressive_sequence, s->alternate_scan, s->top_field_first,\n\n                 s->quarter_sample ? \"q\" : \"h\", s->data_partitioning, s->resync_marker, s->num_sprite_warping_points,\n\n                 s->sprite_warping_accuracy, 1-s->no_rounding, s->vo_type, s->vol_control_parameters ? \" VOLC\" : \" \", s->intra_dc_threshold, s->cplx_estimation_trash_i, s->cplx_estimation_trash_p, s->cplx_estimation_trash_b);\n\n         }\n\n\n\n         if(!s->scalability){\n\n             if (s->shape!=RECT_SHAPE && s->pict_type!=AV_PICTURE_TYPE_I) {\n\n                 skip_bits1(gb); // vop shape coding type\n\n             }\n\n         }else{\n\n             if(s->enhancement_type){\n\n                 int load_backward_shape= get_bits1(gb);\n\n                 if(load_backward_shape){\n\n                     av_log(s->avctx, AV_LOG_ERROR, \"load backward shape isn't supported\\n\");\n\n                 }\n\n             }\n\n             skip_bits(gb, 2); //ref_select_code\n\n         }\n\n     }\n\n     /* detect buggy encoders which don't set the low_delay flag (divx4/xvid/opendivx)*/\n\n     // note we cannot detect divx5 without b-frames easily (although it's buggy too)\n\n     if(s->vo_type==0 && s->vol_control_parameters==0 && s->divx_version==-1 && s->picture_number==0){\n\n         av_log(s->avctx, AV_LOG_WARNING, \"looks like this file was encoded with (divx4/(old)xvid/opendivx) -> forcing low_delay flag\\n\");\n\n         s->low_delay=1;\n\n     }\n\n\n\n     s->picture_number++; // better than pic number==0 always ;)\n\n\n\n     s->y_dc_scale_table= ff_mpeg4_y_dc_scale_table; //FIXME add short header support\n\n     s->c_dc_scale_table= ff_mpeg4_c_dc_scale_table;\n\n\n\n     if(s->workaround_bugs&FF_BUG_EDGE){\n\n         s->h_edge_pos= s->width;\n\n         s->v_edge_pos= s->height;\n\n     }\n\n     return 0;\n\n}\n", "idx": 4258, "_split": "valid", "_hash": "706f38c2d1c0a5f089e44a06463c522f"}
{"project": "FFmpeg", "commit_id": "fd7af82c53ea8a2577ea8952d35fb158db594592", "target": 0, "func": "static int decompress_p(AVCodecContext *avctx,\n\n                        uint32_t *dst, int linesize,\n\n                        uint32_t *prev, int plinesize)\n\n{\n\n    SCPRContext *s = avctx->priv_data;\n\n    GetByteContext *gb = &s->gb;\n\n    int ret, temp, min, max, x, y, cx = 0, cx1 = 0;\n\n    int backstep = linesize - avctx->width;\n\n    const int cxshift = s->cxshift;\n\n\n\n    if (bytestream2_get_byte(gb) == 0)\n\n        return 0;\n\n    bytestream2_skip(gb, 1);\n\n    init_rangecoder(&s->rc, gb);\n\n\n\n    ret  = decode_value(s, s->range_model, 256, 1, &min);\n\n    ret |= decode_value(s, s->range_model, 256, 1, &temp);\n\n    min += temp << 8;\n\n    ret |= decode_value(s, s->range_model, 256, 1, &max);\n\n    ret |= decode_value(s, s->range_model, 256, 1, &temp);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    max += temp << 8;\n\n    memset(s->blocks, 0, sizeof(*s->blocks) * s->nbcount);\n\n\n\n    while (min <= max) {\n\n        int fill, count;\n\n\n\n        ret  = decode_value(s, s->fill_model,  5,   10, &fill);\n\n        ret |= decode_value(s, s->count_model, 256, 20, &count);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        while (min < s->nbcount && count-- > 0) {\n\n            s->blocks[min++] = fill;\n\n        }\n\n    }\n\n\n\n    for (y = 0; y < s->nby; y++) {\n\n        for (x = 0; x < s->nbx; x++) {\n\n            int sy1 = 0, sy2 = 16, sx1 = 0, sx2 = 16;\n\n\n\n            if (s->blocks[y * s->nbx + x] == 0)\n\n                continue;\n\n\n\n            if (((s->blocks[y * s->nbx + x] - 1) & 1) > 0) {\n\n                ret  = decode_value(s, s->sxy_model[0], 16, 100, &sx1);\n\n                ret |= decode_value(s, s->sxy_model[1], 16, 100, &sy1);\n\n                ret |= decode_value(s, s->sxy_model[2], 16, 100, &sx2);\n\n                ret |= decode_value(s, s->sxy_model[3], 16, 100, &sy2);\n\n                if (ret < 0)\n\n                    return ret;\n\n\n\n                sx2++;\n\n                sy2++;\n\n            }\n\n            if (((s->blocks[y * s->nbx + x] - 1) & 2) > 0) {\n\n                int i, j, by = y * 16, bx = x * 16;\n\n                int mvx, mvy;\n\n\n\n                ret  = decode_value(s, s->mv_model[0], 512, 100, &mvx);\n\n                ret |= decode_value(s, s->mv_model[1], 512, 100, &mvy);\n\n                if (ret < 0)\n\n                    return ret;\n\n\n\n                mvx -= 256;\n\n                mvy -= 256;\n\n\n\n                if (by + mvy + sy1 < 0 || bx + mvx + sx1 < 0)\n\n                    return AVERROR_INVALIDDATA;\n\n\n\n                for (i = 0; i < sy2 - sy1 && (by + sy1 + i) < avctx->height; i++) {\n\n                    for (j = 0; j < sx2 - sx1 && (bx + sx1 + j) < avctx->width; j++) {\n\n                        dst[(by + i + sy1) * linesize + bx + sx1 + j] = prev[(by + mvy + sy1 + i) * plinesize + bx + sx1 + mvx + j];\n\n                    }\n\n                }\n\n            } else {\n\n                int run, r, g, b, z, bx = x * 16 + sx1, by = y * 16 + sy1;\n\n                unsigned clr, ptype = 0;\n\n\n\n                for (; by < y * 16 + sy2 && by < avctx->height;) {\n\n                    ret = decode_value(s, s->op_model[ptype], 6, 1000, &ptype);\n\n                    if (ptype == 0) {\n\n                        ret = decode_unit(s, &s->pixel_model[0][cx + cx1], 400, &r);\n\n                        if (ret < 0)\n\n                            return ret;\n\n\n\n                        cx1 = (cx << 6) & 0xFC0;\n\n                        cx = r >> cxshift;\n\n                        ret = decode_unit(s, &s->pixel_model[1][cx + cx1], 400, &g);\n\n                        if (ret < 0)\n\n                            return ret;\n\n\n\n                        cx1 = (cx << 6) & 0xFC0;\n\n                        cx = g >> cxshift;\n\n                        ret = decode_unit(s, &s->pixel_model[2][cx + cx1], 400, &b);\n\n                        if (ret < 0)\n\n                            return ret;\n\n\n\n                        cx1 = (cx << 6) & 0xFC0;\n\n                        cx = b >> cxshift;\n\n                        clr = (b << 16) + (g << 8) + r;\n\n                    }\n\n                    if (ptype > 5)\n\n                        return AVERROR_INVALIDDATA;\n\n                    ret = decode_value(s, s->run_model[ptype], 256, 400, &run);\n\n                    if (ret < 0)\n\n                        return ret;\n\n\n\n                    switch (ptype) {\n\n                    case 0:\n\n                        while (run-- > 0) {\n\n                            if (by >= avctx->height)\n\n                                return AVERROR_INVALIDDATA;\n\n\n\n                            dst[by * linesize + bx] = clr;\n\n                            bx++;\n\n                            if (bx >= x * 16 + sx2 || bx >= avctx->width) {\n\n                                bx = x * 16 + sx1;\n\n                                by++;\n\n                            }\n\n                        }\n\n                        break;\n\n                    case 1:\n\n                        while (run-- > 0) {\n\n                            if (bx == 0) {\n\n                                if (by < 1)\n\n                                    return AVERROR_INVALIDDATA;\n\n                                z = backstep;\n\n                            } else {\n\n                                z = 0;\n\n                            }\n\n\n\n                            if (by >= avctx->height)\n\n                                return AVERROR_INVALIDDATA;\n\n\n\n                            clr = dst[by * linesize + bx - 1 - z];\n\n                            dst[by * linesize + bx] = clr;\n\n                            bx++;\n\n                            if (bx >= x * 16 + sx2 || bx >= avctx->width) {\n\n                                bx = x * 16 + sx1;\n\n                                by++;\n\n                            }\n\n                        }\n\n                        break;\n\n                    case 2:\n\n                        while (run-- > 0) {\n\n                            if (by < 1 || by >= avctx->height)\n\n                                return AVERROR_INVALIDDATA;\n\n\n\n                            clr = dst[(by - 1) * linesize + bx];\n\n                            dst[by * linesize + bx] = clr;\n\n                            bx++;\n\n                            if (bx >= x * 16 + sx2 || bx >= avctx->width) {\n\n                                bx = x * 16 + sx1;\n\n                                by++;\n\n                            }\n\n                        }\n\n                        break;\n\n                    case 3:\n\n                        while (run-- > 0) {\n\n                            if (by >= avctx->height)\n\n                                return AVERROR_INVALIDDATA;\n\n\n\n                            clr = prev[by * linesize + bx];\n\n                            dst[by * linesize + bx] = clr;\n\n                            bx++;\n\n                            if (bx >= x * 16 + sx2 || bx >= avctx->width) {\n\n                                bx = x * 16 + sx1;\n\n                                by++;\n\n                            }\n\n                        }\n\n                        break;\n\n                    case 4:\n\n                        while (run-- > 0) {\n\n                            uint8_t *odst = (uint8_t *)dst;\n\n\n\n                            if (by < 1 || by >= avctx->height)\n\n                                return AVERROR_INVALIDDATA;\n\n\n\n                            if (bx == 0) {\n\n                                z = backstep;\n\n                            } else {\n\n                                z = 0;\n\n                            }\n\n\n\n                            r = odst[((by - 1) * linesize + bx) * 4] +\n\n                                odst[(by * linesize + bx - 1 - z) * 4] -\n\n                                odst[((by - 1) * linesize + bx - 1 - z) * 4];\n\n                            g = odst[((by - 1) * linesize + bx) * 4 + 1] +\n\n                                odst[(by * linesize + bx - 1 - z) * 4 + 1] -\n\n                                odst[((by - 1) * linesize + bx - 1 - z) * 4 + 1];\n\n                            b = odst[((by - 1) * linesize + bx) * 4 + 2] +\n\n                                odst[(by * linesize + bx - 1 - z) * 4 + 2] -\n\n                                odst[((by - 1) * linesize + bx - 1 - z) * 4 + 2];\n\n                            clr = ((b & 0xFF) << 16) + ((g & 0xFF) << 8) + (r & 0xFF);\n\n                            dst[by * linesize + bx] = clr;\n\n                            bx++;\n\n                            if (bx >= x * 16 + sx2 || bx >= avctx->width) {\n\n                                bx = x * 16 + sx1;\n\n                                by++;\n\n                            }\n\n                        }\n\n                        break;\n\n                    case 5:\n\n                        while (run-- > 0) {\n\n                            if (by < 1 || by >= avctx->height)\n\n                                return AVERROR_INVALIDDATA;\n\n\n\n                            if (bx == 0) {\n\n                                z = backstep;\n\n                            } else {\n\n                                z = 0;\n\n                            }\n\n\n\n                            clr = dst[(by - 1) * linesize + bx - 1 - z];\n\n                            dst[by * linesize + bx] = clr;\n\n                            bx++;\n\n                            if (bx >= x * 16 + sx2 || bx >= avctx->width) {\n\n                                bx = x * 16 + sx1;\n\n                                by++;\n\n                            }\n\n                        }\n\n                        break;\n\n                    }\n\n\n\n                    if (avctx->bits_per_coded_sample == 16) {\n\n                        cx1 = (clr & 0xFF00) >> 2;\n\n                        cx = (clr & 0xFFFFFF) >> 16;\n\n                    } else {\n\n                        cx1 = (clr & 0xFC00) >> 4;\n\n                        cx = (clr & 0xFFFFFF) >> 18;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 4268, "_split": "valid", "_hash": "071181c061872d11016f3ffc3c8ffc48"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static av_cold int decode_init_mp3on4(AVCodecContext * avctx)\n\n{\n\n    MP3On4DecodeContext *s = avctx->priv_data;\n\n    MPEG4AudioConfig cfg;\n\n    int i;\n\n\n\n    if ((avctx->extradata_size < 2) || (avctx->extradata == NULL)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Codec extradata missing or too short.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    avpriv_mpeg4audio_get_config(&cfg, avctx->extradata,\n\n                                 avctx->extradata_size * 8, 1);\n\n    if (!cfg.chan_config || cfg.chan_config > 7) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid channel config number.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    s->frames             = mp3Frames[cfg.chan_config];\n\n    s->coff               = chan_offset[cfg.chan_config];\n\n    avctx->channels       = ff_mpeg4audio_channels[cfg.chan_config];\n\n    avctx->channel_layout = chan_layout[cfg.chan_config];\n\n\n\n    if (cfg.sample_rate < 16000)\n\n        s->syncword = 0xffe00000;\n\n    else\n\n        s->syncword = 0xfff00000;\n\n\n\n    /* Init the first mp3 decoder in standard way, so that all tables get builded\n\n     * We replace avctx->priv_data with the context of the first decoder so that\n\n     * decode_init() does not have to be changed.\n\n     * Other decoders will be initialized here copying data from the first context\n\n     */\n\n    // Allocate zeroed memory for the first decoder context\n\n    s->mp3decctx[0] = av_mallocz(sizeof(MPADecodeContext));\n\n    if (!s->mp3decctx[0])\n\n        goto alloc_fail;\n\n    // Put decoder context in place to make init_decode() happy\n\n    avctx->priv_data = s->mp3decctx[0];\n\n    decode_init(avctx);\n\n    // Restore mp3on4 context pointer\n\n    avctx->priv_data = s;\n\n    s->mp3decctx[0]->adu_mode = 1; // Set adu mode\n\n\n\n    /* Create a separate codec/context for each frame (first is already ok).\n\n     * Each frame is 1 or 2 channels - up to 5 frames allowed\n\n     */\n\n    for (i = 1; i < s->frames; i++) {\n\n        s->mp3decctx[i] = av_mallocz(sizeof(MPADecodeContext));\n\n        if (!s->mp3decctx[i])\n\n            goto alloc_fail;\n\n        s->mp3decctx[i]->adu_mode = 1;\n\n        s->mp3decctx[i]->avctx = avctx;\n\n        s->mp3decctx[i]->mpadsp = s->mp3decctx[0]->mpadsp;\n\n    }\n\n\n\n    return 0;\n\nalloc_fail:\n\n    decode_close_mp3on4(avctx);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 4336, "_split": "valid", "_hash": "f5a7a9789105724369be46336ef7c13f"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "static void avc_luma_midv_qrt_and_aver_dst_8w_msa(const uint8_t *src,\n\n                                                  int32_t src_stride,\n\n                                                  uint8_t *dst,\n\n                                                  int32_t dst_stride,\n\n                                                  int32_t height,\n\n                                                  uint8_t vert_offset)\n\n{\n\n    int32_t loop_cnt;\n\n    v16i8 src0, src1, src2, src3, src4;\n\n    v16u8 dst0, dst1, dst2, dst3;\n\n    v16i8 mask0, mask1, mask2;\n\n    v8i16 hz_out0, hz_out1, hz_out2, hz_out3;\n\n    v8i16 hz_out4, hz_out5, hz_out6, hz_out7, hz_out8;\n\n    v8i16 res0, res1, res2, res3;\n\n    v8i16 res4, res5, res6, res7;\n\n\n\n    LD_SB3(&luma_mask_arr[0], 16, mask0, mask1, mask2);\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    hz_out0 = AVC_HORZ_FILTER_SH(src0, mask0, mask1, mask2);\n\n    hz_out1 = AVC_HORZ_FILTER_SH(src1, mask0, mask1, mask2);\n\n    hz_out2 = AVC_HORZ_FILTER_SH(src2, mask0, mask1, mask2);\n\n    hz_out3 = AVC_HORZ_FILTER_SH(src3, mask0, mask1, mask2);\n\n    hz_out4 = AVC_HORZ_FILTER_SH(src4, mask0, mask1, mask2);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src, src_stride, src0, src1, src2, src3);\n\n        XORI_B4_128_SB(src0, src1, src2, src3);\n\n        src += (4 * src_stride);\n\n\n\n        LD_UB4(dst, dst_stride, dst0, dst1, dst2, dst3);\n\n\n\n        hz_out5 = AVC_HORZ_FILTER_SH(src0, mask0, mask1, mask2);\n\n        hz_out6 = AVC_HORZ_FILTER_SH(src1, mask0, mask1, mask2);\n\n        hz_out7 = AVC_HORZ_FILTER_SH(src2, mask0, mask1, mask2);\n\n        hz_out8 = AVC_HORZ_FILTER_SH(src3, mask0, mask1, mask2);\n\n\n\n        res0 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out0, hz_out1, hz_out2,\n\n                                               hz_out3, hz_out4, hz_out5);\n\n        res2 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out1, hz_out2, hz_out3,\n\n                                               hz_out4, hz_out5, hz_out6);\n\n        res4 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out2, hz_out3, hz_out4,\n\n                                               hz_out5, hz_out6, hz_out7);\n\n        res6 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out3, hz_out4, hz_out5,\n\n                                               hz_out6, hz_out7, hz_out8);\n\n\n\n        if (vert_offset) {\n\n            res1 = __msa_srari_h(hz_out3, 5);\n\n            res3 = __msa_srari_h(hz_out4, 5);\n\n            res5 = __msa_srari_h(hz_out5, 5);\n\n            res7 = __msa_srari_h(hz_out6, 5);\n\n        } else {\n\n            res1 = __msa_srari_h(hz_out2, 5);\n\n            res3 = __msa_srari_h(hz_out3, 5);\n\n            res5 = __msa_srari_h(hz_out4, 5);\n\n            res7 = __msa_srari_h(hz_out5, 5);\n\n        }\n\n\n\n        SAT_SH4_SH(res1, res3, res5, res7, 7);\n\n\n\n        res0 = __msa_aver_s_h(res0, res1);\n\n        res1 = __msa_aver_s_h(res2, res3);\n\n        res2 = __msa_aver_s_h(res4, res5);\n\n        res3 = __msa_aver_s_h(res6, res7);\n\n        ILVR_D2_UB(dst1, dst0, dst3, dst2, dst0, dst1);\n\n        CONVERT_UB_AVG_ST8x4_UB(res0, res1, res2, res3, dst0, dst1,\n\n                                dst, dst_stride);\n\n        dst += (4 * dst_stride);\n\n\n\n        hz_out0 = hz_out4;\n\n        hz_out1 = hz_out5;\n\n        hz_out2 = hz_out6;\n\n        hz_out3 = hz_out7;\n\n        hz_out4 = hz_out8;\n\n    }\n\n}\n", "idx": 4343, "_split": "valid", "_hash": "221a0729e414e874523946579fbb7146"}
{"project": "FFmpeg", "commit_id": "fa2a34cd40d124161c748bb0f430dc63c94dd0da", "target": 0, "func": "static const AVClass *filter_child_class_next(const AVClass *prev)\n\n{\n\n    AVFilter **f = NULL;\n\n\n\n    while (prev && *(f = av_filter_next(f)))\n\n        if ((*f)->priv_class == prev)\n\n            break;\n\n\n\n    while (*(f = av_filter_next(f)))\n\n        if ((*f)->priv_class)\n\n            return (*f)->priv_class;\n\n\n\n    return NULL;\n\n}\n", "idx": 4346, "_split": "valid", "_hash": "cd2caed7ce5b85ed730561ab3f09839d"}
{"project": "FFmpeg", "commit_id": "cde9e7800128f5466d97279918e1d20fc250a33b", "target": 0, "func": "static av_always_inline void mpeg_motion_lowres(MpegEncContext *s,\n\n                               uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                               int field_based, int bottom_field, int field_select,\n\n                               uint8_t **ref_picture, h264_chroma_mc_func *pix_op,\n\n                               int motion_x, int motion_y, int h)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int mx, my, src_x, src_y, uvsrc_x, uvsrc_y, uvlinesize, linesize, sx, sy, uvsx, uvsy;\n\n    const int lowres= s->avctx->lowres;\n\n    const int block_s= 8>>lowres;\n\n    const int s_mask= (2<<lowres)-1;\n\n    const int h_edge_pos = s->h_edge_pos >> lowres;\n\n    const int v_edge_pos = s->v_edge_pos >> lowres;\n\n    linesize   = s->current_picture.linesize[0] << field_based;\n\n    uvlinesize = s->current_picture.linesize[1] << field_based;\n\n\n\n    if(s->quarter_sample){ //FIXME obviously not perfect but qpel wont work in lowres anyway\n\n        motion_x/=2;\n\n        motion_y/=2;\n\n    }\n\n\n\n    if(field_based){\n\n        motion_y += (bottom_field - field_select)*((1<<lowres)-1);\n\n    }\n\n\n\n    sx= motion_x & s_mask;\n\n    sy= motion_y & s_mask;\n\n    src_x = s->mb_x*2*block_s               + (motion_x >> (lowres+1));\n\n    src_y =(s->mb_y*2*block_s>>field_based) + (motion_y >> (lowres+1));\n\n\n\n    if (s->out_format == FMT_H263) {\n\n        uvsx = ((motion_x>>1) & s_mask) | (sx&1);\n\n        uvsy = ((motion_y>>1) & s_mask) | (sy&1);\n\n        uvsrc_x = src_x>>1;\n\n        uvsrc_y = src_y>>1;\n\n    }else if(s->out_format == FMT_H261){//even chroma mv's are full pel in H261\n\n        mx = motion_x / 4;\n\n        my = motion_y / 4;\n\n        uvsx = (2*mx) & s_mask;\n\n        uvsy = (2*my) & s_mask;\n\n        uvsrc_x = s->mb_x*block_s               + (mx >> lowres);\n\n        uvsrc_y = s->mb_y*block_s               + (my >> lowres);\n\n    } else {\n\n        mx = motion_x / 2;\n\n        my = motion_y / 2;\n\n        uvsx = mx & s_mask;\n\n        uvsy = my & s_mask;\n\n        uvsrc_x = s->mb_x*block_s               + (mx >> (lowres+1));\n\n        uvsrc_y =(s->mb_y*block_s>>field_based) + (my >> (lowres+1));\n\n    }\n\n\n\n    ptr_y  = ref_picture[0] + src_y * linesize + src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if(   (unsigned)src_x > h_edge_pos                 - (!!sx) - 2*block_s\n\n       || (unsigned)src_y >(v_edge_pos >> field_based) - (!!sy) - h){\n\n            ff_emulated_edge_mc(s->edge_emu_buffer, ptr_y, s->linesize, 17, 17+field_based,\n\n                             src_x, src_y<<field_based, h_edge_pos, v_edge_pos);\n\n            ptr_y = s->edge_emu_buffer;\n\n            if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                uint8_t *uvbuf= s->edge_emu_buffer+18*s->linesize;\n\n                ff_emulated_edge_mc(uvbuf  , ptr_cb, s->uvlinesize, 9, 9+field_based,\n\n                                 uvsrc_x, uvsrc_y<<field_based, h_edge_pos>>1, v_edge_pos>>1);\n\n                ff_emulated_edge_mc(uvbuf+16, ptr_cr, s->uvlinesize, 9, 9+field_based,\n\n                                 uvsrc_x, uvsrc_y<<field_based, h_edge_pos>>1, v_edge_pos>>1);\n\n                ptr_cb= uvbuf;\n\n                ptr_cr= uvbuf+16;\n\n            }\n\n    }\n\n\n\n    if(bottom_field){ //FIXME use this for field pix too instead of the obnoxious hack which changes picture.data\n\n        dest_y += s->linesize;\n\n        dest_cb+= s->uvlinesize;\n\n        dest_cr+= s->uvlinesize;\n\n    }\n\n\n\n    if(field_select){\n\n        ptr_y += s->linesize;\n\n        ptr_cb+= s->uvlinesize;\n\n        ptr_cr+= s->uvlinesize;\n\n    }\n\n\n\n    sx <<= 2 - lowres;\n\n    sy <<= 2 - lowres;\n\n    pix_op[lowres-1](dest_y, ptr_y, linesize, h, sx, sy);\n\n\n\n    if(!(s->flags&CODEC_FLAG_GRAY)){\n\n        uvsx <<= 2 - lowres;\n\n        uvsy <<= 2 - lowres;\n\n        pix_op[lowres](dest_cb, ptr_cb, uvlinesize, h >> s->chroma_y_shift, uvsx, uvsy);\n\n        pix_op[lowres](dest_cr, ptr_cr, uvlinesize, h >> s->chroma_y_shift, uvsx, uvsy);\n\n    }\n\n    //FIXME h261 lowres loop filter\n\n}\n", "idx": 4414, "_split": "valid", "_hash": "7ecc2fb8fc970389669ce2e9b7b058a7"}
{"project": "FFmpeg", "commit_id": "50833c9f7b4e1922197a8955669f8ab3589c8cef", "target": 1, "func": "static int encode_slice_plane(AVCodecContext *avctx, int mb_count,\n\n        uint8_t *src, int src_stride, uint8_t *buf, unsigned buf_size,\n\n        int *qmat, int chroma)\n\n{\n\n    ProresContext* ctx = avctx->priv_data;\n\n    FDCTDSPContext *fdsp = &ctx->fdsp;\n\n    DECLARE_ALIGNED(16, int16_t, blocks)[DEFAULT_SLICE_MB_WIDTH << 8], *block;\n\n    int i, blocks_per_slice;\n\n    PutBitContext pb;\n\n\n\n    block = blocks;\n\n    for (i = 0; i < mb_count; i++) {\n\n        fdct_get(fdsp, src,                  src_stride, block + (0 << 6));\n\n        fdct_get(fdsp, src + 8 * src_stride, src_stride, block + ((2 - chroma) << 6));\n\n        if (!chroma) {\n\n            fdct_get(fdsp, src + 16,                  src_stride, block + (1 << 6));\n\n            fdct_get(fdsp, src + 16 + 8 * src_stride, src_stride, block + (3 << 6));\n\n        }\n\n\n\n        block += (256 >> chroma);\n\n        src   += (32  >> chroma);\n\n    }\n\n\n\n    blocks_per_slice = mb_count << (2 - chroma);\n\n    init_put_bits(&pb, buf, buf_size << 3);\n\n\n\n    encode_dc_coeffs(&pb, blocks, blocks_per_slice, qmat);\n\n    encode_ac_coeffs(avctx, &pb, blocks, blocks_per_slice, qmat);\n\n\n\n    flush_put_bits(&pb);\n\n    return put_bits_ptr(&pb) - pb.buf;\n\n}\n", "idx": 4421, "_split": "valid", "_hash": "6f6ec8720eb5b63f288df96afdd54f79"}
{"project": "FFmpeg", "commit_id": "7149fce2cac0474a5fbc5b47add1158cd8bb283e", "target": 1, "func": "static inline void render_line_unrolled(intptr_t x, intptr_t y, int x1,\n\n                                        intptr_t sy, int ady, int adx,\n\n                                        float *buf)\n\n{\n\n    int err = -adx;\n\n    x -= x1 - 1;\n\n    buf += x1 - 1;\n\n    while (++x < 0) {\n\n        err += ady;\n\n        if (err >= 0) {\n\n            err += ady - adx;\n\n            y   += sy;\n\n            buf[x++] = ff_vorbis_floor1_inverse_db_table[y];\n\n        }\n\n        buf[x] = ff_vorbis_floor1_inverse_db_table[y];\n\n    }\n\n    if (x <= 0) {\n\n        if (err + ady >= 0)\n\n            y += sy;\n\n        buf[x] = ff_vorbis_floor1_inverse_db_table[y];\n\n    }\n\n}\n", "idx": 4424, "_split": "valid", "_hash": "feaf68e7546d1ad840eb7ece1d098996"}
{"project": "FFmpeg", "commit_id": "1c37848f9029985d1271da9a0d161c2ebf0aca81", "target": 1, "func": "static int webm_dash_manifest_write_trailer(AVFormatContext *s)\n\n{\n\n    WebMDashMuxContext *w = s->priv_data;\n\n    int i;\n\n    for (i = 0; i < w->nb_as; i++) {\n\n        av_freep(&w->as[i].streams);\n\n    }\n\n    av_freep(&w->as);\n\n    return 0;\n\n}\n", "idx": 4427, "_split": "valid", "_hash": "19bffcd1dd844dece63e1f09f8cc019b"}
{"project": "FFmpeg", "commit_id": "507dce2536fea4b78a9f4973f77e1fa20cfe1b81", "target": 0, "func": "void ff_rv40dsp_init_neon(RV34DSPContext *c, DSPContext* dsp)\n\n{\n\n    c->put_pixels_tab[0][ 1] = ff_put_rv40_qpel16_mc10_neon;\n\n    c->put_pixels_tab[0][ 3] = ff_put_rv40_qpel16_mc30_neon;\n\n    c->put_pixels_tab[0][ 4] = ff_put_rv40_qpel16_mc01_neon;\n\n    c->put_pixels_tab[0][ 5] = ff_put_rv40_qpel16_mc11_neon;\n\n    c->put_pixels_tab[0][ 6] = ff_put_rv40_qpel16_mc21_neon;\n\n    c->put_pixels_tab[0][ 7] = ff_put_rv40_qpel16_mc31_neon;\n\n    c->put_pixels_tab[0][ 9] = ff_put_rv40_qpel16_mc12_neon;\n\n    c->put_pixels_tab[0][10] = ff_put_rv40_qpel16_mc22_neon;\n\n    c->put_pixels_tab[0][11] = ff_put_rv40_qpel16_mc32_neon;\n\n    c->put_pixels_tab[0][12] = ff_put_rv40_qpel16_mc03_neon;\n\n    c->put_pixels_tab[0][13] = ff_put_rv40_qpel16_mc13_neon;\n\n    c->put_pixels_tab[0][14] = ff_put_rv40_qpel16_mc23_neon;\n\n    c->put_pixels_tab[0][15] = ff_put_rv40_qpel16_mc33_neon;\n\n    c->avg_pixels_tab[0][ 1] = ff_avg_rv40_qpel16_mc10_neon;\n\n    c->avg_pixels_tab[0][ 3] = ff_avg_rv40_qpel16_mc30_neon;\n\n    c->avg_pixels_tab[0][ 4] = ff_avg_rv40_qpel16_mc01_neon;\n\n    c->avg_pixels_tab[0][ 5] = ff_avg_rv40_qpel16_mc11_neon;\n\n    c->avg_pixels_tab[0][ 6] = ff_avg_rv40_qpel16_mc21_neon;\n\n    c->avg_pixels_tab[0][ 7] = ff_avg_rv40_qpel16_mc31_neon;\n\n    c->avg_pixels_tab[0][ 9] = ff_avg_rv40_qpel16_mc12_neon;\n\n    c->avg_pixels_tab[0][10] = ff_avg_rv40_qpel16_mc22_neon;\n\n    c->avg_pixels_tab[0][11] = ff_avg_rv40_qpel16_mc32_neon;\n\n    c->avg_pixels_tab[0][12] = ff_avg_rv40_qpel16_mc03_neon;\n\n    c->avg_pixels_tab[0][13] = ff_avg_rv40_qpel16_mc13_neon;\n\n    c->avg_pixels_tab[0][14] = ff_avg_rv40_qpel16_mc23_neon;\n\n    c->avg_pixels_tab[0][15] = ff_avg_rv40_qpel16_mc33_neon;\n\n    c->put_pixels_tab[1][ 1] = ff_put_rv40_qpel8_mc10_neon;\n\n    c->put_pixels_tab[1][ 3] = ff_put_rv40_qpel8_mc30_neon;\n\n    c->put_pixels_tab[1][ 4] = ff_put_rv40_qpel8_mc01_neon;\n\n    c->put_pixels_tab[1][ 5] = ff_put_rv40_qpel8_mc11_neon;\n\n    c->put_pixels_tab[1][ 6] = ff_put_rv40_qpel8_mc21_neon;\n\n    c->put_pixels_tab[1][ 7] = ff_put_rv40_qpel8_mc31_neon;\n\n    c->put_pixels_tab[1][ 9] = ff_put_rv40_qpel8_mc12_neon;\n\n    c->put_pixels_tab[1][10] = ff_put_rv40_qpel8_mc22_neon;\n\n    c->put_pixels_tab[1][11] = ff_put_rv40_qpel8_mc32_neon;\n\n    c->put_pixels_tab[1][12] = ff_put_rv40_qpel8_mc03_neon;\n\n    c->put_pixels_tab[1][13] = ff_put_rv40_qpel8_mc13_neon;\n\n    c->put_pixels_tab[1][14] = ff_put_rv40_qpel8_mc23_neon;\n\n    c->put_pixels_tab[1][15] = ff_put_rv40_qpel8_mc33_neon;\n\n    c->avg_pixels_tab[1][ 1] = ff_avg_rv40_qpel8_mc10_neon;\n\n    c->avg_pixels_tab[1][ 3] = ff_avg_rv40_qpel8_mc30_neon;\n\n    c->avg_pixels_tab[1][ 4] = ff_avg_rv40_qpel8_mc01_neon;\n\n    c->avg_pixels_tab[1][ 5] = ff_avg_rv40_qpel8_mc11_neon;\n\n    c->avg_pixels_tab[1][ 6] = ff_avg_rv40_qpel8_mc21_neon;\n\n    c->avg_pixels_tab[1][ 7] = ff_avg_rv40_qpel8_mc31_neon;\n\n    c->avg_pixels_tab[1][ 9] = ff_avg_rv40_qpel8_mc12_neon;\n\n    c->avg_pixels_tab[1][10] = ff_avg_rv40_qpel8_mc22_neon;\n\n    c->avg_pixels_tab[1][11] = ff_avg_rv40_qpel8_mc32_neon;\n\n    c->avg_pixels_tab[1][12] = ff_avg_rv40_qpel8_mc03_neon;\n\n    c->avg_pixels_tab[1][13] = ff_avg_rv40_qpel8_mc13_neon;\n\n    c->avg_pixels_tab[1][14] = ff_avg_rv40_qpel8_mc23_neon;\n\n    c->avg_pixels_tab[1][15] = ff_avg_rv40_qpel8_mc33_neon;\n\n\n\n    c->put_chroma_pixels_tab[0] = ff_put_rv40_chroma_mc8_neon;\n\n    c->put_chroma_pixels_tab[1] = ff_put_rv40_chroma_mc4_neon;\n\n    c->avg_chroma_pixels_tab[0] = ff_avg_rv40_chroma_mc8_neon;\n\n    c->avg_chroma_pixels_tab[1] = ff_avg_rv40_chroma_mc4_neon;\n\n\n\n    c->rv40_weight_pixels_tab[0][0] = ff_rv40_weight_func_16_neon;\n\n    c->rv40_weight_pixels_tab[0][1] = ff_rv40_weight_func_8_neon;\n\n\n\n    c->rv40_loop_filter_strength[0] = ff_rv40_h_loop_filter_strength_neon;\n\n    c->rv40_loop_filter_strength[1] = ff_rv40_v_loop_filter_strength_neon;\n\n    c->rv40_weak_loop_filter[0]     = ff_rv40_h_weak_loop_filter_neon;\n\n    c->rv40_weak_loop_filter[1]     = ff_rv40_v_weak_loop_filter_neon;\n\n}\n", "idx": 4447, "_split": "valid", "_hash": "4db79e223be1d91447bc5fcdef476c63"}
{"project": "FFmpeg", "commit_id": "dc79685195a45c9b8b17d7b93d118e0aefa45462", "target": 0, "func": "static int ivi_decode_blocks(GetBitContext *gb, IVIBandDesc *band,\n\n                             IVITile *tile, AVCodecContext *avctx)\n\n{\n\n    int mbn, blk, num_blocks, blk_size, ret, is_intra, mc_type = 0;\n\n    int mv_x = 0, mv_y = 0;\n\n    int32_t prev_dc;\n\n    uint32_t cbp, quant, buf_offs;\n\n    IVIMbInfo *mb;\n\n    ivi_mc_func mc_with_delta_func, mc_no_delta_func;\n\n    const uint8_t *scale_tab;\n\n\n\n    /* init intra prediction for the DC coefficient */\n\n    prev_dc    = 0;\n\n    blk_size   = band->blk_size;\n\n    /* number of blocks per mb */\n\n    num_blocks = (band->mb_size != blk_size) ? 4 : 1;\n\n    if (blk_size == 8) {\n\n        mc_with_delta_func = ff_ivi_mc_8x8_delta;\n\n        mc_no_delta_func   = ff_ivi_mc_8x8_no_delta;\n\n    } else {\n\n        mc_with_delta_func = ff_ivi_mc_4x4_delta;\n\n        mc_no_delta_func   = ff_ivi_mc_4x4_no_delta;\n\n    }\n\n\n\n    for (mbn = 0, mb = tile->mbs; mbn < tile->num_MBs; mb++, mbn++) {\n\n        is_intra = !mb->type;\n\n        cbp      = mb->cbp;\n\n        buf_offs = mb->buf_offs;\n\n\n\n        quant = band->glob_quant + mb->q_delta;\n\n        if (avctx->codec_id == AV_CODEC_ID_INDEO4)\n\n            quant = av_clip(quant, 0, 31);\n\n        else\n\n            quant = av_clip(quant, 0, 23);\n\n\n\n        scale_tab = is_intra ? band->intra_scale : band->inter_scale;\n\n        if (scale_tab)\n\n            quant = scale_tab[quant];\n\n\n\n        if (!is_intra) {\n\n            mv_x = mb->mv_x;\n\n            mv_y = mb->mv_y;\n\n            if (band->is_halfpel) {\n\n                mc_type = ((mv_y & 1) << 1) | (mv_x & 1);\n\n                mv_x >>= 1;\n\n                mv_y >>= 1; /* convert halfpel vectors into fullpel ones */\n\n            }\n\n            if (mb->type) {\n\n                int dmv_x, dmv_y, cx, cy;\n\n\n\n                dmv_x = mb->mv_x >> band->is_halfpel;\n\n                dmv_y = mb->mv_y >> band->is_halfpel;\n\n                cx    = mb->mv_x &  band->is_halfpel;\n\n                cy    = mb->mv_y &  band->is_halfpel;\n\n\n\n                if (mb->xpos + dmv_x < 0 ||\n\n                    mb->xpos + dmv_x + band->mb_size + cx > band->pitch ||\n\n                    mb->ypos + dmv_y < 0 ||\n\n                    mb->ypos + dmv_y + band->mb_size + cy > band->aheight) {\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n            }\n\n        }\n\n\n\n        for (blk = 0; blk < num_blocks; blk++) {\n\n            /* adjust block position in the buffer according to its number */\n\n            if (blk & 1) {\n\n                buf_offs += blk_size;\n\n            } else if (blk == 2) {\n\n                buf_offs -= blk_size;\n\n                buf_offs += blk_size * band->pitch;\n\n            }\n\n\n\n            if (cbp & 1) { /* block coded ? */\n\n                ret = ivi_decode_coded_blocks(gb, band, mc_with_delta_func,\n\n                                              mv_x, mv_y, &prev_dc, is_intra,\n\n                                              mc_type, quant, buf_offs, avctx);\n\n                if (ret < 0)\n\n                    return ret;\n\n            } else {\n\n                /* block not coded */\n\n                /* for intra blocks apply the dc slant transform */\n\n                /* for inter - perform the motion compensation without delta */\n\n                if (is_intra) {\n\n                    if (band->dc_transform)\n\n                        band->dc_transform(&prev_dc, band->buf + buf_offs,\n\n                                           band->pitch, blk_size);\n\n                } else {\n\n                    ret = ivi_mc(mc_no_delta_func, band->buf, band->ref_buf,\n\n                                 buf_offs, mv_x, mv_y, band->pitch, mc_type);\n\n                    if (ret < 0)\n\n                        return ret;\n\n                }\n\n            }\n\n\n\n            cbp >>= 1;\n\n        }// for blk\n\n    }// for mbn\n\n\n\n    align_get_bits(gb);\n\n\n\n    return 0;\n\n}\n", "idx": 4478, "_split": "valid", "_hash": "491196ec24e6928b431d6c64488e7613"}
{"project": "FFmpeg", "commit_id": "93dc1c1221856e88ac9df560a1b4f77dd5f5395d", "target": 0, "func": "void checkasm_check_fixed_dsp(void)\n\n{\n\n    LOCAL_ALIGNED_32(int32_t, src0, [BUF_SIZE]);\n\n    LOCAL_ALIGNED_32(int32_t, src1, [BUF_SIZE]);\n\n    LOCAL_ALIGNED_32(int32_t, src2, [BUF_SIZE]);\n\n    AVFixedDSPContext *fdsp = avpriv_alloc_fixed_dsp(1);\n\n\n\n    randomize_buffers();\n\n    if (check_func(fdsp->vector_fmul, \"vector_fmul\"))\n\n        check_vector_fmul(src0, src1);\n\n    if (check_func(fdsp->vector_fmul_add, \"vector_fmul_add\"))\n\n        check_vector_fmul_add(src0, src1, src2);\n\n    if (check_func(fdsp->vector_fmul_reverse, \"vector_fmul_reverse\"))\n\n        check_vector_fmul(src0, src1);\n\n    if (check_func(fdsp->vector_fmul_window, \"vector_fmul_window\"))\n\n        check_vector_fmul_window(src0, src1, src2);\n\n    if (check_func(fdsp->vector_fmul_window_scaled, \"vector_fmul_window_scaled\"))\n\n        check_vector_fmul_window_scaled(src0, src1, src2);\n\n    report(\"vector_fmul\");\n\n    if (check_func(fdsp->butterflies_fixed, \"butterflies_fixed\"))\n\n        check_butterflies(src0, src1);\n\n    report(\"butterflies_fixed\");\n\n    if (check_func(fdsp->scalarproduct_fixed, \"scalarproduct_fixed\"))\n\n        check_scalarproduct_fixed(src0, src1);\n\n    report(\"scalarproduct_fixed\");\n\n\n\n    av_freep(&fdsp);\n\n}\n", "idx": 4514, "_split": "valid", "_hash": "0f3b654529fa48ff6b7625d1543defb4"}
{"project": "FFmpeg", "commit_id": "a8343bfb6a3f00777943b94ff2969422f578f246", "target": 0, "func": "int ff_read_riff_info(AVFormatContext *s, int64_t size)\n\n{\n\n    int64_t start, end, cur;\n\n    AVIOContext *pb = s->pb;\n\n\n\n    start = avio_tell(pb);\n\n    end = start + size;\n\n\n\n    while ((cur = avio_tell(pb)) >= 0 && cur <= end - 8 /* = tag + size */) {\n\n        uint32_t chunk_code;\n\n        int64_t chunk_size;\n\n        char key[5] = {0};\n\n        char *value;\n\n\n\n        chunk_code = avio_rl32(pb);\n\n        chunk_size = avio_rl32(pb);\n\n\n\n        if (chunk_size > end || end - chunk_size < cur || chunk_size == UINT_MAX) {\n\n            avio_seek(pb, -9, SEEK_CUR);\n\n            chunk_code = avio_rl32(pb);\n\n            chunk_size = avio_rl32(pb);\n\n            if (chunk_size > end || end - chunk_size < cur || chunk_size == UINT_MAX) {\n\n                av_log(s, AV_LOG_WARNING, \"too big INFO subchunk\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n\n\n        chunk_size += (chunk_size & 1);\n\n\n\n        if (!chunk_code) {\n\n            if (chunk_size)\n\n                avio_skip(pb, chunk_size);\n\n            continue;\n\n        }\n\n\n\n        value = av_mallocz(chunk_size + 1);\n\n        if (!value) {\n\n            av_log(s, AV_LOG_ERROR, \"out of memory, unable to read INFO tag\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        AV_WL32(key, chunk_code);\n\n\n\n        if (avio_read(pb, value, chunk_size) != chunk_size) {\n\n            av_log(s, AV_LOG_WARNING, \"premature end of file while reading INFO tag\\n\");\n\n        }\n\n\n\n        av_dict_set(&s->metadata, key, value, AV_DICT_DONT_STRDUP_VAL);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 4525, "_split": "valid", "_hash": "a0fdff82b1be96bed5299d879ebd6a9f"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "void ff_mpeg_flush(AVCodecContext *avctx){\n\n    int i;\n\n    MpegEncContext *s = avctx->priv_data;\n\n\n\n    if(s==NULL || s->picture==NULL)\n\n        return;\n\n\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++)\n\n        ff_mpeg_unref_picture(s, &s->picture[i]);\n\n    s->current_picture_ptr = s->last_picture_ptr = s->next_picture_ptr = NULL;\n\n\n\n    ff_mpeg_unref_picture(s, &s->current_picture);\n\n    ff_mpeg_unref_picture(s, &s->last_picture);\n\n    ff_mpeg_unref_picture(s, &s->next_picture);\n\n\n\n    s->mb_x= s->mb_y= 0;\n\n\n\n    s->parse_context.state= -1;\n\n    s->parse_context.frame_start_found= 0;\n\n    s->parse_context.overread= 0;\n\n    s->parse_context.overread_index= 0;\n\n    s->parse_context.index= 0;\n\n    s->parse_context.last_index= 0;\n\n    s->bitstream_buffer_size=0;\n\n    s->pp_time=0;\n\n}\n", "idx": 4530, "_split": "valid", "_hash": "69016157032b277731d1a3a5a038ef93"}
{"project": "FFmpeg", "commit_id": "7e10145976866fc6227d3ccc697a7c9fee862a77", "target": 0, "func": "static int rwpipe_read_ppm_header( rwpipe *rw, int *width, int *height )\n\n{\n\n    char line[ 3 ];\n\n    FILE *in = rwpipe_reader( rw );\n\n    int max;\n\n\n\n    fgets( line, 3, in );\n\n    if ( !strncmp( line, \"P6\", 2 ) )\n\n    {\n\n        *width = rwpipe_read_number( rw );\n\n        *height = rwpipe_read_number( rw );\n\n        max = rwpipe_read_number( rw );\n\n        return max != 255 || *width <= 0 || *height <= 0;\n\n    }\n\n    return 1;\n\n}\n", "idx": 4575, "_split": "valid", "_hash": "f5babde7120f1887ff326f3b8840b515"}
{"project": "FFmpeg", "commit_id": "ee9f36a88eb3e2706ea659acb0ca80c414fa5d8a", "target": 0, "func": "static int crc_write_header(struct AVFormatContext *s)\n\n{\n\n    CRCState *crc = s->priv_data;\n\n\n\n    /* init CRC */\n\n    crc->crcval = adler32(0, NULL, 0);\n\n\n\n    return 0;\n\n}\n", "idx": 4580, "_split": "valid", "_hash": "8cadb601796a46b1c3d5e1907479a367"}
{"project": "FFmpeg", "commit_id": "3a177a9cca924e097265b32f9282814f6b653e08", "target": 1, "func": "static av_cold int initFilter(int16_t **outFilter, int32_t **filterPos,\n\n                              int *outFilterSize, int xInc, int srcW,\n\n                              int dstW, int filterAlign, int one,\n\n                              int flags, int cpu_flags,\n\n                              SwsVector *srcFilter, SwsVector *dstFilter,\n\n                              double param[2], int is_horizontal)\n\n{\n\n    int i;\n\n    int filterSize;\n\n    int filter2Size;\n\n    int minFilterSize;\n\n    int64_t *filter    = NULL;\n\n    int64_t *filter2   = NULL;\n\n    const int64_t fone = 1LL << 54;\n\n    int ret            = -1;\n\n\n\n    emms_c(); // FIXME should not be required but IS (even for non-MMX versions)\n\n\n\n    // NOTE: the +3 is for the MMX(+1) / SSE(+3) scaler which reads over the end\n\n    FF_ALLOC_OR_GOTO(NULL, *filterPos, (dstW + 3) * sizeof(**filterPos), fail);\n\n\n\n    if (FFABS(xInc - 0x10000) < 10) { // unscaled\n\n        int i;\n\n        filterSize = 1;\n\n        FF_ALLOCZ_OR_GOTO(NULL, filter,\n\n                          dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        for (i = 0; i < dstW; i++) {\n\n            filter[i * filterSize] = fone;\n\n            (*filterPos)[i]        = i;\n\n        }\n\n    } else if (flags & SWS_POINT) { // lame looking point sampling mode\n\n        int i;\n\n        int xDstInSrc;\n\n        filterSize = 1;\n\n        FF_ALLOC_OR_GOTO(NULL, filter,\n\n                         dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        xDstInSrc = xInc / 2 - 0x8000;\n\n        for (i = 0; i < dstW; i++) {\n\n            int xx = (xDstInSrc - ((filterSize - 1) << 15) + (1 << 15)) >> 16;\n\n\n\n            (*filterPos)[i] = xx;\n\n            filter[i]       = fone;\n\n            xDstInSrc      += xInc;\n\n        }\n\n    } else if ((xInc <= (1 << 16) && (flags & SWS_AREA)) ||\n\n               (flags & SWS_FAST_BILINEAR)) { // bilinear upscale\n\n        int i;\n\n        int xDstInSrc;\n\n        filterSize = 2;\n\n        FF_ALLOC_OR_GOTO(NULL, filter,\n\n                         dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        xDstInSrc = xInc / 2 - 0x8000;\n\n        for (i = 0; i < dstW; i++) {\n\n            int xx = (xDstInSrc - ((filterSize - 1) << 15) + (1 << 15)) >> 16;\n\n            int j;\n\n\n\n            (*filterPos)[i] = xx;\n\n            // bilinear upscale / linear interpolate / area averaging\n\n            for (j = 0; j < filterSize; j++) {\n\n                int64_t coeff = fone - FFABS((xx << 16) - xDstInSrc) *\n\n                                (fone >> 16);\n\n                if (coeff < 0)\n\n                    coeff = 0;\n\n                filter[i * filterSize + j] = coeff;\n\n                xx++;\n\n            }\n\n            xDstInSrc += xInc;\n\n        }\n\n    } else {\n\n        int64_t xDstInSrc;\n\n        int sizeFactor;\n\n\n\n        if (flags & SWS_BICUBIC)\n\n            sizeFactor = 4;\n\n        else if (flags & SWS_X)\n\n            sizeFactor = 8;\n\n        else if (flags & SWS_AREA)\n\n            sizeFactor = 1;     // downscale only, for upscale it is bilinear\n\n        else if (flags & SWS_GAUSS)\n\n            sizeFactor = 8;     // infinite ;)\n\n        else if (flags & SWS_LANCZOS)\n\n            sizeFactor = param[0] != SWS_PARAM_DEFAULT ? ceil(2 * param[0]) : 6;\n\n        else if (flags & SWS_SINC)\n\n            sizeFactor = 20;    // infinite ;)\n\n        else if (flags & SWS_SPLINE)\n\n            sizeFactor = 20;    // infinite ;)\n\n        else if (flags & SWS_BILINEAR)\n\n            sizeFactor = 2;\n\n        else {\n\n            sizeFactor = 0;     // GCC warning killer\n\n            assert(0);\n\n        }\n\n\n\n        if (xInc <= 1 << 16)\n\n            filterSize = 1 + sizeFactor;    // upscale\n\n        else\n\n            filterSize = 1 + (sizeFactor * srcW + dstW - 1) / dstW;\n\n\n\n        filterSize = FFMIN(filterSize, srcW - 2);\n\n        filterSize = FFMAX(filterSize, 1);\n\n\n\n        FF_ALLOC_OR_GOTO(NULL, filter,\n\n                         dstW * sizeof(*filter) * filterSize, fail);\n\n\n\n        xDstInSrc = xInc - 0x10000;\n\n        for (i = 0; i < dstW; i++) {\n\n            int xx = (xDstInSrc - ((filterSize - 2) << 16)) / (1 << 17);\n\n            int j;\n\n            (*filterPos)[i] = xx;\n\n            for (j = 0; j < filterSize; j++) {\n\n                int64_t d = (FFABS(((int64_t)xx << 17) - xDstInSrc)) << 13;\n\n                double floatd;\n\n                int64_t coeff;\n\n\n\n                if (xInc > 1 << 16)\n\n                    d = d * dstW / srcW;\n\n                floatd = d * (1.0 / (1 << 30));\n\n\n\n                if (flags & SWS_BICUBIC) {\n\n                    int64_t B = (param[0] != SWS_PARAM_DEFAULT ? param[0] :   0) * (1 << 24);\n\n                    int64_t C = (param[1] != SWS_PARAM_DEFAULT ? param[1] : 0.6) * (1 << 24);\n\n\n\n                    if (d >= 1LL << 31) {\n\n                        coeff = 0.0;\n\n                    } else {\n\n                        int64_t dd  = (d  * d) >> 30;\n\n                        int64_t ddd = (dd * d) >> 30;\n\n\n\n                        if (d < 1LL << 30)\n\n                            coeff =  (12 * (1 << 24) -  9 * B - 6 * C) * ddd +\n\n                                    (-18 * (1 << 24) + 12 * B + 6 * C) *  dd +\n\n                                      (6 * (1 << 24) -  2 * B)         * (1 << 30);\n\n                        else\n\n                            coeff =      (-B -  6 * C) * ddd +\n\n                                      (6 * B + 30 * C) * dd  +\n\n                                    (-12 * B - 48 * C) * d   +\n\n                                      (8 * B + 24 * C) * (1 << 30);\n\n                    }\n\n                    coeff *= fone >> (30 + 24);\n\n                }\n\n#if 0\n\n                else if (flags & SWS_X) {\n\n                    double p  = param ? param * 0.01 : 0.3;\n\n                    coeff     = d ? sin(d * M_PI) / (d * M_PI) : 1.0;\n\n                    coeff    *= pow(2.0, -p * d * d);\n\n                }\n\n#endif\n\n                else if (flags & SWS_X) {\n\n                    double A = param[0] != SWS_PARAM_DEFAULT ? param[0] : 1.0;\n\n                    double c;\n\n\n\n                    if (floatd < 1.0)\n\n                        c = cos(floatd * M_PI);\n\n                    else\n\n                        c = -1.0;\n\n                    if (c < 0.0)\n\n                        c = -pow(-c, A);\n\n                    else\n\n                        c = pow(c, A);\n\n                    coeff = (c * 0.5 + 0.5) * fone;\n\n                } else if (flags & SWS_AREA) {\n\n                    int64_t d2 = d - (1 << 29);\n\n                    if (d2 * xInc < -(1LL << (29 + 16)))\n\n                        coeff = 1.0 * (1LL << (30 + 16));\n\n                    else if (d2 * xInc < (1LL << (29 + 16)))\n\n                        coeff = -d2 * xInc + (1LL << (29 + 16));\n\n                    else\n\n                        coeff = 0.0;\n\n                    coeff *= fone >> (30 + 16);\n\n                } else if (flags & SWS_GAUSS) {\n\n                    double p = param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;\n\n                    coeff = (pow(2.0, -p * floatd * floatd)) * fone;\n\n                } else if (flags & SWS_SINC) {\n\n                    coeff = (d ? sin(floatd * M_PI) / (floatd * M_PI) : 1.0) * fone;\n\n                } else if (flags & SWS_LANCZOS) {\n\n                    double p = param[0] != SWS_PARAM_DEFAULT ? param[0] : 3.0;\n\n                    coeff = (d ? sin(floatd * M_PI) * sin(floatd * M_PI / p) /\n\n                             (floatd * floatd * M_PI * M_PI / p) : 1.0) * fone;\n\n                    if (floatd > p)\n\n                        coeff = 0;\n\n                } else if (flags & SWS_BILINEAR) {\n\n                    coeff = (1 << 30) - d;\n\n                    if (coeff < 0)\n\n                        coeff = 0;\n\n                    coeff *= fone >> 30;\n\n                } else if (flags & SWS_SPLINE) {\n\n                    double p = -2.196152422706632;\n\n                    coeff = getSplineCoeff(1.0, 0.0, p, -p - 1.0, floatd) * fone;\n\n                } else {\n\n                    coeff = 0.0; // GCC warning killer\n\n                    assert(0);\n\n                }\n\n\n\n                filter[i * filterSize + j] = coeff;\n\n                xx++;\n\n            }\n\n            xDstInSrc += 2 * xInc;\n\n        }\n\n    }\n\n\n\n    /* apply src & dst Filter to filter -> filter2\n\n     * av_free(filter);\n\n     */\n\n    assert(filterSize > 0);\n\n    filter2Size = filterSize;\n\n    if (srcFilter)\n\n        filter2Size += srcFilter->length - 1;\n\n    if (dstFilter)\n\n        filter2Size += dstFilter->length - 1;\n\n    assert(filter2Size > 0);\n\n    FF_ALLOCZ_OR_GOTO(NULL, filter2, filter2Size * dstW * sizeof(*filter2), fail);\n\n\n\n    for (i = 0; i < dstW; i++) {\n\n        int j, k;\n\n\n\n        if (srcFilter) {\n\n            for (k = 0; k < srcFilter->length; k++) {\n\n                for (j = 0; j < filterSize; j++)\n\n                    filter2[i * filter2Size + k + j] +=\n\n                        srcFilter->coeff[k] * filter[i * filterSize + j];\n\n            }\n\n        } else {\n\n            for (j = 0; j < filterSize; j++)\n\n                filter2[i * filter2Size + j] = filter[i * filterSize + j];\n\n        }\n\n        // FIXME dstFilter\n\n\n\n        (*filterPos)[i] += (filterSize - 1) / 2 - (filter2Size - 1) / 2;\n\n    }\n\n    av_freep(&filter);\n\n\n\n    /* try to reduce the filter-size (step1 find size and shift left) */\n\n    // Assume it is near normalized (*0.5 or *2.0 is OK but * 0.001 is not).\n\n    minFilterSize = 0;\n\n    for (i = dstW - 1; i >= 0; i--) {\n\n        int min = filter2Size;\n\n        int j;\n\n        int64_t cutOff = 0.0;\n\n\n\n        /* get rid of near zero elements on the left by shifting left */\n\n        for (j = 0; j < filter2Size; j++) {\n\n            int k;\n\n            cutOff += FFABS(filter2[i * filter2Size]);\n\n\n\n            if (cutOff > SWS_MAX_REDUCE_CUTOFF * fone)\n\n                break;\n\n\n\n            /* preserve monotonicity because the core can't handle the\n\n             * filter otherwise */\n\n            if (i < dstW - 1 && (*filterPos)[i] >= (*filterPos)[i + 1])\n\n                break;\n\n\n\n            // move filter coefficients left\n\n            for (k = 1; k < filter2Size; k++)\n\n                filter2[i * filter2Size + k - 1] = filter2[i * filter2Size + k];\n\n            filter2[i * filter2Size + k - 1] = 0;\n\n            (*filterPos)[i]++;\n\n        }\n\n\n\n        cutOff = 0;\n\n        /* count near zeros on the right */\n\n        for (j = filter2Size - 1; j > 0; j--) {\n\n            cutOff += FFABS(filter2[i * filter2Size + j]);\n\n\n\n            if (cutOff > SWS_MAX_REDUCE_CUTOFF * fone)\n\n                break;\n\n            min--;\n\n        }\n\n\n\n        if (min > minFilterSize)\n\n            minFilterSize = min;\n\n    }\n\n\n\n    if (PPC_ALTIVEC(cpu_flags)) {\n\n        // we can handle the special case 4, so we don't want to go the full 8\n\n        if (minFilterSize < 5)\n\n            filterAlign = 4;\n\n\n\n        /* We really don't want to waste our time doing useless computation, so\n\n         * fall back on the scalar C code for very small filters.\n\n         * Vectorizing is worth it only if you have a decent-sized vector. */\n\n        if (minFilterSize < 3)\n\n            filterAlign = 1;\n\n    }\n\n\n\n    if (INLINE_MMX(cpu_flags)) {\n\n        // special case for unscaled vertical filtering\n\n        if (minFilterSize == 1 && filterAlign == 2)\n\n            filterAlign = 1;\n\n    }\n\n\n\n    assert(minFilterSize > 0);\n\n    filterSize = (minFilterSize + (filterAlign - 1)) & (~(filterAlign - 1));\n\n    assert(filterSize > 0);\n\n    filter = av_malloc(filterSize * dstW * sizeof(*filter));\n\n    if (filterSize >= MAX_FILTER_SIZE * 16 /\n\n                      ((flags & SWS_ACCURATE_RND) ? APCK_SIZE : 16) || !filter)\n\n        goto fail;\n\n    *outFilterSize = filterSize;\n\n\n\n    if (flags & SWS_PRINT_INFO)\n\n        av_log(NULL, AV_LOG_VERBOSE,\n\n               \"SwScaler: reducing / aligning filtersize %d -> %d\\n\",\n\n               filter2Size, filterSize);\n\n    /* try to reduce the filter-size (step2 reduce it) */\n\n    for (i = 0; i < dstW; i++) {\n\n        int j;\n\n\n\n        for (j = 0; j < filterSize; j++) {\n\n            if (j >= filter2Size)\n\n                filter[i * filterSize + j] = 0;\n\n            else\n\n                filter[i * filterSize + j] = filter2[i * filter2Size + j];\n\n            if ((flags & SWS_BITEXACT) && j >= minFilterSize)\n\n                filter[i * filterSize + j] = 0;\n\n        }\n\n    }\n\n\n\n    // FIXME try to align filterPos if possible\n\n\n\n    // fix borders\n\n    if (is_horizontal) {\n\n        for (i = 0; i < dstW; i++) {\n\n            int j;\n\n            if ((*filterPos)[i] < 0) {\n\n                // move filter coefficients left to compensate for filterPos\n\n                for (j = 1; j < filterSize; j++) {\n\n                    int left = FFMAX(j + (*filterPos)[i], 0);\n\n                    filter[i * filterSize + left] += filter[i * filterSize + j];\n\n                    filter[i * filterSize + j]     = 0;\n\n                }\n\n                (*filterPos)[i] = 0;\n\n            }\n\n\n\n            if ((*filterPos)[i] + filterSize > srcW) {\n\n                int shift = (*filterPos)[i] + filterSize - srcW;\n\n                // move filter coefficients right to compensate for filterPos\n\n                for (j = filterSize - 2; j >= 0; j--) {\n\n                    int right = FFMIN(j + shift, filterSize - 1);\n\n                    filter[i * filterSize + right] += filter[i * filterSize + j];\n\n                    filter[i * filterSize + j]      = 0;\n\n                }\n\n                (*filterPos)[i] = srcW - filterSize;\n\n            }\n\n        }\n\n    }\n\n\n\n    // Note the +1 is for the MMX scaler which reads over the end\n\n    /* align at 16 for AltiVec (needed by hScale_altivec_real) */\n\n    FF_ALLOCZ_OR_GOTO(NULL, *outFilter,\n\n                      *outFilterSize * (dstW + 3) * sizeof(int16_t), fail);\n\n\n\n    /* normalize & store in outFilter */\n\n    for (i = 0; i < dstW; i++) {\n\n        int j;\n\n        int64_t error = 0;\n\n        int64_t sum   = 0;\n\n\n\n        for (j = 0; j < filterSize; j++) {\n\n            sum += filter[i * filterSize + j];\n\n        }\n\n        sum = (sum + one / 2) / one;\n\n        for (j = 0; j < *outFilterSize; j++) {\n\n            int64_t v = filter[i * filterSize + j] + error;\n\n            int intV  = ROUNDED_DIV(v, sum);\n\n            (*outFilter)[i * (*outFilterSize) + j] = intV;\n\n            error                                  = v - intV * sum;\n\n        }\n\n    }\n\n\n\n    (*filterPos)[dstW + 0] =\n\n    (*filterPos)[dstW + 1] =\n\n    (*filterPos)[dstW + 2] = (*filterPos)[dstW - 1]; /* the MMX/SSE scaler will\n\n                                                      * read over the end */\n\n    for (i = 0; i < *outFilterSize; i++) {\n\n        int k = (dstW - 1) * (*outFilterSize) + i;\n\n        (*outFilter)[k + 1 * (*outFilterSize)] =\n\n        (*outFilter)[k + 2 * (*outFilterSize)] =\n\n        (*outFilter)[k + 3 * (*outFilterSize)] = (*outFilter)[k];\n\n    }\n\n\n\n    ret = 0;\n\n\n\nfail:\n\n    av_free(filter);\n\n    av_free(filter2);\n\n    return ret;\n\n}\n", "idx": 4599, "_split": "valid", "_hash": "9150dc39523da5b2fd7d7ef9b8992b10"}
{"project": "FFmpeg", "commit_id": "5d590d87b30c59dfb853ebde6276d36f8a8bbc58", "target": 1, "func": "static int av_dict_set_fxp(AVDictionary **pm, const char *key, uint64_t value, unsigned int digits,\n\n                int flags)\n\n{\n\n    char valuestr[44];\n\n    snprintf(valuestr, sizeof(valuestr), \"%\"PRId64\".%0*\"PRId64,\n\n             value / PRECISION, digits, ( value % PRECISION ) / ( PRECISION / uintpow(10,digits) ));\n\n    return av_dict_set(pm, key, valuestr, flags);\n\n}\n", "idx": 4647, "_split": "valid", "_hash": "777d18167d8df284a8c7114d2c6fac87"}
{"project": "FFmpeg", "commit_id": "f077ad69c682c13ab75a72aec11a61cac53f0c91", "target": 1, "func": "int av_packet_ref(AVPacket *dst, const AVPacket *src)\n\n{\n\n    int ret;\n\n\n\n    ret = av_packet_copy_props(dst, src);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (!src->buf) {\n\n        ret = packet_alloc(&dst->buf, src->size);\n\n        if (ret < 0)\n\n            goto fail;\n\n        memcpy(dst->buf->data, src->data, src->size);\n\n\n\n        dst->data = dst->buf->data;\n\n    } else {\n\n        dst->buf = av_buffer_ref(src->buf);\n\n        if (!dst->buf) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        dst->data = src->data;\n\n    }\n\n\n\n    dst->size = src->size;\n\n\n\n    return 0;\n\nfail:\n\n    av_packet_free_side_data(dst);\n\n    return ret;\n\n}\n", "idx": 4650, "_split": "valid", "_hash": "2f5851ad0f3eca017cce15c5b70603c5"}
{"project": "FFmpeg", "commit_id": "fde5c7dc79eb017790ba232442ad2a4eecea4bf1", "target": 1, "func": "int ff_h264_pred_weight_table(GetBitContext *gb, const SPS *sps,\n\n                              const int *ref_count, int slice_type_nos,\n\n                              H264PredWeightTable *pwt,\n\n                              int picture_structure, void *logctx)\n\n{\n\n    int list, i, j;\n\n    int luma_def, chroma_def;\n\n\n\n    pwt->use_weight             = 0;\n\n    pwt->use_weight_chroma      = 0;\n\n    pwt->luma_log2_weight_denom = get_ue_golomb(gb);\n\n    if (sps->chroma_format_idc)\n\n        pwt->chroma_log2_weight_denom = get_ue_golomb(gb);\n\n\n\n    if (pwt->luma_log2_weight_denom > 7U) {\n\n        av_log(logctx, AV_LOG_ERROR, \"luma_log2_weight_denom %d is out of range\\n\", pwt->luma_log2_weight_denom);\n\n        pwt->luma_log2_weight_denom = 0;\n\n    }\n\n    if (pwt->chroma_log2_weight_denom > 7U) {\n\n        av_log(logctx, AV_LOG_ERROR, \"chroma_log2_weight_denom %d is out of range\\n\", pwt->chroma_log2_weight_denom);\n\n        pwt->chroma_log2_weight_denom = 0;\n\n    }\n\n\n\n    luma_def   = 1 << pwt->luma_log2_weight_denom;\n\n    chroma_def = 1 << pwt->chroma_log2_weight_denom;\n\n\n\n    for (list = 0; list < 2; list++) {\n\n        pwt->luma_weight_flag[list]   = 0;\n\n        pwt->chroma_weight_flag[list] = 0;\n\n        for (i = 0; i < ref_count[list]; i++) {\n\n            int luma_weight_flag, chroma_weight_flag;\n\n\n\n            luma_weight_flag = get_bits1(gb);\n\n            if (luma_weight_flag) {\n\n                pwt->luma_weight[i][list][0] = get_se_golomb(gb);\n\n                pwt->luma_weight[i][list][1] = get_se_golomb(gb);\n\n                if ((int8_t)pwt->luma_weight[i][list][0] != pwt->luma_weight[i][list][0] ||\n\n                    (int8_t)pwt->luma_weight[i][list][1] != pwt->luma_weight[i][list][1])\n\n                    goto out_range_weight;\n\n                if (pwt->luma_weight[i][list][0] != luma_def ||\n\n                    pwt->luma_weight[i][list][1] != 0) {\n\n                    pwt->use_weight             = 1;\n\n                    pwt->luma_weight_flag[list] = 1;\n\n                }\n\n            } else {\n\n                pwt->luma_weight[i][list][0] = luma_def;\n\n                pwt->luma_weight[i][list][1] = 0;\n\n            }\n\n\n\n            if (sps->chroma_format_idc) {\n\n                chroma_weight_flag = get_bits1(gb);\n\n                if (chroma_weight_flag) {\n\n                    int j;\n\n                    for (j = 0; j < 2; j++) {\n\n                        pwt->chroma_weight[i][list][j][0] = get_se_golomb(gb);\n\n                        pwt->chroma_weight[i][list][j][1] = get_se_golomb(gb);\n\n                        if ((int8_t)pwt->chroma_weight[i][list][j][0] != pwt->chroma_weight[i][list][j][0] ||\n\n                            (int8_t)pwt->chroma_weight[i][list][j][1] != pwt->chroma_weight[i][list][j][1])\n\n                            goto out_range_weight;\n\n                        if (pwt->chroma_weight[i][list][j][0] != chroma_def ||\n\n                            pwt->chroma_weight[i][list][j][1] != 0) {\n\n                            pwt->use_weight_chroma        = 1;\n\n                            pwt->chroma_weight_flag[list] = 1;\n\n                        }\n\n                    }\n\n                } else {\n\n                    int j;\n\n                    for (j = 0; j < 2; j++) {\n\n                        pwt->chroma_weight[i][list][j][0] = chroma_def;\n\n                        pwt->chroma_weight[i][list][j][1] = 0;\n\n                    }\n\n                }\n\n            }\n\n\n\n            // for MBAFF\n\n            if (picture_structure == PICT_FRAME) {\n\n                pwt->luma_weight[16 + 2 * i][list][0] = pwt->luma_weight[16 + 2 * i + 1][list][0] = pwt->luma_weight[i][list][0];\n\n                pwt->luma_weight[16 + 2 * i][list][1] = pwt->luma_weight[16 + 2 * i + 1][list][1] = pwt->luma_weight[i][list][1];\n\n                for (j = 0; j < 2; j++) {\n\n                    pwt->chroma_weight[16 + 2 * i][list][j][0] = pwt->chroma_weight[16 + 2 * i + 1][list][j][0] = pwt->chroma_weight[i][list][j][0];\n\n                    pwt->chroma_weight[16 + 2 * i][list][j][1] = pwt->chroma_weight[16 + 2 * i + 1][list][j][1] = pwt->chroma_weight[i][list][j][1];\n\n                }\n\n            }\n\n        }\n\n        if (slice_type_nos != AV_PICTURE_TYPE_B)\n\n            break;\n\n    }\n\n    pwt->use_weight = pwt->use_weight || pwt->use_weight_chroma;\n\n    return 0;\n\nout_range_weight:\n\n    avpriv_request_sample(logctx, \"Out of range weight\\n\");\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 4654, "_split": "valid", "_hash": "a7c657d28d903c0168a89fe3fc358579"}
{"project": "FFmpeg", "commit_id": "9fc88d7e2025e5df0bced8a175978408a1d9eb9a", "target": 1, "func": "static int libschroedinger_encode_init(AVCodecContext *avccontext)\n\n{\n\n    FfmpegSchroEncoderParams* p_schro_params = avccontext->priv_data;\n\n    SchroVideoFormatEnum preset;\n\n\n\n    /* Initialize the libraries that libschroedinger depends on. */\n\n    schro_init();\n\n\n\n    /* Create an encoder object. */\n\n    p_schro_params->encoder = schro_encoder_new();\n\n\n\n    if (!p_schro_params->encoder) {\n\n        av_log(avccontext, AV_LOG_ERROR,\n\n               \"Unrecoverable Error: schro_encoder_new failed. \");\n\n        return -1;\n\n    }\n\n\n\n    /* Initialize the format. */\n\n    preset = ff_get_schro_video_format_preset(avccontext);\n\n    p_schro_params->format =\n\n                    schro_encoder_get_video_format(p_schro_params->encoder);\n\n    schro_video_format_set_std_video_format (p_schro_params->format, preset);\n\n    p_schro_params->format->width = avccontext->width;\n\n    p_schro_params->format->height = avccontext->height;\n\n\n\n    if (SetSchroChromaFormat(avccontext) == -1)\n\n        return -1;\n\n\n\n    if (ff_get_schro_frame_format(p_schro_params->format->chroma_format,\n\n                                  &p_schro_params->frame_format) == -1) {\n\n        av_log (avccontext, AV_LOG_ERROR,\n\n                \"This codec currently supports only planar YUV 4:2:0, 4:2:2\"\n\n                \" and 4:4:4 formats.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    p_schro_params->format->frame_rate_numerator   = avccontext->time_base.den;\n\n    p_schro_params->format->frame_rate_denominator = avccontext->time_base.num;\n\n\n\n    p_schro_params->frame_size = avpicture_get_size(avccontext->pix_fmt,\n\n                                                    avccontext->width,\n\n                                                    avccontext->height);\n\n\n\n    avccontext->coded_frame = &p_schro_params->picture;\n\n\n\n    if (avccontext->gop_size == 0){\n\n        schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                          \"gop_structure\",\n\n                                          SCHRO_ENCODER_GOP_INTRA_ONLY);\n\n\n\n        if (avccontext->coder_type == FF_CODER_TYPE_VLC) {\n\n            schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                              \"enable_noarith\", 1);\n\n        }\n\n    }\n\n    else {\n\n        schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                          \"gop_structure\",\n\n                                          SCHRO_ENCODER_GOP_BIREF);\n\n        avccontext->has_b_frames = 1;\n\n    }\n\n\n\n    /* FIXME - Need to handle SCHRO_ENCODER_RATE_CONTROL_LOW_DELAY. */\n\n    if (avccontext->flags & CODEC_FLAG_QSCALE) {\n\n        if (avccontext->global_quality == 0) {\n\n            /* lossless coding */\n\n            schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                          \"rate_control\",\n\n                                          SCHRO_ENCODER_RATE_CONTROL_LOSSLESS);\n\n        } else {\n\n            int noise_threshold;\n\n            schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                          \"rate_control\",\n\n                          SCHRO_ENCODER_RATE_CONTROL_CONSTANT_NOISE_THRESHOLD);\n\n\n\n            noise_threshold = avccontext->global_quality/FF_QP2LAMBDA;\n\n            if (noise_threshold > 100)\n\n                noise_threshold = 100;\n\n            schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                              \"noise_threshold\",\n\n                                              noise_threshold);\n\n        }\n\n    }\n\n    else {\n\n        schro_encoder_setting_set_double ( p_schro_params->encoder,\n\n                               \"rate_control\",\n\n                               SCHRO_ENCODER_RATE_CONTROL_CONSTANT_BITRATE);\n\n\n\n        schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                          \"bitrate\",\n\n                                          avccontext->bit_rate);\n\n\n\n    }\n\n\n\n    if (avccontext->flags & CODEC_FLAG_INTERLACED_ME) {\n\n        /* All material can be coded as interlaced or progressive\n\n           irrespective of the type of source material. */\n\n        schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                            \"interlaced_coding\", 1);\n\n    }\n\n\n\n    /* FIXME: Signal range hardcoded to 8-bit data until both libschroedinger\n\n     * and libdirac support other bit-depth data. */\n\n    schro_video_format_set_std_signal_range(p_schro_params->format,\n\n                                            SCHRO_SIGNAL_RANGE_8BIT_VIDEO);\n\n\n\n\n\n    /* Hardcode motion vector precision to quarter pixel. */\n\n    schro_encoder_setting_set_double (p_schro_params->encoder,\n\n                                      \"mv_precision\", 2);\n\n\n\n    /* Set the encoder format. */\n\n    schro_encoder_set_video_format(p_schro_params->encoder,\n\n                                   p_schro_params->format);\n\n\n\n    /* Set the debug level. */\n\n    schro_debug_set_level (avccontext->debug);\n\n\n\n    schro_encoder_start (p_schro_params->encoder);\n\n\n\n    /* Initialize the encoded frame queue. */\n\n    ff_dirac_schro_queue_init (&p_schro_params->enc_frame_queue);\n\n    return 0 ;\n\n}\n", "idx": 4665, "_split": "valid", "_hash": "abf2c9af8b6d693aa7c5fef99689488a"}
{"project": "FFmpeg", "commit_id": "102d39088bb9cfb08cc9f78d8e6eca62ed39bded", "target": 1, "func": "int h263_decode_mb(MpegEncContext *s,\n\n                   DCTELEM block[6][64])\n\n{\n\n    int cbpc, cbpy, i, cbp, pred_x, pred_y, mx, my, dquant;\n\n    unsigned int val;\n\n    INT16 *mot_val;\n\n    static INT8 quant_tab[4] = { -1, -2, 1, 2 };\n\n        \n\n    /* Check for GOB Start Code */\n\n    val = show_bits(&s->gb, 16);\n\n    \n\n    if (val == 0) {\n\n        /* We have a GBSC probably with GSTUFF */\n\n#ifdef DEBUG\n\n        unsigned int gn, gfid;\n\n#endif\n\n        //skip_bits(&s->gb, 16); /* Drop the zeros */\n\n        while (get_bits1(&s->gb) == 0); /* Seek the '1' bit */\n\n#ifdef DEBUG\n\n        fprintf(stderr,\"\\nGOB Start Code at MB %d\\n\", \n\n            (s->mb_y * s->mb_width) + s->mb_x);\n\n        gn = get_bits(&s->gb, 5); /* GN */\n\n        gfid = get_bits(&s->gb, 2); /* GFID */\n\n#else\n\n        skip_bits(&s->gb, 5); /* GN */\n\n        skip_bits(&s->gb, 2); /* GFID */\n\n#endif        \n\n        s->qscale = get_bits(&s->gb, 5); /* GQUANT */\n\n#ifdef DEBUG\n\n        fprintf(stderr, \"\\nGN: %u GFID: %u Quant: %u\\n\", gn, gfid, s->qscale);\n\n#endif\n\n    }\n\n    \n\n    if (s->pict_type == P_TYPE) {\n\n        if (get_bits1(&s->gb)) {\n\n            /* skip mb */\n\n            s->mb_intra = 0;\n\n            for(i=0;i<6;i++)\n\n                s->block_last_index[i] = -1;\n\n            s->mv_dir = MV_DIR_FORWARD;\n\n            s->mv_type = MV_TYPE_16X16;\n\n            s->mv[0][0][0] = 0;\n\n            s->mv[0][0][1] = 0;\n\n            s->mb_skiped = 1;\n\n            return 0;\n\n        }\n\n        cbpc = get_vlc(&s->gb, &inter_MCBPC_vlc);\n\n        //fprintf(stderr, \"\\tCBPC: %d\", cbpc);\n\n        if (cbpc < 0)\n\n            return -1;\n\n        \n\n        dquant = cbpc & 8;\n\n        s->mb_intra = ((cbpc & 4) != 0);\n\n    } else {\n\n        cbpc = get_vlc(&s->gb, &intra_MCBPC_vlc);\n\n        if (cbpc < 0)\n\n            return -1;\n\n        dquant = cbpc & 4;\n\n        s->mb_intra = 1;\n\n    }\n\n\n\n    if (!s->mb_intra) {\n\n        cbpy = get_vlc(&s->gb, &cbpy_vlc);\n\n        cbp = (cbpc & 3) | ((cbpy ^ 0xf) << 2);\n\n        if (dquant) {\n\n            s->qscale += quant_tab[get_bits(&s->gb, 2)];\n\n            if (s->qscale < 1)\n\n                s->qscale = 1;\n\n            else if (s->qscale > 31)\n\n                s->qscale = 31;\n\n        }\n\n        s->mv_dir = MV_DIR_FORWARD;\n\n        if ((cbpc & 16) == 0) {\n\n            /* 16x16 motion prediction */\n\n            s->mv_type = MV_TYPE_16X16;\n\n            h263_pred_motion(s, 0, &pred_x, &pred_y);\n\n            if (s->umvplus_dec)\n\n               mx = h263p_decode_umotion(s, pred_x);\n\n            else\n\n               mx = h263_decode_motion(s, pred_x);\n\n            if (mx >= 0xffff)\n\n                return -1;\n\n            \n\n            if (s->umvplus_dec)\n\n               my = h263p_decode_umotion(s, pred_y);\n\n            else    \n\n               my = h263_decode_motion(s, pred_y);\n\n            if (my >= 0xffff)\n\n                return -1;\n\n            s->mv[0][0][0] = mx;\n\n            s->mv[0][0][1] = my;\n\n            if (s->umvplus_dec && (mx - pred_x) == 1 && (my - pred_y) == 1)\n\n               skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n\n                           \n\n        } else {\n\n            s->mv_type = MV_TYPE_8X8;\n\n            for(i=0;i<4;i++) {\n\n                mot_val = h263_pred_motion(s, i, &pred_x, &pred_y);\n\n                if (s->umvplus_dec)\n\n                  mx = h263p_decode_umotion(s, pred_x);\n\n                else\n\n                  mx = h263_decode_motion(s, pred_x);\n\n                if (mx >= 0xffff)\n\n                    return -1;\n\n                \n\n                if (s->umvplus_dec)\n\n                  my = h263p_decode_umotion(s, pred_y);\n\n                else    \n\n                  my = h263_decode_motion(s, pred_y);\n\n                if (my >= 0xffff)\n\n                    return -1;\n\n                s->mv[0][i][0] = mx;\n\n                s->mv[0][i][1] = my;\n\n                if (s->umvplus_dec && (mx - pred_x) == 1 && (my - pred_y) == 1)\n\n                  skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n\n                mot_val[0] = mx;\n\n                mot_val[1] = my;\n\n            }\n\n        }\n\n    } else {\n\n        s->ac_pred = 0;\n\n\t    if (s->h263_pred) {\n\n            s->ac_pred = get_bits1(&s->gb);\n\n        }\n\n        cbpy = get_vlc(&s->gb, &cbpy_vlc);\n\n        cbp = (cbpc & 3) | (cbpy << 2);\n\n        if (dquant) {\n\n            s->qscale += quant_tab[get_bits(&s->gb, 2)];\n\n            if (s->qscale < 1)\n\n                s->qscale = 1;\n\n            else if (s->qscale > 31)\n\n                s->qscale = 31;\n\n        }\n\n    }\n\n\n\n    /* decode each block */\n\n    if (s->h263_pred) {\n\n\tfor (i = 0; i < 6; i++) {\n\n\t    if (mpeg4_decode_block(s, block[i], i, (cbp >> (5 - i)) & 1) < 0)\n\n                return -1;\n\n\t}\n\n    } else {\n\n\tfor (i = 0; i < 6; i++) {\n\n\t    if (h263_decode_block(s, block[i], i, (cbp >> (5 - i)) & 1) < 0)\n\n                return -1;\n\n\t}\n\n    }\n\n    return 0;\n\n}\n", "idx": 4674, "_split": "valid", "_hash": "93d7f843b1ce22bef53e6eb83ea045cd"}
{"project": "FFmpeg", "commit_id": "b1b0baa3d6a30942b258dddfdd04b4b24c713879", "target": 0, "func": "static void kempf_restore_buf(const uint8_t *src, int len,\n\n                              uint8_t *dst, int stride,\n\n                              const uint8_t *jpeg_tile, int tile_stride,\n\n                              int width, int height,\n\n                              const uint8_t *pal, int npal, int tidx)\n\n{\n\n    GetBitContext gb;\n\n    int i, j, nb, col;\n\n\n\n    init_get_bits8(&gb, src, len);\n\n\n\n    if (npal <= 2)       nb = 1;\n\n    else if (npal <= 4)  nb = 2;\n\n    else if (npal <= 16) nb = 4;\n\n    else                 nb = 8;\n\n\n\n    for (j = 0; j < height; j++, dst += stride, jpeg_tile += tile_stride) {\n\n        if (get_bits(&gb, 8))\n\n            continue;\n\n        for (i = 0; i < width; i++) {\n\n            col = get_bits(&gb, nb);\n\n            if (col != tidx)\n\n                memcpy(dst + i * 3, pal + col * 3, 3);\n\n            else\n\n                memcpy(dst + i * 3, jpeg_tile + i * 3, 3);\n\n        }\n\n    }\n\n}\n", "idx": 4679, "_split": "valid", "_hash": "dab7c6ae8eafb606a0010c61c9dd77bc"}
{"project": "FFmpeg", "commit_id": "33d69a90085d30af8a292d9364b835a26565d6b9", "target": 0, "func": "static JavaVM *get_java_vm(const char *name, void *log_ctx)\n\n{\n\n    JavaVM *vm = NULL;\n\n    jsize nb_vm = 0;\n\n\n\n    void *handle = NULL;\n\n    jint (*get_created_java_vms) (JavaVM ** vmBuf, jsize bufLen, jsize *nVMs) = NULL;\n\n\n\n    handle = dlopen(name, RTLD_LOCAL);\n\n    if (!handle) {\n\n        return NULL;\n\n    }\n\n\n\n    get_created_java_vms = (jint (*)(JavaVM **, jsize, jsize *)) dlsym(handle, \"JNI_GetCreatedJavaVMs\");\n\n    if (!get_created_java_vms) {\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Could not find JNI_GetCreatedJavaVMs symbol in library '%s'\\n\", name);\n\n        goto done;\n\n    }\n\n\n\n    if (get_created_java_vms(&vm, 1, &nb_vm) != JNI_OK) {\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Could not get created Java virtual machines\\n\");\n\n        goto done;\n\n    }\n\n\n\ndone:\n\n    if (handle) {\n\n        dlclose(handle);\n\n    }\n\n\n\n    return vm;\n\n}\n", "idx": 4686, "_split": "valid", "_hash": "8450938e4a52444e212be327808016c7"}
{"project": "FFmpeg", "commit_id": "617c461625daa5d569345df55e6cedc4b6100ec1", "target": 0, "func": "static int mpegts_push_data(MpegTSFilter *filter,\n\n                            const uint8_t *buf, int buf_size, int is_start,\n\n                            int64_t pos)\n\n{\n\n    PESContext *pes = filter->u.pes_filter.opaque;\n\n    MpegTSContext *ts = pes->ts;\n\n    const uint8_t *p;\n\n    int len, code;\n\n\n\n    if(!ts->pkt)\n\n        return 0;\n\n\n\n    if (is_start) {\n\n        if (pes->state == MPEGTS_PAYLOAD && pes->data_index > 0) {\n\n            new_pes_packet(pes, ts->pkt);\n\n            ts->stop_parse = 1;\n\n        }\n\n        pes->state = MPEGTS_HEADER;\n\n        pes->data_index = 0;\n\n        pes->ts_packet_pos = pos;\n\n    }\n\n    p = buf;\n\n    while (buf_size > 0) {\n\n        switch(pes->state) {\n\n        case MPEGTS_HEADER:\n\n            len = PES_START_SIZE - pes->data_index;\n\n            if (len > buf_size)\n\n                len = buf_size;\n\n            memcpy(pes->header + pes->data_index, p, len);\n\n            pes->data_index += len;\n\n            p += len;\n\n            buf_size -= len;\n\n            if (pes->data_index == PES_START_SIZE) {\n\n                /* we got all the PES or section header. We can now\n\n                   decide */\n\n#if 0\n\n                av_hex_dump_log(pes->stream, AV_LOG_DEBUG, pes->header, pes->data_index);\n\n#endif\n\n                if (pes->header[0] == 0x00 && pes->header[1] == 0x00 &&\n\n                    pes->header[2] == 0x01) {\n\n                    /* it must be an mpeg2 PES stream */\n\n                    code = pes->header[3] | 0x100;\n\n                    dprintf(pes->stream, \"pid=%x pes_code=%#x\\n\", pes->pid, code);\n\n\n\n                    if ((pes->st && pes->st->discard == AVDISCARD_ALL) ||\n\n                        code == 0x1be) /* padding_stream */\n\n                        goto skip;\n\n\n\n                    /* stream not present in PMT */\n\n                    if (!pes->st)\n\n                        pes->st = new_pes_av_stream(pes, 0, code);\n\n                    if (!pes->st)\n\n                        return AVERROR(ENOMEM);\n\n\n\n                    pes->total_size = AV_RB16(pes->header + 4);\n\n                    /* NOTE: a zero total size means the PES size is\n\n                       unbounded */\n\n                    if (!pes->total_size)\n\n                        pes->total_size = MAX_PES_PAYLOAD;\n\n\n\n                    /* allocate pes buffer */\n\n                    pes->buffer = av_malloc(pes->total_size+FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!pes->buffer)\n\n                        return AVERROR(ENOMEM);\n\n\n\n                    if (code != 0x1bc && code != 0x1bf && /* program_stream_map, private_stream_2 */\n\n                        code != 0x1f0 && code != 0x1f1 && /* ECM, EMM */\n\n                        code != 0x1ff && code != 0x1f2 && /* program_stream_directory, DSMCC_stream */\n\n                        code != 0x1f8) {                  /* ITU-T Rec. H.222.1 type E stream */\n\n                        pes->state = MPEGTS_PESHEADER_FILL;\n\n                        pes->pes_header_size = pes->header[8] + 9;\n\n                    } else {\n\n                        pes->state = MPEGTS_PAYLOAD;\n\n                        pes->data_index = 0;\n\n                    }\n\n                } else {\n\n                    /* otherwise, it should be a table */\n\n                    /* skip packet */\n\n                skip:\n\n                    pes->state = MPEGTS_SKIP;\n\n                    continue;\n\n                }\n\n            }\n\n            break;\n\n            /**********************************************/\n\n            /* PES packing parsing */\n\n        case MPEGTS_PESHEADER_FILL:\n\n            len = pes->pes_header_size - pes->data_index;\n\n            if (len < 0)\n\n                return -1;\n\n            if (len > buf_size)\n\n                len = buf_size;\n\n            memcpy(pes->header + pes->data_index, p, len);\n\n            pes->data_index += len;\n\n            p += len;\n\n            buf_size -= len;\n\n            if (pes->data_index == pes->pes_header_size) {\n\n                const uint8_t *r;\n\n                unsigned int flags;\n\n\n\n                flags = pes->header[7];\n\n                r = pes->header + 9;\n\n                pes->pts = AV_NOPTS_VALUE;\n\n                pes->dts = AV_NOPTS_VALUE;\n\n                if ((flags & 0xc0) == 0x80) {\n\n                    pes->dts = pes->pts = get_pts(r);\n\n                    r += 5;\n\n                } else if ((flags & 0xc0) == 0xc0) {\n\n                    pes->pts = get_pts(r);\n\n                    r += 5;\n\n                    pes->dts = get_pts(r);\n\n                    r += 5;\n\n                }\n\n\n\n                /* we got the full header. We parse it and get the payload */\n\n                pes->state = MPEGTS_PAYLOAD;\n\n                pes->data_index = 0;\n\n            }\n\n            break;\n\n        case MPEGTS_PAYLOAD:\n\n            if (buf_size > 0) {\n\n                if (pes->data_index+buf_size > pes->total_size) {\n\n                    new_pes_packet(pes, ts->pkt);\n\n                    pes->total_size = MAX_PES_PAYLOAD;\n\n                    pes->buffer = av_malloc(pes->total_size+FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!pes->buffer)\n\n                        return AVERROR(ENOMEM);\n\n                    ts->stop_parse = 1;\n\n                }\n\n                memcpy(pes->buffer+pes->data_index, p, buf_size);\n\n                pes->data_index += buf_size;\n\n            }\n\n            buf_size = 0;\n\n            break;\n\n        case MPEGTS_SKIP:\n\n            buf_size = 0;\n\n            break;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 4701, "_split": "valid", "_hash": "b61c8d4365f86e1199cd035882aac264"}
{"project": "FFmpeg", "commit_id": "cde9e7800128f5466d97279918e1d20fc250a33b", "target": 0, "func": "static av_always_inline void MPV_decode_mb_internal(MpegEncContext *s, DCTELEM block[12][64], int lowres_flag)\n\n{\n\n    int mb_x, mb_y;\n\n    const int mb_xy = s->mb_y * s->mb_stride + s->mb_x;\n\n#ifdef HAVE_XVMC\n\n    if(s->avctx->xvmc_acceleration){\n\n        XVMC_decode_mb(s);//xvmc uses pblocks\n\n        return;\n\n    }\n\n#endif\n\n\n\n    mb_x = s->mb_x;\n\n    mb_y = s->mb_y;\n\n\n\n    if(s->avctx->debug&FF_DEBUG_DCT_COEFF) {\n\n       /* save DCT coefficients */\n\n       int i,j;\n\n       DCTELEM *dct = &s->current_picture.dct_coeff[mb_xy*64*6];\n\n       for(i=0; i<6; i++)\n\n           for(j=0; j<64; j++)\n\n               *dct++ = block[i][s->dsp.idct_permutation[j]];\n\n    }\n\n\n\n    s->current_picture.qscale_table[mb_xy]= s->qscale;\n\n\n\n    /* update DC predictors for P macroblocks */\n\n    if (!s->mb_intra) {\n\n        if (s->h263_pred || s->h263_aic) {\n\n            if(s->mbintra_table[mb_xy])\n\n                ff_clean_intra_table_entries(s);\n\n        } else {\n\n            s->last_dc[0] =\n\n            s->last_dc[1] =\n\n            s->last_dc[2] = 128 << s->intra_dc_precision;\n\n        }\n\n    }\n\n    else if (s->h263_pred || s->h263_aic)\n\n        s->mbintra_table[mb_xy]=1;\n\n\n\n    if ((s->flags&CODEC_FLAG_PSNR) || !(s->encoding && (s->intra_only || s->pict_type==B_TYPE) && s->avctx->mb_decision != FF_MB_DECISION_RD)) { //FIXME precalc\n\n        uint8_t *dest_y, *dest_cb, *dest_cr;\n\n        int dct_linesize, dct_offset;\n\n        op_pixels_func (*op_pix)[4];\n\n        qpel_mc_func (*op_qpix)[16];\n\n        const int linesize= s->current_picture.linesize[0]; //not s->linesize as this would be wrong for field pics\n\n        const int uvlinesize= s->current_picture.linesize[1];\n\n        const int readable= s->pict_type != B_TYPE || s->encoding || s->avctx->draw_horiz_band || lowres_flag;\n\n        const int block_size= lowres_flag ? 8>>s->avctx->lowres : 8;\n\n\n\n        /* avoid copy if macroblock skipped in last frame too */\n\n        /* skip only during decoding as we might trash the buffers during encoding a bit */\n\n        if(!s->encoding){\n\n            uint8_t *mbskip_ptr = &s->mbskip_table[mb_xy];\n\n            const int age= s->current_picture.age;\n\n\n\n            assert(age);\n\n\n\n            if (s->mb_skipped) {\n\n                s->mb_skipped= 0;\n\n                assert(s->pict_type!=I_TYPE);\n\n\n\n                (*mbskip_ptr) ++; /* indicate that this time we skipped it */\n\n                if(*mbskip_ptr >99) *mbskip_ptr= 99;\n\n\n\n                /* if previous was skipped too, then nothing to do !  */\n\n                if (*mbskip_ptr >= age && s->current_picture.reference){\n\n                    return;\n\n                }\n\n            } else if(!s->current_picture.reference){\n\n                (*mbskip_ptr) ++; /* increase counter so the age can be compared cleanly */\n\n                if(*mbskip_ptr >99) *mbskip_ptr= 99;\n\n            } else{\n\n                *mbskip_ptr = 0; /* not skipped */\n\n            }\n\n        }\n\n\n\n        dct_linesize = linesize << s->interlaced_dct;\n\n        dct_offset =(s->interlaced_dct)? linesize : linesize*block_size;\n\n\n\n        if(readable){\n\n            dest_y=  s->dest[0];\n\n            dest_cb= s->dest[1];\n\n            dest_cr= s->dest[2];\n\n        }else{\n\n            dest_y = s->b_scratchpad;\n\n            dest_cb= s->b_scratchpad+16*linesize;\n\n            dest_cr= s->b_scratchpad+32*linesize;\n\n        }\n\n\n\n        if (!s->mb_intra) {\n\n            /* motion handling */\n\n            /* decoding or more than one mb_type (MC was already done otherwise) */\n\n            if(!s->encoding){\n\n                if(lowres_flag){\n\n                    h264_chroma_mc_func *op_pix = s->dsp.put_h264_chroma_pixels_tab;\n\n\n\n                    if (s->mv_dir & MV_DIR_FORWARD) {\n\n                        MPV_motion_lowres(s, dest_y, dest_cb, dest_cr, 0, s->last_picture.data, op_pix);\n\n                        op_pix = s->dsp.avg_h264_chroma_pixels_tab;\n\n                    }\n\n                    if (s->mv_dir & MV_DIR_BACKWARD) {\n\n                        MPV_motion_lowres(s, dest_y, dest_cb, dest_cr, 1, s->next_picture.data, op_pix);\n\n                    }\n\n                }else{\n\n                    op_qpix= s->me.qpel_put;\n\n                    if ((!s->no_rounding) || s->pict_type==B_TYPE){\n\n                        op_pix = s->dsp.put_pixels_tab;\n\n                    }else{\n\n                        op_pix = s->dsp.put_no_rnd_pixels_tab;\n\n                    }\n\n                    if (s->mv_dir & MV_DIR_FORWARD) {\n\n                        MPV_motion(s, dest_y, dest_cb, dest_cr, 0, s->last_picture.data, op_pix, op_qpix);\n\n                        op_pix = s->dsp.avg_pixels_tab;\n\n                        op_qpix= s->me.qpel_avg;\n\n                    }\n\n                    if (s->mv_dir & MV_DIR_BACKWARD) {\n\n                        MPV_motion(s, dest_y, dest_cb, dest_cr, 1, s->next_picture.data, op_pix, op_qpix);\n\n                    }\n\n                }\n\n            }\n\n\n\n            /* skip dequant / idct if we are really late ;) */\n\n            if(s->hurry_up>1) goto skip_idct;\n\n            if(s->avctx->skip_idct){\n\n                if(  (s->avctx->skip_idct >= AVDISCARD_NONREF && s->pict_type == B_TYPE)\n\n                   ||(s->avctx->skip_idct >= AVDISCARD_NONKEY && s->pict_type != I_TYPE)\n\n                   || s->avctx->skip_idct >= AVDISCARD_ALL)\n\n                    goto skip_idct;\n\n            }\n\n\n\n            /* add dct residue */\n\n            if(s->encoding || !(   s->h263_msmpeg4 || s->codec_id==CODEC_ID_MPEG1VIDEO || s->codec_id==CODEC_ID_MPEG2VIDEO\n\n                                || (s->codec_id==CODEC_ID_MPEG4 && !s->mpeg_quant))){\n\n                add_dequant_dct(s, block[0], 0, dest_y                          , dct_linesize, s->qscale);\n\n                add_dequant_dct(s, block[1], 1, dest_y              + block_size, dct_linesize, s->qscale);\n\n                add_dequant_dct(s, block[2], 2, dest_y + dct_offset             , dct_linesize, s->qscale);\n\n                add_dequant_dct(s, block[3], 3, dest_y + dct_offset + block_size, dct_linesize, s->qscale);\n\n\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    if (s->chroma_y_shift){\n\n                        add_dequant_dct(s, block[4], 4, dest_cb, uvlinesize, s->chroma_qscale);\n\n                        add_dequant_dct(s, block[5], 5, dest_cr, uvlinesize, s->chroma_qscale);\n\n                    }else{\n\n                        dct_linesize >>= 1;\n\n                        dct_offset >>=1;\n\n                        add_dequant_dct(s, block[4], 4, dest_cb,              dct_linesize, s->chroma_qscale);\n\n                        add_dequant_dct(s, block[5], 5, dest_cr,              dct_linesize, s->chroma_qscale);\n\n                        add_dequant_dct(s, block[6], 6, dest_cb + dct_offset, dct_linesize, s->chroma_qscale);\n\n                        add_dequant_dct(s, block[7], 7, dest_cr + dct_offset, dct_linesize, s->chroma_qscale);\n\n                    }\n\n                }\n\n            } else if(s->codec_id != CODEC_ID_WMV2){\n\n                add_dct(s, block[0], 0, dest_y                          , dct_linesize);\n\n                add_dct(s, block[1], 1, dest_y              + block_size, dct_linesize);\n\n                add_dct(s, block[2], 2, dest_y + dct_offset             , dct_linesize);\n\n                add_dct(s, block[3], 3, dest_y + dct_offset + block_size, dct_linesize);\n\n\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    if(s->chroma_y_shift){//Chroma420\n\n                        add_dct(s, block[4], 4, dest_cb, uvlinesize);\n\n                        add_dct(s, block[5], 5, dest_cr, uvlinesize);\n\n                    }else{\n\n                        //chroma422\n\n                        dct_linesize = uvlinesize << s->interlaced_dct;\n\n                        dct_offset =(s->interlaced_dct)? uvlinesize : uvlinesize*8;\n\n\n\n                        add_dct(s, block[4], 4, dest_cb, dct_linesize);\n\n                        add_dct(s, block[5], 5, dest_cr, dct_linesize);\n\n                        add_dct(s, block[6], 6, dest_cb+dct_offset, dct_linesize);\n\n                        add_dct(s, block[7], 7, dest_cr+dct_offset, dct_linesize);\n\n                        if(!s->chroma_x_shift){//Chroma444\n\n                            add_dct(s, block[8], 8, dest_cb+8, dct_linesize);\n\n                            add_dct(s, block[9], 9, dest_cr+8, dct_linesize);\n\n                            add_dct(s, block[10], 10, dest_cb+8+dct_offset, dct_linesize);\n\n                            add_dct(s, block[11], 11, dest_cr+8+dct_offset, dct_linesize);\n\n                        }\n\n                    }\n\n                }//fi gray\n\n            }\n\n            else if (ENABLE_WMV2) {\n\n                ff_wmv2_add_mb(s, block, dest_y, dest_cb, dest_cr);\n\n            }\n\n        } else {\n\n            /* dct only in intra block */\n\n            if(s->encoding || !(s->codec_id==CODEC_ID_MPEG1VIDEO || s->codec_id==CODEC_ID_MPEG2VIDEO)){\n\n                put_dct(s, block[0], 0, dest_y                          , dct_linesize, s->qscale);\n\n                put_dct(s, block[1], 1, dest_y              + block_size, dct_linesize, s->qscale);\n\n                put_dct(s, block[2], 2, dest_y + dct_offset             , dct_linesize, s->qscale);\n\n                put_dct(s, block[3], 3, dest_y + dct_offset + block_size, dct_linesize, s->qscale);\n\n\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    if(s->chroma_y_shift){\n\n                        put_dct(s, block[4], 4, dest_cb, uvlinesize, s->chroma_qscale);\n\n                        put_dct(s, block[5], 5, dest_cr, uvlinesize, s->chroma_qscale);\n\n                    }else{\n\n                        dct_offset >>=1;\n\n                        dct_linesize >>=1;\n\n                        put_dct(s, block[4], 4, dest_cb,              dct_linesize, s->chroma_qscale);\n\n                        put_dct(s, block[5], 5, dest_cr,              dct_linesize, s->chroma_qscale);\n\n                        put_dct(s, block[6], 6, dest_cb + dct_offset, dct_linesize, s->chroma_qscale);\n\n                        put_dct(s, block[7], 7, dest_cr + dct_offset, dct_linesize, s->chroma_qscale);\n\n                    }\n\n                }\n\n            }else{\n\n                s->dsp.idct_put(dest_y                          , dct_linesize, block[0]);\n\n                s->dsp.idct_put(dest_y              + block_size, dct_linesize, block[1]);\n\n                s->dsp.idct_put(dest_y + dct_offset             , dct_linesize, block[2]);\n\n                s->dsp.idct_put(dest_y + dct_offset + block_size, dct_linesize, block[3]);\n\n\n\n                if(!(s->flags&CODEC_FLAG_GRAY)){\n\n                    if(s->chroma_y_shift){\n\n                        s->dsp.idct_put(dest_cb, uvlinesize, block[4]);\n\n                        s->dsp.idct_put(dest_cr, uvlinesize, block[5]);\n\n                    }else{\n\n\n\n                        dct_linesize = uvlinesize << s->interlaced_dct;\n\n                        dct_offset =(s->interlaced_dct)? uvlinesize : uvlinesize*8;\n\n\n\n                        s->dsp.idct_put(dest_cb,              dct_linesize, block[4]);\n\n                        s->dsp.idct_put(dest_cr,              dct_linesize, block[5]);\n\n                        s->dsp.idct_put(dest_cb + dct_offset, dct_linesize, block[6]);\n\n                        s->dsp.idct_put(dest_cr + dct_offset, dct_linesize, block[7]);\n\n                        if(!s->chroma_x_shift){//Chroma444\n\n                            s->dsp.idct_put(dest_cb + 8,              dct_linesize, block[8]);\n\n                            s->dsp.idct_put(dest_cr + 8,              dct_linesize, block[9]);\n\n                            s->dsp.idct_put(dest_cb + 8 + dct_offset, dct_linesize, block[10]);\n\n                            s->dsp.idct_put(dest_cr + 8 + dct_offset, dct_linesize, block[11]);\n\n                        }\n\n                    }\n\n                }//gray\n\n            }\n\n        }\n\nskip_idct:\n\n        if(!readable){\n\n            s->dsp.put_pixels_tab[0][0](s->dest[0], dest_y ,   linesize,16);\n\n            s->dsp.put_pixels_tab[s->chroma_x_shift][0](s->dest[1], dest_cb, uvlinesize,16 >> s->chroma_y_shift);\n\n            s->dsp.put_pixels_tab[s->chroma_x_shift][0](s->dest[2], dest_cr, uvlinesize,16 >> s->chroma_y_shift);\n\n        }\n\n    }\n\n}\n", "idx": 4729, "_split": "valid", "_hash": "96ad2f96a408cf7ddbde44f78b0cce65"}
{"project": "FFmpeg", "commit_id": "1bc1cfdddf7ab8ef50d0fc888808d6b609eb5d8d", "target": 1, "func": "static int compute_send_delay(HTTPContext *c)\n\n{\n\n    int datarate = 8 * get_longterm_datarate(&c->datarate, c->data_count); \n\n\n\n    if (datarate > c->stream->bandwidth * 2000) {\n\n        return 1000;\n\n    }\n\n    return 0;\n\n}\n", "idx": 4734, "_split": "valid", "_hash": "e99b0d915f8ec669ec660a43bbb5bc0f"}
{"project": "FFmpeg", "commit_id": "33f10546ec012ad4e1054b57317885cded7e953e", "target": 1, "func": "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size, n_slices = 0, i, ret;\n    VC1Context *v = avctx->priv_data;\n    MpegEncContext *s = &v->s;\n    AVFrame *pict = data;\n    uint8_t *buf2 = NULL;\n    const uint8_t *buf_start = buf;\n    int mb_height, n_slices1;\n    struct {\n        uint8_t *buf;\n        GetBitContext gb;\n        int mby_start;\n    } *slices = NULL, *tmp;\n    /* no supplementary picture */\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n        /* special case for last picture */\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->next_picture_ptr->f)) < 0)\n                return ret;\n            s->next_picture_ptr = NULL;\n            *got_frame = 1;\n        return 0;\n    //for advanced profile we may need to parse and unescape data\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n        int buf_size2 = 0;\n        buf2 = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n            const uint8_t *start, *end, *next;\n            int size;\n            next = buf;\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n                next = find_next_marker(start + 4, end);\n                size = next - start - 4;\n                if (size <= 0) continue;\n                switch (AV_RB32(start)) {\n                case VC1_CODE_FRAME:\n                    if (avctx->hwaccel)\n                        buf_start = start;\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    break;\n                case VC1_CODE_FIELD: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    /* assuming that the field marker is at the exact middle,\n                       hope it's correct */\n                    slices[n_slices].mby_start = s->mb_height >> 1;\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n                    n_slices++;\n                    break;\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n                    break;\n                case VC1_CODE_SLICE: {\n                    int buf_size3;\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                    if (!tmp)\n                    slices = tmp;\n                    slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                    if (!slices[n_slices].buf)\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n                                                    slices[n_slices].buf);\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                                  buf_size3 << 3);\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n                    n_slices++;\n                    break;\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n            const uint8_t *divider;\n            int buf_size3;\n            divider = find_next_marker(buf, buf + buf_size);\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n            } else { // found field marker, unescape second field\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n                if (!tmp)\n                slices = tmp;\n                slices[n_slices].buf = av_mallocz(buf_size + AV_INPUT_BUFFER_PADDING_SIZE);\n                if (!slices[n_slices].buf)\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n                              buf_size3 << 3);\n                slices[n_slices].mby_start = s->mb_height >> 1;\n                n_slices1 = n_slices - 1;\n                n_slices++;\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n        } else {\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n    } else\n        init_get_bits(&s->gb, buf, buf_size*8);\n    if (v->res_sprite) {\n        v->new_sprite  = !get_bits1(&s->gb);\n        v->two_sprites =  get_bits1(&s->gb);\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n           we're using the sprite compositor. These are intentionally kept separate\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n           the vc1 one for WVP2 */\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n            if (v->new_sprite) {\n                // switch AVCodecContext parameters to those of the sprites\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n                avctx->height = avctx->coded_height = v->sprite_height;\n            } else {\n                goto image;\n    if (s->context_initialized &&\n        (s->width  != avctx->coded_width ||\n         s->height != avctx->coded_height)) {\n        ff_vc1_decode_end(avctx);\n    if (!s->context_initialized) {\n        if (ff_msmpeg4_decode_init(avctx) < 0)\n        if (ff_vc1_decode_init_alloc_tables(v) < 0) {\n            ff_mpv_common_end(s);\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n        if (v->profile == PROFILE_ADVANCED) {\n            s->h_edge_pos = avctx->coded_width;\n            s->v_edge_pos = avctx->coded_height;\n    // do parse frame header\n    v->pic_header_flag = 0;\n    v->first_pic_header_flag = 1;\n    if (v->profile < PROFILE_ADVANCED) {\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n    } else {\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n    v->first_pic_header_flag = 0;\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n    // for skipping the frame\n    s->current_picture.f->pict_type = s->pict_type;\n    s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n    /* skip B-frames if we don't have reference frames */\n    if (!s->last_picture_ptr && (s->pict_type == AV_PICTURE_TYPE_B || s->droppable)) {\n        goto end;\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n         avctx->skip_frame >= AVDISCARD_ALL) {\n        goto end;\n    if (s->next_p_frame_damaged) {\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n            goto end;\n        else\n            s->next_p_frame_damaged = 0;\n    if (ff_mpv_frame_start(s, avctx) < 0) {\n    // process pulldown flags\n    s->current_picture_ptr->f->repeat_pict = 0;\n    // Pulldown flags are only valid when 'broadcast' has been set.\n    // So ticks_per_frame will be 2\n    if (v->rff) {\n        // repeat field\n        s->current_picture_ptr->f->repeat_pict = 1;\n    } else if (v->rptfrm) {\n        // repeat frames\n        s->current_picture_ptr->f->repeat_pict = v->rptfrm * 2;\n    s->me.qpel_put = s->qdsp.put_qpel_pixels_tab;\n    s->me.qpel_avg = s->qdsp.avg_qpel_pixels_tab;\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->start_frame(avctx, buf, buf_size) < 0)\n        if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n    } else {\n        int header_ret = 0;\n        ff_mpeg_er_frame_start(s);\n        v->bits = buf_size * 8;\n        v->end_mb_x = s->mb_width;\n        if (v->field_mode) {\n            s->current_picture.f->linesize[0] <<= 1;\n            s->current_picture.f->linesize[1] <<= 1;\n            s->current_picture.f->linesize[2] <<= 1;\n            s->linesize                      <<= 1;\n            s->uvlinesize                    <<= 1;\n        mb_height = s->mb_height >> v->field_mode;\n        if (!mb_height) {\n            av_log(v->s.avctx, AV_LOG_ERROR, \"Invalid mb_height.\\n\");\n        for (i = 0; i <= n_slices; i++) {\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n                if (v->field_mode <= 0) {\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n                           \"picture boundary (%d >= %d)\\n\", i,\n                           slices[i - 1].mby_start, mb_height);\n                    continue;\n                v->second_field = 1;\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n            } else {\n                v->second_field = 0;\n                v->blocks_off   = 0;\n                v->mb_off       = 0;\n            if (i) {\n                v->pic_header_flag = 0;\n                if (v->field_mode && i == n_slices1 + 2) {\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                        continue;\n                } else if (get_bits1(&s->gb)) {\n                    v->pic_header_flag = 1;\n                    if ((header_ret = ff_vc1_parse_frame_header_adv(v, &s->gb)) < 0) {\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n                        continue;\n            if (header_ret < 0)\n                continue;\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n            if (!v->field_mode || v->second_field)\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            else\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n            ff_vc1_decode_blocks(v);\n            if (i != n_slices)\n                s->gb = slices[i].gb;\n        if (v->field_mode) {\n            v->second_field = 0;\n            s->current_picture.f->linesize[0] >>= 1;\n            s->current_picture.f->linesize[1] >>= 1;\n            s->current_picture.f->linesize[2] >>= 1;\n            s->linesize                      >>= 1;\n            s->uvlinesize                    >>= 1;\n            if (v->s.pict_type != AV_PICTURE_TYPE_BI && v->s.pict_type != AV_PICTURE_TYPE_B) {\n                FFSWAP(uint8_t *, v->mv_f_next[0], v->mv_f[0]);\n                FFSWAP(uint8_t *, v->mv_f_next[1], v->mv_f[1]);\n        ff_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n//      return -1;\n        if (!v->field_mode)\n            ff_er_frame_end(&s->er);\n    ff_mpv_frame_end(s);\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\nimage:\n        avctx->width  = avctx->coded_width  = v->output_width;\n        avctx->height = avctx->coded_height = v->output_height;\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n            goto end;\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n        if (vc1_decode_sprites(v, &s->gb))\n#endif\n        if ((ret = av_frame_ref(pict, v->sprite_output_frame)) < 0)\n        *got_frame = 1;\n    } else {\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n            if ((ret = av_frame_ref(pict, s->current_picture_ptr->f)) < 0)\n            ff_print_debug_info(s, s->current_picture_ptr);\n            *got_frame = 1;\n        } else if (s->last_picture_ptr) {\n            if ((ret = av_frame_ref(pict, s->last_picture_ptr->f)) < 0)\n            ff_print_debug_info(s, s->last_picture_ptr);\n            *got_frame = 1;\nend:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return buf_size;\nerr:\n    av_free(buf2);\n    for (i = 0; i < n_slices; i++)\n        av_free(slices[i].buf);\n    av_free(slices);\n    return -1;", "idx": 4816, "_split": "valid", "_hash": "211ac1f52d34a5bf04ec4a35716b355e"}
{"project": "FFmpeg", "commit_id": "5e55c7e1bcb767e6af17c29f6aaebff4d6fd0703", "target": 0, "func": "void ff_hevc_hls_filter(HEVCContext *s, int x, int y, int ctb_size)\n\n{\n\n    deblocking_filter_CTB(s, x, y);\n\n    if (s->sps->sao_enabled) {\n\n        int x_end = x >= s->sps->width  - ctb_size;\n\n        int y_end = y >= s->sps->height - ctb_size;\n\n        if (y && x)\n\n            sao_filter_CTB(s, x - ctb_size, y - ctb_size);\n\n        if (x && y_end)\n\n            sao_filter_CTB(s, x - ctb_size, y);\n\n        if (y && x_end) {\n\n            sao_filter_CTB(s, x, y - ctb_size);\n\n            if (s->threads_type & FF_THREAD_FRAME )\n\n                ff_thread_report_progress(&s->ref->tf, y - ctb_size, 0);\n\n        }\n\n        if (x_end && y_end) {\n\n            sao_filter_CTB(s, x , y);\n\n            if (s->threads_type & FF_THREAD_FRAME )\n\n                ff_thread_report_progress(&s->ref->tf, y, 0);\n\n        }\n\n    } else {\n\n        if (y && x >= s->sps->width - ctb_size)\n\n            if (s->threads_type & FF_THREAD_FRAME )\n\n                ff_thread_report_progress(&s->ref->tf, y, 0);\n\n    }\n\n}\n", "idx": 4848, "_split": "valid", "_hash": "75e87bc45485147b2275b0ff0ae1f9bb"}
{"project": "FFmpeg", "commit_id": "bf2bc926f04dcdde0a22c137d08a0bb546e0179e", "target": 1, "func": "static int advanced_decode_picture_primary_header(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    static const int type_table[4] = { P_TYPE, B_TYPE, I_TYPE, BI_TYPE };\n\n    int type, i;\n\n\n\n    if (v->interlace)\n\n    {\n\n        v->fcm = get_bits(gb, 1);\n\n        if (v->fcm) v->fcm = 2+get_bits(gb, 1);\n\n    }\n\n\n\n    type = get_prefix(gb, 0, 4);\n\n    if (type > 4 || type < 0) return FRAME_SKIPED;\n\n    v->s.pict_type = type_table[type];\n\n    av_log(v->s.avctx, AV_LOG_INFO, \"AP Frame Type: %i\\n\", v->s.pict_type);\n\n\n\n    if (v->tfcntrflag) v->tfcntr = get_bits(gb, 8);\n\n    if (v->broadcast)\n\n    {\n\n        if (!v->interlace) v->rptfrm = get_bits(gb, 2);\n\n        else\n\n        {\n\n            v->tff = get_bits(gb, 1);\n\n            v->rff = get_bits(gb, 1);\n\n        }\n\n    }\n\n\n\n    if (v->panscanflag)\n\n    {\n\n#if 0\n\n        for (i=0; i<v->numpanscanwin; i++)\n\n        {\n\n            v->topleftx[i] = get_bits(gb, 16);\n\n            v->toplefty[i] = get_bits(gb, 16);\n\n            v->bottomrightx[i] = get_bits(gb, 16);\n\n            v->bottomrighty[i] = get_bits(gb, 16);\n\n        }\n\n#else\n\n        skip_bits(gb, 16*4*v->numpanscanwin);\n\n#endif\n\n    }\n\n    v->s.no_rounding = !get_bits(gb, 1);\n\n    v->uvsamp = get_bits(gb, 1);\n\n    if (v->finterpflag == 1) v->interpfrm = get_bits(gb, 1);\n\n\n\n    switch(v->s.pict_type)\n\n    {\n\n    case I_TYPE: if (decode_i_picture_header(v) < 0) return -1;\n\n    case P_TYPE: if (decode_p_picture_primary_header(v) < 0) return -1;\n\n    case BI_TYPE:\n\n    case B_TYPE: if (decode_b_picture_primary_header(v) < 0) return FRAME_SKIPED;\n\n    default: break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 4861, "_split": "valid", "_hash": "7606c8e901cba7eb4bf7a111473e6361"}
{"project": "FFmpeg", "commit_id": "68aefbe81cb3b9dd002108782bb8d798e1c12806", "target": 1, "func": "static double get_video_clock(VideoState *is)\n\n{\n\n    if (is->paused) {\n\n        return is->video_current_pts;\n\n    } else {\n\n        return is->video_current_pts + (av_gettime() - is->video_current_pts_time) / 1000000.0;\n\n    }\n\n}\n", "idx": 4876, "_split": "valid", "_hash": "7f37d3118903e03612bd1a8b0db29cfc"}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0xC(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n\n\n    /* 16-color block encoding: each 2x2 block is a different color */\n\n    CHECK_STREAM_PTR(16);\n\n\n\n    for (y = 0; y < 8; y += 2) {\n\n        for (x = 0; x < 8; x += 2) {\n\n            s->pixel_ptr[x                ] =\n\n            s->pixel_ptr[x + 1            ] =\n\n            s->pixel_ptr[x +     s->stride] =\n\n            s->pixel_ptr[x + 1 + s->stride] = *s->stream_ptr++;\n\n        }\n\n        s->pixel_ptr += s->stride * 2;\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 4958, "_split": "valid", "_hash": "adda64a1b3bc8eb60425c503b316bc47"}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred8x8_horizontal)(uint8_t *_src, int stride){\n\n    int i;\n\n    pixel *src = (pixel*)_src;\n\n    stride /= sizeof(pixel);\n\n\n\n    for(i=0; i<8; i++){\n\n        ((pixel4*)(src+i*stride))[0]=\n\n        ((pixel4*)(src+i*stride))[1]= PIXEL_SPLAT_X4(src[-1+i*stride]);\n\n    }\n\n}\n", "idx": 4991, "_split": "valid", "_hash": "e3896d05624d3c56d45474d0a960751d"}
{"project": "FFmpeg", "commit_id": "c79d2a20bad59298188171f1316a830d563a41ee", "target": 0, "func": "static void decode_parameters(SiprParameters* parms, GetBitContext *pgb,\n\n                              const SiprModeParam *p)\n\n{\n\n    int i, j;\n\n\n\n    parms->ma_pred_switch           = get_bits(pgb, p->ma_predictor_bits);\n\n\n\n    for (i = 0; i < 5; i++)\n\n        parms->vq_indexes[i]        = get_bits(pgb, p->vq_indexes_bits[i]);\n\n\n\n    for (i = 0; i < p->subframe_count; i++) {\n\n        parms->pitch_delay[i]       = get_bits(pgb, p->pitch_delay_bits[i]);\n\n        parms->gp_index[i]          = get_bits(pgb, p->gp_index_bits);\n\n\n\n        for (j = 0; j < p->number_of_fc_indexes; j++)\n\n            parms->fc_indexes[i][j] = get_bits(pgb, p->fc_index_bits[j]);\n\n\n\n        parms->gc_index[i]          = get_bits(pgb, p->gc_index_bits);\n\n    }\n\n}\n", "idx": 5006, "_split": "valid", "_hash": "6b9332c1decbc926ef1772ea0eaec330"}
{"project": "FFmpeg", "commit_id": "e0c6cce44729d94e2a5507a4b6d031f23e8bd7b6", "target": 0, "func": "av_cold void rgb2rgb_init_x86(void)\n\n{\n\n#if HAVE_INLINE_ASM\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (cpu_flags & AV_CPU_FLAG_MMX)\n\n        rgb2rgb_init_MMX();\n\n    if (HAVE_AMD3DNOW && cpu_flags & AV_CPU_FLAG_3DNOW)\n\n        rgb2rgb_init_3DNOW();\n\n    if (HAVE_MMXEXT   && cpu_flags & AV_CPU_FLAG_MMXEXT)\n\n        rgb2rgb_init_MMX2();\n\n    if (HAVE_SSE      && cpu_flags & AV_CPU_FLAG_SSE2)\n\n        rgb2rgb_init_SSE2();\n\n#endif /* HAVE_INLINE_ASM */\n\n}\n", "idx": 5055, "_split": "valid", "_hash": "3c56a19371952a81b87afc29eccefc08"}
{"project": "FFmpeg", "commit_id": "eea784dab00d9f123c508d3e0c6b16e4f3123bb0", "target": 0, "func": "static int mp3_header_compress(AVBitStreamFilterContext *bsfc, AVCodecContext *avctx, const char *args,\n\n                     uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size, int keyframe){\n\n    uint32_t header;\n\n    int mode_extension;\n\n\n\n    if(avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL){\n\n        av_log(avctx, AV_LOG_ERROR, \"not standards compliant\\n\");\n\n        return -1;\n\n    }\n\n\n\n    header = (buf[0] << 24) | (buf[1] << 16) | (buf[2] << 8) | buf[3];\n\n    mode_extension= (header>>4)&3;\n\n\n\n    if(ff_mpa_check_header(header) < 0 || (header&0x70000) != 0x30000){\n\n        *poutbuf= (uint8_t *) buf;\n\n        *poutbuf_size= buf_size;\n\n\n\n        av_log(avctx, AV_LOG_INFO, \"cannot compress %08X\\n\", header);\n\n        return 0;\n\n    }\n\n\n\n    *poutbuf_size= buf_size - 4;\n\n    *poutbuf= av_malloc(buf_size - 4 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    memcpy(*poutbuf, buf + 4, buf_size - 4 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    if(avctx->channels==2){\n\n        if((header & (3<<19)) != 3<<19){\n\n            (*poutbuf)[1] &= 0x3F;\n\n            (*poutbuf)[1] |= mode_extension<<6;\n\n            FFSWAP(int, (*poutbuf)[1], (*poutbuf)[2]);\n\n        }else{\n\n            (*poutbuf)[1] &= 0x8F;\n\n            (*poutbuf)[1] |= mode_extension<<4;\n\n        }\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 5066, "_split": "valid", "_hash": "5c843790f029dc1b826d70aa06e5fe61"}
{"project": "FFmpeg", "commit_id": "93d336fb076a8abe33e37251af5475673e716f6d", "target": 1, "func": "static int set_segment_filename(AVFormatContext *s)\n\n{\n\n    SegmentContext *seg = s->priv_data;\n\n    AVFormatContext *oc = seg->avf;\n\n    size_t size;\n\n\n\n    if (seg->segment_idx_wrap)\n\n        seg->segment_idx %= seg->segment_idx_wrap;\n\n    if (seg->use_strftime) {\n\n        time_t now0;\n\n        struct tm *tm, tmpbuf;\n\n        time(&now0);\n\n        tm = localtime_r(&now0, &tmpbuf);\n\n        if (!strftime(oc->filename, sizeof(oc->filename), s->filename, tm)) {\n\n            av_log(oc, AV_LOG_ERROR, \"Could not get segment filename with strftime\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n    } else if (av_get_frame_filename(oc->filename, sizeof(oc->filename),\n\n                                     s->filename, seg->segment_idx) < 0) {\n\n        av_log(oc, AV_LOG_ERROR, \"Invalid segment filename template '%s'\\n\", s->filename);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* copy modified name in list entry */\n\n    size = strlen(av_basename(oc->filename)) + 1;\n\n    if (seg->entry_prefix)\n\n        size += strlen(seg->entry_prefix);\n\n\n\n    seg->cur_entry.filename = av_mallocz(size);\n\n    if (!seg->cur_entry.filename)\n\n        return AVERROR(ENOMEM);\n\n    snprintf(seg->cur_entry.filename, size, \"%s%s\",\n\n             seg->entry_prefix ? seg->entry_prefix : \"\",\n\n             av_basename(oc->filename));\n\n\n\n    return 0;\n\n}\n", "idx": 5137, "_split": "valid", "_hash": "b2631a7a5cce49d302b6089ed09ec7e4"}
{"project": "FFmpeg", "commit_id": "d81be0a60a6dea2bc48ec29f9466eee63984ed34", "target": 1, "func": "static int hwmap_filter_frame(AVFilterLink *link, AVFrame *input)\n\n{\n\n    AVFilterContext *avctx = link->dst;\n\n    AVFilterLink  *outlink = avctx->outputs[0];\n\n    HWMapContext      *ctx = avctx->priv;\n\n    AVFrame *map = NULL;\n\n    int err;\n\n\n\n    av_log(ctx, AV_LOG_DEBUG, \"Filter input: %s, %ux%u (%\"PRId64\").\\n\",\n\n           av_get_pix_fmt_name(input->format),\n\n           input->width, input->height, input->pts);\n\n\n\n    map = av_frame_alloc();\n\n    if (!map) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    map->format = outlink->format;\n\n    map->hw_frames_ctx = av_buffer_ref(ctx->hwframes_ref);\n\n    if (!map->hw_frames_ctx) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    if (ctx->map_backwards && !input->hw_frames_ctx) {\n\n        // If we mapped backwards from hardware to software, we need\n\n        // to attach the hardware frame context to the input frame to\n\n        // make the mapping visible to av_hwframe_map().\n\n        input->hw_frames_ctx = av_buffer_ref(ctx->hwframes_ref);\n\n        if (!input->hw_frames_ctx) {\n\n            err = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    err = av_hwframe_map(map, input, ctx->mode);\n\n    if (err < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to map frame: %d.\\n\", err);\n\n        goto fail;\n\n    }\n\n\n\n    err = av_frame_copy_props(map, input);\n\n    if (err < 0)\n\n        goto fail;\n\n\n\n    av_frame_free(&input);\n\n\n\n    av_log(ctx, AV_LOG_DEBUG, \"Filter output: %s, %ux%u (%\"PRId64\").\\n\",\n\n           av_get_pix_fmt_name(map->format),\n\n           map->width, map->height, map->pts);\n\n\n\n    return ff_filter_frame(outlink, map);\n\n\n\nfail:\n\n    av_frame_free(&input);\n\n    av_frame_free(&map);\n\n    return err;\n\n}\n", "idx": 5176, "_split": "valid", "_hash": "a785015bc8be04f72c168310b20a3e62"}
{"project": "FFmpeg", "commit_id": "6c583e9048fe9db2ed4d7bbc75f4f1d76e82761a", "target": 1, "func": "static int opus_decode_packet(AVCodecContext *avctx, void *data,\n\n                              int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    OpusContext *c      = avctx->priv_data;\n\n    AVFrame *frame      = data;\n\n    const uint8_t *buf  = avpkt->data;\n\n    int buf_size        = avpkt->size;\n\n    int coded_samples   = 0;\n\n    int decoded_samples = 0;\n\n    int i, ret;\n\n\n\n    for (i = 0; i < c->nb_streams; i++) {\n\n        OpusStreamContext *s = &c->streams[i];\n\n        s->out[0] =\n\n        s->out[1] = NULL;\n\n    }\n\n\n\n    /* decode the header of the first sub-packet to find out the sample count */\n\n    if (buf) {\n\n        OpusPacket *pkt = &c->streams[0].packet;\n\n        ret = ff_opus_parse_packet(pkt, buf, buf_size, c->nb_streams > 1);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error parsing the packet header.\\n\");\n\n            return ret;\n\n        }\n\n        coded_samples += pkt->frame_count * pkt->frame_duration;\n\n        c->streams[0].silk_samplerate = get_silk_samplerate(pkt->config);\n\n    }\n\n\n\n    frame->nb_samples = coded_samples + c->streams[0].delayed_samples;\n\n\n\n    /* no input or buffered data => nothing to do */\n\n    if (!frame->nb_samples) {\n\n        *got_frame_ptr = 0;\n\n        return 0;\n\n    }\n\n\n\n    /* setup the data buffers */\n\n    ret = ff_get_buffer(avctx, frame, 0);\n\n    if (ret < 0)\n\n        return ret;\n\n    frame->nb_samples = 0;\n\n\n\n    for (i = 0; i < avctx->channels; i++) {\n\n        ChannelMap *map = &c->channel_maps[i];\n\n        if (!map->copy)\n\n            c->streams[map->stream_idx].out[map->channel_idx] = (float*)frame->extended_data[i];\n\n    }\n\n\n\n    for (i = 0; i < c->nb_streams; i++)\n\n        c->streams[i].out_size = frame->linesize[0];\n\n\n\n    /* decode each sub-packet */\n\n    for (i = 0; i < c->nb_streams; i++) {\n\n        OpusStreamContext *s = &c->streams[i];\n\n\n\n        if (i && buf) {\n\n            ret = ff_opus_parse_packet(&s->packet, buf, buf_size, i != c->nb_streams - 1);\n\n            if (ret < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Error parsing the packet header.\\n\");\n\n                return ret;\n\n            }\n\n            if (coded_samples != s->packet.frame_count * s->packet.frame_duration) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"Mismatching coded sample count in substream %d.\\n\", i);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            s->silk_samplerate = get_silk_samplerate(s->packet.config);\n\n        }\n\n\n\n        ret = opus_decode_subpacket(&c->streams[i], buf,\n\n                                    s->packet.data_size, coded_samples);\n\n        if (ret < 0)\n\n            return ret;\n\n        if (decoded_samples && ret != decoded_samples) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Different numbers of decoded samples \"\n\n                   \"in a multi-channel stream\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        decoded_samples = ret;\n\n        buf      += s->packet.packet_size;\n\n        buf_size -= s->packet.packet_size;\n\n    }\n\n\n\n    for (i = 0; i < avctx->channels; i++) {\n\n        ChannelMap *map = &c->channel_maps[i];\n\n\n\n        /* handle copied channels */\n\n        if (map->copy) {\n\n            memcpy(frame->extended_data[i],\n\n                   frame->extended_data[map->copy_idx],\n\n                   frame->linesize[0]);\n\n        } else if (map->silence) {\n\n            memset(frame->extended_data[i], 0, frame->linesize[0]);\n\n        }\n\n\n\n        if (c->gain_i) {\n\n            c->fdsp->vector_fmul_scalar((float*)frame->extended_data[i],\n\n                                       (float*)frame->extended_data[i],\n\n                                       c->gain, FFALIGN(decoded_samples, 8));\n\n        }\n\n    }\n\n\n\n    frame->nb_samples = decoded_samples;\n\n    *got_frame_ptr    = !!decoded_samples;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 5178, "_split": "valid", "_hash": "57925bdb9e1d286775ce8fc158585974"}
{"project": "FFmpeg", "commit_id": "4080e67c8e4528684b44e6cf5d0bc4ee4053f87a", "target": 0, "func": "static void av_always_inline filter_mb_dir(H264Context *h, int mb_x, int mb_y, uint8_t *img_y, uint8_t *img_cb, uint8_t *img_cr, unsigned int linesize, unsigned int uvlinesize, int mb_xy, int mb_type, int mvy_limit, int first_vertical_edge_done, int dir) {\n\n    MpegEncContext * const s = &h->s;\n\n    int edge;\n\n    const int mbm_xy = dir == 0 ? mb_xy -1 : h->top_mb_xy;\n\n    const int mbm_type = s->current_picture.mb_type[mbm_xy];\n\n    int (*ref2frm) [64] = h->ref2frm[ h->slice_num          &(MAX_SLICES-1) ][0] + (MB_MBAFF ? 20 : 2);\n\n    int (*ref2frmm)[64] = h->ref2frm[ h->slice_table[mbm_xy]&(MAX_SLICES-1) ][0] + (MB_MBAFF ? 20 : 2);\n\n    int start = h->slice_table[mbm_xy] == 0xFFFF ? 1 : 0;\n\n\n\n    const int edges = (mb_type & (MB_TYPE_16x16|MB_TYPE_SKIP))\n\n                              == (MB_TYPE_16x16|MB_TYPE_SKIP) ? 1 : 4;\n\n    // how often to recheck mv-based bS when iterating between edges\n\n    const int mask_edge = (mb_type & (MB_TYPE_16x16 | (MB_TYPE_16x8 << dir))) ? 3 :\n\n                          (mb_type & (MB_TYPE_8x16 >> dir)) ? 1 : 0;\n\n    // how often to recheck mv-based bS when iterating along each edge\n\n    const int mask_par0 = mb_type & (MB_TYPE_16x16 | (MB_TYPE_8x16 >> dir));\n\n\n\n    if (first_vertical_edge_done) {\n\n        start = 1;\n\n    }\n\n\n\n    if (h->deblocking_filter==2 && h->slice_table[mbm_xy] != h->slice_table[mb_xy])\n\n        start = 1;\n\n\n\n    if (FRAME_MBAFF && (dir == 1) && ((mb_y&1) == 0) && start == 0\n\n        && !IS_INTERLACED(mb_type)\n\n        && IS_INTERLACED(mbm_type)\n\n        ) {\n\n        // This is a special case in the norm where the filtering must\n\n        // be done twice (one each of the field) even if we are in a\n\n        // frame macroblock.\n\n        //\n\n        static const int nnz_idx[4] = {4,5,6,3};\n\n        unsigned int tmp_linesize   = 2 *   linesize;\n\n        unsigned int tmp_uvlinesize = 2 * uvlinesize;\n\n        int mbn_xy = mb_xy - 2 * s->mb_stride;\n\n        int qp;\n\n        int i, j;\n\n        int16_t bS[4];\n\n\n\n        for(j=0; j<2; j++, mbn_xy += s->mb_stride){\n\n            if( IS_INTRA(mb_type) ||\n\n                IS_INTRA(s->current_picture.mb_type[mbn_xy]) ) {\n\n                bS[0] = bS[1] = bS[2] = bS[3] = 3;\n\n            } else {\n\n                const uint8_t *mbn_nnz = h->non_zero_count[mbn_xy];\n\n                for( i = 0; i < 4; i++ ) {\n\n                    if( h->non_zero_count_cache[scan8[0]+i] != 0 ||\n\n                        mbn_nnz[nnz_idx[i]] != 0 )\n\n                        bS[i] = 2;\n\n                    else\n\n                        bS[i] = 1;\n\n                }\n\n            }\n\n            // Do not use s->qscale as luma quantizer because it has not the same\n\n            // value in IPCM macroblocks.\n\n            qp = ( s->current_picture.qscale_table[mb_xy] + s->current_picture.qscale_table[mbn_xy] + 1 ) >> 1;\n\n            tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, tmp_linesize, tmp_uvlinesize);\n\n            { int i; for (i = 0; i < 4; i++) tprintf(s->avctx, \" bS[%d]:%d\", i, bS[i]); tprintf(s->avctx, \"\\n\"); }\n\n            filter_mb_edgeh( h, &img_y[j*linesize], tmp_linesize, bS, qp );\n\n            filter_mb_edgech( h, &img_cb[j*uvlinesize], tmp_uvlinesize, bS,\n\n                              ( h->chroma_qp[0] + get_chroma_qp( h, 0, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1);\n\n            filter_mb_edgech( h, &img_cr[j*uvlinesize], tmp_uvlinesize, bS,\n\n                              ( h->chroma_qp[1] + get_chroma_qp( h, 1, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1);\n\n        }\n\n\n\n        start = 1;\n\n    }\n\n\n\n    /* Calculate bS */\n\n    for( edge = start; edge < edges; edge++ ) {\n\n        /* mbn_xy: neighbor macroblock */\n\n        const int mbn_xy = edge > 0 ? mb_xy : mbm_xy;\n\n        const int mbn_type = s->current_picture.mb_type[mbn_xy];\n\n        int (*ref2frmn)[64] = edge > 0 ? ref2frm : ref2frmm;\n\n        int16_t bS[4];\n\n        int qp;\n\n\n\n        if( (edge&1) && IS_8x8DCT(mb_type) )\n\n            continue;\n\n\n\n        if( IS_INTRA(mb_type) ||\n\n            IS_INTRA(mbn_type) ) {\n\n            int value;\n\n            if (edge == 0) {\n\n                if (   (!IS_INTERLACED(mb_type) && !IS_INTERLACED(mbm_type))\n\n                    || ((FRAME_MBAFF || (s->picture_structure != PICT_FRAME)) && (dir == 0))\n\n                ) {\n\n                    value = 4;\n\n                } else {\n\n                    value = 3;\n\n                }\n\n            } else {\n\n                value = 3;\n\n            }\n\n            bS[0] = bS[1] = bS[2] = bS[3] = value;\n\n        } else {\n\n            int i, l;\n\n            int mv_done;\n\n\n\n            if( edge & mask_edge ) {\n\n                bS[0] = bS[1] = bS[2] = bS[3] = 0;\n\n                mv_done = 1;\n\n            }\n\n            else if( FRAME_MBAFF && IS_INTERLACED(mb_type ^ mbn_type)) {\n\n                bS[0] = bS[1] = bS[2] = bS[3] = 1;\n\n                mv_done = 1;\n\n            }\n\n            else if( mask_par0 && (edge || (mbn_type & (MB_TYPE_16x16 | (MB_TYPE_8x16 >> dir)))) ) {\n\n                int b_idx= 8 + 4 + edge * (dir ? 8:1);\n\n                int bn_idx= b_idx - (dir ? 8:1);\n\n                int v = 0;\n\n\n\n                for( l = 0; !v && l < 1 + (h->slice_type_nos == FF_B_TYPE); l++ ) {\n\n                    v |= ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[l][h->ref_cache[l][bn_idx]] ||\n\n                         FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[l][bn_idx][0] ) >= 4 ||\n\n                         FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[l][bn_idx][1] ) >= mvy_limit;\n\n                }\n\n\n\n                if(h->slice_type_nos == FF_B_TYPE && v){\n\n                    v=0;\n\n                    for( l = 0; !v && l < 2; l++ ) {\n\n                        int ln= 1-l;\n\n                        v |= ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[ln][h->ref_cache[ln][bn_idx]] ||\n\n                            FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[ln][bn_idx][0] ) >= 4 ||\n\n                            FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[ln][bn_idx][1] ) >= mvy_limit;\n\n                    }\n\n                }\n\n\n\n                bS[0] = bS[1] = bS[2] = bS[3] = v;\n\n                mv_done = 1;\n\n            }\n\n            else\n\n                mv_done = 0;\n\n\n\n            for( i = 0; i < 4; i++ ) {\n\n                int x = dir == 0 ? edge : i;\n\n                int y = dir == 0 ? i    : edge;\n\n                int b_idx= 8 + 4 + x + 8*y;\n\n                int bn_idx= b_idx - (dir ? 8:1);\n\n\n\n                if( h->non_zero_count_cache[b_idx] != 0 ||\n\n                    h->non_zero_count_cache[bn_idx] != 0 ) {\n\n                    bS[i] = 2;\n\n                }\n\n                else if(!mv_done)\n\n                {\n\n                    bS[i] = 0;\n\n                    for( l = 0; l < 1 + (h->slice_type_nos == FF_B_TYPE); l++ ) {\n\n                        if( ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[l][h->ref_cache[l][bn_idx]] ||\n\n                            FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[l][bn_idx][0] ) >= 4 ||\n\n                            FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[l][bn_idx][1] ) >= mvy_limit ) {\n\n                            bS[i] = 1;\n\n                            break;\n\n                        }\n\n                    }\n\n\n\n                    if(h->slice_type_nos == FF_B_TYPE && bS[i]){\n\n                        bS[i] = 0;\n\n                        for( l = 0; l < 2; l++ ) {\n\n                            int ln= 1-l;\n\n                            if( ref2frm[l][h->ref_cache[l][b_idx]] != ref2frmn[ln][h->ref_cache[ln][bn_idx]] ||\n\n                                FFABS( h->mv_cache[l][b_idx][0] - h->mv_cache[ln][bn_idx][0] ) >= 4 ||\n\n                                FFABS( h->mv_cache[l][b_idx][1] - h->mv_cache[ln][bn_idx][1] ) >= mvy_limit ) {\n\n                                bS[i] = 1;\n\n                                break;\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n\n\n            if(bS[0]+bS[1]+bS[2]+bS[3] == 0)\n\n                continue;\n\n        }\n\n\n\n        /* Filter edge */\n\n        // Do not use s->qscale as luma quantizer because it has not the same\n\n        // value in IPCM macroblocks.\n\n        qp = ( s->current_picture.qscale_table[mb_xy] + s->current_picture.qscale_table[mbn_xy] + 1 ) >> 1;\n\n        //tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d, QPc:%d, QPcn:%d\\n\", mb_x, mb_y, dir, edge, qp, h->chroma_qp, s->current_picture.qscale_table[mbn_xy]);\n\n        tprintf(s->avctx, \"filter mb:%d/%d dir:%d edge:%d, QPy:%d ls:%d uvls:%d\", mb_x, mb_y, dir, edge, qp, linesize, uvlinesize);\n\n        { int i; for (i = 0; i < 4; i++) tprintf(s->avctx, \" bS[%d]:%d\", i, bS[i]); tprintf(s->avctx, \"\\n\"); }\n\n        if( dir == 0 ) {\n\n            filter_mb_edgev( h, &img_y[4*edge], linesize, bS, qp );\n\n            if( (edge&1) == 0 ) {\n\n                filter_mb_edgecv( h, &img_cb[2*edge], uvlinesize, bS,\n\n                                  ( h->chroma_qp[0] + get_chroma_qp( h, 0, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1);\n\n                filter_mb_edgecv( h, &img_cr[2*edge], uvlinesize, bS,\n\n                                  ( h->chroma_qp[1] + get_chroma_qp( h, 1, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1);\n\n            }\n\n        } else {\n\n            filter_mb_edgeh( h, &img_y[4*edge*linesize], linesize, bS, qp );\n\n            if( (edge&1) == 0 ) {\n\n                filter_mb_edgech( h, &img_cb[2*edge*uvlinesize], uvlinesize, bS,\n\n                                  ( h->chroma_qp[0] + get_chroma_qp( h, 0, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1);\n\n                filter_mb_edgech( h, &img_cr[2*edge*uvlinesize], uvlinesize, bS,\n\n                                  ( h->chroma_qp[1] + get_chroma_qp( h, 1, s->current_picture.qscale_table[mbn_xy] ) + 1 ) >> 1);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 5195, "_split": "valid", "_hash": "e6a8749ac7db6c29cacfb973f43dad15"}
{"project": "FFmpeg", "commit_id": "90901860c21468d6e9ae437c2bacb099c7bd3acf", "target": 0, "func": "static int vorbis_parse_setup_hdr_modes(vorbis_context *vc) {\n\n    GetBitContext *gb=&vc->gb;\n\n    uint_fast8_t i;\n\n\n\n    vc->mode_count=get_bits(gb, 6)+1;\n\n    vc->modes=(vorbis_mode *)av_mallocz(vc->mode_count * sizeof(vorbis_mode));\n\n\n\n    AV_DEBUG(\" There are %d modes.\\n\", vc->mode_count);\n\n\n\n    for(i=0;i<vc->mode_count;++i) {\n\n        vorbis_mode *mode_setup=&vc->modes[i];\n\n\n\n        mode_setup->blockflag=get_bits1(gb);\n\n        mode_setup->windowtype=get_bits(gb, 16); //FIXME check\n\n        mode_setup->transformtype=get_bits(gb, 16); //FIXME check\n\n        mode_setup->mapping=get_bits(gb, 8); //FIXME check\n\n\n\n        AV_DEBUG(\" %d mode: blockflag %d, windowtype %d, transformtype %d, mapping %d \\n\", i, mode_setup->blockflag, mode_setup->windowtype, mode_setup->transformtype, mode_setup->mapping);\n\n    }\n\n    return 0;\n\n}\n", "idx": 5248, "_split": "valid", "_hash": "11be8cb3798ac2af960f4093c461b0cd"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "const uint8_t *ff_h264_decode_nal(H264Context *h, const uint8_t *src,\n\n                                  int *dst_length, int *consumed, int length)\n\n{\n\n    int i, si, di;\n\n    uint8_t *dst;\n\n    int bufidx;\n\n\n\n    // src[0]&0x80; // forbidden bit\n\n    h->nal_ref_idc   = src[0] >> 5;\n\n    h->nal_unit_type = src[0] & 0x1F;\n\n\n\n    src++;\n\n    length--;\n\n\n\n#define STARTCODE_TEST                                                  \\\n\n    if (i + 2 < length && src[i + 1] == 0 && src[i + 2] <= 3) {         \\\n\n        if (src[i + 2] != 3) {                                          \\\n\n            /* startcode, so we must be past the end */                 \\\n\n            length = i;                                                 \\\n\n        }                                                               \\\n\n        break;                                                          \\\n\n    }\n\n\n\n#if HAVE_FAST_UNALIGNED\n\n#define FIND_FIRST_ZERO                                                 \\\n\n    if (i > 0 && !src[i])                                               \\\n\n        i--;                                                            \\\n\n    while (src[i])                                                      \\\n\n        i++\n\n\n\n#if HAVE_FAST_64BIT\n\n    for (i = 0; i + 1 < length; i += 9) {\n\n        if (!((~AV_RN64A(src + i) &\n\n               (AV_RN64A(src + i) - 0x0100010001000101ULL)) &\n\n              0x8000800080008080ULL))\n\n            continue;\n\n        FIND_FIRST_ZERO;\n\n        STARTCODE_TEST;\n\n        i -= 7;\n\n    }\n\n#else\n\n    for (i = 0; i + 1 < length; i += 5) {\n\n        if (!((~AV_RN32A(src + i) &\n\n               (AV_RN32A(src + i) - 0x01000101U)) &\n\n              0x80008080U))\n\n            continue;\n\n        FIND_FIRST_ZERO;\n\n        STARTCODE_TEST;\n\n        i -= 3;\n\n    }\n\n#endif\n\n#else\n\n    for (i = 0; i + 1 < length; i += 2) {\n\n        if (src[i])\n\n            continue;\n\n        if (i > 0 && src[i - 1] == 0)\n\n            i--;\n\n        STARTCODE_TEST;\n\n    }\n\n#endif\n\n\n\n    if (i >= length - 1) { // no escaped 0\n\n        *dst_length = length;\n\n        *consumed   = length + 1; // +1 for the header\n\n        return src;\n\n    }\n\n\n\n    // use second escape buffer for inter data\n\n    bufidx = h->nal_unit_type == NAL_DPC ? 1 : 0;\n\n    av_fast_malloc(&h->rbsp_buffer[bufidx], &h->rbsp_buffer_size[bufidx],\n\n                   length + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    dst = h->rbsp_buffer[bufidx];\n\n\n\n    if (dst == NULL)\n\n        return NULL;\n\n\n\n    memcpy(dst, src, i);\n\n    si = di = i;\n\n    while (si + 2 < length) {\n\n        // remove escapes (very rare 1:2^22)\n\n        if (src[si + 2] > 3) {\n\n            dst[di++] = src[si++];\n\n            dst[di++] = src[si++];\n\n        } else if (src[si] == 0 && src[si + 1] == 0) {\n\n            if (src[si + 2] == 3) { // escape\n\n                dst[di++]  = 0;\n\n                dst[di++]  = 0;\n\n                si        += 3;\n\n                continue;\n\n            } else // next start code\n\n                goto nsc;\n\n        }\n\n\n\n        dst[di++] = src[si++];\n\n    }\n\n    while (si < length)\n\n        dst[di++] = src[si++];\n\n\n\nnsc:\n\n    memset(dst + di, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    *dst_length = di;\n\n    *consumed   = si + 1; // +1 for the header\n\n    /* FIXME store exact number of bits in the getbitcontext\n\n     * (it is needed for decoding) */\n\n    return dst;\n\n}\n", "idx": 5264, "_split": "valid", "_hash": "3e808a1f438256fdbf57c81bd0967793"}
{"project": "FFmpeg", "commit_id": "5a4af049b1a84ee09aba3745678797fce82c4a1e", "target": 0, "func": "static int decode_ics_info(AACContext *ac, IndividualChannelStream *ics,\n\n                           GetBitContext *gb)\n\n{\n\n    if (get_bits1(gb)) {\n\n        av_log(ac->avctx, AV_LOG_ERROR, \"Reserved bit set.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    ics->window_sequence[1] = ics->window_sequence[0];\n\n    ics->window_sequence[0] = get_bits(gb, 2);\n\n    ics->use_kb_window[1]   = ics->use_kb_window[0];\n\n    ics->use_kb_window[0]   = get_bits1(gb);\n\n    ics->num_window_groups  = 1;\n\n    ics->group_len[0]       = 1;\n\n    if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n        int i;\n\n        ics->max_sfb = get_bits(gb, 4);\n\n        for (i = 0; i < 7; i++) {\n\n            if (get_bits1(gb)) {\n\n                ics->group_len[ics->num_window_groups - 1]++;\n\n            } else {\n\n                ics->num_window_groups++;\n\n                ics->group_len[ics->num_window_groups - 1] = 1;\n\n            }\n\n        }\n\n        ics->num_windows       = 8;\n\n        ics->swb_offset        =    ff_swb_offset_128[ac->m4ac.sampling_index];\n\n        ics->num_swb           =   ff_aac_num_swb_128[ac->m4ac.sampling_index];\n\n        ics->tns_max_bands     = ff_tns_max_bands_128[ac->m4ac.sampling_index];\n\n        ics->predictor_present = 0;\n\n    } else {\n\n        ics->max_sfb               = get_bits(gb, 6);\n\n        ics->num_windows           = 1;\n\n        ics->swb_offset            =    ff_swb_offset_1024[ac->m4ac.sampling_index];\n\n        ics->num_swb               =   ff_aac_num_swb_1024[ac->m4ac.sampling_index];\n\n        ics->tns_max_bands         = ff_tns_max_bands_1024[ac->m4ac.sampling_index];\n\n        ics->predictor_present     = get_bits1(gb);\n\n        ics->predictor_reset_group = 0;\n\n        if (ics->predictor_present) {\n\n            if (ac->m4ac.object_type == AOT_AAC_MAIN) {\n\n                if (decode_prediction(ac, ics, gb)) {\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n            } else if (ac->m4ac.object_type == AOT_AAC_LC) {\n\n                av_log(ac->avctx, AV_LOG_ERROR, \"Prediction is not allowed in AAC-LC.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            } else {\n\n                if ((ics->ltp.present = get_bits(gb, 1)))\n\n                    decode_ltp(ac, &ics->ltp, gb, ics->max_sfb);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (ics->max_sfb > ics->num_swb) {\n\n        av_log(ac->avctx, AV_LOG_ERROR,\n\n               \"Number of scalefactor bands in group (%d) exceeds limit (%d).\\n\",\n\n               ics->max_sfb, ics->num_swb);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 5333, "_split": "valid", "_hash": "0831055db8a16f81a81510483df6de4b"}
{"project": "FFmpeg", "commit_id": "f0197e1637bbe9d508f54dabb58a9081e8f36ef3", "target": 1, "func": "static int mov_read_udta_string(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    char tmp_key[5];\n\n    char key2[32], language[4] = {0};\n\n    char *str = NULL;\n\n    const char *key = NULL;\n\n    uint16_t langcode = 0;\n\n    uint32_t data_type = 0, str_size, str_size_alloc;\n\n    int (*parse)(MOVContext*, AVIOContext*, unsigned, const char*) = NULL;\n\n    int raw = 0;\n\n    int num = 0;\n\n\n\n    switch (atom.type) {\n\n    case MKTAG( '@','P','R','M'): key = \"premiere_version\"; raw = 1; break;\n\n    case MKTAG( '@','P','R','Q'): key = \"quicktime_version\"; raw = 1; break;\n\n    case MKTAG( 'X','M','P','_'):\n\n        if (c->export_xmp) { key = \"xmp\"; raw = 1; } break;\n\n    case MKTAG( 'a','A','R','T'): key = \"album_artist\";    break;\n\n    case MKTAG( 'a','k','I','D'): key = \"account_type\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'a','p','I','D'): key = \"account_id\"; break;\n\n    case MKTAG( 'c','a','t','g'): key = \"category\"; break;\n\n    case MKTAG( 'c','p','i','l'): key = \"compilation\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'c','p','r','t'): key = \"copyright\"; break;\n\n    case MKTAG( 'd','e','s','c'): key = \"description\"; break;\n\n    case MKTAG( 'd','i','s','k'): key = \"disc\";\n\n        parse = mov_metadata_track_or_disc_number; break;\n\n    case MKTAG( 'e','g','i','d'): key = \"episode_uid\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'g','n','r','e'): key = \"genre\";\n\n        parse = mov_metadata_gnre; break;\n\n    case MKTAG( 'h','d','v','d'): key = \"hd_video\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'k','e','y','w'): key = \"keywords\";  break;\n\n    case MKTAG( 'l','d','e','s'): key = \"synopsis\";  break;\n\n    case MKTAG( 'l','o','c','i'):\n\n        return mov_metadata_loci(c, pb, atom.size);\n\n    case MKTAG( 'p','c','s','t'): key = \"podcast\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'p','g','a','p'): key = \"gapless_playback\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'p','u','r','d'): key = \"purchase_date\"; break;\n\n    case MKTAG( 'r','t','n','g'): key = \"rating\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 's','o','a','a'): key = \"sort_album_artist\"; break;\n\n    case MKTAG( 's','o','a','l'): key = \"sort_album\";   break;\n\n    case MKTAG( 's','o','a','r'): key = \"sort_artist\";  break;\n\n    case MKTAG( 's','o','c','o'): key = \"sort_composer\"; break;\n\n    case MKTAG( 's','o','n','m'): key = \"sort_name\";    break;\n\n    case MKTAG( 's','o','s','n'): key = \"sort_show\";    break;\n\n    case MKTAG( 's','t','i','k'): key = \"media_type\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 't','r','k','n'): key = \"track\";\n\n        parse = mov_metadata_track_or_disc_number; break;\n\n    case MKTAG( 't','v','e','n'): key = \"episode_id\"; break;\n\n    case MKTAG( 't','v','e','s'): key = \"episode_sort\";\n\n        parse = mov_metadata_int8_bypass_padding; break;\n\n    case MKTAG( 't','v','n','n'): key = \"network\";   break;\n\n    case MKTAG( 't','v','s','h'): key = \"show\";      break;\n\n    case MKTAG( 't','v','s','n'): key = \"season_number\";\n\n        parse = mov_metadata_int8_bypass_padding; break;\n\n    case MKTAG(0xa9,'A','R','T'): key = \"artist\";    break;\n\n    case MKTAG(0xa9,'P','R','D'): key = \"producer\";  break;\n\n    case MKTAG(0xa9,'a','l','b'): key = \"album\";     break;\n\n    case MKTAG(0xa9,'a','u','t'): key = \"artist\";    break;\n\n    case MKTAG(0xa9,'c','h','p'): key = \"chapter\";   break;\n\n    case MKTAG(0xa9,'c','m','t'): key = \"comment\";   break;\n\n    case MKTAG(0xa9,'c','o','m'): key = \"composer\";  break;\n\n    case MKTAG(0xa9,'c','p','y'): key = \"copyright\"; break;\n\n    case MKTAG(0xa9,'d','a','y'): key = \"date\";      break;\n\n    case MKTAG(0xa9,'d','i','r'): key = \"director\";  break;\n\n    case MKTAG(0xa9,'d','i','s'): key = \"disclaimer\"; break;\n\n    case MKTAG(0xa9,'e','d','1'): key = \"edit_date\"; break;\n\n    case MKTAG(0xa9,'e','n','c'): key = \"encoder\";   break;\n\n    case MKTAG(0xa9,'f','m','t'): key = \"original_format\"; break;\n\n    case MKTAG(0xa9,'g','e','n'): key = \"genre\";     break;\n\n    case MKTAG(0xa9,'g','r','p'): key = \"grouping\";  break;\n\n    case MKTAG(0xa9,'h','s','t'): key = \"host_computer\"; break;\n\n    case MKTAG(0xa9,'i','n','f'): key = \"comment\";   break;\n\n    case MKTAG(0xa9,'l','y','r'): key = \"lyrics\";    break;\n\n    case MKTAG(0xa9,'m','a','k'): key = \"make\";      break;\n\n    case MKTAG(0xa9,'m','o','d'): key = \"model\";     break;\n\n    case MKTAG(0xa9,'n','a','m'): key = \"title\";     break;\n\n    case MKTAG(0xa9,'o','p','e'): key = \"original_artist\"; break;\n\n    case MKTAG(0xa9,'p','r','d'): key = \"producer\";  break;\n\n    case MKTAG(0xa9,'p','r','f'): key = \"performers\"; break;\n\n    case MKTAG(0xa9,'r','e','q'): key = \"playback_requirements\"; break;\n\n    case MKTAG(0xa9,'s','r','c'): key = \"original_source\"; break;\n\n    case MKTAG(0xa9,'s','t','3'): key = \"subtitle\";  break;\n\n    case MKTAG(0xa9,'s','w','r'): key = \"encoder\";   break;\n\n    case MKTAG(0xa9,'t','o','o'): key = \"encoder\";   break;\n\n    case MKTAG(0xa9,'t','r','k'): key = \"track\";     break;\n\n    case MKTAG(0xa9,'u','r','l'): key = \"URL\";       break;\n\n    case MKTAG(0xa9,'w','r','n'): key = \"warning\";   break;\n\n    case MKTAG(0xa9,'w','r','t'): key = \"composer\";  break;\n\n    case MKTAG(0xa9,'x','y','z'): key = \"location\";  break;\n\n    }\n\nretry:\n\n    if (c->itunes_metadata && atom.size > 8) {\n\n        int data_size = avio_rb32(pb);\n\n        int tag = avio_rl32(pb);\n\n        if (tag == MKTAG('d','a','t','a') && data_size <= atom.size) {\n\n            data_type = avio_rb32(pb); // type\n\n            avio_rb32(pb); // unknown\n\n            str_size = data_size - 16;\n\n            atom.size -= 16;\n\n\n\n            if (atom.type == MKTAG('c', 'o', 'v', 'r')) {\n\n                int ret = mov_read_covr(c, pb, data_type, str_size);\n\n                if (ret < 0) {\n\n                    av_log(c->fc, AV_LOG_ERROR, \"Error parsing cover art.\\n\");\n\n                }\n\n                return ret;\n\n            } else if (!key && c->found_hdlr_mdta && c->meta_keys) {\n\n                uint32_t index = AV_RB32(&atom.type);\n\n                if (index < c->meta_keys_count) {\n\n                    key = c->meta_keys[index];\n\n                } else {\n\n                    av_log(c->fc, AV_LOG_WARNING,\n\n                           \"The index of 'data' is out of range: %d >= %d.\\n\",\n\n                           index, c->meta_keys_count);\n\n                }\n\n            }\n\n        } else return 0;\n\n    } else if (atom.size > 4 && key && !c->itunes_metadata && !raw) {\n\n        str_size = avio_rb16(pb); // string length\n\n        if (str_size > atom.size) {\n\n            raw = 1;\n\n            avio_seek(pb, -2, SEEK_CUR);\n\n            av_log(c->fc, AV_LOG_WARNING, \"UDTA parsing failed retrying raw\\n\");\n\n            goto retry;\n\n        }\n\n        langcode = avio_rb16(pb);\n\n        ff_mov_lang_to_iso639(langcode, language);\n\n        atom.size -= 4;\n\n    } else\n\n        str_size = atom.size;\n\n\n\n    if (c->export_all && !key) {\n\n        snprintf(tmp_key, 5, \"%.4s\", (char*)&atom.type);\n\n        key = tmp_key;\n\n    }\n\n\n\n    if (!key)\n\n        return 0;\n\n    if (atom.size < 0 || str_size >= INT_MAX/2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    // Allocates enough space if data_type is a float32 number, otherwise\n\n    // worst-case requirement for output string in case of utf8 coded input\n\n    num = (data_type == 23);\n\n    str_size_alloc = (num ? 512 : (raw ? str_size : str_size * 2)) + 1;\n\n    str = av_mallocz(str_size_alloc);\n\n    if (!str)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (parse)\n\n        parse(c, pb, str_size, key);\n\n    else {\n\n        if (!raw && (data_type == 3 || (data_type == 0 && (langcode < 0x400 || langcode == 0x7fff)))) { // MAC Encoded\n\n            mov_read_mac_string(c, pb, str_size, str, str_size_alloc);\n\n        } else if (data_type == 23 && str_size >= 4) {  // BE float32\n\n            float val = av_int2float(avio_rb32(pb));\n\n            if (snprintf(str, str_size_alloc, \"%f\", val) >= str_size_alloc) {\n\n                av_log(c->fc, AV_LOG_ERROR,\n\n                       \"Failed to store the float32 number (%f) in string.\\n\", val);\n\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            int ret = ffio_read_size(pb, str, str_size);\n\n            if (ret < 0) {\n\n\n                return ret;\n\n            }\n\n            str[str_size] = 0;\n\n        }\n\n        c->fc->event_flags |= AVFMT_EVENT_FLAG_METADATA_UPDATED;\n\n        av_dict_set(&c->fc->metadata, key, str, 0);\n\n        if (*language && strcmp(language, \"und\")) {\n\n            snprintf(key2, sizeof(key2), \"%s-%s\", key, language);\n\n            av_dict_set(&c->fc->metadata, key2, str, 0);\n\n        }\n\n    }\n\n    av_log(c->fc, AV_LOG_TRACE, \"lang \\\"%3s\\\" \", language);\n\n    av_log(c->fc, AV_LOG_TRACE, \"tag \\\"%s\\\" value \\\"%s\\\" atom \\\"%.4s\\\" %d %\"PRId64\"\\n\",\n\n            key, str, (char*)&atom.type, str_size_alloc, atom.size);\n\n\n\n    av_freep(&str);\n\n    return 0;\n\n}", "idx": 5363, "_split": "valid", "_hash": "3975ee9cf670b1c5c13670eb74372c44"}
{"project": "FFmpeg", "commit_id": "f95c81ce104554b6860d94724a681a1bac0c4fbd", "target": 1, "func": "static void mov_text_style_cb(void *priv, const char style, int close)\n\n{\n\n    MovTextContext *s = priv;\n\n    if (!close) {\n\n        if (!(s->box_flags & STYL_BOX)) {   //first style entry\n\n\n\n            s->style_attributes_temp = av_malloc(sizeof(*s->style_attributes_temp));\n\n\n\n            if (!s->style_attributes_temp) {\n\n                av_bprint_clear(&s->buffer);\n\n                s->box_flags &= ~STYL_BOX;\n\n\n            }\n\n\n\n            s->style_attributes_temp->style_flag = 0;\n\n            s->style_attributes_temp->style_start = AV_RB16(&s->text_pos);\n\n        } else {\n\n            if (s->style_attributes_temp->style_flag) { //break the style record here and start a new one\n\n                s->style_attributes_temp->style_end = AV_RB16(&s->text_pos);\n\n                av_dynarray_add(&s->style_attributes, &s->count, s->style_attributes_temp);\n\n                s->style_attributes_temp = av_malloc(sizeof(*s->style_attributes_temp));\n\n                if (!s->style_attributes_temp) {\n\n                    mov_text_cleanup(s);\n\n                    av_bprint_clear(&s->buffer);\n\n                    s->box_flags &= ~STYL_BOX;\n\n\n                }\n\n\n\n                s->style_attributes_temp->style_flag = s->style_attributes[s->count - 1]->style_flag;\n\n                s->style_attributes_temp->style_start = AV_RB16(&s->text_pos);\n\n            } else {\n\n                s->style_attributes_temp->style_flag = 0;\n\n                s->style_attributes_temp->style_start = AV_RB16(&s->text_pos);\n\n            }\n\n        }\n\n        switch (style){\n\n        case 'b':\n\n            s->style_attributes_temp->style_flag |= STYLE_FLAG_BOLD;\n\n            break;\n\n        case 'i':\n\n            s->style_attributes_temp->style_flag |= STYLE_FLAG_ITALIC;\n\n            break;\n\n        case 'u':\n\n            s->style_attributes_temp->style_flag |= STYLE_FLAG_UNDERLINE;\n\n            break;\n\n        }\n\n\n\n\n    } else {\n\n        s->style_attributes_temp->style_end = AV_RB16(&s->text_pos);\n\n        av_dynarray_add(&s->style_attributes, &s->count, s->style_attributes_temp);\n\n\n\n        s->style_attributes_temp = av_malloc(sizeof(*s->style_attributes_temp));\n\n\n\n        if (!s->style_attributes_temp) {\n\n            mov_text_cleanup(s);\n\n            av_bprint_clear(&s->buffer);\n\n            s->box_flags &= ~STYL_BOX;\n\n\n        }\n\n\n\n        s->style_attributes_temp->style_flag = s->style_attributes[s->count - 1]->style_flag;\n\n        switch (style){\n\n        case 'b':\n\n            s->style_attributes_temp->style_flag &= ~STYLE_FLAG_BOLD;\n\n            break;\n\n        case 'i':\n\n            s->style_attributes_temp->style_flag &= ~STYLE_FLAG_ITALIC;\n\n            break;\n\n        case 'u':\n\n            s->style_attributes_temp->style_flag &= ~STYLE_FLAG_UNDERLINE;\n\n            break;\n\n        }\n\n        if (s->style_attributes_temp->style_flag) { //start of new style record\n\n            s->style_attributes_temp->style_start = AV_RB16(&s->text_pos);\n\n        }\n\n    }\n\n    s->box_flags |= STYL_BOX;\n\n}", "idx": 5407, "_split": "valid", "_hash": "1145959078a9837958daae84a11a7680"}
{"project": "FFmpeg", "commit_id": "cb5b96cde0842a4a215a49b45ea74ae38a3f02f7", "target": 1, "func": "static int compute_pkt_fields2(AVStream *st, AVPacket *pkt){\n\n    int delay = FFMAX(st->codec->has_b_frames, !!st->codec->max_b_frames);\n\n    int num, den, frame_size, i;\n\n\n\n//    av_log(st->codec, AV_LOG_DEBUG, \"av_write_frame: pts:%\"PRId64\" dts:%\"PRId64\" cur_dts:%\"PRId64\" b:%d size:%d st:%d\\n\", pkt->pts, pkt->dts, st->cur_dts, delay, pkt->size, pkt->stream_index);\n\n\n\n/*    if(pkt->pts == AV_NOPTS_VALUE && pkt->dts == AV_NOPTS_VALUE)\n\n        return -1;*/\n\n\n\n    /* duration field */\n\n    if (pkt->duration == 0) {\n\n        compute_frame_duration(&num, &den, st, NULL, pkt);\n\n        if (den && num) {\n\n            pkt->duration = av_rescale(1, num * (int64_t)st->time_base.den, den * (int64_t)st->time_base.num);\n\n        }\n\n    }\n\n\n\n    if(pkt->pts == AV_NOPTS_VALUE && pkt->dts != AV_NOPTS_VALUE && delay==0)\n\n        pkt->pts= pkt->dts;\n\n\n\n    //XXX/FIXME this is a temporary hack until all encoders output pts\n\n    if((pkt->pts == 0 || pkt->pts == AV_NOPTS_VALUE) && pkt->dts == AV_NOPTS_VALUE && !delay){\n\n        pkt->dts=\n\n//        pkt->pts= st->cur_dts;\n\n        pkt->pts= st->pts.val;\n\n    }\n\n\n\n    //calculate dts from pts\n\n    if(pkt->pts != AV_NOPTS_VALUE && pkt->dts == AV_NOPTS_VALUE){\n\n        st->pts_buffer[0]= pkt->pts;\n\n        for(i=1; i<delay+1 && st->pts_buffer[i] == AV_NOPTS_VALUE; i++)\n\n            st->pts_buffer[i]= (i-delay-1) * pkt->duration;\n\n        for(i=0; i<delay && st->pts_buffer[i] > st->pts_buffer[i+1]; i++)\n\n            FFSWAP(int64_t, st->pts_buffer[i], st->pts_buffer[i+1]);\n\n\n\n        pkt->dts= st->pts_buffer[0];\n\n    }\n\n\n\n    if(st->cur_dts && st->cur_dts != AV_NOPTS_VALUE && st->cur_dts >= pkt->dts){\n\n        av_log(st->codec, AV_LOG_ERROR, \"error, non monotone timestamps %\"PRId64\" >= %\"PRId64\"\\n\", st->cur_dts, pkt->dts);\n\n        return -1;\n\n    }\n\n    if(pkt->dts != AV_NOPTS_VALUE && pkt->pts != AV_NOPTS_VALUE && pkt->pts < pkt->dts){\n\n        av_log(st->codec, AV_LOG_ERROR, \"error, pts < dts\\n\");\n\n        return -1;\n\n    }\n\n\n\n//    av_log(NULL, AV_LOG_DEBUG, \"av_write_frame: pts2:%\"PRId64\" dts2:%\"PRId64\"\\n\", pkt->pts, pkt->dts);\n\n    st->cur_dts= pkt->dts;\n\n    st->pts.val= pkt->dts;\n\n\n\n    /* update pts */\n\n    switch (st->codec->codec_type) {\n\n    case CODEC_TYPE_AUDIO:\n\n        frame_size = get_audio_frame_size(st->codec, pkt->size);\n\n\n\n        /* HACK/FIXME, we skip the initial 0 size packets as they are most\n\n           likely equal to the encoder delay, but it would be better if we\n\n           had the real timestamps from the encoder */\n\n        if (frame_size >= 0 && (pkt->size || st->pts.num!=st->pts.den>>1 || st->pts.val)) {\n\n            av_frac_add(&st->pts, (int64_t)st->time_base.den * frame_size);\n\n        }\n\n        break;\n\n    case CODEC_TYPE_VIDEO:\n\n        av_frac_add(&st->pts, (int64_t)st->time_base.den * st->codec->time_base.num);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 5421, "_split": "valid", "_hash": "5420f61770a4a49310da9f1628f3e557"}
{"project": "FFmpeg", "commit_id": "6c5b98d40b8eeec14174fb9602acbf4b0c924981", "target": 0, "func": "static int dnxhd_encode_fast(AVCodecContext *avctx, DNXHDEncContext *ctx)\n\n{\n\n    int max_bits = 0;\n\n    int ret, x, y;\n\n    if ((ret = dnxhd_find_qscale(ctx)) < 0)\n\n        return ret;\n\n    for (y = 0; y < ctx->m.mb_height; y++) {\n\n        for (x = 0; x < ctx->m.mb_width; x++) {\n\n            int mb = y * ctx->m.mb_width + x;\n\n            int rc = (ctx->qscale * ctx->m.mb_num ) + mb;\n\n            int delta_bits;\n\n            ctx->mb_qscale[mb] = ctx->qscale;\n\n            ctx->mb_bits[mb] = ctx->mb_rc[rc].bits;\n\n            max_bits += ctx->mb_rc[rc].bits;\n\n            if (!RC_VARIANCE) {\n\n                delta_bits = ctx->mb_rc[rc].bits -\n\n                             ctx->mb_rc[rc + ctx->m.mb_num].bits;\n\n                ctx->mb_cmp[mb].mb = mb;\n\n                ctx->mb_cmp[mb].value =\n\n                    delta_bits ? ((ctx->mb_rc[rc].ssd -\n\n                                   ctx->mb_rc[rc + ctx->m.mb_num].ssd) * 100) /\n\n                                  delta_bits\n\n                               : INT_MIN; // avoid increasing qscale\n\n            }\n\n        }\n\n        max_bits += 31; // worst padding\n\n    }\n\n    if (!ret) {\n\n        if (RC_VARIANCE)\n\n            avctx->execute2(avctx, dnxhd_mb_var_thread,\n\n                            NULL, NULL, ctx->m.mb_height);\n\n        radix_sort(ctx->mb_cmp, ctx->m.mb_num);\n\n        for (x = 0; x < ctx->m.mb_num && max_bits > ctx->frame_bits; x++) {\n\n            int mb = ctx->mb_cmp[x].mb;\n\n            int rc = (ctx->qscale * ctx->m.mb_num ) + mb;\n\n            max_bits -= ctx->mb_rc[rc].bits -\n\n                        ctx->mb_rc[rc + ctx->m.mb_num].bits;\n\n            ctx->mb_qscale[mb] = ctx->qscale + 1;\n\n            ctx->mb_bits[mb]   = ctx->mb_rc[rc + ctx->m.mb_num].bits;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 5439, "_split": "valid", "_hash": "1d95d64bd9bae62344171f1b259d6113"}
{"project": "FFmpeg", "commit_id": "22b37f5d3200cfe4c15eded883663cf0612093c1", "target": 0, "func": "static int img_read_header(AVFormatContext *s1, AVFormatParameters *ap)\n\n{\n\n    VideoData *s = s1->priv_data;\n\n    int ret, first_index, last_index;\n\n    char buf[1024];\n\n    ByteIOContext pb1, *f = &pb1;\n\n    AVStream *st;\n\n\n\n    st = av_new_stream(s1, 0);\n\n    if (!st) {\n\n        av_free(s);\n\n        return -ENOMEM;\n\n    }\n\n\n\n    if (ap && ap->image_format)\n\n        s->img_fmt = ap->image_format;\n\n\n\n    strcpy(s->path, s1->filename);\n\n    s->img_number = 0;\n\n\n\n    /* find format */\n\n    if (s1->iformat->flags & AVFMT_NOFILE)\n\n        s->is_pipe = 0;\n\n    else\n\n        s->is_pipe = 1;\n\n        \n\n    if (!ap || !ap->frame_rate) {\n\n        st->codec.frame_rate      = 25;\n\n        st->codec.frame_rate_base = 1;\n\n    } else {\n\n        st->codec.frame_rate      = ap->frame_rate;\n\n        st->codec.frame_rate_base = ap->frame_rate_base;\n\n    }\n\n    \n\n    if (!s->is_pipe) {\n\n        if (find_image_range(&first_index, &last_index, s->path) < 0)\n\n            goto fail;\n\n        s->img_number = first_index;\n\n        /* compute duration */\n\n        st->start_time = 0;\n\n        st->duration = ((int64_t)AV_TIME_BASE * \n\n                        (last_index - first_index + 1) * \n\n                        st->codec.frame_rate_base) / st->codec.frame_rate;\n\n        if (get_frame_filename(buf, sizeof(buf), s->path, s->img_number) < 0)\n\n            goto fail;\n\n        if (url_fopen(f, buf, URL_RDONLY) < 0)\n\n            goto fail;\n\n    } else {\n\n        f = &s1->pb;\n\n    }\n\n    \n\n    ret = av_read_image(f, s1->filename, s->img_fmt, read_header_alloc_cb, s);\n\n    if (ret < 0)\n\n        goto fail1;\n\n\n\n    if (!s->is_pipe) {\n\n        url_fclose(f);\n\n    } else {\n\n        url_fseek(f, 0, SEEK_SET);\n\n    }\n\n    \n\n    st->codec.codec_type = CODEC_TYPE_VIDEO;\n\n    st->codec.codec_id = CODEC_ID_RAWVIDEO;\n\n    st->codec.width = s->width;\n\n    st->codec.height = s->height;\n\n    st->codec.pix_fmt = s->pix_fmt;\n\n    s->img_size = avpicture_get_size(s->pix_fmt, s->width, s->height);\n\n\n\n    return 0;\n\n fail1:\n\n    if (!s->is_pipe)\n\n        url_fclose(f);\n\n fail:\n\n    av_free(s);\n\n    return -EIO;\n\n}\n", "idx": 5446, "_split": "valid", "_hash": "770edb84950683ec3814a0b1c2841101"}
{"project": "FFmpeg", "commit_id": "94c54d97e7f4fe90570c323803f2bdf6246c1010", "target": 0, "func": "static int read_restart_header(MLPDecodeContext *m, BitstreamContext *bc,\n\n                               const uint8_t *buf, unsigned int substr)\n\n{\n\n    SubStream *s = &m->substream[substr];\n\n    unsigned int ch;\n\n    int sync_word, tmp;\n\n    uint8_t checksum;\n\n    uint8_t lossless_check;\n\n    int start_count = bitstream_tell(bc);\n\n    int min_channel, max_channel, max_matrix_channel;\n\n    const int std_max_matrix_channel = m->avctx->codec_id == AV_CODEC_ID_MLP\n\n                                     ? MAX_MATRIX_CHANNEL_MLP\n\n                                     : MAX_MATRIX_CHANNEL_TRUEHD;\n\n\n\n    sync_word = bitstream_read(bc, 13);\n\n\n\n    if (sync_word != 0x31ea >> 1) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"restart header sync incorrect (got 0x%04x)\\n\", sync_word);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->noise_type = bitstream_read_bit(bc);\n\n\n\n    if (m->avctx->codec_id == AV_CODEC_ID_MLP && s->noise_type) {\n\n        av_log(m->avctx, AV_LOG_ERROR, \"MLP must have 0x31ea sync word.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bitstream_skip(bc, 16); /* Output timestamp */\n\n\n\n    min_channel        = bitstream_read(bc, 4);\n\n    max_channel        = bitstream_read(bc, 4);\n\n    max_matrix_channel = bitstream_read(bc, 4);\n\n\n\n    if (max_matrix_channel > std_max_matrix_channel) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Max matrix channel cannot be greater than %d.\\n\",\n\n               max_matrix_channel);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (max_channel != max_matrix_channel) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Max channel must be equal max matrix channel.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* This should happen for TrueHD streams with >6 channels and MLP's noise\n\n     * type. It is not yet known if this is allowed. */\n\n    if (s->max_channel > MAX_MATRIX_CHANNEL_MLP && !s->noise_type) {\n\n        avpriv_request_sample(m->avctx,\n\n                              \"%d channels (more than the \"\n\n                              \"maximum supported by the decoder)\",\n\n                              s->max_channel + 2);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (min_channel > max_channel) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Substream min channel cannot be greater than max channel.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->min_channel        = min_channel;\n\n    s->max_channel        = max_channel;\n\n    s->max_matrix_channel = max_matrix_channel;\n\n\n\n    if (m->avctx->request_channel_layout && (s->mask & m->avctx->request_channel_layout) ==\n\n        m->avctx->request_channel_layout && m->max_decoded_substream > substr) {\n\n        av_log(m->avctx, AV_LOG_DEBUG,\n\n               \"Extracting %d-channel downmix (0x%\"PRIx64\") from substream %d. \"\n\n               \"Further substreams will be skipped.\\n\",\n\n               s->max_channel + 1, s->mask, substr);\n\n        m->max_decoded_substream = substr;\n\n    }\n\n\n\n    s->noise_shift   = bitstream_read(bc,  4);\n\n    s->noisegen_seed = bitstream_read(bc, 23);\n\n\n\n    bitstream_skip(bc, 19);\n\n\n\n    s->data_check_present = bitstream_read_bit(bc);\n\n    lossless_check = bitstream_read(bc, 8);\n\n    if (substr == m->max_decoded_substream\n\n        && s->lossless_check_data != 0xffffffff) {\n\n        tmp = xor_32_to_8(s->lossless_check_data);\n\n        if (tmp != lossless_check)\n\n            av_log(m->avctx, AV_LOG_WARNING,\n\n                   \"Lossless check failed - expected %02x, calculated %02x.\\n\",\n\n                   lossless_check, tmp);\n\n    }\n\n\n\n    bitstream_skip(bc, 16);\n\n\n\n    memset(s->ch_assign, 0, sizeof(s->ch_assign));\n\n\n\n    for (ch = 0; ch <= s->max_matrix_channel; ch++) {\n\n        int ch_assign = bitstream_read(bc, 6);\n\n        if (m->avctx->codec_id == AV_CODEC_ID_TRUEHD) {\n\n            uint64_t channel = thd_channel_layout_extract_channel(s->mask,\n\n                                                                  ch_assign);\n\n            ch_assign = av_get_channel_layout_channel_index(s->mask,\n\n                                                            channel);\n\n        }\n\n        if (ch_assign < 0 || ch_assign > s->max_matrix_channel) {\n\n            avpriv_request_sample(m->avctx,\n\n                                  \"Assignment of matrix channel %d to invalid output channel %d\",\n\n                                  ch, ch_assign);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        s->ch_assign[ch_assign] = ch;\n\n    }\n\n\n\n    checksum = ff_mlp_restart_checksum(buf, bitstream_tell(bc) - start_count);\n\n\n\n    if (checksum != bitstream_read(bc, 8))\n\n        av_log(m->avctx, AV_LOG_ERROR, \"restart header checksum error\\n\");\n\n\n\n    /* Set default decoding parameters. */\n\n    s->param_presence_flags   = 0xff;\n\n    s->num_primitive_matrices = 0;\n\n    s->blocksize              = 8;\n\n    s->lossless_check_data    = 0;\n\n\n\n    memset(s->output_shift   , 0, sizeof(s->output_shift   ));\n\n    memset(s->quant_step_size, 0, sizeof(s->quant_step_size));\n\n\n\n    for (ch = s->min_channel; ch <= s->max_channel; ch++) {\n\n        ChannelParams *cp = &s->channel_params[ch];\n\n        cp->filter_params[FIR].order = 0;\n\n        cp->filter_params[IIR].order = 0;\n\n        cp->filter_params[FIR].shift = 0;\n\n        cp->filter_params[IIR].shift = 0;\n\n\n\n        /* Default audio coding is 24-bit raw PCM. */\n\n        cp->huff_offset      = 0;\n\n        cp->sign_huff_offset = -(1 << 23);\n\n        cp->codebook         = 0;\n\n        cp->huff_lsbs        = 24;\n\n    }\n\n\n\n    if (substr == m->max_decoded_substream) {\n\n        m->avctx->channels       = s->max_matrix_channel + 1;\n\n        m->avctx->channel_layout = s->mask;\n\n        m->dsp.mlp_pack_output = m->dsp.mlp_select_pack_output(s->ch_assign,\n\n                                                               s->output_shift,\n\n                                                               s->max_matrix_channel,\n\n                                                               m->avctx->sample_fmt == AV_SAMPLE_FMT_S32);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 5470, "_split": "valid", "_hash": "ca9e01877cb60d1e208cf86344b05b81"}
{"project": "FFmpeg", "commit_id": "636ced8e1dc8248a1353b416240b93d70ad03edb", "target": 1, "func": "static void do_streamcopy(InputStream *ist, OutputStream *ost, const AVPacket *pkt)\n\n{\n\n    OutputFile *of = output_files[ost->file_index];\n\n    int64_t ost_tb_start_time = av_rescale_q(of->start_time, AV_TIME_BASE_Q, ost->st->time_base);\n\n    AVPacket opkt;\n\n\n\n    av_init_packet(&opkt);\n\n\n\n    if ((!ost->frame_number && !(pkt->flags & AV_PKT_FLAG_KEY)) &&\n\n        !ost->copy_initial_nonkeyframes)\n\n        return;\n\n\n\n    if (of->recording_time != INT64_MAX &&\n\n        ist->last_dts >= of->recording_time + of->start_time) {\n\n        ost->finished = 1;\n\n        return;\n\n    }\n\n\n\n    /* force the input stream PTS */\n\n    if (ost->st->codec->codec_type == AVMEDIA_TYPE_AUDIO)\n\n        audio_size += pkt->size;\n\n    else if (ost->st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n        video_size += pkt->size;\n\n        ost->sync_opts++;\n\n    }\n\n\n\n    if (pkt->pts != AV_NOPTS_VALUE)\n\n        opkt.pts = av_rescale_q(pkt->pts, ist->st->time_base, ost->st->time_base) - ost_tb_start_time;\n\n    else\n\n        opkt.pts = AV_NOPTS_VALUE;\n\n\n\n    if (pkt->dts == AV_NOPTS_VALUE)\n\n        opkt.dts = av_rescale_q(ist->last_dts, AV_TIME_BASE_Q, ost->st->time_base);\n\n    else\n\n        opkt.dts = av_rescale_q(pkt->dts, ist->st->time_base, ost->st->time_base);\n\n    opkt.dts -= ost_tb_start_time;\n\n\n\n    opkt.duration = av_rescale_q(pkt->duration, ist->st->time_base, ost->st->time_base);\n\n    opkt.flags    = pkt->flags;\n\n\n\n    // FIXME remove the following 2 lines they shall be replaced by the bitstream filters\n\n    if (  ost->st->codec->codec_id != AV_CODEC_ID_H264\n\n       && ost->st->codec->codec_id != AV_CODEC_ID_MPEG1VIDEO\n\n       && ost->st->codec->codec_id != AV_CODEC_ID_MPEG2VIDEO\n\n       && ost->st->codec->codec_id != AV_CODEC_ID_VC1\n\n       ) {\n\n        if (av_parser_change(ist->st->parser, ost->st->codec, &opkt.data, &opkt.size, pkt->data, pkt->size, pkt->flags & AV_PKT_FLAG_KEY)) {\n\n            opkt.buf = av_buffer_create(opkt.data, opkt.size, av_buffer_default_free, NULL, 0);\n\n            if (!opkt.buf)\n\n                exit(1);\n\n        }\n\n    } else {\n\n        opkt.data = pkt->data;\n\n        opkt.size = pkt->size;\n\n    }\n\n\n\n    write_frame(of->ctx, &opkt, ost);\n\n    ost->st->codec->frame_number++;\n\n}\n", "idx": 5503, "_split": "valid", "_hash": "985cf5dec16203b2ee97ea4f9f8236c2"}
{"project": "FFmpeg", "commit_id": "f099cdaba38dfaf1eb666df17c6739da500ddbf8", "target": 1, "func": "static int init_pass2(MpegEncContext *s)\n\n{\n\n    RateControlContext *rcc = &s->rc_context;\n\n    AVCodecContext *a       = s->avctx;\n\n    int i, toobig;\n\n    double fps             = get_fps(s->avctx);\n\n    double complexity[5]   = { 0 }; // approximate bits at quant=1\n\n    uint64_t const_bits[5] = { 0 }; // quantizer independent bits\n\n    uint64_t all_const_bits;\n\n    uint64_t all_available_bits = (uint64_t)(s->bit_rate *\n\n                                             (double)rcc->num_entries / fps);\n\n    double rate_factor          = 0;\n\n    double step;\n\n    const int filter_size = (int)(a->qblur * 4) | 1;\n\n    double expected_bits;\n\n    double *qscale, *blurred_qscale, qscale_sum;\n\n\n\n    /* find complexity & const_bits & decide the pict_types */\n\n    for (i = 0; i < rcc->num_entries; i++) {\n\n        RateControlEntry *rce = &rcc->entry[i];\n\n\n\n        rce->new_pict_type                = rce->pict_type;\n\n        rcc->i_cplx_sum[rce->pict_type]  += rce->i_tex_bits * rce->qscale;\n\n        rcc->p_cplx_sum[rce->pict_type]  += rce->p_tex_bits * rce->qscale;\n\n        rcc->mv_bits_sum[rce->pict_type] += rce->mv_bits;\n\n        rcc->frame_count[rce->pict_type]++;\n\n\n\n        complexity[rce->new_pict_type] += (rce->i_tex_bits + rce->p_tex_bits) *\n\n                                          (double)rce->qscale;\n\n        const_bits[rce->new_pict_type] += rce->mv_bits + rce->misc_bits;\n\n    }\n\n\n\n    all_const_bits = const_bits[AV_PICTURE_TYPE_I] +\n\n                     const_bits[AV_PICTURE_TYPE_P] +\n\n                     const_bits[AV_PICTURE_TYPE_B];\n\n\n\n    if (all_available_bits < all_const_bits) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"requested bitrate is too low\\n\");\n\n        return -1;\n\n    }\n\n\n\n    qscale         = av_malloc(sizeof(double) * rcc->num_entries);\n\n    blurred_qscale = av_malloc(sizeof(double) * rcc->num_entries);\n\n    toobig = 0;\n\n\n\n    for (step = 256 * 256; step > 0.0000001; step *= 0.5) {\n\n        expected_bits = 0;\n\n        rate_factor  += step;\n\n\n\n        rcc->buffer_index = s->avctx->rc_buffer_size / 2;\n\n\n\n        /* find qscale */\n\n        for (i = 0; i < rcc->num_entries; i++) {\n\n            RateControlEntry *rce = &rcc->entry[i];\n\n\n\n            qscale[i] = get_qscale(s, &rcc->entry[i], rate_factor, i);\n\n            rcc->last_qscale_for[rce->pict_type] = qscale[i];\n\n        }\n\n        assert(filter_size % 2 == 1);\n\n\n\n        /* fixed I/B QP relative to P mode */\n\n        for (i = FFMAX(0, rcc->num_entries - 300); i < rcc->num_entries; i++) {\n\n            RateControlEntry *rce = &rcc->entry[i];\n\n\n\n            qscale[i] = get_diff_limited_q(s, rce, qscale[i]);\n\n        }\n\n\n\n        for (i = rcc->num_entries - 1; i >= 0; i--) {\n\n            RateControlEntry *rce = &rcc->entry[i];\n\n\n\n            qscale[i] = get_diff_limited_q(s, rce, qscale[i]);\n\n        }\n\n\n\n        /* smooth curve */\n\n        for (i = 0; i < rcc->num_entries; i++) {\n\n            RateControlEntry *rce = &rcc->entry[i];\n\n            const int pict_type   = rce->new_pict_type;\n\n            int j;\n\n            double q = 0.0, sum = 0.0;\n\n\n\n            for (j = 0; j < filter_size; j++) {\n\n                int index    = i + j - filter_size / 2;\n\n                double d     = index - i;\n\n                double coeff = a->qblur == 0 ? 1.0 : exp(-d * d / (a->qblur * a->qblur));\n\n\n\n                if (index < 0 || index >= rcc->num_entries)\n\n                    continue;\n\n                if (pict_type != rcc->entry[index].new_pict_type)\n\n                    continue;\n\n                q   += qscale[index] * coeff;\n\n                sum += coeff;\n\n            }\n\n            blurred_qscale[i] = q / sum;\n\n        }\n\n\n\n        /* find expected bits */\n\n        for (i = 0; i < rcc->num_entries; i++) {\n\n            RateControlEntry *rce = &rcc->entry[i];\n\n            double bits;\n\n\n\n            rce->new_qscale = modify_qscale(s, rce, blurred_qscale[i], i);\n\n\n\n            bits  = qp2bits(rce, rce->new_qscale) + rce->mv_bits + rce->misc_bits;\n\n            bits += 8 * ff_vbv_update(s, bits);\n\n\n\n            rce->expected_bits = expected_bits;\n\n            expected_bits     += bits;\n\n        }\n\n\n\n        av_dlog(s->avctx,\n\n                \"expected_bits: %f all_available_bits: %d rate_factor: %f\\n\",\n\n                expected_bits, (int)all_available_bits, rate_factor);\n\n        if (expected_bits > all_available_bits) {\n\n            rate_factor -= step;\n\n            ++toobig;\n\n        }\n\n    }\n\n    av_free(qscale);\n\n    av_free(blurred_qscale);\n\n\n\n    /* check bitrate calculations and print info */\n\n    qscale_sum = 0.0;\n\n    for (i = 0; i < rcc->num_entries; i++) {\n\n        av_dlog(s, \"[lavc rc] entry[%d].new_qscale = %.3f  qp = %.3f\\n\",\n\n                i,\n\n                rcc->entry[i].new_qscale,\n\n                rcc->entry[i].new_qscale / FF_QP2LAMBDA);\n\n        qscale_sum += av_clip(rcc->entry[i].new_qscale / FF_QP2LAMBDA,\n\n                              s->avctx->qmin, s->avctx->qmax);\n\n    }\n\n    assert(toobig <= 40);\n\n    av_log(s->avctx, AV_LOG_DEBUG,\n\n           \"[lavc rc] requested bitrate: %d bps  expected bitrate: %d bps\\n\",\n\n           s->bit_rate,\n\n           (int)(expected_bits / ((double)all_available_bits / s->bit_rate)));\n\n    av_log(s->avctx, AV_LOG_DEBUG,\n\n           \"[lavc rc] estimated target average qp: %.3f\\n\",\n\n           (float)qscale_sum / rcc->num_entries);\n\n    if (toobig == 0) {\n\n        av_log(s->avctx, AV_LOG_INFO,\n\n               \"[lavc rc] Using all of requested bitrate is not \"\n\n               \"necessary for this video with these parameters.\\n\");\n\n    } else if (toobig == 40) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"[lavc rc] Error: bitrate too low for this video \"\n\n               \"with these parameters.\\n\");\n\n        return -1;\n\n    } else if (fabs(expected_bits / all_available_bits - 1.0) > 0.01) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"[lavc rc] Error: 2pass curve failed to converge\\n\");\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 5517, "_split": "valid", "_hash": "bb4235de9bd1a5e874e803c26be53afa"}
{"project": "FFmpeg", "commit_id": "69c34a6ac986e31b5286a1d566617ec25b93e6a7", "target": 0, "func": "static void paint_mouse_pointer(XImage *image, AVFormatContext *s1)\n\n{\n\n    X11GrabContext *s = s1->priv_data;\n\n    int x_off    = s->x_off;\n\n    int y_off    = s->y_off;\n\n    int width    = s->width;\n\n    int height   = s->height;\n\n    Display *dpy = s->dpy;\n\n    XFixesCursorImage *xcim;\n\n    int x, y;\n\n    int line, column;\n\n    int to_line, to_column;\n\n    int pixstride = image->bits_per_pixel >> 3;\n\n    /* Warning: in its insanity, xlib provides unsigned image data through a\n\n     * char* pointer, so we have to make it uint8_t to make things not break.\n\n     * Anyone who performs further investigation of the xlib API likely risks\n\n     * permanent brain damage. */\n\n    uint8_t *pix = image->data;\n\n    Window root;\n\n    XSetWindowAttributes attr;\n\n\n\n    /* Code doesn't currently support 16-bit or PAL8 */\n\n    if (image->bits_per_pixel != 24 && image->bits_per_pixel != 32)\n\n        return;\n\n\n\n    if (!s->c)\n\n        s->c = XCreateFontCursor(dpy, XC_left_ptr);\n\n    root = DefaultRootWindow(dpy);\n\n    attr.cursor = s->c;\n\n    XChangeWindowAttributes(dpy, root, CWCursor, &attr);\n\n\n\n    xcim = XFixesGetCursorImage(dpy);\n\n    if (!xcim) {\n\n        av_log(s1, AV_LOG_WARNING,\n\n               \"XFixes extension not available, impossible to draw cursor\\n\");\n\n        s->draw_mouse = 0;\n\n        return;\n\n    }\n\n\n\n    x = xcim->x - xcim->xhot;\n\n    y = xcim->y - xcim->yhot;\n\n\n\n    to_line   = FFMIN((y + xcim->height), (height + y_off));\n\n    to_column = FFMIN((x + xcim->width),  (width  + x_off));\n\n\n\n    for (line = FFMAX(y, y_off); line < to_line; line++) {\n\n        for (column = FFMAX(x, x_off); column < to_column; column++) {\n\n            int xcim_addr  = (line  - y)     * xcim->width + column - x;\n\n            int image_addr = ((line - y_off) * width       + column - x_off) * pixstride;\n\n            int r          = (uint8_t)(xcim->pixels[xcim_addr] >>  0);\n\n            int g          = (uint8_t)(xcim->pixels[xcim_addr] >>  8);\n\n            int b          = (uint8_t)(xcim->pixels[xcim_addr] >> 16);\n\n            int a          = (uint8_t)(xcim->pixels[xcim_addr] >> 24);\n\n\n\n            if (a == 255) {\n\n                pix[image_addr + 0] = r;\n\n                pix[image_addr + 1] = g;\n\n                pix[image_addr + 2] = b;\n\n            } else if (a) {\n\n                /* pixel values from XFixesGetCursorImage come premultiplied by alpha */\n\n                pix[image_addr + 0] = r + (pix[image_addr + 0] * (255 - a) + 255 / 2) / 255;\n\n                pix[image_addr + 1] = g + (pix[image_addr + 1] * (255 - a) + 255 / 2) / 255;\n\n                pix[image_addr + 2] = b + (pix[image_addr + 2] * (255 - a) + 255 / 2) / 255;\n\n            }\n\n        }\n\n    }\n\n\n\n    XFree(xcim);\n\n    xcim = NULL;\n\n}\n", "idx": 5523, "_split": "valid", "_hash": "636c29ed02501ccb20042ae7f2e072cf"}
{"project": "FFmpeg", "commit_id": "75ef6898846fb14dd47691cad6ce8850c9106723", "target": 1, "func": "static FFPsyWindowInfo psy_3gpp_window(FFPsyContext *ctx,\n\n                                       const int16_t *audio, const int16_t *la,\n\n                                       int channel, int prev_type)\n\n{\n\n    int i, j;\n\n    int br               = ctx->avctx->bit_rate / ctx->avctx->channels;\n\n    int attack_ratio     = br <= 16000 ? 18 : 10;\n\n    Psy3gppContext *pctx = (Psy3gppContext*) ctx->model_priv_data;\n\n    Psy3gppChannel *pch  = &pctx->ch[channel];\n\n    uint8_t grouping     = 0;\n\n    FFPsyWindowInfo wi;\n\n\n\n    memset(&wi, 0, sizeof(wi));\n\n    if (la) {\n\n        float s[8], v;\n\n        int switch_to_eight = 0;\n\n        float sum = 0.0, sum2 = 0.0;\n\n        int attack_n = 0;\n\n        for (i = 0; i < 8; i++) {\n\n            for (j = 0; j < 128; j++) {\n\n                v = iir_filter(la[(i*128+j)*ctx->avctx->channels], pch->iir_state);\n\n                sum += v*v;\n\n            }\n\n            s[i]  = sum;\n\n            sum2 += sum;\n\n        }\n\n        for (i = 0; i < 8; i++) {\n\n            if (s[i] > pch->win_energy * attack_ratio) {\n\n                attack_n        = i + 1;\n\n                switch_to_eight = 1;\n\n                break;\n\n            }\n\n        }\n\n        pch->win_energy = pch->win_energy*7/8 + sum2/64;\n\n\n\n        wi.window_type[1] = prev_type;\n\n        switch (prev_type) {\n\n        case ONLY_LONG_SEQUENCE:\n\n            wi.window_type[0] = switch_to_eight ? LONG_START_SEQUENCE : ONLY_LONG_SEQUENCE;\n\n            break;\n\n        case LONG_START_SEQUENCE:\n\n            wi.window_type[0] = EIGHT_SHORT_SEQUENCE;\n\n            grouping = pch->next_grouping;\n\n            break;\n\n        case LONG_STOP_SEQUENCE:\n\n            wi.window_type[0] = ONLY_LONG_SEQUENCE;\n\n            break;\n\n        case EIGHT_SHORT_SEQUENCE:\n\n            wi.window_type[0] = switch_to_eight ? EIGHT_SHORT_SEQUENCE : LONG_STOP_SEQUENCE;\n\n            grouping = switch_to_eight ? pch->next_grouping : 0;\n\n            break;\n\n        }\n\n        pch->next_grouping = window_grouping[attack_n];\n\n    } else {\n\n        for (i = 0; i < 3; i++)\n\n            wi.window_type[i] = prev_type;\n\n        grouping = (prev_type == EIGHT_SHORT_SEQUENCE) ? window_grouping[0] : 0;\n\n    }\n\n\n\n    wi.window_shape   = 1;\n\n    if (wi.window_type[0] != EIGHT_SHORT_SEQUENCE) {\n\n        wi.num_windows = 1;\n\n        wi.grouping[0] = 1;\n\n    } else {\n\n        int lastgrp = 0;\n\n        wi.num_windows = 8;\n\n        for (i = 0; i < 8; i++) {\n\n            if (!((grouping >> i) & 1))\n\n                lastgrp = i;\n\n            wi.grouping[lastgrp]++;\n\n        }\n\n    }\n\n\n\n    return wi;\n\n}\n", "idx": 5611, "_split": "valid", "_hash": "cd78ec72965636dc6f2e543e26cd8579"}
{"project": "FFmpeg", "commit_id": "f015e411d78d9e9ae179170beafe4951b778ac50", "target": 1, "func": "static int amr_read_packet(AVFormatContext *s,\n\n                          AVPacket *pkt)\n\n{\n\n    AVCodecContext *enc = s->streams[0]->codec;\n\n    int read, size, toc, mode;\n\n\n\n    if (url_feof(&s->pb))\n\n    {\n\n        return AVERROR_IO;\n\n    }\n\n\n\n//FIXME this is wrong, this should rather be in a AVParset\n\n    toc=get_byte(&s->pb);\n\n    mode = (toc >> 3) & 0x0F;\n\n\n\n    if (enc->codec_id == CODEC_ID_AMR_NB)\n\n    {\n\n        static const uint8_t packed_size[16] = {12, 13, 15, 17, 19, 20, 26, 31, 5, 0, 0, 0, 0, 0, 0, 0};\n\n\n\n        size=packed_size[mode]+1;\n\n    }\n\n    else if(enc->codec_id == CODEC_ID_AMR_WB)\n\n    {\n\n        static uint8_t packed_size[16] = {18, 24, 33, 37, 41, 47, 51, 59, 61, 6, 6, 0, 0, 0, 1, 1};\n\n\n\n        size=packed_size[mode];\n\n    }\n\n    else\n\n    {\n\n        assert(0);\n\n    }\n\n\n\n    if ( (size==0) || av_new_packet(pkt, size))\n\n    {\n\n        return AVERROR_IO;\n\n    }\n\n\n\n    pkt->stream_index = 0;\n\n    pkt->pos= url_ftell(&s->pb);\n\n    pkt->data[0]=toc;\n\n    pkt->duration= enc->codec_id == CODEC_ID_AMR_NB ? 160 : 320;\n\n    read = get_buffer(&s->pb, pkt->data+1, size-1);\n\n\n\n    if (read != size-1)\n\n    {\n\n        av_free_packet(pkt);\n\n        return AVERROR_IO;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 5715, "_split": "valid", "_hash": "4156b6ab8ae9a9b43b63f8ac3b06016e"}
{"project": "FFmpeg", "commit_id": "575d494de561049f36f9c5492e05c7d83dd78e75", "target": 1, "func": "static void park_frame_worker_threads(FrameThreadContext *fctx, int thread_count)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < thread_count; i++) {\n\n        PerThreadContext *p = &fctx->threads[i];\n\n\n\n        if (p->state != STATE_INPUT_READY) {\n\n            pthread_mutex_lock(&p->progress_mutex);\n\n            while (p->state != STATE_INPUT_READY)\n\n                pthread_cond_wait(&p->output_cond, &p->progress_mutex);\n\n            pthread_mutex_unlock(&p->progress_mutex);\n\n        }\n\n\n    }\n\n}", "idx": 5729, "_split": "valid", "_hash": "c5bf2b9c00c72251f0e537d0c305229d"}
{"project": "FFmpeg", "commit_id": "559fd1e79524ca47efde195e28feb4499dd48761", "target": 1, "func": "static int nut_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    NUTContext *nut = s->priv_data;\n\n    ByteIOContext *bc = &s->pb;\n\n    int i, frame_code=0, ret, skip;\n\n    int64_t ts, back_ptr;\n\n\n\n    for(;;){\n\n        int64_t pos= url_ftell(bc);\n\n        uint64_t tmp= nut->next_startcode;\n\n        nut->next_startcode=0;\n\n\n\n        if (url_feof(bc))\n\n            return -1;\n\n\n\n        if(tmp){\n\n            pos-=8;\n\n        }else{\n\n            frame_code = get_byte(bc);\n\n            if(frame_code == 'N'){\n\n                tmp= frame_code;\n\n                for(i=1; i<8; i++)\n\n                    tmp = (tmp<<8) + get_byte(bc);\n\n            }\n\n        }\n\n        switch(tmp){\n\n        case MAIN_STARTCODE:\n\n        case STREAM_STARTCODE:\n\n        case INDEX_STARTCODE:\n\n            skip= get_packetheader(nut, bc, 0);\n\n            url_fseek(bc, skip, SEEK_CUR);\n\n            break;\n\n        case INFO_STARTCODE:\n\n            if(decode_info_header(nut)<0)\n\n                goto resync;\n\n            break;\n\n        case SYNCPOINT_STARTCODE:\n\n            if(decode_syncpoint(nut, &ts, &back_ptr)<0)\n\n                goto resync;\n\n            frame_code = get_byte(bc);\n\n        case 0:\n\n            ret= decode_frame(nut, pkt, frame_code);\n\n            if(ret==0)\n\n                return 0;\n\n            else if(ret==1) //ok but discard packet\n\n                break;\n\n        default:\n\nresync:\n\nav_log(s, AV_LOG_DEBUG, \"syncing from %\"PRId64\"\\n\", pos);\n\n            tmp= find_any_startcode(bc, nut->last_syncpoint_pos+1);\n\n            if(tmp==0)\n\n                return -1;\n\nav_log(s, AV_LOG_DEBUG, \"sync\\n\");\n\n            nut->next_startcode= tmp;\n\n        }\n\n    }\n\n}\n", "idx": 5741, "_split": "valid", "_hash": "99e201745afa499c62c9b4e626c81df4"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void rgb8tobgr8(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tlong i;\n\n\tlong num_pixels = src_size;\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t    unsigned b,g,r;\n\n\t    register uint8_t rgb;\n\n\t    rgb = src[i];\n\n\t    r = (rgb&0x07);\n\n\t    g = (rgb&0x38)>>3;\n\n\t    b = (rgb&0xC0)>>6;\n\n\t    dst[i] = ((b<<1)&0x07) | ((g&0x07)<<3) | ((r&0x03)<<6);\n\n\t}\n\n}\n", "idx": 5757, "_split": "valid", "_hash": "2f098a5ee40cab97ea2628319977f139"}
{"project": "FFmpeg", "commit_id": "dae006d7d7e29b361e28a32b2de2699f9bf4d709", "target": 0, "func": "static av_always_inline void hl_decode_mb_internal(H264Context *h, int simple){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_x= s->mb_x;\n\n    const int mb_y= s->mb_y;\n\n    const int mb_xy= h->mb_xy;\n\n    const int mb_type= s->current_picture.mb_type[mb_xy];\n\n    uint8_t  *dest_y, *dest_cb, *dest_cr;\n\n    int linesize, uvlinesize /*dct_offset*/;\n\n    int i;\n\n    int *block_offset = &h->block_offset[0];\n\n    const int transform_bypass = !simple && (s->qscale == 0 && h->sps.transform_bypass);\n\n    const int is_h264 = simple || s->codec_id == CODEC_ID_H264;\n\n    void (*idct_add)(uint8_t *dst, DCTELEM *block, int stride);\n\n    void (*idct_dc_add)(uint8_t *dst, DCTELEM *block, int stride);\n\n\n\n    dest_y  = s->current_picture.data[0] + (mb_x + mb_y * s->linesize  ) * 16;\n\n    dest_cb = s->current_picture.data[1] + (mb_x + mb_y * s->uvlinesize) * 8;\n\n    dest_cr = s->current_picture.data[2] + (mb_x + mb_y * s->uvlinesize) * 8;\n\n\n\n    s->dsp.prefetch(dest_y + (s->mb_x&3)*4*s->linesize + 64, s->linesize, 4);\n\n    s->dsp.prefetch(dest_cb + (s->mb_x&7)*s->uvlinesize + 64, dest_cr - dest_cb, 2);\n\n\n\n    if (!simple && MB_FIELD) {\n\n        linesize   = h->mb_linesize   = s->linesize * 2;\n\n        uvlinesize = h->mb_uvlinesize = s->uvlinesize * 2;\n\n        block_offset = &h->block_offset[24];\n\n        if(mb_y&1){ //FIXME move out of this function?\n\n            dest_y -= s->linesize*15;\n\n            dest_cb-= s->uvlinesize*7;\n\n            dest_cr-= s->uvlinesize*7;\n\n        }\n\n        if(FRAME_MBAFF) {\n\n            int list;\n\n            for(list=0; list<h->list_count; list++){\n\n                if(!USES_LIST(mb_type, list))\n\n                    continue;\n\n                if(IS_16X16(mb_type)){\n\n                    int8_t *ref = &h->ref_cache[list][scan8[0]];\n\n                    fill_rectangle(ref, 4, 4, 8, (16+*ref)^(s->mb_y&1), 1);\n\n                }else{\n\n                    for(i=0; i<16; i+=4){\n\n                        int ref = h->ref_cache[list][scan8[i]];\n\n                        if(ref >= 0)\n\n                            fill_rectangle(&h->ref_cache[list][scan8[i]], 2, 2, 8, (16+ref)^(s->mb_y&1), 1);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    } else {\n\n        linesize   = h->mb_linesize   = s->linesize;\n\n        uvlinesize = h->mb_uvlinesize = s->uvlinesize;\n\n//        dct_offset = s->linesize * 16;\n\n    }\n\n\n\n    if (!simple && IS_INTRA_PCM(mb_type)) {\n\n        for (i=0; i<16; i++) {\n\n            memcpy(dest_y + i*  linesize, h->mb       + i*8, 16);\n\n        }\n\n        for (i=0; i<8; i++) {\n\n            memcpy(dest_cb+ i*uvlinesize, h->mb + 128 + i*4,  8);\n\n            memcpy(dest_cr+ i*uvlinesize, h->mb + 160 + i*4,  8);\n\n        }\n\n    } else {\n\n        if(IS_INTRA(mb_type)){\n\n            if(h->deblocking_filter)\n\n                xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize, uvlinesize, 1, simple);\n\n\n\n            if(simple || !ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n                h->hpc.pred8x8[ h->chroma_pred_mode ](dest_cb, uvlinesize);\n\n                h->hpc.pred8x8[ h->chroma_pred_mode ](dest_cr, uvlinesize);\n\n            }\n\n\n\n            if(IS_INTRA4x4(mb_type)){\n\n                if(simple || !s->encoding){\n\n                    if(IS_8x8DCT(mb_type)){\n\n                        if(transform_bypass){\n\n                            idct_dc_add =\n\n                            idct_add    = s->dsp.add_pixels8;\n\n                        }else if(IS_8x8DCT(mb_type)){\n\n                            idct_dc_add = s->dsp.h264_idct8_dc_add;\n\n                            idct_add    = s->dsp.h264_idct8_add;\n\n                        }\n\n                        for(i=0; i<16; i+=4){\n\n                            uint8_t * const ptr= dest_y + block_offset[i];\n\n                            const int dir= h->intra4x4_pred_mode_cache[ scan8[i] ];\n\n                            if(transform_bypass && h->sps.profile_idc==244 && dir<=1){\n\n                                h->hpc.pred8x8l_add[dir](ptr, h->mb + i*16, linesize);\n\n                            }else{\n\n                                const int nnz = h->non_zero_count_cache[ scan8[i] ];\n\n                                h->hpc.pred8x8l[ dir ](ptr, (h->topleft_samples_available<<i)&0x8000,\n\n                                                            (h->topright_samples_available<<i)&0x4000, linesize);\n\n                                if(nnz){\n\n                                    if(nnz == 1 && h->mb[i*16])\n\n                                        idct_dc_add(ptr, h->mb + i*16, linesize);\n\n                                    else\n\n                                        idct_add   (ptr, h->mb + i*16, linesize);\n\n                                }\n\n                            }\n\n                        }\n\n                    }else{\n\n                        if(transform_bypass){\n\n                            idct_dc_add =\n\n                            idct_add    = s->dsp.add_pixels4;\n\n                        }else{\n\n                            idct_dc_add = s->dsp.h264_idct_dc_add;\n\n                            idct_add    = s->dsp.h264_idct_add;\n\n                        }\n\n                    for(i=0; i<16; i++){\n\n                        uint8_t * const ptr= dest_y + block_offset[i];\n\n                        const int dir= h->intra4x4_pred_mode_cache[ scan8[i] ];\n\n\n\n                        if(transform_bypass && h->sps.profile_idc==244 && dir<=1){\n\n                            h->hpc.pred4x4_add[dir](ptr, h->mb + i*16, linesize);\n\n                        }else{\n\n                            uint8_t *topright;\n\n                            int nnz, tr;\n\n                            if(dir == DIAG_DOWN_LEFT_PRED || dir == VERT_LEFT_PRED){\n\n                                const int topright_avail= (h->topright_samples_available<<i)&0x8000;\n\n                                assert(mb_y || linesize <= block_offset[i]);\n\n                                if(!topright_avail){\n\n                                    tr= ptr[3 - linesize]*0x01010101;\n\n                                    topright= (uint8_t*) &tr;\n\n                                }else\n\n                                    topright= ptr + 4 - linesize;\n\n                            }else\n\n                                topright= NULL;\n\n\n\n                            h->hpc.pred4x4[ dir ](ptr, topright, linesize);\n\n                            nnz = h->non_zero_count_cache[ scan8[i] ];\n\n                            if(nnz){\n\n                                if(is_h264){\n\n                                    if(nnz == 1 && h->mb[i*16])\n\n                                        idct_dc_add(ptr, h->mb + i*16, linesize);\n\n                                    else\n\n                                        idct_add   (ptr, h->mb + i*16, linesize);\n\n                                }else\n\n                                    svq3_add_idct_c(ptr, h->mb + i*16, linesize, s->qscale, 0);\n\n                            }\n\n                        }\n\n                    }\n\n                    }\n\n                }\n\n            }else{\n\n                h->hpc.pred16x16[ h->intra16x16_pred_mode ](dest_y , linesize);\n\n                if(is_h264){\n\n                    if(!transform_bypass)\n\n                        h264_luma_dc_dequant_idct_c(h->mb, s->qscale, h->dequant4_coeff[0][s->qscale][0]);\n\n                }else\n\n                    svq3_luma_dc_dequant_idct_c(h->mb, s->qscale);\n\n            }\n\n            if(h->deblocking_filter)\n\n                xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize, uvlinesize, 0, simple);\n\n        }else if(is_h264){\n\n            hl_motion(h, dest_y, dest_cb, dest_cr,\n\n                      s->me.qpel_put, s->dsp.put_h264_chroma_pixels_tab,\n\n                      s->me.qpel_avg, s->dsp.avg_h264_chroma_pixels_tab,\n\n                      s->dsp.weight_h264_pixels_tab, s->dsp.biweight_h264_pixels_tab);\n\n        }\n\n\n\n\n\n        if(!IS_INTRA4x4(mb_type)){\n\n            if(is_h264){\n\n                if(IS_INTRA16x16(mb_type)){\n\n                    if(transform_bypass){\n\n                        if(h->sps.profile_idc==244 && (h->intra16x16_pred_mode==VERT_PRED8x8 || h->intra16x16_pred_mode==HOR_PRED8x8)){\n\n                            h->hpc.pred16x16_add[h->intra16x16_pred_mode](dest_y, block_offset, h->mb, linesize);\n\n                        }else{\n\n                            for(i=0; i<16; i++){\n\n                                if(h->non_zero_count_cache[ scan8[i] ] || h->mb[i*16])\n\n                                    s->dsp.add_pixels4(dest_y + block_offset[i], h->mb + i*16, linesize);\n\n                            }\n\n                        }\n\n                    }else{\n\n                         s->dsp.h264_idct_add16intra(dest_y, block_offset, h->mb, linesize, h->non_zero_count_cache);\n\n                    }\n\n                }else if(h->cbp&15){\n\n                    if(transform_bypass){\n\n                        const int di = IS_8x8DCT(mb_type) ? 4 : 1;\n\n                        idct_add= IS_8x8DCT(mb_type) ? s->dsp.add_pixels8 : s->dsp.add_pixels4;\n\n                        for(i=0; i<16; i+=di){\n\n                            if(h->non_zero_count_cache[ scan8[i] ]){\n\n                                idct_add(dest_y + block_offset[i], h->mb + i*16, linesize);\n\n                            }\n\n                        }\n\n                    }else{\n\n                        if(IS_8x8DCT(mb_type)){\n\n                            s->dsp.h264_idct8_add4(dest_y, block_offset, h->mb, linesize, h->non_zero_count_cache);\n\n                        }else{\n\n                            s->dsp.h264_idct_add16(dest_y, block_offset, h->mb, linesize, h->non_zero_count_cache);\n\n                        }\n\n                    }\n\n                }\n\n            }else{\n\n                for(i=0; i<16; i++){\n\n                    if(h->non_zero_count_cache[ scan8[i] ] || h->mb[i*16]){ //FIXME benchmark weird rule, & below\n\n                        uint8_t * const ptr= dest_y + block_offset[i];\n\n                        svq3_add_idct_c(ptr, h->mb + i*16, linesize, s->qscale, IS_INTRA(mb_type) ? 1 : 0);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        if((simple || !ENABLE_GRAY || !(s->flags&CODEC_FLAG_GRAY)) && (h->cbp&0x30)){\n\n            uint8_t *dest[2] = {dest_cb, dest_cr};\n\n            if(transform_bypass){\n\n                idct_add = idct_dc_add = s->dsp.add_pixels4;\n\n            }else{\n\n                idct_add = s->dsp.h264_idct_add;\n\n                idct_dc_add = s->dsp.h264_idct_dc_add;\n\n                chroma_dc_dequant_idct_c(h->mb + 16*16, h->chroma_qp[0], h->dequant4_coeff[IS_INTRA(mb_type) ? 1:4][h->chroma_qp[0]][0]);\n\n                chroma_dc_dequant_idct_c(h->mb + 16*16+4*16, h->chroma_qp[1], h->dequant4_coeff[IS_INTRA(mb_type) ? 2:5][h->chroma_qp[1]][0]);\n\n            }\n\n            if(is_h264){\n\n                if(transform_bypass && IS_INTRA(mb_type) && h->sps.profile_idc==244 && (h->chroma_pred_mode==VERT_PRED8x8 || h->chroma_pred_mode==HOR_PRED8x8)){\n\n                    h->hpc.pred8x8_add[h->chroma_pred_mode](dest[0], block_offset + 16, h->mb + 16*16, uvlinesize);\n\n                    h->hpc.pred8x8_add[h->chroma_pred_mode](dest[1], block_offset + 20, h->mb + 20*16, uvlinesize);\n\n                }else{\n\n                    for(i=16; i<16+8; i++){\n\n                        if(h->non_zero_count_cache[ scan8[i] ])\n\n                            idct_add   (dest[(i&4)>>2] + block_offset[i], h->mb + i*16, uvlinesize);\n\n                        else if(h->mb[i*16])\n\n                            idct_dc_add(dest[(i&4)>>2] + block_offset[i], h->mb + i*16, uvlinesize);\n\n                    }\n\n                }\n\n            }else{\n\n                for(i=16; i<16+8; i++){\n\n                    if(h->non_zero_count_cache[ scan8[i] ] || h->mb[i*16]){\n\n                        uint8_t * const ptr= dest[(i&4)>>2] + block_offset[i];\n\n                        svq3_add_idct_c(ptr, h->mb + i*16, uvlinesize, chroma_qp[s->qscale + 12] - 12, 2);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n    if(h->deblocking_filter) {\n\n        backup_mb_border(h, dest_y, dest_cb, dest_cr, linesize, uvlinesize, simple);\n\n        fill_caches(h, mb_type, 1); //FIXME don't fill stuff which isn't used by filter_mb\n\n        h->chroma_qp[0] = get_chroma_qp(h, 0, s->current_picture.qscale_table[mb_xy]);\n\n        h->chroma_qp[1] = get_chroma_qp(h, 1, s->current_picture.qscale_table[mb_xy]);\n\n        if (!simple && FRAME_MBAFF) {\n\n            filter_mb     (h, mb_x, mb_y, dest_y, dest_cb, dest_cr, linesize, uvlinesize);\n\n        } else {\n\n            filter_mb_fast(h, mb_x, mb_y, dest_y, dest_cb, dest_cr, linesize, uvlinesize);\n\n        }\n\n    }\n\n}\n", "idx": 5761, "_split": "valid", "_hash": "c0cabfc2d559acbe78f02d7435467314"}
{"project": "FFmpeg", "commit_id": "981e99ab99986935affad7c164ebdfe28e8ea7f8", "target": 1, "func": "static void sbr_hf_g_filt_c(int (*Y)[2], const int (*X_high)[40][2],\n\n                          const SoftFloat *g_filt, int m_max, intptr_t ixh)\n\n{\n\n    int m;\n\n    int64_t accu;\n\n\n\n    for (m = 0; m < m_max; m++) {\n\n        int64_t r = 1LL << (22-g_filt[m].exp);\n\n        accu = (int64_t)X_high[m][ixh][0] * ((g_filt[m].mant + 0x40)>>7);\n\n        Y[m][0] = (int)((accu + r) >> (23-g_filt[m].exp));\n\n\n\n        accu = (int64_t)X_high[m][ixh][1] * ((g_filt[m].mant + 0x40)>>7);\n\n        Y[m][1] = (int)((accu + r) >> (23-g_filt[m].exp));\n\n    }\n\n}\n", "idx": 5790, "_split": "valid", "_hash": "d1887fff4ea2a4dded068510a864905d"}
{"project": "FFmpeg", "commit_id": "15e9c4afdc8efbf8da86bb3f7eaf374310b44bf8", "target": 0, "func": "static int output_frame(AVFilterLink *outlink, int need_request)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    MixContext      *s = ctx->priv;\n\n    AVFrame *out_buf, *in_buf;\n\n    int nb_samples, ns, ret, i;\n\n\n\n    ret = calc_active_inputs(s);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (s->input_state[0] & INPUT_ON) {\n\n        /* first input live: use the corresponding frame size */\n\n        nb_samples = frame_list_next_frame_size(s->frame_list);\n\n        for (i = 1; i < s->nb_inputs; i++) {\n\n            if (s->input_state[i] & INPUT_ON) {\n\n                ns = av_audio_fifo_size(s->fifos[i]);\n\n                if (ns < nb_samples) {\n\n                    if (!(s->input_state[i] & INPUT_EOF))\n\n                        /* unclosed input with not enough samples */\n\n                        return need_request ? ff_request_frame(ctx->inputs[i]) : 0;\n\n                    /* closed input to drain */\n\n                    nb_samples = ns;\n\n                }\n\n            }\n\n        }\n\n    } else {\n\n        /* first input closed: use the available samples */\n\n        nb_samples = INT_MAX;\n\n        for (i = 1; i < s->nb_inputs; i++) {\n\n            if (s->input_state[i] & INPUT_ON) {\n\n                ns = av_audio_fifo_size(s->fifos[i]);\n\n                nb_samples = FFMIN(nb_samples, ns);\n\n            }\n\n        }\n\n        if (nb_samples == INT_MAX)\n\n            return AVERROR_EOF;\n\n    }\n\n\n\n    s->next_pts = frame_list_next_pts(s->frame_list);\n\n    frame_list_remove_samples(s->frame_list, nb_samples);\n\n\n\n    calculate_scales(s, nb_samples);\n\n\n\n    if (nb_samples == 0)\n\n        return 0;\n\n\n\n    out_buf = ff_get_audio_buffer(outlink, nb_samples);\n\n    if (!out_buf)\n\n        return AVERROR(ENOMEM);\n\n\n\n    in_buf = ff_get_audio_buffer(outlink, nb_samples);\n\n    if (!in_buf) {\n\n        av_frame_free(&out_buf);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    for (i = 0; i < s->nb_inputs; i++) {\n\n        if (s->input_state[i] & INPUT_ON) {\n\n            int planes, plane_size, p;\n\n\n\n            av_audio_fifo_read(s->fifos[i], (void **)in_buf->extended_data,\n\n                               nb_samples);\n\n\n\n            planes     = s->planar ? s->nb_channels : 1;\n\n            plane_size = nb_samples * (s->planar ? 1 : s->nb_channels);\n\n            plane_size = FFALIGN(plane_size, 16);\n\n\n\n            if (out_buf->format == AV_SAMPLE_FMT_FLT ||\n\n                out_buf->format == AV_SAMPLE_FMT_FLTP) {\n\n                for (p = 0; p < planes; p++) {\n\n                    s->fdsp->vector_fmac_scalar((float *)out_buf->extended_data[p],\n\n                                                (float *) in_buf->extended_data[p],\n\n                                                s->input_scale[i], plane_size);\n\n                }\n\n            } else {\n\n                for (p = 0; p < planes; p++) {\n\n                    s->fdsp->vector_dmac_scalar((double *)out_buf->extended_data[p],\n\n                                                (double *) in_buf->extended_data[p],\n\n                                                s->input_scale[i], plane_size);\n\n                }\n\n            }\n\n        }\n\n    }\n\n    av_frame_free(&in_buf);\n\n\n\n    out_buf->pts = s->next_pts;\n\n    if (s->next_pts != AV_NOPTS_VALUE)\n\n        s->next_pts += nb_samples;\n\n\n\n    return ff_filter_frame(outlink, out_buf);\n\n}\n", "idx": 5815, "_split": "valid", "_hash": "d21df1cf157df050bca1115cedf5917c"}
{"project": "FFmpeg", "commit_id": "e9dea59f16d49e4fa03aa10447c8f4f7e902de76", "target": 0, "func": "make_setup_request (AVFormatContext *s, const char *host, int port, int protocol)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    int j, i, err;\n\n    RTSPStream *rtsp_st;\n\n    AVStream *st;\n\n    RTSPHeader reply1, *reply = &reply1;\n\n    char cmd[2048];\n\n\n\n    /* for each stream, make the setup request */\n\n    /* XXX: we assume the same server is used for the control of each\n\n       RTSP stream */\n\n\n\n    for(j = RTSP_RTP_PORT_MIN, i = 0; i < rt->nb_rtsp_streams; ++i) {\n\n        char transport[2048];\n\n\n\n        rtsp_st = rt->rtsp_streams[i];\n\n\n\n        /* compute available transports */\n\n        transport[0] = '\\0';\n\n\n\n        /* RTP/UDP */\n\n        if (protocol == RTSP_PROTOCOL_RTP_UDP) {\n\n            char buf[256];\n\n\n\n            /* first try in specified port range */\n\n            if (RTSP_RTP_PORT_MIN != 0) {\n\n                while(j <= RTSP_RTP_PORT_MAX) {\n\n                    snprintf(buf, sizeof(buf), \"rtp://%s?localport=%d\", host, j);\n\n                    j += 2; /* we will use two port by rtp stream (rtp and rtcp) */\n\n                    if (url_open(&rtsp_st->rtp_handle, buf, URL_RDWR) == 0) {\n\n                        goto rtp_opened;\n\n                    }\n\n                }\n\n            }\n\n\n\n/*            then try on any port\n\n**            if (url_open(&rtsp_st->rtp_handle, \"rtp://\", URL_RDONLY) < 0) {\n\n**                err = AVERROR_INVALIDDATA;\n\n**                goto fail;\n\n**            }\n\n*/\n\n\n\n        rtp_opened:\n\n            port = rtp_get_local_port(rtsp_st->rtp_handle);\n\n            if (transport[0] != '\\0')\n\n                av_strlcat(transport, \",\", sizeof(transport));\n\n            snprintf(transport + strlen(transport), sizeof(transport) - strlen(transport) - 1,\n\n                     \"RTP/AVP/UDP;unicast;client_port=%d-%d\",\n\n                     port, port + 1);\n\n        }\n\n\n\n        /* RTP/TCP */\n\n        else if (protocol == RTSP_PROTOCOL_RTP_TCP) {\n\n            if (transport[0] != '\\0')\n\n                av_strlcat(transport, \",\", sizeof(transport));\n\n            snprintf(transport + strlen(transport), sizeof(transport) - strlen(transport) - 1,\n\n                     \"RTP/AVP/TCP\");\n\n        }\n\n\n\n        else if (protocol == RTSP_PROTOCOL_RTP_UDP_MULTICAST) {\n\n            if (transport[0] != '\\0')\n\n                av_strlcat(transport, \",\", sizeof(transport));\n\n            snprintf(transport + strlen(transport),\n\n                     sizeof(transport) - strlen(transport) - 1,\n\n                     \"RTP/AVP/UDP;multicast\");\n\n        }\n\n        snprintf(cmd, sizeof(cmd),\n\n                 \"SETUP %s RTSP/1.0\\r\\n\"\n\n                 \"Transport: %s\\r\\n\",\n\n                 rtsp_st->control_url, transport);\n\n        rtsp_send_cmd(s, cmd, reply, NULL);\n\n        if (reply->status_code == 461 /* Unsupported protocol */ && i == 0) {\n\n            err = 1;\n\n            goto fail;\n\n        } else if (reply->status_code != RTSP_STATUS_OK ||\n\n                   reply->nb_transports != 1) {\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        /* XXX: same protocol for all streams is required */\n\n        if (i > 0) {\n\n            if (reply->transports[0].protocol != rt->protocol) {\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n        } else {\n\n            rt->protocol = reply->transports[0].protocol;\n\n        }\n\n\n\n        /* close RTP connection if not choosen */\n\n        if (reply->transports[0].protocol != RTSP_PROTOCOL_RTP_UDP &&\n\n            (protocol == RTSP_PROTOCOL_RTP_UDP)) {\n\n            url_close(rtsp_st->rtp_handle);\n\n            rtsp_st->rtp_handle = NULL;\n\n        }\n\n\n\n        switch(reply->transports[0].protocol) {\n\n        case RTSP_PROTOCOL_RTP_TCP:\n\n            rtsp_st->interleaved_min = reply->transports[0].interleaved_min;\n\n            rtsp_st->interleaved_max = reply->transports[0].interleaved_max;\n\n            break;\n\n\n\n        case RTSP_PROTOCOL_RTP_UDP:\n\n            {\n\n                char url[1024];\n\n\n\n                /* XXX: also use address if specified */\n\n                snprintf(url, sizeof(url), \"rtp://%s:%d\",\n\n                         host, reply->transports[0].server_port_min);\n\n                if (rtp_set_remote_url(rtsp_st->rtp_handle, url) < 0) {\n\n                    err = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n                }\n\n            }\n\n            break;\n\n        case RTSP_PROTOCOL_RTP_UDP_MULTICAST:\n\n            {\n\n                char url[1024];\n\n                struct in_addr in;\n\n\n\n                in.s_addr = htonl(reply->transports[0].destination);\n\n                snprintf(url, sizeof(url), \"rtp://%s:%d?ttl=%d\",\n\n                         inet_ntoa(in),\n\n                         reply->transports[0].port_min,\n\n                         reply->transports[0].ttl);\n\n                if (url_open(&rtsp_st->rtp_handle, url, URL_RDWR) < 0) {\n\n                    err = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n                }\n\n            }\n\n            break;\n\n        }\n\n        /* open the RTP context */\n\n        st = NULL;\n\n        if (rtsp_st->stream_index >= 0)\n\n            st = s->streams[rtsp_st->stream_index];\n\n        if (!st)\n\n            s->ctx_flags |= AVFMTCTX_NOHEADER;\n\n        rtsp_st->rtp_ctx = rtp_parse_open(s, st, rtsp_st->rtp_handle, rtsp_st->sdp_payload_type, &rtsp_st->rtp_payload_data);\n\n\n\n        if (!rtsp_st->rtp_ctx) {\n\n            err = AVERROR(ENOMEM);\n\n            goto fail;\n\n        } else {\n\n            if(rtsp_st->dynamic_handler) {\n\n                rtsp_st->rtp_ctx->dynamic_protocol_context= rtsp_st->dynamic_protocol_context;\n\n                rtsp_st->rtp_ctx->parse_packet= rtsp_st->dynamic_handler->parse_packet;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n\n\nfail:\n\n    for (i=0; i<rt->nb_rtsp_streams; i++) {\n\n        if (rt->rtsp_streams[i]->rtp_handle) {\n\n            url_close(rt->rtsp_streams[i]->rtp_handle);\n\n            rt->rtsp_streams[i]->rtp_handle = NULL;\n\n        }\n\n    }\n\n    return err;\n\n}\n", "idx": 5840, "_split": "valid", "_hash": "e653df163187fdaadcd860e7aa11301e"}
{"project": "FFmpeg", "commit_id": "edcc51fb8e15b704955d742559215697598927bb", "target": 1, "func": "static int add_metadata(int count, int type,\n\n                        const char *name, const char *sep, TiffContext *s)\n\n{\n\n    switch(type) {\n\n    case TIFF_DOUBLE: return add_doubles_metadata(count, name, sep, s);\n\n    case TIFF_SHORT : return add_shorts_metadata(count, name, sep, s);\n\n    case TIFF_STRING: return add_string_metadata(count, name, s);\n\n    default         : return AVERROR_INVALIDDATA;\n\n    };\n\n}\n", "idx": 5847, "_split": "valid", "_hash": "404f913a1de8f268e54c703928d19d6b"}
{"project": "FFmpeg", "commit_id": "655b6dcb34b25d591e15ede17673ea6cb8074711", "target": 0, "func": "real_parse_asm_rule(AVStream *st, const char *p, const char *end)\n\n{\n\n    do {\n\n        /* can be either averagebandwidth= or AverageBandwidth= */\n\n#if AV_HAVE_INCOMPATIBLE_LIBAV_ABI\n\n        if (sscanf(p, \" %*1[Aa]verage%*1[Bb]andwidth=%d\", &st->codec->bit_rate) == 1)\n\n#else\n\n        if (sscanf(p, \" %*1[Aa]verage%*1[Bb]andwidth=%\"SCNd64, &st->codec->bit_rate) == 1)\n\n#endif\n\n            break;\n\n        if (!(p = strchr(p, ',')) || p > end)\n\n            p = end;\n\n        p++;\n\n    } while (p < end);\n\n}\n", "idx": 5860, "_split": "valid", "_hash": "27120152cf5400ed108dd49e300e0b0c"}
{"project": "FFmpeg", "commit_id": "e72d2d12216844a692d7211f97abfbc1867fb01d", "target": 1, "func": "static int vp3_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    GetBitContext gb;\n\n    static int counter = 0;\n\n    int i;\n\n\n\n    init_get_bits(&gb, buf, buf_size * 8);\n\n\n\n    if (s->theora && get_bits1(&gb))\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR, \"Header packet passed to frame decoder, skipping\\n\");\n\n        return -1;\n\n    }\n\n\n\n    s->keyframe = !get_bits1(&gb);\n\n    if (!s->theora)\n\n        skip_bits(&gb, 1);\n\n    for (i = 0; i < 3; i++)\n\n        s->last_qps[i] = s->qps[i];\n\n\n\n    s->nqps=0;\n\n    do{\n\n        s->qps[s->nqps++]= get_bits(&gb, 6);\n\n    } while(s->theora >= 0x030200 && s->nqps<3 && get_bits1(&gb));\n\n    for (i = s->nqps; i < 3; i++)\n\n        s->qps[i] = -1;\n\n\n\n    if (s->avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_log(s->avctx, AV_LOG_INFO, \" VP3 %sframe #%d: Q index = %d\\n\",\n\n            s->keyframe?\"key\":\"\", counter, s->qps[0]);\n\n    counter++;\n\n\n\n    if (s->qps[0] != s->last_qps[0])\n\n        init_loop_filter(s);\n\n\n\n    for (i = 0; i < s->nqps; i++)\n\n        // reinit all dequantizers if the first one changed, because\n\n        // the DC of the first quantizer must be used for all matrices\n\n        if (s->qps[i] != s->last_qps[i] || s->qps[0] != s->last_qps[0])\n\n            init_dequantizer(s, i);\n\n\n\n    if (avctx->skip_frame >= AVDISCARD_NONKEY && !s->keyframe)\n\n        return buf_size;\n\n\n\n    s->current_frame.reference = 3;\n\n    if (avctx->get_buffer(avctx, &s->current_frame) < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->keyframe) {\n\n        if (!s->theora)\n\n        {\n\n            skip_bits(&gb, 4); /* width code */\n\n            skip_bits(&gb, 4); /* height code */\n\n            if (s->version)\n\n            {\n\n                s->version = get_bits(&gb, 5);\n\n                if (counter == 1)\n\n                    av_log(s->avctx, AV_LOG_DEBUG, \"VP version: %d\\n\", s->version);\n\n            }\n\n        }\n\n        if (s->version || s->theora)\n\n        {\n\n                if (get_bits1(&gb))\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"Warning, unsupported keyframe coding type?!\\n\");\n\n            skip_bits(&gb, 2); /* reserved? */\n\n        }\n\n    } else {\n\n        if (!s->golden_frame.data[0]) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"vp3: first frame not a keyframe\\n\");\n\n            avctx->release_buffer(avctx, &s->current_frame);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    s->current_frame.qscale_table= s->qscale_table; //FIXME allocate individual tables per AVFrame\n\n    s->current_frame.qstride= 0;\n\n\n\n    init_frame(s, &gb);\n\n\n\n    if (unpack_superblocks(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_superblocks\\n\");\n\n        return -1;\n\n    }\n\n    if (unpack_modes(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_modes\\n\");\n\n        return -1;\n\n    }\n\n    if (unpack_vectors(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_vectors\\n\");\n\n        return -1;\n\n    }\n\n    if (unpack_block_qpis(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_block_qpis\\n\");\n\n        return -1;\n\n    }\n\n    if (unpack_dct_coeffs(s, &gb)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"error in unpack_dct_coeffs\\n\");\n\n        return -1;\n\n    }\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        if (s->flipped_image)\n\n            s->data_offset[i] = 0;\n\n        else\n\n            s->data_offset[i] = ((s->height>>!!i)-1) * s->current_frame.linesize[i];\n\n    }\n\n\n\n    s->last_slice_end = 0;\n\n    for (i = 0; i < s->c_superblock_height; i++)\n\n        render_slice(s, i);\n\n\n\n    // filter the last row\n\n    for (i = 0; i < 3; i++) {\n\n        int row = (s->height >> (3+!!i)) - 1;\n\n        apply_loop_filter(s, i, row, row+1);\n\n    }\n\n    vp3_draw_horiz_band(s, s->height);\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data= s->current_frame;\n\n\n\n    /* release the last frame, if it is allocated and if it is not the\n\n     * golden frame */\n\n    if ((s->last_frame.data[0]) &&\n\n        (s->last_frame.data[0] != s->golden_frame.data[0]))\n\n        avctx->release_buffer(avctx, &s->last_frame);\n\n\n\n    /* shuffle frames (last = current) */\n\n    s->last_frame= s->current_frame;\n\n\n\n    if (s->keyframe) {\n\n        if (s->golden_frame.data[0])\n\n            avctx->release_buffer(avctx, &s->golden_frame);\n\n        s->golden_frame = s->current_frame;\n\n    }\n\n\n\n    s->current_frame.data[0]= NULL; /* ensure that we catch any access to this released frame */\n\n\n\n    return buf_size;\n\n}\n", "idx": 5869, "_split": "valid", "_hash": "d452be3ce408f4c77f155e674f48304b"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int dxva2_vc1_end_frame(AVCodecContext *avctx)\n\n{\n\n    VC1Context *v = avctx->priv_data;\n\n    struct dxva2_picture_context *ctx_pic = v->s.current_picture_ptr->hwaccel_picture_private;\n\n    int ret;\n\n\n\n    if (ctx_pic->bitstream_size <= 0)\n\n        return -1;\n\n\n\n    ret = ff_dxva2_common_end_frame(avctx, &v->s.current_picture_ptr->f,\n\n                                    &ctx_pic->pp, sizeof(ctx_pic->pp),\n\n                                    NULL, 0,\n\n                                    commit_bitstream_and_slice_buffer);\n\n    if (!ret)\n\n        ff_mpeg_draw_horiz_band(&v->s, 0, avctx->height);\n\n    return ret;\n\n}\n", "idx": 5910, "_split": "valid", "_hash": "bfca64689dec264dadb4900557c5019e"}
{"project": "FFmpeg", "commit_id": "3cd8aaa2b2e78faf039691e1c31ff4f8d94e3bc6", "target": 0, "func": "static int kmvc_decode_intra_8x8(KmvcContext * ctx, int w, int h)\n\n{\n\n    BitBuf bb;\n\n    int res, val;\n\n    int i, j;\n\n    int bx, by;\n\n    int l0x, l1x, l0y, l1y;\n\n    int mx, my;\n\n\n\n    kmvc_init_getbits(bb, &ctx->g);\n\n\n\n    for (by = 0; by < h; by += 8)\n\n        for (bx = 0; bx < w; bx += 8) {\n\n            if (!bytestream2_get_bytes_left(&ctx->g)) {\n\n                av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            kmvc_getbit(bb, &ctx->g, res);\n\n            if (!res) {         // fill whole 8x8 block\n\n                val = bytestream2_get_byte(&ctx->g);\n\n                for (i = 0; i < 64; i++)\n\n                    BLK(ctx->cur, bx + (i & 0x7), by + (i >> 3)) = val;\n\n            } else {            // handle four 4x4 subblocks\n\n                for (i = 0; i < 4; i++) {\n\n                    l0x = bx + (i & 1) * 4;\n\n                    l0y = by + (i & 2) * 2;\n\n                    kmvc_getbit(bb, &ctx->g, res);\n\n                    if (!res) {\n\n                        kmvc_getbit(bb, &ctx->g, res);\n\n                        if (!res) {     // fill whole 4x4 block\n\n                            val = bytestream2_get_byte(&ctx->g);\n\n                            for (j = 0; j < 16; j++)\n\n                                BLK(ctx->cur, l0x + (j & 3), l0y + (j >> 2)) = val;\n\n                        } else {        // copy block from already decoded place\n\n                            val = bytestream2_get_byte(&ctx->g);\n\n                            mx = val & 0xF;\n\n                            my = val >> 4;\n\n                            if ((l0x-mx) + 320*(l0y-my) < 0 || (l0x-mx) + 320*(l0y-my) > 316*196) {\n\n                                av_log(ctx->avctx, AV_LOG_ERROR, \"Invalid MV\\n\");\n\n                                return AVERROR_INVALIDDATA;\n\n                            }\n\n                            for (j = 0; j < 16; j++)\n\n                                BLK(ctx->cur, l0x + (j & 3), l0y + (j >> 2)) =\n\n                                    BLK(ctx->cur, l0x + (j & 3) - mx, l0y + (j >> 2) - my);\n\n                        }\n\n                    } else {    // descend to 2x2 sub-sub-blocks\n\n                        for (j = 0; j < 4; j++) {\n\n                            l1x = l0x + (j & 1) * 2;\n\n                            l1y = l0y + (j & 2);\n\n                            kmvc_getbit(bb, &ctx->g, res);\n\n                            if (!res) {\n\n                                kmvc_getbit(bb, &ctx->g, res);\n\n                                if (!res) {     // fill whole 2x2 block\n\n                                    val = bytestream2_get_byte(&ctx->g);\n\n                                    BLK(ctx->cur, l1x, l1y) = val;\n\n                                    BLK(ctx->cur, l1x + 1, l1y) = val;\n\n                                    BLK(ctx->cur, l1x, l1y + 1) = val;\n\n                                    BLK(ctx->cur, l1x + 1, l1y + 1) = val;\n\n                                } else {        // copy block from already decoded place\n\n                                    val = bytestream2_get_byte(&ctx->g);\n\n                                    mx = val & 0xF;\n\n                                    my = val >> 4;\n\n                                    if ((l1x-mx) + 320*(l1y-my) < 0 || (l1x-mx) + 320*(l1y-my) > 318*198) {\n\n                                        av_log(ctx->avctx, AV_LOG_ERROR, \"Invalid MV\\n\");\n\n                                        return AVERROR_INVALIDDATA;\n\n                                    }\n\n                                    BLK(ctx->cur, l1x, l1y) = BLK(ctx->cur, l1x - mx, l1y - my);\n\n                                    BLK(ctx->cur, l1x + 1, l1y) =\n\n                                        BLK(ctx->cur, l1x + 1 - mx, l1y - my);\n\n                                    BLK(ctx->cur, l1x, l1y + 1) =\n\n                                        BLK(ctx->cur, l1x - mx, l1y + 1 - my);\n\n                                    BLK(ctx->cur, l1x + 1, l1y + 1) =\n\n                                        BLK(ctx->cur, l1x + 1 - mx, l1y + 1 - my);\n\n                                }\n\n                            } else {    // read values for block\n\n                                BLK(ctx->cur, l1x, l1y) = bytestream2_get_byte(&ctx->g);\n\n                                BLK(ctx->cur, l1x + 1, l1y) = bytestream2_get_byte(&ctx->g);\n\n                                BLK(ctx->cur, l1x, l1y + 1) = bytestream2_get_byte(&ctx->g);\n\n                                BLK(ctx->cur, l1x + 1, l1y + 1) = bytestream2_get_byte(&ctx->g);\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n    return 0;\n\n}\n", "idx": 5923, "_split": "valid", "_hash": "6fbca5ac1eca86905e19964f994c892a"}
{"project": "FFmpeg", "commit_id": "fdbc544d29176ba69d67dd879df4696f0a19052e", "target": 1, "func": "static int asf_read_metadata_obj(AVFormatContext *s, const GUIDParseTable *g)\n\n{\n\n    ASFContext *asf   = s->priv_data;\n\n    AVIOContext *pb   = s->pb;\n\n    uint64_t size     = avio_rl64(pb);\n\n    uint16_t nb_recs  = avio_rl16(pb); // number of records in the Description Records list\n\n    int i, ret;\n\n\n\n    for (i = 0; i < nb_recs; i++) {\n\n        uint16_t name_len, buflen, type, val_len, st_num;\n\n        uint8_t *name = NULL;\n\n\n\n        avio_skip(pb, 2); // skip reserved field\n\n        st_num   = avio_rl16(pb);\n\n        name_len = avio_rl16(pb);\n\n        buflen   = 2 * name_len + 1;\n\n        if (!name_len)\n\n            break;\n\n        type     = avio_rl16(pb);\n\n        val_len  = avio_rl32(pb);\n\n        name     = av_malloc(name_len);\n\n        if (!name)\n\n            return AVERROR(ENOMEM);\n\n        avio_get_str16le(pb, name_len, name,\n\n                         buflen);\n\n\n\n        if (!strcmp(name, \"AspectRatioX\") || !strcmp(name, \"AspectRatioY\")) {\n\n            asf_store_aspect_ratio(s, st_num, name);\n\n        } else {\n\n            if (st_num < ASF_MAX_STREAMS) {\n\n                if ((ret = process_metadata(s, name, name_len, val_len, type,\n\n                                            &asf->asf_sd[st_num].asf_met)) < 0)\n\n                    break;\n\n            } else\n\n                av_freep(&name);\n\n        }\n\n    }\n\n\n\n    align_position(pb, asf->offset, size);\n\n    return 0;\n\n}\n", "idx": 5948, "_split": "valid", "_hash": "9f52d096f81158d67e2f48055a6a11cc"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(rgb24toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t *udst, uint8_t *vdst,\n\n\tunsigned int width, unsigned int height,\n\n\tint lumStride, int chromStride, int srcStride)\n\n{\n\n\tunsigned y;\n\n\tconst unsigned chromWidth= width>>1;\n\n#ifdef HAVE_MMX\n\n\tfor(y=0; y<height-2; y+=2)\n\n\t{\n\n\t\tunsigned i;\n\n\t\tfor(i=0; i<2; i++)\n\n\t\t{\n\n\t\t\tasm volatile(\n\n\t\t\t\t\"mov %2, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\t\"movq \"MANGLE(bgr2YCoeff)\", %%mm6\t\t\\n\\t\"\n\n\t\t\t\t\"movq \"MANGLE(w1111)\", %%mm5\t\t\\n\\t\"\n\n\t\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\t\"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_b\"\\n\\t\"\n\n\t\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\tPREFETCH\" 64(%0, %%\"REG_b\")\t\\n\\t\"\n\n\t\t\t\t\"movd (%0, %%\"REG_b\"), %%mm0\t\\n\\t\"\n\n\t\t\t\t\"movd 3(%0, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\t\t\"movd 6(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\t\"movd 9(%0, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm1\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm3\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\t\t\"packssdw %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\t\"packssdw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm5, %%mm0\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm5, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"packssdw %%mm2, %%mm0\t\t\\n\\t\"\n\n\t\t\t\t\"psraw $7, %%mm0\t\t\\n\\t\"\n\n\n\n\t\t\t\t\"movd 12(%0, %%\"REG_b\"), %%mm4\t\\n\\t\"\n\n\t\t\t\t\"movd 15(%0, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\t\t\"movd 18(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\t\"movd 21(%0, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm4\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm1\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm6, %%mm3\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\t\t\"psrad $8, %%mm4\t\t\\n\\t\"\n\n\t\t\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\t\t\"packssdw %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\t\t\"packssdw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\t\t\"pmaddwd %%mm5, %%mm2\t\t\\n\\t\"\n\n\t\t\t\t\"add $24, %%\"REG_b\"\t\t\\n\\t\"\n\n\t\t\t\t\"packssdw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\t\t\"psraw $7, %%mm4\t\t\\n\\t\"\n\n\n\n\t\t\t\t\"packuswb %%mm4, %%mm0\t\t\\n\\t\"\n\n\t\t\t\t\"paddusb \"MANGLE(bgr2YOffset)\", %%mm0\t\\n\\t\"\n\n\n\n\t\t\t\tMOVNTQ\" %%mm0, (%1, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t\t\t: : \"r\" (src+width*3), \"r\" (ydst+width), \"g\" ((long)-width)\n\n\t\t\t\t: \"%\"REG_a, \"%\"REG_b\n\n\t\t\t);\n\n\t\t\tydst += lumStride;\n\n\t\t\tsrc  += srcStride;\n\n\t\t}\n\n\t\tsrc -= srcStride*2;\n\n\t\tasm volatile(\n\n\t\t\t\"mov %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w1111)\", %%mm5\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(bgr2UCoeff)\", %%mm6\t\t\\n\\t\"\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_b\"\\n\\t\"\n\n\t\t\t\"add %%\"REG_b\", %%\"REG_b\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%0, %%\"REG_b\")\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%1, %%\"REG_b\")\t\\n\\t\"\n\n#if defined (HAVE_MMX2) || defined (HAVE_3DNOW)\n\n\t\t\t\"movq (%0, %%\"REG_b\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movq (%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movq 6(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movq 6(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"psrlq $24, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"psrlq $24, %%mm2\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n#else\n\n\t\t\t\"movd (%0, %%\"REG_b\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movd (%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movd 3(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movd 3(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm2, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"movd 6(%0, %%\"REG_b\"), %%mm4\t\\n\\t\"\n\n\t\t\t\"movd 6(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movd 9(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movd 9(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm4, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"psrlw $2, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"psrlw $2, %%mm2\t\t\\n\\t\"\n\n#endif\n\n\t\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm1\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm3\t\t\\n\\t\"\n\n\n\n\t\t\t\"pmaddwd %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\t\"packssdw %%mm2, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm3, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm5, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm5, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm1, %%mm0\t\t\\n\\t\" // V1 V0 U1 U0\n\n\t\t\t\"psraw $7, %%mm0\t\t\\n\\t\"\n\n\n\n#if defined (HAVE_MMX2) || defined (HAVE_3DNOW)\n\n\t\t\t\"movq 12(%0, %%\"REG_b\"), %%mm4\t\\n\\t\"\n\n\t\t\t\"movq 12(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movq 18(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movq 18(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"psrlq $24, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"psrlq $24, %%mm2\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n#else\n\n\t\t\t\"movd 12(%0, %%\"REG_b\"), %%mm4\t\\n\\t\"\n\n\t\t\t\"movd 12(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movd 15(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movd 15(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"movd 18(%0, %%\"REG_b\"), %%mm5\t\\n\\t\"\n\n\t\t\t\"movd 18(%1, %%\"REG_b\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movd 21(%0, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movd 21(%1, %%\"REG_b\"), %%mm3\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm1, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm3, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm5, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w1111)\", %%mm5\t\t\\n\\t\"\n\n\t\t\t\"psrlw $2, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"psrlw $2, %%mm2\t\t\\n\\t\"\n\n#endif\n\n\t\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm1\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(bgr2VCoeff)\", %%mm3\t\t\\n\\t\"\n\n\n\n\t\t\t\"pmaddwd %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm2\t\t\\n\\t\"\n\n#ifndef FAST_BGR2YV12\n\n\t\t\t\"psrad $8, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n#endif\n\n\t\t\t\"packssdw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm3, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm5, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"add $24, %%\"REG_b\"\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm1, %%mm4\t\t\\n\\t\" // V3 V2 U3 U2\n\n\t\t\t\"psraw $7, %%mm4\t\t\\n\\t\"\n\n\n\n\t\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"punpckldq %%mm4, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpckhdq %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\t\"packsswb %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"paddb \"MANGLE(bgr2UVOffset)\", %%mm0\t\\n\\t\"\n\n\t\t\t\"movd %%mm0, (%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\t\"punpckhdq %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"movd %%mm0, (%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\t\"add $4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t\t: : \"r\" (src+chromWidth*6), \"r\" (src+srcStride+chromWidth*6), \"r\" (udst+chromWidth), \"r\" (vdst+chromWidth), \"g\" ((long)-chromWidth)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_b\n\n\t\t);\n\n\n\n\t\tudst += chromStride;\n\n\t\tvdst += chromStride;\n\n\t\tsrc  += srcStride*2;\n\n\t}\n\n\n\n\tasm volatile(   EMMS\" \\n\\t\"\n\n\t\t\tSFENCE\" \\n\\t\"\n\n\t\t\t:::\"memory\");\n\n#else\n\n\ty=0;\n\n#endif\n\n\tfor(; y<height; y+=2)\n\n\t{\n\n\t\tunsigned i;\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tunsigned int b= src[6*i+0];\n\n\t\t\tunsigned int g= src[6*i+1];\n\n\t\t\tunsigned int r= src[6*i+2];\n\n\n\n\t\t\tunsigned int Y  =  ((RY*r + GY*g + BY*b)>>RGB2YUV_SHIFT) + 16;\n\n\t\t\tunsigned int V  =  ((RV*r + GV*g + BV*b)>>RGB2YUV_SHIFT) + 128;\n\n\t\t\tunsigned int U  =  ((RU*r + GU*g + BU*b)>>RGB2YUV_SHIFT) + 128;\n\n\n\n\t\t\tudst[i] \t= U;\n\n\t\t\tvdst[i] \t= V;\n\n\t\t\tydst[2*i] \t= Y;\n\n\n\n\t\t\tb= src[6*i+3];\n\n\t\t\tg= src[6*i+4];\n\n\t\t\tr= src[6*i+5];\n\n\n\n\t\t\tY  =  ((RY*r + GY*g + BY*b)>>RGB2YUV_SHIFT) + 16;\n\n\t\t\tydst[2*i+1] \t= Y;\n\n\t\t}\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tunsigned int b= src[6*i+0];\n\n\t\t\tunsigned int g= src[6*i+1];\n\n\t\t\tunsigned int r= src[6*i+2];\n\n\n\n\t\t\tunsigned int Y  =  ((RY*r + GY*g + BY*b)>>RGB2YUV_SHIFT) + 16;\n\n\n\n\t\t\tydst[2*i] \t= Y;\n\n\n\n\t\t\tb= src[6*i+3];\n\n\t\t\tg= src[6*i+4];\n\n\t\t\tr= src[6*i+5];\n\n\n\n\t\t\tY  =  ((RY*r + GY*g + BY*b)>>RGB2YUV_SHIFT) + 16;\n\n\t\t\tydst[2*i+1] \t= Y;\n\n\t\t}\n\n\t\tudst += chromStride;\n\n\t\tvdst += chromStride;\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\t}\n\n}\n", "idx": 5997, "_split": "valid", "_hash": "23dd982bac6b2fcb1a5695d2f18d73f8"}
{"project": "FFmpeg", "commit_id": "6bed20f45a484f5709fec4c97a238240161b1797", "target": 0, "func": "matroska_parse_blockgroup (MatroskaDemuxContext *matroska,\n\n                           uint64_t              cluster_time)\n\n{\n\n    int res = 0;\n\n    uint32_t id;\n\n    AVPacket *pkt = NULL;\n\n    int is_keyframe = PKT_FLAG_KEY, last_num_packets = matroska->num_packets;\n\n    uint64_t duration = AV_NOPTS_VALUE;\n\n    int track = -1;\n\n    uint8_t *data;\n\n    int size = 0;\n\n    int64_t pos = 0;\n\n\n\n    av_log(matroska->ctx, AV_LOG_DEBUG, \"parsing blockgroup...\\n\");\n\n\n\n    while (res == 0) {\n\n        if (!(id = ebml_peek_id(matroska, &matroska->level_up))) {\n\n            res = AVERROR_IO;\n\n            break;\n\n        } else if (matroska->level_up) {\n\n            matroska->level_up--;\n\n            break;\n\n        }\n\n\n\n        switch (id) {\n\n            /* one block inside the group. Note, block parsing is one\n\n             * of the harder things, so this code is a bit complicated.\n\n             * See http://www.matroska.org/ for documentation. */\n\n            case MATROSKA_ID_BLOCK: {\n\n                pos = url_ftell(&matroska->ctx->pb);\n\n                res = ebml_read_binary(matroska, &id, &data, &size);\n\n                break;\n\n            }\n\n\n\n            case MATROSKA_ID_BLOCKDURATION: {\n\n                if ((res = ebml_read_uint(matroska, &id, &duration)) < 0)\n\n                    break;\n\n                break;\n\n            }\n\n\n\n            case MATROSKA_ID_BLOCKREFERENCE:\n\n                /* We've found a reference, so not even the first frame in\n\n                 * the lace is a key frame. */\n\n                is_keyframe = 0;\n\n                if (last_num_packets != matroska->num_packets)\n\n                    matroska->packets[last_num_packets]->flags = 0;\n\n                res = ebml_read_skip(matroska);\n\n                break;\n\n\n\n            default:\n\n                av_log(matroska->ctx, AV_LOG_INFO,\n\n                       \"Unknown entry 0x%x in blockgroup data\\n\", id);\n\n                /* fall-through */\n\n\n\n            case EBML_ID_VOID:\n\n                res = ebml_read_skip(matroska);\n\n                break;\n\n        }\n\n\n\n        if (matroska->level_up) {\n\n            matroska->level_up--;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (res)\n\n        return res;\n\n\n\n    if (size > 0)\n\n        res = matroska_parse_block(matroska, data, size, pos, cluster_time,\n\n                                   is_keyframe, &track, &pkt);\n\n\n\n    if (pkt)\n\n    {\n\n        if (duration != AV_NOPTS_VALUE)\n\n            pkt->duration = duration;\n\n        else if (track >= 0 && track < matroska->num_tracks)\n\n            pkt->duration = matroska->tracks[track]->default_duration / matroska->time_scale;\n\n    }\n\n\n\n    return res;\n\n}\n", "idx": 6040, "_split": "valid", "_hash": "97836038793b1ff71ab341b0a35ffb59"}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0x7(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char P[2];\n\n    unsigned int flags;\n\n\n\n    /* 2-color encoding */\n\n    CHECK_STREAM_PTR(2);\n\n\n\n    P[0] = *s->stream_ptr++;\n\n    P[1] = *s->stream_ptr++;\n\n\n\n    if (P[0] <= P[1]) {\n\n\n\n        /* need 8 more bytes from the stream */\n\n        CHECK_STREAM_PTR(8);\n\n\n\n        for (y = 0; y < 8; y++) {\n\n            flags = *s->stream_ptr++ | 0x100;\n\n            for (; flags != 1; flags >>= 1)\n\n                *s->pixel_ptr++ = P[flags & 1];\n\n            s->pixel_ptr += s->line_inc;\n\n        }\n\n\n\n    } else {\n\n\n\n        /* need 2 more bytes from the stream */\n\n        CHECK_STREAM_PTR(2);\n\n\n\n        flags = bytestream_get_le16(&s->stream_ptr);\n\n        for (y = 0; y < 8; y += 2) {\n\n            for (x = 0; x < 8; x += 2, flags >>= 1) {\n\n                s->pixel_ptr[x                ] =\n\n                s->pixel_ptr[x + 1            ] =\n\n                s->pixel_ptr[x +     s->stride] =\n\n                s->pixel_ptr[x + 1 + s->stride] = P[flags & 1];\n\n            }\n\n            s->pixel_ptr += s->stride * 2;\n\n        }\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 6059, "_split": "valid", "_hash": "e0bc89e86684d9013703cbfa83f3f7a2"}
{"project": "FFmpeg", "commit_id": "320ae9fb784f898331d21de225178a1fca0a7849", "target": 0, "func": "int attribute_align_arg sws_scale(struct SwsContext *c,\n\n                                  const uint8_t * const srcSlice[],\n\n                                  const int srcStride[], int srcSliceY,\n\n                                  int srcSliceH, uint8_t *const dst[],\n\n                                  const int dstStride[])\n\n{\n\n    int i, ret;\n\n    const uint8_t *src2[4] = { srcSlice[0], srcSlice[1], srcSlice[2], srcSlice[3] };\n\n    uint8_t *dst2[4] = { dst[0], dst[1], dst[2], dst[3] };\n\n    uint8_t *rgb0_tmp = NULL;\n\n\n\n    // do not mess up sliceDir if we have a \"trailing\" 0-size slice\n\n    if (srcSliceH == 0)\n\n        return 0;\n\n\n\n    if (!check_image_pointers(srcSlice, c->srcFormat, srcStride)) {\n\n        av_log(c, AV_LOG_ERROR, \"bad src image pointers\\n\");\n\n        return 0;\n\n    }\n\n    if (!check_image_pointers((const uint8_t* const*)dst, c->dstFormat, dstStride)) {\n\n        av_log(c, AV_LOG_ERROR, \"bad dst image pointers\\n\");\n\n        return 0;\n\n    }\n\n\n\n    if (c->sliceDir == 0 && srcSliceY != 0 && srcSliceY + srcSliceH != c->srcH) {\n\n        av_log(c, AV_LOG_ERROR, \"Slices start in the middle!\\n\");\n\n        return 0;\n\n    }\n\n    if (c->sliceDir == 0) {\n\n        if (srcSliceY == 0) c->sliceDir = 1; else c->sliceDir = -1;\n\n    }\n\n\n\n    if (usePal(c->srcFormat)) {\n\n        for (i = 0; i < 256; i++) {\n\n            int p, r, g, b, y, u, v, a = 0xff;\n\n            if (c->srcFormat == AV_PIX_FMT_PAL8) {\n\n                p = ((const uint32_t *)(srcSlice[1]))[i];\n\n                a = (p >> 24) & 0xFF;\n\n                r = (p >> 16) & 0xFF;\n\n                g = (p >>  8) & 0xFF;\n\n                b =  p        & 0xFF;\n\n            } else if (c->srcFormat == AV_PIX_FMT_RGB8) {\n\n                r = ( i >> 5     ) * 36;\n\n                g = ((i >> 2) & 7) * 36;\n\n                b = ( i       & 3) * 85;\n\n            } else if (c->srcFormat == AV_PIX_FMT_BGR8) {\n\n                b = ( i >> 6     ) * 85;\n\n                g = ((i >> 3) & 7) * 36;\n\n                r = ( i       & 7) * 36;\n\n            } else if (c->srcFormat == AV_PIX_FMT_RGB4_BYTE) {\n\n                r = ( i >> 3     ) * 255;\n\n                g = ((i >> 1) & 3) * 85;\n\n                b = ( i       & 1) * 255;\n\n            } else if (c->srcFormat == AV_PIX_FMT_GRAY8 || c->srcFormat == AV_PIX_FMT_GRAY8A) {\n\n                r = g = b = i;\n\n            } else {\n\n                av_assert1(c->srcFormat == AV_PIX_FMT_BGR4_BYTE);\n\n                b = ( i >> 3     ) * 255;\n\n                g = ((i >> 1) & 3) * 85;\n\n                r = ( i       & 1) * 255;\n\n            }\n\n#define RGB2YUV_SHIFT 15\n\n#define BY ( (int) (0.114 * 219 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define BV (-(int) (0.081 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define BU ( (int) (0.500 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define GY ( (int) (0.587 * 219 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define GV (-(int) (0.419 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define GU (-(int) (0.331 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define RY ( (int) (0.299 * 219 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define RV ( (int) (0.500 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n#define RU (-(int) (0.169 * 224 / 255 * (1 << RGB2YUV_SHIFT) + 0.5))\n\n\n\n            y = av_clip_uint8((RY * r + GY * g + BY * b + ( 33 << (RGB2YUV_SHIFT - 1))) >> RGB2YUV_SHIFT);\n\n            u = av_clip_uint8((RU * r + GU * g + BU * b + (257 << (RGB2YUV_SHIFT - 1))) >> RGB2YUV_SHIFT);\n\n            v = av_clip_uint8((RV * r + GV * g + BV * b + (257 << (RGB2YUV_SHIFT - 1))) >> RGB2YUV_SHIFT);\n\n            c->pal_yuv[i]= y + (u<<8) + (v<<16) + ((unsigned)a<<24);\n\n\n\n            switch (c->dstFormat) {\n\n            case AV_PIX_FMT_BGR32:\n\n#if !HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_RGB24:\n\n#endif\n\n                c->pal_rgb[i]=  r + (g<<8) + (b<<16) + ((unsigned)a<<24);\n\n                break;\n\n            case AV_PIX_FMT_BGR32_1:\n\n#if HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_BGR24:\n\n#endif\n\n                c->pal_rgb[i]= a + (r<<8) + (g<<16) + ((unsigned)b<<24);\n\n                break;\n\n            case AV_PIX_FMT_RGB32_1:\n\n#if HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_RGB24:\n\n#endif\n\n                c->pal_rgb[i]= a + (b<<8) + (g<<16) + ((unsigned)r<<24);\n\n                break;\n\n            case AV_PIX_FMT_RGB32:\n\n#if !HAVE_BIGENDIAN\n\n            case AV_PIX_FMT_BGR24:\n\n#endif\n\n            default:\n\n                c->pal_rgb[i]=  b + (g<<8) + (r<<16) + ((unsigned)a<<24);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (c->src0Alpha && !c->dst0Alpha && isALPHA(c->dstFormat)) {\n\n        uint8_t *base;\n\n        int x,y;\n\n        rgb0_tmp = av_malloc(FFABS(srcStride[0]) * srcSliceH + 32);\n\n        base = srcStride[0] < 0 ? rgb0_tmp - srcStride[0] * (srcSliceH-1) : rgb0_tmp;\n\n        for (y=0; y<srcSliceH; y++){\n\n            memcpy(base + srcStride[0]*y, src2[0] + srcStride[0]*y, 4*c->srcW);\n\n            for (x=c->src0Alpha-1; x<4*c->srcW; x+=4) {\n\n                base[ srcStride[0]*y + x] = 0xFF;\n\n            }\n\n        }\n\n        src2[0] = base;\n\n    }\n\n\n\n    // copy strides, so they can safely be modified\n\n    if (c->sliceDir == 1) {\n\n        // slices go from top to bottom\n\n        int srcStride2[4] = { srcStride[0], srcStride[1], srcStride[2],\n\n                              srcStride[3] };\n\n        int dstStride2[4] = { dstStride[0], dstStride[1], dstStride[2],\n\n                              dstStride[3] };\n\n\n\n        reset_ptr(src2, c->srcFormat);\n\n        reset_ptr((void*)dst2, c->dstFormat);\n\n\n\n        /* reset slice direction at end of frame */\n\n        if (srcSliceY + srcSliceH == c->srcH)\n\n            c->sliceDir = 0;\n\n\n\n        ret = c->swScale(c, src2, srcStride2, srcSliceY, srcSliceH, dst2,\n\n                          dstStride2);\n\n    } else {\n\n        // slices go from bottom to top => we flip the image internally\n\n        int srcStride2[4] = { -srcStride[0], -srcStride[1], -srcStride[2],\n\n                              -srcStride[3] };\n\n        int dstStride2[4] = { -dstStride[0], -dstStride[1], -dstStride[2],\n\n                              -dstStride[3] };\n\n\n\n        src2[0] += (srcSliceH - 1) * srcStride[0];\n\n        if (!usePal(c->srcFormat))\n\n            src2[1] += ((srcSliceH >> c->chrSrcVSubSample) - 1) * srcStride[1];\n\n        src2[2] += ((srcSliceH >> c->chrSrcVSubSample) - 1) * srcStride[2];\n\n        src2[3] += (srcSliceH - 1) * srcStride[3];\n\n        dst2[0] += ( c->dstH                         - 1) * dstStride[0];\n\n        dst2[1] += ((c->dstH >> c->chrDstVSubSample) - 1) * dstStride[1];\n\n        dst2[2] += ((c->dstH >> c->chrDstVSubSample) - 1) * dstStride[2];\n\n        dst2[3] += ( c->dstH                         - 1) * dstStride[3];\n\n\n\n        reset_ptr(src2, c->srcFormat);\n\n        reset_ptr((void*)dst2, c->dstFormat);\n\n\n\n        /* reset slice direction at end of frame */\n\n        if (!srcSliceY)\n\n            c->sliceDir = 0;\n\n\n\n        ret = c->swScale(c, src2, srcStride2, c->srcH-srcSliceY-srcSliceH,\n\n                          srcSliceH, dst2, dstStride2);\n\n    }\n\n\n\n    av_free(rgb0_tmp);\n\n    return ret;\n\n}\n", "idx": 6102, "_split": "valid", "_hash": "776c983d86d5fbe3f7da2b59437ced3f"}
{"project": "FFmpeg", "commit_id": "16c91d2b233fe04697ba8f7ab6d1bad12a4ad69f", "target": 0, "func": "static void do_rematrixing(AC3DecodeContext *s)\n\n{\n\n    int bnd, i;\n\n    int end, bndend;\n\n    int tmp0, tmp1;\n\n\n\n    end = FFMIN(s->end_freq[1], s->end_freq[2]);\n\n\n\n    for(bnd=0; bnd<s->num_rematrixing_bands; bnd++) {\n\n        if(s->rematrixing_flags[bnd]) {\n\n            bndend = FFMIN(end, ff_ac3_rematrix_band_tab[bnd+1]);\n\n            for(i=ff_ac3_rematrix_band_tab[bnd]; i<bndend; i++) {\n\n                tmp0 = s->fixed_coeffs[1][i];\n\n                tmp1 = s->fixed_coeffs[2][i];\n\n                s->fixed_coeffs[1][i] = tmp0 + tmp1;\n\n                s->fixed_coeffs[2][i] = tmp0 - tmp1;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 6129, "_split": "valid", "_hash": "82e64d2aea8a9ba34d4cde5c9e1eb91f"}
{"project": "FFmpeg", "commit_id": "7172175da6f8dfe6939e5366190a8066b78d71df", "target": 1, "func": "static int scan_file(AVFormatContext *avctx, AVStream *vst, AVStream *ast, int file)\n\n{\n\n    MlvContext *mlv = avctx->priv_data;\n\n    AVIOContext *pb = mlv->pb[file];\n\n    int ret;\n\n    while (!avio_feof(pb)) {\n\n        int type;\n\n        unsigned int size;\n\n        type = avio_rl32(pb);\n\n        size = avio_rl32(pb);\n\n        avio_skip(pb, 8); //timestamp\n\n        if (size < 16)\n\n            break;\n\n        size -= 16;\n\n        if (vst && type == MKTAG('R','A','W','I') && size >= 164) {\n\n            vst->codec->width  = avio_rl16(pb);\n\n            vst->codec->height = avio_rl16(pb);\n\n\n\n\n            if (avio_rl32(pb) != 1)\n\n                avpriv_request_sample(avctx, \"raw api version\");\n\n            avio_skip(pb, 20); // pointer, width, height, pitch, frame_size\n\n            vst->codec->bits_per_coded_sample = avio_rl32(pb);\n\n\n\n\n\n\n\n\n\n            avio_skip(pb, 8 + 16 + 24); // black_level, white_level, xywh, active_area, exposure_bias\n\n            if (avio_rl32(pb) != 0x2010100) /* RGGB */\n\n                avpriv_request_sample(avctx, \"cfa_pattern\");\n\n            avio_skip(pb, 80); // calibration_illuminant1, color_matrix1, dynamic_range\n\n            vst->codec->pix_fmt  = AV_PIX_FMT_BAYER_RGGB16LE;\n\n            vst->codec->codec_tag = MKTAG('B', 'I', 'T', 16);\n\n            size -= 164;\n\n        } else if (ast && type == MKTAG('W', 'A', 'V', 'I') && size >= 16) {\n\n            ret = ff_get_wav_header(avctx, pb, ast->codec, 16, 0);\n\n\n\n            size -= 16;\n\n        } else if (type == MKTAG('I','N','F','O')) {\n\n            if (size > 0)\n\n                read_string(avctx, pb, \"info\", size);\n\n            continue;\n\n        } else if (type == MKTAG('I','D','N','T') && size >= 36) {\n\n            read_string(avctx, pb, \"cameraName\", 32);\n\n            read_uint32(avctx, pb, \"cameraModel\", \"0x%\"PRIx32);\n\n            size -= 36;\n\n            if (size >= 32) {\n\n                read_string(avctx, pb, \"cameraSerial\", 32);\n\n                size -= 32;\n\n\n        } else if (type == MKTAG('L','E','N','S') && size >= 48) {\n\n            read_uint16(avctx, pb, \"focalLength\", \"%i\");\n\n            read_uint16(avctx, pb, \"focalDist\", \"%i\");\n\n            read_uint16(avctx, pb, \"aperture\", \"%i\");\n\n            read_uint8(avctx, pb, \"stabilizerMode\", \"%i\");\n\n            read_uint8(avctx, pb, \"autofocusMode\", \"%i\");\n\n            read_uint32(avctx, pb, \"flags\", \"0x%\"PRIx32);\n\n            read_uint32(avctx, pb, \"lensID\", \"%\"PRIi32);\n\n            read_string(avctx, pb, \"lensName\", 32);\n\n            size -= 48;\n\n            if (size >= 32) {\n\n                read_string(avctx, pb, \"lensSerial\", 32);\n\n                size -= 32;\n\n\n        } else if (vst && type == MKTAG('V', 'I', 'D', 'F') && size >= 4) {\n\n            uint64_t pts = avio_rl32(pb);\n\n            ff_add_index_entry(&vst->index_entries, &vst->nb_index_entries, &vst->index_entries_allocated_size,\n\n                               avio_tell(pb) - 20, pts, file, 0, AVINDEX_KEYFRAME);\n\n            size -= 4;\n\n        } else if (ast && type == MKTAG('A', 'U', 'D', 'F') && size >= 4) {\n\n            uint64_t pts = avio_rl32(pb);\n\n            ff_add_index_entry(&ast->index_entries, &ast->nb_index_entries, &ast->index_entries_allocated_size,\n\n                               avio_tell(pb) - 20, pts, file, 0, AVINDEX_KEYFRAME);\n\n            size -= 4;\n\n        } else if (vst && type == MKTAG('W','B','A','L') && size >= 28) {\n\n            read_uint32(avctx, pb, \"wb_mode\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"kelvin\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"wbgain_r\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"wbgain_g\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"wbgain_b\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"wbs_gm\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"wbs_ba\", \"%\"PRIi32);\n\n            size -= 28;\n\n        } else if (type == MKTAG('R','T','C','I') && size >= 20) {\n\n            char str[32];\n\n            struct tm time = { 0 };\n\n            time.tm_sec    = avio_rl16(pb);\n\n            time.tm_min    = avio_rl16(pb);\n\n            time.tm_hour   = avio_rl16(pb);\n\n            time.tm_mday   = avio_rl16(pb);\n\n            time.tm_mon    = avio_rl16(pb);\n\n            time.tm_year   = avio_rl16(pb);\n\n            time.tm_wday   = avio_rl16(pb);\n\n            time.tm_yday   = avio_rl16(pb);\n\n            time.tm_isdst  = avio_rl16(pb);\n\n            avio_skip(pb, 2);\n\n            if (strftime(str, sizeof(str), \"%Y-%m-%d %H:%M:%S\", &time))\n\n                av_dict_set(&avctx->metadata, \"time\", str, 0);\n\n            size -= 20;\n\n        } else if (type == MKTAG('E','X','P','O') && size >= 16) {\n\n            av_dict_set(&avctx->metadata, \"isoMode\", avio_rl32(pb) ? \"auto\" : \"manual\", 0);\n\n            read_uint32(avctx, pb, \"isoValue\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"isoAnalog\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"digitalGain\", \"%\"PRIi32);\n\n            size -= 16;\n\n            if (size >= 8) {\n\n                read_uint64(avctx, pb, \"shutterValue\", \"%\"PRIi64);\n\n                size -= 8;\n\n\n        } else if (type == MKTAG('S','T','Y','L') && size >= 36) {\n\n            read_uint32(avctx, pb, \"picStyleId\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"contrast\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"sharpness\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"saturation\", \"%\"PRIi32);\n\n            read_uint32(avctx, pb, \"colortone\", \"%\"PRIi32);\n\n            read_string(avctx, pb, \"picStyleName\", 16);\n\n            size -= 36;\n\n        } else if (type == MKTAG('M','A','R','K')) {\n\n        } else if (type == MKTAG('N','U','L','L')) {\n\n        } else if (type == MKTAG('M','L','V','I')) { /* occurs when MLV and Mnn files are concatenated */\n\n        } else {\n\n            av_log(avctx, AV_LOG_INFO, \"unsupported tag %c%c%c%c, size %u\\n\", type&0xFF, (type>>8)&0xFF, (type>>16)&0xFF, (type>>24)&0xFF, size);\n\n\n        avio_skip(pb, size);\n\n\n    return 0;\n", "idx": 6158, "_split": "valid", "_hash": "5008b81f5338e5aafda8934035561d0e"}
{"project": "FFmpeg", "commit_id": "50a6c318b2d00a103297f2aa6256a7404b0f64f8", "target": 1, "func": "static int get_codec_data(ByteIOContext *pb, AVStream *vst,\n\n                          AVStream *ast, int myth) {\n\n    frametype_t frametype;\n\n    if (!vst && !myth)\n\n        return 1; // no codec data needed\n\n    while (!url_feof(pb)) {\n\n        int size, subtype;\n\n        frametype = get_byte(pb);\n\n        switch (frametype) {\n\n            case NUV_EXTRADATA:\n\n                subtype = get_byte(pb);\n\n                url_fskip(pb, 6);\n\n                size = PKTSIZE(get_le32(pb));\n\n                if (subtype == 'R') {\n\n                    vst->codec->extradata_size = size;\n\n                    vst->codec->extradata = av_malloc(size);\n\n                    get_buffer(pb, vst->codec->extradata, size);\n\n                    size = 0;\n\n                    if (!myth)\n\n                        return 1;\n\n                }\n\n                break;\n\n            case NUV_MYTHEXT:\n\n                url_fskip(pb, 7);\n\n                size = PKTSIZE(get_le32(pb));\n\n                if (size != 128 * 4)\n\n                    break;\n\n                get_le32(pb); // version\n\n                if (vst) {\n\n                    vst->codec->codec_tag = get_le32(pb);\n\n                    vst->codec->codec_id =\n\n                        codec_get_id(codec_bmp_tags, vst->codec->codec_tag);\n\n                } else\n\n                    url_fskip(pb, 4);\n\n\n\n                if (ast) {\n\n                    ast->codec->codec_tag = get_le32(pb);\n\n                    ast->codec->sample_rate = get_le32(pb);\n\n                    ast->codec->bits_per_sample = get_le32(pb);\n\n                    ast->codec->channels = get_le32(pb);\n\n                    ast->codec->codec_id =\n\n                        wav_codec_get_id(ast->codec->codec_tag,\n\n                                         ast->codec->bits_per_sample);\n\n                } else\n\n                    url_fskip(pb, 4 * 4);\n\n\n\n                size -= 6 * 4;\n\n                url_fskip(pb, size);\n\n                return 1;\n\n            case NUV_SEEKP:\n\n                size = 11;\n\n                break;\n\n            default:\n\n                url_fskip(pb, 7);\n\n                size = PKTSIZE(get_le32(pb));\n\n                break;\n\n        }\n\n        url_fskip(pb, size);\n\n    }\n\n    return 0;\n\n}\n", "idx": 6215, "_split": "valid", "_hash": "f81b0fd574e8728b3276249474a6d6d6"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(rgb24to15)(const uint8_t *src, uint8_t *dst, unsigned src_size)\n\n{\n\n\tconst uint8_t *s = src;\n\n\tconst uint8_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint8_t *mm_end;\n\n#endif\n\n\tuint16_t *d = (uint16_t *)dst;\n\n\tend = s + src_size;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*src):\"memory\");\n\n\t__asm __volatile(\n\n\t    \"movq\t%0, %%mm7\\n\\t\"\n\n\t    \"movq\t%1, %%mm6\\n\\t\"\n\n\t    ::\"m\"(red_15mask),\"m\"(green_15mask));\n\n\tmm_end = end - 11;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movd\t%1, %%mm0\\n\\t\"\n\n\t\t\"movd\t3%1, %%mm3\\n\\t\"\n\n\t\t\"punpckldq 6%1, %%mm0\\n\\t\"\n\n\t\t\"punpckldq 9%1, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm5\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm3\\n\\t\"\n\n\t\t\"pand\t%2, %%mm0\\n\\t\"\n\n\t\t\"pand\t%2, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$6, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$6, %%mm4\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm4\\n\\t\"\n\n\t\t\"psrlq\t$9, %%mm2\\n\\t\"\n\n\t\t\"psrlq\t$9, %%mm5\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm2\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\t:\"=m\"(*d):\"m\"(*s),\"m\"(blue_15mask):\"memory\");\n\n\t\td += 4;\n\n\t\ts += 12;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tconst int b= *s++;\n\n\t\tconst int g= *s++;\n\n\t\tconst int r= *s++;\n\n\t\t*d++ = (b>>3) | ((g&0xF8)<<2) | ((r&0xF8)<<7);\n\n\t}\n\n}\n", "idx": 6269, "_split": "valid", "_hash": "72037fddc493e4ef6011feb4b316be23"}
{"project": "FFmpeg", "commit_id": "ee5f0f1d355fa0fd9194ac97a2c8598c93ed328b", "target": 1, "func": "static int rsd_read_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    int i, ret, version, start = 0x800;\n\n    AVCodecParameters *par;\n\n    AVStream *st = avformat_new_stream(s, NULL);\n\n\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avio_skip(pb, 3); // \"RSD\"\n\n    version = avio_r8(pb) - '0';\n\n\n\n    par = st->codecpar;\n\n    par->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    par->codec_tag  = avio_rl32(pb);\n\n    par->codec_id   = ff_codec_get_id(rsd_tags, par->codec_tag);\n\n    if (!par->codec_id) {\n\n        char tag_buf[32];\n\n\n\n        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), par->codec_tag);\n\n        for (i=0; i < FF_ARRAY_ELEMS(rsd_unsupported_tags); i++) {\n\n            if (par->codec_tag == rsd_unsupported_tags[i]) {\n\n                avpriv_request_sample(s, \"Codec tag: %s\", tag_buf);\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n        }\n\n        av_log(s, AV_LOG_ERROR, \"Unknown codec tag: %s\\n\", tag_buf);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    par->channels = avio_rl32(pb);\n\n    if (!par->channels)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    avio_skip(pb, 4); // Bit depth\n\n    par->sample_rate = avio_rl32(pb);\n\n    if (!par->sample_rate)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    avio_skip(pb, 4); // Unknown\n\n\n\n    switch (par->codec_id) {\n\n    case AV_CODEC_ID_XMA2:\n\n        par->block_align = 2048;\n\n        ff_alloc_extradata(par, 34);\n\n        if (!par->extradata)\n\n            return AVERROR(ENOMEM);\n\n        memset(par->extradata, 0, 34);\n\n        break;\n\n    case AV_CODEC_ID_ADPCM_PSX:\n\n        par->block_align = 16 * par->channels;\n\n        if (pb->seekable)\n\n            st->duration = av_get_audio_frame_duration2(par, avio_size(pb) - start);\n\n        break;\n\n    case AV_CODEC_ID_ADPCM_IMA_RAD:\n\n        par->block_align = 20 * par->channels;\n\n        if (pb->seekable)\n\n            st->duration = av_get_audio_frame_duration2(par, avio_size(pb) - start);\n\n        break;\n\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n\n        if (version == 2)\n\n            start = avio_rl32(pb);\n\n\n\n        par->bits_per_coded_sample = 4;\n\n        par->block_align = 36 * par->channels;\n\n        if (pb->seekable)\n\n            st->duration = av_get_audio_frame_duration2(par, avio_size(pb) - start);\n\n        break;\n\n    case AV_CODEC_ID_ADPCM_THP_LE:\n\n        /* RSD3GADP is mono, so only alloc enough memory\n\n           to store the coeff table for a single channel. */\n\n\n\n        start = avio_rl32(pb);\n\n\n\n        if ((ret = ff_get_extradata(s, par, s->pb, 32)) < 0)\n\n            return ret;\n\n        if (pb->seekable)\n\n            st->duration = av_get_audio_frame_duration2(par, avio_size(pb) - start);\n\n        break;\n\n    case AV_CODEC_ID_ADPCM_THP:\n\n        par->block_align = 8 * par->channels;\n\n        avio_skip(s->pb, 0x1A4 - avio_tell(s->pb));\n\n\n\n        if ((ret = ff_alloc_extradata(st->codecpar, 32 * par->channels)) < 0)\n\n            return ret;\n\n\n\n        for (i = 0; i < par->channels; i++) {\n\n            avio_read(s->pb, st->codecpar->extradata + 32 * i, 32);\n\n            avio_skip(s->pb, 8);\n\n        }\n\n        if (pb->seekable)\n\n            st->duration = (avio_size(pb) - start) / (8 * par->channels) * 14;\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16LE:\n\n    case AV_CODEC_ID_PCM_S16BE:\n\n        if (version != 4)\n\n            start = avio_rl32(pb);\n\n\n\n        if (pb->seekable)\n\n            st->duration = (avio_size(pb) - start) / 2 / par->channels;\n\n        break;\n\n    }\n\n\n\n    avio_skip(pb, start - avio_tell(pb));\n\n    if (par->codec_id == AV_CODEC_ID_XMA2) {\n\n        avio_skip(pb, avio_rb32(pb) + avio_rb32(pb));\n\n        st->duration = avio_rb32(pb);\n\n    }\n\n\n\n    avpriv_set_pts_info(st, 64, 1, par->sample_rate);\n\n\n\n    return 0;\n\n}\n", "idx": 6274, "_split": "valid", "_hash": "e4749ba0251b9d7f0b26ab16361f3a08"}
{"project": "FFmpeg", "commit_id": "a782f209df44c372545ecf8ef29d17fedaa8e75e", "target": 0, "func": "static int http_prepare_data(HTTPContext *c)\n\n{\n\n    int i, len, ret;\n\n    AVFormatContext *ctx;\n\n\n\n    switch(c->state) {\n\n    case HTTPSTATE_SEND_DATA_HEADER:\n\n        memset(&c->fmt_ctx, 0, sizeof(c->fmt_ctx));\n\n        pstrcpy(c->fmt_ctx.author, sizeof(c->fmt_ctx.author), \n\n                c->stream->author);\n\n        pstrcpy(c->fmt_ctx.comment, sizeof(c->fmt_ctx.comment), \n\n                c->stream->comment);\n\n        pstrcpy(c->fmt_ctx.copyright, sizeof(c->fmt_ctx.copyright), \n\n                c->stream->copyright);\n\n        pstrcpy(c->fmt_ctx.title, sizeof(c->fmt_ctx.title), \n\n                c->stream->title);\n\n\n\n        /* open output stream by using specified codecs */\n\n        c->fmt_ctx.oformat = c->stream->fmt;\n\n        c->fmt_ctx.nb_streams = c->stream->nb_streams;\n\n        for(i=0;i<c->fmt_ctx.nb_streams;i++) {\n\n            AVStream *st;\n\n            st = av_mallocz(sizeof(AVStream));\n\n            c->fmt_ctx.streams[i] = st;\n\n            /* if file or feed, then just take streams from FFStream struct */\n\n            if (!c->stream->feed || \n\n                c->stream->feed == c->stream)\n\n                memcpy(st, c->stream->streams[i], sizeof(AVStream));\n\n            else\n\n                memcpy(st, c->stream->feed->streams[c->stream->feed_streams[i]],\n\n                           sizeof(AVStream));\n\n            st->codec.frame_number = 0; /* XXX: should be done in\n\n                                           AVStream, not in codec */\n\n        }\n\n        c->got_key_frame = 0;\n\n\n\n        /* prepare header and save header data in a stream */\n\n        if (url_open_dyn_buf(&c->fmt_ctx.pb) < 0) {\n\n            /* XXX: potential leak */\n\n            return -1;\n\n        }\n\n        c->fmt_ctx.pb.is_streamed = 1;\n\n\n\n        av_write_header(&c->fmt_ctx);\n\n\n\n        len = url_close_dyn_buf(&c->fmt_ctx.pb, &c->pb_buffer);\n\n        c->buffer_ptr = c->pb_buffer;\n\n        c->buffer_end = c->pb_buffer + len;\n\n\n\n        c->state = HTTPSTATE_SEND_DATA;\n\n        c->last_packet_sent = 0;\n\n        break;\n\n    case HTTPSTATE_SEND_DATA:\n\n        /* find a new packet */\n\n        {\n\n            AVPacket pkt;\n\n            \n\n            /* read a packet from the input stream */\n\n            if (c->stream->feed) {\n\n                ffm_set_write_index(c->fmt_in, \n\n                                    c->stream->feed->feed_write_index,\n\n                                    c->stream->feed->feed_size);\n\n            }\n\n\n\n            if (c->stream->max_time && \n\n                c->stream->max_time + c->start_time - cur_time < 0) {\n\n                /* We have timed out */\n\n                c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n            } else {\n\n                if (c->is_packetized) {\n\n                    if (compute_send_delay(c) > 0) {\n\n                        c->state = HTTPSTATE_WAIT;\n\n                        return 1; /* state changed */\n\n                    }\n\n                }\n\n                if (av_read_frame(c->fmt_in, &pkt) < 0) {\n\n                    if (c->stream->feed && c->stream->feed->feed_opened) {\n\n                        /* if coming from feed, it means we reached the end of the\n\n                           ffm file, so must wait for more data */\n\n                        c->state = HTTPSTATE_WAIT_FEED;\n\n                        return 1; /* state changed */\n\n                    } else {\n\n                        /* must send trailer now because eof or error */\n\n                        c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n                    }\n\n                } else {\n\n                    /* update first pts if needed */\n\n                    if (c->first_pts == AV_NOPTS_VALUE)\n\n                        c->first_pts = pkt.pts;\n\n                    \n\n                    /* send it to the appropriate stream */\n\n                    if (c->stream->feed) {\n\n                        /* if coming from a feed, select the right stream */\n\n                        if (c->switch_pending) {\n\n                            c->switch_pending = 0;\n\n                            for(i=0;i<c->stream->nb_streams;i++) {\n\n                                if (c->switch_feed_streams[i] == pkt.stream_index) {\n\n                                    if (pkt.flags & PKT_FLAG_KEY) {\n\n                                        do_switch_stream(c, i);\n\n                                    }\n\n                                }\n\n                                if (c->switch_feed_streams[i] >= 0) {\n\n                                    c->switch_pending = 1;\n\n                                }\n\n                            }\n\n                        }\n\n                        for(i=0;i<c->stream->nb_streams;i++) {\n\n                            if (c->feed_streams[i] == pkt.stream_index) {\n\n                                pkt.stream_index = i;\n\n                                if (pkt.flags & PKT_FLAG_KEY) {\n\n                                    c->got_key_frame |= 1 << i;\n\n                                }\n\n                                /* See if we have all the key frames, then \n\n                                 * we start to send. This logic is not quite\n\n                                 * right, but it works for the case of a \n\n                                 * single video stream with one or more\n\n                                 * audio streams (for which every frame is \n\n                                 * typically a key frame). \n\n                                 */\n\n                                if (!c->stream->send_on_key || \n\n                                    ((c->got_key_frame + 1) >> c->stream->nb_streams)) {\n\n                                    goto send_it;\n\n                                }\n\n                            }\n\n                        }\n\n                    } else {\n\n                        AVCodecContext *codec;\n\n                        \n\n                    send_it:\n\n                        /* specific handling for RTP: we use several\n\n                           output stream (one for each RTP\n\n                           connection). XXX: need more abstract handling */\n\n                        if (c->is_packetized) {\n\n                            c->packet_stream_index = pkt.stream_index;\n\n                            ctx = c->rtp_ctx[c->packet_stream_index];\n\n                            codec = &ctx->streams[0]->codec;\n\n                        } else {\n\n                            ctx = &c->fmt_ctx;\n\n                            /* Fudge here */\n\n                            codec = &ctx->streams[pkt.stream_index]->codec;\n\n                        }\n\n                        \n\n                        codec->key_frame = ((pkt.flags & PKT_FLAG_KEY) != 0);\n\n                        \n\n#ifdef PJSG\n\n                        if (codec->codec_type == CODEC_TYPE_AUDIO) {\n\n                            codec->frame_size = (codec->sample_rate * pkt.duration + 500000) / 1000000;\n\n                            /* printf(\"Calculated size %d, from sr %d, duration %d\\n\", codec->frame_size, codec->sample_rate, pkt.duration); */\n\n                        }\n\n#endif\n\n                        \n\n                        if (c->is_packetized) {\n\n                            ret = url_open_dyn_packet_buf(&ctx->pb, \n\n                                                          url_get_max_packet_size(c->rtp_handles[c->packet_stream_index]));\n\n                            c->packet_byte_count = 0;\n\n                            c->packet_start_time_us = av_gettime();\n\n                        } else {\n\n                            ret = url_open_dyn_buf(&ctx->pb);\n\n                        }\n\n                        if (ret < 0) {\n\n                            /* XXX: potential leak */\n\n                            return -1;\n\n                        }\n\n                        if (av_write_packet(ctx, &pkt, pkt.pts)) {\n\n                            c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n                        }\n\n                        \n\n                        len = url_close_dyn_buf(&ctx->pb, &c->pb_buffer);\n\n                        c->buffer_ptr = c->pb_buffer;\n\n                        c->buffer_end = c->pb_buffer + len;\n\n                        \n\n                        codec->frame_number++;\n\n                    }\n\n#ifndef AV_READ_FRAME\n\n                    av_free_packet(&pkt);\n\n#endif\n\n                }\n\n            }\n\n        }\n\n        break;\n\n    default:\n\n    case HTTPSTATE_SEND_DATA_TRAILER:\n\n        /* last packet test ? */\n\n        if (c->last_packet_sent || c->is_packetized)\n\n            return -1;\n\n        ctx = &c->fmt_ctx;\n\n        /* prepare header */\n\n        if (url_open_dyn_buf(&ctx->pb) < 0) {\n\n            /* XXX: potential leak */\n\n            return -1;\n\n        }\n\n        av_write_trailer(ctx);\n\n        len = url_close_dyn_buf(&ctx->pb, &c->pb_buffer);\n\n        c->buffer_ptr = c->pb_buffer;\n\n        c->buffer_end = c->pb_buffer + len;\n\n\n\n        c->last_packet_sent = 1;\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 6282, "_split": "valid", "_hash": "169dc449434525adb4a11a7587ba5f8e"}
{"project": "FFmpeg", "commit_id": "52fa5cea0377974618e8c6486ee0830c2ed9d96a", "target": 0, "func": "static void decode_fixed_sparse(AMRFixed *fixed_sparse, const uint16_t *pulses,\n\n                                const enum Mode mode, const int subframe)\n\n{\n\n    av_assert1(MODE_4k75 <= mode && mode <= MODE_12k2);\n\n\n\n    if (mode == MODE_12k2) {\n\n        ff_decode_10_pulses_35bits(pulses, fixed_sparse, gray_decode, 5, 3);\n\n    } else if (mode == MODE_10k2) {\n\n        decode_8_pulses_31bits(pulses, fixed_sparse);\n\n    } else {\n\n        int *pulse_position = fixed_sparse->x;\n\n        int i, pulse_subset;\n\n        const int fixed_index = pulses[0];\n\n\n\n        if (mode <= MODE_5k15) {\n\n            pulse_subset      = ((fixed_index >> 3) & 8)     + (subframe << 1);\n\n            pulse_position[0] = ( fixed_index       & 7) * 5 + track_position[pulse_subset];\n\n            pulse_position[1] = ((fixed_index >> 3) & 7) * 5 + track_position[pulse_subset + 1];\n\n            fixed_sparse->n = 2;\n\n        } else if (mode == MODE_5k9) {\n\n            pulse_subset      = ((fixed_index & 1) << 1) + 1;\n\n            pulse_position[0] = ((fixed_index >> 1) & 7) * 5 + pulse_subset;\n\n            pulse_subset      = (fixed_index  >> 4) & 3;\n\n            pulse_position[1] = ((fixed_index >> 6) & 7) * 5 + pulse_subset + (pulse_subset == 3 ? 1 : 0);\n\n            fixed_sparse->n = pulse_position[0] == pulse_position[1] ? 1 : 2;\n\n        } else if (mode == MODE_6k7) {\n\n            pulse_position[0] = (fixed_index        & 7) * 5;\n\n            pulse_subset      = (fixed_index  >> 2) & 2;\n\n            pulse_position[1] = ((fixed_index >> 4) & 7) * 5 + pulse_subset + 1;\n\n            pulse_subset      = (fixed_index  >> 6) & 2;\n\n            pulse_position[2] = ((fixed_index >> 8) & 7) * 5 + pulse_subset + 2;\n\n            fixed_sparse->n = 3;\n\n        } else { // mode <= MODE_7k95\n\n            pulse_position[0] = gray_decode[ fixed_index        & 7];\n\n            pulse_position[1] = gray_decode[(fixed_index >> 3)  & 7] + 1;\n\n            pulse_position[2] = gray_decode[(fixed_index >> 6)  & 7] + 2;\n\n            pulse_subset      = (fixed_index >> 9) & 1;\n\n            pulse_position[3] = gray_decode[(fixed_index >> 10) & 7] + pulse_subset + 3;\n\n            fixed_sparse->n = 4;\n\n        }\n\n        for (i = 0; i < fixed_sparse->n; i++)\n\n            fixed_sparse->y[i] = (pulses[1] >> i) & 1 ? 1.0 : -1.0;\n\n    }\n\n}\n", "idx": 6322, "_split": "valid", "_hash": "f59d6f24de16fd11cee2fe19f238a7a3"}
{"project": "FFmpeg", "commit_id": "9d87374ec0f382c8394ad511243db6980afa42af", "target": 0, "func": "static void hb_synthesis(AMRWBContext *ctx, int subframe, float *samples,\n\n                         const float *exc, const float *isf, const float *isf_past)\n\n{\n\n    float hb_lpc[LP_ORDER_16k];\n\n    enum Mode mode = ctx->fr_cur_mode;\n\n\n\n    if (mode == MODE_6k60) {\n\n        float e_isf[LP_ORDER_16k]; // ISF vector for extrapolation\n\n        double e_isp[LP_ORDER_16k];\n\n\n\n        ff_weighted_vector_sumf(e_isf, isf_past, isf, isfp_inter[subframe],\n\n                                1.0 - isfp_inter[subframe], LP_ORDER);\n\n\n\n        extrapolate_isf(e_isf, e_isf);\n\n\n\n        e_isf[LP_ORDER_16k - 1] *= 2.0;\n\n        ff_acelp_lsf2lspd(e_isp, e_isf, LP_ORDER_16k);\n\n        ff_amrwb_lsp2lpc(e_isp, hb_lpc, LP_ORDER_16k);\n\n\n\n        lpc_weighting(hb_lpc, hb_lpc, 0.9, LP_ORDER_16k);\n\n    } else {\n\n        lpc_weighting(hb_lpc, ctx->lp_coef[subframe], 0.6, LP_ORDER);\n\n    }\n\n\n\n    ff_celp_lp_synthesis_filterf(samples, hb_lpc, exc, AMRWB_SFR_SIZE_16k,\n\n                                 (mode == MODE_6k60) ? LP_ORDER_16k : LP_ORDER);\n\n}\n", "idx": 6409, "_split": "valid", "_hash": "0968b6a0057cf9d0c7ed22d6386846c9"}
{"project": "FFmpeg", "commit_id": "c619ff6daf93a8f3c03decf2d3345d2474c3db91", "target": 0, "func": "static always_inline void dv_set_class_number(DCTELEM* blk, EncBlockInfo* bi, \n\n                                              const uint8_t* zigzag_scan, int bias)\n\n{\n\n    int i, area;\n\n    int run;\n\n    int classes[] = {12, 24, 36, 0xffff};\n\n\n\n    run = 0;\n\n    bi->mb[0] = blk[0]; \n\n    bi->cno = 0;\n\n    for (area = 0; area < 4; area++) {\n\n       bi->prev_run[area] = run;\n\n       bi->bit_size[area] = 0;\n\n       for (i=mb_area_start[area]; i<mb_area_start[area+1]; i++) {\n\n          bi->mb[i] = (blk[zigzag_scan[i]] / 16);\n\n          while ((bi->mb[i] ^ (bi->mb[i] >> 8)) > classes[bi->cno])\n\n              bi->cno++;\n\n       \n\n          if (bi->mb[i]) {\n\n              bi->bit_size[area] += dv_rl2vlc_size(run, bi->mb[i]);\n\n\t      run = 0;\n\n          } else\n\n              ++run;\n\n       }\n\n    }\n\n    bi->bit_size[3] += 4; /* EOB marker */\n\n    bi->cno += bias;\n\n    \n\n    if (bi->cno >= 3) { /* FIXME: we have to recreate bit_size[], prev_run[] */\n\n        bi->cno = 3;\n\n\tfor (i=1; i<64; i++)\n\n\t   bi->mb[i] /= 2;\n\n    }\n\n}\n", "idx": 6431, "_split": "valid", "_hash": "016d4d4040ac2dc437107f83b2200f0b"}
{"project": "FFmpeg", "commit_id": "e53c9065ca08a9153ecc73a6a8940bcc6d667e58", "target": 0, "func": "static int test_vector_fmul_window(AVFloatDSPContext *fdsp, AVFloatDSPContext *cdsp,\n\n                                   const float *v1, const float *v2, const float *v3)\n\n{\n\n    LOCAL_ALIGNED(32, float, cdst, [LEN]);\n\n    LOCAL_ALIGNED(32, float, odst, [LEN]);\n\n    int ret;\n\n\n\n    cdsp->vector_fmul_window(cdst, v1, v2, v3, LEN / 2);\n\n    fdsp->vector_fmul_window(odst, v1, v2, v3, LEN / 2);\n\n\n\n    if (ret = compare_floats(cdst, odst, LEN, ARBITRARY_FMUL_WINDOW_CONST))\n\n        av_log(NULL, AV_LOG_ERROR, \"vector_fmul_window failed\\n\");\n\n\n\n    return ret;\n\n}\n", "idx": 6491, "_split": "valid", "_hash": "489953ffa7f346b22fd66c2fe8cc0c02"}
{"project": "FFmpeg", "commit_id": "34ae40971b3299c075878f32479c8059d7acc2bf", "target": 1, "func": "matroska_parse_block(MatroskaDemuxContext *matroska, uint8_t *data, int size,\n\n                     int64_t pos, uint64_t cluster_time, uint64_t duration,\n\n                     int is_keyframe, int is_bframe)\n\n{\n\n    int res = 0;\n\n    int track;\n\n    AVStream *st;\n\n    AVPacket *pkt;\n\n    uint8_t *origdata = data;\n\n    int16_t block_time;\n\n    uint32_t *lace_size = NULL;\n\n    int n, flags, laces = 0;\n\n    uint64_t num;\n\n    int stream_index;\n\n\n\n    /* first byte(s): tracknum */\n\n    if ((n = matroska_ebmlnum_uint(data, size, &num)) < 0) {\n\n        av_log(matroska->ctx, AV_LOG_ERROR, \"EBML block data error\\n\");\n\n        av_free(origdata);\n\n        return res;\n\n    }\n\n    data += n;\n\n    size -= n;\n\n\n\n    /* fetch track from num */\n\n    track = matroska_find_track_by_num(matroska, num);\n\n    if (size <= 3 || track < 0 || track >= matroska->num_tracks) {\n\n        av_log(matroska->ctx, AV_LOG_INFO,\n\n               \"Invalid stream %d or size %u\\n\", track, size);\n\n        av_free(origdata);\n\n        return res;\n\n    }\n\n    stream_index = matroska->tracks[track]->stream_index;\n\n    if (stream_index < 0 || stream_index >= matroska->ctx->nb_streams) {\n\n        av_free(origdata);\n\n        return res;\n\n    }\n\n    st = matroska->ctx->streams[stream_index];\n\n    if (st->discard >= AVDISCARD_ALL) {\n\n        av_free(origdata);\n\n        return res;\n\n    }\n\n    if (duration == AV_NOPTS_VALUE)\n\n        duration = matroska->tracks[track]->default_duration / matroska->time_scale;\n\n\n\n    /* block_time (relative to cluster time) */\n\n    block_time = AV_RB16(data);\n\n    data += 2;\n\n    flags = *data++;\n\n    size -= 3;\n\n    if (is_keyframe == -1)\n\n        is_keyframe = flags & 0x80 ? PKT_FLAG_KEY : 0;\n\n\n\n    if (matroska->skip_to_keyframe) {\n\n        if (!is_keyframe || st != matroska->skip_to_stream) {\n\n            av_free(origdata);\n\n            return res;\n\n        }\n\n        matroska->skip_to_keyframe = 0;\n\n    }\n\n\n\n    switch ((flags & 0x06) >> 1) {\n\n        case 0x0: /* no lacing */\n\n            laces = 1;\n\n            lace_size = av_mallocz(sizeof(int));\n\n            lace_size[0] = size;\n\n            break;\n\n\n\n        case 0x1: /* xiph lacing */\n\n        case 0x2: /* fixed-size lacing */\n\n        case 0x3: /* EBML lacing */\n\n            assert(size>0); // size <=3 is checked before size-=3 above\n\n            laces = (*data) + 1;\n\n            data += 1;\n\n            size -= 1;\n\n            lace_size = av_mallocz(laces * sizeof(int));\n\n\n\n            switch ((flags & 0x06) >> 1) {\n\n                case 0x1: /* xiph lacing */ {\n\n                    uint8_t temp;\n\n                    uint32_t total = 0;\n\n                    for (n = 0; res == 0 && n < laces - 1; n++) {\n\n                        while (1) {\n\n                            if (size == 0) {\n\n                                res = -1;\n\n                                break;\n\n                            }\n\n                            temp = *data;\n\n                            lace_size[n] += temp;\n\n                            data += 1;\n\n                            size -= 1;\n\n                            if (temp != 0xff)\n\n                                break;\n\n                        }\n\n                        total += lace_size[n];\n\n                    }\n\n                    lace_size[n] = size - total;\n\n                    break;\n\n                }\n\n\n\n                case 0x2: /* fixed-size lacing */\n\n                    for (n = 0; n < laces; n++)\n\n                        lace_size[n] = size / laces;\n\n                    break;\n\n\n\n                case 0x3: /* EBML lacing */ {\n\n                    uint32_t total;\n\n                    n = matroska_ebmlnum_uint(data, size, &num);\n\n                    if (n < 0) {\n\n                        av_log(matroska->ctx, AV_LOG_INFO,\n\n                               \"EBML block data error\\n\");\n\n                        break;\n\n                    }\n\n                    data += n;\n\n                    size -= n;\n\n                    total = lace_size[0] = num;\n\n                    for (n = 1; res == 0 && n < laces - 1; n++) {\n\n                        int64_t snum;\n\n                        int r;\n\n                        r = matroska_ebmlnum_sint (data, size, &snum);\n\n                        if (r < 0) {\n\n                            av_log(matroska->ctx, AV_LOG_INFO,\n\n                                   \"EBML block data error\\n\");\n\n                            break;\n\n                        }\n\n                        data += r;\n\n                        size -= r;\n\n                        lace_size[n] = lace_size[n - 1] + snum;\n\n                        total += lace_size[n];\n\n                    }\n\n                    lace_size[n] = size - total;\n\n                    break;\n\n                }\n\n            }\n\n            break;\n\n    }\n\n\n\n    if (res == 0) {\n\n        uint64_t timecode = AV_NOPTS_VALUE;\n\n\n\n        if (cluster_time != (uint64_t)-1\n\n            && (block_time >= 0 || cluster_time >= -block_time))\n\n            timecode = cluster_time + block_time;\n\n\n\n        for (n = 0; n < laces; n++) {\n\n            if (st->codec->codec_id == CODEC_ID_RA_288 ||\n\n                st->codec->codec_id == CODEC_ID_COOK ||\n\n                st->codec->codec_id == CODEC_ID_ATRAC3) {\n\n                MatroskaAudioTrack *audiotrack = (MatroskaAudioTrack *)matroska->tracks[track];\n\n                int a = st->codec->block_align;\n\n                int sps = audiotrack->sub_packet_size;\n\n                int cfs = audiotrack->coded_framesize;\n\n                int h = audiotrack->sub_packet_h;\n\n                int y = audiotrack->sub_packet_cnt;\n\n                int w = audiotrack->frame_size;\n\n                int x;\n\n\n\n                if (!audiotrack->pkt_cnt) {\n\n                    if (st->codec->codec_id == CODEC_ID_RA_288)\n\n                        for (x=0; x<h/2; x++)\n\n                            memcpy(audiotrack->buf+x*2*w+y*cfs,\n\n                                   data+x*cfs, cfs);\n\n                    else\n\n                        for (x=0; x<w/sps; x++)\n\n                            memcpy(audiotrack->buf+sps*(h*x+((h+1)/2)*(y&1)+(y>>1)), data+x*sps, sps);\n\n\n\n                    if (++audiotrack->sub_packet_cnt >= h) {\n\n                        audiotrack->sub_packet_cnt = 0;\n\n                        audiotrack->pkt_cnt = h*w / a;\n\n                    }\n\n                }\n\n                while (audiotrack->pkt_cnt) {\n\n                    pkt = av_mallocz(sizeof(AVPacket));\n\n                    av_new_packet(pkt, a);\n\n                    memcpy(pkt->data, audiotrack->buf\n\n                           + a * (h*w / a - audiotrack->pkt_cnt--), a);\n\n                    pkt->pos = pos;\n\n                    pkt->stream_index = stream_index;\n\n                    matroska_queue_packet(matroska, pkt);\n\n                }\n\n            } else {\n\n                int result, offset = 0, ilen, olen, pkt_size = lace_size[n];\n\n                uint8_t *pkt_data = data;\n\n\n\n                if (matroska->tracks[track]->encoding_scope & 1) {\n\n                    switch (matroska->tracks[track]->encoding_algo) {\n\n                    case MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP:\n\n                        offset = matroska->tracks[track]->encoding_settings_len;\n\n                        break;\n\n                    case MATROSKA_TRACK_ENCODING_COMP_LZO:\n\n                        pkt_data = NULL;\n\n                        do {\n\n                            ilen = lace_size[n];\n\n                            olen = pkt_size *= 3;\n\n                            pkt_data = av_realloc(pkt_data,\n\n                                                  pkt_size+LZO_OUTPUT_PADDING);\n\n                            result = lzo1x_decode(pkt_data, &olen, data, &ilen);\n\n                        } while (result==LZO_OUTPUT_FULL && pkt_size<10000000);\n\n                        if (result) {\n\n                            av_free(pkt_data);\n\n                            continue;\n\n                        }\n\n                        pkt_size -= olen;\n\n                        break;\n\n#ifdef CONFIG_ZLIB\n\n                    case MATROSKA_TRACK_ENCODING_COMP_ZLIB: {\n\n                        z_stream zstream = {0};\n\n                        pkt_data = NULL;\n\n                        if (inflateInit(&zstream) != Z_OK)\n\n                            continue;\n\n                        zstream.next_in = data;\n\n                        zstream.avail_in = lace_size[n];\n\n                        do {\n\n                            pkt_size *= 3;\n\n                            pkt_data = av_realloc(pkt_data, pkt_size);\n\n                            zstream.avail_out = pkt_size - zstream.total_out;\n\n                            zstream.next_out = pkt_data + zstream.total_out;\n\n                            result = inflate(&zstream, Z_NO_FLUSH);\n\n                        } while (result==Z_OK && pkt_size<10000000);\n\n                        pkt_size = zstream.total_out;\n\n                        inflateEnd(&zstream);\n\n                        if (result != Z_STREAM_END) {\n\n                            av_free(pkt_data);\n\n                            continue;\n\n                        }\n\n                        break;\n\n                    }\n\n#endif\n\n#ifdef CONFIG_BZLIB\n\n                    case MATROSKA_TRACK_ENCODING_COMP_BZLIB: {\n\n                        bz_stream bzstream = {0};\n\n                        pkt_data = NULL;\n\n                        if (BZ2_bzDecompressInit(&bzstream, 0, 0) != BZ_OK)\n\n                            continue;\n\n                        bzstream.next_in = data;\n\n                        bzstream.avail_in = lace_size[n];\n\n                        do {\n\n                            pkt_size *= 3;\n\n                            pkt_data = av_realloc(pkt_data, pkt_size);\n\n                            bzstream.avail_out = pkt_size - bzstream.total_out_lo32;\n\n                            bzstream.next_out = pkt_data + bzstream.total_out_lo32;\n\n                            result = BZ2_bzDecompress(&bzstream);\n\n                        } while (result==BZ_OK && pkt_size<10000000);\n\n                        pkt_size = bzstream.total_out_lo32;\n\n                        BZ2_bzDecompressEnd(&bzstream);\n\n                        if (result != BZ_STREAM_END) {\n\n                            av_free(pkt_data);\n\n                            continue;\n\n                        }\n\n                        break;\n\n                    }\n\n#endif\n\n                    }\n\n                }\n\n\n\n                pkt = av_mallocz(sizeof(AVPacket));\n\n                /* XXX: prevent data copy... */\n\n                if (av_new_packet(pkt, pkt_size+offset) < 0) {\n\n\n                    res = AVERROR(ENOMEM);\n\n                    n = laces-1;\n\n                    break;\n\n                }\n\n                if (offset)\n\n                    memcpy (pkt->data, matroska->tracks[track]->encoding_settings, offset);\n\n                memcpy (pkt->data+offset, pkt_data, pkt_size);\n\n\n\n                if (n == 0)\n\n                    pkt->flags = is_keyframe;\n\n                pkt->stream_index = stream_index;\n\n\n\n                pkt->pts = timecode;\n\n                pkt->pos = pos;\n\n                pkt->duration = duration;\n\n\n\n                matroska_queue_packet(matroska, pkt);\n\n            }\n\n\n\n            if (timecode != AV_NOPTS_VALUE)\n\n                timecode = duration ? timecode + duration : AV_NOPTS_VALUE;\n\n            data += lace_size[n];\n\n        }\n\n    }\n\n\n\n    av_free(lace_size);\n\n    av_free(origdata);\n\n    return res;\n\n}", "idx": 6504, "_split": "valid", "_hash": "b07936384f8e0fc0519cfbdea8d1d0bb"}
{"project": "FFmpeg", "commit_id": "14de55784dcf0b875dab35896c9e55d5792c6fd4", "target": 1, "func": "yuv2planeX_16_c_template(const int16_t *filter, int filterSize,\n\n                         const int32_t **src, uint16_t *dest, int dstW,\n\n                         int big_endian, int output_bits)\n\n{\n\n    int i;\n\n    int shift = 15;\n\n    av_assert0(output_bits == 16);\n\n\n\n    for (i = 0; i < dstW; i++) {\n\n        int val = 1 << (shift - 1);\n\n        int j;\n\n\n\n        /* range of val is [0,0x7FFFFFFF], so 31 bits, but with lanczos/spline\n\n         * filters (or anything with negative coeffs, the range can be slightly\n\n         * wider in both directions. To account for this overflow, we subtract\n\n         * a constant so it always fits in the signed range (assuming a\n\n         * reasonable filterSize), and re-add that at the end. */\n\n        val -= 0x40000000;\n\n        for (j = 0; j < filterSize; j++)\n\n            val += src[j][i] * filter[j];\n\n\n\n        output_pixel(&dest[i], val, 0x8000, int);\n\n    }\n\n}\n", "idx": 6515, "_split": "valid", "_hash": "5d755a4fa891d0045f559febf41ecc10"}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static int generate_coupling_coordinates(AC3DecodeContext * ctx)\n\n{\n\n    ac3_audio_block *ab = &ctx->audio_block;\n\n    uint8_t exp, mstrcplco;\n\n    int16_t mant;\n\n    uint32_t cplbndstrc = (1 << ab->ncplsubnd) >> 1;\n\n    int ch, bnd, sbnd;\n\n    float cplco;\n\n\n\n    if (ab->cplcoe)\n\n        for (ch = 0; ch < ctx->bsi.nfchans; ch++)\n\n            if (ab->cplcoe & (1 << ch)) {\n\n                mstrcplco = 3 * ab->mstrcplco[ch];\n\n                sbnd = ab->cplbegf;\n\n                for (bnd = 0; bnd < ab->ncplbnd; bnd++) {\n\n                    exp = ab->cplcoexp[ch][bnd];\n\n                    if (exp == 15)\n\n                        mant = ab->cplcomant[ch][bnd] <<= 14;\n\n                    else\n\n                        mant = (ab->cplcomant[ch][bnd] | 0x10) << 13;\n\n                    cplco = to_float(exp + mstrcplco, mant);\n\n                    if (ctx->bsi.acmod == 0x02 && (ab->flags & AC3_AB_PHSFLGINU) && ch == 1\n\n                            && (ab->phsflg & (1 << bnd)))\n\n                        cplco = -cplco; /* invert the right channel */\n\n                    ab->cplco[ch][sbnd++] = cplco;\n\n                    while (cplbndstrc & ab->cplbndstrc) {\n\n                        cplbndstrc >>= 1;\n\n                        ab->cplco[ch][sbnd++] = cplco;\n\n                    }\n\n                    cplbndstrc >>= 1;\n\n                }\n\n            }\n\n\n\n    return 0;\n\n}\n", "idx": 6517, "_split": "valid", "_hash": "adcb1ffec478e6c7238339f981902586"}
{"project": "FFmpeg", "commit_id": "e20e9b9033b75fac32a4a3bc2cdd3fcc3cedb33a", "target": 1, "func": "static void fifo_deinit(AVFormatContext *avf)\n\n{\n\n    FifoContext *fifo = avf->priv_data;\n\n\n\n    av_dict_free(&fifo->format_options);\n\n    avformat_free_context(fifo->avf);\n\n    av_thread_message_queue_free(&fifo->queue);\n\n    pthread_mutex_destroy(&fifo->overflow_flag_lock);\n\n}\n", "idx": 6523, "_split": "valid", "_hash": "42784db1478e5d055d7bd34bcdf6e266"}
{"project": "FFmpeg", "commit_id": "bfcc38ef4815229e0aa9d8417611e0f666bb4fc7", "target": 1, "func": "static av_cold int vpx_init(AVCodecContext *avctx,\n                            const struct vpx_codec_iface *iface)\n{\n    VP8Context *ctx = avctx->priv_data;\n    struct vpx_codec_enc_cfg enccfg;\n    int res;\n    av_log(avctx, AV_LOG_INFO, \"%s\\n\", vpx_codec_version_str());\n    av_log(avctx, AV_LOG_VERBOSE, \"%s\\n\", vpx_codec_build_config());\n    if ((res = vpx_codec_enc_config_default(iface, &enccfg, 0)) != VPX_CODEC_OK) {\n        av_log(avctx, AV_LOG_ERROR, \"Failed to get config: %s\\n\",\n               vpx_codec_err_to_string(res));\n    if(!avctx->bit_rate)\n        if(avctx->rc_max_rate || avctx->rc_buffer_size || avctx->rc_initial_buffer_occupancy) {\n            av_log( avctx, AV_LOG_ERROR, \"Rate control parameters set without a bitrate\\n\");\n    dump_enc_cfg(avctx, &enccfg);\n    enccfg.g_w            = avctx->width;\n    enccfg.g_h            = avctx->height;\n    enccfg.g_timebase.num = avctx->time_base.num;\n    enccfg.g_timebase.den = avctx->time_base.den;\n    enccfg.g_threads      = avctx->thread_count;\n    enccfg.g_lag_in_frames= ctx->lag_in_frames;\n    if (avctx->flags & CODEC_FLAG_PASS1)\n        enccfg.g_pass = VPX_RC_FIRST_PASS;\n    else if (avctx->flags & CODEC_FLAG_PASS2)\n        enccfg.g_pass = VPX_RC_LAST_PASS;\n    else\n        enccfg.g_pass = VPX_RC_ONE_PASS;\n    if (avctx->rc_min_rate == avctx->rc_max_rate &&\n        avctx->rc_min_rate == avctx->bit_rate && avctx->bit_rate)\n        enccfg.rc_end_usage = VPX_CBR;\n    else if (ctx->crf)\n        enccfg.rc_end_usage = VPX_CQ;\n    if (avctx->bit_rate) {\n        enccfg.rc_target_bitrate = av_rescale_rnd(avctx->bit_rate, 1, 1000,\n                                                AV_ROUND_NEAR_INF);\n    } else {\n            enccfg.rc_target_bitrate = 1000000;\n        } else {\n            avctx->bit_rate = enccfg.rc_target_bitrate * 1000;\n            av_log(avctx, AV_LOG_WARNING,\n                   \"Neither bitrate nor constrained quality specified, using default bitrate of %dkbit/sec\\n\",\n                   enccfg.rc_target_bitrate);\n    if (avctx->qmin >= 0)\n        enccfg.rc_min_quantizer = avctx->qmin;\n    if (avctx->qmax > 0)\n        enccfg.rc_max_quantizer = avctx->qmax;\n    enccfg.rc_dropframe_thresh = avctx->frame_skip_threshold;\n    //0-100 (0 => CBR, 100 => VBR)\n    enccfg.rc_2pass_vbr_bias_pct           = round(avctx->qcompress * 100);\n    if (avctx->bit_rate)\n        enccfg.rc_2pass_vbr_minsection_pct     =\n            avctx->rc_min_rate * 100LL / avctx->bit_rate;\n    if (avctx->rc_max_rate)\n        enccfg.rc_2pass_vbr_maxsection_pct =\n            avctx->rc_max_rate * 100LL / avctx->bit_rate;\n    if (avctx->rc_buffer_size)\n        enccfg.rc_buf_sz         =\n            avctx->rc_buffer_size * 1000LL / avctx->bit_rate;\n    if (avctx->rc_initial_buffer_occupancy)\n        enccfg.rc_buf_initial_sz =\n            avctx->rc_initial_buffer_occupancy * 1000LL / avctx->bit_rate;\n    enccfg.rc_buf_optimal_sz     = enccfg.rc_buf_sz * 5 / 6;\n    enccfg.rc_undershoot_pct     = round(avctx->rc_buffer_aggressivity * 100);\n    //_enc_init() will balk if kf_min_dist differs from max w/VPX_KF_AUTO\n    if (avctx->keyint_min >= 0 && avctx->keyint_min == avctx->gop_size)\n        enccfg.kf_min_dist = avctx->keyint_min;\n    if (avctx->gop_size >= 0)\n        enccfg.kf_max_dist = avctx->gop_size;\n    if (enccfg.g_pass == VPX_RC_FIRST_PASS)\n        enccfg.g_lag_in_frames = 0;\n    else if (enccfg.g_pass == VPX_RC_LAST_PASS) {\n        int decode_size;\n        if (!avctx->stats_in) {\n            av_log(avctx, AV_LOG_ERROR, \"No stats file for second pass\\n\");\n            return AVERROR_INVALIDDATA;\n        ctx->twopass_stats.sz  = strlen(avctx->stats_in) * 3 / 4;\n        ctx->twopass_stats.buf = av_malloc(ctx->twopass_stats.sz);\n        if (!ctx->twopass_stats.buf) {\n                   \"Stat buffer alloc (%zu bytes) failed\\n\",\n                   ctx->twopass_stats.sz);\n            return AVERROR(ENOMEM);\n        decode_size = av_base64_decode(ctx->twopass_stats.buf, avctx->stats_in,\n                                       ctx->twopass_stats.sz);\n        if (decode_size < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Stat buffer decode failed\\n\");\n            return AVERROR_INVALIDDATA;\n        ctx->twopass_stats.sz      = decode_size;\n        enccfg.rc_twopass_stats_in = ctx->twopass_stats;\n    /* 0-3: For non-zero values the encoder increasingly optimizes for reduced\n       complexity playback on low powered devices at the expense of encode\n       quality. */\n   if (avctx->profile != FF_PROFILE_UNKNOWN)\n       enccfg.g_profile = avctx->profile;\n    enccfg.g_error_resilient = ctx->error_resilient || ctx->flags & VP8F_ERROR_RESILIENT;\n    dump_enc_cfg(avctx, &enccfg);\n    /* Construct Encoder Context */\n    res = vpx_codec_enc_init(&ctx->encoder, iface, &enccfg, 0);\n    if (res != VPX_CODEC_OK) {\n        log_encoder_error(avctx, \"Failed to initialize encoder\");\n    //codec control failures are currently treated only as warnings\n    av_log(avctx, AV_LOG_DEBUG, \"vpx_codec_control\\n\");\n    if (ctx->cpu_used != INT_MIN)\n        codecctl_int(avctx, VP8E_SET_CPUUSED,          ctx->cpu_used);\n    if (ctx->flags & VP8F_AUTO_ALT_REF)\n        ctx->auto_alt_ref = 1;\n    if (ctx->auto_alt_ref >= 0)\n        codecctl_int(avctx, VP8E_SET_ENABLEAUTOALTREF, ctx->auto_alt_ref);\n    if (ctx->arnr_max_frames >= 0)\n        codecctl_int(avctx, VP8E_SET_ARNR_MAXFRAMES,   ctx->arnr_max_frames);\n    if (ctx->arnr_strength >= 0)\n        codecctl_int(avctx, VP8E_SET_ARNR_STRENGTH,    ctx->arnr_strength);\n    if (ctx->arnr_type >= 0)\n        codecctl_int(avctx, VP8E_SET_ARNR_TYPE,        ctx->arnr_type);\n    codecctl_int(avctx, VP8E_SET_NOISE_SENSITIVITY, avctx->noise_reduction);\n    codecctl_int(avctx, VP8E_SET_TOKEN_PARTITIONS,  av_log2(avctx->slices));\n    codecctl_int(avctx, VP8E_SET_STATIC_THRESHOLD,  avctx->mb_threshold);\n    codecctl_int(avctx, VP8E_SET_CQ_LEVEL,          ctx->crf);\n    if (ctx->max_intra_rate >= 0)\n        codecctl_int(avctx, VP8E_SET_MAX_INTRA_BITRATE_PCT, ctx->max_intra_rate);\n    av_log(avctx, AV_LOG_DEBUG, \"Using deadline: %d\\n\", ctx->deadline);\n    //provide dummy value to initialize wrapper, values will be updated each _encode()\n    vpx_img_wrap(&ctx->rawimg, VPX_IMG_FMT_I420, avctx->width, avctx->height, 1,\n                 (unsigned char*)1);\n    avctx->coded_frame = avcodec_alloc_frame();\n    if (!avctx->coded_frame) {\n        av_log(avctx, AV_LOG_ERROR, \"Error allocating coded frame\\n\");\n        vp8_free(avctx);\n        return AVERROR(ENOMEM);\n    return 0;", "idx": 6553, "_split": "valid", "_hash": "9df301dfaca4fafb9ca7ee66db85b294"}
{"project": "FFmpeg", "commit_id": "4c5e7b27d57dd2be777780e840eef9be63242158", "target": 1, "func": "static int get_metadata_size(const uint8_t *buf, int buf_size)\n\n{\n\n    int metadata_last, metadata_size;\n\n    const uint8_t *buf_end = buf + buf_size;\n\n\n\n    buf += 4;\n\n    do {\n\n        ff_flac_parse_block_header(buf, &metadata_last, NULL, &metadata_size);\n\n        buf += 4;\n\n        if (buf + metadata_size > buf_end) {\n\n            /* need more data in order to read the complete header */\n\n            return 0;\n\n        }\n\n        buf += metadata_size;\n\n    } while (!metadata_last);\n\n\n\n    return buf_size - (buf_end - buf);\n\n}\n", "idx": 6557, "_split": "valid", "_hash": "0418f97bde0212612b7cbd4671ea6c71"}
{"project": "FFmpeg", "commit_id": "2fed05f53a881b64a02de7a324d67d8c029c6cf1", "target": 1, "func": "static av_cold int msrle_decode_init(AVCodecContext *avctx)\n\n{\n\n    MsrleContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    s->avctx = avctx;\n\n\n\n    switch (avctx->bits_per_coded_sample) {\n\n    case 1:\n\n        avctx->pix_fmt = AV_PIX_FMT_MONOWHITE;\n\n        break;\n\n    case 4:\n\n    case 8:\n\n        avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n        break;\n\n    case 24:\n\n        avctx->pix_fmt = AV_PIX_FMT_BGR24;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported bits per sample\\n\");\n\n        return -1;\n\n    }\n\n\n\n    avcodec_get_frame_defaults(&s->frame);\n\n    s->frame.data[0] = NULL;\n\n\n\n    if (avctx->extradata_size >= AVPALETTE_SIZE)\n\n        for (i = 0; i < AVPALETTE_SIZE/4; i++)\n\n            s->pal[i] = 0xFF<<24 | AV_RL32(avctx->extradata+4*i);\n\n\n\n    return 0;\n\n}\n", "idx": 6569, "_split": "valid", "_hash": "a4296c7111fefb335b244472cc831374"}
{"project": "FFmpeg", "commit_id": "420d1df2e2a857eae45fa947e16eae7494793d57", "target": 0, "func": "static inline int ape_decode_value(APEContext *ctx, APERice *rice)\n\n{\n\n    int x, overflow;\n\n\n\n    if (ctx->fileversion < 3990) {\n\n        int tmpk;\n\n\n\n        overflow = range_get_symbol(ctx, counts_3970, counts_diff_3970);\n\n\n\n        if (overflow == (MODEL_ELEMENTS - 1)) {\n\n            tmpk = range_decode_bits(ctx, 5);\n\n            overflow = 0;\n\n        } else\n\n            tmpk = (rice->k < 1) ? 0 : rice->k - 1;\n\n\n\n        if (tmpk <= 16)\n\n            x = range_decode_bits(ctx, tmpk);\n\n        else {\n\n            x = range_decode_bits(ctx, 16);\n\n            x |= (range_decode_bits(ctx, tmpk - 16) << 16);\n\n        }\n\n        x += overflow << tmpk;\n\n    } else {\n\n        int base, pivot;\n\n\n\n        pivot = rice->ksum >> 5;\n\n        if (pivot == 0)\n\n            pivot = 1;\n\n\n\n        overflow = range_get_symbol(ctx, counts_3980, counts_diff_3980);\n\n\n\n        if (overflow == (MODEL_ELEMENTS - 1)) {\n\n            overflow  = range_decode_bits(ctx, 16) << 16;\n\n            overflow |= range_decode_bits(ctx, 16);\n\n        }\n\n\n\n        if (pivot < 0x10000) {\n\n            base = range_decode_culfreq(ctx, pivot);\n\n            range_decode_update(ctx, 1, base);\n\n        } else {\n\n            int base_hi = pivot, base_lo;\n\n            int bbits = 0;\n\n\n\n            while (base_hi & ~0xFFFF) {\n\n                base_hi >>= 1;\n\n                bbits++;\n\n            }\n\n            base_hi = range_decode_culfreq(ctx, base_hi + 1);\n\n            range_decode_update(ctx, 1, base_hi);\n\n            base_lo = range_decode_culfreq(ctx, 1 << bbits);\n\n            range_decode_update(ctx, 1, base_lo);\n\n\n\n            base = (base_hi << bbits) + base_lo;\n\n        }\n\n\n\n        x = base + overflow * pivot;\n\n    }\n\n\n\n    update_rice(rice, x);\n\n\n\n    /* Convert to signed */\n\n    if (x & 1)\n\n        return (x >> 1) + 1;\n\n    else\n\n        return -(x >> 1);\n\n}\n", "idx": 6618, "_split": "valid", "_hash": "16580f64cf8408f77ca15b827a04fd12"}
{"project": "FFmpeg", "commit_id": "0d4a66ee7f48c65ac67f4d91c8f8f2bfd47afa0d", "target": 0, "func": "int ffio_ensure_seekback(AVIOContext *s, int buf_size)\n\n{\n\n    uint8_t *buffer;\n\n    int max_buffer_size = s->max_packet_size ?\n\n                          s->max_packet_size : IO_BUFFER_SIZE;\n\n\n\n    buf_size += s->buf_ptr - s->buffer + max_buffer_size;\n\n\n\n    if (buf_size < s->buffer_size || s->seekable)\n\n        return 0;\n\n    av_assert0(!s->write_flag);\n\n\n\n    buffer = av_malloc(buf_size);\n\n    if (!buffer)\n\n        return AVERROR(ENOMEM);\n\n\n\n    memcpy(buffer, s->buffer, s->buffer_size);\n\n    av_free(s->buffer);\n\n    s->buf_ptr = buffer + (s->buf_ptr - s->buffer);\n\n    s->buf_end = buffer + (s->buf_end - s->buffer);\n\n    s->buffer = buffer;\n\n    s->buffer_size = buf_size;\n\n    return 0;\n\n}\n", "idx": 6619, "_split": "valid", "_hash": "c15ec8aea0d6c617a9bc50eba619b32b"}
{"project": "FFmpeg", "commit_id": "3e6b7bbce510c53b4d7962f29aaf745c9b729775", "target": 1, "func": "static int film_probe(AVProbeData *p)\n{\n    if (AV_RB32(&p->buf[0]) != FILM_TAG)\n    return AVPROBE_SCORE_MAX;\n}", "idx": 6626, "_split": "valid", "_hash": "dac2f9794f420ed7e8dae9697108939e"}
{"project": "FFmpeg", "commit_id": "114f3f526e5ad1557c514fe1213dd87f4ebe6f6a", "target": 0, "func": "static int plot_cqt(AVFilterLink *inlink)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    ShowCQTContext *s = ctx->priv;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    int fft_len = 1 << s->fft_bits;\n\n    FFTSample result[VIDEO_WIDTH][4];\n\n    int x, y, ret = 0;\n\n    int linesize = s->outpicref->linesize[0];\n\n    int video_scale = s->fullhd ? 2 : 1;\n\n    int video_width = (VIDEO_WIDTH/2) * video_scale;\n\n    int spectogram_height = (SPECTOGRAM_HEIGHT/2) * video_scale;\n\n    int spectogram_start = (SPECTOGRAM_START/2) * video_scale;\n\n    int font_height = (FONT_HEIGHT/2) * video_scale;\n\n\n\n    /* real part contains left samples, imaginary part contains right samples */\n\n    memcpy(s->fft_result, s->fft_data, fft_len * sizeof(*s->fft_data));\n\n    av_fft_permute(s->fft_context, s->fft_result);\n\n    av_fft_calc(s->fft_context, s->fft_result);\n\n    s->fft_result[fft_len] = s->fft_result[0];\n\n\n\n    /* calculating cqt */\n\n    for (x = 0; x < VIDEO_WIDTH; x++) {\n\n        int u;\n\n        FFTComplex v = {0,0};\n\n        FFTComplex w = {0,0};\n\n        FFTComplex l, r;\n\n\n\n        for (u = 0; u < s->coeffs[x].len; u++) {\n\n            FFTSample value = s->coeffs[x].values[u];\n\n            int index = s->coeffs[x].start + u;\n\n            v.re += value * s->fft_result[index].re;\n\n            v.im += value * s->fft_result[index].im;\n\n            w.re += value * s->fft_result[fft_len - index].re;\n\n            w.im += value * s->fft_result[fft_len - index].im;\n\n        }\n\n\n\n        /* separate left and right, (and multiply by 2.0) */\n\n        l.re = v.re + w.re;\n\n        l.im = v.im - w.im;\n\n        r.re = w.im + v.im;\n\n        r.im = w.re - v.re;\n\n        /* result is power, not amplitude */\n\n        result[x][0] = l.re * l.re + l.im * l.im;\n\n        result[x][2] = r.re * r.re + r.im * r.im;\n\n        result[x][1] = 0.5f * (result[x][0] + result[x][2]);\n\n\n\n        if (s->gamma2 == 1.0f)\n\n            result[x][3] = result[x][1];\n\n        else if (s->gamma2 == 2.0f)\n\n            result[x][3] = sqrtf(result[x][1]);\n\n        else if (s->gamma2 == 3.0f)\n\n            result[x][3] = cbrtf(result[x][1]);\n\n        else if (s->gamma2 == 4.0f)\n\n            result[x][3] = sqrtf(sqrtf(result[x][1]));\n\n        else\n\n            result[x][3] = expf(logf(result[x][1]) * (1.0f / s->gamma2));\n\n\n\n        result[x][0] = FFMIN(1.0f, result[x][0]);\n\n        result[x][1] = FFMIN(1.0f, result[x][1]);\n\n        result[x][2] = FFMIN(1.0f, result[x][2]);\n\n        if (s->gamma == 1.0f) {\n\n            result[x][0] = 255.0f * result[x][0];\n\n            result[x][1] = 255.0f * result[x][1];\n\n            result[x][2] = 255.0f * result[x][2];\n\n        } else if (s->gamma == 2.0f) {\n\n            result[x][0] = 255.0f * sqrtf(result[x][0]);\n\n            result[x][1] = 255.0f * sqrtf(result[x][1]);\n\n            result[x][2] = 255.0f * sqrtf(result[x][2]);\n\n        } else if (s->gamma == 3.0f) {\n\n            result[x][0] = 255.0f * cbrtf(result[x][0]);\n\n            result[x][1] = 255.0f * cbrtf(result[x][1]);\n\n            result[x][2] = 255.0f * cbrtf(result[x][2]);\n\n        } else if (s->gamma == 4.0f) {\n\n            result[x][0] = 255.0f * sqrtf(sqrtf(result[x][0]));\n\n            result[x][1] = 255.0f * sqrtf(sqrtf(result[x][1]));\n\n            result[x][2] = 255.0f * sqrtf(sqrtf(result[x][2]));\n\n        } else {\n\n            result[x][0] = 255.0f * expf(logf(result[x][0]) * (1.0f / s->gamma));\n\n            result[x][1] = 255.0f * expf(logf(result[x][1]) * (1.0f / s->gamma));\n\n            result[x][2] = 255.0f * expf(logf(result[x][2]) * (1.0f / s->gamma));\n\n        }\n\n    }\n\n\n\n    if (!s->fullhd) {\n\n        for (x = 0; x < video_width; x++) {\n\n            result[x][0] = 0.5f * (result[2*x][0] + result[2*x+1][0]);\n\n            result[x][1] = 0.5f * (result[2*x][1] + result[2*x+1][1]);\n\n            result[x][2] = 0.5f * (result[2*x][2] + result[2*x+1][2]);\n\n            result[x][3] = 0.5f * (result[2*x][3] + result[2*x+1][3]);\n\n        }\n\n    }\n\n\n\n    for (x = 0; x < video_width; x++) {\n\n        s->spectogram[s->spectogram_index*linesize + 3*x] = result[x][0] + 0.5f;\n\n        s->spectogram[s->spectogram_index*linesize + 3*x + 1] = result[x][1] + 0.5f;\n\n        s->spectogram[s->spectogram_index*linesize + 3*x + 2] = result[x][2] + 0.5f;\n\n    }\n\n\n\n    /* drawing */\n\n    if (!s->spectogram_count) {\n\n        uint8_t *data = (uint8_t*) s->outpicref->data[0];\n\n        float rcp_result[VIDEO_WIDTH];\n\n        int total_length = linesize * spectogram_height;\n\n        int back_length = linesize * s->spectogram_index;\n\n\n\n        for (x = 0; x < video_width; x++)\n\n            rcp_result[x] = 1.0f / (result[x][3]+0.0001f);\n\n\n\n        /* drawing bar */\n\n        for (y = 0; y < spectogram_height; y++) {\n\n            float height = (spectogram_height - y) * (1.0f/spectogram_height);\n\n            uint8_t *lineptr = data + y * linesize;\n\n            for (x = 0; x < video_width; x++) {\n\n                float mul;\n\n                if (result[x][3] <= height) {\n\n                    *lineptr++ = 0;\n\n                    *lineptr++ = 0;\n\n                    *lineptr++ = 0;\n\n                } else {\n\n                    mul = (result[x][3] - height) * rcp_result[x];\n\n                    *lineptr++ = mul * result[x][0] + 0.5f;\n\n                    *lineptr++ = mul * result[x][1] + 0.5f;\n\n                    *lineptr++ = mul * result[x][2] + 0.5f;\n\n                }\n\n            }\n\n        }\n\n\n\n        /* drawing font */\n\n        if (s->font_alpha && s->draw_text) {\n\n            for (y = 0; y < font_height; y++) {\n\n                uint8_t *lineptr = data + (spectogram_height + y) * linesize;\n\n                uint8_t *spectogram_src = s->spectogram + s->spectogram_index * linesize;\n\n                uint8_t *fontcolor_value = s->fontcolor_value;\n\n                for (x = 0; x < video_width; x++) {\n\n                    uint8_t alpha = s->font_alpha[y*video_width+x];\n\n                    lineptr[3*x] = (spectogram_src[3*x] * (255-alpha) + fontcolor_value[0] * alpha + 255) >> 8;\n\n                    lineptr[3*x+1] = (spectogram_src[3*x+1] * (255-alpha) + fontcolor_value[1] * alpha + 255) >> 8;\n\n                    lineptr[3*x+2] = (spectogram_src[3*x+2] * (255-alpha) + fontcolor_value[2] * alpha + 255) >> 8;\n\n                    fontcolor_value += 3;\n\n                }\n\n            }\n\n        } else if (s->draw_text) {\n\n            for (y = 0; y < font_height; y++) {\n\n                uint8_t *lineptr = data + (spectogram_height + y) * linesize;\n\n                memcpy(lineptr, s->spectogram + s->spectogram_index * linesize, video_width*3);\n\n            }\n\n            for (x = 0; x < video_width; x += video_width/10) {\n\n                int u;\n\n                static const char str[] = \"EF G A BC D \";\n\n                uint8_t *startptr = data + spectogram_height * linesize + x * 3;\n\n                for (u = 0; str[u]; u++) {\n\n                    int v;\n\n                    for (v = 0; v < 16; v++) {\n\n                        uint8_t *p = startptr + v * linesize * video_scale + 8 * 3 * u * video_scale;\n\n                        int ux = x + 8 * u * video_scale;\n\n                        int mask;\n\n                        for (mask = 0x80; mask; mask >>= 1) {\n\n                            if (mask & avpriv_vga16_font[str[u] * 16 + v]) {\n\n                                p[0] = s->fontcolor_value[3*ux];\n\n                                p[1] = s->fontcolor_value[3*ux+1];\n\n                                p[2] = s->fontcolor_value[3*ux+2];\n\n                                if (video_scale == 2) {\n\n                                    p[linesize] = p[0];\n\n                                    p[linesize+1] = p[1];\n\n                                    p[linesize+2] = p[2];\n\n                                    p[3] = p[linesize+3] = s->fontcolor_value[3*ux+3];\n\n                                    p[4] = p[linesize+4] = s->fontcolor_value[3*ux+4];\n\n                                    p[5] = p[linesize+5] = s->fontcolor_value[3*ux+5];\n\n                                }\n\n                            }\n\n                            p  += 3 * video_scale;\n\n                            ux += video_scale;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        } else {\n\n            for (y = 0; y < font_height; y++) {\n\n                uint8_t *lineptr = data + (spectogram_height + y) * linesize;\n\n                uint8_t *spectogram_src = s->spectogram + s->spectogram_index * linesize;\n\n                for (x = 0; x < video_width; x++) {\n\n                    lineptr[3*x] = spectogram_src[3*x];\n\n                    lineptr[3*x+1] = spectogram_src[3*x+1];\n\n                    lineptr[3*x+2] = spectogram_src[3*x+2];\n\n                }\n\n            }\n\n        }\n\n\n\n        /* drawing spectogram/sonogram */\n\n        data += spectogram_start * linesize;\n\n        memcpy(data, s->spectogram + s->spectogram_index*linesize, total_length - back_length);\n\n\n\n        data += total_length - back_length;\n\n        if (back_length)\n\n            memcpy(data, s->spectogram, back_length);\n\n\n\n        s->outpicref->pts = s->frame_count;\n\n        ret = ff_filter_frame(outlink, av_frame_clone(s->outpicref));\n\n        s->req_fullfilled = 1;\n\n        s->frame_count++;\n\n    }\n\n    s->spectogram_count = (s->spectogram_count + 1) % s->count;\n\n    s->spectogram_index = (s->spectogram_index + spectogram_height - 1) % spectogram_height;\n\n    return ret;\n\n}\n", "idx": 6632, "_split": "valid", "_hash": "d8f11906ce89e2f61f68ecf5920c6685"}
{"project": "FFmpeg", "commit_id": "a8de60ba2740185c53cabbee6c00ed67a0d530e2", "target": 1, "func": "static void tqi_calculate_qtable(TqiContext *t, int quant)\n\n{\n\n    const int qscale = (215 - 2*quant)*5;\n\n    int i;\n\n\n\n    t->intra_matrix[0] = (ff_inv_aanscales[0] * ff_mpeg1_default_intra_matrix[0]) >> 11;\n\n    for(i=1; i<64; i++)\n\n        t->intra_matrix[i] = (ff_inv_aanscales[i] * ff_mpeg1_default_intra_matrix[i] * qscale + 32) >> 14;\n\n}\n", "idx": 6697, "_split": "valid", "_hash": "c74e5b4eb47f03922033b62f84fb9caa"}
{"project": "FFmpeg", "commit_id": "9034b0ed66c8f4a0da13947618503d575fc43957", "target": 0, "func": "static void free_input_threads(void)\n\n{\n\n    int i;\n\n\n\n    if (nb_input_files == 1)\n\n        return;\n\n\n\n    transcoding_finished = 1;\n\n\n\n    for (i = 0; i < nb_input_files; i++) {\n\n        InputFile *f = input_files[i];\n\n        AVPacket pkt;\n\n\n\n        if (f->joined)\n\n            continue;\n\n\n\n        pthread_mutex_lock(&f->fifo_lock);\n\n        while (av_fifo_size(f->fifo)) {\n\n            av_fifo_generic_read(f->fifo, &pkt, sizeof(pkt), NULL);\n\n            av_free_packet(&pkt);\n\n        }\n\n        pthread_cond_signal(&f->fifo_cond);\n\n        pthread_mutex_unlock(&f->fifo_lock);\n\n\n\n        pthread_join(f->thread, NULL);\n\n        f->joined = 1;\n\n\n\n        while (av_fifo_size(f->fifo)) {\n\n            av_fifo_generic_read(f->fifo, &pkt, sizeof(pkt), NULL);\n\n            av_free_packet(&pkt);\n\n        }\n\n        av_fifo_free(f->fifo);\n\n    }\n\n}\n", "idx": 6706, "_split": "valid", "_hash": "996145249b1acfc81b7e82101e3b61c6"}
{"project": "FFmpeg", "commit_id": "0e58865d6e86bbb664d92311c0f81c65e0213c35", "target": 0, "func": "static int vc1_decode_p_block(VC1Context *v, DCTELEM block[64], int n, int mquant, int ttmb, int first_block,\n\n                              uint8_t *dst, int linesize, int skip_block, int apply_filter, int cbp_top, int cbp_left)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int i, j;\n\n    int subblkpat = 0;\n\n    int scale, off, idx, last, skip, value;\n\n    int ttblk = ttmb & 7;\n\n    int pat = 0;\n\n\n\n    if(ttmb == -1) {\n\n        ttblk = ff_vc1_ttblk_to_tt[v->tt_index][get_vlc2(gb, ff_vc1_ttblk_vlc[v->tt_index].table, VC1_TTBLK_VLC_BITS, 1)];\n\n    }\n\n    if(ttblk == TT_4X4) {\n\n        subblkpat = ~(get_vlc2(gb, ff_vc1_subblkpat_vlc[v->tt_index].table, VC1_SUBBLKPAT_VLC_BITS, 1) + 1);\n\n    }\n\n    if((ttblk != TT_8X8 && ttblk != TT_4X4) && (v->ttmbf || (ttmb != -1 && (ttmb & 8) && !first_block))) {\n\n        subblkpat = decode012(gb);\n\n        if(subblkpat) subblkpat ^= 3; //swap decoded pattern bits\n\n        if(ttblk == TT_8X4_TOP || ttblk == TT_8X4_BOTTOM) ttblk = TT_8X4;\n\n        if(ttblk == TT_4X8_RIGHT || ttblk == TT_4X8_LEFT) ttblk = TT_4X8;\n\n    }\n\n    scale = 2 * mquant + ((v->pq == mquant) ? v->halfpq : 0);\n\n\n\n    // convert transforms like 8X4_TOP to generic TT and SUBBLKPAT\n\n    if(ttblk == TT_8X4_TOP || ttblk == TT_8X4_BOTTOM) {\n\n        subblkpat = 2 - (ttblk == TT_8X4_TOP);\n\n        ttblk = TT_8X4;\n\n    }\n\n    if(ttblk == TT_4X8_RIGHT || ttblk == TT_4X8_LEFT) {\n\n        subblkpat = 2 - (ttblk == TT_4X8_LEFT);\n\n        ttblk = TT_4X8;\n\n    }\n\n    switch(ttblk) {\n\n    case TT_8X8:\n\n        pat = 0xF;\n\n        i = 0;\n\n        last = 0;\n\n        while (!last) {\n\n            vc1_decode_ac_coeff(v, &last, &skip, &value, v->codingset2);\n\n            i += skip;\n\n            if(i > 63)\n\n                break;\n\n            idx = wmv1_scantable[0][i++];\n\n            block[idx] = value * scale;\n\n            if(!v->pquantizer)\n\n                block[idx] += (block[idx] < 0) ? -mquant : mquant;\n\n        }\n\n        if(!skip_block){\n\n            s->dsp.vc1_inv_trans_8x8(block);\n\n            s->dsp.add_pixels_clamped(block, dst, linesize);\n\n            if(apply_filter && cbp_top  & 0xC)\n\n                vc1_loop_filter(dst, 1, linesize, 8, mquant);\n\n            if(apply_filter && cbp_left & 0xA)\n\n                vc1_loop_filter(dst, linesize, 1, 8, mquant);\n\n        }\n\n        break;\n\n    case TT_4X4:\n\n        pat = ~subblkpat & 0xF;\n\n        for(j = 0; j < 4; j++) {\n\n            last = subblkpat & (1 << (3 - j));\n\n            i = 0;\n\n            off = (j & 1) * 4 + (j & 2) * 16;\n\n            while (!last) {\n\n                vc1_decode_ac_coeff(v, &last, &skip, &value, v->codingset2);\n\n                i += skip;\n\n                if(i > 15)\n\n                    break;\n\n                idx = ff_vc1_simple_progressive_4x4_zz[i++];\n\n                block[idx + off] = value * scale;\n\n                if(!v->pquantizer)\n\n                    block[idx + off] += (block[idx + off] < 0) ? -mquant : mquant;\n\n            }\n\n            if(!(subblkpat & (1 << (3 - j))) && !skip_block){\n\n                s->dsp.vc1_inv_trans_4x4(dst + (j&1)*4 + (j&2)*2*linesize, linesize, block + off);\n\n                if(apply_filter && (j&2 ? pat & (1<<(j-2)) : (cbp_top & (1 << (j + 2)))))\n\n                    vc1_loop_filter(dst + (j&1)*4 + (j&2)*2*linesize, 1, linesize, 4, mquant);\n\n                if(apply_filter && (j&1 ? pat & (1<<(j-1)) : (cbp_left & (1 << (j + 1)))))\n\n                    vc1_loop_filter(dst + (j&1)*4 + (j&2)*2*linesize, linesize, 1, 4, mquant);\n\n            }\n\n        }\n\n        break;\n\n    case TT_8X4:\n\n        pat = ~((subblkpat & 2)*6 + (subblkpat & 1)*3) & 0xF;\n\n        for(j = 0; j < 2; j++) {\n\n            last = subblkpat & (1 << (1 - j));\n\n            i = 0;\n\n            off = j * 32;\n\n            while (!last) {\n\n                vc1_decode_ac_coeff(v, &last, &skip, &value, v->codingset2);\n\n                i += skip;\n\n                if(i > 31)\n\n                    break;\n\n                idx = v->zz_8x4[i++]+off;\n\n                block[idx] = value * scale;\n\n                if(!v->pquantizer)\n\n                    block[idx] += (block[idx] < 0) ? -mquant : mquant;\n\n            }\n\n            if(!(subblkpat & (1 << (1 - j))) && !skip_block){\n\n                s->dsp.vc1_inv_trans_8x4(dst + j*4*linesize, linesize, block + off);\n\n                if(apply_filter && j ? pat & 0x3 : (cbp_top & 0xC))\n\n                    vc1_loop_filter(dst + j*4*linesize, 1, linesize, 8, mquant);\n\n                if(apply_filter && cbp_left & (2 << j))\n\n                    vc1_loop_filter(dst + j*4*linesize, linesize, 1, 4, mquant);\n\n            }\n\n        }\n\n        break;\n\n    case TT_4X8:\n\n        pat = ~(subblkpat*5) & 0xF;\n\n        for(j = 0; j < 2; j++) {\n\n            last = subblkpat & (1 << (1 - j));\n\n            i = 0;\n\n            off = j * 4;\n\n            while (!last) {\n\n                vc1_decode_ac_coeff(v, &last, &skip, &value, v->codingset2);\n\n                i += skip;\n\n                if(i > 31)\n\n                    break;\n\n                idx = v->zz_4x8[i++]+off;\n\n                block[idx] = value * scale;\n\n                if(!v->pquantizer)\n\n                    block[idx] += (block[idx] < 0) ? -mquant : mquant;\n\n            }\n\n            if(!(subblkpat & (1 << (1 - j))) && !skip_block){\n\n                s->dsp.vc1_inv_trans_4x8(dst + j*4, linesize, block + off);\n\n                if(apply_filter && cbp_top & (2 << j))\n\n                    vc1_loop_filter(dst + j*4, 1, linesize, 4, mquant);\n\n                if(apply_filter && j ? pat & 0x5 : (cbp_left & 0xA))\n\n                    vc1_loop_filter(dst + j*4, linesize, 1, 8, mquant);\n\n            }\n\n        }\n\n        break;\n\n    }\n\n    return pat;\n\n}\n", "idx": 6802, "_split": "valid", "_hash": "ec0234b97568e4db57e660ca7f8885b3"}
{"project": "FFmpeg", "commit_id": "b3facc4af8110beabdcade75e8d753b511d0e8cf", "target": 1, "func": "static int ac3_eac3_probe(AVProbeData *p, enum AVCodecID expected_codec_id)\n\n{\n\n    int max_frames, first_frames = 0, frames;\n\n    uint8_t *buf, *buf2, *end;\n\n    AC3HeaderInfo hdr;\n\n    GetBitContext gbc;\n\n    enum AVCodecID codec_id = AV_CODEC_ID_AC3;\n\n\n\n    max_frames = 0;\n\n    buf = p->buf;\n\n    end = buf + p->buf_size;\n\n\n\n    for(; buf < end; buf++) {\n\n        if(buf > p->buf && !(buf[0] == 0x0B && buf[1] == 0x77)\n\n                        && !(buf[0] == 0x77 && buf[1] == 0x0B) )\n\n            continue;\n\n        buf2 = buf;\n\n\n\n        for(frames = 0; buf2 < end; frames++) {\n\n            uint8_t buf3[4096];\n\n            int i;\n\n            if(!memcmp(buf2, \"\\x1\\x10\\0\\0\\0\\0\\0\\0\", 8))\n\n                buf2+=16;\n\n            if (buf[0] == 0x77 && buf[1] == 0x0B) {\n\n                for(i=0; i<8; i+=2) {\n\n                    buf3[i  ] = buf[i+1];\n\n                    buf3[i+1] = buf[i  ];\n\n                }\n\n                init_get_bits(&gbc, buf3, 54);\n\n            }else\n\n                init_get_bits(&gbc, buf2, 54);\n\n            if(avpriv_ac3_parse_header(&gbc, &hdr) < 0)\n\n                break;\n\n            if(buf2 + hdr.frame_size > end)\n\n                break;\n\n            if (buf[0] == 0x77 && buf[1] == 0x0B) {\n\n                av_assert0(hdr.frame_size <= sizeof(buf3));\n\n                for(; i<hdr.frame_size; i+=2) {\n\n                    buf3[i  ] = buf[i+1];\n\n                    buf3[i+1] = buf[i  ];\n\n                }\n\n            }\n\n            if(av_crc(av_crc_get_table(AV_CRC_16_ANSI), 0, gbc.buffer + 2, hdr.frame_size - 2))\n\n                break;\n\n            if (hdr.bitstream_id > 10)\n\n                codec_id = AV_CODEC_ID_EAC3;\n\n            buf2 += hdr.frame_size;\n\n        }\n\n        max_frames = FFMAX(max_frames, frames);\n\n        if(buf == p->buf)\n\n            first_frames = frames;\n\n    }\n\n    if(codec_id != expected_codec_id) return 0;\n\n    // keep this in sync with mp3 probe, both need to avoid\n\n    // issues with MPEG-files!\n\n    if   (first_frames>=4) return AVPROBE_SCORE_MAX/2+1;\n\n    else if(max_frames>200)return AVPROBE_SCORE_MAX/2;\n\n    else if(max_frames>=4) return AVPROBE_SCORE_MAX/4;\n\n    else if(max_frames>=1) return 1;\n\n    else                   return 0;\n\n}\n", "idx": 6811, "_split": "valid", "_hash": "91275390d92ce9145dc3a36c233eb32f"}
{"project": "FFmpeg", "commit_id": "bcedf2e519c60e8ffa05838c65a88934f1ead3bf", "target": 1, "func": "static int asf_read_frame_header(AVFormatContext *s, AVIOContext *pb){\n\n    ASFContext *asf = s->priv_data;\n\n    int rsize = 1;\n\n    int num = avio_r8(pb);\n\n    int64_t ts0, ts1;\n\n\n\n    asf->packet_segments--;\n\n    asf->packet_key_frame = num >> 7;\n\n    asf->stream_index = asf->asfid2avid[num & 0x7f];\n\n    // sequence should be ignored!\n\n    DO_2BITS(asf->packet_property >> 4, asf->packet_seq, 0);\n\n    DO_2BITS(asf->packet_property >> 2, asf->packet_frag_offset, 0);\n\n    DO_2BITS(asf->packet_property, asf->packet_replic_size, 0);\n\n//printf(\"key:%d stream:%d seq:%d offset:%d replic_size:%d\\n\", asf->packet_key_frame, asf->stream_index, asf->packet_seq, //asf->packet_frag_offset, asf->packet_replic_size);\n\n    if (asf->packet_replic_size >= 8) {\n\n        asf->packet_obj_size = avio_rl32(pb);\n\n        if(asf->packet_obj_size >= (1<<24) || asf->packet_obj_size <= 0){\n\n            av_log(s, AV_LOG_ERROR, \"packet_obj_size invalid\\n\");\n\n\n\n        asf->packet_frag_timestamp = avio_rl32(pb); // timestamp\n\n        if(asf->packet_replic_size >= 8+38+4){\n\n//            for(i=0; i<asf->packet_replic_size-8; i++)\n\n//                av_log(s, AV_LOG_DEBUG, \"%02X \",avio_r8(pb));\n\n//            av_log(s, AV_LOG_DEBUG, \"\\n\");\n\n            avio_skip(pb, 10);\n\n            ts0= avio_rl64(pb);\n\n            ts1= avio_rl64(pb);\n\n            avio_skip(pb, 12);\n\n            avio_rl32(pb);\n\n            avio_skip(pb, asf->packet_replic_size - 8 - 38 - 4);\n\n            if(ts0!= -1) asf->packet_frag_timestamp= ts0/10000;\n\n            else         asf->packet_frag_timestamp= AV_NOPTS_VALUE;\n\n        }else\n\n            avio_skip(pb, asf->packet_replic_size - 8);\n\n        rsize += asf->packet_replic_size; // FIXME - check validity\n\n    } else if (asf->packet_replic_size==1){\n\n        // multipacket - frag_offset is beginning timestamp\n\n        asf->packet_time_start = asf->packet_frag_offset;\n\n        asf->packet_frag_offset = 0;\n\n        asf->packet_frag_timestamp = asf->packet_timestamp;\n\n\n\n        asf->packet_time_delta = avio_r8(pb);\n\n        rsize++;\n\n    }else if(asf->packet_replic_size!=0){\n\n        av_log(s, AV_LOG_ERROR, \"unexpected packet_replic_size of %d\\n\", asf->packet_replic_size);\n\n\n\n\n\n\n\n    if (asf->packet_flags & 0x01) {\n\n        DO_2BITS(asf->packet_segsizetype >> 6, asf->packet_frag_size, 0); // 0 is illegal\n\n        if(asf->packet_frag_size > asf->packet_size_left - rsize){\n\n            if (asf->packet_frag_size > asf->packet_size_left - rsize + asf->packet_padsize) {\n\n                av_log(s, AV_LOG_ERROR, \"packet_frag_size is invalid (%d-%d)\\n\", asf->packet_size_left, rsize);\n\n\n            } else {\n\n                int diff = asf->packet_frag_size - (asf->packet_size_left - rsize);\n\n                asf->packet_size_left += diff;\n\n                asf->packet_padsize   -= diff;\n\n\n\n        //printf(\"Fragsize %d\\n\", asf->packet_frag_size);\n\n    } else {\n\n        asf->packet_frag_size = asf->packet_size_left - rsize;\n\n        //printf(\"Using rest  %d %d %d\\n\", asf->packet_frag_size, asf->packet_size_left, rsize);\n\n\n    if (asf->packet_replic_size == 1) {\n\n        asf->packet_multi_size = asf->packet_frag_size;\n\n        if (asf->packet_multi_size > asf->packet_size_left)\n\n\n\n    asf->packet_size_left -= rsize;\n\n    //printf(\"___objsize____  %d   %d    rs:%d\\n\", asf->packet_obj_size, asf->packet_frag_offset, rsize);\n\n\n\n    return 0;\n", "idx": 6812, "_split": "valid", "_hash": "7466c578fcae909022f289fb48a6da9b"}
{"project": "FFmpeg", "commit_id": "b5da848facd41169283d7bfe568b83bdfa7fc42e", "target": 1, "func": "static void mp_decode_line(MotionPixelsContext *mp, GetBitContext *gb, int y)\n\n{\n\n    YuvPixel p;\n\n    const int y0 = y * mp->avctx->width;\n\n    int w, i, x = 0;\n\n\n\n    p = mp->vpt[y];\n\n    if (mp->changes_map[y0 + x] == 0) {\n\n        memset(mp->gradient_scale, 1, sizeof(mp->gradient_scale));\n\n        ++x;\n\n    }\n\n    while (x < mp->avctx->width) {\n\n        w = mp->changes_map[y0 + x];\n\n        if (w != 0) {\n\n            if ((y & 3) == 0) {\n\n                if (mp->changes_map[y0 + x + mp->avctx->width] < w ||\n\n                    mp->changes_map[y0 + x + mp->avctx->width * 2] < w ||\n\n                    mp->changes_map[y0 + x + mp->avctx->width * 3] < w) {\n\n                    for (i = (x + 3) & ~3; i < x + w; i += 4) {\n\n                        mp->hpt[((y / 4) * mp->avctx->width + i) / 4] = mp_get_yuv_from_rgb(mp, i, y);\n\n                    }\n\n                }\n\n            }\n\n            x += w;\n\n            memset(mp->gradient_scale, 1, sizeof(mp->gradient_scale));\n\n            p = mp_get_yuv_from_rgb(mp, x - 1, y);\n\n        } else {\n\n            p.y += mp_gradient(mp, 0, mp_get_vlc(mp, gb));\n\n\n            if ((x & 3) == 0) {\n\n                if ((y & 3) == 0) {\n\n                    p.v += mp_gradient(mp, 1, mp_get_vlc(mp, gb));\n\n\n                    p.u += mp_gradient(mp, 2, mp_get_vlc(mp, gb));\n\n\n                    mp->hpt[((y / 4) * mp->avctx->width + x) / 4] = p;\n\n                } else {\n\n                    p.v = mp->hpt[((y / 4) * mp->avctx->width + x) / 4].v;\n\n                    p.u = mp->hpt[((y / 4) * mp->avctx->width + x) / 4].u;\n\n                }\n\n            }\n\n            mp_set_rgb_from_yuv(mp, x, y, &p);\n\n            ++x;\n\n        }\n\n    }\n\n}", "idx": 6814, "_split": "valid", "_hash": "50a1c2eba117562e64380101615ebcd7"}
{"project": "FFmpeg", "commit_id": "4f03bebc79f76df3a3e5bb9e1bc32baabfb7797c", "target": 1, "func": "void avcodec_string(char *buf, int buf_size, AVCodecContext *enc, int encode)\n\n{\n\n    const char *codec_type;\n\n    const char *codec_name;\n\n    const char *profile = NULL;\n\n    const AVCodec *p;\n\n    int64_t bitrate;\n\n    int new_line = 0;\n\n    AVRational display_aspect_ratio;\n\n    const char *separator = enc->dump_separator ? (const char *)enc->dump_separator : \", \";\n\n\n\n    if (!buf || buf_size <= 0)\n\n        return;\n\n    codec_type = av_get_media_type_string(enc->codec_type);\n\n    codec_name = avcodec_get_name(enc->codec_id);\n\n    if (enc->profile != FF_PROFILE_UNKNOWN) {\n\n        if (enc->codec)\n\n            p = enc->codec;\n\n        else\n\n            p = encode ? avcodec_find_encoder(enc->codec_id) :\n\n                        avcodec_find_decoder(enc->codec_id);\n\n        if (p)\n\n            profile = av_get_profile_name(p, enc->profile);\n\n    }\n\n\n\n    snprintf(buf, buf_size, \"%s: %s\", codec_type ? codec_type : \"unknown\",\n\n             codec_name);\n\n    buf[0] ^= 'a' ^ 'A'; /* first letter in uppercase */\n\n\n\n    if (enc->codec && strcmp(enc->codec->name, codec_name))\n\n        snprintf(buf + strlen(buf), buf_size - strlen(buf), \" (%s)\", enc->codec->name);\n\n\n\n    if (profile)\n\n        snprintf(buf + strlen(buf), buf_size - strlen(buf), \" (%s)\", profile);\n\n    if (   enc->codec_type == AVMEDIA_TYPE_VIDEO\n\n        && av_log_get_level() >= AV_LOG_VERBOSE\n\n        && enc->refs)\n\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                 \", %d reference frame%s\",\n\n                 enc->refs, enc->refs > 1 ? \"s\" : \"\");\n\n\n\n    if (enc->codec_tag) {\n\n        char tag_buf[32];\n\n        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), enc->codec_tag);\n\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                 \" (%s / 0x%04X)\", tag_buf, enc->codec_tag);\n\n    }\n\n\n\n    switch (enc->codec_type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        {\n\n            char detail[256] = \"(\";\n\n\n\n            av_strlcat(buf, separator, buf_size);\n\n\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                 \"%s\", enc->pix_fmt == AV_PIX_FMT_NONE ? \"none\" :\n\n                     av_get_pix_fmt_name(enc->pix_fmt));\n\n            if (enc->bits_per_raw_sample && enc->pix_fmt != AV_PIX_FMT_NONE &&\n\n                enc->bits_per_raw_sample < av_pix_fmt_desc_get(enc->pix_fmt)->comp[0].depth)\n\n                av_strlcatf(detail, sizeof(detail), \"%d bpc, \", enc->bits_per_raw_sample);\n\n            if (enc->color_range != AVCOL_RANGE_UNSPECIFIED)\n\n                av_strlcatf(detail, sizeof(detail), \"%s, \",\n\n                            av_color_range_name(enc->color_range));\n\n\n\n            if (enc->colorspace != AVCOL_SPC_UNSPECIFIED ||\n\n                enc->color_primaries != AVCOL_PRI_UNSPECIFIED ||\n\n                enc->color_trc != AVCOL_TRC_UNSPECIFIED) {\n\n                if (enc->colorspace != (int)enc->color_primaries ||\n\n                    enc->colorspace != (int)enc->color_trc) {\n\n                    new_line = 1;\n\n                    av_strlcatf(detail, sizeof(detail), \"%s/%s/%s, \",\n\n                                av_color_space_name(enc->colorspace),\n\n                                av_color_primaries_name(enc->color_primaries),\n\n                                av_color_transfer_name(enc->color_trc));\n\n                } else\n\n                    av_strlcatf(detail, sizeof(detail), \"%s, \",\n\n                                av_get_colorspace_name(enc->colorspace));\n\n            }\n\n\n\n            if (av_log_get_level() >= AV_LOG_DEBUG &&\n\n                enc->chroma_sample_location != AVCHROMA_LOC_UNSPECIFIED)\n\n                av_strlcatf(detail, sizeof(detail), \"%s, \",\n\n                            av_chroma_location_name(enc->chroma_sample_location));\n\n\n\n            if (strlen(detail) > 1) {\n\n                detail[strlen(detail) - 2] = 0;\n\n                av_strlcatf(buf, buf_size, \"%s)\", detail);\n\n            }\n\n        }\n\n\n\n        if (enc->width) {\n\n            av_strlcat(buf, new_line ? separator : \", \", buf_size);\n\n\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \"%dx%d\",\n\n                     enc->width, enc->height);\n\n\n\n            if (av_log_get_level() >= AV_LOG_VERBOSE &&\n\n                (enc->width != enc->coded_width ||\n\n                 enc->height != enc->coded_height))\n\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                         \" (%dx%d)\", enc->coded_width, enc->coded_height);\n\n\n\n            if (enc->sample_aspect_ratio.num) {\n\n                av_reduce(&display_aspect_ratio.num, &display_aspect_ratio.den,\n\n                          enc->width * enc->sample_aspect_ratio.num,\n\n                          enc->height * enc->sample_aspect_ratio.den,\n\n                          1024 * 1024);\n\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                         \" [SAR %d:%d DAR %d:%d]\",\n\n                         enc->sample_aspect_ratio.num, enc->sample_aspect_ratio.den,\n\n                         display_aspect_ratio.num, display_aspect_ratio.den);\n\n            }\n\n            if (av_log_get_level() >= AV_LOG_DEBUG) {\n\n                int g = av_gcd(enc->time_base.num, enc->time_base.den);\n\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                         \", %d/%d\",\n\n                         enc->time_base.num / g, enc->time_base.den / g);\n\n            }\n\n        }\n\n        if (encode) {\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \", q=%d-%d\", enc->qmin, enc->qmax);\n\n        } else {\n\n            if (enc->properties & FF_CODEC_PROPERTY_CLOSED_CAPTIONS)\n\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                         \", Closed Captions\");\n\n            if (enc->properties & FF_CODEC_PROPERTY_LOSSLESS)\n\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                         \", lossless\");\n\n        }\n\n        break;\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        av_strlcat(buf, separator, buf_size);\n\n\n\n        if (enc->sample_rate) {\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \"%d Hz, \", enc->sample_rate);\n\n        }\n\n        av_get_channel_layout_string(buf + strlen(buf), buf_size - strlen(buf), enc->channels, enc->channel_layout);\n\n        if (enc->sample_fmt != AV_SAMPLE_FMT_NONE) {\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \", %s\", av_get_sample_fmt_name(enc->sample_fmt));\n\n        }\n\n        if (   enc->bits_per_raw_sample > 0\n\n            && enc->bits_per_raw_sample != av_get_bytes_per_sample(enc->sample_fmt) * 8)\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \" (%d bit)\", enc->bits_per_raw_sample);\n\n        break;\n\n    case AVMEDIA_TYPE_DATA:\n\n        if (av_log_get_level() >= AV_LOG_DEBUG) {\n\n            int g = av_gcd(enc->time_base.num, enc->time_base.den);\n\n            if (g)\n\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                         \", %d/%d\",\n\n                         enc->time_base.num / g, enc->time_base.den / g);\n\n        }\n\n        break;\n\n    case AVMEDIA_TYPE_SUBTITLE:\n\n        if (enc->width)\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \", %dx%d\", enc->width, enc->height);\n\n        break;\n\n    default:\n\n        return;\n\n    }\n\n    if (encode) {\n\n        if (enc->flags & AV_CODEC_FLAG_PASS1)\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \", pass 1\");\n\n        if (enc->flags & AV_CODEC_FLAG_PASS2)\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                     \", pass 2\");\n\n    }\n\n    bitrate = get_bit_rate(enc);\n\n    if (bitrate != 0) {\n\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                 \", %\"PRId64\" kb/s\", bitrate / 1000);\n\n    } else if (enc->rc_max_rate > 0) {\n\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n\n                 \", max. %\"PRId64\" kb/s\", (int64_t)enc->rc_max_rate / 1000);\n\n    }\n\n}\n", "idx": 6818, "_split": "valid", "_hash": "9ff0cdfe07a96aa14c077cee8e2cea1d"}
{"project": "FFmpeg", "commit_id": "f777504f640260337974848c7d5d7a3f064bbb45", "target": 0, "func": "static int decode_slice_header(H264Context *h, H264Context *h0)\n\n{\n\n    unsigned int first_mb_in_slice;\n\n    unsigned int pps_id;\n\n    int ret;\n\n    unsigned int slice_type, tmp, i, j;\n\n    int default_ref_list_done = 0;\n\n    int last_pic_structure, last_pic_droppable;\n\n    int needs_reinit = 0;\n\n    int field_pic_flag, bottom_field_flag;\n\n\n\n    h->me.qpel_put = h->h264qpel.put_h264_qpel_pixels_tab;\n\n    h->me.qpel_avg = h->h264qpel.avg_h264_qpel_pixels_tab;\n\n\n\n    first_mb_in_slice = get_ue_golomb(&h->gb);\n\n\n\n    if (first_mb_in_slice == 0) { // FIXME better field boundary detection\n\n        if (h0->current_slice && h->cur_pic_ptr && FIELD_PICTURE(h)) {\n\n            field_end(h, 1);\n\n        }\n\n\n\n        h0->current_slice = 0;\n\n        if (!h0->first_field) {\n\n            if (h->cur_pic_ptr && !h->droppable) {\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                          h->picture_structure == PICT_BOTTOM_FIELD);\n\n            }\n\n            h->cur_pic_ptr = NULL;\n\n        }\n\n    }\n\n\n\n    slice_type = get_ue_golomb_31(&h->gb);\n\n    if (slice_type > 9) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"slice type %d too large at %d %d\\n\",\n\n               slice_type, h->mb_x, h->mb_y);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (slice_type > 4) {\n\n        slice_type -= 5;\n\n        h->slice_type_fixed = 1;\n\n    } else\n\n        h->slice_type_fixed = 0;\n\n\n\n    slice_type = golomb_to_pict_type[slice_type];\n\n    if (slice_type == AV_PICTURE_TYPE_I ||\n\n        (h0->current_slice != 0 && slice_type == h0->last_slice_type)) {\n\n        default_ref_list_done = 1;\n\n    }\n\n    h->slice_type     = slice_type;\n\n    h->slice_type_nos = slice_type & 3;\n\n\n\n    if (h->nal_unit_type  == NAL_IDR_SLICE &&\n\n        h->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"A non-intra slice in an IDR NAL unit.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // to make a few old functions happy, it's wrong though\n\n    h->pict_type = h->slice_type;\n\n\n\n    pps_id = get_ue_golomb(&h->gb);\n\n    if (pps_id >= MAX_PPS_COUNT) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"pps_id %u out of range\\n\", pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!h0->pps_buffers[pps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing PPS %u referenced\\n\",\n\n               pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    h->pps = *h0->pps_buffers[pps_id];\n\n\n\n    if (!h0->sps_buffers[h->pps.sps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing SPS %u referenced\\n\",\n\n               h->pps.sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (h->pps.sps_id != h->sps.sps_id ||\n\n        h0->sps_buffers[h->pps.sps_id]->new) {\n\n        h0->sps_buffers[h->pps.sps_id]->new = 0;\n\n\n\n        h->sps = *h0->sps_buffers[h->pps.sps_id];\n\n\n\n        if (h->bit_depth_luma    != h->sps.bit_depth_luma ||\n\n            h->chroma_format_idc != h->sps.chroma_format_idc) {\n\n            h->bit_depth_luma    = h->sps.bit_depth_luma;\n\n            h->chroma_format_idc = h->sps.chroma_format_idc;\n\n            needs_reinit         = 1;\n\n        }\n\n        if ((ret = h264_set_parameter_from_sps(h)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    h->avctx->profile = ff_h264_get_profile(&h->sps);\n\n    h->avctx->level   = h->sps.level_idc;\n\n    h->avctx->refs    = h->sps.ref_frame_count;\n\n\n\n    if (h->mb_width  != h->sps.mb_width ||\n\n        h->mb_height != h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag))\n\n        needs_reinit = 1;\n\n\n\n    h->mb_width  = h->sps.mb_width;\n\n    h->mb_height = h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag);\n\n    h->mb_num    = h->mb_width * h->mb_height;\n\n    h->mb_stride = h->mb_width + 1;\n\n\n\n    h->b_stride = h->mb_width * 4;\n\n\n\n    h->chroma_y_shift = h->sps.chroma_format_idc <= 1; // 400 uses yuv420p\n\n\n\n    h->width  = 16 * h->mb_width;\n\n    h->height = 16 * h->mb_height;\n\n\n\n    ret = init_dimensions(h);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (h->sps.video_signal_type_present_flag) {\n\n        h->avctx->color_range = h->sps.full_range ? AVCOL_RANGE_JPEG\n\n                                                  : AVCOL_RANGE_MPEG;\n\n        if (h->sps.colour_description_present_flag) {\n\n            if (h->avctx->colorspace != h->sps.colorspace)\n\n                needs_reinit = 1;\n\n            h->avctx->color_primaries = h->sps.color_primaries;\n\n            h->avctx->color_trc       = h->sps.color_trc;\n\n            h->avctx->colorspace      = h->sps.colorspace;\n\n        }\n\n    }\n\n\n\n    if (h->context_initialized &&\n\n        (h->width  != h->avctx->coded_width   ||\n\n         h->height != h->avctx->coded_height  ||\n\n         needs_reinit)) {\n\n        if (h != h0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"changing width %d -> %d / height %d -> %d on \"\n\n                   \"slice %d\\n\",\n\n                   h->width, h->avctx->coded_width,\n\n                   h->height, h->avctx->coded_height,\n\n                   h0->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        flush_change(h);\n\n\n\n        if ((ret = get_pixel_format(h)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        av_log(h->avctx, AV_LOG_INFO, \"Reinit context to %dx%d, \"\n\n               \"pix_fmt: %d\\n\", h->width, h->height, h->avctx->pix_fmt);\n\n\n\n        if ((ret = h264_slice_header_init(h, 1)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n    if (!h->context_initialized) {\n\n        if (h != h0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Cannot (re-)initialize context during parallel decoding.\\n\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n\n\n        if ((ret = get_pixel_format(h)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        if ((ret = h264_slice_header_init(h, 0)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    if (h == h0 && h->dequant_coeff_pps != pps_id) {\n\n        h->dequant_coeff_pps = pps_id;\n\n        init_dequant_tables(h);\n\n    }\n\n\n\n    h->frame_num = get_bits(&h->gb, h->sps.log2_max_frame_num);\n\n\n\n    h->mb_mbaff        = 0;\n\n    h->mb_aff_frame    = 0;\n\n    last_pic_structure = h0->picture_structure;\n\n    last_pic_droppable = h0->droppable;\n\n    h->droppable       = h->nal_ref_idc == 0;\n\n    if (h->sps.frame_mbs_only_flag) {\n\n        h->picture_structure = PICT_FRAME;\n\n    } else {\n\n        field_pic_flag = get_bits1(&h->gb);\n\n        if (field_pic_flag) {\n\n            bottom_field_flag = get_bits1(&h->gb);\n\n            h->picture_structure = PICT_TOP_FIELD + bottom_field_flag;\n\n        } else {\n\n            h->picture_structure = PICT_FRAME;\n\n            h->mb_aff_frame      = h->sps.mb_aff;\n\n        }\n\n    }\n\n    h->mb_field_decoding_flag = h->picture_structure != PICT_FRAME;\n\n\n\n    if (h0->current_slice != 0) {\n\n        if (last_pic_structure != h->picture_structure ||\n\n            last_pic_droppable != h->droppable) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Changing field mode (%d -> %d) between slices is not allowed\\n\",\n\n                   last_pic_structure, h->picture_structure);\n\n            h->picture_structure = last_pic_structure;\n\n            h->droppable         = last_pic_droppable;\n\n            return AVERROR_INVALIDDATA;\n\n        } else if (!h0->cur_pic_ptr) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"unset cur_pic_ptr on slice %d\\n\",\n\n                   h0->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else {\n\n        /* Shorten frame num gaps so we don't have to allocate reference\n\n         * frames just to throw them away */\n\n        if (h->frame_num != h->prev_frame_num) {\n\n            int unwrap_prev_frame_num = h->prev_frame_num;\n\n            int max_frame_num         = 1 << h->sps.log2_max_frame_num;\n\n\n\n            if (unwrap_prev_frame_num > h->frame_num)\n\n                unwrap_prev_frame_num -= max_frame_num;\n\n\n\n            if ((h->frame_num - unwrap_prev_frame_num) > h->sps.ref_frame_count) {\n\n                unwrap_prev_frame_num = (h->frame_num - h->sps.ref_frame_count) - 1;\n\n                if (unwrap_prev_frame_num < 0)\n\n                    unwrap_prev_frame_num += max_frame_num;\n\n\n\n                h->prev_frame_num = unwrap_prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * Here, we're using that to see if we should mark previously\n\n         * decode frames as \"finished\".\n\n         * We have to do that before the \"dummy\" in-between frame allocation,\n\n         * since that can modify s->current_picture_ptr. */\n\n        if (h0->first_field) {\n\n            assert(h0->cur_pic_ptr);\n\n            assert(h0->cur_pic_ptr->f.buf[0]);\n\n            assert(h0->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                if (!last_pic_droppable && last_pic_structure != PICT_FRAME) {\n\n                    ff_thread_report_progress(&h0->cur_pic_ptr->tf, INT_MAX,\n\n                                              last_pic_structure == PICT_TOP_FIELD);\n\n                }\n\n            } else {\n\n                if (h0->cur_pic_ptr->frame_num != h->frame_num) {\n\n                    /* This and previous field were reference, but had\n\n                     * different frame_nums. Consider this field first in\n\n                     * pair. Throw away previous field except for reference\n\n                     * purposes. */\n\n                    if (!last_pic_droppable && last_pic_structure != PICT_FRAME) {\n\n                        ff_thread_report_progress(&h0->cur_pic_ptr->tf, INT_MAX,\n\n                                                  last_pic_structure == PICT_TOP_FIELD);\n\n                    }\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    if (!((last_pic_structure   == PICT_TOP_FIELD &&\n\n                           h->picture_structure == PICT_BOTTOM_FIELD) ||\n\n                          (last_pic_structure   == PICT_BOTTOM_FIELD &&\n\n                           h->picture_structure == PICT_TOP_FIELD))) {\n\n                        av_log(h->avctx, AV_LOG_ERROR,\n\n                               \"Invalid field mode combination %d/%d\\n\",\n\n                               last_pic_structure, h->picture_structure);\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_INVALIDDATA;\n\n                    } else if (last_pic_droppable != h->droppable) {\n\n                        avpriv_request_sample(h->avctx,\n\n                                              \"Found reference and non-reference fields in the same frame, which\");\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_PATCHWELCOME;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        while (h->frame_num != h->prev_frame_num &&\n\n               h->frame_num != (h->prev_frame_num + 1) % (1 << h->sps.log2_max_frame_num)) {\n\n            Picture *prev = h->short_ref_count ? h->short_ref[0] : NULL;\n\n            av_log(h->avctx, AV_LOG_DEBUG, \"Frame num gap %d %d\\n\",\n\n                   h->frame_num, h->prev_frame_num);\n\n            ret = h264_frame_start(h);\n\n            if (ret < 0) {\n\n                h0->first_field = 0;\n\n                return ret;\n\n            }\n\n\n\n            h->prev_frame_num++;\n\n            h->prev_frame_num        %= 1 << h->sps.log2_max_frame_num;\n\n            h->cur_pic_ptr->frame_num = h->prev_frame_num;\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 0);\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 1);\n\n            ret = ff_generate_sliding_window_mmcos(h, 1);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            ret = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            /* Error concealment: If a ref is missing, copy the previous ref\n\n             * in its place.\n\n             * FIXME: Avoiding a memcpy would be nice, but ref handling makes\n\n             * many assumptions about there being no actual duplicates.\n\n             * FIXME: This does not copy padding for out-of-frame motion\n\n             * vectors.  Given we are concealing a lost frame, this probably\n\n             * is not noticeable by comparison, but it should be fixed. */\n\n            if (h->short_ref_count) {\n\n                if (prev) {\n\n                    av_image_copy(h->short_ref[0]->f.data,\n\n                                  h->short_ref[0]->f.linesize,\n\n                                  (const uint8_t **)prev->f.data,\n\n                                  prev->f.linesize,\n\n                                  h->avctx->pix_fmt,\n\n                                  h->mb_width  * 16,\n\n                                  h->mb_height * 16);\n\n                    h->short_ref[0]->poc = prev->poc + 2;\n\n                }\n\n                h->short_ref[0]->frame_num = h->prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * We're using that to see whether to continue decoding in that\n\n         * frame, or to allocate a new one. */\n\n        if (h0->first_field) {\n\n            assert(h0->cur_pic_ptr);\n\n            assert(h0->cur_pic_ptr->f.buf[0]);\n\n            assert(h0->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                h0->cur_pic_ptr = NULL;\n\n                h0->first_field = FIELD_PICTURE(h);\n\n            } else {\n\n                if (h0->cur_pic_ptr->frame_num != h->frame_num) {\n\n                    /* This and the previous field had different frame_nums.\n\n                     * Consider this field first in pair. Throw away previous\n\n                     * one except for reference purposes. */\n\n                    h0->first_field = 1;\n\n                    h0->cur_pic_ptr = NULL;\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    h0->first_field = 0;\n\n                }\n\n            }\n\n        } else {\n\n            /* Frame or first field in a potentially complementary pair */\n\n            h0->first_field = FIELD_PICTURE(h);\n\n        }\n\n\n\n        if (!FIELD_PICTURE(h) || h0->first_field) {\n\n            if (h264_frame_start(h) < 0) {\n\n                h0->first_field = 0;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            release_unused_pictures(h, 0);\n\n        }\n\n    }\n\n    if (h != h0 && (ret = clone_slice(h, h0)) < 0)\n\n        return ret;\n\n\n\n    h->cur_pic_ptr->frame_num = h->frame_num; // FIXME frame_num cleanup\n\n\n\n    assert(h->mb_num == h->mb_width * h->mb_height);\n\n    if (first_mb_in_slice << FIELD_OR_MBAFF_PICTURE(h) >= h->mb_num ||\n\n        first_mb_in_slice >= h->mb_num) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"first_mb_in_slice overflow\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    h->resync_mb_x = h->mb_x =  first_mb_in_slice % h->mb_width;\n\n    h->resync_mb_y = h->mb_y = (first_mb_in_slice / h->mb_width) <<\n\n                               FIELD_OR_MBAFF_PICTURE(h);\n\n    if (h->picture_structure == PICT_BOTTOM_FIELD)\n\n        h->resync_mb_y = h->mb_y = h->mb_y + 1;\n\n    assert(h->mb_y < h->mb_height);\n\n\n\n    if (h->picture_structure == PICT_FRAME) {\n\n        h->curr_pic_num = h->frame_num;\n\n        h->max_pic_num  = 1 << h->sps.log2_max_frame_num;\n\n    } else {\n\n        h->curr_pic_num = 2 * h->frame_num + 1;\n\n        h->max_pic_num  = 1 << (h->sps.log2_max_frame_num + 1);\n\n    }\n\n\n\n    if (h->nal_unit_type == NAL_IDR_SLICE)\n\n        get_ue_golomb(&h->gb); /* idr_pic_id */\n\n\n\n    if (h->sps.poc_type == 0) {\n\n        h->poc_lsb = get_bits(&h->gb, h->sps.log2_max_poc_lsb);\n\n\n\n        if (h->pps.pic_order_present == 1 && h->picture_structure == PICT_FRAME)\n\n            h->delta_poc_bottom = get_se_golomb(&h->gb);\n\n    }\n\n\n\n    if (h->sps.poc_type == 1 && !h->sps.delta_pic_order_always_zero_flag) {\n\n        h->delta_poc[0] = get_se_golomb(&h->gb);\n\n\n\n        if (h->pps.pic_order_present == 1 && h->picture_structure == PICT_FRAME)\n\n            h->delta_poc[1] = get_se_golomb(&h->gb);\n\n    }\n\n\n\n    ff_init_poc(h, h->cur_pic_ptr->field_poc, &h->cur_pic_ptr->poc);\n\n\n\n    if (h->pps.redundant_pic_cnt_present)\n\n        h->redundant_pic_count = get_ue_golomb(&h->gb);\n\n\n\n    ret = ff_set_ref_count(h);\n\n    if (ret < 0)\n\n        return ret;\n\n    else if (ret == 1)\n\n        default_ref_list_done = 0;\n\n\n\n    if (!default_ref_list_done)\n\n        ff_h264_fill_default_ref_list(h);\n\n\n\n    if (h->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n       ret = ff_h264_decode_ref_pic_list_reordering(h);\n\n       if (ret < 0) {\n\n           h->ref_count[1] = h->ref_count[0] = 0;\n\n           return ret;\n\n       }\n\n    }\n\n\n\n    if ((h->pps.weighted_pred && h->slice_type_nos == AV_PICTURE_TYPE_P) ||\n\n        (h->pps.weighted_bipred_idc == 1 &&\n\n         h->slice_type_nos == AV_PICTURE_TYPE_B))\n\n        ff_pred_weight_table(h);\n\n    else if (h->pps.weighted_bipred_idc == 2 &&\n\n             h->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        implicit_weight_table(h, -1);\n\n    } else {\n\n        h->use_weight = 0;\n\n        for (i = 0; i < 2; i++) {\n\n            h->luma_weight_flag[i]   = 0;\n\n            h->chroma_weight_flag[i] = 0;\n\n        }\n\n    }\n\n\n\n    // If frame-mt is enabled, only update mmco tables for the first slice\n\n    // in a field. Subsequent slices can temporarily clobber h->mmco_index\n\n    // or h->mmco, which will cause ref list mix-ups and decoding errors\n\n    // further down the line. This may break decoding if the first slice is\n\n    // corrupt, thus we only do this if frame-mt is enabled.\n\n    if (h->nal_ref_idc) {\n\n        ret = ff_h264_decode_ref_pic_marking(h0, &h->gb,\n\n                                             !(h->avctx->active_thread_type & FF_THREAD_FRAME) ||\n\n                                             h0->current_slice == 0);\n\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (FRAME_MBAFF(h)) {\n\n        ff_h264_fill_mbaff_ref_list(h);\n\n\n\n        if (h->pps.weighted_bipred_idc == 2 && h->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n            implicit_weight_table(h, 0);\n\n            implicit_weight_table(h, 1);\n\n        }\n\n    }\n\n\n\n    if (h->slice_type_nos == AV_PICTURE_TYPE_B && !h->direct_spatial_mv_pred)\n\n        ff_h264_direct_dist_scale_factor(h);\n\n    ff_h264_direct_ref_list_init(h);\n\n\n\n    if (h->slice_type_nos != AV_PICTURE_TYPE_I && h->pps.cabac) {\n\n        tmp = get_ue_golomb_31(&h->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"cabac_init_idc %u overflow\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        h->cabac_init_idc = tmp;\n\n    }\n\n\n\n    h->last_qscale_diff = 0;\n\n    tmp = h->pps.init_qp + get_se_golomb(&h->gb);\n\n    if (tmp > 51 + 6 * (h->sps.bit_depth_luma - 8)) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"QP %u out of range\\n\", tmp);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    h->qscale       = tmp;\n\n    h->chroma_qp[0] = get_chroma_qp(h, 0, h->qscale);\n\n    h->chroma_qp[1] = get_chroma_qp(h, 1, h->qscale);\n\n    // FIXME qscale / qp ... stuff\n\n    if (h->slice_type == AV_PICTURE_TYPE_SP)\n\n        get_bits1(&h->gb); /* sp_for_switch_flag */\n\n    if (h->slice_type == AV_PICTURE_TYPE_SP ||\n\n        h->slice_type == AV_PICTURE_TYPE_SI)\n\n        get_se_golomb(&h->gb); /* slice_qs_delta */\n\n\n\n    h->deblocking_filter     = 1;\n\n    h->slice_alpha_c0_offset = 52;\n\n    h->slice_beta_offset     = 52;\n\n    if (h->pps.deblocking_filter_parameters_present) {\n\n        tmp = get_ue_golomb_31(&h->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"deblocking_filter_idc %u out of range\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        h->deblocking_filter = tmp;\n\n        if (h->deblocking_filter < 2)\n\n            h->deblocking_filter ^= 1;  // 1<->0\n\n\n\n        if (h->deblocking_filter) {\n\n            h->slice_alpha_c0_offset += get_se_golomb(&h->gb) << 1;\n\n            h->slice_beta_offset     += get_se_golomb(&h->gb) << 1;\n\n            if (h->slice_alpha_c0_offset > 104U ||\n\n                h->slice_beta_offset     > 104U) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"deblocking filter parameters %d %d out of range\\n\",\n\n                       h->slice_alpha_c0_offset, h->slice_beta_offset);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (h->avctx->skip_loop_filter >= AVDISCARD_ALL ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_NONKEY &&\n\n         h->slice_type_nos != AV_PICTURE_TYPE_I) ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_BIDIR  &&\n\n         h->slice_type_nos == AV_PICTURE_TYPE_B) ||\n\n        (h->avctx->skip_loop_filter >= AVDISCARD_NONREF &&\n\n         h->nal_ref_idc == 0))\n\n        h->deblocking_filter = 0;\n\n\n\n    if (h->deblocking_filter == 1 && h0->max_contexts > 1) {\n\n        if (h->avctx->flags2 & CODEC_FLAG2_FAST) {\n\n            /* Cheat slightly for speed:\n\n             * Do not bother to deblock across slices. */\n\n            h->deblocking_filter = 2;\n\n        } else {\n\n            h0->max_contexts = 1;\n\n            if (!h0->single_decode_warning) {\n\n                av_log(h->avctx, AV_LOG_INFO,\n\n                       \"Cannot parallelize deblocking type 1, decoding such frames in sequential order\\n\");\n\n                h0->single_decode_warning = 1;\n\n            }\n\n            if (h != h0) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"Deblocking switched inside frame.\\n\");\n\n                return 1;\n\n            }\n\n        }\n\n    }\n\n    h->qp_thresh = 15 + 52 -\n\n                   FFMIN(h->slice_alpha_c0_offset, h->slice_beta_offset) -\n\n                   FFMAX3(0,\n\n                          h->pps.chroma_qp_index_offset[0],\n\n                          h->pps.chroma_qp_index_offset[1]) +\n\n                   6 * (h->sps.bit_depth_luma - 8);\n\n\n\n    h0->last_slice_type = slice_type;\n\n    h->slice_num        = ++h0->current_slice;\n\n    if (h->slice_num >= MAX_SLICES) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"Too many slices, increase MAX_SLICES and recompile\\n\");\n\n    }\n\n\n\n    for (j = 0; j < 2; j++) {\n\n        int id_list[16];\n\n        int *ref2frm = h->ref2frm[h->slice_num & (MAX_SLICES - 1)][j];\n\n        for (i = 0; i < 16; i++) {\n\n            id_list[i] = 60;\n\n            if (j < h->list_count && i < h->ref_count[j] &&\n\n                h->ref_list[j][i].f.buf[0]) {\n\n                int k;\n\n                AVBuffer *buf = h->ref_list[j][i].f.buf[0]->buffer;\n\n                for (k = 0; k < h->short_ref_count; k++)\n\n                    if (h->short_ref[k]->f.buf[0]->buffer == buf) {\n\n                        id_list[i] = k;\n\n                        break;\n\n                    }\n\n                for (k = 0; k < h->long_ref_count; k++)\n\n                    if (h->long_ref[k] && h->long_ref[k]->f.buf[0]->buffer == buf) {\n\n                        id_list[i] = h->short_ref_count + k;\n\n                        break;\n\n                    }\n\n            }\n\n        }\n\n\n\n        ref2frm[0] =\n\n        ref2frm[1] = -1;\n\n        for (i = 0; i < 16; i++)\n\n            ref2frm[i + 2] = 4 * id_list[i] + (h->ref_list[j][i].reference & 3);\n\n        ref2frm[18 + 0] =\n\n        ref2frm[18 + 1] = -1;\n\n        for (i = 16; i < 48; i++)\n\n            ref2frm[i + 4] = 4 * id_list[(i - 16) >> 1] +\n\n                             (h->ref_list[j][i].reference & 3);\n\n    }\n\n\n\n    if (h->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n        av_log(h->avctx, AV_LOG_DEBUG,\n\n               \"slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\\n\",\n\n               h->slice_num,\n\n               (h->picture_structure == PICT_FRAME ? \"F\" : h->picture_structure == PICT_TOP_FIELD ? \"T\" : \"B\"),\n\n               first_mb_in_slice,\n\n               av_get_picture_type_char(h->slice_type),\n\n               h->slice_type_fixed ? \" fix\" : \"\",\n\n               h->nal_unit_type == NAL_IDR_SLICE ? \" IDR\" : \"\",\n\n               pps_id, h->frame_num,\n\n               h->cur_pic_ptr->field_poc[0],\n\n               h->cur_pic_ptr->field_poc[1],\n\n               h->ref_count[0], h->ref_count[1],\n\n               h->qscale,\n\n               h->deblocking_filter,\n\n               h->slice_alpha_c0_offset / 2 - 26, h->slice_beta_offset / 2 - 26,\n\n               h->use_weight,\n\n               h->use_weight == 1 && h->use_weight_chroma ? \"c\" : \"\",\n\n               h->slice_type == AV_PICTURE_TYPE_B ? (h->direct_spatial_mv_pred ? \"SPAT\" : \"TEMP\") : \"\");\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 6917, "_split": "valid", "_hash": "04656d89e2845925c6063d8ac68b5cc4"}
{"project": "FFmpeg", "commit_id": "837112c0c84dd9de67421b57664933a0d27843f9", "target": 1, "func": "static av_cold int channelmap_init(AVFilterContext *ctx)\n\n{\n\n    ChannelMapContext *s = ctx->priv;\n\n    int ret;\n\n    char *mapping, separator = '|';\n\n    int map_entries = 0;\n\n    char buf[256];\n\n    enum MappingMode mode;\n\n    uint64_t out_ch_mask = 0;\n\n    int i;\n\n\n\n    mapping = s->mapping_str;\n\n\n\n    if (!mapping) {\n\n        mode = MAP_NONE;\n\n    } else {\n\n        char *dash = strchr(mapping, '-');\n\n        if (!dash) {  // short mapping\n\n            if (av_isdigit(*mapping))\n\n                mode = MAP_ONE_INT;\n\n            else\n\n                mode = MAP_ONE_STR;\n\n        } else if (av_isdigit(*mapping)) {\n\n            if (av_isdigit(*(dash+1)))\n\n                mode = MAP_PAIR_INT_INT;\n\n            else\n\n                mode = MAP_PAIR_INT_STR;\n\n        } else {\n\n            if (av_isdigit(*(dash+1)))\n\n                mode = MAP_PAIR_STR_INT;\n\n            else\n\n                mode = MAP_PAIR_STR_STR;\n\n        }\n\n#if FF_API_OLD_FILTER_OPTS\n\n        if (strchr(mapping, ',')) {\n\n            av_log(ctx, AV_LOG_WARNING, \"This syntax is deprecated, use \"\n\n                   \"'|' to separate the mappings.\\n\");\n\n            separator = ',';\n\n        }\n\n#endif\n\n    }\n\n\n\n    if (mode != MAP_NONE) {\n\n        char *sep = mapping;\n\n        map_entries = 1;\n\n        while ((sep = strchr(sep, separator))) {\n\n            if (*++sep)  // Allow trailing comma\n\n                map_entries++;\n\n        }\n\n    }\n\n\n\n    if (map_entries > MAX_CH) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Too many channels mapped: '%d'.\\n\", map_entries);\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    for (i = 0; i < map_entries; i++) {\n\n        int in_ch_idx = -1, out_ch_idx = -1;\n\n        uint64_t in_ch = 0, out_ch = 0;\n\n        static const char err[] = \"Failed to parse channel map\\n\";\n\n        switch (mode) {\n\n        case MAP_ONE_INT:\n\n            if (get_channel_idx(&mapping, &in_ch_idx, separator, MAX_CH) < 0) {\n\n                ret = AVERROR(EINVAL);\n\n                av_log(ctx, AV_LOG_ERROR, err);\n\n                goto fail;\n\n            }\n\n            s->map[i].in_channel_idx  = in_ch_idx;\n\n            s->map[i].out_channel_idx = i;\n\n            break;\n\n        case MAP_ONE_STR:\n\n            if (!get_channel(&mapping, &in_ch, separator)) {\n\n                av_log(ctx, AV_LOG_ERROR, err);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            s->map[i].in_channel      = in_ch;\n\n            s->map[i].out_channel_idx = i;\n\n            break;\n\n        case MAP_PAIR_INT_INT:\n\n            if (get_channel_idx(&mapping, &in_ch_idx, '-', MAX_CH) < 0 ||\n\n                get_channel_idx(&mapping, &out_ch_idx, separator, MAX_CH) < 0) {\n\n                av_log(ctx, AV_LOG_ERROR, err);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            s->map[i].in_channel_idx  = in_ch_idx;\n\n            s->map[i].out_channel_idx = out_ch_idx;\n\n            break;\n\n        case MAP_PAIR_INT_STR:\n\n            if (get_channel_idx(&mapping, &in_ch_idx, '-', MAX_CH) < 0 ||\n\n                get_channel(&mapping, &out_ch, separator) < 0 ||\n\n                out_ch & out_ch_mask) {\n\n                av_log(ctx, AV_LOG_ERROR, err);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            s->map[i].in_channel_idx  = in_ch_idx;\n\n            s->map[i].out_channel     = out_ch;\n\n            out_ch_mask |= out_ch;\n\n            break;\n\n        case MAP_PAIR_STR_INT:\n\n            if (get_channel(&mapping, &in_ch, '-') < 0 ||\n\n                get_channel_idx(&mapping, &out_ch_idx, separator, MAX_CH) < 0) {\n\n                av_log(ctx, AV_LOG_ERROR, err);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            s->map[i].in_channel      = in_ch;\n\n            s->map[i].out_channel_idx = out_ch_idx;\n\n            break;\n\n        case MAP_PAIR_STR_STR:\n\n            if (get_channel(&mapping, &in_ch, '-') < 0 ||\n\n                get_channel(&mapping, &out_ch, separator) < 0 ||\n\n                out_ch & out_ch_mask) {\n\n                av_log(ctx, AV_LOG_ERROR, err);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            s->map[i].in_channel = in_ch;\n\n            s->map[i].out_channel = out_ch;\n\n            out_ch_mask |= out_ch;\n\n            break;\n\n        }\n\n    }\n\n    s->mode          = mode;\n\n    s->nch           = map_entries;\n\n    s->output_layout = out_ch_mask ? out_ch_mask :\n\n                       av_get_default_channel_layout(map_entries);\n\n\n\n    if (s->channel_layout_str) {\n\n        uint64_t fmt;\n\n        if ((fmt = av_get_channel_layout(s->channel_layout_str)) == 0) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Error parsing channel layout: '%s'.\\n\",\n\n                   s->channel_layout_str);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        if (mode == MAP_NONE) {\n\n            int i;\n\n            s->nch = av_get_channel_layout_nb_channels(fmt);\n\n            for (i = 0; i < s->nch; i++) {\n\n                s->map[i].in_channel_idx  = i;\n\n                s->map[i].out_channel_idx = i;\n\n            }\n\n        } else if (out_ch_mask && out_ch_mask != fmt) {\n\n            av_get_channel_layout_string(buf, sizeof(buf), 0, out_ch_mask);\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Output channel layout '%s' does not match the list of channel mapped: '%s'.\\n\",\n\n                   s->channel_layout_str, buf);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        } else if (s->nch != av_get_channel_layout_nb_channels(fmt)) {\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Output channel layout %s does not match the number of channels mapped %d.\\n\",\n\n                   s->channel_layout_str, s->nch);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        s->output_layout = fmt;\n\n    }\n\n    ff_add_channel_layout(&s->channel_layouts, s->output_layout);\n\n\n\n    if (mode == MAP_PAIR_INT_STR || mode == MAP_PAIR_STR_STR) {\n\n        for (i = 0; i < s->nch; i++) {\n\n            s->map[i].out_channel_idx = av_get_channel_layout_channel_index(\n\n                s->output_layout, s->map[i].out_channel);\n\n        }\n\n    }\n\n\n\nfail:\n\n    av_opt_free(s);\n\n    return ret;\n\n}\n", "idx": 6967, "_split": "valid", "_hash": "26c40ad1c77248f4a1c90da034f4a1e9"}
{"project": "FFmpeg", "commit_id": "2c874548d663225a61b9c25a8b2ce490d26b65fa", "target": 1, "func": "static void pred_weight_table(HEVCContext *s, GetBitContext *gb)\n\n{\n\n    int i = 0;\n\n    int j = 0;\n\n    uint8_t luma_weight_l0_flag[16];\n\n    uint8_t chroma_weight_l0_flag[16];\n\n    uint8_t luma_weight_l1_flag[16];\n\n    uint8_t chroma_weight_l1_flag[16];\n\n    int luma_log2_weight_denom;\n\n\n\n    luma_log2_weight_denom = get_ue_golomb_long(gb);\n\n    if (luma_log2_weight_denom < 0 || luma_log2_weight_denom > 7)\n\n        av_log(s->avctx, AV_LOG_ERROR, \"luma_log2_weight_denom %d is invalid\\n\", luma_log2_weight_denom);\n\n    s->sh.luma_log2_weight_denom = av_clip_uintp2(luma_log2_weight_denom, 3);\n\n    if (s->ps.sps->chroma_format_idc != 0) {\n\n        int delta = get_se_golomb(gb);\n\n        s->sh.chroma_log2_weight_denom = av_clip_uintp2(s->sh.luma_log2_weight_denom + delta, 3);\n\n    }\n\n\n\n    for (i = 0; i < s->sh.nb_refs[L0]; i++) {\n\n        luma_weight_l0_flag[i] = get_bits1(gb);\n\n        if (!luma_weight_l0_flag[i]) {\n\n            s->sh.luma_weight_l0[i] = 1 << s->sh.luma_log2_weight_denom;\n\n            s->sh.luma_offset_l0[i] = 0;\n\n        }\n\n    }\n\n    if (s->ps.sps->chroma_format_idc != 0) {\n\n        for (i = 0; i < s->sh.nb_refs[L0]; i++)\n\n            chroma_weight_l0_flag[i] = get_bits1(gb);\n\n    } else {\n\n        for (i = 0; i < s->sh.nb_refs[L0]; i++)\n\n            chroma_weight_l0_flag[i] = 0;\n\n    }\n\n    for (i = 0; i < s->sh.nb_refs[L0]; i++) {\n\n        if (luma_weight_l0_flag[i]) {\n\n            int delta_luma_weight_l0 = get_se_golomb(gb);\n\n            s->sh.luma_weight_l0[i] = (1 << s->sh.luma_log2_weight_denom) + delta_luma_weight_l0;\n\n            s->sh.luma_offset_l0[i] = get_se_golomb(gb);\n\n        }\n\n        if (chroma_weight_l0_flag[i]) {\n\n            for (j = 0; j < 2; j++) {\n\n                int delta_chroma_weight_l0 = get_se_golomb(gb);\n\n                int delta_chroma_offset_l0 = get_se_golomb(gb);\n\n                s->sh.chroma_weight_l0[i][j] = (1 << s->sh.chroma_log2_weight_denom) + delta_chroma_weight_l0;\n\n                s->sh.chroma_offset_l0[i][j] = av_clip((delta_chroma_offset_l0 - ((128 * s->sh.chroma_weight_l0[i][j])\n\n                                                                                    >> s->sh.chroma_log2_weight_denom) + 128), -128, 127);\n\n            }\n\n        } else {\n\n            s->sh.chroma_weight_l0[i][0] = 1 << s->sh.chroma_log2_weight_denom;\n\n            s->sh.chroma_offset_l0[i][0] = 0;\n\n            s->sh.chroma_weight_l0[i][1] = 1 << s->sh.chroma_log2_weight_denom;\n\n            s->sh.chroma_offset_l0[i][1] = 0;\n\n        }\n\n    }\n\n    if (s->sh.slice_type == HEVC_SLICE_B) {\n\n        for (i = 0; i < s->sh.nb_refs[L1]; i++) {\n\n            luma_weight_l1_flag[i] = get_bits1(gb);\n\n            if (!luma_weight_l1_flag[i]) {\n\n                s->sh.luma_weight_l1[i] = 1 << s->sh.luma_log2_weight_denom;\n\n                s->sh.luma_offset_l1[i] = 0;\n\n            }\n\n        }\n\n        if (s->ps.sps->chroma_format_idc != 0) {\n\n            for (i = 0; i < s->sh.nb_refs[L1]; i++)\n\n                chroma_weight_l1_flag[i] = get_bits1(gb);\n\n        } else {\n\n            for (i = 0; i < s->sh.nb_refs[L1]; i++)\n\n                chroma_weight_l1_flag[i] = 0;\n\n        }\n\n        for (i = 0; i < s->sh.nb_refs[L1]; i++) {\n\n            if (luma_weight_l1_flag[i]) {\n\n                int delta_luma_weight_l1 = get_se_golomb(gb);\n\n                s->sh.luma_weight_l1[i] = (1 << s->sh.luma_log2_weight_denom) + delta_luma_weight_l1;\n\n                s->sh.luma_offset_l1[i] = get_se_golomb(gb);\n\n            }\n\n            if (chroma_weight_l1_flag[i]) {\n\n                for (j = 0; j < 2; j++) {\n\n                    int delta_chroma_weight_l1 = get_se_golomb(gb);\n\n                    int delta_chroma_offset_l1 = get_se_golomb(gb);\n\n                    s->sh.chroma_weight_l1[i][j] = (1 << s->sh.chroma_log2_weight_denom) + delta_chroma_weight_l1;\n\n                    s->sh.chroma_offset_l1[i][j] = av_clip((delta_chroma_offset_l1 - ((128 * s->sh.chroma_weight_l1[i][j])\n\n                                                                                        >> s->sh.chroma_log2_weight_denom) + 128), -128, 127);\n\n                }\n\n            } else {\n\n                s->sh.chroma_weight_l1[i][0] = 1 << s->sh.chroma_log2_weight_denom;\n\n                s->sh.chroma_offset_l1[i][0] = 0;\n\n                s->sh.chroma_weight_l1[i][1] = 1 << s->sh.chroma_log2_weight_denom;\n\n                s->sh.chroma_offset_l1[i][1] = 0;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 6981, "_split": "valid", "_hash": "f3f1c5f8d0094e00f70ec4f685aab832"}
{"project": "FFmpeg", "commit_id": "aac8b76983e340bc744d3542d676f72efa3b474f", "target": 0, "func": "static void filter_mb_mbaff_edgev( H264Context *h, uint8_t *pix, int stride, int16_t bS[8], int qp[2] ) {\n\n    int i;\n\n    for( i = 0; i < 16; i++, pix += stride) {\n\n        int index_a;\n\n        int alpha;\n\n        int beta;\n\n\n\n        int qp_index;\n\n        int bS_index = (i >> 1);\n\n        if (!MB_FIELD) {\n\n            bS_index &= ~1;\n\n            bS_index |= (i & 1);\n\n        }\n\n\n\n        if( bS[bS_index] == 0 ) {\n\n            continue;\n\n        }\n\n\n\n        qp_index = MB_FIELD ? (i >> 3) : (i & 1);\n\n        index_a = qp[qp_index] + h->slice_alpha_c0_offset;\n\n        alpha = (alpha_table+52)[index_a];\n\n        beta  = (beta_table+52)[qp[qp_index] + h->slice_beta_offset];\n\n\n\n        if( bS[bS_index] < 4 ) {\n\n            const int tc0 = (tc0_table+52)[index_a][bS[bS_index] - 1];\n\n            const int p0 = pix[-1];\n\n            const int p1 = pix[-2];\n\n            const int p2 = pix[-3];\n\n            const int q0 = pix[0];\n\n            const int q1 = pix[1];\n\n            const int q2 = pix[2];\n\n\n\n            if( FFABS( p0 - q0 ) < alpha &&\n\n                FFABS( p1 - p0 ) < beta &&\n\n                FFABS( q1 - q0 ) < beta ) {\n\n                int tc = tc0;\n\n                int i_delta;\n\n\n\n                if( FFABS( p2 - p0 ) < beta ) {\n\n                    pix[-2] = p1 + av_clip( ( p2 + ( ( p0 + q0 + 1 ) >> 1 ) - ( p1 << 1 ) ) >> 1, -tc0, tc0 );\n\n                    tc++;\n\n                }\n\n                if( FFABS( q2 - q0 ) < beta ) {\n\n                    pix[1] = q1 + av_clip( ( q2 + ( ( p0 + q0 + 1 ) >> 1 ) - ( q1 << 1 ) ) >> 1, -tc0, tc0 );\n\n                    tc++;\n\n                }\n\n\n\n                i_delta = av_clip( (((q0 - p0 ) << 2) + (p1 - q1) + 4) >> 3, -tc, tc );\n\n                pix[-1] = av_clip_uint8( p0 + i_delta );    /* p0' */\n\n                pix[0]  = av_clip_uint8( q0 - i_delta );    /* q0' */\n\n                tprintf(h->s.avctx, \"filter_mb_mbaff_edgev i:%d, qp:%d, indexA:%d, alpha:%d, beta:%d, tc:%d\\n# bS:%d -> [%02x, %02x, %02x, %02x, %02x, %02x] =>[%02x, %02x, %02x, %02x]\\n\", i, qp[qp_index], index_a, alpha, beta, tc, bS[bS_index], pix[-3], p1, p0, q0, q1, pix[2], p1, pix[-1], pix[0], q1);\n\n            }\n\n        }else{\n\n            const int p0 = pix[-1];\n\n            const int p1 = pix[-2];\n\n            const int p2 = pix[-3];\n\n\n\n            const int q0 = pix[0];\n\n            const int q1 = pix[1];\n\n            const int q2 = pix[2];\n\n\n\n            if( FFABS( p0 - q0 ) < alpha &&\n\n                FFABS( p1 - p0 ) < beta &&\n\n                FFABS( q1 - q0 ) < beta ) {\n\n\n\n                if(FFABS( p0 - q0 ) < (( alpha >> 2 ) + 2 )){\n\n                    if( FFABS( p2 - p0 ) < beta)\n\n                    {\n\n                        const int p3 = pix[-4];\n\n                        /* p0', p1', p2' */\n\n                        pix[-1] = ( p2 + 2*p1 + 2*p0 + 2*q0 + q1 + 4 ) >> 3;\n\n                        pix[-2] = ( p2 + p1 + p0 + q0 + 2 ) >> 2;\n\n                        pix[-3] = ( 2*p3 + 3*p2 + p1 + p0 + q0 + 4 ) >> 3;\n\n                    } else {\n\n                        /* p0' */\n\n                        pix[-1] = ( 2*p1 + p0 + q1 + 2 ) >> 2;\n\n                    }\n\n                    if( FFABS( q2 - q0 ) < beta)\n\n                    {\n\n                        const int q3 = pix[3];\n\n                        /* q0', q1', q2' */\n\n                        pix[0] = ( p1 + 2*p0 + 2*q0 + 2*q1 + q2 + 4 ) >> 3;\n\n                        pix[1] = ( p0 + q0 + q1 + q2 + 2 ) >> 2;\n\n                        pix[2] = ( 2*q3 + 3*q2 + q1 + q0 + p0 + 4 ) >> 3;\n\n                    } else {\n\n                        /* q0' */\n\n                        pix[0] = ( 2*q1 + q0 + p1 + 2 ) >> 2;\n\n                    }\n\n                }else{\n\n                    /* p0', q0' */\n\n                    pix[-1] = ( 2*p1 + p0 + q1 + 2 ) >> 2;\n\n                    pix[ 0] = ( 2*q1 + q0 + p1 + 2 ) >> 2;\n\n                }\n\n                tprintf(h->s.avctx, \"filter_mb_mbaff_edgev i:%d, qp:%d, indexA:%d, alpha:%d, beta:%d\\n# bS:4 -> [%02x, %02x, %02x, %02x, %02x, %02x] =>[%02x, %02x, %02x, %02x, %02x, %02x]\\n\", i, qp[qp_index], index_a, alpha, beta, p2, p1, p0, q0, q1, q2, pix[-3], pix[-2], pix[-1], pix[0], pix[1], pix[2]);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 7026, "_split": "valid", "_hash": "ae102528290f3e335f0f5d562bb2c0a4"}
{"project": "FFmpeg", "commit_id": "3c895fc098f7637f6d5ec3a9d6766e724a8b9e41", "target": 0, "func": "static void do_audio_out(AVFormatContext *s, \n\n                         AVOutputStream *ost, \n\n                         AVInputStream *ist,\n\n                         unsigned char *buf, int size)\n\n{\n\n    uint8_t *buftmp;\n\n    static uint8_t *audio_buf = NULL;\n\n    static uint8_t *audio_out = NULL;\n\n    const int audio_out_size= 4*MAX_AUDIO_PACKET_SIZE;\n\n\n\n    int size_out, frame_bytes, ret;\n\n    AVCodecContext *enc;\n\n\n\n    /* SC: dynamic allocation of buffers */\n\n    if (!audio_buf)\n\n        audio_buf = av_malloc(2*MAX_AUDIO_PACKET_SIZE);\n\n    if (!audio_out)\n\n        audio_out = av_malloc(audio_out_size);\n\n    if (!audio_buf || !audio_out)\n\n        return;               /* Should signal an error ! */\n\n\n\n    \n\n    enc = &ost->st->codec;\n\n\n\n    if (ost->audio_resample) {\n\n        buftmp = audio_buf;\n\n        size_out = audio_resample(ost->resample, \n\n                                  (short *)buftmp, (short *)buf,\n\n                                  size / (ist->st->codec.channels * 2));\n\n        size_out = size_out * enc->channels * 2;\n\n    } else {\n\n        buftmp = buf;\n\n        size_out = size;\n\n    }\n\n\n\n    /* now encode as many frames as possible */\n\n    if (enc->frame_size > 1) {\n\n        /* output resampled raw samples */\n\n        fifo_write(&ost->fifo, buftmp, size_out, \n\n                   &ost->fifo.wptr);\n\n\n\n        frame_bytes = enc->frame_size * 2 * enc->channels;\n\n        \n\n        while (fifo_read(&ost->fifo, audio_buf, frame_bytes, \n\n                     &ost->fifo.rptr) == 0) {\n\n            AVPacket pkt;\n\n            av_init_packet(&pkt);\n\n\n\n            ret = avcodec_encode_audio(enc, audio_out, audio_out_size, \n\n                                       (short *)audio_buf);\n\n            audio_size += ret;\n\n            pkt.stream_index= ost->index;\n\n            pkt.data= audio_out;\n\n            pkt.size= ret;\n\n            if(enc->coded_frame)\n\n                pkt.pts= enc->coded_frame->pts;\n\n            pkt.flags |= PKT_FLAG_KEY;\n\n            av_write_frame(s, &pkt);\n\n        }\n\n    } else {\n\n        AVPacket pkt;\n\n        av_init_packet(&pkt);\n\n        /* output a pcm frame */\n\n        /* XXX: change encoding codec API to avoid this ? */\n\n        switch(enc->codec->id) {\n\n        case CODEC_ID_PCM_S16LE:\n\n        case CODEC_ID_PCM_S16BE:\n\n        case CODEC_ID_PCM_U16LE:\n\n        case CODEC_ID_PCM_U16BE:\n\n            break;\n\n        default:\n\n            size_out = size_out >> 1;\n\n            break;\n\n        }\n\n        ret = avcodec_encode_audio(enc, audio_out, size_out, \n\n\t\t\t\t   (short *)buftmp);\n\n        audio_size += ret;\n\n        pkt.stream_index= ost->index;\n\n        pkt.data= audio_out;\n\n        pkt.size= ret;\n\n        if(enc->coded_frame)\n\n            pkt.pts= enc->coded_frame->pts;\n\n        pkt.flags |= PKT_FLAG_KEY;\n\n        av_write_frame(s, &pkt);\n\n    }\n\n}\n", "idx": 7037, "_split": "valid", "_hash": "8eadc7aa928a1d44560863af2e1e3966"}
{"project": "FFmpeg", "commit_id": "6701c92fa4269872856c70c3170a9b3291b46247", "target": 0, "func": "static int libopus_encode(AVCodecContext *avctx, AVPacket *avpkt,\n\n                          const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    LibopusEncContext *opus = avctx->priv_data;\n\n    const int sample_size   = avctx->channels *\n\n                              av_get_bytes_per_sample(avctx->sample_fmt);\n\n    uint8_t *audio;\n\n    int ret;\n\n    int discard_padding;\n\n\n\n    if (frame) {\n\n        ret = ff_af_queue_add(&opus->afq, frame);\n\n        if (ret < 0)\n\n            return ret;\n\n        if (frame->nb_samples < opus->opts.packet_size) {\n\n            audio = opus->samples;\n\n            memcpy(audio, frame->data[0], frame->nb_samples * sample_size);\n\n        } else\n\n            audio = frame->data[0];\n\n    } else {\n\n        if (!opus->afq.remaining_samples)\n\n            return 0;\n\n        audio = opus->samples;\n\n        memset(audio, 0, opus->opts.packet_size * sample_size);\n\n    }\n\n\n\n    /* Maximum packet size taken from opusenc in opus-tools. 60ms packets\n\n     * consist of 3 frames in one packet. The maximum frame size is 1275\n\n     * bytes along with the largest possible packet header of 7 bytes. */\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, (1275 * 3 + 7) * opus->stream_count, 0)) < 0)\n\n        return ret;\n\n\n\n    if (avctx->sample_fmt == AV_SAMPLE_FMT_FLT)\n\n        ret = opus_multistream_encode_float(opus->enc, (float *)audio,\n\n                                            opus->opts.packet_size,\n\n                                            avpkt->data, avpkt->size);\n\n    else\n\n        ret = opus_multistream_encode(opus->enc, (opus_int16 *)audio,\n\n                                      opus->opts.packet_size,\n\n                                      avpkt->data, avpkt->size);\n\n\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Error encoding frame: %s\\n\", opus_strerror(ret));\n\n        return ff_opus_error_to_averror(ret);\n\n    }\n\n\n\n    av_shrink_packet(avpkt, ret);\n\n\n\n    ff_af_queue_remove(&opus->afq, opus->opts.packet_size,\n\n                       &avpkt->pts, &avpkt->duration);\n\n\n\n    discard_padding = opus->opts.packet_size - avpkt->duration;\n\n    // Check if subtraction resulted in an overflow\n\n    if ((discard_padding < opus->opts.packet_size) != (avpkt->duration > 0)) {\n\n        av_free_packet(avpkt);\n\n        av_free(avpkt);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if (discard_padding > 0) {\n\n        uint8_t* side_data = av_packet_new_side_data(avpkt,\n\n                                                     AV_PKT_DATA_SKIP_SAMPLES,\n\n                                                     10);\n\n        if(!side_data) {\n\n            av_free_packet(avpkt);\n\n            av_free(avpkt);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        AV_WL32(side_data + 4, discard_padding);\n\n    }\n\n\n\n    *got_packet_ptr = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 7055, "_split": "valid", "_hash": "94e8bbe2a797899756c7cc4044f7af8a"}
{"project": "FFmpeg", "commit_id": "ec4c48397641dbaf4ae8df36c32aaa5a311a11bf", "target": 1, "func": "int avio_open2(AVIOContext **s, const char *filename, int flags,\n\n               const AVIOInterruptCB *int_cb, AVDictionary **options)\n\n{\n\n    AVIOInternal *internal;\n\n    const URLProtocol **protocols;\n\n    URLContext *h;\n\n    int err;\n\n\n\n    protocols = ffurl_get_protocols(NULL, NULL);\n\n    if (!protocols)\n\n        return AVERROR(ENOMEM);\n\n\n\n    err = ffurl_open(&h, filename, flags, int_cb, options, protocols);\n\n    if (err < 0) {\n\n        av_freep(&protocols);\n\n        return err;\n\n    }\n\n\n\n    err = ffio_fdopen(s, h);\n\n    if (err < 0) {\n\n        ffurl_close(h);\n\n        av_freep(&protocols);\n\n        return err;\n\n    }\n\n\n\n    internal = (*s)->opaque;\n\n    internal->protocols = protocols;\n\n\n\n    return 0;\n\n}\n", "idx": 7138, "_split": "valid", "_hash": "1c4c5475625af39bb51d3357f8e57609"}
{"project": "FFmpeg", "commit_id": "36fb07d1abc7738427c98cfb154e2d1b9bcc40fe", "target": 1, "func": "static int decode_vop_header(Mpeg4DecContext *ctx, GetBitContext *gb)\n\n{\n\n    MpegEncContext *s = &ctx->m;\n\n    int time_incr, time_increment;\n\n    int64_t pts;\n\n\n\n    s->pict_type = get_bits(gb, 2) + AV_PICTURE_TYPE_I;        /* pict type: I = 0 , P = 1 */\n\n    if (s->pict_type == AV_PICTURE_TYPE_B && s->low_delay &&\n\n        s->vol_control_parameters == 0 && !(s->flags & CODEC_FLAG_LOW_DELAY)) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"low_delay flag incorrectly, clearing it\\n\");\n\n        s->low_delay = 0;\n\n    }\n\n\n\n    s->partitioned_frame = s->data_partitioning && s->pict_type != AV_PICTURE_TYPE_B;\n\n    if (s->partitioned_frame)\n\n        s->decode_mb = mpeg4_decode_partitioned_mb;\n\n    else\n\n        s->decode_mb = mpeg4_decode_mb;\n\n\n\n    time_incr = 0;\n\n    while (get_bits1(gb) != 0)\n\n        time_incr++;\n\n\n\n    check_marker(gb, \"before time_increment\");\n\n\n\n    if (ctx->time_increment_bits == 0 ||\n\n        !(show_bits(gb, ctx->time_increment_bits + 1) & 1)) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"hmm, seems the headers are not complete, trying to guess time_increment_bits\\n\");\n\n\n\n        for (ctx->time_increment_bits = 1;\n\n             ctx->time_increment_bits < 16;\n\n             ctx->time_increment_bits++) {\n\n            if (s->pict_type == AV_PICTURE_TYPE_P ||\n\n                (s->pict_type == AV_PICTURE_TYPE_S &&\n\n                 ctx->vol_sprite_usage == GMC_SPRITE)) {\n\n                if ((show_bits(gb, ctx->time_increment_bits + 6) & 0x37) == 0x30)\n\n                    break;\n\n            } else if ((show_bits(gb, ctx->time_increment_bits + 5) & 0x1F) == 0x18)\n\n                break;\n\n        }\n\n\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"my guess is %d bits ;)\\n\", ctx->time_increment_bits);\n\n        if (s->avctx->time_base.den && 4*s->avctx->time_base.den < 1<<ctx->time_increment_bits) {\n\n            s->avctx->time_base.den = 1<<ctx->time_increment_bits;\n\n        }\n\n    }\n\n\n\n    if (IS_3IV1)\n\n        time_increment = get_bits1(gb);        // FIXME investigate further\n\n    else\n\n        time_increment = get_bits(gb, ctx->time_increment_bits);\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n        s->last_time_base = s->time_base;\n\n        s->time_base     += time_incr;\n\n        s->time = s->time_base * s->avctx->time_base.den + time_increment;\n\n        if (s->workaround_bugs & FF_BUG_UMP4) {\n\n            if (s->time < s->last_non_b_time) {\n\n                /* header is not mpeg-4-compatible, broken encoder,\n\n                 * trying to workaround */\n\n                s->time_base++;\n\n                s->time += s->avctx->time_base.den;\n\n            }\n\n        }\n\n        s->pp_time         = s->time - s->last_non_b_time;\n\n        s->last_non_b_time = s->time;\n\n    } else {\n\n        s->time    = (s->last_time_base + time_incr) * s->avctx->time_base.den + time_increment;\n\n        s->pb_time = s->pp_time - (s->last_non_b_time - s->time);\n\n        if (s->pp_time <= s->pb_time ||\n\n            s->pp_time <= s->pp_time - s->pb_time ||\n\n            s->pp_time <= 0) {\n\n            /* messed up order, maybe after seeking? skipping current b-frame */\n\n            return FRAME_SKIPPED;\n\n        }\n\n        ff_mpeg4_init_direct_mv(s);\n\n\n\n        if (ctx->t_frame == 0)\n\n            ctx->t_frame = s->pb_time;\n\n        if (ctx->t_frame == 0)\n\n            ctx->t_frame = 1;  // 1/0 protection\n\n        s->pp_field_time = (ROUNDED_DIV(s->last_non_b_time, ctx->t_frame) -\n\n                            ROUNDED_DIV(s->last_non_b_time - s->pp_time, ctx->t_frame)) * 2;\n\n        s->pb_field_time = (ROUNDED_DIV(s->time, ctx->t_frame) -\n\n                            ROUNDED_DIV(s->last_non_b_time - s->pp_time, ctx->t_frame)) * 2;\n\n        if (!s->progressive_sequence) {\n\n            if (s->pp_field_time <= s->pb_field_time || s->pb_field_time <= 1)\n\n                return FRAME_SKIPPED;\n\n        }\n\n    }\n\n\n\n    if (s->avctx->time_base.num)\n\n        pts = ROUNDED_DIV(s->time, s->avctx->time_base.num);\n\n    else\n\n        pts = AV_NOPTS_VALUE;\n\n    if (s->avctx->debug&FF_DEBUG_PTS)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"MPEG4 PTS: %\"PRId64\"\\n\",\n\n               pts);\n\n\n\n    check_marker(gb, \"before vop_coded\");\n\n\n\n    /* vop coded */\n\n    if (get_bits1(gb) != 1) {\n\n        if (s->avctx->debug & FF_DEBUG_PICT_INFO)\n\n            av_log(s->avctx, AV_LOG_ERROR, \"vop not coded\\n\");\n\n        return FRAME_SKIPPED;\n\n    }\n\n    if (ctx->new_pred)\n\n        decode_new_pred(ctx, gb);\n\n\n\n    if (ctx->shape != BIN_ONLY_SHAPE &&\n\n                    (s->pict_type == AV_PICTURE_TYPE_P ||\n\n                     (s->pict_type == AV_PICTURE_TYPE_S &&\n\n                      ctx->vol_sprite_usage == GMC_SPRITE))) {\n\n        /* rounding type for motion estimation */\n\n        s->no_rounding = get_bits1(gb);\n\n    } else {\n\n        s->no_rounding = 0;\n\n    }\n\n    // FIXME reduced res stuff\n\n\n\n    if (ctx->shape != RECT_SHAPE) {\n\n        if (ctx->vol_sprite_usage != 1 || s->pict_type != AV_PICTURE_TYPE_I) {\n\n            skip_bits(gb, 13);  /* width */\n\n            skip_bits1(gb);     /* marker */\n\n            skip_bits(gb, 13);  /* height */\n\n            skip_bits1(gb);     /* marker */\n\n            skip_bits(gb, 13);  /* hor_spat_ref */\n\n            skip_bits1(gb);     /* marker */\n\n            skip_bits(gb, 13);  /* ver_spat_ref */\n\n        }\n\n        skip_bits1(gb);         /* change_CR_disable */\n\n\n\n        if (get_bits1(gb) != 0)\n\n            skip_bits(gb, 8);   /* constant_alpha_value */\n\n    }\n\n\n\n    // FIXME complexity estimation stuff\n\n\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n\n        skip_bits_long(gb, ctx->cplx_estimation_trash_i);\n\n        if (s->pict_type != AV_PICTURE_TYPE_I)\n\n            skip_bits_long(gb, ctx->cplx_estimation_trash_p);\n\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n\n            skip_bits_long(gb, ctx->cplx_estimation_trash_b);\n\n\n\n        if (get_bits_left(gb) < 3) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Header truncated\\n\");\n\n            return -1;\n\n        }\n\n        ctx->intra_dc_threshold = ff_mpeg4_dc_threshold[get_bits(gb, 3)];\n\n        if (!s->progressive_sequence) {\n\n            s->top_field_first = get_bits1(gb);\n\n            s->alternate_scan  = get_bits1(gb);\n\n        } else\n\n            s->alternate_scan = 0;\n\n    }\n\n\n\n    if (s->alternate_scan) {\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable,   ff_alternate_vertical_scan);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable,   ff_alternate_vertical_scan);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n    } else {\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable,   ff_zigzag_direct);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable,   ff_zigzag_direct);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n\n        ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n    }\n\n\n\n    if (s->pict_type == AV_PICTURE_TYPE_S &&\n\n        (ctx->vol_sprite_usage == STATIC_SPRITE ||\n\n         ctx->vol_sprite_usage == GMC_SPRITE)) {\n\n        if (mpeg4_decode_sprite_trajectory(ctx, gb) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n        if (ctx->sprite_brightness_change)\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"sprite_brightness_change not supported\\n\");\n\n        if (ctx->vol_sprite_usage == STATIC_SPRITE)\n\n            av_log(s->avctx, AV_LOG_ERROR, \"static sprite not supported\\n\");\n\n    }\n\n\n\n    if (ctx->shape != BIN_ONLY_SHAPE) {\n\n        s->chroma_qscale = s->qscale = get_bits(gb, s->quant_precision);\n\n        if (s->qscale == 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Error, header damaged or not MPEG4 header (qscale=0)\\n\");\n\n            return -1;  // makes no sense to continue, as there is nothing left from the image then\n\n        }\n\n\n\n        if (s->pict_type != AV_PICTURE_TYPE_I) {\n\n            s->f_code = get_bits(gb, 3);        /* fcode_for */\n\n            if (s->f_code == 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"Error, header damaged or not MPEG4 header (f_code=0)\\n\");\n\n                s->f_code = 1;\n\n                return -1;  // makes no sense to continue, as there is nothing left from the image then\n\n            }\n\n        } else\n\n            s->f_code = 1;\n\n\n\n        if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n            s->b_code = get_bits(gb, 3);\n\n            if (s->b_code == 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"Error, header damaged or not MPEG4 header (b_code=0)\\n\");\n\n                s->b_code=1;\n\n                return -1; // makes no sense to continue, as the MV decoding will break very quickly\n\n            }\n\n        } else\n\n            s->b_code = 1;\n\n\n\n        if (s->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"qp:%d fc:%d,%d %s size:%d pro:%d alt:%d top:%d %spel part:%d resync:%d w:%d a:%d rnd:%d vot:%d%s dc:%d ce:%d/%d/%d time:%\"PRId64\" tincr:%d\\n\",\n\n                   s->qscale, s->f_code, s->b_code,\n\n                   s->pict_type == AV_PICTURE_TYPE_I ? \"I\" : (s->pict_type == AV_PICTURE_TYPE_P ? \"P\" : (s->pict_type == AV_PICTURE_TYPE_B ? \"B\" : \"S\")),\n\n                   gb->size_in_bits,s->progressive_sequence, s->alternate_scan,\n\n                   s->top_field_first, s->quarter_sample ? \"q\" : \"h\",\n\n                   s->data_partitioning, ctx->resync_marker,\n\n                   ctx->num_sprite_warping_points, s->sprite_warping_accuracy,\n\n                   1 - s->no_rounding, s->vo_type,\n\n                   s->vol_control_parameters ? \" VOLC\" : \" \", ctx->intra_dc_threshold,\n\n                   ctx->cplx_estimation_trash_i, ctx->cplx_estimation_trash_p,\n\n                   ctx->cplx_estimation_trash_b,\n\n                   s->time,\n\n                   time_increment\n\n                  );\n\n        }\n\n\n\n        if (!ctx->scalability) {\n\n            if (ctx->shape != RECT_SHAPE && s->pict_type != AV_PICTURE_TYPE_I)\n\n                skip_bits1(gb);  // vop shape coding type\n\n        } else {\n\n            if (ctx->enhancement_type) {\n\n                int load_backward_shape = get_bits1(gb);\n\n                if (load_backward_shape)\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                           \"load backward shape isn't supported\\n\");\n\n            }\n\n            skip_bits(gb, 2);  // ref_select_code\n\n        }\n\n    }\n\n    /* detect buggy encoders which don't set the low_delay flag\n\n     * (divx4/xvid/opendivx). Note we cannot detect divx5 without b-frames\n\n     * easily (although it's buggy too) */\n\n    if (s->vo_type == 0 && s->vol_control_parameters == 0 &&\n\n        ctx->divx_version == -1 && s->picture_number == 0) {\n\n        av_log(s->avctx, AV_LOG_WARNING,\n\n               \"looks like this file was encoded with (divx4/(old)xvid/opendivx) -> forcing low_delay flag\\n\");\n\n        s->low_delay = 1;\n\n    }\n\n\n\n    s->picture_number++;  // better than pic number==0 always ;)\n\n\n\n    // FIXME add short header support\n\n    s->y_dc_scale_table = ff_mpeg4_y_dc_scale_table;\n\n    s->c_dc_scale_table = ff_mpeg4_c_dc_scale_table;\n\n\n\n    if (s->workaround_bugs & FF_BUG_EDGE) {\n\n        s->h_edge_pos = s->width;\n\n        s->v_edge_pos = s->height;\n\n    }\n\n    return 0;\n\n}\n", "idx": 7139, "_split": "valid", "_hash": "d222f2f7ec530c4723645d92516979f9"}
{"project": "FFmpeg", "commit_id": "5a2ad7ede33b5d63c1f1b1313a218da62e1c0d48", "target": 0, "func": "static int vorbis_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                               const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    vorbis_enc_context *venc = avctx->priv_data;\n\n    int i, ret, need_more;\n\n    int samples = 0, frame_size = 1 << (venc->log2_blocksize[1] - 1);\n\n    vorbis_enc_mode *mode;\n\n    vorbis_enc_mapping *mapping;\n\n    PutBitContext pb;\n\n\n\n    if (frame) {\n\n        if ((ret = ff_af_queue_add(&venc->afq, frame)) < 0)\n\n            return ret;\n\n        ff_bufqueue_add(avctx, &venc->bufqueue, av_frame_clone(frame));\n\n    } else\n\n        if (!venc->afq.remaining_samples)\n\n            return 0;\n\n\n\n    need_more = venc->bufqueue.available * avctx->frame_size < frame_size;\n\n    need_more = frame && need_more;\n\n    if (need_more)\n\n        return 0;\n\n\n\n    /* Pad the bufqueue with empty frames for encoding the last packet. */\n\n    if (!frame) {\n\n        if (venc->bufqueue.available * avctx->frame_size < frame_size) {\n\n            int frames_needed = (frame_size/avctx->frame_size) - venc->bufqueue.available;\n\n\n\n            for (int i = 0; i < frames_needed; i++) {\n\n               AVFrame *empty = spawn_empty_frame(avctx, venc->channels);\n\n               if (!empty)\n\n                   return AVERROR(ENOMEM);\n\n\n\n               ff_bufqueue_add(avctx, &venc->bufqueue, empty);\n\n            }\n\n        }\n\n    }\n\n\n\n    move_audio(venc, venc->scratch, &samples, avctx->frame_size);\n\n\n\n    if (!apply_window_and_mdct(venc, venc->scratch, samples))\n\n        return 0;\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, 8192, 0)) < 0)\n\n        return ret;\n\n\n\n    init_put_bits(&pb, avpkt->data, avpkt->size);\n\n\n\n    if (pb.size_in_bits - put_bits_count(&pb) < 1 + ilog(venc->nmodes - 1)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"output buffer is too small\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    put_bits(&pb, 1, 0); // magic bit\n\n\n\n    put_bits(&pb, ilog(venc->nmodes - 1), 0); // 0 bits, the mode\n\n\n\n    mode    = &venc->modes[0];\n\n    mapping = &venc->mappings[mode->mapping];\n\n    if (mode->blockflag) {\n\n        put_bits(&pb, 1, 0);\n\n        put_bits(&pb, 1, 0);\n\n    }\n\n\n\n    for (i = 0; i < venc->channels; i++) {\n\n        vorbis_enc_floor *fc = &venc->floors[mapping->floor[mapping->mux[i]]];\n\n        uint16_t posts[MAX_FLOOR_VALUES];\n\n        floor_fit(venc, fc, &venc->coeffs[i * samples], posts, samples);\n\n        if (floor_encode(venc, fc, &pb, posts, &venc->floor[i * samples], samples)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"output buffer is too small\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < venc->channels * samples; i++)\n\n        venc->coeffs[i] /= venc->floor[i];\n\n\n\n    for (i = 0; i < mapping->coupling_steps; i++) {\n\n        float *mag = venc->coeffs + mapping->magnitude[i] * samples;\n\n        float *ang = venc->coeffs + mapping->angle[i]     * samples;\n\n        int j;\n\n        for (j = 0; j < samples; j++) {\n\n            float a = ang[j];\n\n            ang[j] -= mag[j];\n\n            if (mag[j] > 0)\n\n                ang[j] = -ang[j];\n\n            if (ang[j] < 0)\n\n                mag[j] = a;\n\n        }\n\n    }\n\n\n\n    if (residue_encode(venc, &venc->residues[mapping->residue[mapping->mux[0]]],\n\n                       &pb, venc->coeffs, samples, venc->channels)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"output buffer is too small\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    flush_put_bits(&pb);\n\n    avpkt->size = put_bits_count(&pb) >> 3;\n\n\n\n    ff_af_queue_remove(&venc->afq, frame_size, &avpkt->pts, &avpkt->duration);\n\n\n\n    if (frame_size > avpkt->duration) {\n\n        uint8_t *side = av_packet_new_side_data(avpkt, AV_PKT_DATA_SKIP_SAMPLES, 10);\n\n        if (!side)\n\n            return AVERROR(ENOMEM);\n\n        AV_WL32(&side[4], frame_size - avpkt->duration);\n\n    }\n\n\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 7187, "_split": "valid", "_hash": "81af5dc424520d37b3e4352831d97e7c"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(rgb24tobgr16)(const uint8_t *src, uint8_t *dst, unsigned int src_size)\n\n{\n\n\tconst uint8_t *s = src;\n\n\tconst uint8_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint8_t *mm_end;\n\n#endif\n\n\tuint16_t *d = (uint16_t *)dst;\n\n\tend = s + src_size;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*src):\"memory\");\n\n\t__asm __volatile(\n\n\t    \"movq\t%0, %%mm7\\n\\t\"\n\n\t    \"movq\t%1, %%mm6\\n\\t\"\n\n\t    ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n\tmm_end = end - 15;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movd\t%1, %%mm0\\n\\t\"\n\n\t\t\"movd\t3%1, %%mm3\\n\\t\"\n\n\t\t\"punpckldq 6%1, %%mm0\\n\\t\"\n\n\t\t\"punpckldq 9%1, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm5\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm0\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm3\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm0\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm4\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm4\\n\\t\"\n\n\t\t\"psrlq\t$19, %%mm2\\n\\t\"\n\n\t\t\"psrlq\t$19, %%mm5\\n\\t\"\n\n\t\t\"pand\t%2, %%mm2\\n\\t\"\n\n\t\t\"pand\t%2, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\t:\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n\t\td += 4;\n\n\t\ts += 12;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tconst int r= *s++;\n\n\t\tconst int g= *s++;\n\n\t\tconst int b= *s++;\n\n\t\t*d++ = (b>>3) | ((g&0xFC)<<3) | ((r&0xF8)<<8);\n\n\t}\n\n}\n", "idx": 7250, "_split": "valid", "_hash": "ec2360131ecb473ce6f3d130adb90575"}
{"project": "FFmpeg", "commit_id": "e87190f5d20d380608f792ceb14d0def1d80e24b", "target": 0, "func": "static int probe_file(WriterContext *wctx, const char *filename)\n\n{\n\n    AVFormatContext *fmt_ctx;\n\n    int ret, i;\n\n    int section_id;\n\n\n\n    do_read_frames = do_show_frames || do_count_frames;\n\n    do_read_packets = do_show_packets || do_count_packets;\n\n\n\n    ret = open_input_file(&fmt_ctx, filename);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    nb_streams_frames  = av_calloc(fmt_ctx->nb_streams, sizeof(*nb_streams_frames));\n\n    nb_streams_packets = av_calloc(fmt_ctx->nb_streams, sizeof(*nb_streams_packets));\n\n    selected_streams   = av_calloc(fmt_ctx->nb_streams, sizeof(*selected_streams));\n\n\n\n    for (i = 0; i < fmt_ctx->nb_streams; i++) {\n\n        if (stream_specifier) {\n\n            ret = avformat_match_stream_specifier(fmt_ctx,\n\n                                                  fmt_ctx->streams[i],\n\n                                                  stream_specifier);\n\n            if (ret < 0)\n\n                goto end;\n\n            else\n\n                selected_streams[i] = ret;\n\n            ret = 0;\n\n        } else {\n\n            selected_streams[i] = 1;\n\n        }\n\n    }\n\n\n\n    if (do_read_frames || do_read_packets) {\n\n        if (do_show_frames && do_show_packets &&\n\n            wctx->writer->flags & WRITER_FLAG_PUT_PACKETS_AND_FRAMES_IN_SAME_CHAPTER)\n\n            section_id = SECTION_ID_PACKETS_AND_FRAMES;\n\n        else if (do_show_packets && !do_show_frames)\n\n            section_id = SECTION_ID_PACKETS;\n\n        else // (!do_show_packets && do_show_frames)\n\n            section_id = SECTION_ID_FRAMES;\n\n        if (do_show_frames || do_show_packets)\n\n            writer_print_section_header(wctx, section_id);\n\n        read_packets(wctx, fmt_ctx);\n\n        if (do_show_frames || do_show_packets)\n\n            writer_print_section_footer(wctx);\n\n    }\n\n    if (do_show_programs)\n\n        show_programs(wctx, fmt_ctx);\n\n    if (do_show_streams)\n\n        show_streams(wctx, fmt_ctx);\n\n    if (do_show_chapters)\n\n        show_chapters(wctx, fmt_ctx);\n\n    if (do_show_format)\n\n        show_format(wctx, fmt_ctx);\n\n\n\nend:\n\n    close_input_file(&fmt_ctx);\n\n    av_freep(&nb_streams_frames);\n\n    av_freep(&nb_streams_packets);\n\n    av_freep(&selected_streams);\n\n\n\n    return ret;\n\n}\n", "idx": 7256, "_split": "valid", "_hash": "1f288c51b0839584a9fbb589db508e19"}
{"project": "FFmpeg", "commit_id": "9aeca1c572dcd446bba340eb6c5fa4f65e18d1e8", "target": 1, "func": "static int decode_frame_header(AVCodecContext *ctx,\n\n                               const uint8_t *data, int size, int *ref)\n\n{\n\n    VP9Context *s = ctx->priv_data;\n\n    int c, i, j, k, l, m, n, w, h, max, size2, res, sharp;\n\n    int last_invisible;\n\n    const uint8_t *data2;\n\n\n\n    /* general header */\n\n    if ((res = init_get_bits8(&s->gb, data, size)) < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Failed to initialize bitstream reader\\n\");\n\n        return res;\n\n    }\n\n    if (get_bits(&s->gb, 2) != 0x2) { // frame marker\n\n        av_log(ctx, AV_LOG_ERROR, \"Invalid frame marker\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    s->profile = get_bits1(&s->gb);\n\n    if (get_bits1(&s->gb)) { // reserved bit\n\n        av_log(ctx, AV_LOG_ERROR, \"Reserved bit should be zero\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (get_bits1(&s->gb)) {\n\n        *ref = get_bits(&s->gb, 3);\n\n        return 0;\n\n    }\n\n    s->last_uses_2pass = s->uses_2pass;\n\n    s->last_keyframe  = s->keyframe;\n\n    s->keyframe       = !get_bits1(&s->gb);\n\n    last_invisible    = s->invisible;\n\n    s->invisible      = !get_bits1(&s->gb);\n\n    s->errorres       = get_bits1(&s->gb);\n\n    s->use_last_frame_mvs = !s->errorres && !last_invisible;\n\n    if (s->keyframe) {\n\n        if (get_bits_long(&s->gb, 24) != VP9_SYNCCODE) { // synccode\n\n            av_log(ctx, AV_LOG_ERROR, \"Invalid sync code\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->colorspace = get_bits(&s->gb, 3);\n\n        if (s->colorspace == 7) { // RGB = profile 1\n\n            av_log(ctx, AV_LOG_ERROR, \"RGB not supported in profile 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->fullrange  = get_bits1(&s->gb);\n\n        // for profile 1, here follows the subsampling bits\n\n        s->refreshrefmask = 0xff;\n\n        w = get_bits(&s->gb, 16) + 1;\n\n        h = get_bits(&s->gb, 16) + 1;\n\n        if (get_bits1(&s->gb)) // display size\n\n            skip_bits(&s->gb, 32);\n\n    } else {\n\n        s->intraonly  = s->invisible ? get_bits1(&s->gb) : 0;\n\n        s->resetctx   = s->errorres ? 0 : get_bits(&s->gb, 2);\n\n        if (s->intraonly) {\n\n            if (get_bits_long(&s->gb, 24) != VP9_SYNCCODE) { // synccode\n\n                av_log(ctx, AV_LOG_ERROR, \"Invalid sync code\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            s->refreshrefmask = get_bits(&s->gb, 8);\n\n            w = get_bits(&s->gb, 16) + 1;\n\n            h = get_bits(&s->gb, 16) + 1;\n\n            if (get_bits1(&s->gb)) // display size\n\n                skip_bits(&s->gb, 32);\n\n        } else {\n\n            s->refreshrefmask = get_bits(&s->gb, 8);\n\n            s->refidx[0]      = get_bits(&s->gb, 3);\n\n            s->signbias[0]    = get_bits1(&s->gb);\n\n            s->refidx[1]      = get_bits(&s->gb, 3);\n\n            s->signbias[1]    = get_bits1(&s->gb);\n\n            s->refidx[2]      = get_bits(&s->gb, 3);\n\n            s->signbias[2]    = get_bits1(&s->gb);\n\n            if (!s->refs[s->refidx[0]].f->data[0] ||\n\n                !s->refs[s->refidx[1]].f->data[0] ||\n\n                !s->refs[s->refidx[2]].f->data[0]) {\n\n                av_log(ctx, AV_LOG_ERROR, \"Not all references are available\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (get_bits1(&s->gb)) {\n\n                w = s->refs[s->refidx[0]].f->width;\n\n                h = s->refs[s->refidx[0]].f->height;\n\n            } else if (get_bits1(&s->gb)) {\n\n                w = s->refs[s->refidx[1]].f->width;\n\n                h = s->refs[s->refidx[1]].f->height;\n\n            } else if (get_bits1(&s->gb)) {\n\n                w = s->refs[s->refidx[2]].f->width;\n\n                h = s->refs[s->refidx[2]].f->height;\n\n            } else {\n\n                w = get_bits(&s->gb, 16) + 1;\n\n                h = get_bits(&s->gb, 16) + 1;\n\n            }\n\n            // Note that in this code, \"CUR_FRAME\" is actually before we\n\n            // have formally allocated a frame, and thus actually represents\n\n            // the _last_ frame\n\n            s->use_last_frame_mvs &= s->frames[CUR_FRAME].tf.f->width == w &&\n\n                                     s->frames[CUR_FRAME].tf.f->height == h;\n\n            if (get_bits1(&s->gb)) // display size\n\n                skip_bits(&s->gb, 32);\n\n            s->highprecisionmvs = get_bits1(&s->gb);\n\n            s->filtermode = get_bits1(&s->gb) ? FILTER_SWITCHABLE :\n\n                                                get_bits(&s->gb, 2);\n\n            s->allowcompinter = s->signbias[0] != s->signbias[1] ||\n\n                                s->signbias[0] != s->signbias[2];\n\n            if (s->allowcompinter) {\n\n                if (s->signbias[0] == s->signbias[1]) {\n\n                    s->fixcompref    = 2;\n\n                    s->varcompref[0] = 0;\n\n                    s->varcompref[1] = 1;\n\n                } else if (s->signbias[0] == s->signbias[2]) {\n\n                    s->fixcompref    = 1;\n\n                    s->varcompref[0] = 0;\n\n                    s->varcompref[1] = 2;\n\n                } else {\n\n                    s->fixcompref    = 0;\n\n                    s->varcompref[0] = 1;\n\n                    s->varcompref[1] = 2;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    s->refreshctx   = s->errorres ? 0 : get_bits1(&s->gb);\n\n    s->parallelmode = s->errorres ? 1 : get_bits1(&s->gb);\n\n    s->framectxid   = c = get_bits(&s->gb, 2);\n\n\n\n    /* loopfilter header data */\n\n    s->filter.level = get_bits(&s->gb, 6);\n\n    sharp = get_bits(&s->gb, 3);\n\n    // if sharpness changed, reinit lim/mblim LUTs. if it didn't change, keep\n\n    // the old cache values since they are still valid\n\n    if (s->filter.sharpness != sharp)\n\n        memset(s->filter.lim_lut, 0, sizeof(s->filter.lim_lut));\n\n    s->filter.sharpness = sharp;\n\n    if ((s->lf_delta.enabled = get_bits1(&s->gb))) {\n\n        if (get_bits1(&s->gb)) {\n\n            for (i = 0; i < 4; i++)\n\n                if (get_bits1(&s->gb))\n\n                    s->lf_delta.ref[i] = get_sbits_inv(&s->gb, 6);\n\n            for (i = 0; i < 2; i++)\n\n                if (get_bits1(&s->gb))\n\n                    s->lf_delta.mode[i] = get_sbits_inv(&s->gb, 6);\n\n        }\n\n    } else {\n\n        memset(&s->lf_delta, 0, sizeof(s->lf_delta));\n\n    }\n\n\n\n    /* quantization header data */\n\n    s->yac_qi      = get_bits(&s->gb, 8);\n\n    s->ydc_qdelta  = get_bits1(&s->gb) ? get_sbits_inv(&s->gb, 4) : 0;\n\n    s->uvdc_qdelta = get_bits1(&s->gb) ? get_sbits_inv(&s->gb, 4) : 0;\n\n    s->uvac_qdelta = get_bits1(&s->gb) ? get_sbits_inv(&s->gb, 4) : 0;\n\n    s->lossless    = s->yac_qi == 0 && s->ydc_qdelta == 0 &&\n\n                     s->uvdc_qdelta == 0 && s->uvac_qdelta == 0;\n\n\n\n    /* segmentation header info */\n\n    if ((s->segmentation.enabled = get_bits1(&s->gb))) {\n\n        if ((s->segmentation.update_map = get_bits1(&s->gb))) {\n\n            for (i = 0; i < 7; i++)\n\n                s->prob.seg[i] = get_bits1(&s->gb) ?\n\n                                 get_bits(&s->gb, 8) : 255;\n\n            if ((s->segmentation.temporal = get_bits1(&s->gb)))\n\n                for (i = 0; i < 3; i++)\n\n                    s->prob.segpred[i] = get_bits1(&s->gb) ?\n\n                                         get_bits(&s->gb, 8) : 255;\n\n        } else {\n\n            s->use_last_frame_segmap = !s->keyframe && !s->intraonly &&\n\n                s->frames[CUR_FRAME].tf.f->width == w &&\n\n                s->frames[CUR_FRAME].tf.f->height == h;\n\n        }\n\n\n\n        if (get_bits1(&s->gb)) {\n\n            s->segmentation.absolute_vals = get_bits1(&s->gb);\n\n            for (i = 0; i < 8; i++) {\n\n                if ((s->segmentation.feat[i].q_enabled = get_bits1(&s->gb)))\n\n                    s->segmentation.feat[i].q_val = get_sbits_inv(&s->gb, 8);\n\n                if ((s->segmentation.feat[i].lf_enabled = get_bits1(&s->gb)))\n\n                    s->segmentation.feat[i].lf_val = get_sbits_inv(&s->gb, 6);\n\n                if ((s->segmentation.feat[i].ref_enabled = get_bits1(&s->gb)))\n\n                    s->segmentation.feat[i].ref_val = get_bits(&s->gb, 2);\n\n                s->segmentation.feat[i].skip_enabled = get_bits1(&s->gb);\n\n            }\n\n        }\n\n    } else {\n\n        s->segmentation.feat[0].q_enabled    = 0;\n\n        s->segmentation.feat[0].lf_enabled   = 0;\n\n        s->segmentation.feat[0].skip_enabled = 0;\n\n        s->segmentation.feat[0].ref_enabled  = 0;\n\n    }\n\n\n\n    // set qmul[] based on Y/UV, AC/DC and segmentation Q idx deltas\n\n    for (i = 0; i < (s->segmentation.enabled ? 8 : 1); i++) {\n\n        int qyac, qydc, quvac, quvdc, lflvl, sh;\n\n\n\n        if (s->segmentation.feat[i].q_enabled) {\n\n            if (s->segmentation.absolute_vals)\n\n                qyac = s->segmentation.feat[i].q_val;\n\n            else\n\n                qyac = s->yac_qi + s->segmentation.feat[i].q_val;\n\n        } else {\n\n            qyac  = s->yac_qi;\n\n        }\n\n        qydc  = av_clip_uintp2(qyac + s->ydc_qdelta, 8);\n\n        quvdc = av_clip_uintp2(qyac + s->uvdc_qdelta, 8);\n\n        quvac = av_clip_uintp2(qyac + s->uvac_qdelta, 8);\n\n        qyac  = av_clip_uintp2(qyac, 8);\n\n\n\n        s->segmentation.feat[i].qmul[0][0] = vp9_dc_qlookup[qydc];\n\n        s->segmentation.feat[i].qmul[0][1] = vp9_ac_qlookup[qyac];\n\n        s->segmentation.feat[i].qmul[1][0] = vp9_dc_qlookup[quvdc];\n\n        s->segmentation.feat[i].qmul[1][1] = vp9_ac_qlookup[quvac];\n\n\n\n        sh = s->filter.level >= 32;\n\n        if (s->segmentation.feat[i].lf_enabled) {\n\n            if (s->segmentation.absolute_vals)\n\n                lflvl = s->segmentation.feat[i].lf_val;\n\n            else\n\n                lflvl = s->filter.level + s->segmentation.feat[i].lf_val;\n\n        } else {\n\n            lflvl  = s->filter.level;\n\n        }\n\n        s->segmentation.feat[i].lflvl[0][0] =\n\n        s->segmentation.feat[i].lflvl[0][1] =\n\n            av_clip_uintp2(lflvl + (s->lf_delta.ref[0] << sh), 6);\n\n        for (j = 1; j < 4; j++) {\n\n            s->segmentation.feat[i].lflvl[j][0] =\n\n                av_clip_uintp2(lflvl + ((s->lf_delta.ref[j] +\n\n                                         s->lf_delta.mode[0]) << sh), 6);\n\n            s->segmentation.feat[i].lflvl[j][1] =\n\n                av_clip_uintp2(lflvl + ((s->lf_delta.ref[j] +\n\n                                         s->lf_delta.mode[1]) << sh), 6);\n\n        }\n\n    }\n\n\n\n    /* tiling info */\n\n    if ((res = update_size(ctx, w, h)) < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Failed to initialize decoder for %dx%d\\n\", w, h);\n\n        return res;\n\n    }\n\n    for (s->tiling.log2_tile_cols = 0;\n\n         (s->sb_cols >> s->tiling.log2_tile_cols) > 64;\n\n         s->tiling.log2_tile_cols++) ;\n\n    for (max = 0; (s->sb_cols >> max) >= 4; max++) ;\n\n    max = FFMAX(0, max - 1);\n\n    while (max > s->tiling.log2_tile_cols) {\n\n        if (get_bits1(&s->gb))\n\n            s->tiling.log2_tile_cols++;\n\n        else\n\n            break;\n\n    }\n\n    s->tiling.log2_tile_rows = decode012(&s->gb);\n\n    s->tiling.tile_rows = 1 << s->tiling.log2_tile_rows;\n\n    if (s->tiling.tile_cols != (1 << s->tiling.log2_tile_cols)) {\n\n        s->tiling.tile_cols = 1 << s->tiling.log2_tile_cols;\n\n        s->c_b = av_fast_realloc(s->c_b, &s->c_b_size,\n\n                                 sizeof(VP56RangeCoder) * s->tiling.tile_cols);\n\n        if (!s->c_b) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Ran out of memory during range coder init\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n\n\n    if (s->keyframe || s->errorres || s->intraonly) {\n\n        s->prob_ctx[0].p = s->prob_ctx[1].p = s->prob_ctx[2].p =\n\n                           s->prob_ctx[3].p = vp9_default_probs;\n\n        memcpy(s->prob_ctx[0].coef, vp9_default_coef_probs,\n\n               sizeof(vp9_default_coef_probs));\n\n        memcpy(s->prob_ctx[1].coef, vp9_default_coef_probs,\n\n               sizeof(vp9_default_coef_probs));\n\n        memcpy(s->prob_ctx[2].coef, vp9_default_coef_probs,\n\n               sizeof(vp9_default_coef_probs));\n\n        memcpy(s->prob_ctx[3].coef, vp9_default_coef_probs,\n\n               sizeof(vp9_default_coef_probs));\n\n    }\n\n\n\n    // next 16 bits is size of the rest of the header (arith-coded)\n\n    size2 = get_bits(&s->gb, 16);\n\n    data2 = align_get_bits(&s->gb);\n\n    if (size2 > size - (data2 - data)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Invalid compressed header size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    ff_vp56_init_range_decoder(&s->c, data2, size2);\n\n    if (vp56_rac_get_prob_branchy(&s->c, 128)) { // marker bit\n\n        av_log(ctx, AV_LOG_ERROR, \"Marker bit was set\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->keyframe || s->intraonly) {\n\n        memset(s->counts.coef, 0, sizeof(s->counts.coef) + sizeof(s->counts.eob));\n\n    } else {\n\n        memset(&s->counts, 0, sizeof(s->counts));\n\n    }\n\n    // FIXME is it faster to not copy here, but do it down in the fw updates\n\n    // as explicit copies if the fw update is missing (and skip the copy upon\n\n    // fw update)?\n\n    s->prob.p = s->prob_ctx[c].p;\n\n\n\n    // txfm updates\n\n    if (s->lossless) {\n\n        s->txfmmode = TX_4X4;\n\n    } else {\n\n        s->txfmmode = vp8_rac_get_uint(&s->c, 2);\n\n        if (s->txfmmode == 3)\n\n            s->txfmmode += vp8_rac_get(&s->c);\n\n\n\n        if (s->txfmmode == TX_SWITCHABLE) {\n\n            for (i = 0; i < 2; i++)\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.tx8p[i] = update_prob(&s->c, s->prob.p.tx8p[i]);\n\n            for (i = 0; i < 2; i++)\n\n                for (j = 0; j < 2; j++)\n\n                    if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                        s->prob.p.tx16p[i][j] =\n\n                            update_prob(&s->c, s->prob.p.tx16p[i][j]);\n\n            for (i = 0; i < 2; i++)\n\n                for (j = 0; j < 3; j++)\n\n                    if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                        s->prob.p.tx32p[i][j] =\n\n                            update_prob(&s->c, s->prob.p.tx32p[i][j]);\n\n        }\n\n    }\n\n\n\n    // coef updates\n\n    for (i = 0; i < 4; i++) {\n\n        uint8_t (*ref)[2][6][6][3] = s->prob_ctx[c].coef[i];\n\n        if (vp8_rac_get(&s->c)) {\n\n            for (j = 0; j < 2; j++)\n\n                for (k = 0; k < 2; k++)\n\n                    for (l = 0; l < 6; l++)\n\n                        for (m = 0; m < 6; m++) {\n\n                            uint8_t *p = s->prob.coef[i][j][k][l][m];\n\n                            uint8_t *r = ref[j][k][l][m];\n\n                            if (m >= 3 && l == 0) // dc only has 3 pt\n\n                                break;\n\n                            for (n = 0; n < 3; n++) {\n\n                                if (vp56_rac_get_prob_branchy(&s->c, 252)) {\n\n                                    p[n] = update_prob(&s->c, r[n]);\n\n                                } else {\n\n                                    p[n] = r[n];\n\n                                }\n\n                            }\n\n                            p[3] = 0;\n\n                        }\n\n        } else {\n\n            for (j = 0; j < 2; j++)\n\n                for (k = 0; k < 2; k++)\n\n                    for (l = 0; l < 6; l++)\n\n                        for (m = 0; m < 6; m++) {\n\n                            uint8_t *p = s->prob.coef[i][j][k][l][m];\n\n                            uint8_t *r = ref[j][k][l][m];\n\n                            if (m > 3 && l == 0) // dc only has 3 pt\n\n                                break;\n\n                            memcpy(p, r, 3);\n\n                            p[3] = 0;\n\n                        }\n\n        }\n\n        if (s->txfmmode == i)\n\n            break;\n\n    }\n\n\n\n    // mode updates\n\n    for (i = 0; i < 3; i++)\n\n        if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n            s->prob.p.skip[i] = update_prob(&s->c, s->prob.p.skip[i]);\n\n    if (!s->keyframe && !s->intraonly) {\n\n        for (i = 0; i < 7; i++)\n\n            for (j = 0; j < 3; j++)\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.mv_mode[i][j] =\n\n                        update_prob(&s->c, s->prob.p.mv_mode[i][j]);\n\n\n\n        if (s->filtermode == FILTER_SWITCHABLE)\n\n            for (i = 0; i < 4; i++)\n\n                for (j = 0; j < 2; j++)\n\n                    if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                        s->prob.p.filter[i][j] =\n\n                            update_prob(&s->c, s->prob.p.filter[i][j]);\n\n\n\n        for (i = 0; i < 4; i++)\n\n            if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                s->prob.p.intra[i] = update_prob(&s->c, s->prob.p.intra[i]);\n\n\n\n        if (s->allowcompinter) {\n\n            s->comppredmode = vp8_rac_get(&s->c);\n\n            if (s->comppredmode)\n\n                s->comppredmode += vp8_rac_get(&s->c);\n\n            if (s->comppredmode == PRED_SWITCHABLE)\n\n                for (i = 0; i < 5; i++)\n\n                    if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                        s->prob.p.comp[i] =\n\n                            update_prob(&s->c, s->prob.p.comp[i]);\n\n        } else {\n\n            s->comppredmode = PRED_SINGLEREF;\n\n        }\n\n\n\n        if (s->comppredmode != PRED_COMPREF) {\n\n            for (i = 0; i < 5; i++) {\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.single_ref[i][0] =\n\n                        update_prob(&s->c, s->prob.p.single_ref[i][0]);\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.single_ref[i][1] =\n\n                        update_prob(&s->c, s->prob.p.single_ref[i][1]);\n\n            }\n\n        }\n\n\n\n        if (s->comppredmode != PRED_SINGLEREF) {\n\n            for (i = 0; i < 5; i++)\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.comp_ref[i] =\n\n                        update_prob(&s->c, s->prob.p.comp_ref[i]);\n\n        }\n\n\n\n        for (i = 0; i < 4; i++)\n\n            for (j = 0; j < 9; j++)\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.y_mode[i][j] =\n\n                        update_prob(&s->c, s->prob.p.y_mode[i][j]);\n\n\n\n        for (i = 0; i < 4; i++)\n\n            for (j = 0; j < 4; j++)\n\n                for (k = 0; k < 3; k++)\n\n                    if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                        s->prob.p.partition[3 - i][j][k] =\n\n                            update_prob(&s->c, s->prob.p.partition[3 - i][j][k]);\n\n\n\n        // mv fields don't use the update_prob subexp model for some reason\n\n        for (i = 0; i < 3; i++)\n\n            if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                s->prob.p.mv_joint[i] = (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n\n\n        for (i = 0; i < 2; i++) {\n\n            if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                s->prob.p.mv_comp[i].sign = (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n\n\n            for (j = 0; j < 10; j++)\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.mv_comp[i].classes[j] =\n\n                        (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n\n\n            if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                s->prob.p.mv_comp[i].class0 = (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n\n\n            for (j = 0; j < 10; j++)\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.mv_comp[i].bits[j] =\n\n                        (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n        }\n\n\n\n        for (i = 0; i < 2; i++) {\n\n            for (j = 0; j < 2; j++)\n\n                for (k = 0; k < 3; k++)\n\n                    if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                        s->prob.p.mv_comp[i].class0_fp[j][k] =\n\n                            (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n\n\n            for (j = 0; j < 3; j++)\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.mv_comp[i].fp[j] =\n\n                        (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n        }\n\n\n\n        if (s->highprecisionmvs) {\n\n            for (i = 0; i < 2; i++) {\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.mv_comp[i].class0_hp =\n\n                        (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n\n\n                if (vp56_rac_get_prob_branchy(&s->c, 252))\n\n                    s->prob.p.mv_comp[i].hp =\n\n                        (vp8_rac_get_uint(&s->c, 7) << 1) | 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    return (data2 - data) + size2;\n\n}\n", "idx": 7288, "_split": "valid", "_hash": "5c8397a219d513d35425f9722fad7d60"}
{"project": "FFmpeg", "commit_id": "1ca7dc60d2f2cac8fce1bdb53d3d5bae195161b0", "target": 1, "func": "yuv2422_1_c_template(SwsContext *c, const int16_t *buf0,\n\n                     const int16_t *ubuf[2], const int16_t *vbuf[2],\n\n                     const int16_t *abuf0, uint8_t *dest, int dstW,\n\n                     int uvalpha, int y, enum PixelFormat target)\n\n{\n\n    const int16_t *ubuf0 = ubuf[0], *ubuf1 = ubuf[1],\n\n                  *vbuf0 = vbuf[0], *vbuf1 = vbuf[1];\n\n    int i;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 = buf0[i * 2]     >> 7;\n\n            int Y2 = buf0[i * 2 + 1] >> 7;\n\n            int U  = ubuf1[i]        >> 7;\n\n            int V  = vbuf1[i]        >> 7;\n\n\n\n            output_pixels(i * 4, Y1, U, Y2, V);\n\n        }\n\n    } else {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 =  buf0[i * 2]          >> 7;\n\n            int Y2 =  buf0[i * 2 + 1]      >> 7;\n\n            int U  = (ubuf0[i] + ubuf1[i]) >> 8;\n\n            int V  = (vbuf0[i] + vbuf1[i]) >> 8;\n\n\n\n            output_pixels(i * 4, Y1, U, Y2, V);\n\n        }\n\n    }\n\n}\n", "idx": 7295, "_split": "valid", "_hash": "acd1d4b1b310bfaff5378fb65f24dd5d"}
{"project": "FFmpeg", "commit_id": "838740e6420538ad45982da6b1d3aa3ae91307f5", "target": 1, "func": "static void decode_sublayer_hrd(HEVCContext *s, int nb_cpb,\n\n                                int subpic_params_present)\n\n{\n\n    GetBitContext *gb = &s->HEVClc.gb;\n\n    int i;\n\n\n\n    for (i = 0; i < nb_cpb; i++) {\n\n        get_ue_golomb_long(gb); // bit_rate_value_minus1\n\n        get_ue_golomb_long(gb); // cpb_size_value_minus1\n\n\n\n        if (subpic_params_present) {\n\n            get_ue_golomb_long(gb); // cpb_size_du_value_minus1\n\n            get_ue_golomb_long(gb); // bit_rate_du_value_minus1\n\n        }\n\n        skip_bits1(gb); // cbr_flag\n\n    }\n\n}\n", "idx": 7352, "_split": "valid", "_hash": "05b5e7bd84e8b849bda39009c0f25538"}
{"project": "FFmpeg", "commit_id": "baced9f5986a466c957456f5cf32a722d8b35512", "target": 0, "func": "static void mpeg4_encode_visual_object_header(MpegEncContext * s){\n\n    int profile_and_level_indication;\n\n    int vo_ver_id;\n\n    \n\n    if(s->max_b_frames || s->quarter_sample){\n\n        profile_and_level_indication= 0xF1; // adv simple level 1\n\n        vo_ver_id= 5;\n\n    }else{\n\n        profile_and_level_indication= 0x01; // simple level 1\n\n        vo_ver_id= 1;\n\n    }\n\n    //FIXME levels\n\n\n\n    put_bits(&s->pb, 16, 0);\n\n    put_bits(&s->pb, 16, VOS_STARTCODE);\n\n\n\n    put_bits(&s->pb, 8, profile_and_level_indication);\n\n\n\n    put_bits(&s->pb, 16, 0);\n\n    put_bits(&s->pb, 16, VISUAL_OBJ_STARTCODE);\n\n    \n\n    put_bits(&s->pb, 1, 1);\n\n        put_bits(&s->pb, 4, vo_ver_id);\n\n        put_bits(&s->pb, 3, 1); //priority\n\n \n\n    put_bits(&s->pb, 4, 1); //visual obj type== video obj\n\n    \n\n    put_bits(&s->pb, 1, 0); //video signal type == no clue //FIXME\n\n\n\n    ff_mpeg4_stuffing(&s->pb);\n\n}\n", "idx": 7406, "_split": "valid", "_hash": "c6b3b93c05f84736ba042dc5af58bd2f"}
{"project": "FFmpeg", "commit_id": "3c27275c1309190f2d6ed69140b67d014215b6c9", "target": 0, "func": "static void add_entry1(TiffEncoderContext *s,\n\n                       enum TiffTags tag, enum TiffTypes type, int val)\n\n{\n\n    uint16_t w  = val;\n\n    uint32_t dw = val;\n\n    add_entry(s, tag, type, 1, type == TIFF_SHORT ? (void *)&w : (void *)&dw);\n\n}\n", "idx": 7434, "_split": "valid", "_hash": "83fbcc44bee552cf0a2506670e28f610"}
{"project": "FFmpeg", "commit_id": "ab296c7a9fe590860dc95ba97e9cbb9dde798f20", "target": 0, "func": "int ff_hevc_decode_nal_sps(HEVCContext *s)\n\n{\n\n    const AVPixFmtDescriptor *desc;\n\n    GetBitContext *gb = &s->HEVClc->gb;\n\n    int ret    = 0;\n\n    int sps_id = 0;\n\n    int log2_diff_max_min_transform_block_size;\n\n    int bit_depth_chroma, start, vui_present, sublayer_ordering_info;\n\n    int i;\n\n\n\n    HEVCSPS *sps;\n\n    AVBufferRef *sps_buf = av_buffer_allocz(sizeof(*sps));\n\n\n\n    if (!sps_buf)\n\n        return AVERROR(ENOMEM);\n\n    sps = (HEVCSPS*)sps_buf->data;\n\n\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"Decoding SPS\\n\");\n\n\n\n    // Coded parameters\n\n\n\n    sps->vps_id = get_bits(gb, 4);\n\n    if (sps->vps_id >= MAX_VPS_COUNT) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"VPS id out of range: %d\\n\", sps->vps_id);\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n\n\n    if (!s->vps_list[sps->vps_id]) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"VPS does not exist \\n\");\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n\n\n    sps->max_sub_layers = get_bits(gb, 3) + 1;\n\n    if (sps->max_sub_layers > MAX_SUB_LAYERS) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"sps_max_sub_layers out of range: %d\\n\",\n\n               sps->max_sub_layers);\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n\n\n    skip_bits1(gb); // temporal_id_nesting_flag\n\n\n\n    parse_ptl(s, &sps->ptl, sps->max_sub_layers);\n\n\n\n    sps_id = get_ue_golomb_long(gb);\n\n    if (sps_id >= MAX_SPS_COUNT) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"SPS id out of range: %d\\n\", sps_id);\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n\n\n    sps->chroma_format_idc = get_ue_golomb_long(gb);\n\n    if (sps->chroma_format_idc != 1) {\n\n        avpriv_report_missing_feature(s->avctx, \"chroma_format_idc != 1\\n\");\n\n        ret = AVERROR_PATCHWELCOME;\n\n        goto err;\n\n    }\n\n\n\n    if (sps->chroma_format_idc == 3)\n\n        sps->separate_colour_plane_flag = get_bits1(gb);\n\n\n\n    sps->width  = get_ue_golomb_long(gb);\n\n    sps->height = get_ue_golomb_long(gb);\n\n    if ((ret = av_image_check_size(sps->width,\n\n                                   sps->height, 0, s->avctx)) < 0)\n\n        goto err;\n\n\n\n    if (get_bits1(gb)) { // pic_conformance_flag\n\n        //TODO: * 2 is only valid for 420\n\n        sps->pic_conf_win.left_offset   = get_ue_golomb_long(gb) * 2;\n\n        sps->pic_conf_win.right_offset  = get_ue_golomb_long(gb) * 2;\n\n        sps->pic_conf_win.top_offset    = get_ue_golomb_long(gb) * 2;\n\n        sps->pic_conf_win.bottom_offset = get_ue_golomb_long(gb) * 2;\n\n\n\n        if (s->avctx->flags2 & CODEC_FLAG2_IGNORE_CROP) {\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"discarding sps conformance window, \"\n\n                   \"original values are l:%u r:%u t:%u b:%u\\n\",\n\n                   sps->pic_conf_win.left_offset,\n\n                   sps->pic_conf_win.right_offset,\n\n                   sps->pic_conf_win.top_offset,\n\n                   sps->pic_conf_win.bottom_offset);\n\n\n\n            sps->pic_conf_win.left_offset   =\n\n            sps->pic_conf_win.right_offset  =\n\n            sps->pic_conf_win.top_offset    =\n\n            sps->pic_conf_win.bottom_offset = 0;\n\n        }\n\n        sps->output_window = sps->pic_conf_win;\n\n    }\n\n\n\n    sps->bit_depth   = get_ue_golomb_long(gb) + 8;\n\n    bit_depth_chroma = get_ue_golomb_long(gb) + 8;\n\n    if (bit_depth_chroma != sps->bit_depth) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Luma bit depth (%d) is different from chroma bit depth (%d), \"\n\n               \"this is unsupported.\\n\",\n\n               sps->bit_depth, bit_depth_chroma);\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n\n\n    if (sps->chroma_format_idc == 1) {\n\n        switch (sps->bit_depth) {\n\n        case 8:  sps->pix_fmt = AV_PIX_FMT_YUV420P;   break;\n\n        case 9:  sps->pix_fmt = AV_PIX_FMT_YUV420P9;  break;\n\n        case 10: sps->pix_fmt = AV_PIX_FMT_YUV420P10; break;\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Unsupported bit depth: %d\\n\",\n\n                   sps->bit_depth);\n\n            ret = AVERROR_PATCHWELCOME;\n\n            goto err;\n\n        }\n\n    } else {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"non-4:2:0 support is currently unspecified.\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    desc = av_pix_fmt_desc_get(sps->pix_fmt);\n\n    if (!desc) {\n\n        ret = AVERROR(EINVAL);\n\n        goto err;\n\n    }\n\n\n\n    sps->hshift[0] = sps->vshift[0] = 0;\n\n    sps->hshift[2] = sps->hshift[1] = desc->log2_chroma_w;\n\n    sps->vshift[2] = sps->vshift[1] = desc->log2_chroma_h;\n\n\n\n    sps->pixel_shift = sps->bit_depth > 8;\n\n\n\n    sps->log2_max_poc_lsb = get_ue_golomb_long(gb) + 4;\n\n    if (sps->log2_max_poc_lsb > 16) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"log2_max_pic_order_cnt_lsb_minus4 out range: %d\\n\",\n\n               sps->log2_max_poc_lsb - 4);\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n\n\n    sublayer_ordering_info = get_bits1(gb);\n\n    start = sublayer_ordering_info ? 0 : sps->max_sub_layers - 1;\n\n    for (i = start; i < sps->max_sub_layers; i++) {\n\n        sps->temporal_layer[i].max_dec_pic_buffering = get_ue_golomb_long(gb) + 1;\n\n        sps->temporal_layer[i].num_reorder_pics      = get_ue_golomb_long(gb);\n\n        sps->temporal_layer[i].max_latency_increase  = get_ue_golomb_long(gb) - 1;\n\n        if (sps->temporal_layer[i].max_dec_pic_buffering > MAX_DPB_SIZE) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"sps_max_dec_pic_buffering_minus1 out of range: %d\\n\",\n\n                   sps->temporal_layer[i].max_dec_pic_buffering - 1);\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto err;\n\n        }\n\n        if (sps->temporal_layer[i].num_reorder_pics > sps->temporal_layer[i].max_dec_pic_buffering - 1) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"sps_max_num_reorder_pics out of range: %d\\n\",\n\n                   sps->temporal_layer[i].num_reorder_pics);\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto err;\n\n        }\n\n    }\n\n\n\n    if (!sublayer_ordering_info) {\n\n        for (i = 0; i < start; i++) {\n\n            sps->temporal_layer[i].max_dec_pic_buffering = sps->temporal_layer[start].max_dec_pic_buffering;\n\n            sps->temporal_layer[i].num_reorder_pics      = sps->temporal_layer[start].num_reorder_pics;\n\n            sps->temporal_layer[i].max_latency_increase  = sps->temporal_layer[start].max_latency_increase;\n\n        }\n\n    }\n\n\n\n    sps->log2_min_cb_size                    = get_ue_golomb_long(gb) + 3;\n\n    sps->log2_diff_max_min_coding_block_size = get_ue_golomb_long(gb);\n\n    sps->log2_min_tb_size                    = get_ue_golomb_long(gb) + 2;\n\n    log2_diff_max_min_transform_block_size   = get_ue_golomb_long(gb);\n\n    sps->log2_max_trafo_size                 = log2_diff_max_min_transform_block_size +\n\n                                               sps->log2_min_tb_size;\n\n\n\n    if (sps->log2_min_tb_size >= sps->log2_min_cb_size) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid value for log2_min_tb_size\");\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n    sps->max_transform_hierarchy_depth_inter = get_ue_golomb_long(gb);\n\n    sps->max_transform_hierarchy_depth_intra = get_ue_golomb_long(gb);\n\n\n\n    sps->scaling_list_enable_flag = get_bits1(gb);\n\n    if (sps->scaling_list_enable_flag) {\n\n        set_default_scaling_list_data(&sps->scaling_list);\n\n\n\n        if (get_bits1(gb)) {\n\n            ret = scaling_list_data(s, &sps->scaling_list);\n\n            if (ret < 0)\n\n                goto err;\n\n        }\n\n    }\n\n\n\n    sps->amp_enabled_flag = get_bits1(gb);\n\n    sps->sao_enabled      = get_bits1(gb);\n\n\n\n    sps->pcm_enabled_flag = get_bits1(gb);\n\n    if (sps->pcm_enabled_flag) {\n\n        sps->pcm.bit_depth   = get_bits(gb, 4) + 1;\n\n        sps->pcm.bit_depth_chroma = get_bits(gb, 4) + 1;\n\n        sps->pcm.log2_min_pcm_cb_size = get_ue_golomb_long(gb) + 3;\n\n        sps->pcm.log2_max_pcm_cb_size = sps->pcm.log2_min_pcm_cb_size +\n\n                                        get_ue_golomb_long(gb);\n\n        if (sps->pcm.bit_depth > sps->bit_depth) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"PCM bit depth (%d) is greater than normal bit depth (%d)\\n\",\n\n                   sps->pcm.bit_depth, sps->bit_depth);\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto err;\n\n        }\n\n\n\n        sps->pcm.loop_filter_disable_flag = get_bits1(gb);\n\n    }\n\n\n\n    sps->nb_st_rps = get_ue_golomb_long(gb);\n\n    if (sps->nb_st_rps > MAX_SHORT_TERM_RPS_COUNT) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Too many short term RPS: %d.\\n\",\n\n               sps->nb_st_rps);\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n    for (i = 0; i < sps->nb_st_rps; i++) {\n\n        if ((ret = ff_hevc_decode_short_term_rps(s, &sps->st_rps[i],\n\n                                                 sps, 0)) < 0)\n\n            goto err;\n\n    }\n\n\n\n    sps->long_term_ref_pics_present_flag = get_bits1(gb);\n\n    if (sps->long_term_ref_pics_present_flag) {\n\n        sps->num_long_term_ref_pics_sps = get_ue_golomb_long(gb);\n\n        for (i = 0; i < sps->num_long_term_ref_pics_sps; i++) {\n\n            sps->lt_ref_pic_poc_lsb_sps[i]       = get_bits(gb, sps->log2_max_poc_lsb);\n\n            sps->used_by_curr_pic_lt_sps_flag[i] = get_bits1(gb);\n\n        }\n\n    }\n\n\n\n    sps->sps_temporal_mvp_enabled_flag          = get_bits1(gb);\n\n    sps->sps_strong_intra_smoothing_enable_flag = get_bits1(gb);\n\n    sps->vui.sar = (AVRational){0, 1};\n\n    vui_present = get_bits1(gb);\n\n    if (vui_present)\n\n        decode_vui(s, sps);\n\n    skip_bits1(gb); // sps_extension_flag\n\n\n\n    if (s->apply_defdispwin) {\n\n        sps->output_window.left_offset   += sps->vui.def_disp_win.left_offset;\n\n        sps->output_window.right_offset  += sps->vui.def_disp_win.right_offset;\n\n        sps->output_window.top_offset    += sps->vui.def_disp_win.top_offset;\n\n        sps->output_window.bottom_offset += sps->vui.def_disp_win.bottom_offset;\n\n    }\n\n    if (sps->output_window.left_offset & (0x1F >> (sps->pixel_shift)) &&\n\n        !(s->avctx->flags & CODEC_FLAG_UNALIGNED)) {\n\n        sps->output_window.left_offset &= ~(0x1F >> (sps->pixel_shift));\n\n        av_log(s->avctx, AV_LOG_WARNING, \"Reducing left output window to %d \"\n\n               \"chroma samples to preserve alignment.\\n\",\n\n               sps->output_window.left_offset);\n\n    }\n\n    sps->output_width  = sps->width -\n\n                         (sps->output_window.left_offset + sps->output_window.right_offset);\n\n    sps->output_height = sps->height -\n\n                         (sps->output_window.top_offset + sps->output_window.bottom_offset);\n\n    if (sps->output_width <= 0 || sps->output_height <= 0) {\n\n        av_log(s->avctx, AV_LOG_WARNING, \"Invalid visible frame dimensions: %dx%d.\\n\",\n\n               sps->output_width, sps->output_height);\n\n        if (s->avctx->err_recognition & AV_EF_EXPLODE) {\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto err;\n\n        }\n\n        av_log(s->avctx, AV_LOG_WARNING,\n\n               \"Displaying the whole video surface.\\n\");\n\n        sps->pic_conf_win.left_offset   =\n\n        sps->pic_conf_win.right_offset  =\n\n        sps->pic_conf_win.top_offset    =\n\n        sps->pic_conf_win.bottom_offset = 0;\n\n        sps->output_width               = sps->width;\n\n        sps->output_height              = sps->height;\n\n    }\n\n\n\n    // Inferred parameters\n\n    sps->log2_ctb_size = sps->log2_min_cb_size +\n\n                         sps->log2_diff_max_min_coding_block_size;\n\n    sps->log2_min_pu_size = sps->log2_min_cb_size - 1;\n\n\n\n    sps->ctb_width  = (sps->width  + (1 << sps->log2_ctb_size) - 1) >> sps->log2_ctb_size;\n\n    sps->ctb_height = (sps->height + (1 << sps->log2_ctb_size) - 1) >> sps->log2_ctb_size;\n\n    sps->ctb_size   = sps->ctb_width * sps->ctb_height;\n\n\n\n    sps->min_cb_width  = sps->width  >> sps->log2_min_cb_size;\n\n    sps->min_cb_height = sps->height >> sps->log2_min_cb_size;\n\n    sps->min_tb_width  = sps->width  >> sps->log2_min_tb_size;\n\n    sps->min_tb_height = sps->height >> sps->log2_min_tb_size;\n\n    sps->min_pu_width  = sps->width  >> sps->log2_min_pu_size;\n\n    sps->min_pu_height = sps->height >> sps->log2_min_pu_size;\n\n\n\n    sps->qp_bd_offset = 6 * (sps->bit_depth - 8);\n\n\n\n    if (sps->width  & ((1 << sps->log2_min_cb_size) - 1) ||\n\n        sps->height & ((1 << sps->log2_min_cb_size) - 1)) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid coded frame dimensions.\\n\");\n\n        goto err;\n\n    }\n\n\n\n    if (sps->log2_ctb_size > MAX_LOG2_CTB_SIZE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"CTB size out of range: 2^%d\\n\", sps->log2_ctb_size);\n\n        goto err;\n\n    }\n\n    if (sps->max_transform_hierarchy_depth_inter > sps->log2_ctb_size - sps->log2_min_tb_size) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"max_transform_hierarchy_depth_inter out of range: %d\\n\",\n\n               sps->max_transform_hierarchy_depth_inter);\n\n        goto err;\n\n    }\n\n    if (sps->max_transform_hierarchy_depth_intra > sps->log2_ctb_size - sps->log2_min_tb_size) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"max_transform_hierarchy_depth_intra out of range: %d\\n\",\n\n               sps->max_transform_hierarchy_depth_intra);\n\n        goto err;\n\n    }\n\n    if (sps->log2_max_trafo_size > FFMIN(sps->log2_ctb_size, 5)) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"max transform block size out of range: %d\\n\",\n\n               sps->log2_max_trafo_size);\n\n        goto err;\n\n    }\n\n\n\n    if (s->avctx->debug & FF_DEBUG_BITSTREAM) {\n\n        av_log(s->avctx, AV_LOG_DEBUG,\n\n               \"Parsed SPS: id %d; coded wxh: %dx%d; \"\n\n               \"cropped wxh: %dx%d; pix_fmt: %s.\\n\",\n\n               sps_id, sps->width, sps->height,\n\n               sps->output_width, sps->output_height,\n\n               av_get_pix_fmt_name(sps->pix_fmt));\n\n    }\n\n\n\n    /* check if this is a repeat of an already parsed SPS, then keep the\n\n     * original one.\n\n     * otherwise drop all PPSes that depend on it */\n\n    if (s->sps_list[sps_id] &&\n\n        !memcmp(s->sps_list[sps_id]->data, sps_buf->data, sps_buf->size)) {\n\n        av_buffer_unref(&sps_buf);\n\n    } else {\n\n        for (i = 0; i < FF_ARRAY_ELEMS(s->pps_list); i++) {\n\n            if (s->pps_list[i] && ((HEVCPPS*)s->pps_list[i]->data)->sps_id == sps_id)\n\n                av_buffer_unref(&s->pps_list[i]);\n\n        }\n\n        av_buffer_unref(&s->sps_list[sps_id]);\n\n        s->sps_list[sps_id] = sps_buf;\n\n    }\n\n\n\n    return 0;\n\n\n\nerr:\n\n    av_buffer_unref(&sps_buf);\n\n    return ret;\n\n}\n", "idx": 7469, "_split": "valid", "_hash": "e6b80e904f69eb10bbe2e1e6f2d878ae"}
{"project": "FFmpeg", "commit_id": "b073819bc974965056f435d69dc51e9ec5877395", "target": 0, "func": "static void do_audio_out(AVFormatContext *s, OutputStream *ost,\n\n                         InputStream *ist, AVFrame *decoded_frame)\n\n{\n\n    uint8_t *buftmp;\n\n\n\n    int size_out, frame_bytes, resample_changed;\n\n    AVCodecContext *enc = ost->st->codec;\n\n    AVCodecContext *dec = ist->st->codec;\n\n    int osize = av_get_bytes_per_sample(enc->sample_fmt);\n\n    int isize = av_get_bytes_per_sample(dec->sample_fmt);\n\n    uint8_t *buf = decoded_frame->data[0];\n\n    int size     = decoded_frame->nb_samples * dec->channels * isize;\n\n\n\n    if (alloc_audio_output_buf(dec, enc, decoded_frame->nb_samples) < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Error allocating audio buffer\\n\");\n\n        exit_program(1);\n\n    }\n\n\n\n    if (enc->channels != dec->channels || enc->sample_rate != dec->sample_rate)\n\n        ost->audio_resample = 1;\n\n\n\n    resample_changed = ost->resample_sample_fmt  != dec->sample_fmt ||\n\n                       ost->resample_channels    != dec->channels   ||\n\n                       ost->resample_sample_rate != dec->sample_rate;\n\n\n\n    if ((ost->audio_resample && !ost->resample) || resample_changed) {\n\n        if (resample_changed) {\n\n            av_log(NULL, AV_LOG_INFO, \"Input stream #%d:%d frame changed from rate:%d fmt:%s ch:%d to rate:%d fmt:%s ch:%d\\n\",\n\n                   ist->file_index, ist->st->index,\n\n                   ost->resample_sample_rate, av_get_sample_fmt_name(ost->resample_sample_fmt), ost->resample_channels,\n\n                   dec->sample_rate, av_get_sample_fmt_name(dec->sample_fmt), dec->channels);\n\n            ost->resample_sample_fmt  = dec->sample_fmt;\n\n            ost->resample_channels    = dec->channels;\n\n            ost->resample_sample_rate = dec->sample_rate;\n\n            if (ost->resample)\n\n                audio_resample_close(ost->resample);\n\n        }\n\n        /* if audio_sync_method is >1 the resampler is needed for audio drift compensation */\n\n        if (audio_sync_method <= 1 &&\n\n            ost->resample_sample_fmt  == enc->sample_fmt &&\n\n            ost->resample_channels    == enc->channels   &&\n\n            ost->resample_sample_rate == enc->sample_rate) {\n\n            ost->resample = NULL;\n\n            ost->audio_resample = 0;\n\n        } else if (ost->audio_resample) {\n\n            if (dec->sample_fmt != AV_SAMPLE_FMT_S16)\n\n                av_log(NULL, AV_LOG_WARNING, \"Using s16 intermediate sample format for resampling\\n\");\n\n            ost->resample = av_audio_resample_init(enc->channels,    dec->channels,\n\n                                                   enc->sample_rate, dec->sample_rate,\n\n                                                   enc->sample_fmt,  dec->sample_fmt,\n\n                                                   16, 10, 0, 0.8);\n\n            if (!ost->resample) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Can not resample %d channels @ %d Hz to %d channels @ %d Hz\\n\",\n\n                       dec->channels, dec->sample_rate,\n\n                       enc->channels, enc->sample_rate);\n\n                exit_program(1);\n\n            }\n\n        }\n\n    }\n\n\n\n#define MAKE_SFMT_PAIR(a,b) ((a)+AV_SAMPLE_FMT_NB*(b))\n\n    if (!ost->audio_resample && dec->sample_fmt != enc->sample_fmt &&\n\n        MAKE_SFMT_PAIR(enc->sample_fmt,dec->sample_fmt) != ost->reformat_pair) {\n\n        if (ost->reformat_ctx)\n\n            av_audio_convert_free(ost->reformat_ctx);\n\n        ost->reformat_ctx = av_audio_convert_alloc(enc->sample_fmt, 1,\n\n                                                   dec->sample_fmt, 1, NULL, 0);\n\n        if (!ost->reformat_ctx) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Cannot convert %s sample format to %s sample format\\n\",\n\n                   av_get_sample_fmt_name(dec->sample_fmt),\n\n                   av_get_sample_fmt_name(enc->sample_fmt));\n\n            exit_program(1);\n\n        }\n\n        ost->reformat_pair = MAKE_SFMT_PAIR(enc->sample_fmt,dec->sample_fmt);\n\n    }\n\n\n\n    if (audio_sync_method) {\n\n        double delta = get_sync_ipts(ost, ist->last_dts) * enc->sample_rate - ost->sync_opts -\n\n                       av_fifo_size(ost->fifo) / (enc->channels * osize);\n\n        int idelta = delta * dec->sample_rate / enc->sample_rate;\n\n        int byte_delta = idelta * isize * dec->channels;\n\n\n\n        // FIXME resample delay\n\n        if (fabs(delta) > 50) {\n\n            if (ist->is_start || fabs(delta) > audio_drift_threshold*enc->sample_rate) {\n\n                if (byte_delta < 0) {\n\n                    byte_delta = FFMAX(byte_delta, -size);\n\n                    size += byte_delta;\n\n                    buf  -= byte_delta;\n\n                    av_log(NULL, AV_LOG_VERBOSE, \"discarding %d audio samples\\n\",\n\n                           -byte_delta / (isize * dec->channels));\n\n                    if (!size)\n\n                        return;\n\n                    ist->is_start = 0;\n\n                } else {\n\n                    av_fast_malloc(&async_buf, &allocated_async_buf_size,\n\n                                   byte_delta + size);\n\n                    if (!async_buf) {\n\n                        av_log(NULL, AV_LOG_FATAL, \"Out of memory in do_audio_out\\n\");\n\n                        exit_program(1);\n\n                    }\n\n\n\n                    if (alloc_audio_output_buf(dec, enc, decoded_frame->nb_samples + idelta) < 0) {\n\n                        av_log(NULL, AV_LOG_FATAL, \"Error allocating audio buffer\\n\");\n\n                        exit_program(1);\n\n                    }\n\n                    ist->is_start = 0;\n\n\n\n                    generate_silence(async_buf, dec->sample_fmt, byte_delta);\n\n                    memcpy(async_buf + byte_delta, buf, size);\n\n                    buf = async_buf;\n\n                    size += byte_delta;\n\n                    av_log(NULL, AV_LOG_VERBOSE, \"adding %d audio samples of silence\\n\", idelta);\n\n                }\n\n            } else if (audio_sync_method > 1) {\n\n                int comp = av_clip(delta, -audio_sync_method, audio_sync_method);\n\n                av_assert0(ost->audio_resample);\n\n                av_log(NULL, AV_LOG_VERBOSE, \"compensating audio timestamp drift:%f compensation:%d in:%d\\n\",\n\n                       delta, comp, enc->sample_rate);\n\n//                fprintf(stderr, \"drift:%f len:%d opts:%\"PRId64\" ipts:%\"PRId64\" fifo:%d\\n\", delta, -1, ost->sync_opts, (int64_t)(get_sync_ipts(ost) * enc->sample_rate), av_fifo_size(ost->fifo)/(ost->st->codec->channels * 2));\n\n                av_resample_compensate(*(struct AVResampleContext**)ost->resample, comp, enc->sample_rate);\n\n            }\n\n        }\n\n    } else\n\n        ost->sync_opts = lrintf(get_sync_ipts(ost, ist->last_dts) * enc->sample_rate) -\n\n                                av_fifo_size(ost->fifo) / (enc->channels * osize); // FIXME wrong\n\n\n\n    if (ost->audio_resample) {\n\n        buftmp = audio_buf;\n\n        size_out = audio_resample(ost->resample,\n\n                                  (short *)buftmp, (short *)buf,\n\n                                  size / (dec->channels * isize));\n\n        size_out = size_out * enc->channels * osize;\n\n    } else {\n\n        buftmp = buf;\n\n        size_out = size;\n\n    }\n\n\n\n    if (!ost->audio_resample && dec->sample_fmt != enc->sample_fmt) {\n\n        const void *ibuf[6] = { buftmp };\n\n        void *obuf[6]  = { audio_buf };\n\n        int istride[6] = { isize };\n\n        int ostride[6] = { osize };\n\n        int len = size_out / istride[0];\n\n        if (av_audio_convert(ost->reformat_ctx, obuf, ostride, ibuf, istride, len) < 0) {\n\n            printf(\"av_audio_convert() failed\\n\");\n\n            if (exit_on_error)\n\n                exit_program(1);\n\n            return;\n\n        }\n\n        buftmp = audio_buf;\n\n        size_out = len * osize;\n\n    }\n\n\n\n    /* now encode as many frames as possible */\n\n    if (!(enc->codec->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE)) {\n\n        /* output resampled raw samples */\n\n        if (av_fifo_realloc2(ost->fifo, av_fifo_size(ost->fifo) + size_out) < 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"av_fifo_realloc2() failed\\n\");\n\n            exit_program(1);\n\n        }\n\n        av_fifo_generic_write(ost->fifo, buftmp, size_out, NULL);\n\n\n\n        frame_bytes = enc->frame_size * osize * enc->channels;\n\n\n\n        while (av_fifo_size(ost->fifo) >= frame_bytes) {\n\n            av_fifo_generic_read(ost->fifo, audio_buf, frame_bytes, NULL);\n\n            encode_audio_frame(s, ost, audio_buf, frame_bytes);\n\n        }\n\n    } else {\n\n        encode_audio_frame(s, ost, buftmp, size_out);\n\n    }\n\n}\n", "idx": 7473, "_split": "valid", "_hash": "e446f92b9ab47c0b501b173dd544d355"}
{"project": "FFmpeg", "commit_id": "e75518e18d953080409711bab291d9501625e103", "target": 0, "func": "static int decode_cell(Indeo3DecodeContext *ctx, AVCodecContext *avctx,\n\n                       Plane *plane, Cell *cell, const uint8_t *data_ptr,\n\n                       const uint8_t *last_ptr)\n\n{\n\n    int           x, mv_x, mv_y, mode, vq_index, prim_indx, second_indx;\n\n    int           zoom_fac;\n\n    int           offset, error = 0, swap_quads[2];\n\n    uint8_t       code, *block, *ref_block = 0;\n\n    const vqEntry *delta[2];\n\n    const uint8_t *data_start = data_ptr;\n\n\n\n    /* get coding mode and VQ table index from the VQ descriptor byte */\n\n    code     = *data_ptr++;\n\n    mode     = code >> 4;\n\n    vq_index = code & 0xF;\n\n\n\n    /* setup output and reference pointers */\n\n    offset = (cell->ypos << 2) * plane->pitch + (cell->xpos << 2);\n\n    block  =  plane->pixels[ctx->buf_sel] + offset;\n\n    if (!cell->mv_ptr) {\n\n        /* use previous line as reference for INTRA cells */\n\n        ref_block = block - plane->pitch;\n\n    } else if (mode >= 10) {\n\n        /* for mode 10 and 11 INTER first copy the predicted cell into the current one */\n\n        /* so we don't need to do data copying for each RLE code later */\n\n        copy_cell(ctx, plane, cell);\n\n    } else {\n\n        /* set the pointer to the reference pixels for modes 0-4 INTER */\n\n        mv_y      = cell->mv_ptr[0];\n\n        mv_x      = cell->mv_ptr[1];\n\n        if (   mv_x + 4*cell->xpos < 0\n\n            || mv_y + 4*cell->ypos < 0\n\n            || mv_x + 4*cell->xpos + 4*cell->width  > plane->width\n\n            || mv_y + 4*cell->ypos + 4*cell->height > plane->height) {\n\n            av_log(avctx, AV_LOG_ERROR, \"motion vector %d %d outside reference\\n\", mv_x + 4*cell->xpos, mv_y + 4*cell->ypos);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        offset   += mv_y * plane->pitch + mv_x;\n\n        ref_block = plane->pixels[ctx->buf_sel ^ 1] + offset;\n\n    }\n\n\n\n    /* select VQ tables as follows: */\n\n    /* modes 0 and 3 use only the primary table for all lines in a block */\n\n    /* while modes 1 and 4 switch between primary and secondary tables on alternate lines */\n\n    if (mode == 1 || mode == 4) {\n\n        code        = ctx->alt_quant[vq_index];\n\n        prim_indx   = (code >> 4)  + ctx->cb_offset;\n\n        second_indx = (code & 0xF) + ctx->cb_offset;\n\n    } else {\n\n        vq_index += ctx->cb_offset;\n\n        prim_indx = second_indx = vq_index;\n\n    }\n\n\n\n    if (prim_indx >= 24 || second_indx >= 24) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid VQ table indexes! Primary: %d, secondary: %d!\\n\",\n\n               prim_indx, second_indx);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    delta[0] = &vq_tab[second_indx];\n\n    delta[1] = &vq_tab[prim_indx];\n\n    swap_quads[0] = second_indx >= 16;\n\n    swap_quads[1] = prim_indx   >= 16;\n\n\n\n    /* requantize the prediction if VQ index of this cell differs from VQ index */\n\n    /* of the predicted cell in order to avoid overflows. */\n\n    if (vq_index >= 8 && ref_block) {\n\n        for (x = 0; x < cell->width << 2; x++)\n\n            ref_block[x] = requant_tab[vq_index & 7][ref_block[x] & 127];\n\n    }\n\n\n\n    error = IV3_NOERR;\n\n\n\n    switch (mode) {\n\n    case 0: /*------------------ MODES 0 & 1 (4x4 block processing) --------------------*/\n\n    case 1:\n\n    case 3: /*------------------ MODES 3 & 4 (4x8 block processing) --------------------*/\n\n    case 4:\n\n        if (mode >= 3 && cell->mv_ptr) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Attempt to apply Mode 3/4 to an INTER cell!\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        zoom_fac = mode >= 3;\n\n        error = decode_cell_data(cell, block, ref_block, plane->pitch, 0, zoom_fac,\n\n                                 mode, delta, swap_quads, &data_ptr, last_ptr);\n\n        break;\n\n    case 10: /*-------------------- MODE 10 (8x8 block processing) ---------------------*/\n\n    case 11: /*----------------- MODE 11 (4x8 INTER block processing) ------------------*/\n\n        if (mode == 10 && !cell->mv_ptr) { /* MODE 10 INTRA processing */\n\n            error = decode_cell_data(cell, block, ref_block, plane->pitch, 1, 1,\n\n                                     mode, delta, swap_quads, &data_ptr, last_ptr);\n\n        } else { /* mode 10 and 11 INTER processing */\n\n            if (mode == 11 && !cell->mv_ptr) {\n\n               av_log(avctx, AV_LOG_ERROR, \"Attempt to use Mode 11 for an INTRA cell!\\n\");\n\n               return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            zoom_fac = mode == 10;\n\n            error = decode_cell_data(cell, block, ref_block, plane->pitch,\n\n                                     zoom_fac, 1, mode, delta, swap_quads,\n\n                                     &data_ptr, last_ptr);\n\n        }\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported coding mode: %d\\n\", mode);\n\n        return AVERROR_INVALIDDATA;\n\n    }//switch mode\n\n\n\n    switch (error) {\n\n    case IV3_BAD_RLE:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: RLE code %X is not allowed at the current line\\n\",\n\n               mode, data_ptr[-1]);\n\n        return AVERROR_INVALIDDATA;\n\n    case IV3_BAD_DATA:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: invalid VQ data\\n\", mode);\n\n        return AVERROR_INVALIDDATA;\n\n    case IV3_BAD_COUNTER:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: RLE-FB invalid counter: %d\\n\", mode, code);\n\n        return AVERROR_INVALIDDATA;\n\n    case IV3_UNSUPPORTED:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: unsupported RLE code: %X\\n\", mode, data_ptr[-1]);\n\n        return AVERROR_INVALIDDATA;\n\n    case IV3_OUT_OF_DATA:\n\n        av_log(avctx, AV_LOG_ERROR, \"Mode %d: attempt to read past end of buffer\\n\", mode);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return data_ptr - data_start; /* report number of bytes consumed from the input buffer */\n\n}\n", "idx": 7511, "_split": "valid", "_hash": "0f77d890e81fc73606683ae6b8a83d8a"}
{"project": "FFmpeg", "commit_id": "fc6a3ef40d34ce8443ae57c2452f3f273d7d4891", "target": 1, "func": "static void reduce_matrix(AudioMix *am, const double *matrix, int stride)\n\n{\n\n    int i, o;\n\n\n\n    memset(am->output_zero, 0, sizeof(am->output_zero));\n\n    memset(am->input_skip,  0, sizeof(am->input_skip));\n\n    memset(am->output_skip, 0, sizeof(am->output_skip));\n\n\n\n    /* exclude output channels if they can be zeroed instead of mixed */\n\n    for (o = 0; o < am->out_channels; o++) {\n\n        int zero = 1;\n\n\n\n        /* check if the output is always silent */\n\n        for (i = 0; i < am->in_channels; i++) {\n\n            if (matrix[o * stride + i] != 0.0) {\n\n                zero = 0;\n\n                break;\n\n            }\n\n        }\n\n        /* check if the corresponding input channel makes a contribution to\n\n           any output channel */\n\n        if (o < am->in_channels) {\n\n            for (i = 0; i < am->out_channels; i++) {\n\n                if (matrix[i * stride + o] != 0.0) {\n\n                    zero = 0;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n        if (zero) {\n\n            am->output_zero[o] = 1;\n\n            am->out_matrix_channels--;\n\n        }\n\n    }\n\n    if (am->out_matrix_channels == 0) {\n\n        am->in_matrix_channels = 0;\n\n        return;\n\n    }\n\n\n\n    /* skip input channels that contribute fully only to the corresponding\n\n       output channel */\n\n    for (i = 0; i < FFMIN(am->in_channels, am->out_channels); i++) {\n\n        int skip = 1;\n\n\n\n        for (o = 0; o < am->out_channels; o++) {\n\n            int i0;\n\n            if ((o != i && matrix[o * stride + i] != 0.0) ||\n\n                (o == i && matrix[o * stride + i] != 1.0)) {\n\n                skip = 0;\n\n                break;\n\n            }\n\n            /* if the input contributes fully to the output, also check that no\n\n               other inputs contribute to this output */\n\n            if (o == i) {\n\n                for (i0 = 0; i0 < am->in_channels; i0++) {\n\n                    if (i0 != i && matrix[o * stride + i0] != 0.0) {\n\n                        skip = 0;\n\n                        break;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        if (skip) {\n\n            am->input_skip[i] = 1;\n\n            am->in_matrix_channels--;\n\n        }\n\n    }\n\n    /* skip input channels that do not contribute to any output channel */\n\n    for (; i < am->in_channels; i++) {\n\n        int contrib = 0;\n\n\n\n        for (o = 0; o < am->out_channels; o++) {\n\n            if (matrix[o * stride + i] != 0.0) {\n\n                contrib = 1;\n\n                break;\n\n            }\n\n        }\n\n        if (!contrib) {\n\n            am->input_skip[i] = 1;\n\n            am->in_matrix_channels--;\n\n        }\n\n    }\n\n    if (am->in_matrix_channels == 0) {\n\n        am->out_matrix_channels = 0;\n\n        return;\n\n    }\n\n\n\n    /* skip output channels that only get full contribution from the\n\n       corresponding input channel */\n\n    for (o = 0; o < FFMIN(am->in_channels, am->out_channels); o++) {\n\n        int skip = 1;\n\n        int o0;\n\n\n\n        for (i = 0; i < am->in_channels; i++) {\n\n            if ((o != i && matrix[o * stride + i] != 0.0) ||\n\n                (o == i && matrix[o * stride + i] != 1.0)) {\n\n                skip = 0;\n\n                break;\n\n            }\n\n        }\n\n        /* check if the corresponding input channel makes a contribution to\n\n           any other output channel */\n\n        i = o;\n\n        for (o0 = 0; o0 < am->out_channels; o0++) {\n\n            if (o0 != i && matrix[o0 * stride + i] != 0.0) {\n\n                skip = 0;\n\n                break;\n\n            }\n\n        }\n\n        if (skip) {\n\n            am->output_skip[o] = 1;\n\n            am->out_matrix_channels--;\n\n        }\n\n    }\n\n    if (am->out_matrix_channels == 0) {\n\n        am->in_matrix_channels = 0;\n\n        return;\n\n    }\n\n}\n", "idx": 7530, "_split": "valid", "_hash": "a64b11ed779664fa3a848ef1e97bcd2a"}
{"project": "FFmpeg", "commit_id": "66e6038cf1459304ed92305b8f3e61e2f45e8fc7", "target": 1, "func": "static int decode_slice_header(H264Context *h, H264Context *h0){\n\n    MpegEncContext * const s = &h->s;\n\n    MpegEncContext * const s0 = &h0->s;\n\n    unsigned int first_mb_in_slice;\n\n    unsigned int pps_id;\n\n    int num_ref_idx_active_override_flag;\n\n    unsigned int slice_type, tmp, i, j;\n\n    int default_ref_list_done = 0;\n\n    int last_pic_structure;\n\n\n\n    s->dropable= h->nal_ref_idc == 0;\n\n\n\n    if((s->avctx->flags2 & CODEC_FLAG2_FAST) && !h->nal_ref_idc){\n\n        s->me.qpel_put= s->dsp.put_2tap_qpel_pixels_tab;\n\n        s->me.qpel_avg= s->dsp.avg_2tap_qpel_pixels_tab;\n\n    }else{\n\n        s->me.qpel_put= s->dsp.put_h264_qpel_pixels_tab;\n\n        s->me.qpel_avg= s->dsp.avg_h264_qpel_pixels_tab;\n\n    }\n\n\n\n    first_mb_in_slice= get_ue_golomb(&s->gb);\n\n\n\n    if((s->flags2 & CODEC_FLAG2_CHUNKS) && first_mb_in_slice == 0){\n\n        h0->current_slice = 0;\n\n        if (!s0->first_field)\n\n            s->current_picture_ptr= NULL;\n\n    }\n\n\n\n    slice_type= get_ue_golomb_31(&s->gb);\n\n    if(slice_type > 9){\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"slice type too large (%d) at %d %d\\n\", h->slice_type, s->mb_x, s->mb_y);\n\n        return -1;\n\n    }\n\n    if(slice_type > 4){\n\n        slice_type -= 5;\n\n        h->slice_type_fixed=1;\n\n    }else\n\n        h->slice_type_fixed=0;\n\n\n\n    slice_type= golomb_to_pict_type[ slice_type ];\n\n    if (slice_type == FF_I_TYPE\n\n        || (h0->current_slice != 0 && slice_type == h0->last_slice_type) ) {\n\n        default_ref_list_done = 1;\n\n    }\n\n    h->slice_type= slice_type;\n\n    h->slice_type_nos= slice_type & 3;\n\n\n\n    s->pict_type= h->slice_type; // to make a few old functions happy, it's wrong though\n\n    if (s->pict_type == FF_B_TYPE && s0->last_picture_ptr == NULL) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR,\n\n               \"B picture before any references, skipping\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pps_id= get_ue_golomb(&s->gb);\n\n    if(pps_id>=MAX_PPS_COUNT){\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"pps_id out of range\\n\");\n\n        return -1;\n\n    }\n\n    if(!h0->pps_buffers[pps_id]) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"non-existing PPS referenced\\n\");\n\n        return -1;\n\n    }\n\n    h->pps= *h0->pps_buffers[pps_id];\n\n\n\n    if(!h0->sps_buffers[h->pps.sps_id]) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"non-existing SPS referenced\\n\");\n\n        return -1;\n\n    }\n\n    h->sps = *h0->sps_buffers[h->pps.sps_id];\n\n\n\n    if(h == h0 && h->dequant_coeff_pps != pps_id){\n\n        h->dequant_coeff_pps = pps_id;\n\n        init_dequant_tables(h);\n\n    }\n\n\n\n    s->mb_width= h->sps.mb_width;\n\n    s->mb_height= h->sps.mb_height * (2 - h->sps.frame_mbs_only_flag);\n\n\n\n    h->b_stride=  s->mb_width*4;\n\n    h->b8_stride= s->mb_width*2;\n\n\n\n    s->width = 16*s->mb_width - 2*FFMIN(h->sps.crop_right, 7);\n\n    if(h->sps.frame_mbs_only_flag)\n\n        s->height= 16*s->mb_height - 2*FFMIN(h->sps.crop_bottom, 7);\n\n    else\n\n        s->height= 16*s->mb_height - 4*FFMIN(h->sps.crop_bottom, 3);\n\n\n\n    if (s->context_initialized\n\n        && (   s->width != s->avctx->width || s->height != s->avctx->height)) {\n\n        if(h != h0)\n\n            return -1;   // width / height changed during parallelized decoding\n\n        free_tables(h);\n\n        flush_dpb(s->avctx);\n\n        MPV_common_end(s);\n\n    }\n\n    if (!s->context_initialized) {\n\n        if(h != h0)\n\n            return -1;  // we cant (re-)initialize context during parallel decoding\n\n        if (MPV_common_init(s) < 0)\n\n            return -1;\n\n        s->first_field = 0;\n\n\n\n        init_scan_tables(h);\n\n        alloc_tables(h);\n\n\n\n        for(i = 1; i < s->avctx->thread_count; i++) {\n\n            H264Context *c;\n\n            c = h->thread_context[i] = av_malloc(sizeof(H264Context));\n\n            memcpy(c, h->s.thread_context[i], sizeof(MpegEncContext));\n\n            memset(&c->s + 1, 0, sizeof(H264Context) - sizeof(MpegEncContext));\n\n            c->sps = h->sps;\n\n            c->pps = h->pps;\n\n            init_scan_tables(c);\n\n            clone_tables(c, h);\n\n        }\n\n\n\n        for(i = 0; i < s->avctx->thread_count; i++)\n\n            if(context_init(h->thread_context[i]) < 0)\n\n                return -1;\n\n\n\n        s->avctx->width = s->width;\n\n        s->avctx->height = s->height;\n\n        s->avctx->sample_aspect_ratio= h->sps.sar;\n\n        if(!s->avctx->sample_aspect_ratio.den)\n\n            s->avctx->sample_aspect_ratio.den = 1;\n\n\n\n        if(h->sps.timing_info_present_flag){\n\n            s->avctx->time_base= (AVRational){h->sps.num_units_in_tick * 2, h->sps.time_scale};\n\n            if(h->x264_build > 0 && h->x264_build < 44)\n\n                s->avctx->time_base.den *= 2;\n\n            av_reduce(&s->avctx->time_base.num, &s->avctx->time_base.den,\n\n                      s->avctx->time_base.num, s->avctx->time_base.den, 1<<30);\n\n        }\n\n    }\n\n\n\n    h->frame_num= get_bits(&s->gb, h->sps.log2_max_frame_num);\n\n\n\n    h->mb_mbaff = 0;\n\n    h->mb_aff_frame = 0;\n\n    last_pic_structure = s0->picture_structure;\n\n    if(h->sps.frame_mbs_only_flag){\n\n        s->picture_structure= PICT_FRAME;\n\n    }else{\n\n        if(get_bits1(&s->gb)) { //field_pic_flag\n\n            s->picture_structure= PICT_TOP_FIELD + get_bits1(&s->gb); //bottom_field_flag\n\n        } else {\n\n            s->picture_structure= PICT_FRAME;\n\n            h->mb_aff_frame = h->sps.mb_aff;\n\n        }\n\n    }\n\n    h->mb_field_decoding_flag= s->picture_structure != PICT_FRAME;\n\n\n\n    if(h0->current_slice == 0){\n\n        while(h->frame_num !=  h->prev_frame_num &&\n\n              h->frame_num != (h->prev_frame_num+1)%(1<<h->sps.log2_max_frame_num)){\n\n            av_log(NULL, AV_LOG_DEBUG, \"Frame num gap %d %d\\n\", h->frame_num, h->prev_frame_num);\n\n            frame_start(h);\n\n            h->prev_frame_num++;\n\n            h->prev_frame_num %= 1<<h->sps.log2_max_frame_num;\n\n            s->current_picture_ptr->frame_num= h->prev_frame_num;\n\n            execute_ref_pic_marking(h, NULL, 0);\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair... */\n\n        if (s0->first_field) {\n\n            assert(s0->current_picture_ptr);\n\n            assert(s0->current_picture_ptr->data[0]);\n\n            assert(s0->current_picture_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE || s->picture_structure == last_pic_structure) {\n\n                /*\n\n                 * Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such.\n\n                 */\n\n                s0->current_picture_ptr = NULL;\n\n                s0->first_field = FIELD_PICTURE;\n\n\n\n            } else {\n\n                if (h->nal_ref_idc &&\n\n                        s0->current_picture_ptr->reference &&\n\n                        s0->current_picture_ptr->frame_num != h->frame_num) {\n\n                    /*\n\n                     * This and previous field were reference, but had\n\n                     * different frame_nums. Consider this field first in\n\n                     * pair. Throw away previous field except for reference\n\n                     * purposes.\n\n                     */\n\n                    s0->first_field = 1;\n\n                    s0->current_picture_ptr = NULL;\n\n\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    s0->first_field = 0;\n\n                }\n\n            }\n\n\n\n        } else {\n\n            /* Frame or first field in a potentially complementary pair */\n\n            assert(!s0->current_picture_ptr);\n\n            s0->first_field = FIELD_PICTURE;\n\n        }\n\n\n\n        if((!FIELD_PICTURE || s0->first_field) && frame_start(h) < 0) {\n\n            s0->first_field = 0;\n\n            return -1;\n\n        }\n\n    }\n\n    if(h != h0)\n\n        clone_slice(h, h0);\n\n\n\n    s->current_picture_ptr->frame_num= h->frame_num; //FIXME frame_num cleanup\n\n\n\n    assert(s->mb_num == s->mb_width * s->mb_height);\n\n    if(first_mb_in_slice << FIELD_OR_MBAFF_PICTURE >= s->mb_num ||\n\n       first_mb_in_slice                    >= s->mb_num){\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"first_mb_in_slice overflow\\n\");\n\n        return -1;\n\n    }\n\n    s->resync_mb_x = s->mb_x = first_mb_in_slice % s->mb_width;\n\n    s->resync_mb_y = s->mb_y = (first_mb_in_slice / s->mb_width) << FIELD_OR_MBAFF_PICTURE;\n\n    if (s->picture_structure == PICT_BOTTOM_FIELD)\n\n        s->resync_mb_y = s->mb_y = s->mb_y + 1;\n\n    assert(s->mb_y < s->mb_height);\n\n\n\n    if(s->picture_structure==PICT_FRAME){\n\n        h->curr_pic_num=   h->frame_num;\n\n        h->max_pic_num= 1<< h->sps.log2_max_frame_num;\n\n    }else{\n\n        h->curr_pic_num= 2*h->frame_num + 1;\n\n        h->max_pic_num= 1<<(h->sps.log2_max_frame_num + 1);\n\n    }\n\n\n\n    if(h->nal_unit_type == NAL_IDR_SLICE){\n\n        get_ue_golomb(&s->gb); /* idr_pic_id */\n\n    }\n\n\n\n    if(h->sps.poc_type==0){\n\n        h->poc_lsb= get_bits(&s->gb, h->sps.log2_max_poc_lsb);\n\n\n\n        if(h->pps.pic_order_present==1 && s->picture_structure==PICT_FRAME){\n\n            h->delta_poc_bottom= get_se_golomb(&s->gb);\n\n        }\n\n    }\n\n\n\n    if(h->sps.poc_type==1 && !h->sps.delta_pic_order_always_zero_flag){\n\n        h->delta_poc[0]= get_se_golomb(&s->gb);\n\n\n\n        if(h->pps.pic_order_present==1 && s->picture_structure==PICT_FRAME)\n\n            h->delta_poc[1]= get_se_golomb(&s->gb);\n\n    }\n\n\n\n    init_poc(h);\n\n\n\n    if(h->pps.redundant_pic_cnt_present){\n\n        h->redundant_pic_count= get_ue_golomb(&s->gb);\n\n    }\n\n\n\n    //set defaults, might be overridden a few lines later\n\n    h->ref_count[0]= h->pps.ref_count[0];\n\n    h->ref_count[1]= h->pps.ref_count[1];\n\n\n\n    if(h->slice_type_nos != FF_I_TYPE){\n\n        if(h->slice_type_nos == FF_B_TYPE){\n\n            h->direct_spatial_mv_pred= get_bits1(&s->gb);\n\n        }\n\n        num_ref_idx_active_override_flag= get_bits1(&s->gb);\n\n\n\n        if(num_ref_idx_active_override_flag){\n\n            h->ref_count[0]= get_ue_golomb(&s->gb) + 1;\n\n            if(h->slice_type_nos==FF_B_TYPE)\n\n                h->ref_count[1]= get_ue_golomb(&s->gb) + 1;\n\n\n\n            if(h->ref_count[0]-1 > 32-1 || h->ref_count[1]-1 > 32-1){\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"reference overflow\\n\");\n\n                h->ref_count[0]= h->ref_count[1]= 1;\n\n                return -1;\n\n            }\n\n        }\n\n        if(h->slice_type_nos == FF_B_TYPE)\n\n            h->list_count= 2;\n\n        else\n\n            h->list_count= 1;\n\n    }else\n\n        h->list_count= 0;\n\n\n\n    if(!default_ref_list_done){\n\n        fill_default_ref_list(h);\n\n    }\n\n\n\n    if(h->slice_type_nos!=FF_I_TYPE && decode_ref_pic_list_reordering(h) < 0)\n\n        return -1;\n\n\n\n    if(h->slice_type_nos!=FF_I_TYPE){\n\n        s->last_picture_ptr= &h->ref_list[0][0];\n\n        ff_copy_picture(&s->last_picture, s->last_picture_ptr);\n\n    }\n\n    if(h->slice_type_nos==FF_B_TYPE){\n\n        s->next_picture_ptr= &h->ref_list[1][0];\n\n        ff_copy_picture(&s->next_picture, s->next_picture_ptr);\n\n    }\n\n\n\n    if(   (h->pps.weighted_pred          && h->slice_type_nos == FF_P_TYPE )\n\n       ||  (h->pps.weighted_bipred_idc==1 && h->slice_type_nos== FF_B_TYPE ) )\n\n        pred_weight_table(h);\n\n    else if(h->pps.weighted_bipred_idc==2 && h->slice_type_nos== FF_B_TYPE)\n\n        implicit_weight_table(h);\n\n    else {\n\n        h->use_weight = 0;\n\n        for (i = 0; i < 2; i++) {\n\n            h->luma_weight_flag[i]   = 0;\n\n            h->chroma_weight_flag[i] = 0;\n\n        }\n\n    }\n\n\n\n    if(h->nal_ref_idc)\n\n        decode_ref_pic_marking(h0, &s->gb);\n\n\n\n    if(FRAME_MBAFF)\n\n        fill_mbaff_ref_list(h);\n\n\n\n    if(h->slice_type_nos==FF_B_TYPE && !h->direct_spatial_mv_pred)\n\n        direct_dist_scale_factor(h);\n\n    direct_ref_list_init(h);\n\n\n\n    if( h->slice_type_nos != FF_I_TYPE && h->pps.cabac ){\n\n        tmp = get_ue_golomb_31(&s->gb);\n\n        if(tmp > 2){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"cabac_init_idc overflow\\n\");\n\n            return -1;\n\n        }\n\n        h->cabac_init_idc= tmp;\n\n    }\n\n\n\n    h->last_qscale_diff = 0;\n\n    tmp = h->pps.init_qp + get_se_golomb(&s->gb);\n\n    if(tmp>51){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"QP %u out of range\\n\", tmp);\n\n        return -1;\n\n    }\n\n    s->qscale= tmp;\n\n    h->chroma_qp[0] = get_chroma_qp(h, 0, s->qscale);\n\n    h->chroma_qp[1] = get_chroma_qp(h, 1, s->qscale);\n\n    //FIXME qscale / qp ... stuff\n\n    if(h->slice_type == FF_SP_TYPE){\n\n        get_bits1(&s->gb); /* sp_for_switch_flag */\n\n    }\n\n    if(h->slice_type==FF_SP_TYPE || h->slice_type == FF_SI_TYPE){\n\n        get_se_golomb(&s->gb); /* slice_qs_delta */\n\n    }\n\n\n\n    h->deblocking_filter = 1;\n\n    h->slice_alpha_c0_offset = 0;\n\n    h->slice_beta_offset = 0;\n\n    if( h->pps.deblocking_filter_parameters_present ) {\n\n        tmp= get_ue_golomb_31(&s->gb);\n\n        if(tmp > 2){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"deblocking_filter_idc %u out of range\\n\", tmp);\n\n            return -1;\n\n        }\n\n        h->deblocking_filter= tmp;\n\n        if(h->deblocking_filter < 2)\n\n            h->deblocking_filter^= 1; // 1<->0\n\n\n\n        if( h->deblocking_filter ) {\n\n            h->slice_alpha_c0_offset = get_se_golomb(&s->gb) << 1;\n\n            h->slice_beta_offset = get_se_golomb(&s->gb) << 1;\n\n        }\n\n    }\n\n\n\n    if(   s->avctx->skip_loop_filter >= AVDISCARD_ALL\n\n       ||(s->avctx->skip_loop_filter >= AVDISCARD_NONKEY && h->slice_type_nos != FF_I_TYPE)\n\n       ||(s->avctx->skip_loop_filter >= AVDISCARD_BIDIR  && h->slice_type_nos == FF_B_TYPE)\n\n       ||(s->avctx->skip_loop_filter >= AVDISCARD_NONREF && h->nal_ref_idc == 0))\n\n        h->deblocking_filter= 0;\n\n\n\n    if(h->deblocking_filter == 1 && h0->max_contexts > 1) {\n\n        if(s->avctx->flags2 & CODEC_FLAG2_FAST) {\n\n            /* Cheat slightly for speed:\n\n               Do not bother to deblock across slices. */\n\n            h->deblocking_filter = 2;\n\n        } else {\n\n            h0->max_contexts = 1;\n\n            if(!h0->single_decode_warning) {\n\n                av_log(s->avctx, AV_LOG_INFO, \"Cannot parallelize deblocking type 1, decoding such frames in sequential order\\n\");\n\n                h0->single_decode_warning = 1;\n\n            }\n\n            if(h != h0)\n\n                return 1; // deblocking switched inside frame\n\n        }\n\n    }\n\n\n\n#if 0 //FMO\n\n    if( h->pps.num_slice_groups > 1  && h->pps.mb_slice_group_map_type >= 3 && h->pps.mb_slice_group_map_type <= 5)\n\n        slice_group_change_cycle= get_bits(&s->gb, ?);\n\n#endif\n\n\n\n    h0->last_slice_type = slice_type;\n\n    h->slice_num = ++h0->current_slice;\n\n    if(h->slice_num >= MAX_SLICES){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Too many slices, increase MAX_SLICES and recompile\\n\");\n\n    }\n\n\n\n    for(j=0; j<2; j++){\n\n        int *ref2frm= h->ref2frm[h->slice_num&(MAX_SLICES-1)][j];\n\n        ref2frm[0]=\n\n        ref2frm[1]= -1;\n\n        for(i=0; i<16; i++)\n\n            ref2frm[i+2]= 4*h->ref_list[j][i].frame_num\n\n                          +(h->ref_list[j][i].reference&3);\n\n        ref2frm[18+0]=\n\n        ref2frm[18+1]= -1;\n\n        for(i=16; i<48; i++)\n\n            ref2frm[i+4]= 4*h->ref_list[j][i].frame_num\n\n                          +(h->ref_list[j][i].reference&3);\n\n    }\n\n\n\n    h->emu_edge_width= (s->flags&CODEC_FLAG_EMU_EDGE) ? 0 : 16;\n\n    h->emu_edge_height= (FRAME_MBAFF || FIELD_PICTURE) ? 0 : h->emu_edge_width;\n\n\n\n    s->avctx->refs= h->sps.ref_frame_count;\n\n\n\n    if(s->avctx->debug&FF_DEBUG_PICT_INFO){\n\n        av_log(h->s.avctx, AV_LOG_DEBUG, \"slice:%d %s mb:%d %c%s%s pps:%u frame:%d poc:%d/%d ref:%d/%d qp:%d loop:%d:%d:%d weight:%d%s %s\\n\",\n\n               h->slice_num,\n\n               (s->picture_structure==PICT_FRAME ? \"F\" : s->picture_structure==PICT_TOP_FIELD ? \"T\" : \"B\"),\n\n               first_mb_in_slice,\n\n               av_get_pict_type_char(h->slice_type), h->slice_type_fixed ? \" fix\" : \"\", h->nal_unit_type == NAL_IDR_SLICE ? \" IDR\" : \"\",\n\n               pps_id, h->frame_num,\n\n               s->current_picture_ptr->field_poc[0], s->current_picture_ptr->field_poc[1],\n\n               h->ref_count[0], h->ref_count[1],\n\n               s->qscale,\n\n               h->deblocking_filter, h->slice_alpha_c0_offset/2, h->slice_beta_offset/2,\n\n               h->use_weight,\n\n               h->use_weight==1 && h->use_weight_chroma ? \"c\" : \"\",\n\n               h->slice_type == FF_B_TYPE ? (h->direct_spatial_mv_pred ? \"SPAT\" : \"TEMP\") : \"\"\n\n               );\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 7543, "_split": "valid", "_hash": "29b634f9359cf6cba830ccd861275763"}
{"project": "FFmpeg", "commit_id": "7e7e59409294af9caa63808e56c5cc824c98b4fc", "target": 0, "func": "static void yuvj444p_to_rgb24(AVPicture *dst, AVPicture *src,\n\n                              int width, int height)\n\n{\n\n    uint8_t *y1_ptr, *cb_ptr, *cr_ptr, *d, *d1;\n\n    int w, y, cb, cr, r_add, g_add, b_add;\n\n    uint8_t *cm = cropTbl + MAX_NEG_CROP;\n\n    unsigned int r, g, b;\n\n\n\n    d = dst->data[0];\n\n    y1_ptr = src->data[0];\n\n    cb_ptr = src->data[1];\n\n    cr_ptr = src->data[2];\n\n    for(;height > 0; height --) {\n\n        d1 = d;\n\n        for(w = width; w > 0; w--) {\n\n            YUV_TO_RGB1(cb_ptr[0], cr_ptr[0]);\n\n\n\n            YUV_TO_RGB2(r, g, b, y1_ptr[0]);\n\n            RGB_OUT(d1, r, g, b);\n\n            d1 += BPP;\n\n\n\n            y1_ptr++;\n\n            cb_ptr++;\n\n            cr_ptr++;\n\n        }\n\n        d += dst->linesize[0];\n\n        y1_ptr += src->linesize[0] - width;\n\n        cb_ptr += src->linesize[1] - width;\n\n        cr_ptr += src->linesize[2] - width;\n\n    }\n\n}\n", "idx": 7610, "_split": "valid", "_hash": "3e27708847e9efddfe6f53776bea959b"}
{"project": "FFmpeg", "commit_id": "c1847c932b1576e8224c38e112a5fd29fa8a6098", "target": 1, "func": "static int rtcp_parse_packet(RTPDemuxContext *s, const unsigned char *buf, int len)\n\n{\n\n    int payload_len;\n\n    while (len >= 2) {\n\n        switch (buf[1]) {\n\n        case RTCP_SR:\n\n            if (len < 16) {\n\n                av_log(NULL, AV_LOG_ERROR, \"Invalid length for RTCP SR packet\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            payload_len = (AV_RB16(buf + 2) + 1) * 4;\n\n\n\n            s->last_rtcp_ntp_time = AV_RB64(buf + 8);\n\n            s->last_rtcp_timestamp = AV_RB32(buf + 16);\n\n            if (s->first_rtcp_ntp_time == AV_NOPTS_VALUE) {\n\n                s->first_rtcp_ntp_time = s->last_rtcp_ntp_time;\n\n                if (!s->base_timestamp)\n\n                    s->base_timestamp = s->last_rtcp_timestamp;\n\n                s->rtcp_ts_offset = s->last_rtcp_timestamp - s->base_timestamp;\n\n            }\n\n\n\n            buf += payload_len;\n\n            len -= payload_len;\n\n            break;\n\n        case RTCP_BYE:\n\n            return -RTCP_BYE;\n\n        default:\n\n            return -1;\n\n        }\n\n    }\n\n    return -1;\n\n}\n", "idx": 7689, "_split": "valid", "_hash": "3d291e0ecc290e6162e9cc25b002433b"}
{"project": "FFmpeg", "commit_id": "076c3a9fa23ca2b0dd167a087ab1e4fb4357a31b", "target": 1, "func": "static int mov_read_header(AVFormatContext *s)\n\n{\n\n    MOVContext *mov = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int j, err;\n\n    MOVAtom atom = { AV_RL32(\"root\") };\n\n    int i;\n\n\n\n    if (mov->decryption_key_len != 0 && mov->decryption_key_len != AES_CTR_KEY_SIZE) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid decryption key len %d expected %d\\n\",\n\n            mov->decryption_key_len, AES_CTR_KEY_SIZE);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    mov->fc = s;\n\n    mov->trak_index = -1;\n\n    /* .mov and .mp4 aren't streamable anyway (only progressive download if moov is before mdat) */\n\n    if (pb->seekable)\n\n        atom.size = avio_size(pb);\n\n    else\n\n        atom.size = INT64_MAX;\n\n\n\n    /* check MOV header */\n\n    do {\n\n    if (mov->moov_retry)\n\n        avio_seek(pb, 0, SEEK_SET);\n\n    if ((err = mov_read_default(mov, pb, atom)) < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"error reading header\\n\");\n\n        mov_read_close(s);\n\n        return err;\n\n    }\n\n    } while (pb->seekable && !mov->found_moov && !mov->moov_retry++);\n\n    if (!mov->found_moov) {\n\n        av_log(s, AV_LOG_ERROR, \"moov atom not found\\n\");\n\n        mov_read_close(s);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    av_log(mov->fc, AV_LOG_TRACE, \"on_parse_exit_offset=%\"PRId64\"\\n\", avio_tell(pb));\n\n\n\n    if (pb->seekable) {\n\n        if (mov->nb_chapter_tracks > 0 && !mov->ignore_chapters)\n\n            mov_read_chapters(s);\n\n        for (i = 0; i < s->nb_streams; i++)\n\n            if (s->streams[i]->codecpar->codec_tag == AV_RL32(\"tmcd\")) {\n\n                mov_read_timecode_track(s, s->streams[i]);\n\n            } else if (s->streams[i]->codecpar->codec_tag == AV_RL32(\"rtmd\")) {\n\n                mov_read_rtmd_track(s, s->streams[i]);\n\n            }\n\n    }\n\n\n\n    /* copy timecode metadata from tmcd tracks to the related video streams */\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        MOVStreamContext *sc = st->priv_data;\n\n        if (sc->timecode_track > 0) {\n\n            AVDictionaryEntry *tcr;\n\n            int tmcd_st_id = -1;\n\n\n\n            for (j = 0; j < s->nb_streams; j++)\n\n                if (s->streams[j]->id == sc->timecode_track)\n\n                    tmcd_st_id = j;\n\n\n\n            if (tmcd_st_id < 0 || tmcd_st_id == i)\n\n                continue;\n\n            tcr = av_dict_get(s->streams[tmcd_st_id]->metadata, \"timecode\", NULL, 0);\n\n            if (tcr)\n\n                av_dict_set(&st->metadata, \"timecode\", tcr->value, 0);\n\n        }\n\n    }\n\n    export_orphan_timecode(s);\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        MOVStreamContext *sc = st->priv_data;\n\n        fix_timescale(mov, sc);\n\n        if(st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO && st->codecpar->codec_id == AV_CODEC_ID_AAC) {\n\n            st->skip_samples = sc->start_pad;\n\n        }\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO && sc->nb_frames_for_fps > 0 && sc->duration_for_fps > 0)\n\n            av_reduce(&st->avg_frame_rate.num, &st->avg_frame_rate.den,\n\n                      sc->time_scale*(int64_t)sc->nb_frames_for_fps, sc->duration_for_fps, INT_MAX);\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n\n            if (st->codecpar->width <= 0 || st->codecpar->height <= 0) {\n\n                st->codecpar->width  = sc->width;\n\n                st->codecpar->height = sc->height;\n\n            }\n\n            if (st->codecpar->codec_id == AV_CODEC_ID_DVD_SUBTITLE) {\n\n                if ((err = mov_rewrite_dvd_sub_extradata(st)) < 0)\n\n                    return err;\n\n            }\n\n        }\n\n        if (mov->handbrake_version &&\n\n            mov->handbrake_version <= 1000000*0 + 1000*10 + 2 &&  // 0.10.2\n\n            st->codecpar->codec_id == AV_CODEC_ID_MP3\n\n        ) {\n\n            av_log(s, AV_LOG_VERBOSE, \"Forcing full parsing for mp3 stream\\n\");\n\n            st->need_parsing = AVSTREAM_PARSE_FULL;\n\n        }\n\n    }\n\n\n\n    if (mov->trex_data) {\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            AVStream *st = s->streams[i];\n\n            MOVStreamContext *sc = st->priv_data;\n\n            if (st->duration > 0)\n\n                st->codecpar->bit_rate = sc->data_size * 8 * sc->time_scale / st->duration;\n\n        }\n\n    }\n\n\n\n    if (mov->use_mfra_for > 0) {\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            AVStream *st = s->streams[i];\n\n            MOVStreamContext *sc = st->priv_data;\n\n            if (sc->duration_for_fps > 0) {\n\n                st->codecpar->bit_rate = sc->data_size * 8 * sc->time_scale /\n\n                    sc->duration_for_fps;\n\n            }\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < mov->bitrates_count && i < s->nb_streams; i++) {\n\n        if (mov->bitrates[i]) {\n\n            s->streams[i]->codecpar->bit_rate = mov->bitrates[i];\n\n        }\n\n    }\n\n\n\n    ff_rfps_calculate(s);\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        MOVStreamContext *sc = st->priv_data;\n\n\n\n        switch (st->codecpar->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            err = ff_replaygain_export(st, s->metadata);\n\n            if (err < 0) {\n\n                mov_read_close(s);\n\n                return err;\n\n            }\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if (sc->display_matrix) {\n\n                err = av_stream_add_side_data(st, AV_PKT_DATA_DISPLAYMATRIX, (uint8_t*)sc->display_matrix,\n\n                                              sizeof(int32_t) * 9);\n\n                if (err < 0)\n\n                    return err;\n\n\n\n                sc->display_matrix = NULL;\n\n            }\n\n            if (sc->stereo3d) {\n\n                err = av_stream_add_side_data(st, AV_PKT_DATA_STEREO3D,\n\n                                              (uint8_t *)sc->stereo3d,\n\n                                              sizeof(*sc->stereo3d));\n\n                if (err < 0)\n\n                    return err;\n\n\n\n                sc->stereo3d = NULL;\n\n            }\n\n            if (sc->spherical) {\n\n                err = av_stream_add_side_data(st, AV_PKT_DATA_SPHERICAL,\n\n                                              (uint8_t *)sc->spherical,\n\n                                              sc->spherical_size);\n\n                if (err < 0)\n\n                    return err;\n\n\n\n                sc->spherical = NULL;\n\n            }\n\n            break;\n\n        }\n\n    }\n\n    ff_configure_buffers_for_index(s, AV_TIME_BASE);\n\n\n\n    return 0;\n\n}\n", "idx": 7709, "_split": "valid", "_hash": "5381f471527f7ccf2bc85f7bd6589bfb"}
{"project": "FFmpeg", "commit_id": "b505f15b1530d72682b3314e84936f80fe6e43b2", "target": 1, "func": "static int thread_execute(AVCodecContext *avctx, action_func* func, void *arg, int *ret, int job_count, int job_size)\n\n{\n\n    SliceThreadContext *c = avctx->internal->thread_ctx;\n\n\n\n    if (!(avctx->active_thread_type&FF_THREAD_SLICE) || avctx->thread_count <= 1)\n\n        return avcodec_default_execute(avctx, func, arg, ret, job_count, job_size);\n\n\n\n    if (job_count <= 0)\n\n        return 0;\n\n\n\n    pthread_mutex_lock(&c->current_job_lock);\n\n\n\n    c->current_job = avctx->thread_count;\n\n    c->job_count = job_count;\n\n    c->job_size = job_size;\n\n    c->args = arg;\n\n    c->func = func;\n\n    c->rets = ret;\n\n    c->current_execute++;\n\n    pthread_cond_broadcast(&c->current_job_cond);\n\n\n\n    thread_park_workers(c, avctx->thread_count);\n\n\n\n    return 0;\n\n}\n", "idx": 7712, "_split": "valid", "_hash": "39e407acff767f60aa5c3b29c0c69ffa"}
{"project": "FFmpeg", "commit_id": "85e7386ae0d33ede4c575d4df4c1faae6c906338", "target": 0, "func": "static void gain_compensate(COOKContext *q, cook_gains *gains_ptr,\n\n                            float* previous_buffer)\n\n{\n\n    const float fc = q->pow2tab[gains_ptr->previous[0] + 63];\n\n    float *buffer = q->mono_mdct_output;\n\n    int i;\n\n\n\n    /* Overlap with the previous block. */\n\n    for(i=0 ; i<q->samples_per_channel ; i++) {\n\n        buffer[i] *= fc;\n\n        buffer[i] += previous_buffer[i];\n\n    }\n\n\n\n    /* Apply gain profile */\n\n    for (i = 0; i < 8; i++) {\n\n        if (gains_ptr->now[i] || gains_ptr->now[i + 1])\n\n            interpolate(q, &buffer[q->gain_size_factor * i],\n\n                        gains_ptr->now[i], gains_ptr->now[i + 1]);\n\n    }\n\n\n\n    /* Save away the current to be previous block. */\n\n    memcpy(previous_buffer, buffer+q->samples_per_channel,\n\n           sizeof(float)*q->samples_per_channel);\n\n}\n", "idx": 7715, "_split": "valid", "_hash": "1a2085bf2e1bc352ff3d698e8723a2e7"}
{"project": "FFmpeg", "commit_id": "ce41c51b0c71c87f623914ba0786aef325d818fe", "target": 1, "func": "int ff_mov_init_hinting(AVFormatContext *s, int index, int src_index)\n\n{\n\n    MOVMuxContext *mov  = s->priv_data;\n\n    MOVTrack *track     = &mov->tracks[index];\n\n    MOVTrack *src_track = &mov->tracks[src_index];\n\n    AVStream *src_st    = s->streams[src_index];\n\n    int ret = AVERROR(ENOMEM);\n\n    AVOutputFormat *rtp_format = av_guess_format(\"rtp\", NULL, NULL);\n\n\n\n    track->tag = MKTAG('r','t','p',' ');\n\n    track->src_track = src_index;\n\n\n\n    if (!rtp_format) {\n\n        ret = AVERROR(ENOENT);\n\n        goto fail;\n\n    }\n\n\n\n    track->enc = avcodec_alloc_context();\n\n    if (!track->enc)\n\n        goto fail;\n\n    track->enc->codec_type = AVMEDIA_TYPE_DATA;\n\n    track->enc->codec_tag  = track->tag;\n\n\n\n    track->rtp_ctx = avformat_alloc_context();\n\n    if (!track->rtp_ctx)\n\n        goto fail;\n\n    track->rtp_ctx->oformat = rtp_format;\n\n    if (!av_new_stream(track->rtp_ctx, 0))\n\n        goto fail;\n\n\n\n    /* Copy stream parameters */\n\n    track->rtp_ctx->streams[0]->sample_aspect_ratio =\n\n                        src_st->sample_aspect_ratio;\n\n\n\n    /* Remove the allocated codec context, link to the original one\n\n     * instead, to give the rtp muxer access to codec parameters. */\n\n    av_free(track->rtp_ctx->streams[0]->codec);\n\n    track->rtp_ctx->streams[0]->codec = src_st->codec;\n\n\n\n    if ((ret = url_open_dyn_packet_buf(&track->rtp_ctx->pb,\n\n                                       RTP_MAX_PACKET_SIZE)) < 0)\n\n        goto fail;\n\n    ret = av_write_header(track->rtp_ctx);\n\n    if (ret)\n\n        goto fail;\n\n\n\n    /* Copy the RTP AVStream timebase back to the hint AVStream */\n\n    track->timescale = track->rtp_ctx->streams[0]->time_base.den;\n\n\n\n    /* Mark the hinted track that packets written to it should be\n\n     * sent to this track for hinting. */\n\n    src_track->hint_track = index;\n\n    return 0;\n\nfail:\n\n    av_log(s, AV_LOG_WARNING,\n\n           \"Unable to initialize hinting of stream %d\\n\", src_index);\n\n    if (track->rtp_ctx && track->rtp_ctx->pb) {\n\n        uint8_t *buf;\n\n        url_close_dyn_buf(track->rtp_ctx->pb, &buf);\n\n        av_free(buf);\n\n    }\n\n    if (track->rtp_ctx && track->rtp_ctx->streams[0]) {\n\n        av_metadata_free(&track->rtp_ctx->streams[0]->metadata);\n\n\n        av_free(track->rtp_ctx->streams[0]);\n\n    }\n\n    if (track->rtp_ctx) {\n\n        av_metadata_free(&track->rtp_ctx->metadata);\n\n        av_free(track->rtp_ctx->priv_data);\n\n        av_freep(&track->rtp_ctx);\n\n    }\n\n    av_freep(&track->enc);\n\n    /* Set a default timescale, to avoid crashes in dump_format */\n\n    track->timescale = 90000;\n\n    return ret;\n\n}", "idx": 7719, "_split": "valid", "_hash": "5b7b9617bb36219b48a9393efa3a6c37"}
{"project": "FFmpeg", "commit_id": "8ebed703f153e979edb2156754c8bdac4d5d6266", "target": 1, "func": "static inline int l3_unscale(int value, int exponent)\n\n{\n\n    unsigned int m;\n\n    int e;\n\n\n\n    e  = table_4_3_exp  [4 * value + (exponent & 3)];\n\n    m  = table_4_3_value[4 * value + (exponent & 3)];\n\n    e -= exponent >> 2;\n\n#ifdef DEBUG\n\n    if(e < 1)\n\n        av_log(NULL, AV_LOG_WARNING, \"l3_unscale: e is %d\\n\", e);\n\n#endif\n\n    if (e > (SUINT)31)\n\n        return 0;\n\n    m = (m + (1 << (e - 1))) >> e;\n\n\n\n    return m;\n\n}\n", "idx": 7735, "_split": "valid", "_hash": "c89e5df2506aee6b3ec1b3e0ebf1880d"}
{"project": "FFmpeg", "commit_id": "47c5a3058eeae2043bd0dc2704b024cac8adcb3b", "target": 1, "func": "static int handle_p_frame_apng(AVCodecContext *avctx, PNGDecContext *s,\n\n                               AVFrame *p)\n\n{\n\n    size_t x, y;\n\n    uint8_t *buffer = av_malloc(s->image_linesize * s->height);\n\n\n\n    if (!buffer)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (s->blend_op == APNG_BLEND_OP_OVER &&\n\n        avctx->pix_fmt != AV_PIX_FMT_RGBA &&\n\n        avctx->pix_fmt != AV_PIX_FMT_GRAY8A &&\n\n        avctx->pix_fmt != AV_PIX_FMT_PAL8) {\n\n        avpriv_request_sample(avctx, \"Blending with pixel format %s\",\n\n                              av_get_pix_fmt_name(avctx->pix_fmt));\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    // Do the disposal operation specified by the last frame on the frame\n\n    if (s->last_dispose_op != APNG_DISPOSE_OP_PREVIOUS) {\n\n        ff_thread_await_progress(&s->last_picture, INT_MAX, 0);\n\n        memcpy(buffer, s->last_picture.f->data[0], s->image_linesize * s->height);\n\n\n\n        if (s->last_dispose_op == APNG_DISPOSE_OP_BACKGROUND)\n\n            for (y = s->last_y_offset; y < s->last_y_offset + s->last_h; ++y)\n\n                memset(buffer + s->image_linesize * y + s->bpp * s->last_x_offset, 0, s->bpp * s->last_w);\n\n\n\n        memcpy(s->previous_picture.f->data[0], buffer, s->image_linesize * s->height);\n\n        ff_thread_report_progress(&s->previous_picture, INT_MAX, 0);\n\n    } else {\n\n        ff_thread_await_progress(&s->previous_picture, INT_MAX, 0);\n\n        memcpy(buffer, s->previous_picture.f->data[0], s->image_linesize * s->height);\n\n    }\n\n\n\n    // Perform blending\n\n    if (s->blend_op == APNG_BLEND_OP_SOURCE) {\n\n        for (y = s->y_offset; y < s->y_offset + s->cur_h; ++y) {\n\n            size_t row_start = s->image_linesize * y + s->bpp * s->x_offset;\n\n            memcpy(buffer + row_start, p->data[0] + row_start, s->bpp * s->cur_w);\n\n        }\n\n    } else { // APNG_BLEND_OP_OVER\n\n        for (y = s->y_offset; y < s->y_offset + s->cur_h; ++y) {\n\n            uint8_t *foreground = p->data[0] + s->image_linesize * y + s->bpp * s->x_offset;\n\n            uint8_t *background = buffer + s->image_linesize * y + s->bpp * s->x_offset;\n\n            for (x = s->x_offset; x < s->x_offset + s->cur_w; ++x, foreground += s->bpp, background += s->bpp) {\n\n                size_t b;\n\n                uint8_t foreground_alpha, background_alpha, output_alpha;\n\n                uint8_t output[4];\n\n\n\n                // Since we might be blending alpha onto alpha, we use the following equations:\n\n                // output_alpha = foreground_alpha + (1 - foreground_alpha) * background_alpha\n\n                // output = (foreground_alpha * foreground + (1 - foreground_alpha) * background_alpha * background) / output_alpha\n\n\n\n                switch (avctx->pix_fmt) {\n\n                case AV_PIX_FMT_RGBA:\n\n                    foreground_alpha = foreground[3];\n\n                    background_alpha = background[3];\n\n                    break;\n\n\n\n                case AV_PIX_FMT_GRAY8A:\n\n                    foreground_alpha = foreground[1];\n\n                    background_alpha = background[1];\n\n                    break;\n\n\n\n                case AV_PIX_FMT_PAL8:\n\n                    foreground_alpha = s->palette[foreground[0]] >> 24;\n\n                    background_alpha = s->palette[background[0]] >> 24;\n\n                    break;\n\n                }\n\n\n\n                if (foreground_alpha == 0)\n\n                    continue;\n\n\n\n                if (foreground_alpha == 255) {\n\n                    memcpy(background, foreground, s->bpp);\n\n                    continue;\n\n                }\n\n\n\n                if (avctx->pix_fmt == AV_PIX_FMT_PAL8) {\n\n                    // TODO: Alpha blending with PAL8 will likely need the entire image converted over to RGBA first\n\n                    avpriv_request_sample(avctx, \"Alpha blending palette samples\");\n\n                    background[0] = foreground[0];\n\n                    continue;\n\n                }\n\n\n\n                output_alpha = foreground_alpha + FAST_DIV255((255 - foreground_alpha) * background_alpha);\n\n\n\n                for (b = 0; b < s->bpp - 1; ++b) {\n\n                    if (output_alpha == 0) {\n\n                        output[b] = 0;\n\n                    } else if (background_alpha == 255) {\n\n                        output[b] = FAST_DIV255(foreground_alpha * foreground[b] + (255 - foreground_alpha) * background[b]);\n\n                    } else {\n\n                        output[b] = (255 * foreground_alpha * foreground[b] + (255 - foreground_alpha) * background_alpha * background[b]) / (255 * output_alpha);\n\n                    }\n\n                }\n\n                output[b] = output_alpha;\n\n                memcpy(background, output, s->bpp);\n\n            }\n\n        }\n\n    }\n\n\n\n    // Copy blended buffer into the frame and free\n\n    memcpy(p->data[0], buffer, s->image_linesize * s->height);\n\n    av_free(buffer);\n\n\n\n    return 0;\n\n}\n", "idx": 7772, "_split": "valid", "_hash": "9a66bc06c74f627959a8c7d30ee29c2a"}
{"project": "FFmpeg", "commit_id": "d5fd610dabb4c7a6f63d4479e66c93c37339b6c0", "target": 1, "func": "static int kalman_smoothen(WMAVoiceContext *s, int pitch,\n\n                           const float *in, float *out, int size)\n\n{\n\n    int n;\n\n    float optimal_gain = 0, dot;\n\n    const float *ptr = &in[-FFMAX(s->min_pitch_val, pitch - 3)],\n\n                *end = &in[-FFMIN(s->max_pitch_val, pitch + 3)],\n\n                *best_hist_ptr;\n\n\n\n    /* find best fitting point in history */\n\n    do {\n\n        dot = ff_scalarproduct_float_c(in, ptr, size);\n\n        if (dot > optimal_gain) {\n\n            optimal_gain  = dot;\n\n            best_hist_ptr = ptr;\n\n        }\n\n    } while (--ptr >= end);\n\n\n\n    if (optimal_gain <= 0)\n\n        return -1;\n\n    dot = ff_scalarproduct_float_c(best_hist_ptr, best_hist_ptr, size);\n\n    if (dot <= 0) // would be 1.0\n\n        return -1;\n\n\n\n    if (optimal_gain <= dot) {\n\n        dot = dot / (dot + 0.6 * optimal_gain); // 0.625-1.000\n\n    } else\n\n        dot = 0.625;\n\n\n\n    /* actual smoothing */\n\n    for (n = 0; n < size; n++)\n\n        out[n] = best_hist_ptr[n] + dot * (in[n] - best_hist_ptr[n]);\n\n\n\n    return 0;\n\n}\n", "idx": 7894, "_split": "valid", "_hash": "31ee2597ecf1cbccb3dfdf130a930193"}
{"project": "FFmpeg", "commit_id": "b505f15b1530d72682b3314e84936f80fe6e43b2", "target": 1, "func": "static av_always_inline void thread_park_workers(SliceThreadContext *c, int thread_count)\n\n{\n\n    while (c->current_job != thread_count + c->job_count)\n\n        pthread_cond_wait(&c->last_job_cond, &c->current_job_lock);\n\n    pthread_mutex_unlock(&c->current_job_lock);\n\n}\n", "idx": 7905, "_split": "valid", "_hash": "f45323cee346d72d42e564ccbb1c5c51"}
{"project": "FFmpeg", "commit_id": "c0170d09738c74280af78c6f64914c52a9b6e075", "target": 0, "func": "int av_image_get_linesize(enum PixelFormat pix_fmt, int width, int plane)\n\n{\n\n    const AVPixFmtDescriptor *desc = &av_pix_fmt_descriptors[pix_fmt];\n\n    int max_step     [4];       /* max pixel step for each plane */\n\n    int max_step_comp[4];       /* the component for each plane which has the max pixel step */\n\n    int s, linesize;\n\n\n\n    if ((unsigned)pix_fmt >= PIX_FMT_NB || desc->flags & PIX_FMT_HWACCEL)\n\n        return AVERROR(EINVAL);\n\n\n\n    av_image_fill_max_pixsteps(max_step, max_step_comp, desc);\n\n    s = (max_step_comp[plane] == 1 || max_step_comp[plane] == 2) ? desc->log2_chroma_w : 0;\n\n    linesize = max_step[plane] * (((width + (1 << s) - 1)) >> s);\n\n    if (desc->flags & PIX_FMT_BITSTREAM)\n\n        linesize = (linesize + 7) >> 3;\n\n    return linesize;\n\n}\n", "idx": 7906, "_split": "valid", "_hash": "66fc33d02c45e9ce77bb39cde5cdfcc8"}
{"project": "FFmpeg", "commit_id": "695af8eed642ff0104834495652d1ee784a4c14d", "target": 0, "func": "static int field_end(H264Context *h, int in_setup)\n\n{\n\n    MpegEncContext *const s     = &h->s;\n\n    AVCodecContext *const avctx = s->avctx;\n\n    int err = 0;\n\n    s->mb_y = 0;\n\n\n\n    if (!in_setup && !s->droppable)\n\n        ff_thread_report_progress(&s->current_picture_ptr->f, INT_MAX,\n\n                                  s->picture_structure == PICT_BOTTOM_FIELD);\n\n\n\n    if (CONFIG_H264_VDPAU_DECODER &&\n\n        s->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n\n        ff_vdpau_h264_set_reference_frames(s);\n\n\n\n    if (in_setup || !(avctx->active_thread_type & FF_THREAD_FRAME)) {\n\n        if (!s->droppable) {\n\n            err = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n\n            h->prev_poc_msb = h->poc_msb;\n\n            h->prev_poc_lsb = h->poc_lsb;\n\n        }\n\n        h->prev_frame_num_offset = h->frame_num_offset;\n\n        h->prev_frame_num        = h->frame_num;\n\n        h->outputed_poc          = h->next_outputed_poc;\n\n    }\n\n\n\n    if (avctx->hwaccel) {\n\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"hardware accelerator failed to decode picture\\n\");\n\n    }\n\n\n\n    if (CONFIG_H264_VDPAU_DECODER &&\n\n        s->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n\n        ff_vdpau_h264_picture_complete(s);\n\n\n\n    /*\n\n     * FIXME: Error handling code does not seem to support interlaced\n\n     * when slices span multiple rows\n\n     * The ff_er_add_slice calls don't work right for bottom\n\n     * fields; they cause massive erroneous error concealing\n\n     * Error marking covers both fields (top and bottom).\n\n     * This causes a mismatched s->error_count\n\n     * and a bad error table. Further, the error count goes to\n\n     * INT_MAX when called for bottom field, because mb_y is\n\n     * past end by one (callers fault) and resync_mb_y != 0\n\n     * causes problems for the first MB line, too.\n\n     */\n\n    if (!FIELD_PICTURE && h->current_slice)\n\n        ff_er_frame_end(s);\n\n\n\n    ff_MPV_frame_end(s);\n\n\n\n    h->current_slice = 0;\n\n\n\n    return err;\n\n}\n", "idx": 7907, "_split": "valid", "_hash": "abcf63821af5f6b9e5a1cd69801c9324"}
{"project": "FFmpeg", "commit_id": "676da248cad49debc40720baa13214f0b94dcc71", "target": 0, "func": "static int vmd_decode(VmdVideoContext *s, AVFrame *frame)\n\n{\n\n    int i;\n\n    unsigned int *palette32;\n\n    unsigned char r, g, b;\n\n\n\n    GetByteContext gb;\n\n\n\n    unsigned char meth;\n\n    unsigned char *dp;   /* pointer to current frame */\n\n    unsigned char *pp;   /* pointer to previous frame */\n\n    unsigned char len;\n\n    int ofs;\n\n\n\n    int frame_x, frame_y;\n\n    int frame_width, frame_height;\n\n\n\n    frame_x = AV_RL16(&s->buf[6]);\n\n    frame_y = AV_RL16(&s->buf[8]);\n\n    frame_width = AV_RL16(&s->buf[10]) - frame_x + 1;\n\n    frame_height = AV_RL16(&s->buf[12]) - frame_y + 1;\n\n    if (frame_x < 0 || frame_width < 0 ||\n\n        frame_x >= s->avctx->width ||\n\n        frame_width > s->avctx->width ||\n\n        frame_x + frame_width > s->avctx->width) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Invalid horizontal range %d-%d\\n\",\n\n               frame_x, frame_width);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (frame_y < 0 || frame_height < 0 ||\n\n        frame_y >= s->avctx->height ||\n\n        frame_height > s->avctx->height ||\n\n        frame_y + frame_height > s->avctx->height) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Invalid vertical range %d-%d\\n\",\n\n               frame_x, frame_width);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((frame_width == s->avctx->width && frame_height == s->avctx->height) &&\n\n        (frame_x || frame_y)) {\n\n\n\n        s->x_off = frame_x;\n\n        s->y_off = frame_y;\n\n    }\n\n    frame_x -= s->x_off;\n\n    frame_y -= s->y_off;\n\n\n\n    /* if only a certain region will be updated, copy the entire previous\n\n     * frame before the decode */\n\n    if (s->prev_frame.data[0] &&\n\n        (frame_x || frame_y || (frame_width != s->avctx->width) ||\n\n        (frame_height != s->avctx->height))) {\n\n\n\n        memcpy(frame->data[0], s->prev_frame.data[0],\n\n            s->avctx->height * frame->linesize[0]);\n\n    }\n\n\n\n    /* check if there is a new palette */\n\n    bytestream2_init(&gb, s->buf + 16, s->size - 16);\n\n    if (s->buf[15] & 0x02) {\n\n        bytestream2_skip(&gb, 2);\n\n        palette32 = (unsigned int *)s->palette;\n\n        if (bytestream2_get_bytes_left(&gb) >= PALETTE_COUNT * 3) {\n\n            for (i = 0; i < PALETTE_COUNT; i++) {\n\n                r = bytestream2_get_byteu(&gb) * 4;\n\n                g = bytestream2_get_byteu(&gb) * 4;\n\n                b = bytestream2_get_byteu(&gb) * 4;\n\n                palette32[i] = (r << 16) | (g << 8) | (b);\n\n            }\n\n        } else {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Incomplete palette\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->size -= PALETTE_COUNT * 3 + 2;\n\n    }\n\n    if (s->size > 0) {\n\n        /* originally UnpackFrame in VAG's code */\n\n        bytestream2_init(&gb, gb.buffer, s->buf + s->size - gb.buffer);\n\n        if (bytestream2_get_bytes_left(&gb) < 1)\n\n            return AVERROR_INVALIDDATA;\n\n        meth = bytestream2_get_byteu(&gb);\n\n        if (meth & 0x80) {\n\n            lz_unpack(gb.buffer, bytestream2_get_bytes_left(&gb),\n\n                      s->unpack_buffer, s->unpack_buffer_size);\n\n            meth &= 0x7F;\n\n            bytestream2_init(&gb, s->unpack_buffer, s->unpack_buffer_size);\n\n        }\n\n\n\n        dp = &frame->data[0][frame_y * frame->linesize[0] + frame_x];\n\n        pp = &s->prev_frame.data[0][frame_y * s->prev_frame.linesize[0] + frame_x];\n\n        switch (meth) {\n\n        case 1:\n\n            for (i = 0; i < frame_height; i++) {\n\n                ofs = 0;\n\n                do {\n\n                    len = bytestream2_get_byte(&gb);\n\n                    if (len & 0x80) {\n\n                        len = (len & 0x7F) + 1;\n\n                        if (ofs + len > frame_width || bytestream2_get_bytes_left(&gb) < len)\n\n                            return AVERROR_INVALIDDATA;\n\n                        bytestream2_get_buffer(&gb, &dp[ofs], len);\n\n                        ofs += len;\n\n                    } else {\n\n                        /* interframe pixel copy */\n\n                        if (ofs + len + 1 > frame_width || !s->prev_frame.data[0])\n\n                            return AVERROR_INVALIDDATA;\n\n                        memcpy(&dp[ofs], &pp[ofs], len + 1);\n\n                        ofs += len + 1;\n\n                    }\n\n                } while (ofs < frame_width);\n\n                if (ofs > frame_width) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"VMD video: offset > width (%d > %d)\\n\",\n\n                        ofs, frame_width);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                dp += frame->linesize[0];\n\n                pp += s->prev_frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case 2:\n\n            for (i = 0; i < frame_height; i++) {\n\n                bytestream2_get_buffer(&gb, dp, frame_width);\n\n                dp += frame->linesize[0];\n\n                pp += s->prev_frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case 3:\n\n            for (i = 0; i < frame_height; i++) {\n\n                ofs = 0;\n\n                do {\n\n                    len = bytestream2_get_byte(&gb);\n\n                    if (len & 0x80) {\n\n                        len = (len & 0x7F) + 1;\n\n                        if (bytestream2_get_byte(&gb) == 0xFF)\n\n                            len = rle_unpack(gb.buffer, &dp[ofs],\n\n                                             len, bytestream2_get_bytes_left(&gb),\n\n                                             frame_width - ofs);\n\n                        else\n\n                            bytestream2_get_buffer(&gb, &dp[ofs], len);\n\n                        bytestream2_skip(&gb, len);\n\n                    } else {\n\n                        /* interframe pixel copy */\n\n                        if (ofs + len + 1 > frame_width || !s->prev_frame.data[0])\n\n                            return AVERROR_INVALIDDATA;\n\n                        memcpy(&dp[ofs], &pp[ofs], len + 1);\n\n                        ofs += len + 1;\n\n                    }\n\n                } while (ofs < frame_width);\n\n                if (ofs > frame_width) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"VMD video: offset > width (%d > %d)\\n\",\n\n                        ofs, frame_width);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                dp += frame->linesize[0];\n\n                pp += s->prev_frame.linesize[0];\n\n            }\n\n            break;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 7908, "_split": "valid", "_hash": "7b26f480243156b81d729f9815d18d71"}
{"project": "FFmpeg", "commit_id": "702200358197a0ea5ea82d1d6540c785bb04fae4", "target": 0, "func": "static void joint_decode(COOKContext *q, float* mlt_buffer1,\n\n                         float* mlt_buffer2) {\n\n    int i,j;\n\n    int decouple_tab[SUBBAND_SIZE];\n\n    float decode_buffer[2048];  //Only 1060 might be needed.\n\n    int idx, cpl_tmp,tmp_idx;\n\n    float f1,f2;\n\n    float* cplscale;\n\n\n\n    memset(decouple_tab, 0, sizeof(decouple_tab));\n\n    memset(decode_buffer, 0, sizeof(decode_buffer));\n\n\n\n    /* Make sure the buffers are zeroed out. */\n\n    memset(mlt_buffer1,0, 1024*sizeof(float));\n\n    memset(mlt_buffer2,0, 1024*sizeof(float));\n\n    decouple_info(q, decouple_tab);\n\n    mono_decode(q, decode_buffer);\n\n\n\n    /* The two channels are stored interleaved in decode_buffer. */\n\n    for (i=0 ; i<q->js_subband_start ; i++) {\n\n        for (j=0 ; j<SUBBAND_SIZE ; j++) {\n\n            mlt_buffer1[i*20+j] = decode_buffer[i*40+j];\n\n            mlt_buffer2[i*20+j] = decode_buffer[i*40+20+j];\n\n        }\n\n    }\n\n\n\n    /* When we reach js_subband_start (the higher frequencies)\n\n       the coefficients are stored in a coupling scheme. */\n\n    idx = (1 << q->js_vlc_bits) - 1;\n\n    if (q->js_subband_start < q->subbands) {\n\n        for (i=0 ; i<q->subbands ; i++) {\n\n            cpl_tmp = cplband[i + q->js_subband_start];\n\n            idx -=decouple_tab[cpl_tmp];\n\n            cplscale = (float*)cplscales[q->js_vlc_bits-2];  //choose decoupler table\n\n            f1 = cplscale[decouple_tab[cpl_tmp]];\n\n            f2 = cplscale[idx-1];\n\n            for (j=0 ; j<SUBBAND_SIZE ; j++) {\n\n                tmp_idx = ((2*q->js_subband_start + i)*20)+j;\n\n                mlt_buffer1[20*(i+q->js_subband_start) + j] = f1 * decode_buffer[tmp_idx];\n\n                mlt_buffer2[20*(i+q->js_subband_start) + j] = f2 * decode_buffer[tmp_idx];\n\n            }\n\n            idx = (1 << q->js_vlc_bits) - 1;\n\n        }\n\n    }\n\n}\n", "idx": 7926, "_split": "valid", "_hash": "ec038102960569390ca21fbdc9f03c2d"}
{"project": "FFmpeg", "commit_id": "705f5e5e155f6f280a360af220fc5b30cfcee702", "target": 0, "func": "av_cold void ff_synth_filter_init(SynthFilterContext *c)\n\n{\n\n    c->synth_filter_float = synth_filter_float;\n\n\n\n    if (ARCH_ARM) ff_synth_filter_init_arm(c);\n\n    if (ARCH_X86) ff_synth_filter_init_x86(c);\n\n}\n", "idx": 8030, "_split": "valid", "_hash": "1a4815570dc2cf2d913e6603e3486271"}
{"project": "FFmpeg", "commit_id": "90527811d7db0da5d770235261c4b718b0869a99", "target": 0, "func": "int main(int argc, char** argv)\n\n{\n\n    FILE *f= fopen(argv[1], \"rb+\");\n\n    int count= atoi(argv[2]);\n\n    int maxburst= atoi(argv[3]);\n\n    int length;\n\n\n\n    srand (time (0));\n\n\n\n    fseek(f, 0, SEEK_END);\n\n    length= ftell(f);\n\n    fseek(f, 0, SEEK_SET);\n\n\n\n    while(count--){\n\n        int burst= 1 + random() * (uint64_t) (abs(maxburst)-1) / RAND_MAX;\n\n        int pos= random() * (uint64_t) length / RAND_MAX;\n\n        fseek(f, pos, SEEK_SET);\n\n\n\n        if(maxburst<0) burst= -maxburst;\n\n\n\n        if(pos + burst > length)\n\n            continue;\n\n\n\n        while(burst--){\n\n            int val= random() * 256ULL / RAND_MAX;\n\n\n\n            if(maxburst<0) val=0;\n\n\n\n            fwrite(&val, 1, 1, f);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 8065, "_split": "valid", "_hash": "e8460c8ba2221e9832e5655dc5c3f349"}
{"project": "FFmpeg", "commit_id": "6f600ab35424823fb682b5669241edcc66590a8d", "target": 0, "func": "static av_cold int oggvorbis_encode_init(AVCodecContext *avccontext)\n\n{\n\n    OggVorbisContext *context = avccontext->priv_data;\n\n    ogg_packet header, header_comm, header_code;\n\n    uint8_t *p;\n\n    unsigned int offset;\n\n\n\n    vorbis_info_init(&context->vi);\n\n    if (oggvorbis_init_encoder(&context->vi, avccontext) < 0) {\n\n        av_log(avccontext, AV_LOG_ERROR, \"oggvorbis_encode_init: init_encoder failed\\n\");\n\n        return -1;\n\n    }\n\n    vorbis_analysis_init(&context->vd, &context->vi);\n\n    vorbis_block_init(&context->vd, &context->vb);\n\n\n\n    vorbis_comment_init(&context->vc);\n\n    vorbis_comment_add_tag(&context->vc, \"encoder\", LIBAVCODEC_IDENT);\n\n\n\n    vorbis_analysis_headerout(&context->vd, &context->vc, &header,\n\n                              &header_comm, &header_code);\n\n\n\n    avccontext->extradata_size =\n\n        1 + xiph_len(header.bytes) + xiph_len(header_comm.bytes) +\n\n        header_code.bytes;\n\n    p = avccontext->extradata =\n\n            av_malloc(avccontext->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    p[0]    = 2;\n\n    offset  = 1;\n\n    offset += av_xiphlacing(&p[offset], header.bytes);\n\n    offset += av_xiphlacing(&p[offset], header_comm.bytes);\n\n    memcpy(&p[offset], header.packet, header.bytes);\n\n    offset += header.bytes;\n\n    memcpy(&p[offset], header_comm.packet, header_comm.bytes);\n\n    offset += header_comm.bytes;\n\n    memcpy(&p[offset], header_code.packet, header_code.bytes);\n\n    offset += header_code.bytes;\n\n    assert(offset == avccontext->extradata_size);\n\n\n\n#if 0\n\n    vorbis_block_clear(&context->vb);\n\n    vorbis_dsp_clear(&context->vd);\n\n    vorbis_info_clear(&context->vi);\n\n#endif\n\n    vorbis_comment_clear(&context->vc);\n\n\n\n    avccontext->frame_size = OGGVORBIS_FRAME_SIZE;\n\n\n\n    avccontext->coded_frame = avcodec_alloc_frame();\n\n\n\n    return 0;\n\n}\n", "idx": 8093, "_split": "valid", "_hash": "f641db914424391322a80bae71f842c6"}
{"project": "FFmpeg", "commit_id": "1560c3295db00119e1bef51c2eca1957edd972f4", "target": 0, "func": "static int iff_read_header(AVFormatContext *s)\n\n{\n\n    IffDemuxContext *iff = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    uint8_t *buf;\n\n    uint32_t chunk_id, data_size;\n\n    uint32_t screenmode = 0, num, den;\n\n    unsigned transparency = 0;\n\n    unsigned masking = 0; // no mask\n\n    uint8_t fmt[16];\n\n    int fmt_size;\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codec->channels = 1;\n\n    st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n    avio_skip(pb, 8);\n\n    // codec_tag used by ByteRun1 decoder to distinguish progressive (PBM) and interlaced (ILBM) content\n\n    st->codec->codec_tag = avio_rl32(pb);\n\n\n\n    while(!url_feof(pb)) {\n\n        uint64_t orig_pos;\n\n        int res;\n\n        const char *metadata_tag = NULL;\n\n        chunk_id = avio_rl32(pb);\n\n        data_size = avio_rb32(pb);\n\n        orig_pos = avio_tell(pb);\n\n\n\n        switch(chunk_id) {\n\n        case ID_VHDR:\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n            if (data_size < 14)\n\n                return AVERROR_INVALIDDATA;\n\n            avio_skip(pb, 12);\n\n            st->codec->sample_rate = avio_rb16(pb);\n\n            if (data_size >= 16) {\n\n                avio_skip(pb, 1);\n\n                iff->svx8_compression = avio_r8(pb);\n\n            }\n\n            break;\n\n\n\n        case ID_MHDR:\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n            iff->maud_bits = -1;\n\n            iff->maud_compression = -1;\n\n            if (data_size < 32)\n\n                return AVERROR_INVALIDDATA;\n\n            avio_skip(pb, 4);\n\n            iff->maud_bits = avio_rb16(pb);\n\n            avio_skip(pb, 2);\n\n            num = avio_rb32(pb);\n\n            den = avio_rb16(pb);\n\n            if (!den)\n\n                return AVERROR_INVALIDDATA;\n\n            avio_skip(pb, 2);\n\n            st->codec->sample_rate = num / den;\n\n            st->codec->channels = avio_rb16(pb);\n\n            iff->maud_compression = avio_rb16(pb);\n\n            if (st->codec->channels == 1)\n\n                st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n            else if (st->codec->channels == 2)\n\n                st->codec->channel_layout = AV_CH_LAYOUT_STEREO;\n\n            break;\n\n\n\n        case ID_ABIT:\n\n        case ID_BODY:\n\n        case ID_DBOD:\n\n        case ID_MDAT:\n\n            iff->body_pos = avio_tell(pb);\n\n            iff->body_size = data_size;\n\n            break;\n\n\n\n        case ID_CHAN:\n\n            if (data_size < 4)\n\n                return AVERROR_INVALIDDATA;\n\n            if (avio_rb32(pb) < 6) {\n\n                st->codec->channels       = 1;\n\n                st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n            } else {\n\n                st->codec->channels       = 2;\n\n                st->codec->channel_layout = AV_CH_LAYOUT_STEREO;\n\n            }\n\n            break;\n\n\n\n        case ID_CAMG:\n\n            if (data_size < 4)\n\n                return AVERROR_INVALIDDATA;\n\n            screenmode                = avio_rb32(pb);\n\n            break;\n\n\n\n        case ID_CMAP:\n\n            st->codec->extradata_size = data_size + IFF_EXTRA_VIDEO_SIZE;\n\n            st->codec->extradata      = av_malloc(data_size + IFF_EXTRA_VIDEO_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!st->codec->extradata)\n\n                return AVERROR(ENOMEM);\n\n            if (avio_read(pb, st->codec->extradata + IFF_EXTRA_VIDEO_SIZE, data_size) < 0)\n\n                return AVERROR(EIO);\n\n            break;\n\n\n\n        case ID_BMHD:\n\n            iff->bitmap_compression = -1;\n\n            st->codec->codec_type            = AVMEDIA_TYPE_VIDEO;\n\n            if (data_size <= 8)\n\n                return AVERROR_INVALIDDATA;\n\n            st->codec->width                 = avio_rb16(pb);\n\n            st->codec->height                = avio_rb16(pb);\n\n            avio_skip(pb, 4); // x, y offset\n\n            st->codec->bits_per_coded_sample = avio_r8(pb);\n\n            if (data_size >= 10)\n\n                masking                      = avio_r8(pb);\n\n            if (data_size >= 11)\n\n                iff->bitmap_compression      = avio_r8(pb);\n\n            if (data_size >= 14) {\n\n                avio_skip(pb, 1); // padding\n\n                transparency                 = avio_rb16(pb);\n\n            }\n\n            if (data_size >= 16) {\n\n                st->sample_aspect_ratio.num  = avio_r8(pb);\n\n                st->sample_aspect_ratio.den  = avio_r8(pb);\n\n            }\n\n            break;\n\n\n\n        case ID_DPEL:\n\n            if (data_size < 4 || (data_size & 3))\n\n                return AVERROR_INVALIDDATA;\n\n            if ((fmt_size = avio_read(pb, fmt, sizeof(fmt))) < 0)\n\n                return fmt_size;\n\n            if (fmt_size == sizeof(deep_rgb24) && !memcmp(fmt, deep_rgb24, sizeof(deep_rgb24)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_RGB24;\n\n            else if (fmt_size == sizeof(deep_rgba) && !memcmp(fmt, deep_rgba, sizeof(deep_rgba)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_RGBA;\n\n            else if (fmt_size == sizeof(deep_bgra) && !memcmp(fmt, deep_bgra, sizeof(deep_bgra)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_BGRA;\n\n            else if (fmt_size == sizeof(deep_argb) && !memcmp(fmt, deep_argb, sizeof(deep_argb)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_ARGB;\n\n            else if (fmt_size == sizeof(deep_abgr) && !memcmp(fmt, deep_abgr, sizeof(deep_abgr)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_ABGR;\n\n            else {\n\n                av_log_ask_for_sample(s, \"unsupported color format\\n\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n            break;\n\n\n\n        case ID_DGBL:\n\n            st->codec->codec_type            = AVMEDIA_TYPE_VIDEO;\n\n            if (data_size < 8)\n\n                return AVERROR_INVALIDDATA;\n\n            st->codec->width                 = avio_rb16(pb);\n\n            st->codec->height                = avio_rb16(pb);\n\n            iff->bitmap_compression          = avio_rb16(pb);\n\n            st->sample_aspect_ratio.num      = avio_r8(pb);\n\n            st->sample_aspect_ratio.den      = avio_r8(pb);\n\n            st->codec->bits_per_coded_sample = 24;\n\n            break;\n\n\n\n        case ID_DLOC:\n\n            if (data_size < 4)\n\n                return AVERROR_INVALIDDATA;\n\n            st->codec->width  = avio_rb16(pb);\n\n            st->codec->height = avio_rb16(pb);\n\n            break;\n\n\n\n        case ID_ANNO:\n\n        case ID_TEXT:      metadata_tag = \"comment\";   break;\n\n        case ID_AUTH:      metadata_tag = \"artist\";    break;\n\n        case ID_COPYRIGHT: metadata_tag = \"copyright\"; break;\n\n        case ID_NAME:      metadata_tag = \"title\";     break;\n\n        }\n\n\n\n        if (metadata_tag) {\n\n            if ((res = get_metadata(s, metadata_tag, data_size)) < 0) {\n\n                av_log(s, AV_LOG_ERROR, \"cannot allocate metadata tag %s!\\n\", metadata_tag);\n\n                return res;\n\n            }\n\n        }\n\n        avio_skip(pb, data_size - (avio_tell(pb) - orig_pos) + (data_size & 1));\n\n    }\n\n\n\n    avio_seek(pb, iff->body_pos, SEEK_SET);\n\n\n\n    switch(st->codec->codec_type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        avpriv_set_pts_info(st, 32, 1, st->codec->sample_rate);\n\n\n\n        if (st->codec->codec_tag == ID_16SV)\n\n            st->codec->codec_id = AV_CODEC_ID_PCM_S16BE_PLANAR;\n\n        else if (st->codec->codec_tag == ID_MAUD) {\n\n            if (iff->maud_bits == 8 && !iff->maud_compression) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_U8;\n\n            } else if (iff->maud_bits == 16 && !iff->maud_compression) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_S16BE;\n\n            } else if (iff->maud_bits ==  8 && iff->maud_compression == 2) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_ALAW;\n\n            } else if (iff->maud_bits ==  8 && iff->maud_compression == 3) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_MULAW;\n\n            } else {\n\n                av_log_ask_for_sample(s, \"unsupported compression %d and bit depth %d\\n\", iff->maud_compression, iff->maud_bits);\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n            st->codec->bits_per_coded_sample =\n\n                av_get_bits_per_sample(st->codec->codec_id);\n\n\n\n            st->codec->block_align =\n\n                st->codec->bits_per_coded_sample * st->codec->channels / 8;\n\n        } else {\n\n        switch (iff->svx8_compression) {\n\n        case COMP_NONE:\n\n            st->codec->codec_id = AV_CODEC_ID_PCM_S8_PLANAR;\n\n            break;\n\n        case COMP_FIB:\n\n            st->codec->codec_id = AV_CODEC_ID_8SVX_FIB;\n\n            break;\n\n        case COMP_EXP:\n\n            st->codec->codec_id = AV_CODEC_ID_8SVX_EXP;\n\n            break;\n\n        default:\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"Unknown SVX8 compression method '%d'\\n\", iff->svx8_compression);\n\n            return -1;\n\n        }\n\n        }\n\n\n\n        st->codec->bits_per_coded_sample = av_get_bits_per_sample(st->codec->codec_id);\n\n        st->codec->bit_rate = st->codec->channels * st->codec->sample_rate * st->codec->bits_per_coded_sample;\n\n        st->codec->block_align = st->codec->channels * st->codec->bits_per_coded_sample;\n\n        break;\n\n\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        iff->bpp          = st->codec->bits_per_coded_sample;\n\n        if ((screenmode & 0x800 /* Hold And Modify */) && iff->bpp <= 8) {\n\n            iff->ham      = iff->bpp > 6 ? 6 : 4;\n\n            st->codec->bits_per_coded_sample = 24;\n\n        }\n\n        iff->flags        = (screenmode & 0x80 /* Extra HalfBrite */) && iff->bpp <= 8;\n\n        iff->masking      = masking;\n\n        iff->transparency = transparency;\n\n\n\n        if (!st->codec->extradata) {\n\n            st->codec->extradata_size = IFF_EXTRA_VIDEO_SIZE;\n\n            st->codec->extradata      = av_malloc(IFF_EXTRA_VIDEO_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!st->codec->extradata)\n\n                return AVERROR(ENOMEM);\n\n        }\n\n        buf = st->codec->extradata;\n\n        bytestream_put_be16(&buf, IFF_EXTRA_VIDEO_SIZE);\n\n        bytestream_put_byte(&buf, iff->bitmap_compression);\n\n        bytestream_put_byte(&buf, iff->bpp);\n\n        bytestream_put_byte(&buf, iff->ham);\n\n        bytestream_put_byte(&buf, iff->flags);\n\n        bytestream_put_be16(&buf, iff->transparency);\n\n        bytestream_put_byte(&buf, iff->masking);\n\n        st->codec->codec_id = AV_CODEC_ID_IFF_ILBM;\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 8095, "_split": "valid", "_hash": "853393cdef69c57367614cdfb6fe491c"}
{"project": "FFmpeg", "commit_id": "2c823b3ccca3a9d42d02713fc5ea2538a9b9a99e", "target": 1, "func": "static int unpack_modes(Vp3DecodeContext *s, GetBitContext *gb)\n\n{\n\n    int i, j, k;\n\n    int scheme;\n\n    int current_macroblock;\n\n    int current_fragment;\n\n    int coding_mode;\n\n    int custom_mode_alphabet[CODING_MODE_COUNT];\n\n\n\n    if (s->keyframe) {\n\n        for (i = 0; i < s->fragment_count; i++)\n\n            s->all_fragments[i].coding_method = MODE_INTRA;\n\n\n\n    } else {\n\n\n\n        /* fetch the mode coding scheme for this frame */\n\n        scheme = get_bits(gb, 3);\n\n\n\n        /* is it a custom coding scheme? */\n\n        if (scheme == 0) {\n\n\n\n\n                custom_mode_alphabet[get_bits(gb, 3)] = i;\n\n        }\n\n\n\n        /* iterate through all of the macroblocks that contain 1 or more\n\n         * coded fragments */\n\n        for (i = 0; i < s->u_superblock_start; i++) {\n\n\n\n            for (j = 0; j < 4; j++) {\n\n                current_macroblock = s->superblock_macroblocks[i * 4 + j];\n\n                if ((current_macroblock == -1) ||\n\n                    (s->macroblock_coding[current_macroblock] == MODE_COPY))\n\n                    continue;\n\n                if (current_macroblock >= s->macroblock_count) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"  vp3:unpack_modes(): bad macroblock number (%d >= %d)\\n\",\n\n                        current_macroblock, s->macroblock_count);\n\n                    return 1;\n\n                }\n\n\n\n                /* mode 7 means get 3 bits for each coding mode */\n\n                if (scheme == 7)\n\n                    coding_mode = get_bits(gb, 3);\n\n                else if(scheme == 0)\n\n                    coding_mode = custom_mode_alphabet\n\n                        [get_vlc2(gb, s->mode_code_vlc.table, 3, 3)];\n\n                else\n\n                    coding_mode = ModeAlphabet[scheme-1]\n\n                        [get_vlc2(gb, s->mode_code_vlc.table, 3, 3)];\n\n\n\n                s->macroblock_coding[current_macroblock] = coding_mode;\n\n                for (k = 0; k < 6; k++) {\n\n                    current_fragment =\n\n                        s->macroblock_fragments[current_macroblock * 6 + k];\n\n                    if (current_fragment == -1)\n\n                        continue;\n\n                    if (current_fragment >= s->fragment_count) {\n\n                        av_log(s->avctx, AV_LOG_ERROR, \"  vp3:unpack_modes(): bad fragment number (%d >= %d)\\n\",\n\n                            current_fragment, s->fragment_count);\n\n                        return 1;\n\n                    }\n\n                    if (s->all_fragments[current_fragment].coding_method !=\n\n                        MODE_COPY)\n\n                        s->all_fragments[current_fragment].coding_method =\n\n                            coding_mode;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 8129, "_split": "valid", "_hash": "c95c7e64f170a931f8be96d1205d83b3"}
{"project": "FFmpeg", "commit_id": "e60dbe421c7e9cd896d33e35a6a1b0cef953918e", "target": 0, "func": "static int vpx_decode(AVCodecContext *avctx,\n\n                      void *data, int *got_frame, AVPacket *avpkt)\n\n{\n\n    VPxContext *ctx = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    const void *iter = NULL;\n\n    const void *iter_alpha = NULL;\n\n    struct vpx_image *img, *img_alpha;\n\n    int ret;\n\n    uint8_t *side_data = NULL;\n\n    int side_data_size = 0;\n\n\n\n    ret = decode_frame(avctx, &ctx->decoder, avpkt->data, avpkt->size);\n\n    if (ret)\n\n        return ret;\n\n\n\n    side_data = av_packet_get_side_data(avpkt,\n\n                                        AV_PKT_DATA_MATROSKA_BLOCKADDITIONAL,\n\n                                        &side_data_size);\n\n    if (side_data_size > 1) {\n\n        const uint64_t additional_id = AV_RB64(side_data);\n\n        side_data += 8;\n\n        side_data_size -= 8;\n\n        if (additional_id == 1) {  // 1 stands for alpha channel data.\n\n            if (!ctx->has_alpha_channel) {\n\n                ctx->has_alpha_channel = 1;\n\n                ret = vpx_init(avctx,\n\n#if CONFIG_LIBVPX_VP8_DECODER && CONFIG_LIBVPX_VP9_DECODER\n\n                               (avctx->codec_id == AV_CODEC_ID_VP8) ?\n\n                               &vpx_codec_vp8_dx_algo : &vpx_codec_vp9_dx_algo,\n\n#elif CONFIG_LIBVPX_VP8_DECODER\n\n                               &vpx_codec_vp8_dx_algo,\n\n#else\n\n                               &vpx_codec_vp9_dx_algo,\n\n#endif\n\n                               1);\n\n                if (ret)\n\n                    return ret;\n\n            }\n\n            ret = decode_frame(avctx, &ctx->decoder_alpha, side_data,\n\n                               side_data_size);\n\n            if (ret)\n\n                return ret;\n\n        }\n\n    }\n\n\n\n    if ((img = vpx_codec_get_frame(&ctx->decoder, &iter)) &&\n\n        (!ctx->has_alpha_channel ||\n\n         (img_alpha = vpx_codec_get_frame(&ctx->decoder_alpha, &iter_alpha)))) {\n\n        uint8_t *planes[4];\n\n        int linesizes[4];\n\n\n\n        if (img->d_w > img->w || img->d_h > img->h) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Display dimensions %dx%d exceed storage %dx%d\\n\",\n\n                   img->d_w, img->d_h, img->w, img->h);\n\n            return AVERROR_EXTERNAL;\n\n        }\n\n\n\n        if ((ret = set_pix_fmt(avctx, img, ctx->has_alpha_channel)) < 0) {\n\n#ifdef VPX_IMG_FMT_HIGHBITDEPTH\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported output colorspace (%d) / bit_depth (%d)\\n\",\n\n                   img->fmt, img->bit_depth);\n\n#else\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported output colorspace (%d) / bit_depth (%d)\\n\",\n\n                   img->fmt, 8);\n\n#endif\n\n            return ret;\n\n        }\n\n\n\n        if ((int) img->d_w != avctx->width || (int) img->d_h != avctx->height) {\n\n            av_log(avctx, AV_LOG_INFO, \"dimension change! %dx%d -> %dx%d\\n\",\n\n                   avctx->width, avctx->height, img->d_w, img->d_h);\n\n            ret = ff_set_dimensions(avctx, img->d_w, img->d_h);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n        if ((ret = ff_get_buffer(avctx, picture, 0)) < 0)\n\n            return ret;\n\n\n\n        planes[0] = img->planes[VPX_PLANE_Y];\n\n        planes[1] = img->planes[VPX_PLANE_U];\n\n        planes[2] = img->planes[VPX_PLANE_V];\n\n        planes[3] =\n\n            ctx->has_alpha_channel ? img_alpha->planes[VPX_PLANE_Y] : NULL;\n\n        linesizes[0] = img->stride[VPX_PLANE_Y];\n\n        linesizes[1] = img->stride[VPX_PLANE_U];\n\n        linesizes[2] = img->stride[VPX_PLANE_V];\n\n        linesizes[3] =\n\n            ctx->has_alpha_channel ? img_alpha->stride[VPX_PLANE_Y] : 0;\n\n        av_image_copy(picture->data, picture->linesize, (const uint8_t**)planes,\n\n                      linesizes, avctx->pix_fmt, img->d_w, img->d_h);\n\n        *got_frame           = 1;\n\n    }\n\n    return avpkt->size;\n\n}\n", "idx": 8160, "_split": "valid", "_hash": "05294eb014cc6d22c649830c11c3959f"}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0xB(IpvideoContext *s)\n\n{\n\n    int y;\n\n\n\n    /* 64-color encoding (each pixel in block is a different color) */\n\n    CHECK_STREAM_PTR(64);\n\n\n\n    for (y = 0; y < 8; y++) {\n\n        memcpy(s->pixel_ptr, s->stream_ptr, 8);\n\n        s->stream_ptr += 8;\n\n        s->pixel_ptr  += s->stride;\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 8162, "_split": "valid", "_hash": "8a5b464db8a8a6919679973b959ed511"}
{"project": "FFmpeg", "commit_id": "4c5fa628da099dbb598c93bc4555b8733d2c3035", "target": 0, "func": "static int mov_read_tkhd(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    int i;\n\n    int width;\n\n    int height;\n\n    int64_t disp_transform[2];\n\n    int display_matrix[3][3];\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    int version;\n\n    int flags;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n    sc = st->priv_data;\n\n\n\n    version = avio_r8(pb);\n\n    flags = avio_rb24(pb);\n\n    st->disposition |= (flags & MOV_TKHD_FLAG_ENABLED) ? AV_DISPOSITION_DEFAULT : 0;\n\n\n\n    if (version == 1) {\n\n        avio_rb64(pb);\n\n        avio_rb64(pb);\n\n    } else {\n\n        avio_rb32(pb); /* creation time */\n\n        avio_rb32(pb); /* modification time */\n\n    }\n\n    st->id = (int)avio_rb32(pb); /* track id (NOT 0 !)*/\n\n    avio_rb32(pb); /* reserved */\n\n\n\n    /* highlevel (considering edits) duration in movie timebase */\n\n    (version == 1) ? avio_rb64(pb) : avio_rb32(pb);\n\n    avio_rb32(pb); /* reserved */\n\n    avio_rb32(pb); /* reserved */\n\n\n\n    avio_rb16(pb); /* layer */\n\n    avio_rb16(pb); /* alternate group */\n\n    avio_rb16(pb); /* volume */\n\n    avio_rb16(pb); /* reserved */\n\n\n\n    //read in the display matrix (outlined in ISO 14496-12, Section 6.2.2)\n\n    // they're kept in fixed point format through all calculations\n\n    // save u,v,z to store the whole matrix in the AV_PKT_DATA_DISPLAYMATRIX\n\n    // side data, but the scale factor is not needed to calculate aspect ratio\n\n    for (i = 0; i < 3; i++) {\n\n        display_matrix[i][0] = avio_rb32(pb);   // 16.16 fixed point\n\n        display_matrix[i][1] = avio_rb32(pb);   // 16.16 fixed point\n\n        display_matrix[i][2] = avio_rb32(pb);   //  2.30 fixed point\n\n    }\n\n\n\n    width = avio_rb32(pb);       // 16.16 fixed point track width\n\n    height = avio_rb32(pb);      // 16.16 fixed point track height\n\n    sc->width = width >> 16;\n\n    sc->height = height >> 16;\n\n\n\n    // save the matrix when it is not the default identity\n\n    if (display_matrix[0][0] != (1 << 16) ||\n\n        display_matrix[1][1] != (1 << 16) ||\n\n        display_matrix[2][2] != (1 << 30) ||\n\n        display_matrix[0][1] || display_matrix[0][2] ||\n\n        display_matrix[1][0] || display_matrix[1][2] ||\n\n        display_matrix[2][0] || display_matrix[2][1]) {\n\n        int i, j;\n\n\n\n        av_freep(&sc->display_matrix);\n\n        sc->display_matrix = av_malloc(sizeof(int32_t) * 9);\n\n        if (!sc->display_matrix)\n\n            return AVERROR(ENOMEM);\n\n\n\n        for (i = 0; i < 3; i++)\n\n            for (j = 0; j < 3; j++)\n\n                sc->display_matrix[i * 3 + j] = display_matrix[j][i];\n\n    }\n\n\n\n    // transform the display width/height according to the matrix\n\n    // skip this if the rotation angle is 0 degrees\n\n    // to keep the same scale, use [width height 1<<16]\n\n    if (width && height && sc->display_matrix &&\n\n        av_display_rotation_get(sc->display_matrix) != 0.0f) {\n\n        for (i = 0; i < 2; i++)\n\n            disp_transform[i] =\n\n                (int64_t)  width  * display_matrix[0][i] +\n\n                (int64_t)  height * display_matrix[1][i] +\n\n                ((int64_t) display_matrix[2][i] << 16);\n\n\n\n        //sample aspect ratio is new width/height divided by old width/height\n\n        st->sample_aspect_ratio = av_d2q(\n\n            ((double) disp_transform[0] * height) /\n\n            ((double) disp_transform[1] * width), INT_MAX);\n\n    }\n\n    return 0;\n\n}\n", "idx": 8164, "_split": "valid", "_hash": "874a7ca23f428903a8374a67fed96361"}
{"project": "FFmpeg", "commit_id": "9cbb3fce5965f4e1423cace3d1dc340a7a8091f4", "target": 1, "func": "uint8_t *av_packet_new_side_data(AVPacket *pkt, enum AVPacketSideDataType type,\n\n                                 int size)\n\n{\n\n    int elems = pkt->side_data_elems;\n\n\n\n    if ((unsigned)elems + 1 > INT_MAX / sizeof(*pkt->side_data))\n\n        return NULL;\n\n    if ((unsigned)size > INT_MAX - FF_INPUT_BUFFER_PADDING_SIZE)\n\n        return NULL;\n\n\n\n    pkt->side_data = av_realloc(pkt->side_data,\n\n                                (elems + 1) * sizeof(*pkt->side_data));\n\n    if (!pkt->side_data)\n\n        return NULL;\n\n\n\n    pkt->side_data[elems].data = av_malloc(size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!pkt->side_data[elems].data)\n\n        return NULL;\n\n    pkt->side_data[elems].size = size;\n\n    pkt->side_data[elems].type = type;\n\n    pkt->side_data_elems++;\n\n\n\n    return pkt->side_data[elems].data;\n\n}\n", "idx": 8168, "_split": "valid", "_hash": "8e2fc5488e88724fd65157225cf7f094"}
{"project": "FFmpeg", "commit_id": "c89658008705d949c319df3fa6f400c481ad73e1", "target": 0, "func": "static void rtsp_parse_transport(RTSPMessageHeader *reply, const char *p)\n\n{\n\n    char transport_protocol[16];\n\n    char profile[16];\n\n    char lower_transport[16];\n\n    char parameter[16];\n\n    RTSPTransportField *th;\n\n    char buf[256];\n\n\n\n    reply->nb_transports = 0;\n\n\n\n    for(;;) {\n\n        skip_spaces(&p);\n\n        if (*p == '\\0')\n\n            break;\n\n\n\n        th = &reply->transports[reply->nb_transports];\n\n\n\n        get_word_sep(transport_protocol, sizeof(transport_protocol),\n\n                     \"/\", &p);\n\n        if (!strcasecmp (transport_protocol, \"rtp\")) {\n\n            get_word_sep(profile, sizeof(profile), \"/;,\", &p);\n\n            lower_transport[0] = '\\0';\n\n            /* rtp/avp/<protocol> */\n\n            if (*p == '/') {\n\n                get_word_sep(lower_transport, sizeof(lower_transport),\n\n                             \";,\", &p);\n\n            }\n\n            th->transport = RTSP_TRANSPORT_RTP;\n\n        } else if (!strcasecmp (transport_protocol, \"x-pn-tng\") ||\n\n                   !strcasecmp (transport_protocol, \"x-real-rdt\")) {\n\n            /* x-pn-tng/<protocol> */\n\n            get_word_sep(lower_transport, sizeof(lower_transport), \"/;,\", &p);\n\n            profile[0] = '\\0';\n\n            th->transport = RTSP_TRANSPORT_RDT;\n\n        }\n\n        if (!strcasecmp(lower_transport, \"TCP\"))\n\n            th->lower_transport = RTSP_LOWER_TRANSPORT_TCP;\n\n        else\n\n            th->lower_transport = RTSP_LOWER_TRANSPORT_UDP;\n\n\n\n        if (*p == ';')\n\n            p++;\n\n        /* get each parameter */\n\n        while (*p != '\\0' && *p != ',') {\n\n            get_word_sep(parameter, sizeof(parameter), \"=;,\", &p);\n\n            if (!strcmp(parameter, \"port\")) {\n\n                if (*p == '=') {\n\n                    p++;\n\n                    rtsp_parse_range(&th->port_min, &th->port_max, &p);\n\n                }\n\n            } else if (!strcmp(parameter, \"client_port\")) {\n\n                if (*p == '=') {\n\n                    p++;\n\n                    rtsp_parse_range(&th->client_port_min,\n\n                                     &th->client_port_max, &p);\n\n                }\n\n            } else if (!strcmp(parameter, \"server_port\")) {\n\n                if (*p == '=') {\n\n                    p++;\n\n                    rtsp_parse_range(&th->server_port_min,\n\n                                     &th->server_port_max, &p);\n\n                }\n\n            } else if (!strcmp(parameter, \"interleaved\")) {\n\n                if (*p == '=') {\n\n                    p++;\n\n                    rtsp_parse_range(&th->interleaved_min,\n\n                                     &th->interleaved_max, &p);\n\n                }\n\n            } else if (!strcmp(parameter, \"multicast\")) {\n\n                if (th->lower_transport == RTSP_LOWER_TRANSPORT_UDP)\n\n                    th->lower_transport = RTSP_LOWER_TRANSPORT_UDP_MULTICAST;\n\n            } else if (!strcmp(parameter, \"ttl\")) {\n\n                if (*p == '=') {\n\n                    p++;\n\n                    th->ttl = strtol(p, (char **)&p, 10);\n\n                }\n\n            } else if (!strcmp(parameter, \"destination\")) {\n\n                struct in_addr ipaddr;\n\n\n\n                if (*p == '=') {\n\n                    p++;\n\n                    get_word_sep(buf, sizeof(buf), \";,\", &p);\n\n                    if (inet_aton(buf, &ipaddr))\n\n                        th->destination = ntohl(ipaddr.s_addr);\n\n                }\n\n            }\n\n            while (*p != ';' && *p != '\\0' && *p != ',')\n\n                p++;\n\n            if (*p == ';')\n\n                p++;\n\n        }\n\n        if (*p == ',')\n\n            p++;\n\n\n\n        reply->nb_transports++;\n\n    }\n\n}\n", "idx": 8182, "_split": "valid", "_hash": "bc7c4c4a5f0653924586e44ca97dacf8"}
{"project": "FFmpeg", "commit_id": "ed7fa39c2dd63607fd5c5ed3c607a11a8a33bbe3", "target": 0, "func": "static int mov_write_avcc_tag(ByteIOContext *pb, MOVTrack *track)\n\n{\n\n    offset_t pos = url_ftell(pb);\n\n\n\n    put_be32(pb, 0);\n\n    put_tag(pb, \"avcC\");\n\n    if (track->vosLen > 6) {\n\n        /* check for h264 start code */\n\n        if (AV_RB32(track->vosData) == 0x00000001) {\n\n            uint8_t *buf, *end;\n\n            uint32_t sps_size=0, pps_size=0;\n\n            uint8_t *sps=0, *pps=0;\n\n\n\n            avc_parse_nal_units(&track->vosData, &track->vosLen);\n\n            buf = track->vosData;\n\n            end = track->vosData + track->vosLen;\n\n\n\n            /* look for sps and pps */\n\n            while (buf < end) {\n\n                unsigned int size;\n\n                uint8_t nal_type;\n\n                size = AV_RB32(buf);\n\n                nal_type = buf[4] & 0x1f;\n\n                if (nal_type == 7) { /* SPS */\n\n                    sps = buf + 4;\n\n                    sps_size = size;\n\n                } else if (nal_type == 8) { /* PPS */\n\n                    pps = buf + 4;\n\n                    pps_size = size;\n\n                }\n\n                buf += size + 4;\n\n            }\n\n            assert(sps);\n\n            assert(pps);\n\n\n\n            put_byte(pb, 1); /* version */\n\n            put_byte(pb, sps[1]); /* profile */\n\n            put_byte(pb, sps[2]); /* profile compat */\n\n            put_byte(pb, sps[3]); /* level */\n\n            put_byte(pb, 0xff); /* 6 bits reserved (111111) + 2 bits nal size length - 1 (11) */\n\n            put_byte(pb, 0xe1); /* 3 bits reserved (111) + 5 bits number of sps (00001) */\n\n\n\n            put_be16(pb, sps_size);\n\n            put_buffer(pb, sps, sps_size);\n\n            put_byte(pb, 1); /* number of pps */\n\n            put_be16(pb, pps_size);\n\n            put_buffer(pb, pps, pps_size);\n\n        } else {\n\n            put_buffer(pb, track->vosData, track->vosLen);\n\n        }\n\n    }\n\n    return updateSize(pb, pos);\n\n}\n", "idx": 8190, "_split": "valid", "_hash": "a71ec16cf194a8cb2d8a315caf4d6964"}
{"project": "FFmpeg", "commit_id": "f3ad901a32c95239f302f173b866b82fb1f6cdf9", "target": 0, "func": "static inline int compress_coeffs(int *coef, int order, int c_bits)\n\n{\n\n    int i, res = 0;\n\n    const int low_idx   = c_bits ?  4 : 2;\n\n    const int shift_val = c_bits ?  8 : 4;\n\n    const int high_idx  = c_bits ? 11 : 5;\n\n    for (i = 0; i < order; i++)\n\n        if (coef[i] < low_idx || coef[i] > high_idx)\n\n            res++;\n\n    if (res == order)\n\n        for (i = 0; i < order; i++)\n\n            coef[i] -= (coef[i] > high_idx) ? shift_val : 0;\n\n    return res == order;\n\n}\n", "idx": 8196, "_split": "valid", "_hash": "a993747f0396073b3fc6cfd5b75482c3"}
{"project": "FFmpeg", "commit_id": "7f58eb3c2b552f232905731b5944307e72c590a0", "target": 1, "func": "static av_cold int indeo3_decode_end(AVCodecContext *avctx)\n{\n    Indeo3DecodeContext *s = avctx->priv_data;\n    iv_free_func(s);\n    return 0;\n}", "idx": 8218, "_split": "valid", "_hash": "4dafb9879b896512f7ff753981748885"}
{"project": "FFmpeg", "commit_id": "7656c4c6e66f8a787d384f027ad824cc1677fda1", "target": 0, "func": "static void restore_median_il(uint8_t *src, int step, int stride,\n\n                              int width, int height, int slices, int rmode)\n\n{\n\n    int i, j, slice;\n\n    int A, B, C;\n\n    uint8_t *bsrc;\n\n    int slice_start, slice_height;\n\n    const int cmask   = ~(rmode ? 3 : 1);\n\n    const int stride2 = stride << 1;\n\n\n\n    for (slice = 0; slice < slices; slice++) {\n\n        slice_start    = ((slice * height) / slices) & cmask;\n\n        slice_height   = ((((slice + 1) * height) / slices) & cmask) -\n\n                         slice_start;\n\n        slice_height >>= 1;\n\n\n\n        bsrc = src + slice_start * stride;\n\n\n\n        // first line - left neighbour prediction\n\n        bsrc[0] += 0x80;\n\n        A        = bsrc[0];\n\n        for (i = step; i < width * step; i += step) {\n\n            bsrc[i] += A;\n\n            A        = bsrc[i];\n\n        }\n\n        for (i = 0; i < width * step; i += step) {\n\n            bsrc[stride + i] += A;\n\n            A                 = bsrc[stride + i];\n\n        }\n\n        bsrc += stride2;\n\n        if (slice_height == 1)\n\n            continue;\n\n        // second line - first element has top prediction, the rest uses median\n\n        C        = bsrc[-stride2];\n\n        bsrc[0] += C;\n\n        A        = bsrc[0];\n\n        for (i = step; i < width * step; i += step) {\n\n            B        = bsrc[i - stride2];\n\n            bsrc[i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n            C        = B;\n\n            A        = bsrc[i];\n\n        }\n\n        for (i = 0; i < width * step; i += step) {\n\n            B                 = bsrc[i - stride];\n\n            bsrc[stride + i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n            C                 = B;\n\n            A                 = bsrc[stride + i];\n\n        }\n\n        bsrc += stride2;\n\n        // the rest of lines use continuous median prediction\n\n        for (j = 2; j < slice_height; j++) {\n\n            for (i = 0; i < width * step; i += step) {\n\n                B        = bsrc[i - stride2];\n\n                bsrc[i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n                C        = B;\n\n                A        = bsrc[i];\n\n            }\n\n            for (i = 0; i < width * step; i += step) {\n\n                B                 = bsrc[i - stride];\n\n                bsrc[i + stride] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n                C                 = B;\n\n                A                 = bsrc[i + stride];\n\n            }\n\n            bsrc += stride2;\n\n        }\n\n    }\n\n}\n", "idx": 8274, "_split": "valid", "_hash": "918c1c90dfb532979998e444635a24c9"}
{"project": "FFmpeg", "commit_id": "57d77b3963ce1023eaf5ada8cba58b9379405cc8", "target": 0, "func": "AVOpenCLExternalEnv *av_opencl_alloc_external_env(void)\n\n{\n\n    AVOpenCLExternalEnv *ext = av_mallocz(sizeof(AVOpenCLExternalEnv));\n\n    if (!ext) {\n\n        av_log(&openclutils, AV_LOG_ERROR,\n\n         \"Could not malloc external opencl environment data space\\n\");\n\n    }\n\n    return ext;\n\n}\n", "idx": 8276, "_split": "valid", "_hash": "61f299f6a1b52a91b653ac12018422fe"}
{"project": "FFmpeg", "commit_id": "d31dbec3742e488156621b9ca21069f8c05aabf0", "target": 0, "func": "static int context_init(H264Context *h){\n\n    CHECKED_ALLOCZ(h->top_borders[0], h->s.mb_width * (16+8+8) * sizeof(uint8_t))\n\n    CHECKED_ALLOCZ(h->top_borders[1], h->s.mb_width * (16+8+8) * sizeof(uint8_t))\n\n\n\n    return 0;\n\nfail:\n\n    return -1; // free_tables will clean up for us\n\n}\n", "idx": 8311, "_split": "valid", "_hash": "a4a346af954dc3ac686e15f1e7de7c4d"}
{"project": "FFmpeg", "commit_id": "3e0f7126b53b395d9e79df57b2e626eb99ad846b", "target": 1, "func": "void ff_snow_vertical_compose97i_mmx(DWTELEM *b0, DWTELEM *b1, DWTELEM *b2, DWTELEM *b3, DWTELEM *b4, DWTELEM *b5, int width){\n\n    long i = width;\n\n    while(i & 0x7)\n\n    {\n\n        i--;\n\n        b4[i] -= (W_DM*(b3[i] + b5[i])+W_DO)>>W_DS;\n\n        b3[i] -= (W_CM*(b2[i] + b4[i])+W_CO)>>W_CS;\n\n        b2[i] += (W_BM*(b1[i] + b3[i])+4*b2[i]+W_BO)>>W_BS;\n\n        b1[i] += (W_AM*(b0[i] + b2[i])+W_AO)>>W_AS;\n\n    }\n\n\n\n    asm volatile(\n\n        \"jmp 2f                                      \\n\\t\"\n\n        \"1:                                          \\n\\t\"\n\n\n\n        \"mov %6, %%\"REG_a\"                           \\n\\t\"\n\n        \"mov %4, %%\"REG_S\"                           \\n\\t\"\n\n\n\n        snow_vertical_compose_mmx_load(REG_S,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(REG_a,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_move(\"mm0\",\"mm2\",\"mm4\",\"mm6\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_mmx_r2r_add(\"mm0\",\"mm2\",\"mm4\",\"mm6\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_r2r_add(\"mm1\",\"mm3\",\"mm5\",\"mm7\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n\n\n        \"pcmpeqd %%mm1, %%mm1                        \\n\\t\"\n\n        \"pslld $31, %%mm1                            \\n\\t\"\n\n        \"psrld $29, %%mm1                            \\n\\t\"\n\n        \"mov %5, %%\"REG_a\"                           \\n\\t\"\n\n\n\n        snow_vertical_compose_mmx_r2r_add(\"mm1\",\"mm1\",\"mm1\",\"mm1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_sra(\"3\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_load(REG_a,\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_mmx_sub(\"mm0\",\"mm2\",\"mm4\",\"mm6\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_mmx_store(REG_a,\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        \"mov %3, %%\"REG_c\"                           \\n\\t\"\n\n        snow_vertical_compose_mmx_load(REG_S,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(REG_c,\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_mmx_sub(\"mm1\",\"mm3\",\"mm5\",\"mm7\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_store(REG_S,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        \"mov %2, %%\"REG_a\"                           \\n\\t\"\n\n        snow_vertical_compose_mmx_add(REG_a,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_sra(\"2\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(REG_c,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n\n\n        \"pcmpeqd %%mm1, %%mm1                        \\n\\t\"\n\n        \"pslld $31, %%mm1                            \\n\\t\"\n\n        \"psrld $30, %%mm1                            \\n\\t\"\n\n        \"mov %1, %%\"REG_S\"                           \\n\\t\"\n\n\n\n        snow_vertical_compose_mmx_r2r_add(\"mm1\",\"mm1\",\"mm1\",\"mm1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_sra(\"2\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(REG_c,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_store(REG_c,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(REG_S,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_move(\"mm0\",\"mm2\",\"mm4\",\"mm6\",\"mm1\",\"mm3\",\"mm5\",\"mm7\")\n\n        snow_vertical_compose_mmx_sra(\"1\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_r2r_add(\"mm1\",\"mm3\",\"mm5\",\"mm7\",\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_add(REG_a,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n        snow_vertical_compose_mmx_store(REG_a,\"mm0\",\"mm2\",\"mm4\",\"mm6\")\n\n\n\n        \"2:                                          \\n\\t\"\n\n        \"sub $8, %%\"REG_d\"                           \\n\\t\"\n\n        \"jge 1b                                      \\n\\t\"\n\n        :\"+d\"(i)\n\n        :\n\n        \"m\"(b0),\"m\"(b1),\"m\"(b2),\"m\"(b3),\"m\"(b4),\"m\"(b5):\n\n        \"%\"REG_a\"\",\"%\"REG_S\"\",\"%\"REG_c\"\");\n\n}\n", "idx": 8337, "_split": "valid", "_hash": "68b344f3a77f170f1ded81a5f9d368ba"}
{"project": "FFmpeg", "commit_id": "fd34dbea58e097609ff09cf7dcc59f74930195d3", "target": 1, "func": "static int mxf_read_material_package(void *arg, AVIOContext *pb, int tag, int size, UID uid)\n\n{\n\n    MXFPackage *package = arg;\n\n    switch(tag) {\n\n    case 0x4403:\n\n        package->tracks_count = avio_rb32(pb);\n\n        if (package->tracks_count >= UINT_MAX / sizeof(UID))\n\n            return -1;\n\n        package->tracks_refs = av_malloc(package->tracks_count * sizeof(UID));\n\n        if (!package->tracks_refs)\n\n            return -1;\n\n        avio_skip(pb, 4); /* useless size of objects, always 16 according to specs */\n\n        avio_read(pb, (uint8_t *)package->tracks_refs, package->tracks_count * sizeof(UID));\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 8366, "_split": "valid", "_hash": "0e0dae9b553bdf3dad5c276a59ca8759"}
{"project": "FFmpeg", "commit_id": "472ea1284e925297b08921b7189f57f6789c898c", "target": 1, "func": "static int cinepak_decode_strip (CinepakContext *s,\n                                 cvid_strip_t *strip, uint8_t *data, int size)\n{\n    uint8_t *eod = (data + size);\n    int      chunk_id, chunk_size;\n    /* coordinate sanity checks */\n    if (strip->x1 >= s->width  || strip->x2 > s->width  ||\n        strip->y1 >= s->height || strip->y2 > s->height ||\n        strip->x1 >= strip->x2 || strip->y1 >= strip->y2)\n    while ((data + 4) <= eod) {\n        chunk_id   = BE_16 (&data[0]);\n        chunk_size = BE_16 (&data[2]) - 4;\n        data      += 4;\n        chunk_size = ((data + chunk_size) > eod) ? (eod - data) : chunk_size;\n        switch (chunk_id) {\n        case 0x2000:\n        case 0x2100:\n        case 0x2400:\n        case 0x2500:\n            cinepak_decode_codebook (strip->v4_codebook, chunk_id, \n                chunk_size, data);\n            break;\n        case 0x2200:\n        case 0x2300:\n        case 0x2600:\n        case 0x2700:\n            cinepak_decode_codebook (strip->v1_codebook, chunk_id, \n                chunk_size, data);\n            break;\n        case 0x3000:\n        case 0x3100:\n        case 0x3200:\n            return cinepak_decode_vectors (s, strip, chunk_id, \n                chunk_size, data);\n        }\n        data += chunk_size;\n    }\n}", "idx": 8419, "_split": "valid", "_hash": "5025de4b32602a598f64d7198f479cb6"}
{"project": "FFmpeg", "commit_id": "c3e6e8f06c42499bd020fd0b37f9542150e6067b", "target": 0, "func": "void *av_realloc_array(void *ptr, size_t nmemb, size_t size)\n\n{\n\n    if (size <= 0 || nmemb >= INT_MAX / size)\n\n        return NULL;\n\n    return av_realloc(ptr, nmemb * size);\n\n}\n", "idx": 8424, "_split": "valid", "_hash": "4baea38ed2fe1b4bb027c55260e5cb1b"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,\n\n\t\t\tuint8_t *dst1, uint8_t *dst2,\n\n\t\t\tunsigned width, unsigned height,\n\n\t\t\tint srcStride1, int srcStride2,\n\n\t\t\tint dstStride1, int dstStride2)\n\n{\n\n    unsigned int y,x,h;\n\n    int w;\n\n    w=width/2; h=height/2;\n\n#ifdef HAVE_MMX\n\n    asm volatile(\n\n\tPREFETCH\" %0\\n\\t\"\n\n\tPREFETCH\" %1\\n\\t\"\n\n\t::\"m\"(*(src1+srcStride1)),\"m\"(*(src2+srcStride2)):\"memory\");\n\n#endif\n\n    for(y=0;y<h;y++){\n\n\tconst uint8_t* s1=src1+srcStride1*(y>>1);\n\n\tuint8_t* d=dst1+dstStride1*y;\n\n\tx=0;\n\n#ifdef HAVE_MMX\n\n\tfor(;x<w-31;x+=32)\n\n\t{\n\n\t    asm volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t        \"movq\t%1, %%mm0\\n\\t\"\n\n\t        \"movq\t8%1, %%mm2\\n\\t\"\n\n\t        \"movq\t16%1, %%mm4\\n\\t\"\n\n\t        \"movq\t24%1, %%mm6\\n\\t\"\n\n\t        \"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t        \"movq\t%%mm2, %%mm3\\n\\t\"\n\n\t        \"movq\t%%mm4, %%mm5\\n\\t\"\n\n\t        \"movq\t%%mm6, %%mm7\\n\\t\"\n\n\t\t\"punpcklbw %%mm0, %%mm0\\n\\t\"\n\n\t\t\"punpckhbw %%mm1, %%mm1\\n\\t\"\n\n\t\t\"punpcklbw %%mm2, %%mm2\\n\\t\"\n\n\t\t\"punpckhbw %%mm3, %%mm3\\n\\t\"\n\n\t\t\"punpcklbw %%mm4, %%mm4\\n\\t\"\n\n\t\t\"punpckhbw %%mm5, %%mm5\\n\\t\"\n\n\t\t\"punpcklbw %%mm6, %%mm6\\n\\t\"\n\n\t\t\"punpckhbw %%mm7, %%mm7\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm1, 8%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm2, 16%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm3, 24%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm4, 32%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm5, 40%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm6, 48%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm7, 56%0\"\n\n\t\t:\"=m\"(d[2*x])\n\n\t\t:\"m\"(s1[x])\n\n\t\t:\"memory\");\n\n\t}\n\n#endif\n\n\tfor(;x<w;x++) d[2*x]=d[2*x+1]=s1[x];\n\n    }\n\n    for(y=0;y<h;y++){\n\n\tconst uint8_t* s2=src2+srcStride2*(y>>1);\n\n\tuint8_t* d=dst2+dstStride2*y;\n\n\tx=0;\n\n#ifdef HAVE_MMX\n\n\tfor(;x<w-31;x+=32)\n\n\t{\n\n\t    asm volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t        \"movq\t%1, %%mm0\\n\\t\"\n\n\t        \"movq\t8%1, %%mm2\\n\\t\"\n\n\t        \"movq\t16%1, %%mm4\\n\\t\"\n\n\t        \"movq\t24%1, %%mm6\\n\\t\"\n\n\t        \"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t        \"movq\t%%mm2, %%mm3\\n\\t\"\n\n\t        \"movq\t%%mm4, %%mm5\\n\\t\"\n\n\t        \"movq\t%%mm6, %%mm7\\n\\t\"\n\n\t\t\"punpcklbw %%mm0, %%mm0\\n\\t\"\n\n\t\t\"punpckhbw %%mm1, %%mm1\\n\\t\"\n\n\t\t\"punpcklbw %%mm2, %%mm2\\n\\t\"\n\n\t\t\"punpckhbw %%mm3, %%mm3\\n\\t\"\n\n\t\t\"punpcklbw %%mm4, %%mm4\\n\\t\"\n\n\t\t\"punpckhbw %%mm5, %%mm5\\n\\t\"\n\n\t\t\"punpcklbw %%mm6, %%mm6\\n\\t\"\n\n\t\t\"punpckhbw %%mm7, %%mm7\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm1, 8%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm2, 16%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm3, 24%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm4, 32%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm5, 40%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm6, 48%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm7, 56%0\"\n\n\t\t:\"=m\"(d[2*x])\n\n\t\t:\"m\"(s2[x])\n\n\t\t:\"memory\");\n\n\t}\n\n#endif\n\n\tfor(;x<w;x++) d[2*x]=d[2*x+1]=s2[x];\n\n    }\n\n#ifdef HAVE_MMX\n\n\tasm(\n\n\t\tEMMS\" \\n\\t\"\n\n\t\tSFENCE\" \\n\\t\"\n\n\t\t::: \"memory\"\n\n\t\t);\n\n#endif\n\n}\n", "idx": 8428, "_split": "valid", "_hash": "1f2bb2610a505e385f72998ab3466b16"}
{"project": "FFmpeg", "commit_id": "9ecf7fada31aac294dee540abb9a8dcf8131d67d", "target": 1, "func": "static void av_estimate_timings_from_pts(AVFormatContext *ic)\n\n{\n\n    AVPacket pkt1, *pkt = &pkt1;\n\n    AVStream *st;\n\n    int read_size, i, ret;\n\n    int64_t end_time;\n\n    int64_t filesize, offset, duration;\n\n\n\n    /* free previous packet */\n\n    if (ic->cur_st && ic->cur_st->parser)\n\n        av_free_packet(&ic->cur_pkt);\n\n    ic->cur_st = NULL;\n\n\n\n    /* flush packet queue */\n\n    flush_packet_queue(ic);\n\n\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        st = ic->streams[i];\n\n        if (st->parser) {\n\n            av_parser_close(st->parser);\n\n            st->parser= NULL;\n\n        }\n\n    }\n\n\n\n    /* we read the first packets to get the first PTS (not fully\n\n       accurate, but it is enough now) */\n\n    url_fseek(&ic->pb, 0, SEEK_SET);\n\n    read_size = 0;\n\n    for(;;) {\n\n        if (read_size >= DURATION_MAX_READ_SIZE)\n\n            break;\n\n        /* if all info is available, we can stop */\n\n        for(i = 0;i < ic->nb_streams; i++) {\n\n            st = ic->streams[i];\n\n            if (st->start_time == AV_NOPTS_VALUE)\n\n                break;\n\n        }\n\n        if (i == ic->nb_streams)\n\n            break;\n\n\n\n        ret = av_read_packet(ic, pkt);\n\n        if (ret != 0)\n\n            break;\n\n        read_size += pkt->size;\n\n        st = ic->streams[pkt->stream_index];\n\n        if (pkt->pts != AV_NOPTS_VALUE) {\n\n            if (st->start_time == AV_NOPTS_VALUE)\n\n                st->start_time = pkt->pts;\n\n        }\n\n        av_free_packet(pkt);\n\n    }\n\n\n\n    /* estimate the end time (duration) */\n\n    /* XXX: may need to support wrapping */\n\n    filesize = ic->file_size;\n\n    offset = filesize - DURATION_MAX_READ_SIZE;\n\n    if (offset < 0)\n\n        offset = 0;\n\n\n\n    url_fseek(&ic->pb, offset, SEEK_SET);\n\n    read_size = 0;\n\n    for(;;) {\n\n        if (read_size >= DURATION_MAX_READ_SIZE)\n\n            break;\n\n        /* if all info is available, we can stop */\n\n        for(i = 0;i < ic->nb_streams; i++) {\n\n            st = ic->streams[i];\n\n            if (st->duration == AV_NOPTS_VALUE)\n\n                break;\n\n        }\n\n        if (i == ic->nb_streams)\n\n            break;\n\n\n\n        ret = av_read_packet(ic, pkt);\n\n        if (ret != 0)\n\n            break;\n\n        read_size += pkt->size;\n\n        st = ic->streams[pkt->stream_index];\n\n        if (pkt->pts != AV_NOPTS_VALUE) {\n\n            end_time = pkt->pts;\n\n            duration = end_time - st->start_time;\n\n            if (duration > 0) {\n\n                if (st->duration == AV_NOPTS_VALUE ||\n\n                    st->duration < duration)\n\n                    st->duration = duration;\n\n            }\n\n        }\n\n        av_free_packet(pkt);\n\n    }\n\n\n\n    fill_all_stream_timings(ic);\n\n\n\n    url_fseek(&ic->pb, 0, SEEK_SET);\n\n}\n", "idx": 8456, "_split": "valid", "_hash": "012892c71722540eebc4bb1654ae4c33"}
{"project": "FFmpeg", "commit_id": "c8f9f9b91a3d3254e62f4fbcd6065a504164b06b", "target": 1, "func": "static int vmdaudio_decode_frame(AVCodecContext *avctx,\n\n                                 void *data, int *data_size,\n\n                                 uint8_t *buf, int buf_size)\n\n{\n\n    VmdAudioContext *s = (VmdAudioContext *)avctx->priv_data;\n\n    unsigned int sound_flags;\n\n    unsigned char *output_samples = (unsigned char *)data;\n\n\n\n    /* point to the start of the encoded data */\n\n    unsigned char *p = buf + 16;\n\n    unsigned char *p_end = buf + buf_size;\n\n\n\n    if (buf_size < 16)\n\n        return buf_size;\n\n\n\n    if (buf[6] == 1) {\n\n        /* the chunk contains audio */\n\n        *data_size = vmdaudio_loadsound(s, output_samples, p, 0);\n\n    } else if (buf[6] == 2) {\n\n        /* the chunk contains audio and silence mixed together */\n\n        sound_flags = LE_32(p);\n\n        p += 4;\n\n\n\n        /* do something with extrabufs here? */\n\n\n\n        while (p < p_end) {\n\n            if (sound_flags & 0x01)\n\n                /* silence */\n\n                *data_size += vmdaudio_loadsound(s, output_samples, p, 1);\n\n            else {\n\n                /* audio */\n\n                *data_size += vmdaudio_loadsound(s, output_samples, p, 0);\n\n                p += s->block_align;\n\n            }\n\n            output_samples += (s->block_align * s->bits / 8);\n\n            sound_flags >>= 1;\n\n        }\n\n    } else if (buf[6] == 3) {\n\n        /* silent chunk */\n\n        *data_size = vmdaudio_loadsound(s, output_samples, p, 1);\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 8460, "_split": "valid", "_hash": "86def70d28e223fe46d799afc85e015f"}
{"project": "FFmpeg", "commit_id": "69c7aad494683953e833e8622776e3bbcc7921ed", "target": 1, "func": "static int audio_open(AVFormatContext *s1, int is_output, const char *audio_device)\n\n{\n\n    AudioData *s = s1->priv_data;\n\n    int audio_fd;\n\n    int tmp, err;\n\n    char *flip = getenv(\"AUDIO_FLIP_LEFT\");\n\n\n\n    if (is_output)\n\n        audio_fd = avpriv_open(audio_device, O_WRONLY);\n\n    else\n\n        audio_fd = avpriv_open(audio_device, O_RDONLY);\n\n    if (audio_fd < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"%s: %s\\n\", audio_device, strerror(errno));\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    if (flip && *flip == '1') {\n\n        s->flip_left = 1;\n\n    }\n\n\n\n    /* non blocking mode */\n\n    if (!is_output) {\n\n        if (fcntl(audio_fd, F_SETFL, O_NONBLOCK) < 0) {\n\n            av_log(s1, AV_LOG_WARNING, \"%s: Could not enable non block mode (%s)\\n\", audio_device, strerror(errno));\n\n        }\n\n    }\n\n\n\n    s->frame_size = AUDIO_BLOCK_SIZE;\n\n\n\n    /* select format : favour native format */\n\n    err = ioctl(audio_fd, SNDCTL_DSP_GETFMTS, &tmp);\n\n\n\n#if HAVE_BIGENDIAN\n\n    if (tmp & AFMT_S16_BE) {\n\n        tmp = AFMT_S16_BE;\n\n    } else if (tmp & AFMT_S16_LE) {\n\n        tmp = AFMT_S16_LE;\n\n    } else {\n\n        tmp = 0;\n\n    }\n\n#else\n\n    if (tmp & AFMT_S16_LE) {\n\n        tmp = AFMT_S16_LE;\n\n    } else if (tmp & AFMT_S16_BE) {\n\n        tmp = AFMT_S16_BE;\n\n    } else {\n\n        tmp = 0;\n\n    }\n\n#endif\n\n\n\n    switch(tmp) {\n\n    case AFMT_S16_LE:\n\n        s->codec_id = AV_CODEC_ID_PCM_S16LE;\n\n        break;\n\n    case AFMT_S16_BE:\n\n        s->codec_id = AV_CODEC_ID_PCM_S16BE;\n\n        break;\n\n    default:\n\n        av_log(s1, AV_LOG_ERROR, \"Soundcard does not support 16 bit sample format\\n\");\n\n        close(audio_fd);\n\n        return AVERROR(EIO);\n\n    }\n\n    err=ioctl(audio_fd, SNDCTL_DSP_SETFMT, &tmp);\n\n    if (err < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"SNDCTL_DSP_SETFMT: %s\\n\", strerror(errno));\n\n        goto fail;\n\n    }\n\n\n\n    tmp = (s->channels == 2);\n\n    err = ioctl(audio_fd, SNDCTL_DSP_STEREO, &tmp);\n\n    if (err < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"SNDCTL_DSP_STEREO: %s\\n\", strerror(errno));\n\n        goto fail;\n\n    }\n\n\n\n    tmp = s->sample_rate;\n\n    err = ioctl(audio_fd, SNDCTL_DSP_SPEED, &tmp);\n\n    if (err < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"SNDCTL_DSP_SPEED: %s\\n\", strerror(errno));\n\n        goto fail;\n\n    }\n\n    s->sample_rate = tmp; /* store real sample rate */\n\n    s->fd = audio_fd;\n\n\n\n    return 0;\n\n fail:\n\n    close(audio_fd);\n\n    return AVERROR(EIO);\n\n}\n", "idx": 8538, "_split": "valid", "_hash": "aead3826375ef347c05c18399dc0c43e"}
{"project": "FFmpeg", "commit_id": "37d93fdbf0fec0eac885974c01fba99826ae7763", "target": 0, "func": "static int mpeg_decode_mb(MpegEncContext *s, int16_t block[12][64])\n\n{\n\n    int i, j, k, cbp, val, mb_type, motion_type;\n\n    const int mb_block_count = 4 + (1 << s->chroma_format);\n\n    int ret;\n\n\n\n    av_dlog(s->avctx, \"decode_mb: x=%d y=%d\\n\", s->mb_x, s->mb_y);\n\n\n\n    av_assert2(s->mb_skipped == 0);\n\n\n\n    if (s->mb_skip_run-- != 0) {\n\n        if (s->pict_type == AV_PICTURE_TYPE_P) {\n\n            s->mb_skipped = 1;\n\n            s->current_picture.mb_type[s->mb_x + s->mb_y * s->mb_stride] =\n\n                MB_TYPE_SKIP | MB_TYPE_L0 | MB_TYPE_16x16;\n\n        } else {\n\n            int mb_type;\n\n\n\n            if (s->mb_x)\n\n                mb_type = s->current_picture.mb_type[s->mb_x + s->mb_y * s->mb_stride - 1];\n\n            else\n\n                // FIXME not sure if this is allowed in MPEG at all\n\n                mb_type = s->current_picture.mb_type[s->mb_width + (s->mb_y - 1) * s->mb_stride - 1];\n\n            if (IS_INTRA(mb_type)) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"skip with previntra\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            s->current_picture.mb_type[s->mb_x + s->mb_y * s->mb_stride] =\n\n                mb_type | MB_TYPE_SKIP;\n\n\n\n            if ((s->mv[0][0][0] | s->mv[0][0][1] | s->mv[1][0][0] | s->mv[1][0][1]) == 0)\n\n                s->mb_skipped = 1;\n\n        }\n\n\n\n        return 0;\n\n    }\n\n\n\n    switch (s->pict_type) {\n\n    default:\n\n    case AV_PICTURE_TYPE_I:\n\n        if (get_bits1(&s->gb) == 0) {\n\n            if (get_bits1(&s->gb) == 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"invalid mb type in I Frame at %d %d\\n\",\n\n                       s->mb_x, s->mb_y);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            mb_type = MB_TYPE_QUANT | MB_TYPE_INTRA;\n\n        } else {\n\n            mb_type = MB_TYPE_INTRA;\n\n        }\n\n        break;\n\n    case AV_PICTURE_TYPE_P:\n\n        mb_type = get_vlc2(&s->gb, ff_mb_ptype_vlc.table, MB_PTYPE_VLC_BITS, 1);\n\n        if (mb_type < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"invalid mb type in P Frame at %d %d\\n\", s->mb_x, s->mb_y);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        mb_type = ptype2mb_type[mb_type];\n\n        break;\n\n    case AV_PICTURE_TYPE_B:\n\n        mb_type = get_vlc2(&s->gb, ff_mb_btype_vlc.table, MB_BTYPE_VLC_BITS, 1);\n\n        if (mb_type < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"invalid mb type in B Frame at %d %d\\n\", s->mb_x, s->mb_y);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        mb_type = btype2mb_type[mb_type];\n\n        break;\n\n    }\n\n    av_dlog(s->avctx, \"mb_type=%x\\n\", mb_type);\n\n//    motion_type = 0; /* avoid warning */\n\n    if (IS_INTRA(mb_type)) {\n\n        s->bdsp.clear_blocks(s->block[0]);\n\n\n\n        if (!s->chroma_y_shift)\n\n            s->bdsp.clear_blocks(s->block[6]);\n\n\n\n        /* compute DCT type */\n\n        // FIXME: add an interlaced_dct coded var?\n\n        if (s->picture_structure == PICT_FRAME &&\n\n            !s->frame_pred_frame_dct)\n\n            s->interlaced_dct = get_bits1(&s->gb);\n\n\n\n        if (IS_QUANT(mb_type))\n\n            s->qscale = get_qscale(s);\n\n\n\n        if (s->concealment_motion_vectors) {\n\n            /* just parse them */\n\n            if (s->picture_structure != PICT_FRAME)\n\n                skip_bits1(&s->gb);  /* field select */\n\n\n\n            s->mv[0][0][0]      =\n\n            s->last_mv[0][0][0] =\n\n            s->last_mv[0][1][0] = mpeg_decode_motion(s, s->mpeg_f_code[0][0],\n\n                                                     s->last_mv[0][0][0]);\n\n            s->mv[0][0][1]      =\n\n            s->last_mv[0][0][1] =\n\n            s->last_mv[0][1][1] = mpeg_decode_motion(s, s->mpeg_f_code[0][1],\n\n                                                     s->last_mv[0][0][1]);\n\n\n\n            skip_bits1(&s->gb); /* marker */\n\n        } else {\n\n            /* reset mv prediction */\n\n            memset(s->last_mv, 0, sizeof(s->last_mv));\n\n        }\n\n        s->mb_intra = 1;\n\n        // if 1, we memcpy blocks in xvmcvideo\n\n        if ((CONFIG_MPEG1_XVMC_HWACCEL || CONFIG_MPEG2_XVMC_HWACCEL) && s->pack_pblocks)\n\n            ff_xvmc_pack_pblocks(s, -1); // inter are always full blocks\n\n\n\n        if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n            if (s->flags2 & CODEC_FLAG2_FAST) {\n\n                for (i = 0; i < 6; i++)\n\n                    mpeg2_fast_decode_block_intra(s, *s->pblocks[i], i);\n\n            } else {\n\n                for (i = 0; i < mb_block_count; i++)\n\n                    if ((ret = mpeg2_decode_block_intra(s, *s->pblocks[i], i)) < 0)\n\n                        return ret;\n\n            }\n\n        } else {\n\n            for (i = 0; i < 6; i++)\n\n                if ((ret = mpeg1_decode_block_intra(s, *s->pblocks[i], i)) < 0)\n\n                    return ret;\n\n        }\n\n    } else {\n\n        if (mb_type & MB_TYPE_ZERO_MV) {\n\n            av_assert2(mb_type & MB_TYPE_CBP);\n\n\n\n            s->mv_dir = MV_DIR_FORWARD;\n\n            if (s->picture_structure == PICT_FRAME) {\n\n                if (s->picture_structure == PICT_FRAME\n\n                    && !s->frame_pred_frame_dct)\n\n                    s->interlaced_dct = get_bits1(&s->gb);\n\n                s->mv_type = MV_TYPE_16X16;\n\n            } else {\n\n                s->mv_type            = MV_TYPE_FIELD;\n\n                mb_type              |= MB_TYPE_INTERLACED;\n\n                s->field_select[0][0] = s->picture_structure - 1;\n\n            }\n\n\n\n            if (IS_QUANT(mb_type))\n\n                s->qscale = get_qscale(s);\n\n\n\n            s->last_mv[0][0][0] = 0;\n\n            s->last_mv[0][0][1] = 0;\n\n            s->last_mv[0][1][0] = 0;\n\n            s->last_mv[0][1][1] = 0;\n\n            s->mv[0][0][0]      = 0;\n\n            s->mv[0][0][1]      = 0;\n\n        } else {\n\n            av_assert2(mb_type & MB_TYPE_L0L1);\n\n            // FIXME decide if MBs in field pictures are MB_TYPE_INTERLACED\n\n            /* get additional motion vector type */\n\n            if (s->picture_structure == PICT_FRAME && s->frame_pred_frame_dct) {\n\n                motion_type = MT_FRAME;\n\n            } else {\n\n                motion_type = get_bits(&s->gb, 2);\n\n                if (s->picture_structure == PICT_FRAME && HAS_CBP(mb_type))\n\n                    s->interlaced_dct = get_bits1(&s->gb);\n\n            }\n\n\n\n            if (IS_QUANT(mb_type))\n\n                s->qscale = get_qscale(s);\n\n\n\n            /* motion vectors */\n\n            s->mv_dir = (mb_type >> 13) & 3;\n\n            av_dlog(s->avctx, \"motion_type=%d\\n\", motion_type);\n\n            switch (motion_type) {\n\n            case MT_FRAME: /* or MT_16X8 */\n\n                if (s->picture_structure == PICT_FRAME) {\n\n                    mb_type   |= MB_TYPE_16x16;\n\n                    s->mv_type = MV_TYPE_16X16;\n\n                    for (i = 0; i < 2; i++) {\n\n                        if (USES_LIST(mb_type, i)) {\n\n                            /* MT_FRAME */\n\n                            s->mv[i][0][0]      =\n\n                            s->last_mv[i][0][0] =\n\n                            s->last_mv[i][1][0] =\n\n                                mpeg_decode_motion(s, s->mpeg_f_code[i][0],\n\n                                                   s->last_mv[i][0][0]);\n\n                            s->mv[i][0][1]      =\n\n                            s->last_mv[i][0][1] =\n\n                            s->last_mv[i][1][1] =\n\n                                mpeg_decode_motion(s, s->mpeg_f_code[i][1],\n\n                                                   s->last_mv[i][0][1]);\n\n                            /* full_pel: only for MPEG-1 */\n\n                            if (s->full_pel[i]) {\n\n                                s->mv[i][0][0] <<= 1;\n\n                                s->mv[i][0][1] <<= 1;\n\n                            }\n\n                        }\n\n                    }\n\n                } else {\n\n                    mb_type   |= MB_TYPE_16x8 | MB_TYPE_INTERLACED;\n\n                    s->mv_type = MV_TYPE_16X8;\n\n                    for (i = 0; i < 2; i++) {\n\n                        if (USES_LIST(mb_type, i)) {\n\n                            /* MT_16X8 */\n\n                            for (j = 0; j < 2; j++) {\n\n                                s->field_select[i][j] = get_bits1(&s->gb);\n\n                                for (k = 0; k < 2; k++) {\n\n                                    val = mpeg_decode_motion(s, s->mpeg_f_code[i][k],\n\n                                                             s->last_mv[i][j][k]);\n\n                                    s->last_mv[i][j][k] = val;\n\n                                    s->mv[i][j][k]      = val;\n\n                                }\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n                break;\n\n            case MT_FIELD:\n\n                s->mv_type = MV_TYPE_FIELD;\n\n                if (s->picture_structure == PICT_FRAME) {\n\n                    mb_type |= MB_TYPE_16x8 | MB_TYPE_INTERLACED;\n\n                    for (i = 0; i < 2; i++) {\n\n                        if (USES_LIST(mb_type, i)) {\n\n                            for (j = 0; j < 2; j++) {\n\n                                s->field_select[i][j] = get_bits1(&s->gb);\n\n                                val = mpeg_decode_motion(s, s->mpeg_f_code[i][0],\n\n                                                         s->last_mv[i][j][0]);\n\n                                s->last_mv[i][j][0] = val;\n\n                                s->mv[i][j][0]      = val;\n\n                                av_dlog(s->avctx, \"fmx=%d\\n\", val);\n\n                                val = mpeg_decode_motion(s, s->mpeg_f_code[i][1],\n\n                                                         s->last_mv[i][j][1] >> 1);\n\n                                s->last_mv[i][j][1] = 2 * val;\n\n                                s->mv[i][j][1]      = val;\n\n                                av_dlog(s->avctx, \"fmy=%d\\n\", val);\n\n                            }\n\n                        }\n\n                    }\n\n                } else {\n\n                    av_assert0(!s->progressive_sequence);\n\n                    mb_type |= MB_TYPE_16x16 | MB_TYPE_INTERLACED;\n\n                    for (i = 0; i < 2; i++) {\n\n                        if (USES_LIST(mb_type, i)) {\n\n                            s->field_select[i][0] = get_bits1(&s->gb);\n\n                            for (k = 0; k < 2; k++) {\n\n                                val = mpeg_decode_motion(s, s->mpeg_f_code[i][k],\n\n                                                         s->last_mv[i][0][k]);\n\n                                s->last_mv[i][0][k] = val;\n\n                                s->last_mv[i][1][k] = val;\n\n                                s->mv[i][0][k]      = val;\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n                break;\n\n            case MT_DMV:\n\n                if (s->progressive_sequence){\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"MT_DMV in progressive_sequence\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                s->mv_type = MV_TYPE_DMV;\n\n                for (i = 0; i < 2; i++) {\n\n                    if (USES_LIST(mb_type, i)) {\n\n                        int dmx, dmy, mx, my, m;\n\n                        const int my_shift = s->picture_structure == PICT_FRAME;\n\n\n\n                        mx = mpeg_decode_motion(s, s->mpeg_f_code[i][0],\n\n                                                s->last_mv[i][0][0]);\n\n                        s->last_mv[i][0][0] = mx;\n\n                        s->last_mv[i][1][0] = mx;\n\n                        dmx = get_dmv(s);\n\n                        my  = mpeg_decode_motion(s, s->mpeg_f_code[i][1],\n\n                                                 s->last_mv[i][0][1] >> my_shift);\n\n                        dmy = get_dmv(s);\n\n\n\n\n\n                        s->last_mv[i][0][1] = my << my_shift;\n\n                        s->last_mv[i][1][1] = my << my_shift;\n\n\n\n                        s->mv[i][0][0] = mx;\n\n                        s->mv[i][0][1] = my;\n\n                        s->mv[i][1][0] = mx; // not used\n\n                        s->mv[i][1][1] = my; // not used\n\n\n\n                        if (s->picture_structure == PICT_FRAME) {\n\n                            mb_type |= MB_TYPE_16x16 | MB_TYPE_INTERLACED;\n\n\n\n                            // m = 1 + 2 * s->top_field_first;\n\n                            m = s->top_field_first ? 1 : 3;\n\n\n\n                            /* top -> top pred */\n\n                            s->mv[i][2][0] = ((mx * m + (mx > 0)) >> 1) + dmx;\n\n                            s->mv[i][2][1] = ((my * m + (my > 0)) >> 1) + dmy - 1;\n\n                            m = 4 - m;\n\n                            s->mv[i][3][0] = ((mx * m + (mx > 0)) >> 1) + dmx;\n\n                            s->mv[i][3][1] = ((my * m + (my > 0)) >> 1) + dmy + 1;\n\n                        } else {\n\n                            mb_type |= MB_TYPE_16x16;\n\n\n\n                            s->mv[i][2][0] = ((mx + (mx > 0)) >> 1) + dmx;\n\n                            s->mv[i][2][1] = ((my + (my > 0)) >> 1) + dmy;\n\n                            if (s->picture_structure == PICT_TOP_FIELD)\n\n                                s->mv[i][2][1]--;\n\n                            else\n\n                                s->mv[i][2][1]++;\n\n                        }\n\n                    }\n\n                }\n\n                break;\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"00 motion_type at %d %d\\n\", s->mb_x, s->mb_y);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n\n\n        s->mb_intra = 0;\n\n        if (HAS_CBP(mb_type)) {\n\n            s->bdsp.clear_blocks(s->block[0]);\n\n\n\n            cbp = get_vlc2(&s->gb, ff_mb_pat_vlc.table, MB_PAT_VLC_BITS, 1);\n\n            if (mb_block_count > 6) {\n\n                cbp <<= mb_block_count - 6;\n\n                cbp  |= get_bits(&s->gb, mb_block_count - 6);\n\n                s->bdsp.clear_blocks(s->block[6]);\n\n            }\n\n            if (cbp <= 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"invalid cbp %d at %d %d\\n\", cbp, s->mb_x, s->mb_y);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            // if 1, we memcpy blocks in xvmcvideo\n\n            if ((CONFIG_MPEG1_XVMC_HWACCEL || CONFIG_MPEG2_XVMC_HWACCEL) && s->pack_pblocks)\n\n                ff_xvmc_pack_pblocks(s, cbp);\n\n\n\n            if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n                if (s->flags2 & CODEC_FLAG2_FAST) {\n\n                    for (i = 0; i < 6; i++) {\n\n                        if (cbp & 32)\n\n                            mpeg2_fast_decode_block_non_intra(s, *s->pblocks[i], i);\n\n                        else\n\n                            s->block_last_index[i] = -1;\n\n                        cbp += cbp;\n\n                    }\n\n                } else {\n\n                    cbp <<= 12 - mb_block_count;\n\n\n\n                    for (i = 0; i < mb_block_count; i++) {\n\n                        if (cbp & (1 << 11)) {\n\n                            if ((ret = mpeg2_decode_block_non_intra(s, *s->pblocks[i], i)) < 0)\n\n                                return ret;\n\n                        } else {\n\n                            s->block_last_index[i] = -1;\n\n                        }\n\n                        cbp += cbp;\n\n                    }\n\n                }\n\n            } else {\n\n                if (s->flags2 & CODEC_FLAG2_FAST) {\n\n                    for (i = 0; i < 6; i++) {\n\n                        if (cbp & 32)\n\n                            mpeg1_fast_decode_block_inter(s, *s->pblocks[i], i);\n\n                        else\n\n                            s->block_last_index[i] = -1;\n\n                        cbp += cbp;\n\n                    }\n\n                } else {\n\n                    for (i = 0; i < 6; i++) {\n\n                        if (cbp & 32) {\n\n                            if ((ret = mpeg1_decode_block_inter(s, *s->pblocks[i], i)) < 0)\n\n                                return ret;\n\n                        } else {\n\n                            s->block_last_index[i] = -1;\n\n                        }\n\n                        cbp += cbp;\n\n                    }\n\n                }\n\n            }\n\n        } else {\n\n            for (i = 0; i < 12; i++)\n\n                s->block_last_index[i] = -1;\n\n        }\n\n    }\n\n\n\n    s->current_picture.mb_type[s->mb_x + s->mb_y * s->mb_stride] = mb_type;\n\n\n\n    return 0;\n\n}\n", "idx": 8562, "_split": "valid", "_hash": "d40ffd460d9a01ab756c74ed197285a9"}
{"project": "FFmpeg", "commit_id": "baf4c489e5f468a208596cd128a6f1c49e6ae35b", "target": 0, "func": "int avio_printf(AVIOContext *s, const char *fmt, ...)\n\n{\n\n    va_list ap;\n\n    char buf[4096];\n\n    int ret;\n\n\n\n    va_start(ap, fmt);\n\n    ret = vsnprintf(buf, sizeof(buf), fmt, ap);\n\n    va_end(ap);\n\n    avio_write(s, buf, strlen(buf));\n\n    return ret;\n\n}\n", "idx": 8573, "_split": "valid", "_hash": "a17d277f72063ef69baf372d741d53e0"}
{"project": "FFmpeg", "commit_id": "5127f465bd3e2cf9cbf66dea3cf7b481b522d266", "target": 1, "func": "static void vmd_decode(VmdVideoContext *s)\n\n{\n\n    int i;\n\n    unsigned int *palette32;\n\n    unsigned char r, g, b;\n\n\n\n    /* point to the start of the encoded data */\n\n    const unsigned char *p = s->buf + 16;\n\n\n\n    const unsigned char *pb;\n\n    unsigned char meth;\n\n    unsigned char *dp;   /* pointer to current frame */\n\n    unsigned char *pp;   /* pointer to previous frame */\n\n    unsigned char len;\n\n    int ofs;\n\n\n\n    int frame_x, frame_y;\n\n    int frame_width, frame_height;\n\n\n\n    frame_x = AV_RL16(&s->buf[6]);\n\n    frame_y = AV_RL16(&s->buf[8]);\n\n    frame_width = AV_RL16(&s->buf[10]) - frame_x + 1;\n\n    frame_height = AV_RL16(&s->buf[12]) - frame_y + 1;\n\n    if (frame_x < 0 || frame_width < 0 ||\n\n        frame_x >= s->avctx->width ||\n\n        frame_width > s->avctx->width ||\n\n        frame_x + frame_width > s->avctx->width)\n\n        return;\n\n    if (frame_y < 0 || frame_height < 0 ||\n\n        frame_y >= s->avctx->height ||\n\n        frame_height > s->avctx->height ||\n\n        frame_y + frame_height > s->avctx->height)\n\n        return;\n\n\n\n    if ((frame_width == s->avctx->width && frame_height == s->avctx->height) &&\n\n        (frame_x || frame_y)) {\n\n\n\n        s->x_off = frame_x;\n\n        s->y_off = frame_y;\n\n    }\n\n    frame_x -= s->x_off;\n\n    frame_y -= s->y_off;\n\n\n\n    /* if only a certain region will be updated, copy the entire previous\n\n     * frame before the decode */\n\n    if (s->prev_frame.data[0] &&\n\n        (frame_x || frame_y || (frame_width != s->avctx->width) ||\n\n        (frame_height != s->avctx->height))) {\n\n\n\n        memcpy(s->frame.data[0], s->prev_frame.data[0],\n\n            s->avctx->height * s->frame.linesize[0]);\n\n    }\n\n\n\n    /* check if there is a new palette */\n\n    if (s->buf[15] & 0x02) {\n\n        p += 2;\n\n        palette32 = (unsigned int *)s->palette;\n\n        for (i = 0; i < PALETTE_COUNT; i++) {\n\n            r = *p++ * 4;\n\n            g = *p++ * 4;\n\n            b = *p++ * 4;\n\n            palette32[i] = (r << 16) | (g << 8) | (b);\n\n        }\n\n        s->size -= (256 * 3 + 2);\n\n    }\n\n    if (s->size >= 0) {\n\n        /* originally UnpackFrame in VAG's code */\n\n        pb = p;\n\n        meth = *pb++;\n\n        if (meth & 0x80) {\n\n            lz_unpack(pb, s->unpack_buffer, s->unpack_buffer_size);\n\n            meth &= 0x7F;\n\n            pb = s->unpack_buffer;\n\n        }\n\n\n\n        dp = &s->frame.data[0][frame_y * s->frame.linesize[0] + frame_x];\n\n        pp = &s->prev_frame.data[0][frame_y * s->prev_frame.linesize[0] + frame_x];\n\n        switch (meth) {\n\n        case 1:\n\n            for (i = 0; i < frame_height; i++) {\n\n                ofs = 0;\n\n                do {\n\n                    len = *pb++;\n\n                    if (len & 0x80) {\n\n                        len = (len & 0x7F) + 1;\n\n                        if (ofs + len > frame_width)\n\n                            return;\n\n                        memcpy(&dp[ofs], pb, len);\n\n                        pb += len;\n\n                        ofs += len;\n\n                    } else {\n\n                        /* interframe pixel copy */\n\n                        if (ofs + len + 1 > frame_width || !s->prev_frame.data[0])\n\n                            return;\n\n                        memcpy(&dp[ofs], &pp[ofs], len + 1);\n\n                        ofs += len + 1;\n\n                    }\n\n                } while (ofs < frame_width);\n\n                if (ofs > frame_width) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"VMD video: offset > width (%d > %d)\\n\",\n\n                        ofs, frame_width);\n\n                    break;\n\n                }\n\n                dp += s->frame.linesize[0];\n\n                pp += s->prev_frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case 2:\n\n            for (i = 0; i < frame_height; i++) {\n\n                memcpy(dp, pb, frame_width);\n\n                pb += frame_width;\n\n                dp += s->frame.linesize[0];\n\n                pp += s->prev_frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case 3:\n\n            for (i = 0; i < frame_height; i++) {\n\n                ofs = 0;\n\n                do {\n\n                    len = *pb++;\n\n                    if (len & 0x80) {\n\n                        len = (len & 0x7F) + 1;\n\n                        if (*pb++ == 0xFF)\n\n                            len = rle_unpack(pb, &dp[ofs], len, frame_width - ofs);\n\n                        else\n\n                            memcpy(&dp[ofs], pb, len);\n\n                        pb += len;\n\n                        ofs += len;\n\n                    } else {\n\n                        /* interframe pixel copy */\n\n                        if (ofs + len + 1 > frame_width || !s->prev_frame.data[0])\n\n                            return;\n\n                        memcpy(&dp[ofs], &pp[ofs], len + 1);\n\n                        ofs += len + 1;\n\n                    }\n\n                } while (ofs < frame_width);\n\n                if (ofs > frame_width) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"VMD video: offset > width (%d > %d)\\n\",\n\n                        ofs, frame_width);\n\n                }\n\n                dp += s->frame.linesize[0];\n\n                pp += s->prev_frame.linesize[0];\n\n            }\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 8602, "_split": "valid", "_hash": "3119326e43b87d153770325e9d68d8b2"}
{"project": "FFmpeg", "commit_id": "c64b2d480b4a35d4face9928b4265a0fda3f3dd9", "target": 1, "func": "static int get_stats(AVCodecContext *avctx, int eos)\n\n{\n\n#ifdef TH_ENCCTL_2PASS_OUT\n\n    TheoraContext *h = avctx->priv_data;\n\n    uint8_t *buf;\n\n    int bytes;\n\n\n\n    bytes = th_encode_ctl(h->t_state, TH_ENCCTL_2PASS_OUT, &buf, sizeof(buf));\n\n    if (bytes < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting first pass stats\\n\");\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n    if (!eos) {\n\n        void *tmp = av_fast_realloc(h->stats, &h->stats_size,\n\n                                   h->stats_offset + bytes);\n\n        if (!tmp)\n\n\n        h->stats = tmp;\n\n        memcpy(h->stats + h->stats_offset, buf, bytes);\n\n        h->stats_offset += bytes;\n\n    } else {\n\n        int b64_size = AV_BASE64_SIZE(h->stats_offset);\n\n        // libtheora generates a summary header at the end\n\n        memcpy(h->stats, buf, bytes);\n\n        avctx->stats_out = av_malloc(b64_size);\n\n\n\n        av_base64_encode(avctx->stats_out, b64_size, h->stats, h->stats_offset);\n\n    }\n\n    return 0;\n\n#else\n\n    av_log(avctx, AV_LOG_ERROR, \"libtheora too old to support 2pass\\n\");\n\n    return AVERROR(ENOSUP);\n\n#endif\n\n}", "idx": 8694, "_split": "valid", "_hash": "8a67c438835f42774ca98565e9265712"}
{"project": "FFmpeg", "commit_id": "3920d1387834e2bc334aff9f518f4beb24e470bd", "target": 1, "func": "static int allocate_buffers(ALACContext *alac)\n\n{\n\n    int ch;\n\n    int buf_size = alac->max_samples_per_frame * sizeof(int32_t);\n\n\n\n    for (ch = 0; ch < FFMIN(alac->channels, 2); ch++) {\n\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->predict_error_buffer[ch],\n\n                         buf_size, buf_alloc_fail);\n\n\n\n        alac->direct_output = alac->sample_size > 16 && av_sample_fmt_is_planar(alac->avctx->sample_fmt);\n\n        if (!alac->direct_output) {\n\n            FF_ALLOC_OR_GOTO(alac->avctx, alac->output_samples_buffer[ch],\n\n                             buf_size, buf_alloc_fail);\n\n        }\n\n\n\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->extra_bits_buffer[ch],\n\n                         buf_size, buf_alloc_fail);\n\n    }\n\n    return 0;\n\nbuf_alloc_fail:\n\n    alac_decode_close(alac->avctx);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 8702, "_split": "valid", "_hash": "dca029534ffeeaf5309e7876d5eaf8c2"}
{"project": "FFmpeg", "commit_id": "5c3079aaa94ba8140fc727b5533b75b5b337b2bb", "target": 1, "func": "static av_cold int iss_read_header(AVFormatContext *s)\n\n{\n\n    IssDemuxContext *iss = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    char token[MAX_TOKEN_SIZE];\n\n    int stereo, rate_divisor;\n\n\n\n    get_token(pb, token, sizeof(token)); //\"IMA_ADPCM_Sound\"\n\n    get_token(pb, token, sizeof(token)); //packet size\n\n    sscanf(token, \"%d\", &iss->packet_size);\n\n    get_token(pb, token, sizeof(token)); //File ID\n\n    get_token(pb, token, sizeof(token)); //out size\n\n    get_token(pb, token, sizeof(token)); //stereo\n\n    sscanf(token, \"%d\", &stereo);\n\n    get_token(pb, token, sizeof(token)); //Unknown1\n\n    get_token(pb, token, sizeof(token)); //RateDivisor\n\n    sscanf(token, \"%d\", &rate_divisor);\n\n    get_token(pb, token, sizeof(token)); //Unknown2\n\n    get_token(pb, token, sizeof(token)); //Version ID\n\n    get_token(pb, token, sizeof(token)); //Size\n\n\n\n    if (iss->packet_size <= 0) {\n\n        av_log(s, AV_LOG_ERROR, \"packet_size %d is invalid\\n\", iss->packet_size);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    iss->sample_start_pos = avio_tell(pb);\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_id = AV_CODEC_ID_ADPCM_IMA_ISS;\n\n    if (stereo) {\n\n        st->codec->channels       = 2;\n\n        st->codec->channel_layout = AV_CH_LAYOUT_STEREO;\n\n    } else {\n\n        st->codec->channels       = 1;\n\n        st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n    }\n\n    st->codec->sample_rate = 44100;\n\n    if(rate_divisor > 0)\n\n         st->codec->sample_rate /= rate_divisor;\n\n    st->codec->bits_per_coded_sample = 4;\n\n    st->codec->bit_rate = st->codec->channels * st->codec->sample_rate\n\n                                      * st->codec->bits_per_coded_sample;\n\n    st->codec->block_align = iss->packet_size;\n\n    avpriv_set_pts_info(st, 32, 1, st->codec->sample_rate);\n\n\n\n    return 0;\n\n}\n", "idx": 8712, "_split": "valid", "_hash": "fbaefe294e4b8dbc4fb7b6cf404b7aa1"}
{"project": "FFmpeg", "commit_id": "37c506e8b94d2691539bc29ef861903503a99b82", "target": 1, "func": "static int mmsh_open(URLContext *h, const char *uri, int flags)\n\n{\n\n    int i, port, err;\n\n    char httpname[256], path[256], host[128], location[1024];\n\n    char *stream_selection;\n\n    char headers[1024];\n\n    MMSHContext *mmsh;\n\n    MMSContext *mms;\n\n\n\n    mmsh = h->priv_data = av_mallocz(sizeof(MMSHContext));\n\n    if (!h->priv_data)\n\n        return AVERROR(ENOMEM);\n\n    mmsh->request_seq = h->is_streamed = 1;\n\n    mms = &mmsh->mms;\n\n    av_strlcpy(location, uri, sizeof(location));\n\n\n\n    av_url_split(NULL, 0, NULL, 0,\n\n        host, sizeof(host), &port, path, sizeof(path), location);\n\n    if (port<0)\n\n        port = 80; // default mmsh protocol port\n\n    ff_url_join(httpname, sizeof(httpname), \"http\", NULL, host, port, path);\n\n\n\n    if (url_alloc(&mms->mms_hd, httpname, URL_RDONLY) < 0) {\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    snprintf(headers, sizeof(headers),\n\n             \"Accept: */*\\r\\n\"\n\n             USERAGENT\n\n             \"Host: %s:%d\\r\\n\"\n\n             \"Pragma: no-cache,rate=1.000000,stream-time=0,\"\n\n             \"stream-offset=0:0,request-context=%u,max-duration=0\\r\\n\"\n\n             CLIENTGUID\n\n             \"Connection: Close\\r\\n\\r\\n\",\n\n             host, port, mmsh->request_seq++);\n\n    ff_http_set_headers(mms->mms_hd, headers);\n\n\n\n    err = url_connect(mms->mms_hd);\n\n    if (err) {\n\n        goto fail;\n\n    }\n\n    err = get_http_header_data(mmsh);\n\n    if (err) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Get http header data failed!\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    // close the socket and then reopen it for sending the second play request.\n\n    url_close(mms->mms_hd);\n\n    memset(headers, 0, sizeof(headers));\n\n    if (url_alloc(&mms->mms_hd, httpname, URL_RDONLY) < 0) {\n\n        return AVERROR(EIO);\n\n    }\n\n    stream_selection = av_mallocz(mms->stream_num * 19 + 1);\n\n    if (!stream_selection)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < mms->stream_num; i++) {\n\n        char tmp[20];\n\n        err = snprintf(tmp, sizeof(tmp), \"ffff:%d:0 \", mms->streams[i].id);\n\n        if (err < 0)\n\n            goto fail;\n\n        av_strlcat(stream_selection, tmp, mms->stream_num * 19 + 1);\n\n    }\n\n    // send play request\n\n    err = snprintf(headers, sizeof(headers),\n\n                   \"Accept: */*\\r\\n\"\n\n                   USERAGENT\n\n                   \"Host: %s:%d\\r\\n\"\n\n                   \"Pragma: no-cache,rate=1.000000,request-context=%u\\r\\n\"\n\n                   \"Pragma: xPlayStrm=1\\r\\n\"\n\n                   CLIENTGUID\n\n                   \"Pragma: stream-switch-count=%d\\r\\n\"\n\n                   \"Pragma: stream-switch-entry=%s\\r\\n\"\n\n                   \"Connection: Close\\r\\n\\r\\n\",\n\n                   host, port, mmsh->request_seq++, mms->stream_num, stream_selection);\n\n    av_freep(&stream_selection);\n\n    if (err < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Build play request failed!\\n\");\n\n        goto fail;\n\n    }\n\n    dprintf(NULL, \"out_buffer is %s\", headers);\n\n    ff_http_set_headers(mms->mms_hd, headers);\n\n\n\n    err = url_connect(mms->mms_hd);\n\n    if (err) {\n\n          goto fail;\n\n    }\n\n\n\n    err = get_http_header_data(mmsh);\n\n    if (err) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Get http header data failed!\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    dprintf(NULL, \"Connection successfully open\\n\");\n\n    return 0;\n\nfail:\n\n    av_freep(&stream_selection);\n\n    mmsh_close(h);\n\n    dprintf(NULL, \"Connection failed with error %d\\n\", err);\n\n    return err;\n\n}\n", "idx": 8735, "_split": "valid", "_hash": "37c3751d8f63d31acca68582e0b18704"}
{"project": "FFmpeg", "commit_id": "631c56a8e46dea41585f3e7b3ef9c52b49faa385", "target": 0, "func": "int ff_network_init(void)\n\n{\n\n#if HAVE_WINSOCK2_H\n\n    WSADATA wsaData;\n\n#endif\n\n\n\n    if (!ff_network_inited_globally)\n\n        av_log(NULL, AV_LOG_WARNING, \"Using network protocols without global \"\n\n                                     \"network initialization. Please use \"\n\n                                     \"avformat_network_init(), this will \"\n\n                                     \"become mandatory later.\\n\");\n\n#if HAVE_WINSOCK2_H\n\n    if (WSAStartup(MAKEWORD(1,1), &wsaData))\n\n        return 0;\n\n#endif\n\n    return 1;\n\n}\n", "idx": 8801, "_split": "valid", "_hash": "e618eb74d28a7782d0a44d0415c3055a"}
{"project": "FFmpeg", "commit_id": "e83aae283975ad5657c626912f9f225d7fe673f0", "target": 1, "func": "static int handle_connect_error(URLContext *s, const char *desc)\n\n{\n\n    RTMPContext *rt = s->priv_data;\n\n    char buf[300], *ptr, authmod[15];\n\n    int i = 0, ret = 0;\n\n    const char *user = \"\", *salt = \"\", *opaque = NULL,\n\n               *challenge = NULL, *cptr = NULL, *nonce = NULL;\n\n\n\n    if (!(cptr = strstr(desc, \"authmod=adobe\")) &&\n\n        !(cptr = strstr(desc, \"authmod=llnw\"))) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"Unknown connect error (unsupported authentication method?)\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n    cptr += strlen(\"authmod=\");\n\n    while (*cptr && *cptr != ' ' && i < sizeof(authmod) - 1)\n\n        authmod[i++] = *cptr++;\n\n    authmod[i] = '\\0';\n\n\n\n    if (!rt->username[0] || !rt->password[0]) {\n\n        av_log(s, AV_LOG_ERROR, \"No credentials set\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if (strstr(desc, \"?reason=authfailed\")) {\n\n        av_log(s, AV_LOG_ERROR, \"Incorrect username/password\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    } else if (strstr(desc, \"?reason=nosuchuser\")) {\n\n        av_log(s, AV_LOG_ERROR, \"Incorrect username\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if (rt->auth_tried) {\n\n        av_log(s, AV_LOG_ERROR, \"Authentication failed\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    rt->auth_params[0] = '\\0';\n\n\n\n    if (strstr(desc, \"code=403 need auth\")) {\n\n        snprintf(rt->auth_params, sizeof(rt->auth_params),\n\n                 \"?authmod=%s&user=%s\", authmod, rt->username);\n\n        return 0;\n\n    }\n\n\n\n    if (!(cptr = strstr(desc, \"?reason=needauth\"))) {\n\n        av_log(s, AV_LOG_ERROR, \"No auth parameters found\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    av_strlcpy(buf, cptr + 1, sizeof(buf));\n\n    ptr = buf;\n\n\n\n    while (ptr) {\n\n        char *next  = strchr(ptr, '&');\n\n        char *value = strchr(ptr, '=');\n\n        if (next)\n\n            *next++ = '\\0';\n\n        if (value)\n\n            *value++ = '\\0';\n\n        if (!strcmp(ptr, \"user\")) {\n\n            user = value;\n\n        } else if (!strcmp(ptr, \"salt\")) {\n\n            salt = value;\n\n        } else if (!strcmp(ptr, \"opaque\")) {\n\n            opaque = value;\n\n        } else if (!strcmp(ptr, \"challenge\")) {\n\n            challenge = value;\n\n        } else if (!strcmp(ptr, \"nonce\")) {\n\n            nonce = value;\n\n        }\n\n        ptr = next;\n\n    }\n\n\n\n    if (!strcmp(authmod, \"adobe\")) {\n\n        if ((ret = do_adobe_auth(rt, user, salt, opaque, challenge)) < 0)\n\n            return ret;\n\n    } else {\n\n        if ((ret = do_llnw_auth(rt, user, nonce)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    rt->auth_tried = 1;\n\n    return 0;\n\n}\n", "idx": 8802, "_split": "valid", "_hash": "bd227348f9ee4e10ca95e7d5f8bd1332"}
{"project": "FFmpeg", "commit_id": "90fc00a623de44e137fe1601b91356e8cd8bdd54", "target": 1, "func": "static int jacosub_probe(AVProbeData *p)\n\n{\n\n    const char *ptr     = p->buf;\n\n    const char *ptr_end = p->buf + p->buf_size;\n\n\n\n    if (AV_RB24(ptr) == 0xEFBBBF)\n\n        ptr += 3; /* skip UTF-8 BOM */\n\n\n\n    while (ptr < ptr_end) {\n\n        while (jss_whitespace(*ptr))\n\n            ptr++;\n\n        if (*ptr != '#' && *ptr != '\\n') {\n\n            if (timed_line(ptr))\n\n                return AVPROBE_SCORE_EXTENSION + 1;\n\n            return 0;\n\n        }\n\n        ptr += strcspn(ptr, \"\\n\") + 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 8803, "_split": "valid", "_hash": "640a8ef30b0fa9cffb71a27faa793293"}
{"project": "FFmpeg", "commit_id": "e0966eb140b3569b3d6b5b5008961944ef229c06", "target": 1, "func": "static void vp6_parse_coeff(VP56Context *s)\n\n{\n\n    VP56RangeCoder *c = s->ccp;\n\n    VP56Model *model = s->modelp;\n\n    uint8_t *permute = s->scantable.permutated;\n\n    uint8_t *model1, *model2, *model3;\n\n    int coeff, sign, coeff_idx;\n\n    int b, i, cg, idx, ctx;\n\n    int pt = 0;    /* plane type (0 for Y, 1 for U or V) */\n\n\n\n    for (b=0; b<6; b++) {\n\n        int ct = 1;    /* code type */\n\n        int run = 1;\n\n\n\n        if (b > 3) pt = 1;\n\n\n\n        ctx = s->left_block[vp56_b6to4[b]].not_null_dc\n\n              + s->above_blocks[s->above_block_idx[b]].not_null_dc;\n\n        model1 = model->coeff_dccv[pt];\n\n        model2 = model->coeff_dcct[pt][ctx];\n\n\n\n        for (coeff_idx=0; coeff_idx<64; ) {\n\n            if ((coeff_idx>1 && ct==0) || vp56_rac_get_prob(c, model2[0])) {\n\n                /* parse a coeff */\n\n                if (vp56_rac_get_prob(c, model2[2])) {\n\n                    if (vp56_rac_get_prob(c, model2[3])) {\n\n                        idx = vp56_rac_get_tree(c, vp56_pc_tree, model1);\n\n                        coeff = vp56_coeff_bias[idx+5];\n\n                        for (i=vp56_coeff_bit_length[idx]; i>=0; i--)\n\n                            coeff += vp56_rac_get_prob(c, vp56_coeff_parse_table[idx][i]) << i;\n\n                    } else {\n\n                        if (vp56_rac_get_prob(c, model2[4]))\n\n                            coeff = 3 + vp56_rac_get_prob(c, model1[5]);\n\n                        else\n\n                            coeff = 2;\n\n                    }\n\n                    ct = 2;\n\n                } else {\n\n                    ct = 1;\n\n                    coeff = 1;\n\n                }\n\n                sign = vp56_rac_get(c);\n\n                coeff = (coeff ^ -sign) + sign;\n\n                if (coeff_idx)\n\n                    coeff *= s->dequant_ac;\n\n                idx = model->coeff_index_to_pos[coeff_idx];\n\n                s->block_coeff[b][permute[idx]] = coeff;\n\n                run = 1;\n\n            } else {\n\n                /* parse a run */\n\n                ct = 0;\n\n                if (coeff_idx > 0) {\n\n                    if (!vp56_rac_get_prob(c, model2[1]))\n\n                        break;\n\n\n\n                    model3 = model->coeff_runv[coeff_idx >= 6];\n\n                    run = vp56_rac_get_tree(c, vp6_pcr_tree, model3);\n\n                    if (!run)\n\n                        for (run=9, i=0; i<6; i++)\n\n                            run += vp56_rac_get_prob(c, model3[i+8]) << i;\n\n                }\n\n            }\n\n\n\n            cg = vp6_coeff_groups[coeff_idx+=run];\n\n            model1 = model2 = model->coeff_ract[pt][ct][cg];\n\n        }\n\n\n\n        s->left_block[vp56_b6to4[b]].not_null_dc =\n\n        s->above_blocks[s->above_block_idx[b]].not_null_dc = !!s->block_coeff[b][0];\n\n    }\n\n}\n", "idx": 8809, "_split": "valid", "_hash": "6bba569f038f8b9fccdc6a5fe39ed09f"}
{"project": "FFmpeg", "commit_id": "698f4cc7f0af0ba9ef54b01cfffd1f02d7aa5d05", "target": 0, "func": "int av_write_header(AVFormatContext *s)\n\n{\n\n    int ret, i;\n\n    AVStream *st;\n\n\n\n    // some sanity checks\n\n    if (s->nb_streams == 0) {\n\n        av_log(s, AV_LOG_ERROR, \"no streams\\n\");\n\n        return -1;\n\n    }\n\n\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        st = s->streams[i];\n\n\n\n        switch (st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            if(st->codec->sample_rate<=0){\n\n                av_log(s, AV_LOG_ERROR, \"sample rate not set\\n\");\n\n                return -1;\n\n            }\n\n            if(!st->codec->block_align)\n\n                st->codec->block_align = st->codec->channels *\n\n                    av_get_bits_per_sample(st->codec->codec_id) >> 3;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if(st->codec->time_base.num<=0 || st->codec->time_base.den<=0){ //FIXME audio too?\n\n                av_log(s, AV_LOG_ERROR, \"time base not set\\n\");\n\n                return -1;\n\n            }\n\n            if((st->codec->width<=0 || st->codec->height<=0) && !(s->oformat->flags & AVFMT_NODIMENSIONS)){\n\n                av_log(s, AV_LOG_ERROR, \"dimensions not set\\n\");\n\n                return -1;\n\n            }\n\n            if(av_cmp_q(st->sample_aspect_ratio, st->codec->sample_aspect_ratio)){\n\n                av_log(s, AV_LOG_ERROR, \"Aspect ratio mismatch between encoder and muxer layer\\n\");\n\n                return -1;\n\n            }\n\n            break;\n\n        }\n\n\n\n        if(s->oformat->codec_tag){\n\n            if(st->codec->codec_tag){\n\n                //FIXME\n\n                //check that tag + id is in the table\n\n                //if neither is in the table -> OK\n\n                //if tag is in the table with another id -> FAIL\n\n                //if id is in the table with another tag -> FAIL unless strict < ?\n\n            }else\n\n                st->codec->codec_tag= av_codec_get_tag(s->oformat->codec_tag, st->codec->codec_id);\n\n        }\n\n\n\n        if(s->oformat->flags & AVFMT_GLOBALHEADER &&\n\n            !(st->codec->flags & CODEC_FLAG_GLOBAL_HEADER))\n\n          av_log(s, AV_LOG_WARNING, \"Codec for stream %d does not use global headers but container format requires global headers\\n\", i);\n\n    }\n\n\n\n    if (!s->priv_data && s->oformat->priv_data_size > 0) {\n\n        s->priv_data = av_mallocz(s->oformat->priv_data_size);\n\n        if (!s->priv_data)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n#if LIBAVFORMAT_VERSION_MAJOR < 53\n\n    ff_metadata_mux_compat(s);\n\n#endif\n\n\n\n    /* set muxer identification string */\n\n    if (!(s->streams[0]->codec->flags & CODEC_FLAG_BITEXACT)) {\n\n        AVMetadata *m;\n\n        AVMetadataTag *t;\n\n\n\n        if (!(m = av_mallocz(sizeof(AVMetadata))))\n\n            return AVERROR(ENOMEM);\n\n        av_metadata_set2(&m, \"encoder\", LIBAVFORMAT_IDENT, 0);\n\n        metadata_conv(&m, s->oformat->metadata_conv, NULL);\n\n        if ((t = av_metadata_get(m, \"\", NULL, AV_METADATA_IGNORE_SUFFIX)))\n\n            av_metadata_set2(&s->metadata, t->key, t->value, 0);\n\n        av_metadata_free(&m);\n\n    }\n\n\n\n    if(s->oformat->write_header){\n\n        ret = s->oformat->write_header(s);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    /* init PTS generation */\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        int64_t den = AV_NOPTS_VALUE;\n\n        st = s->streams[i];\n\n\n\n        switch (st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            den = (int64_t)st->time_base.num * st->codec->sample_rate;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            den = (int64_t)st->time_base.num * st->codec->time_base.den;\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n        if (den != AV_NOPTS_VALUE) {\n\n            if (den <= 0)\n\n                return AVERROR_INVALIDDATA;\n\n            av_frac_init(&st->pts, 0, 0, den);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 8881, "_split": "valid", "_hash": "89d6e3945e760fafbfc6c2ff9e11e3cf"}
{"project": "FFmpeg", "commit_id": "ce326c11308c380f30e580cb05e6e210b6344fc7", "target": 1, "func": "static int transcode_video(InputStream *ist, AVPacket *pkt, int *got_output, int64_t *pkt_pts)\n\n{\n\n    AVFrame *decoded_frame, *filtered_frame = NULL;\n\n    void *buffer_to_free = NULL;\n\n    int i, ret = 0;\n\n    float quality;\n\n#if CONFIG_AVFILTER\n\n    int frame_available = 1;\n\n#endif\n\n\n\n    if (!ist->decoded_frame && !(ist->decoded_frame = avcodec_alloc_frame()))\n\n        return AVERROR(ENOMEM);\n\n    else\n\n        avcodec_get_frame_defaults(ist->decoded_frame);\n\n    decoded_frame = ist->decoded_frame;\n\n    pkt->pts  = *pkt_pts;\n\n    pkt->dts  = ist->last_dts;\n\n    *pkt_pts  = AV_NOPTS_VALUE;\n\n\n\n    ret = avcodec_decode_video2(ist->st->codec,\n\n                                decoded_frame, got_output, pkt);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    quality = same_quant ? decoded_frame->quality : 0;\n\n    if (!*got_output) {\n\n        /* no picture yet */\n\n        return ret;\n\n    }\n\n    decoded_frame->pts = guess_correct_pts(&ist->pts_ctx, decoded_frame->pkt_pts,\n\n                                           decoded_frame->pkt_dts);\n\n    pkt->size = 0;\n\n    pre_process_video_frame(ist, (AVPicture *)decoded_frame, &buffer_to_free);\n\n\n\n    rate_emu_sleep(ist);\n\n\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        OutputStream *ost = &output_streams[i];\n\n        int frame_size, resample_changed;\n\n\n\n        if (!check_output_constraints(ist, ost) || !ost->encoding_needed)\n\n            continue;\n\n\n\n#if CONFIG_AVFILTER\n\n        resample_changed = ost->resample_width   != decoded_frame->width  ||\n\n                           ost->resample_height  != decoded_frame->height ||\n\n                           ost->resample_pix_fmt != decoded_frame->format;\n\n        if (resample_changed) {\n\n            av_log(NULL, AV_LOG_INFO,\n\n                    \"Input stream #%d:%d frame changed from size:%dx%d fmt:%s to size:%dx%d fmt:%s\\n\",\n\n                    ist->file_index, ist->st->index,\n\n                    ost->resample_width,  ost->resample_height,  av_get_pix_fmt_name(ost->resample_pix_fmt),\n\n                    decoded_frame->width, decoded_frame->height, av_get_pix_fmt_name(decoded_frame->format));\n\n\n\n            avfilter_graph_free(&ost->graph);\n\n            if (configure_video_filters(ist, ost)) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Error reinitializing filters!\\n\");\n\n                exit_program(1);\n\n            }\n\n\n\n            ost->resample_width   = decoded_frame->width;\n\n            ost->resample_height  = decoded_frame->height;\n\n            ost->resample_pix_fmt = decoded_frame->format;\n\n        }\n\n\n\n        if (ist->st->sample_aspect_ratio.num)\n\n            decoded_frame->sample_aspect_ratio = ist->st->sample_aspect_ratio;\n\n        if (ist->st->codec->codec->capabilities & CODEC_CAP_DR1) {\n\n            FrameBuffer      *buf = decoded_frame->opaque;\n\n            AVFilterBufferRef *fb = avfilter_get_video_buffer_ref_from_arrays(\n\n                                        decoded_frame->data, decoded_frame->linesize,\n\n                                        AV_PERM_READ | AV_PERM_PRESERVE,\n\n                                        ist->st->codec->width, ist->st->codec->height,\n\n                                        ist->st->codec->pix_fmt);\n\n\n\n            avfilter_copy_frame_props(fb, decoded_frame);\n\n            fb->buf->priv           = buf;\n\n            fb->buf->free           = filter_release_buffer;\n\n\n\n            buf->refcount++;\n\n            av_buffersrc_buffer(ost->input_video_filter, fb);\n\n        } else\n\n            av_vsrc_buffer_add_frame(ost->input_video_filter, decoded_frame,\n\n                                     decoded_frame->pts, decoded_frame->sample_aspect_ratio);\n\n\n\n        if (!ist->filtered_frame && !(ist->filtered_frame = avcodec_alloc_frame())) {\n\n            av_free(buffer_to_free);\n\n            return AVERROR(ENOMEM);\n\n        } else\n\n            avcodec_get_frame_defaults(ist->filtered_frame);\n\n        filtered_frame = ist->filtered_frame;\n\n\n\n        frame_available = avfilter_poll_frame(ost->output_video_filter->inputs[0]);\n\n        while (frame_available) {\n\n            AVRational ist_pts_tb;\n\n            get_filtered_video_frame(ost->output_video_filter, filtered_frame, &ost->picref, &ist_pts_tb);\n\n            if (ost->picref)\n\n                filtered_frame->pts = av_rescale_q(ost->picref->pts, ist_pts_tb, AV_TIME_BASE_Q);\n\n            if (ost->picref->video && !ost->frame_aspect_ratio)\n\n                ost->st->codec->sample_aspect_ratio = ost->picref->video->pixel_aspect;\n\n#else\n\n            filtered_frame = decoded_frame;\n\n#endif\n\n\n\n            do_video_out(output_files[ost->file_index].ctx, ost, ist, filtered_frame, &frame_size,\n\n                         same_quant ? quality : ost->st->codec->global_quality);\n\n            if (vstats_filename && frame_size)\n\n                do_video_stats(output_files[ost->file_index].ctx, ost, frame_size);\n\n#if CONFIG_AVFILTER\n\n            frame_available = ost->output_video_filter && avfilter_poll_frame(ost->output_video_filter->inputs[0]);\n\n            if (ost->picref)\n\n                avfilter_unref_buffer(ost->picref);\n\n        }\n\n#endif\n\n    }\n\n\n\n    av_free(buffer_to_free);\n\n    return ret;\n\n}\n", "idx": 8906, "_split": "valid", "_hash": "8809b57bf01793ee5e3a9be0ca171b92"}
{"project": "FFmpeg", "commit_id": "484b1cdd5303771447e15d0067a2034b0c17fdc8", "target": 0, "func": "static int ljpeg_decode_rgb_scan(MJpegDecodeContext *s, int predictor, int point_transform){\n\n    int i, mb_x, mb_y;\n\n    uint16_t (*buffer)[4];\n\n    int left[3], top[3], topleft[3];\n\n    const int linesize= s->linesize[0];\n\n    const int mask= (1<<s->bits)-1;\n\n\n\n    av_fast_malloc(&s->ljpeg_buffer, &s->ljpeg_buffer_size, (unsigned)s->mb_width * 4 * sizeof(s->ljpeg_buffer[0][0]));\n\n    buffer= s->ljpeg_buffer;\n\n\n\n    for(i=0; i<3; i++){\n\n        buffer[0][i]= 1 << (s->bits + point_transform - 1);\n\n    }\n\n    for(mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        const int modified_predictor= mb_y ? predictor : 1;\n\n        uint8_t *ptr = s->picture.data[0] + (linesize * mb_y);\n\n\n\n        if (s->interlaced && s->bottom_field)\n\n            ptr += linesize >> 1;\n\n\n\n        for(i=0; i<3; i++){\n\n            top[i]= left[i]= topleft[i]= buffer[0][i];\n\n        }\n\n        for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            if (s->restart_interval && !s->restart_count)\n\n                s->restart_count = s->restart_interval;\n\n\n\n            for(i=0;i<3;i++) {\n\n                int pred;\n\n\n\n                topleft[i]= top[i];\n\n                top[i]= buffer[mb_x][i];\n\n\n\n                PREDICT(pred, topleft[i], top[i], left[i], modified_predictor);\n\n\n\n                left[i]=\n\n                buffer[mb_x][i]= mask & (pred + (mjpeg_decode_dc(s, s->dc_index[i]) << point_transform));\n\n            }\n\n\n\n            if (s->restart_interval && !--s->restart_count) {\n\n                align_get_bits(&s->gb);\n\n                skip_bits(&s->gb, 16); /* skip RSTn */\n\n            }\n\n        }\n\n\n\n        if(s->rct){\n\n            for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                ptr[3*mb_x+1] = buffer[mb_x][0] - ((buffer[mb_x][1] + buffer[mb_x][2] - 0x200)>>2);\n\n                ptr[3*mb_x+0] = buffer[mb_x][1] + ptr[3*mb_x+1];\n\n                ptr[3*mb_x+2] = buffer[mb_x][2] + ptr[3*mb_x+1];\n\n            }\n\n        }else if(s->pegasus_rct){\n\n            for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                ptr[3*mb_x+1] = buffer[mb_x][0] - ((buffer[mb_x][1] + buffer[mb_x][2])>>2);\n\n                ptr[3*mb_x+0] = buffer[mb_x][1] + ptr[3*mb_x+1];\n\n                ptr[3*mb_x+2] = buffer[mb_x][2] + ptr[3*mb_x+1];\n\n            }\n\n        }else{\n\n            for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                ptr[3*mb_x+0] = buffer[mb_x][2];\n\n                ptr[3*mb_x+1] = buffer[mb_x][1];\n\n                ptr[3*mb_x+2] = buffer[mb_x][0];\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 8930, "_split": "valid", "_hash": "83eeb6a7eb383de590a6006babaa1039"}
{"project": "FFmpeg", "commit_id": "9e7b62f0fb7462a902330fcc82cf596388f0187b", "target": 0, "func": "static int twinvq_read_bitstream(AVCodecContext *avctx, TwinVQContext *tctx,\n\n                                 const uint8_t *buf, int buf_size)\n\n{\n\n    TwinVQFrameData     *bits = &tctx->bits;\n\n    const TwinVQModeTab *mtab = tctx->mtab;\n\n    int channels              = tctx->avctx->channels;\n\n    int sub;\n\n    GetBitContext gb;\n\n    int i, j, k;\n\n\n\n    if (buf_size * 8 < avctx->bit_rate * mtab->size / avctx->sample_rate + 8) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Frame too small (%d bytes). Truncated file?\\n\", buf_size);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    init_get_bits(&gb, buf, buf_size * 8);\n\n    skip_bits(&gb, get_bits(&gb, 8));\n\n\n\n    bits->window_type = get_bits(&gb, TWINVQ_WINDOW_TYPE_BITS);\n\n\n\n    if (bits->window_type > 8) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid window type, broken sample?\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bits->ftype = ff_twinvq_wtype_to_ftype_table[tctx->bits.window_type];\n\n\n\n    sub = mtab->fmode[bits->ftype].sub;\n\n\n\n    read_cb_data(tctx, &gb, bits->main_coeffs, bits->ftype);\n\n\n\n    for (i = 0; i < channels; i++)\n\n        for (j = 0; j < sub; j++)\n\n            for (k = 0; k < mtab->fmode[bits->ftype].bark_n_coef; k++)\n\n                bits->bark1[i][j][k] =\n\n                    get_bits(&gb, mtab->fmode[bits->ftype].bark_n_bit);\n\n\n\n    for (i = 0; i < channels; i++)\n\n        for (j = 0; j < sub; j++)\n\n            bits->bark_use_hist[i][j] = get_bits1(&gb);\n\n\n\n    if (bits->ftype == TWINVQ_FT_LONG) {\n\n        for (i = 0; i < channels; i++)\n\n            bits->gain_bits[i] = get_bits(&gb, TWINVQ_GAIN_BITS);\n\n    } else {\n\n        for (i = 0; i < channels; i++) {\n\n            bits->gain_bits[i] = get_bits(&gb, TWINVQ_GAIN_BITS);\n\n            for (j = 0; j < sub; j++)\n\n                bits->sub_gain_bits[i * sub + j] = get_bits(&gb,\n\n                                                       TWINVQ_SUB_GAIN_BITS);\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < channels; i++) {\n\n        bits->lpc_hist_idx[i] = get_bits(&gb, mtab->lsp_bit0);\n\n        bits->lpc_idx1[i]     = get_bits(&gb, mtab->lsp_bit1);\n\n\n\n        for (j = 0; j < mtab->lsp_split; j++)\n\n            bits->lpc_idx2[i][j] = get_bits(&gb, mtab->lsp_bit2);\n\n    }\n\n\n\n    if (bits->ftype == TWINVQ_FT_LONG) {\n\n        read_cb_data(tctx, &gb, bits->ppc_coeffs, 3);\n\n        for (i = 0; i < channels; i++) {\n\n            bits->p_coef[i] = get_bits(&gb, mtab->ppc_period_bit);\n\n            bits->g_coef[i] = get_bits(&gb, mtab->pgain_bit);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 8980, "_split": "valid", "_hash": "3f48bc61748d5af07da89da829a40155"}
{"project": "FFmpeg", "commit_id": "990b13806d38f51201afb4e5048c61bf3e1c576e", "target": 1, "func": "static void blend_frame(AVFilterContext *ctx,\n\n                        AVFrame *top_buf,\n\n                        AVFrame *bottom_buf,\n\n                        AVFrame *dst_buf)\n\n{\n\n    BlendContext *b = ctx->priv;\n\n    AVFilterLink *inlink = ctx->inputs[0];\n\n    FilterParams *param;\n\n    int plane;\n\n\n\n    for (plane = 0; dst_buf->data[plane]; plane++) {\n\n        int hsub = plane == 1 || plane == 2 ? b->hsub : 0;\n\n        int vsub = plane == 1 || plane == 2 ? b->vsub : 0;\n\n        int outw = dst_buf->width  >> hsub;\n\n        int outh = dst_buf->height >> vsub;\n\n        uint8_t *dst    = dst_buf->data[plane];\n\n        uint8_t *top    = top_buf->data[plane];\n\n        uint8_t *bottom = bottom_buf->data[plane];\n\n\n\n        param = &b->params[plane];\n\n        param->values[VAR_N]  = inlink->frame_count;\n\n        param->values[VAR_T]  = dst_buf->pts == AV_NOPTS_VALUE ? NAN : dst_buf->pts * av_q2d(inlink->time_base);\n\n        param->values[VAR_W]  = outw;\n\n        param->values[VAR_H]  = outh;\n\n        param->values[VAR_SW] = outw / dst_buf->width;\n\n        param->values[VAR_SH] = outh / dst_buf->height;\n\n        param->blend(top, top_buf->linesize[plane],\n\n                     bottom, bottom_buf->linesize[plane],\n\n                     dst, dst_buf->linesize[plane], outw, outh, param);\n\n    }\n\n}\n", "idx": 9024, "_split": "valid", "_hash": "303d99969f475d7ff2664dbdeb58f3ed"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "void ff_put_h264_qpel4_mc21_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midv_qrt_4w_msa(src - (2 * stride) - 2, stride, dst, stride, 4, 0);\n\n}\n", "idx": 9083, "_split": "valid", "_hash": "e1071a4f32712c2aa1d6999b92c2401f"}
{"project": "FFmpeg", "commit_id": "57623cba1301ee7874687dd7e04c611051638e9d", "target": 0, "func": "static int vp8_lossy_decode_frame(AVCodecContext *avctx, AVFrame *p,\n\n                                  int *got_frame, uint8_t *data_start,\n\n                                  unsigned int data_size)\n\n{\n\n    WebPContext *s = avctx->priv_data;\n\n    AVPacket pkt;\n\n    int ret;\n\n\n\n    if (!s->initialized) {\n\n        ff_vp8_decode_init(avctx);\n\n        s->initialized = 1;\n\n        avctx->get_format = webp_get_format;\n\n    }\n\n    s->lossless = 0;\n\n\n\n    if (data_size > INT_MAX) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported chunk size\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    av_init_packet(&pkt);\n\n    pkt.data = data_start;\n\n    pkt.size = data_size;\n\n\n\n    ret = ff_vp8_decode_frame(avctx, p, got_frame, &pkt);\n\n    if (s->has_alpha) {\n\n        ret = vp8_lossy_decode_alpha(avctx, p, s->alpha_data,\n\n                                     s->alpha_data_size);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    return ret;\n\n}\n", "idx": 9130, "_split": "valid", "_hash": "8d2088213d7a4f813961d5b629c5b5e5"}
{"project": "FFmpeg", "commit_id": "1c495b0bf690995c45f79f4f19500921e14ec78a", "target": 1, "func": "static void sd_1d97_float(float *p, int i0, int i1)\n\n{\n\n    int i;\n\n\n\n    if (i1 <= i0 + 1) {\n\n        if (i0 == 1)\n\n            p[1] *= F_LFTG_X;\n\n        else\n\n            p[0] *= F_LFTG_K;\n\n        return;\n\n    }\n\n\n\n    extend97_float(p, i0, i1);\n\n    i0++; i1++;\n\n\n\n    for (i = i0/2 - 2; i < i1/2 + 1; i++)\n\n        p[2*i+1] -= 1.586134 * (p[2*i] + p[2*i+2]);\n\n    for (i = i0/2 - 1; i < i1/2 + 1; i++)\n\n        p[2*i] -= 0.052980 * (p[2*i-1] + p[2*i+1]);\n\n    for (i = i0/2 - 1; i < i1/2; i++)\n\n        p[2*i+1] += 0.882911 * (p[2*i] + p[2*i+2]);\n\n    for (i = i0/2; i < i1/2; i++)\n\n        p[2*i] += 0.443506 * (p[2*i-1] + p[2*i+1]);\n\n}\n", "idx": 9192, "_split": "valid", "_hash": "8d5c0226b157fc58d4014bbfc3bad04b"}
{"project": "FFmpeg", "commit_id": "cf31e2df08e39082241c8e2e10eaacb115c69a6c", "target": 1, "func": "int ff_mpv_frame_start(MpegEncContext *s, AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    Picture *pic;\n\n    s->mb_skipped = 0;\n\n\n\n    if (!ff_thread_can_start_frame(avctx)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Attempt to start a frame outside SETUP state\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* mark & release old frames */\n\n    if (s->pict_type != AV_PICTURE_TYPE_B && s->last_picture_ptr &&\n\n        s->last_picture_ptr != s->next_picture_ptr &&\n\n        s->last_picture_ptr->f->buf[0]) {\n\n        ff_mpeg_unref_picture(s, s->last_picture_ptr);\n\n    }\n\n\n\n    /* release forgotten pictures */\n\n    /* if (mpeg124/h263) */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (&s->picture[i] != s->last_picture_ptr &&\n\n            &s->picture[i] != s->next_picture_ptr &&\n\n            s->picture[i].reference && !s->picture[i].needs_realloc) {\n\n            if (!(avctx->active_thread_type & FF_THREAD_FRAME))\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"releasing zombie picture\\n\");\n\n            ff_mpeg_unref_picture(s, &s->picture[i]);\n\n        }\n\n    }\n\n\n\n    ff_mpeg_unref_picture(s, &s->current_picture);\n\n\n\n    release_unused_pictures(s);\n\n\n\n    if (s->current_picture_ptr && !s->current_picture_ptr->f->buf[0]) {\n\n        // we already have a unused image\n\n        // (maybe it was set before reading the header)\n\n        pic = s->current_picture_ptr;\n\n    } else {\n\n        i   = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        pic = &s->picture[i];\n\n    }\n\n\n\n    pic->reference = 0;\n\n    if (!s->droppable) {\n\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n\n            pic->reference = 3;\n\n    }\n\n\n\n    pic->f->coded_picture_number = s->coded_picture_number++;\n\n\n\n    if (ff_alloc_picture(s, pic, 0) < 0)\n\n        return -1;\n\n\n\n    s->current_picture_ptr = pic;\n\n    // FIXME use only the vars from current_pic\n\n    s->current_picture_ptr->f->top_field_first = s->top_field_first;\n\n    if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO ||\n\n        s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        if (s->picture_structure != PICT_FRAME)\n\n            s->current_picture_ptr->f->top_field_first =\n\n                (s->picture_structure == PICT_TOP_FIELD) == s->first_field;\n\n    }\n\n    s->current_picture_ptr->f->interlaced_frame = !s->progressive_frame &&\n\n                                                 !s->progressive_sequence;\n\n    s->current_picture_ptr->field_picture      =  s->picture_structure != PICT_FRAME;\n\n\n\n    s->current_picture_ptr->f->pict_type = s->pict_type;\n\n    // if (s->flags && CODEC_FLAG_QSCALE)\n\n    //     s->current_picture_ptr->quality = s->new_picture_ptr->quality;\n\n    s->current_picture_ptr->f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    if ((ret = ff_mpeg_ref_picture(s, &s->current_picture,\n\n                                   s->current_picture_ptr)) < 0)\n\n        return ret;\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n        s->last_picture_ptr = s->next_picture_ptr;\n\n        if (!s->droppable)\n\n            s->next_picture_ptr = s->current_picture_ptr;\n\n    }\n\n    ff_dlog(s->avctx, \"L%p N%p C%p L%p N%p C%p type:%d drop:%d\\n\",\n\n            s->last_picture_ptr, s->next_picture_ptr,s->current_picture_ptr,\n\n            s->last_picture_ptr    ? s->last_picture_ptr->f->data[0]    : NULL,\n\n            s->next_picture_ptr    ? s->next_picture_ptr->f->data[0]    : NULL,\n\n            s->current_picture_ptr ? s->current_picture_ptr->f->data[0] : NULL,\n\n            s->pict_type, s->droppable);\n\n\n\n    if ((!s->last_picture_ptr || !s->last_picture_ptr->f->buf[0]) &&\n\n        (s->pict_type != AV_PICTURE_TYPE_I ||\n\n         s->picture_structure != PICT_FRAME)) {\n\n        int h_chroma_shift, v_chroma_shift;\n\n        av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt,\n\n                                         &h_chroma_shift, &v_chroma_shift);\n\n        if (s->pict_type == AV_PICTURE_TYPE_B && s->next_picture_ptr && s->next_picture_ptr->f->buf[0])\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocating dummy last picture for B frame\\n\");\n\n        else if (s->pict_type != AV_PICTURE_TYPE_I)\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"warning: first frame is no keyframe\\n\");\n\n        else if (s->picture_structure != PICT_FRAME)\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocate dummy last picture for field based first keyframe\\n\");\n\n\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->last_picture_ptr = &s->picture[i];\n\n\n\n        s->last_picture_ptr->reference   = 3;\n\n        s->last_picture_ptr->f->key_frame = 0;\n\n        s->last_picture_ptr->f->pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->last_picture_ptr, 0) < 0) {\n\n            s->last_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n\n\n        if (!avctx->hwaccel && !(avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)) {\n\n            for(i=0; i<avctx->height; i++)\n\n                memset(s->last_picture_ptr->f->data[0] + s->last_picture_ptr->f->linesize[0]*i,\n\n                       0x80, avctx->width);\n\n            for(i=0; i<FF_CEIL_RSHIFT(avctx->height, v_chroma_shift); i++) {\n\n                memset(s->last_picture_ptr->f->data[1] + s->last_picture_ptr->f->linesize[1]*i,\n\n                       0x80, FF_CEIL_RSHIFT(avctx->width, h_chroma_shift));\n\n                memset(s->last_picture_ptr->f->data[2] + s->last_picture_ptr->f->linesize[2]*i,\n\n                       0x80, FF_CEIL_RSHIFT(avctx->width, h_chroma_shift));\n\n            }\n\n\n\n            if(s->codec_id == AV_CODEC_ID_FLV1 || s->codec_id == AV_CODEC_ID_H263){\n\n                for(i=0; i<avctx->height; i++)\n\n                memset(s->last_picture_ptr->f->data[0] + s->last_picture_ptr->f->linesize[0]*i, 16, avctx->width);\n\n            }\n\n        }\n\n\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n    if ((!s->next_picture_ptr || !s->next_picture_ptr->f->buf[0]) &&\n\n        s->pict_type == AV_PICTURE_TYPE_B) {\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->next_picture_ptr = &s->picture[i];\n\n\n\n        s->next_picture_ptr->reference   = 3;\n\n        s->next_picture_ptr->f->key_frame = 0;\n\n        s->next_picture_ptr->f->pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->next_picture_ptr, 0) < 0) {\n\n            s->next_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n\n\n#if 0 // BUFREF-FIXME\n\n    memset(s->last_picture.f->data, 0, sizeof(s->last_picture.f->data));\n\n    memset(s->next_picture.f->data, 0, sizeof(s->next_picture.f->data));\n\n#endif\n\n    if (s->last_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->last_picture);\n\n        if (s->last_picture_ptr->f->buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->last_picture,\n\n                                       s->last_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n    if (s->next_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->next_picture);\n\n        if (s->next_picture_ptr->f->buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->next_picture,\n\n                                       s->next_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    av_assert0(s->pict_type == AV_PICTURE_TYPE_I || (s->last_picture_ptr &&\n\n                                                 s->last_picture_ptr->f->buf[0]));\n\n\n\n    if (s->picture_structure!= PICT_FRAME) {\n\n        int i;\n\n        for (i = 0; i < 4; i++) {\n\n            if (s->picture_structure == PICT_BOTTOM_FIELD) {\n\n                s->current_picture.f->data[i] +=\n\n                    s->current_picture.f->linesize[i];\n\n            }\n\n            s->current_picture.f->linesize[i] *= 2;\n\n            s->last_picture.f->linesize[i]    *= 2;\n\n            s->next_picture.f->linesize[i]    *= 2;\n\n        }\n\n    }\n\n\n\n    s->err_recognition = avctx->err_recognition;\n\n\n\n    /* set dequantizer, we can't do it during init as\n\n     * it might change for mpeg4 and we can't do it in the header\n\n     * decode as init is not called for mpeg4 there yet */\n\n    if (s->mpeg_quant || s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg2_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg2_inter;\n\n    } else if (s->out_format == FMT_H263 || s->out_format == FMT_H261) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_h263_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_h263_inter;\n\n    } else {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg1_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg1_inter;\n\n    }\n\n\n\n    if (s->avctx->debug & FF_DEBUG_NOMC) {\n\n        gray_frame(s->current_picture_ptr->f);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 9198, "_split": "valid", "_hash": "e083b944dfd0997b8ccae59a60d04244"}
{"project": "FFmpeg", "commit_id": "99683a307776a7638ccce236a4ce5aa3e914e77d", "target": 1, "func": "static void jpeg_put_comments(MpegEncContext *s)\n\n{\n\n    PutBitContext *p = &s->pb;\n\n    int size;\n\n    uint8_t *ptr;\n\n\n\n    if (s->aspect_ratio_info /* && !lossless */)\n\n    {\n\n    /* JFIF header */\n\n    put_marker(p, APP0);\n\n    put_bits(p, 16, 16);\n\n    put_string(p, \"JFIF\"); /* this puts the trailing zero-byte too */\n\n    put_bits(p, 16, 0x0201); /* v 1.02 */\n\n    put_bits(p, 8, 0); /* units type: 0 - aspect ratio */\n\n    put_bits(p, 16, s->avctx->sample_aspect_ratio.num);\n\n    put_bits(p, 16, s->avctx->sample_aspect_ratio.den);\n\n    put_bits(p, 8, 0); /* thumbnail width */\n\n    put_bits(p, 8, 0); /* thumbnail height */\n\n    }\n\n\n\n    /* comment */\n\n    if(!(s->flags & CODEC_FLAG_BITEXACT)){\n\n        put_marker(p, COM);\n\n        flush_put_bits(p);\n\n        ptr = pbBufPtr(p);\n\n        put_bits(p, 16, 0); /* patched later */\n\n        put_string(p, LIBAVCODEC_IDENT);\n\n        size = strlen(LIBAVCODEC_IDENT)+3;\n\n        ptr[0] = size >> 8;\n\n        ptr[1] = size;\n\n    }\n\n}\n", "idx": 9227, "_split": "valid", "_hash": "27aae6b24337318bb2719e24ab02cd2b"}
{"project": "FFmpeg", "commit_id": "8c50704ebf1777bee76772c4835d9760b3721057", "target": 1, "func": "static av_always_inline int vorbis_residue_decode_internal(vorbis_context *vc,\n\n                                                           vorbis_residue *vr,\n\n                                                           unsigned ch,\n\n                                                           uint8_t *do_not_decode,\n\n                                                           float *vec,\n\n                                                           unsigned vlen,\n\n                                                           unsigned ch_left,\n\n                                                           int vr_type)\n\n{\n\n    GetBitContext *gb = &vc->gb;\n\n    unsigned c_p_c        = vc->codebooks[vr->classbook].dimensions;\n\n    uint8_t *classifs = vr->classifs;\n\n    unsigned pass, ch_used, i, j, k, l;\n\n    unsigned max_output = (ch - 1) * vlen;\n\n    int ptns_to_read = vr->ptns_to_read;\n\n    int libvorbis_bug = 0;\n\n\n\n    if (vr_type == 2) {\n\n        for (j = 1; j < ch; ++j)\n\n            do_not_decode[0] &= do_not_decode[j];  // FIXME - clobbering input\n\n        if (do_not_decode[0])\n\n            return 0;\n\n        ch_used = 1;\n\n        max_output += vr->end / ch;\n\n    } else {\n\n        ch_used = ch;\n\n        max_output += vr->end;\n\n    }\n\n\n\n    if (max_output > ch_left * vlen) {\n\n        if (max_output <= ch_left * vlen + vr->partition_size*ch_used/ch) {\n\n            ptns_to_read--;\n\n            libvorbis_bug = 1;\n\n        } else {\n\n            av_log(vc->avctx, AV_LOG_ERROR, \"Insufficient output buffer\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    av_dlog(NULL, \" residue type 0/1/2 decode begin, ch: %d  cpc %d  \\n\", ch, c_p_c);\n\n\n\n    for (pass = 0; pass <= vr->maxpass; ++pass) { // FIXME OPTIMIZE?\n\n        int voffset, partition_count, j_times_ptns_to_read;\n\n\n\n        voffset = vr->begin;\n\n        for (partition_count = 0; partition_count < ptns_to_read;) {  // SPEC        error\n\n            if (!pass) {\n\n                int ret;\n\n                if ((ret = setup_classifs(vc, vr, do_not_decode, ch_used, partition_count)) < 0)\n\n                    return ret;\n\n            }\n\n            for (i = 0; (i < c_p_c) && (partition_count < ptns_to_read); ++i) {\n\n                for (j_times_ptns_to_read = 0, j = 0; j < ch_used; ++j) {\n\n                    unsigned voffs;\n\n\n\n                    if (!do_not_decode[j]) {\n\n                        unsigned vqclass = classifs[j_times_ptns_to_read + partition_count];\n\n                        int vqbook  = vr->books[vqclass][pass];\n\n\n\n                        if (vqbook >= 0 && vc->codebooks[vqbook].codevectors) {\n\n                            unsigned coffs;\n\n                            unsigned dim  = vc->codebooks[vqbook].dimensions;\n\n                            unsigned step = FASTDIV(vr->partition_size << 1, dim << 1);\n\n                            vorbis_codebook codebook = vc->codebooks[vqbook];\n\n\n\n                            if (vr_type == 0) {\n\n\n\n                                voffs = voffset+j*vlen;\n\n                                for (k = 0; k < step; ++k) {\n\n                                    coffs = get_vlc2(gb, codebook.vlc.table, codebook.nb_bits, 3) * dim;\n\n                                    for (l = 0; l < dim; ++l)\n\n                                        vec[voffs + k + l * step] += codebook.codevectors[coffs + l];\n\n                                }\n\n                            } else if (vr_type == 1) {\n\n                                voffs = voffset + j * vlen;\n\n                                for (k = 0; k < step; ++k) {\n\n                                    coffs = get_vlc2(gb, codebook.vlc.table, codebook.nb_bits, 3) * dim;\n\n                                    for (l = 0; l < dim; ++l, ++voffs) {\n\n                                        vec[voffs]+=codebook.codevectors[coffs+l];\n\n\n\n                                        av_dlog(NULL, \" pass %d offs: %d curr: %f change: %f cv offs.: %d  \\n\",\n\n                                                pass, voffs, vec[voffs], codebook.codevectors[coffs+l], coffs);\n\n                                    }\n\n                                }\n\n                            } else if (vr_type == 2 && ch == 2 && (voffset & 1) == 0 && (dim & 1) == 0) { // most frequent case optimized\n\n                                voffs = voffset >> 1;\n\n\n\n                                if (dim == 2) {\n\n                                    for (k = 0; k < step; ++k) {\n\n                                        coffs = get_vlc2(gb, codebook.vlc.table, codebook.nb_bits, 3) * 2;\n\n                                        vec[voffs + k       ] += codebook.codevectors[coffs    ];\n\n                                        vec[voffs + k + vlen] += codebook.codevectors[coffs + 1];\n\n                                    }\n\n                                } else if (dim == 4) {\n\n                                    for (k = 0; k < step; ++k, voffs += 2) {\n\n                                        coffs = get_vlc2(gb, codebook.vlc.table, codebook.nb_bits, 3) * 4;\n\n                                        vec[voffs           ] += codebook.codevectors[coffs    ];\n\n                                        vec[voffs + 1       ] += codebook.codevectors[coffs + 2];\n\n                                        vec[voffs + vlen    ] += codebook.codevectors[coffs + 1];\n\n                                        vec[voffs + vlen + 1] += codebook.codevectors[coffs + 3];\n\n                                    }\n\n                                } else\n\n                                for (k = 0; k < step; ++k) {\n\n                                    coffs = get_vlc2(gb, codebook.vlc.table, codebook.nb_bits, 3) * dim;\n\n                                    for (l = 0; l < dim; l += 2, voffs++) {\n\n                                        vec[voffs       ] += codebook.codevectors[coffs + l    ];\n\n                                        vec[voffs + vlen] += codebook.codevectors[coffs + l + 1];\n\n\n\n                                        av_dlog(NULL, \" pass %d offs: %d curr: %f change: %f cv offs.: %d+%d  \\n\",\n\n                                                pass, voffset / ch + (voffs % ch) * vlen,\n\n                                                vec[voffset / ch + (voffs % ch) * vlen],\n\n                                                codebook.codevectors[coffs + l], coffs, l);\n\n                                    }\n\n                                }\n\n\n\n                            } else if (vr_type == 2) {\n\n                                unsigned voffs_div = FASTDIV(voffset << 1, ch <<1);\n\n                                unsigned voffs_mod = voffset - voffs_div * ch;\n\n\n\n                                for (k = 0; k < step; ++k) {\n\n                                    coffs = get_vlc2(gb, codebook.vlc.table, codebook.nb_bits, 3) * dim;\n\n                                    for (l = 0; l < dim; ++l) {\n\n                                        vec[voffs_div + voffs_mod * vlen] +=\n\n                                            codebook.codevectors[coffs + l];\n\n\n\n                                        av_dlog(NULL, \" pass %d offs: %d curr: %f change: %f cv offs.: %d+%d  \\n\",\n\n                                                pass, voffs_div + voffs_mod * vlen,\n\n                                                vec[voffs_div + voffs_mod * vlen],\n\n                                                codebook.codevectors[coffs + l], coffs, l);\n\n\n\n                                        if (++voffs_mod == ch) {\n\n                                            voffs_div++;\n\n                                            voffs_mod = 0;\n\n                                        }\n\n                                    }\n\n                                }\n\n                            }\n\n                        }\n\n                    }\n\n                    j_times_ptns_to_read += ptns_to_read;\n\n                }\n\n                ++partition_count;\n\n                voffset += vr->partition_size;\n\n            }\n\n        }\n\n        if (libvorbis_bug && !pass) {\n\n            for (j = 0; j < ch_used; ++j) {\n\n                if (!do_not_decode[j]) {\n\n                    get_vlc2(&vc->gb, vc->codebooks[vr->classbook].vlc.table,\n\n                                vc->codebooks[vr->classbook].nb_bits, 3);\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 9229, "_split": "valid", "_hash": "00192ec6b4527fbde2c14902186c4e92"}
{"project": "FFmpeg", "commit_id": "1359c2d43e8b13f09ad46526261fe00d7834d411", "target": 0, "func": "static int asf_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    GUID g;\n\n    ByteIOContext *pb = &s->pb;\n\n    AVStream *st;\n\n    ASFStream *asf_st;\n\n    int size, i, bps;\n\n    INT64 gsize;\n\n\n\n    get_guid(pb, &g);\n\n    if (memcmp(&g, &asf_header, sizeof(GUID)))\n\n        goto fail;\n\n    get_le64(pb);\n\n    get_le32(pb);\n\n    get_byte(pb);\n\n    get_byte(pb);\n\n    memset(&asf->asfid2avid, -1, sizeof(asf->asfid2avid));\n\n    for(;;) {\n\n        get_guid(pb, &g);\n\n        gsize = get_le64(pb);\n\n#ifdef DEBUG\n\n        printf(\"%08Lx: \", url_ftell(pb) - 24);\n\n        print_guid(&g);\n\n        printf(\"  size=0x%Lx\\n\", gsize);\n\n#endif\n\n        if (gsize < 24)\n\n            goto fail;\n\n        if (!memcmp(&g, &file_header, sizeof(GUID))) {\n\n            get_guid(pb, &asf->hdr.guid);\n\n\t    asf->hdr.file_size\t\t= get_le64(pb);\n\n\t    asf->hdr.create_time\t= get_le64(pb);\n\n\t    asf->hdr.packets_count\t= get_le64(pb);\n\n\t    asf->hdr.play_time\t\t= get_le64(pb);\n\n\t    asf->hdr.send_time\t\t= get_le64(pb);\n\n\t    asf->hdr.preroll\t\t= get_le32(pb);\n\n\t    asf->hdr.ignore\t\t= get_le32(pb);\n\n\t    asf->hdr.flags\t\t= get_le32(pb);\n\n\t    asf->hdr.min_pktsize\t= get_le32(pb);\n\n\t    asf->hdr.max_pktsize\t= get_le32(pb);\n\n\t    asf->hdr.max_bitrate\t= get_le32(pb);\n\n\t    asf->packet_size = asf->hdr.max_pktsize;\n\n            asf->nb_packets = asf->hdr.packets_count;\n\n        } else if (!memcmp(&g, &stream_header, sizeof(GUID))) {\n\n            int type, id, total_size;\n\n            unsigned int tag1;\n\n            INT64 pos1, pos2;\n\n\n\n            pos1 = url_ftell(pb);\n\n\n\n            st = av_mallocz(sizeof(AVStream));\n\n            if (!st)\n\n                goto fail;\n\n            s->streams[s->nb_streams] = st;\n\n            asf_st = av_mallocz(sizeof(ASFStream));\n\n            if (!asf_st)\n\n                goto fail;\n\n            st->priv_data = asf_st;\n\n\t    st->time_length = (asf->hdr.send_time - asf->hdr.preroll) / 10000;\n\n            get_guid(pb, &g);\n\n            if (!memcmp(&g, &audio_stream, sizeof(GUID))) {\n\n                type = CODEC_TYPE_AUDIO;\n\n            } else if (!memcmp(&g, &video_stream, sizeof(GUID))) {\n\n                type = CODEC_TYPE_VIDEO;\n\n            } else {\n\n                goto fail;\n\n            }\n\n            get_guid(pb, &g);\n\n            total_size = get_le64(pb);\n\n            get_le32(pb);\n\n            get_le32(pb);\n\n\t    st->id = get_le16(pb) & 0x7f; /* stream id */\n\n            // mapping of asf ID to AV stream ID;\n\n            asf->asfid2avid[st->id] = s->nb_streams++;\n\n\n\n            get_le32(pb);\n\n\t    st->codec.codec_type = type;\n\n            st->codec.frame_rate = 1000; // in packet ticks\n\n            if (type == CODEC_TYPE_AUDIO) {\n\n                id = get_le16(pb);\n\n                st->codec.codec_tag = id;\n\n                st->codec.channels = get_le16(pb);\n\n\t\tst->codec.sample_rate = get_le32(pb);\n\n                st->codec.bit_rate = get_le32(pb) * 8;\n\n\t\tst->codec.block_align = get_le16(pb); /* block align */\n\n                bps = get_le16(pb); /* bits per sample */\n\n                st->codec.codec_id = wav_codec_get_id(id, bps);\n\n\t\tsize = get_le16(pb);\n\n\t\tif (size > 0) {\n\n\t\t    st->extra_data = av_mallocz(size);\n\n\t\t    get_buffer(pb, st->extra_data, size);\n\n\t\t    st->extra_data_size = size;\n\n\t\t}\n\n\t\t/* We have to init the frame size at some point .... */\n\n\t\tpos2 = url_ftell(pb);\n\n\t\tif (gsize > (pos2 + 8 - pos1 + 24)) {\n\n\t\t    asf_st->ds_span = get_byte(pb);\n\n\t\t    asf_st->ds_packet_size = get_le16(pb);\n\n\t\t    asf_st->ds_chunk_size = get_le16(pb);\n\n\t\t    asf_st->ds_data_size = get_le16(pb);\n\n\t\t    asf_st->ds_silence_data = get_byte(pb);\n\n\t\t}\n\n\t\t//printf(\"Descrambling: ps:%d cs:%d ds:%d s:%d  sd:%d\\n\",\n\n\t\t//       asf_st->ds_packet_size, asf_st->ds_chunk_size,\n\n\t\t//       asf_st->ds_data_size, asf_st->ds_span, asf_st->ds_silence_data);\n\n\t\tif (asf_st->ds_span > 1) {\n\n\t\t    if (!asf_st->ds_chunk_size\n\n\t\t\t|| (asf_st->ds_packet_size/asf_st->ds_chunk_size <= 1))\n\n\t\t\tasf_st->ds_span = 0; // disable descrambling\n\n\t\t}\n\n                switch (st->codec.codec_id) {\n\n                case CODEC_ID_MP3LAME:\n\n                    st->codec.frame_size = MPA_FRAME_SIZE;\n\n                    break;\n\n                case CODEC_ID_PCM_S16LE:\n\n                case CODEC_ID_PCM_S16BE:\n\n                case CODEC_ID_PCM_U16LE:\n\n                case CODEC_ID_PCM_U16BE:\n\n                case CODEC_ID_PCM_S8:\n\n                case CODEC_ID_PCM_U8:\n\n                case CODEC_ID_PCM_ALAW:\n\n                case CODEC_ID_PCM_MULAW:\n\n                    st->codec.frame_size = 1;\n\n                    break;\n\n                default:\n\n                    /* This is probably wrong, but it prevents a crash later */\n\n                    st->codec.frame_size = 1;\n\n                    break;\n\n                }\n\n            } else {\n\n\t\tget_le32(pb);\n\n                get_le32(pb);\n\n                get_byte(pb);\n\n                size = get_le16(pb); /* size */\n\n                get_le32(pb); /* size */\n\n                st->codec.width = get_le32(pb);\n\n\t\tst->codec.height = get_le32(pb);\n\n                /* not available for asf */\n\n                get_le16(pb); /* panes */\n\n                get_le16(pb); /* depth */\n\n                tag1 = get_le32(pb);\n\n\t\turl_fskip(pb, 20);\n\n\t\tif (size > 40) {\n\n\t\t    st->extra_data_size = size - 40;\n\n\t\t    st->extra_data = av_mallocz(st->extra_data_size);\n\n\t\t    get_buffer(pb, st->extra_data, st->extra_data_size);\n\n\t\t}\n\n                st->codec.codec_tag = tag1;\n\n\t\tst->codec.codec_id = codec_get_id(codec_asf_bmp_tags, tag1);\n\n            }\n\n            pos2 = url_ftell(pb);\n\n            url_fskip(pb, gsize - (pos2 - pos1 + 24));\n\n        } else if (!memcmp(&g, &data_header, sizeof(GUID))) {\n\n            break;\n\n        } else if (!memcmp(&g, &comment_header, sizeof(GUID))) {\n\n            int len1, len2, len3, len4, len5;\n\n\n\n            len1 = get_le16(pb);\n\n            len2 = get_le16(pb);\n\n            len3 = get_le16(pb);\n\n            len4 = get_le16(pb);\n\n            len5 = get_le16(pb);\n\n            get_str16_nolen(pb, len1, s->title, sizeof(s->title));\n\n            get_str16_nolen(pb, len2, s->author, sizeof(s->author));\n\n            get_str16_nolen(pb, len3, s->copyright, sizeof(s->copyright));\n\n            get_str16_nolen(pb, len4, s->comment, sizeof(s->comment));\n\n\t    url_fskip(pb, len5);\n\n#if 0\n\n        } else if (!memcmp(&g, &head1_guid, sizeof(GUID))) {\n\n            int v1, v2;\n\n            get_guid(pb, &g);\n\n            v1 = get_le32(pb);\n\n            v2 = get_le16(pb);\n\n        } else if (!memcmp(&g, &codec_comment_header, sizeof(GUID))) {\n\n            int len, v1, n, num;\n\n            char str[256], *q;\n\n            char tag[16];\n\n\n\n            get_guid(pb, &g);\n\n            print_guid(&g);\n\n\n\n            n = get_le32(pb);\n\n            for(i=0;i<n;i++) {\n\n                num = get_le16(pb); /* stream number */\n\n                get_str16(pb, str, sizeof(str));\n\n                get_str16(pb, str, sizeof(str));\n\n                len = get_le16(pb);\n\n                q = tag;\n\n                while (len > 0) {\n\n                    v1 = get_byte(pb);\n\n                    if ((q - tag) < sizeof(tag) - 1)\n\n                        *q++ = v1;\n\n                    len--;\n\n                }\n\n                *q = '\\0';\n\n            }\n\n#endif\n\n        } else if (url_feof(pb)) {\n\n            goto fail;\n\n        } else {\n\n            url_fseek(pb, gsize - 24, SEEK_CUR);\n\n        }\n\n    }\n\n    get_guid(pb, &g);\n\n    get_le64(pb);\n\n    get_byte(pb);\n\n    get_byte(pb);\n\n    if (url_feof(pb))\n\n        goto fail;\n\n    asf->data_offset = url_ftell(pb);\n\n    asf->packet_size_left = 0;\n\n\n\n    return 0;\n\n\n\n fail:\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        AVStream *st = s->streams[i];\n\n\tif (st) {\n\n\t    av_free(st->priv_data);\n\n\t    av_free(st->extra_data);\n\n\t}\n\n        av_free(st);\n\n    }\n\n    //av_free(asf);\n\n    return -1;\n\n}\n", "idx": 9241, "_split": "valid", "_hash": "4b259e739cc5a1140927b7cf693fedcc"}
{"project": "FFmpeg", "commit_id": "d5ecffbac69543185a2f6d91414dbe097645f62c", "target": 0, "func": "static void guess_mv(ERContext *s)\n\n{\n\n    uint8_t *fixed = s->er_temp_buffer;\n\n#define MV_FROZEN    3\n\n#define MV_CHANGED   2\n\n#define MV_UNCHANGED 1\n\n    const int mb_stride = s->mb_stride;\n\n    const int mb_width  = s->mb_width;\n\n    int mb_height = s->mb_height;\n\n    int i, depth, num_avail;\n\n    int mb_x, mb_y, mot_step, mot_stride;\n\n\n\n    if (s->last_pic.f && s->last_pic.f->data[0])\n\n        mb_height = FFMIN(mb_height, (s->last_pic.f->height+15)>>4);\n\n    if (s->next_pic.f && s->next_pic.f->data[0])\n\n        mb_height = FFMIN(mb_height, (s->next_pic.f->height+15)>>4);\n\n\n\n    set_mv_strides(s, &mot_step, &mot_stride);\n\n\n\n    num_avail = 0;\n\n    if (s->last_pic.motion_val[0])\n\n        ff_thread_await_progress(s->last_pic.tf, mb_height-1, 0);\n\n    for (i = 0; i < mb_width * mb_height; i++) {\n\n        const int mb_xy = s->mb_index2xy[i];\n\n        int f = 0;\n\n        int error = s->error_status_table[mb_xy];\n\n\n\n        if (IS_INTRA(s->cur_pic.mb_type[mb_xy]))\n\n            f = MV_FROZEN; // intra // FIXME check\n\n        if (!(error & ER_MV_ERROR))\n\n            f = MV_FROZEN; // inter with undamaged MV\n\n\n\n        fixed[mb_xy] = f;\n\n        if (f == MV_FROZEN)\n\n            num_avail++;\n\n        else if(s->last_pic.f->data[0] && s->last_pic.motion_val[0]){\n\n            const int mb_y= mb_xy / s->mb_stride;\n\n            const int mb_x= mb_xy % s->mb_stride;\n\n            const int mot_index= (mb_x + mb_y*mot_stride) * mot_step;\n\n            s->cur_pic.motion_val[0][mot_index][0]= s->last_pic.motion_val[0][mot_index][0];\n\n            s->cur_pic.motion_val[0][mot_index][1]= s->last_pic.motion_val[0][mot_index][1];\n\n            s->cur_pic.ref_index[0][4*mb_xy]      = s->last_pic.ref_index[0][4*mb_xy];\n\n        }\n\n    }\n\n\n\n    if ((!(s->avctx->error_concealment&FF_EC_GUESS_MVS)) ||\n\n        num_avail <= mb_width / 2) {\n\n        for (mb_y = 0; mb_y < mb_height; mb_y++) {\n\n            for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                const int mb_xy = mb_x + mb_y * s->mb_stride;\n\n                int mv_dir = (s->last_pic.f && s->last_pic.f->data[0]) ? MV_DIR_FORWARD : MV_DIR_BACKWARD;\n\n\n\n                if (IS_INTRA(s->cur_pic.mb_type[mb_xy]))\n\n                    continue;\n\n                if (!(s->error_status_table[mb_xy] & ER_MV_ERROR))\n\n                    continue;\n\n\n\n                s->mv[0][0][0] = 0;\n\n                s->mv[0][0][1] = 0;\n\n                s->decode_mb(s->opaque, 0, mv_dir, MV_TYPE_16X16, &s->mv,\n\n                             mb_x, mb_y, 0, 0);\n\n            }\n\n        }\n\n        return;\n\n    }\n\n\n\n    for (depth = 0; ; depth++) {\n\n        int changed, pass, none_left;\n\n\n\n        none_left = 1;\n\n        changed   = 1;\n\n        for (pass = 0; (changed || pass < 2) && pass < 10; pass++) {\n\n            int mb_x, mb_y;\n\n            int score_sum = 0;\n\n\n\n            changed = 0;\n\n            for (mb_y = 0; mb_y < mb_height; mb_y++) {\n\n                for (mb_x = (mb_y ^ pass) & 1; mb_x < s->mb_width; mb_x+=2) {\n\n                    const int mb_xy        = mb_x + mb_y * s->mb_stride;\n\n                    int mv_predictor[8][2] = { { 0 } };\n\n                    int ref[8]             = { 0 };\n\n                    int pred_count         = 0;\n\n                    int j;\n\n                    int best_score         = 256 * 256 * 256 * 64;\n\n                    int best_pred          = 0;\n\n                    const int mot_index    = (mb_x + mb_y * mot_stride) * mot_step;\n\n                    int prev_x = 0, prev_y = 0, prev_ref = 0;\n\n\n\n                    if (fixed[mb_xy] == MV_FROZEN)\n\n                        continue;\n\n                    av_assert1(!IS_INTRA(s->cur_pic.mb_type[mb_xy]));\n\n                    av_assert1(s->last_pic.f && s->last_pic.f->data[0]);\n\n\n\n                    j = 0;\n\n                    if (mb_x > 0             && fixed[mb_xy - 1]         == MV_FROZEN)\n\n                        j = 1;\n\n                    if (mb_x + 1 < mb_width  && fixed[mb_xy + 1]         == MV_FROZEN)\n\n                        j = 1;\n\n                    if (mb_y > 0             && fixed[mb_xy - mb_stride] == MV_FROZEN)\n\n                        j = 1;\n\n                    if (mb_y + 1 < mb_height && fixed[mb_xy + mb_stride] == MV_FROZEN)\n\n                        j = 1;\n\n                    if (j == 0)\n\n                        continue;\n\n\n\n                    j = 0;\n\n                    if (mb_x > 0             && fixed[mb_xy - 1        ] == MV_CHANGED)\n\n                        j = 1;\n\n                    if (mb_x + 1 < mb_width  && fixed[mb_xy + 1        ] == MV_CHANGED)\n\n                        j = 1;\n\n                    if (mb_y > 0             && fixed[mb_xy - mb_stride] == MV_CHANGED)\n\n                        j = 1;\n\n                    if (mb_y + 1 < mb_height && fixed[mb_xy + mb_stride] == MV_CHANGED)\n\n                        j = 1;\n\n                    if (j == 0 && pass > 1)\n\n                        continue;\n\n\n\n                    none_left = 0;\n\n\n\n                    if (mb_x > 0 && fixed[mb_xy - 1]) {\n\n                        mv_predictor[pred_count][0] =\n\n                            s->cur_pic.motion_val[0][mot_index - mot_step][0];\n\n                        mv_predictor[pred_count][1] =\n\n                            s->cur_pic.motion_val[0][mot_index - mot_step][1];\n\n                        ref[pred_count] =\n\n                            s->cur_pic.ref_index[0][4 * (mb_xy - 1)];\n\n                        pred_count++;\n\n                    }\n\n                    if (mb_x + 1 < mb_width && fixed[mb_xy + 1]) {\n\n                        mv_predictor[pred_count][0] =\n\n                            s->cur_pic.motion_val[0][mot_index + mot_step][0];\n\n                        mv_predictor[pred_count][1] =\n\n                            s->cur_pic.motion_val[0][mot_index + mot_step][1];\n\n                        ref[pred_count] =\n\n                            s->cur_pic.ref_index[0][4 * (mb_xy + 1)];\n\n                        pred_count++;\n\n                    }\n\n                    if (mb_y > 0 && fixed[mb_xy - mb_stride]) {\n\n                        mv_predictor[pred_count][0] =\n\n                            s->cur_pic.motion_val[0][mot_index - mot_stride * mot_step][0];\n\n                        mv_predictor[pred_count][1] =\n\n                            s->cur_pic.motion_val[0][mot_index - mot_stride * mot_step][1];\n\n                        ref[pred_count] =\n\n                            s->cur_pic.ref_index[0][4 * (mb_xy - s->mb_stride)];\n\n                        pred_count++;\n\n                    }\n\n                    if (mb_y + 1<mb_height && fixed[mb_xy + mb_stride]) {\n\n                        mv_predictor[pred_count][0] =\n\n                            s->cur_pic.motion_val[0][mot_index + mot_stride * mot_step][0];\n\n                        mv_predictor[pred_count][1] =\n\n                            s->cur_pic.motion_val[0][mot_index + mot_stride * mot_step][1];\n\n                        ref[pred_count] =\n\n                            s->cur_pic.ref_index[0][4 * (mb_xy + s->mb_stride)];\n\n                        pred_count++;\n\n                    }\n\n                    if (pred_count == 0)\n\n                        continue;\n\n\n\n                    if (pred_count > 1) {\n\n                        int sum_x = 0, sum_y = 0, sum_r = 0;\n\n                        int max_x, max_y, min_x, min_y, max_r, min_r;\n\n\n\n                        for (j = 0; j < pred_count; j++) {\n\n                            sum_x += mv_predictor[j][0];\n\n                            sum_y += mv_predictor[j][1];\n\n                            sum_r += ref[j];\n\n                            if (j && ref[j] != ref[j - 1])\n\n                                goto skip_mean_and_median;\n\n                        }\n\n\n\n                        /* mean */\n\n                        mv_predictor[pred_count][0] = sum_x / j;\n\n                        mv_predictor[pred_count][1] = sum_y / j;\n\n                                 ref[pred_count]    = sum_r / j;\n\n\n\n                        /* median */\n\n                        if (pred_count >= 3) {\n\n                            min_y = min_x = min_r =  99999;\n\n                            max_y = max_x = max_r = -99999;\n\n                        } else {\n\n                            min_x = min_y = max_x = max_y = min_r = max_r = 0;\n\n                        }\n\n                        for (j = 0; j < pred_count; j++) {\n\n                            max_x = FFMAX(max_x, mv_predictor[j][0]);\n\n                            max_y = FFMAX(max_y, mv_predictor[j][1]);\n\n                            max_r = FFMAX(max_r, ref[j]);\n\n                            min_x = FFMIN(min_x, mv_predictor[j][0]);\n\n                            min_y = FFMIN(min_y, mv_predictor[j][1]);\n\n                            min_r = FFMIN(min_r, ref[j]);\n\n                        }\n\n                        mv_predictor[pred_count + 1][0] = sum_x - max_x - min_x;\n\n                        mv_predictor[pred_count + 1][1] = sum_y - max_y - min_y;\n\n                                 ref[pred_count + 1]    = sum_r - max_r - min_r;\n\n\n\n                        if (pred_count == 4) {\n\n                            mv_predictor[pred_count + 1][0] /= 2;\n\n                            mv_predictor[pred_count + 1][1] /= 2;\n\n                                     ref[pred_count + 1]    /= 2;\n\n                        }\n\n                        pred_count += 2;\n\n                    }\n\n\n\nskip_mean_and_median:\n\n                    /* zero MV */\n\n                    pred_count++;\n\n\n\n                    prev_x   = s->cur_pic.motion_val[0][mot_index][0];\n\n                    prev_y   = s->cur_pic.motion_val[0][mot_index][1];\n\n                    prev_ref = s->cur_pic.ref_index[0][4 * mb_xy];\n\n\n\n                    /* last MV */\n\n                    mv_predictor[pred_count][0] = prev_x;\n\n                    mv_predictor[pred_count][1] = prev_y;\n\n                             ref[pred_count]    = prev_ref;\n\n                    pred_count++;\n\n\n\n                    for (j = 0; j < pred_count; j++) {\n\n                        int *linesize = s->cur_pic.f->linesize;\n\n                        int score = 0;\n\n                        uint8_t *src = s->cur_pic.f->data[0] +\n\n                                       mb_x * 16 + mb_y * 16 * linesize[0];\n\n\n\n                        s->cur_pic.motion_val[0][mot_index][0] =\n\n                            s->mv[0][0][0] = mv_predictor[j][0];\n\n                        s->cur_pic.motion_val[0][mot_index][1] =\n\n                            s->mv[0][0][1] = mv_predictor[j][1];\n\n\n\n                        // predictor intra or otherwise not available\n\n                        if (ref[j] < 0)\n\n                            continue;\n\n\n\n                        s->decode_mb(s->opaque, ref[j], MV_DIR_FORWARD,\n\n                                     MV_TYPE_16X16, &s->mv, mb_x, mb_y, 0, 0);\n\n\n\n                        if (mb_x > 0 && fixed[mb_xy - 1]) {\n\n                            int k;\n\n                            for (k = 0; k < 16; k++)\n\n                                score += FFABS(src[k * linesize[0] - 1] -\n\n                                               src[k * linesize[0]]);\n\n                        }\n\n                        if (mb_x + 1 < mb_width && fixed[mb_xy + 1]) {\n\n                            int k;\n\n                            for (k = 0; k < 16; k++)\n\n                                score += FFABS(src[k * linesize[0] + 15] -\n\n                                               src[k * linesize[0] + 16]);\n\n                        }\n\n                        if (mb_y > 0 && fixed[mb_xy - mb_stride]) {\n\n                            int k;\n\n                            for (k = 0; k < 16; k++)\n\n                                score += FFABS(src[k - linesize[0]] - src[k]);\n\n                        }\n\n                        if (mb_y + 1 < mb_height && fixed[mb_xy + mb_stride]) {\n\n                            int k;\n\n                            for (k = 0; k < 16; k++)\n\n                                score += FFABS(src[k + linesize[0] * 15] -\n\n                                               src[k + linesize[0] * 16]);\n\n                        }\n\n\n\n                        if (score <= best_score) { // <= will favor the last MV\n\n                            best_score = score;\n\n                            best_pred  = j;\n\n                        }\n\n                    }\n\n                    score_sum += best_score;\n\n                    s->mv[0][0][0] = mv_predictor[best_pred][0];\n\n                    s->mv[0][0][1] = mv_predictor[best_pred][1];\n\n\n\n                    for (i = 0; i < mot_step; i++)\n\n                        for (j = 0; j < mot_step; j++) {\n\n                            s->cur_pic.motion_val[0][mot_index + i + j * mot_stride][0] = s->mv[0][0][0];\n\n                            s->cur_pic.motion_val[0][mot_index + i + j * mot_stride][1] = s->mv[0][0][1];\n\n                        }\n\n\n\n                    s->decode_mb(s->opaque, ref[best_pred], MV_DIR_FORWARD,\n\n                                 MV_TYPE_16X16, &s->mv, mb_x, mb_y, 0, 0);\n\n\n\n\n\n                    if (s->mv[0][0][0] != prev_x || s->mv[0][0][1] != prev_y) {\n\n                        fixed[mb_xy] = MV_CHANGED;\n\n                        changed++;\n\n                    } else\n\n                        fixed[mb_xy] = MV_UNCHANGED;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (none_left)\n\n            return;\n\n\n\n        for (i = 0; i < mb_width * mb_height; i++) {\n\n            int mb_xy = s->mb_index2xy[i];\n\n            if (fixed[mb_xy])\n\n                fixed[mb_xy] = MV_FROZEN;\n\n        }\n\n    }\n\n}\n", "idx": 9248, "_split": "valid", "_hash": "4cb381d7fe948d595d098a838af55ab2"}
{"project": "FFmpeg", "commit_id": "4381bddc9f93da34a44e683bdc4c05c6f061244e", "target": 0, "func": "static void ff_dlog_link(void *ctx, AVFilterLink *link, int end)\n\n{\n\n    if (link->type == AVMEDIA_TYPE_VIDEO) {\n\n        av_dlog(ctx,\n\n                \"link[%p s:%dx%d fmt:%-16s %-16s->%-16s]%s\",\n\n                link, link->w, link->h,\n\n                av_pix_fmt_descriptors[link->format].name,\n\n                link->src ? link->src->filter->name : \"\",\n\n                link->dst ? link->dst->filter->name : \"\",\n\n                end ? \"\\n\" : \"\");\n\n    } else {\n\n        char buf[128];\n\n        av_get_channel_layout_string(buf, sizeof(buf), -1, link->channel_layout);\n\n\n\n        av_dlog(ctx,\n\n                \"link[%p r:%\"PRId64\" cl:%s fmt:%-16s %-16s->%-16s]%s\",\n\n                link, link->sample_rate, buf,\n\n                av_get_sample_fmt_name(link->format),\n\n                link->src ? link->src->filter->name : \"\",\n\n                link->dst ? link->dst->filter->name : \"\",\n\n                end ? \"\\n\" : \"\");\n\n    }\n\n}\n", "idx": 9327, "_split": "valid", "_hash": "0fc62517a597d138887c81158c8e9864"}
{"project": "FFmpeg", "commit_id": "f37246952a65c675c1e4a229ea95a0f82f32b084", "target": 0, "func": "static int http_connect(URLContext *h, const char *path, const char *hoststr,\n\n                        const char *auth, int *new_location)\n\n{\n\n    HTTPContext *s = h->priv_data;\n\n    int post, err;\n\n    char line[1024];\n\n    char headers[1024] = \"\";\n\n    char *authstr = NULL;\n\n    int64_t off = s->off;\n\n    int len = 0;\n\n\n\n\n\n    /* send http header */\n\n    post = h->flags & URL_WRONLY;\n\n    authstr = ff_http_auth_create_response(&s->auth_state, auth, path,\n\n                                        post ? \"POST\" : \"GET\");\n\n\n\n    /* set default headers if needed */\n\n    if (!has_header(s->headers, \"\\r\\nUser-Agent: \"))\n\n       len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                          \"User-Agent: %s\\r\\n\", LIBAVFORMAT_IDENT);\n\n    if (!has_header(s->headers, \"\\r\\nAccept: \"))\n\n        len += av_strlcpy(headers + len, \"Accept: */*\\r\\n\",\n\n                          sizeof(headers) - len);\n\n    if (!has_header(s->headers, \"\\r\\nRange: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Range: bytes=%\"PRId64\"-\\r\\n\", s->off);\n\n    if (!has_header(s->headers, \"\\r\\nConnection: \"))\n\n        len += av_strlcpy(headers + len, \"Connection: close\\r\\n\",\n\n                          sizeof(headers)-len);\n\n    if (!has_header(s->headers, \"\\r\\nHost: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Host: %s\\r\\n\", hoststr);\n\n\n\n    /* now add in custom headers */\n\n    av_strlcpy(headers+len, s->headers, sizeof(headers)-len);\n\n\n\n    snprintf(s->buffer, sizeof(s->buffer),\n\n             \"%s %s HTTP/1.1\\r\\n\"\n\n             \"%s\"\n\n             \"%s\"\n\n             \"%s\"\n\n             \"\\r\\n\",\n\n             post ? \"POST\" : \"GET\",\n\n             path,\n\n             post && s->is_chunked ? \"Transfer-Encoding: chunked\\r\\n\" : \"\",\n\n             headers,\n\n             authstr ? authstr : \"\");\n\n\n\n    av_freep(&authstr);\n\n    if (http_write(h, s->buffer, strlen(s->buffer)) < 0)\n\n        return AVERROR(EIO);\n\n\n\n    /* init input buffer */\n\n    s->buf_ptr = s->buffer;\n\n    s->buf_end = s->buffer;\n\n    s->line_count = 0;\n\n    s->off = 0;\n\n    s->filesize = -1;\n\n    if (post) {\n\n        /* always use chunked encoding for upload data */\n\n        s->chunksize = 0;\n\n        /* Pretend that it did work. We didn't read any header yet, since\n\n         * we've still to send the POST data, but the code calling this\n\n         * function will check http_code after we return. */\n\n        s->http_code = 200;\n\n        return 0;\n\n    }\n\n\n\n    /* wait for header */\n\n    for(;;) {\n\n        if (http_get_line(s, line, sizeof(line)) < 0)\n\n            return AVERROR(EIO);\n\n\n\n        dprintf(NULL, \"header='%s'\\n\", line);\n\n\n\n        err = process_line(h, line, s->line_count, new_location);\n\n        if (err < 0)\n\n            return err;\n\n        if (err == 0)\n\n            break;\n\n        s->line_count++;\n\n    }\n\n\n\n    return (off == s->off) ? 0 : -1;\n\n}\n", "idx": 9356, "_split": "valid", "_hash": "3215864401ee31e6b4657ca3d178ebe3"}
{"project": "FFmpeg", "commit_id": "6a6bc43f5f79587b8936334cc0b3a6616f4807ac", "target": 0, "func": "static int dxtory_decode_v2_rgb(AVCodecContext *avctx, AVFrame *pic,\n\n                                const uint8_t *src, int src_size)\n\n{\n\n    GetByteContext gb;\n\n    GetBitContext  gb2;\n\n    int nslices, slice, slice_height;\n\n    uint32_t off, slice_size;\n\n    uint8_t *dst;\n\n    int ret;\n\n\n\n    bytestream2_init(&gb, src, src_size);\n\n    nslices = bytestream2_get_le16(&gb);\n\n    off = FFALIGN(nslices * 4 + 2, 16);\n\n    if (src_size < off) {\n\n        av_log(avctx, AV_LOG_ERROR, \"no slice data\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (!nslices || avctx->height % nslices) {\n\n        avpriv_request_sample(avctx, \"%d slices for %dx%d\", nslices,\n\n                              avctx->width, avctx->height);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    slice_height = avctx->height / nslices;\n\n    avctx->pix_fmt = AV_PIX_FMT_BGR24;\n\n    if ((ret = ff_get_buffer(avctx, pic, 0)) < 0)\n\n        return ret;\n\n\n\n    dst = pic->data[0];\n\n    for (slice = 0; slice < nslices; slice++) {\n\n        slice_size = bytestream2_get_le32(&gb);\n\n        if (slice_size > src_size - off) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"invalid slice size %\"PRIu32\" (only %\"PRIu32\" bytes left)\\n\",\n\n                   slice_size, src_size - off);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (slice_size <= 16) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid slice size %\"PRIu32\"\\n\",\n\n                   slice_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (AV_RL32(src + off) != slice_size - 16) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Slice sizes mismatch: got %\"PRIu32\" instead of %\"PRIu32\"\\n\",\n\n                   AV_RL32(src + off), slice_size - 16);\n\n        }\n\n        init_get_bits(&gb2, src + off + 16, (slice_size - 16) * 8);\n\n        dx2_decode_slice_rgb(&gb2, avctx->width, slice_height, dst,\n\n                             pic->linesize[0]);\n\n\n\n        dst += pic->linesize[0] * slice_height;\n\n        off += slice_size;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 9358, "_split": "valid", "_hash": "9c0030d90f13aaa52bab302dac948c76"}
{"project": "FFmpeg", "commit_id": "af19f78f2fe2b969104d4419efd25fdee90a2814", "target": 0, "func": "void dsputil_init_mlib(void)\n\n{\n\n    put_pixels_tab[0][0] = put_pixels16_mlib;\n\n    put_pixels_tab[0][1] = put_pixels16_x2_mlib;\n\n    put_pixels_tab[0][2] = put_pixels16_y2_mlib;\n\n    put_pixels_tab[0][3] = put_pixels16_xy2_mlib;\n\n    put_pixels_tab[1][0] = put_pixels8_mlib;\n\n    put_pixels_tab[1][1] = put_pixels8_x2_mlib;\n\n    put_pixels_tab[1][2] = put_pixels8_y2_mlib;\n\n    put_pixels_tab[1][3] = put_pixels8_xy2_mlib;\n\n\n\n    avg_pixels_tab[0][0] = avg_pixels16_mlib;\n\n    avg_pixels_tab[0][1] = avg_pixels16_x2_mlib;\n\n    avg_pixels_tab[0][2] = avg_pixels16_y2_mlib;\n\n    avg_pixels_tab[0][3] = avg_pixels16_xy2_mlib;\n\n    avg_pixels_tab[1][0] = avg_pixels8_mlib;\n\n    avg_pixels_tab[1][1] = avg_pixels8_x2_mlib;\n\n    avg_pixels_tab[1][2] = avg_pixels8_y2_mlib;\n\n    avg_pixels_tab[1][3] = avg_pixels8_xy2_mlib;\n\n    \n\n    put_no_rnd_pixels_tab[0][0] = put_pixels16_mlib;\n\n    put_no_rnd_pixels_tab[1][0] = put_pixels8_mlib;\n\n    \n\n    add_pixels_clamped = add_pixels_clamped_mlib;\n\n}\n", "idx": 9359, "_split": "valid", "_hash": "ffc20d7663245ee6d717374a10db3657"}
{"project": "FFmpeg", "commit_id": "42ee137a0a7d025f77964e38b438d00095e6dd11", "target": 1, "func": "static av_cold int m101_decode_init(AVCodecContext *avctx)\n\n{\n\n    if (avctx->extradata_size < 6*4)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (avctx->extradata[2*4] == 10)\n\n        avctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n\n    else\n\n        avctx->pix_fmt = AV_PIX_FMT_YUYV422;\n\n\n\n\n\n    return 0;\n\n}\n", "idx": 9408, "_split": "valid", "_hash": "9832a30e033db03f35b679d01904743b"}
{"project": "FFmpeg", "commit_id": "c06e556274446a45efab34745c05049033389260", "target": 1, "func": "static int mpeg4_decode_mb(MpegEncContext *s, int16_t block[6][64])\n\n{\n\n    Mpeg4DecContext *ctx = (Mpeg4DecContext *)s;\n\n    int cbpc, cbpy, i, cbp, pred_x, pred_y, mx, my, dquant;\n\n    int16_t *mot_val;\n\n    static const int8_t quant_tab[4] = { -1, -2, 1, 2 };\n\n    const int xy = s->mb_x + s->mb_y * s->mb_stride;\n\n\n\n    av_assert2(s->h263_pred);\n\n\n\n    if (s->pict_type == AV_PICTURE_TYPE_P ||\n\n        s->pict_type == AV_PICTURE_TYPE_S) {\n\n        do {\n\n            if (get_bits1(&s->gb)) {\n\n                /* skip mb */\n\n                s->mb_intra = 0;\n\n                for (i = 0; i < 6; i++)\n\n                    s->block_last_index[i] = -1;\n\n                s->mv_dir  = MV_DIR_FORWARD;\n\n                s->mv_type = MV_TYPE_16X16;\n\n                if (s->pict_type == AV_PICTURE_TYPE_S &&\n\n                    ctx->vol_sprite_usage == GMC_SPRITE) {\n\n                    s->current_picture.mb_type[xy] = MB_TYPE_SKIP  |\n\n                                                     MB_TYPE_GMC   |\n\n                                                     MB_TYPE_16x16 |\n\n                                                     MB_TYPE_L0;\n\n                    s->mcsel       = 1;\n\n                    s->mv[0][0][0] = get_amv(ctx, 0);\n\n                    s->mv[0][0][1] = get_amv(ctx, 1);\n\n                    s->mb_skipped  = 0;\n\n                } else {\n\n                    s->current_picture.mb_type[xy] = MB_TYPE_SKIP  |\n\n                                                     MB_TYPE_16x16 |\n\n                                                     MB_TYPE_L0;\n\n                    s->mcsel       = 0;\n\n                    s->mv[0][0][0] = 0;\n\n                    s->mv[0][0][1] = 0;\n\n                    s->mb_skipped  = 1;\n\n\n                goto end;\n\n\n            cbpc = get_vlc2(&s->gb, ff_h263_inter_MCBPC_vlc.table, INTER_MCBPC_VLC_BITS, 2);\n\n            if (cbpc < 0) {\n\n\n                       \"mcbpc damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n                return -1;\n\n\n        } while (cbpc == 20);\n\n\n\n        s->bdsp.clear_blocks(s->block[0]);\n\n        dquant      = cbpc & 8;\n\n        s->mb_intra = ((cbpc & 4) != 0);\n\n        if (s->mb_intra)\n\n            goto intra;\n\n\n\n        if (s->pict_type == AV_PICTURE_TYPE_S &&\n\n            ctx->vol_sprite_usage == GMC_SPRITE && (cbpc & 16) == 0)\n\n            s->mcsel = get_bits1(&s->gb);\n\n        else\n\n            s->mcsel = 0;\n\n        cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1) ^ 0x0F;\n\n\n\n\n\n\n\n\n        cbp = (cbpc & 3) | (cbpy << 2);\n\n        if (dquant)\n\n            ff_set_qscale(s, s->qscale + quant_tab[get_bits(&s->gb, 2)]);\n\n        if ((!s->progressive_sequence) &&\n\n            (cbp || (s->workaround_bugs & FF_BUG_XVID_ILACE)))\n\n            s->interlaced_dct = get_bits1(&s->gb);\n\n\n\n        s->mv_dir = MV_DIR_FORWARD;\n\n        if ((cbpc & 16) == 0) {\n\n            if (s->mcsel) {\n\n                s->current_picture.mb_type[xy] = MB_TYPE_GMC   |\n\n                                                 MB_TYPE_16x16 |\n\n                                                 MB_TYPE_L0;\n\n                /* 16x16 global motion prediction */\n\n                s->mv_type     = MV_TYPE_16X16;\n\n                mx             = get_amv(ctx, 0);\n\n                my             = get_amv(ctx, 1);\n\n                s->mv[0][0][0] = mx;\n\n                s->mv[0][0][1] = my;\n\n            } else if ((!s->progressive_sequence) && get_bits1(&s->gb)) {\n\n                s->current_picture.mb_type[xy] = MB_TYPE_16x8 |\n\n                                                 MB_TYPE_L0   |\n\n                                                 MB_TYPE_INTERLACED;\n\n                /* 16x8 field motion prediction */\n\n                s->mv_type = MV_TYPE_FIELD;\n\n\n\n                s->field_select[0][0] = get_bits1(&s->gb);\n\n                s->field_select[0][1] = get_bits1(&s->gb);\n\n\n\n                ff_h263_pred_motion(s, 0, 0, &pred_x, &pred_y);\n\n\n\n                for (i = 0; i < 2; i++) {\n\n                    mx = ff_h263_decode_motion(s, pred_x, s->f_code);\n\n                    if (mx >= 0xffff)\n\n                        return -1;\n\n\n\n                    my = ff_h263_decode_motion(s, pred_y / 2, s->f_code);\n\n                    if (my >= 0xffff)\n\n                        return -1;\n\n\n\n                    s->mv[0][i][0] = mx;\n\n                    s->mv[0][i][1] = my;\n\n\n            } else {\n\n                s->current_picture.mb_type[xy] = MB_TYPE_16x16 | MB_TYPE_L0;\n\n                /* 16x16 motion prediction */\n\n                s->mv_type = MV_TYPE_16X16;\n\n                ff_h263_pred_motion(s, 0, 0, &pred_x, &pred_y);\n\n                mx = ff_h263_decode_motion(s, pred_x, s->f_code);\n\n\n\n                if (mx >= 0xffff)\n\n                    return -1;\n\n\n\n                my = ff_h263_decode_motion(s, pred_y, s->f_code);\n\n\n\n                if (my >= 0xffff)\n\n                    return -1;\n\n                s->mv[0][0][0] = mx;\n\n                s->mv[0][0][1] = my;\n\n\n        } else {\n\n            s->current_picture.mb_type[xy] = MB_TYPE_8x8 | MB_TYPE_L0;\n\n            s->mv_type                     = MV_TYPE_8X8;\n\n            for (i = 0; i < 4; i++) {\n\n                mot_val = ff_h263_pred_motion(s, i, 0, &pred_x, &pred_y);\n\n                mx      = ff_h263_decode_motion(s, pred_x, s->f_code);\n\n                if (mx >= 0xffff)\n\n                    return -1;\n\n\n\n                my = ff_h263_decode_motion(s, pred_y, s->f_code);\n\n                if (my >= 0xffff)\n\n                    return -1;\n\n                s->mv[0][i][0] = mx;\n\n                s->mv[0][i][1] = my;\n\n                mot_val[0]     = mx;\n\n                mot_val[1]     = my;\n\n\n\n    } else if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n        int modb1;   // first bit of modb\n\n        int modb2;   // second bit of modb\n\n        int mb_type;\n\n\n\n        s->mb_intra = 0;  // B-frames never contain intra blocks\n\n        s->mcsel    = 0;  //      ...               true gmc blocks\n\n\n\n        if (s->mb_x == 0) {\n\n            for (i = 0; i < 2; i++) {\n\n                s->last_mv[i][0][0] =\n\n                s->last_mv[i][0][1] =\n\n                s->last_mv[i][1][0] =\n\n                s->last_mv[i][1][1] = 0;\n\n\n\n\n            ff_thread_await_progress(&s->next_picture_ptr->tf, s->mb_y, 0);\n\n\n\n\n        /* if we skipped it in the future P Frame than skip it now too */\n\n        s->mb_skipped = s->next_picture.mbskip_table[s->mb_y * s->mb_stride + s->mb_x];  // Note, skiptab=0 if last was GMC\n\n\n\n        if (s->mb_skipped) {\n\n            /* skip mb */\n\n            for (i = 0; i < 6; i++)\n\n                s->block_last_index[i] = -1;\n\n\n\n            s->mv_dir      = MV_DIR_FORWARD;\n\n            s->mv_type     = MV_TYPE_16X16;\n\n            s->mv[0][0][0] =\n\n            s->mv[0][0][1] =\n\n            s->mv[1][0][0] =\n\n            s->mv[1][0][1] = 0;\n\n            s->current_picture.mb_type[xy] = MB_TYPE_SKIP  |\n\n                                             MB_TYPE_16x16 |\n\n                                             MB_TYPE_L0;\n\n            goto end;\n\n\n\n\n        modb1 = get_bits1(&s->gb);\n\n        if (modb1) {\n\n            // like MB_TYPE_B_DIRECT but no vectors coded\n\n            mb_type = MB_TYPE_DIRECT2 | MB_TYPE_SKIP | MB_TYPE_L0L1;\n\n            cbp     = 0;\n\n        } else {\n\n            modb2   = get_bits1(&s->gb);\n\n            mb_type = get_vlc2(&s->gb, mb_type_b_vlc.table, MB_TYPE_B_VLC_BITS, 1);\n\n            if (mb_type < 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"illegal MB_type\\n\");\n\n                return -1;\n\n\n            mb_type = mb_type_b_map[mb_type];\n\n            if (modb2) {\n\n                cbp = 0;\n\n            } else {\n\n                s->bdsp.clear_blocks(s->block[0]);\n\n                cbp = get_bits(&s->gb, 6);\n\n\n\n\n            if ((!IS_DIRECT(mb_type)) && cbp) {\n\n                if (get_bits1(&s->gb))\n\n                    ff_set_qscale(s, s->qscale + get_bits1(&s->gb) * 4 - 2);\n\n\n\n\n            if (!s->progressive_sequence) {\n\n                if (cbp)\n\n                    s->interlaced_dct = get_bits1(&s->gb);\n\n\n\n                if (!IS_DIRECT(mb_type) && get_bits1(&s->gb)) {\n\n                    mb_type |= MB_TYPE_16x8 | MB_TYPE_INTERLACED;\n\n                    mb_type &= ~MB_TYPE_16x16;\n\n\n\n                    if (USES_LIST(mb_type, 0)) {\n\n                        s->field_select[0][0] = get_bits1(&s->gb);\n\n                        s->field_select[0][1] = get_bits1(&s->gb);\n\n\n                    if (USES_LIST(mb_type, 1)) {\n\n                        s->field_select[1][0] = get_bits1(&s->gb);\n\n                        s->field_select[1][1] = get_bits1(&s->gb);\n\n\n\n\n\n\n            s->mv_dir = 0;\n\n            if ((mb_type & (MB_TYPE_DIRECT2 | MB_TYPE_INTERLACED)) == 0) {\n\n                s->mv_type = MV_TYPE_16X16;\n\n\n\n                if (USES_LIST(mb_type, 0)) {\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n\n\n                    mx = ff_h263_decode_motion(s, s->last_mv[0][0][0], s->f_code);\n\n                    my = ff_h263_decode_motion(s, s->last_mv[0][0][1], s->f_code);\n\n                    s->last_mv[0][1][0] =\n\n                    s->last_mv[0][0][0] =\n\n                    s->mv[0][0][0]      = mx;\n\n                    s->last_mv[0][1][1] =\n\n                    s->last_mv[0][0][1] =\n\n                    s->mv[0][0][1]      = my;\n\n\n\n\n                if (USES_LIST(mb_type, 1)) {\n\n                    s->mv_dir |= MV_DIR_BACKWARD;\n\n\n\n                    mx = ff_h263_decode_motion(s, s->last_mv[1][0][0], s->b_code);\n\n                    my = ff_h263_decode_motion(s, s->last_mv[1][0][1], s->b_code);\n\n                    s->last_mv[1][1][0] =\n\n                    s->last_mv[1][0][0] =\n\n                    s->mv[1][0][0]      = mx;\n\n                    s->last_mv[1][1][1] =\n\n                    s->last_mv[1][0][1] =\n\n                    s->mv[1][0][1]      = my;\n\n\n            } else if (!IS_DIRECT(mb_type)) {\n\n                s->mv_type = MV_TYPE_FIELD;\n\n\n\n                if (USES_LIST(mb_type, 0)) {\n\n                    s->mv_dir = MV_DIR_FORWARD;\n\n\n\n                    for (i = 0; i < 2; i++) {\n\n                        mx = ff_h263_decode_motion(s, s->last_mv[0][i][0], s->f_code);\n\n                        my = ff_h263_decode_motion(s, s->last_mv[0][i][1] / 2, s->f_code);\n\n                        s->last_mv[0][i][0] =\n\n                        s->mv[0][i][0]      = mx;\n\n                        s->last_mv[0][i][1] = (s->mv[0][i][1] = my) * 2;\n\n\n\n\n\n                if (USES_LIST(mb_type, 1)) {\n\n                    s->mv_dir |= MV_DIR_BACKWARD;\n\n\n\n                    for (i = 0; i < 2; i++) {\n\n                        mx = ff_h263_decode_motion(s, s->last_mv[1][i][0], s->b_code);\n\n                        my = ff_h263_decode_motion(s, s->last_mv[1][i][1] / 2, s->b_code);\n\n                        s->last_mv[1][i][0] =\n\n                        s->mv[1][i][0]      = mx;\n\n                        s->last_mv[1][i][1] = (s->mv[1][i][1] = my) * 2;\n\n\n\n\n\n\n\n        if (IS_DIRECT(mb_type)) {\n\n            if (IS_SKIP(mb_type)) {\n\n                mx =\n\n                my = 0;\n\n            } else {\n\n                mx = ff_h263_decode_motion(s, 0, 1);\n\n                my = ff_h263_decode_motion(s, 0, 1);\n\n\n\n\n            s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT;\n\n            mb_type  |= ff_mpeg4_set_direct_mv(s, mx, my);\n\n\n        s->current_picture.mb_type[xy] = mb_type;\n\n    } else { /* I-Frame */\n\n        do {\n\n            cbpc = get_vlc2(&s->gb, ff_h263_intra_MCBPC_vlc.table, INTRA_MCBPC_VLC_BITS, 2);\n\n            if (cbpc < 0) {\n\n\n                       \"I cbpc damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n                return -1;\n\n\n        } while (cbpc == 8);\n\n\n\n        dquant = cbpc & 4;\n\n        s->mb_intra = 1;\n\n\n\nintra:\n\n        s->ac_pred = get_bits1(&s->gb);\n\n        if (s->ac_pred)\n\n            s->current_picture.mb_type[xy] = MB_TYPE_INTRA | MB_TYPE_ACPRED;\n\n        else\n\n            s->current_picture.mb_type[xy] = MB_TYPE_INTRA;\n\n\n\n        cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1);\n\n\n\n                   \"I cbpy damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n\n        cbp = (cbpc & 3) | (cbpy << 2);\n\n\n\n        ctx->use_intra_dc_vlc = s->qscale < ctx->intra_dc_threshold;\n\n\n\n        if (dquant)\n\n            ff_set_qscale(s, s->qscale + quant_tab[get_bits(&s->gb, 2)]);\n\n\n\n        if (!s->progressive_sequence)\n\n            s->interlaced_dct = get_bits1(&s->gb);\n\n\n\n        s->bdsp.clear_blocks(s->block[0]);\n\n        /* decode each block */\n\n        for (i = 0; i < 6; i++) {\n\n            if (mpeg4_decode_block(ctx, block[i], i, cbp & 32, 1, 0) < 0)\n\n                return -1;\n\n            cbp += cbp;\n\n\n        goto end;\n\n\n\n\n    /* decode each block */\n\n    for (i = 0; i < 6; i++) {\n\n        if (mpeg4_decode_block(ctx, block[i], i, cbp & 32, 0, 0) < 0)\n\n            return -1;\n\n        cbp += cbp;\n\n\n\n\nend:\n\n    /* per-MB end of slice check */\n\n    if (s->codec_id == AV_CODEC_ID_MPEG4) {\n\n        int next = mpeg4_is_resync(ctx);\n\n        if (next) {\n\n            if        (s->mb_x + s->mb_y*s->mb_width + 1 >  next && (s->avctx->err_recognition & AV_EF_AGGRESSIVE)) {\n\n                return -1;\n\n            } else if (s->mb_x + s->mb_y*s->mb_width + 1 >= next)\n\n                return SLICE_END;\n\n\n\n            if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n                const int delta= s->mb_x + 1 == s->mb_width ? 2 : 1;\n\n                ff_thread_await_progress(&s->next_picture_ptr->tf,\n\n                                         (s->mb_x + delta >= s->mb_width)\n\n                                         ? FFMIN(s->mb_y + 1, s->mb_height - 1)\n\n                                         : s->mb_y, 0);\n\n                if (s->next_picture.mbskip_table[xy + delta])\n\n                    return SLICE_OK;\n\n\n\n\n            return SLICE_END;\n\n\n\n\n\n    return SLICE_OK;\n", "idx": 9427, "_split": "valid", "_hash": "02786f51b4dce8d968089b07a2b4490c"}
{"project": "FFmpeg", "commit_id": "45198477de19ccb00729b7eec07d81494f0353e0", "target": 1, "func": "static inline void FUNC(idctSparseCol_extrashift)(int16_t *col)\n\n#else\n\nstatic inline void FUNC(idctSparseColPut)(pixel *dest, int line_size,\n\n                                          int16_t *col)\n\n{\n\n    int a0, a1, a2, a3, b0, b1, b2, b3;\n\n\n\n    IDCT_COLS;\n\n\n\n    dest[0] = av_clip_pixel((a0 + b0) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel((a1 + b1) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel((a2 + b2) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel((a3 + b3) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel((a3 - b3) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel((a2 - b2) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel((a1 - b1) >> COL_SHIFT);\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel((a0 - b0) >> COL_SHIFT);\n\n}\n\n\n\nstatic inline void FUNC(idctSparseColAdd)(pixel *dest, int line_size,\n\n                                          int16_t *col)\n\n{\n\n    int a0, a1, a2, a3, b0, b1, b2, b3;\n\n\n\n    IDCT_COLS;\n\n\n\n    dest[0] = av_clip_pixel(dest[0] + ((a0 + b0) >> COL_SHIFT));\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel(dest[0] + ((a1 + b1) >> COL_SHIFT));\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel(dest[0] + ((a2 + b2) >> COL_SHIFT));\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel(dest[0] + ((a3 + b3) >> COL_SHIFT));\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel(dest[0] + ((a3 - b3) >> COL_SHIFT));\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel(dest[0] + ((a2 - b2) >> COL_SHIFT));\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel(dest[0] + ((a1 - b1) >> COL_SHIFT));\n\n    dest += line_size;\n\n    dest[0] = av_clip_pixel(dest[0] + ((a0 - b0) >> COL_SHIFT));\n\n}\n\n\n\nstatic inline void FUNC(idctSparseCol)(int16_t *col)\n\n#endif\n\n{\n\n    int a0, a1, a2, a3, b0, b1, b2, b3;\n\n\n\n    IDCT_COLS;\n\n\n\n    col[0 ] = ((a0 + b0) >> COL_SHIFT);\n\n    col[8 ] = ((a1 + b1) >> COL_SHIFT);\n\n    col[16] = ((a2 + b2) >> COL_SHIFT);\n\n    col[24] = ((a3 + b3) >> COL_SHIFT);\n\n    col[32] = ((a3 - b3) >> COL_SHIFT);\n\n    col[40] = ((a2 - b2) >> COL_SHIFT);\n\n    col[48] = ((a1 - b1) >> COL_SHIFT);\n\n    col[56] = ((a0 - b0) >> COL_SHIFT);\n\n}\n", "idx": 9464, "_split": "valid", "_hash": "7f18f8bfe4ce5538b7a54611afdb0a81"}
{"project": "FFmpeg", "commit_id": "0ce3a0f9d9523a9bcad4c6d451ca5bbd7a4f420d", "target": 1, "func": "static void restore_median(uint8_t *src, int step, int stride,\n\n                           int width, int height, int slices, int rmode)\n\n{\n\n    int i, j, slice;\n\n    int A, B, C;\n\n    uint8_t *bsrc;\n\n    int slice_start, slice_height;\n\n    const int cmask = ~rmode;\n\n\n\n    for (slice = 0; slice < slices; slice++) {\n\n        slice_start  = ((slice * height) / slices) & cmask;\n\n        slice_height = ((((slice + 1) * height) / slices) & cmask) -\n\n                       slice_start;\n\n\n\n\n\n        bsrc = src + slice_start * stride;\n\n\n\n        // first line - left neighbour prediction\n\n        bsrc[0] += 0x80;\n\n        A = bsrc[0];\n\n        for (i = step; i < width * step; i += step) {\n\n            bsrc[i] += A;\n\n            A        = bsrc[i];\n\n        }\n\n        bsrc += stride;\n\n        if (slice_height == 1)\n\n\n        // second line - first element has top prediction, the rest uses median\n\n        C        = bsrc[-stride];\n\n        bsrc[0] += C;\n\n        A        = bsrc[0];\n\n        for (i = step; i < width * step; i += step) {\n\n            B        = bsrc[i - stride];\n\n            bsrc[i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n            C        = B;\n\n            A        = bsrc[i];\n\n        }\n\n        bsrc += stride;\n\n        // the rest of lines use continuous median prediction\n\n        for (j = 2; j < slice_height; j++) {\n\n            for (i = 0; i < width * step; i += step) {\n\n                B        = bsrc[i - stride];\n\n                bsrc[i] += mid_pred(A, B, (uint8_t)(A + B - C));\n\n                C        = B;\n\n                A        = bsrc[i];\n\n            }\n\n            bsrc += stride;\n\n        }\n\n    }\n\n}", "idx": 9466, "_split": "valid", "_hash": "b9ae7cc1134ff4bf46564550c2fc6193"}
{"project": "FFmpeg", "commit_id": "25715064c2ef4978672a91f8c856f3e8809a7c45", "target": 0, "func": "static int decode_seq_header(AVSContext *h) {\n\n    MpegEncContext *s = &h->s;\n\n    int frame_rate_code;\n\n\n\n    h->profile =         get_bits(&s->gb,8);\n\n    h->level =           get_bits(&s->gb,8);\n\n    skip_bits1(&s->gb); //progressive sequence\n\n    s->width =           get_bits(&s->gb,14);\n\n    s->height =          get_bits(&s->gb,14);\n\n    skip_bits(&s->gb,2); //chroma format\n\n    skip_bits(&s->gb,3); //sample_precision\n\n    h->aspect_ratio =    get_bits(&s->gb,4);\n\n    frame_rate_code =    get_bits(&s->gb,4);\n\n    skip_bits(&s->gb,18);//bit_rate_lower\n\n    skip_bits1(&s->gb);  //marker_bit\n\n    skip_bits(&s->gb,12);//bit_rate_upper\n\n    s->low_delay =       get_bits1(&s->gb);\n\n    h->mb_width  = (s->width  + 15) >> 4;\n\n    h->mb_height = (s->height + 15) >> 4;\n\n    h->s.avctx->time_base.den = avpriv_frame_rate_tab[frame_rate_code].num;\n\n    h->s.avctx->time_base.num = avpriv_frame_rate_tab[frame_rate_code].den;\n\n    h->s.avctx->width  = s->width;\n\n    h->s.avctx->height = s->height;\n\n    if(!h->top_qp)\n\n        ff_cavs_init_top_lines(h);\n\n    return 0;\n\n}\n", "idx": 9481, "_split": "valid", "_hash": "47cc1502755e2f1a1bc6a0327825d38c"}
{"project": "FFmpeg", "commit_id": "d9d9fd9446eb722fd288f56d905f0dfde661af8f", "target": 1, "func": "int ff_mpeg_er_init(MpegEncContext *s)\n\n{\n\n    ERContext *er = &s->er;\n\n    int mb_array_size = s->mb_height * s->mb_stride;\n\n    int i;\n\n\n\n    er->avctx       = s->avctx;\n\n\n\n    er->mb_index2xy = s->mb_index2xy;\n\n    er->mb_num      = s->mb_num;\n\n    er->mb_width    = s->mb_width;\n\n    er->mb_height   = s->mb_height;\n\n    er->mb_stride   = s->mb_stride;\n\n    er->b8_stride   = s->b8_stride;\n\n\n\n    er->er_temp_buffer     = av_malloc(s->mb_height * s->mb_stride);\n\n    er->error_status_table = av_mallocz(mb_array_size);\n\n    if (!er->er_temp_buffer || !er->error_status_table)\n\n        goto fail;\n\n\n\n    er->mbskip_table  = s->mbskip_table;\n\n    er->mbintra_table = s->mbintra_table;\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->dc_val); i++)\n\n        er->dc_val[i] = s->dc_val[i];\n\n\n\n    er->decode_mb = mpeg_er_decode_mb;\n\n    er->opaque    = s;\n\n\n\n    return 0;\n\nfail:\n\n    av_freep(&er->er_temp_buffer);\n\n    av_freep(&er->error_status_table);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 9483, "_split": "valid", "_hash": "1ab0b2f8168f2c79a0be55c8c69bb82f"}
{"project": "FFmpeg", "commit_id": "4f00519d9508e07aac58a00a9b514dae8ad95723", "target": 1, "func": "int vc1_decode_entry_point(AVCodecContext *avctx, VC1Context *v, GetBitContext *gb)\n\n{\n\n    int i;\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Entry point: %08X\\n\", show_bits_long(gb, 32));\n\n    v->broken_link = get_bits1(gb);\n\n    v->closed_entry = get_bits1(gb);\n\n    v->panscanflag = get_bits1(gb);\n\n    v->refdist_flag = get_bits1(gb);\n\n    v->s.loop_filter = get_bits1(gb);\n\n    v->fastuvmc = get_bits1(gb);\n\n    v->extended_mv = get_bits1(gb);\n\n    v->dquant = get_bits(gb, 2);\n\n    v->vstransform = get_bits1(gb);\n\n    v->overlap = get_bits1(gb);\n\n    v->quantizer_mode = get_bits(gb, 2);\n\n\n\n    if(v->hrd_param_flag){\n\n        for(i = 0; i < v->hrd_num_leaky_buckets; i++) {\n\n            skip_bits(gb, 8); //hrd_full[n]\n\n        }\n\n    }\n\n\n\n    if(get_bits1(gb)){\n\n        avctx->coded_width = (get_bits(gb, 12)+1)<<1;\n\n        avctx->coded_height = (get_bits(gb, 12)+1)<<1;\n\n    }\n\n    if(v->extended_mv)\n\n        v->extended_dmv = get_bits1(gb);\n\n    if((v->range_mapy_flag = get_bits1(gb))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Luma scaling is not supported, expect wrong picture\\n\");\n\n        v->range_mapy = get_bits(gb, 3);\n\n    }\n\n    if((v->range_mapuv_flag = get_bits1(gb))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Chroma scaling is not supported, expect wrong picture\\n\");\n\n        v->range_mapuv = get_bits(gb, 3);\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Entry point info:\\n\"\n\n        \"BrokenLink=%i, ClosedEntry=%i, PanscanFlag=%i\\n\"\n\n        \"RefDist=%i, Postproc=%i, FastUVMC=%i, ExtMV=%i\\n\"\n\n        \"DQuant=%i, VSTransform=%i, Overlap=%i, Qmode=%i\\n\",\n\n        v->broken_link, v->closed_entry, v->panscanflag, v->refdist_flag, v->s.loop_filter,\n\n        v->fastuvmc, v->extended_mv, v->dquant, v->vstransform, v->overlap, v->quantizer_mode);\n\n\n\n    return 0;\n\n}\n", "idx": 9515, "_split": "valid", "_hash": "ac1ca9073f176c12c0bc7ef7cc06fdd1"}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(bgr24ToUV_half)(uint8_t *dstU, uint8_t *dstV, const uint8_t *src1, const uint8_t *src2, int width, uint32_t *unused)\n\n{\n\n    int i;\n\n    for (i=0; i<width; i++) {\n\n        int b= src1[6*i + 0] + src1[6*i + 3];\n\n        int g= src1[6*i + 1] + src1[6*i + 4];\n\n        int r= src1[6*i + 2] + src1[6*i + 5];\n\n\n\n        dstU[i]= (RU*r + GU*g + BU*b + (257<<RGB2YUV_SHIFT))>>(RGB2YUV_SHIFT+1);\n\n        dstV[i]= (RV*r + GV*g + BV*b + (257<<RGB2YUV_SHIFT))>>(RGB2YUV_SHIFT+1);\n\n    }\n\n    assert(src1 == src2);\n\n}\n", "idx": 9522, "_split": "valid", "_hash": "edde4867b321d27c306afcb742ac082d"}
{"project": "FFmpeg", "commit_id": "2e7744a6a265604600f86a85c6961dbf5df9ecdd", "target": 1, "func": "static int subviewer_decode_frame(AVCodecContext *avctx,\n\n                                  void *data, int *got_sub_ptr, AVPacket *avpkt)\n\n{\n\n    char c;\n\n    AVSubtitle *sub = data;\n\n    const char *ptr = avpkt->data;\n\n    AVBPrint buf;\n\n\n\n    /* To be removed later */\n\n    if (sscanf(ptr, \"%*u:%*u:%*u.%*u,%*u:%*u:%*u.%*u%c\", &c) == 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"AVPacket is not clean (contains timing \"\n\n               \"information). You need to upgrade your libavformat or \"\n\n               \"sanitize your packet.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    av_bprint_init(&buf, 0, AV_BPRINT_SIZE_UNLIMITED);\n\n    // note: no need to rescale pts & duration since they are in the same\n\n    // timebase as ASS (1/100)\n\n    if (ptr && avpkt->size > 0 && !subviewer_event_to_ass(&buf, ptr))\n\n        ff_ass_add_rect(sub, buf.str, avpkt->pts, avpkt->duration, 0);\n\n    *got_sub_ptr = sub->num_rects > 0;\n\n    av_bprint_finalize(&buf, NULL);\n\n    return avpkt->size;\n\n}\n", "idx": 9649, "_split": "valid", "_hash": "66958f544aaa112a75ce9e52e4a6a21a"}
{"project": "FFmpeg", "commit_id": "564dd3f0f40008be8943af59686c0e8c4d67dd08", "target": 1, "func": "void ff_mpeg4_pred_ac(MpegEncContext *s, int16_t *block, int n, int dir)\n\n{\n\n    int i;\n\n    int16_t *ac_val, *ac_val1;\n\n    int8_t *const qscale_table = s->current_picture.qscale_table;\n\n\n\n    /* find prediction */\n\n    ac_val  = s->ac_val[0][0] + s->block_index[n] * 16;\n\n    ac_val1 = ac_val;\n\n    if (s->ac_pred) {\n\n        if (dir == 0) {\n\n            const int xy = s->mb_x - 1 + s->mb_y * s->mb_stride;\n\n            /* left prediction */\n\n            ac_val -= 16;\n\n\n\n            if (s->mb_x == 0 || s->qscale == qscale_table[xy] ||\n\n                n == 1 || n == 3) {\n\n                /* same qscale */\n\n                for (i = 1; i < 8; i++)\n\n                    block[s->idsp.idct_permutation[i << 3]] += ac_val[i];\n\n            } else {\n\n                /* different qscale, we must rescale */\n\n                for (i = 1; i < 8; i++)\n\n                    block[s->idsp.idct_permutation[i << 3]] += ROUNDED_DIV(ac_val[i] * qscale_table[xy], s->qscale);\n\n            }\n\n        } else {\n\n            const int xy = s->mb_x + s->mb_y * s->mb_stride - s->mb_stride;\n\n            /* top prediction */\n\n            ac_val -= 16 * s->block_wrap[n];\n\n\n\n            if (s->mb_y == 0 || s->qscale == qscale_table[xy] ||\n\n                n == 2 || n == 3) {\n\n                /* same qscale */\n\n                for (i = 1; i < 8; i++)\n\n                    block[s->idsp.idct_permutation[i]] += ac_val[i + 8];\n\n            } else {\n\n                /* different qscale, we must rescale */\n\n                for (i = 1; i < 8; i++)\n\n                    block[s->idsp.idct_permutation[i]] += ROUNDED_DIV(ac_val[i + 8] * qscale_table[xy], s->qscale);\n\n            }\n\n        }\n\n    }\n\n    /* left copy */\n\n    for (i = 1; i < 8; i++)\n\n        ac_val1[i] = block[s->idsp.idct_permutation[i << 3]];\n\n\n\n    /* top copy */\n\n    for (i = 1; i < 8; i++)\n\n        ac_val1[8 + i] = block[s->idsp.idct_permutation[i]];\n\n}\n", "idx": 9659, "_split": "valid", "_hash": "e9f53ec54dab2295d7afb6148f4dc374"}
{"project": "FFmpeg", "commit_id": "e5540b3fd30367ce3cc33b2f34a04b660dbc4b38", "target": 0, "func": "static int standard_decode_picture_header(VC9Context *v)\n\n{\n\n    int status = 0;\n\n\n\n    if (v->finterpflag) v->interpfrm = get_bits(&v->gb, 1);\n\n    skip_bits(&v->gb, 2); //framecnt unused\n\n    if (v->rangered) v->rangeredfrm = get_bits(&v->gb, 1);\n\n    v->pict_type = get_bits(&v->gb, 1);\n\n    if (v->avctx->max_b_frames && !v->pict_type)\n\n    {\n\n        if (get_bits(&v->gb, 1)) v->pict_type = I_TYPE;\n\n        else v->pict_type = P_TYPE;\n\n    }\n\n    else v->pict_type++; //P_TYPE\n\n\n\n    switch (v->pict_type)\n\n    {\n\n    case I_TYPE: status = decode_i_picture_header(v); break;\n\n    case BI_TYPE: status = decode_b_picture_header(v); break;\n\n    case P_TYPE: status = decode_p_picture_header(v); break;\n\n    case B_TYPE: status = decode_b_picture_header(v); break;\n\n    }\n\n\n\n    if (status == FRAME_SKIPED)\n\n    {\n\n      av_log(v, AV_LOG_INFO, \"Skipping frame...\\n\");\n\n      return status;\n\n    }\n\n\n\n    /* AC/DC Syntax */\n\n    v->transacfrm = get_bits(&v->gb, 1);\n\n    if (v->transacfrm) v->transacfrm += get_bits(&v->gb, 1);\n\n    if (v->pict_type == I_TYPE || v->pict_type == BI_TYPE)\n\n    {\n\n        v->transacfrm2 = get_bits(&v->gb, 1);\n\n        if (v->transacfrm2) v->transacfrm2 += get_bits(&v->gb, 1);\n\n    }\n\n    v->transacdctab = get_bits(&v->gb, 1);\n\n   \n\n    return 0;\n\n}\n", "idx": 9661, "_split": "valid", "_hash": "84b92dd6517cc7206860394b93020859"}
{"project": "FFmpeg", "commit_id": "6ba5cbc699e77cae66bb719354fa142114b64eab", "target": 0, "func": "static void rtsp_cmd_setup(HTTPContext *c, const char *url, \n\n                           RTSPHeader *h)\n\n{\n\n    FFStream *stream;\n\n    int stream_index, port;\n\n    char buf[1024];\n\n    char path1[1024];\n\n    const char *path;\n\n    HTTPContext *rtp_c;\n\n    RTSPTransportField *th;\n\n    struct sockaddr_in dest_addr;\n\n    RTSPActionServerSetup setup;\n\n    \n\n    /* find which url is asked */\n\n    url_split(NULL, 0, NULL, 0, NULL, path1, sizeof(path1), url);\n\n    path = path1;\n\n    if (*path == '/')\n\n        path++;\n\n\n\n    /* now check each stream */\n\n    for(stream = first_stream; stream != NULL; stream = stream->next) {\n\n        if (!stream->is_feed && stream->fmt == &rtp_mux) {\n\n            /* accept aggregate filenames only if single stream */\n\n            if (!strcmp(path, stream->filename)) {\n\n                if (stream->nb_streams != 1) {\n\n                    rtsp_reply_error(c, RTSP_STATUS_AGGREGATE);\n\n                    return;\n\n                }\n\n                stream_index = 0;\n\n                goto found;\n\n            }\n\n                \n\n            for(stream_index = 0; stream_index < stream->nb_streams;\n\n                stream_index++) {\n\n                snprintf(buf, sizeof(buf), \"%s/streamid=%d\", \n\n                         stream->filename, stream_index);\n\n                if (!strcmp(path, buf))\n\n                    goto found;\n\n            }\n\n        }\n\n    }\n\n    /* no stream found */\n\n    rtsp_reply_error(c, RTSP_STATUS_SERVICE); /* XXX: right error ? */\n\n    return;\n\n found:\n\n\n\n    /* generate session id if needed */\n\n    if (h->session_id[0] == '\\0') {\n\n        snprintf(h->session_id, sizeof(h->session_id), \n\n                 \"%08x%08x\", (int)random(), (int)random());\n\n    }\n\n\n\n    /* find rtp session, and create it if none found */\n\n    rtp_c = find_rtp_session(h->session_id);\n\n    if (!rtp_c) {\n\n        /* always prefer UDP */\n\n        th = find_transport(h, RTSP_PROTOCOL_RTP_UDP);\n\n        if (!th) {\n\n            th = find_transport(h, RTSP_PROTOCOL_RTP_TCP);\n\n            if (!th) {\n\n                rtsp_reply_error(c, RTSP_STATUS_TRANSPORT);\n\n                return;\n\n            }\n\n        }\n\n\n\n        rtp_c = rtp_new_connection(&c->from_addr, stream, h->session_id,\n\n                                   th->protocol);\n\n        if (!rtp_c) {\n\n            rtsp_reply_error(c, RTSP_STATUS_BANDWIDTH);\n\n            return;\n\n        }\n\n\n\n        /* open input stream */\n\n        if (open_input_stream(rtp_c, \"\") < 0) {\n\n            rtsp_reply_error(c, RTSP_STATUS_INTERNAL);\n\n            return;\n\n        }\n\n    }\n\n    \n\n    /* test if stream is OK (test needed because several SETUP needs\n\n       to be done for a given file) */\n\n    if (rtp_c->stream != stream) {\n\n        rtsp_reply_error(c, RTSP_STATUS_SERVICE);\n\n        return;\n\n    }\n\n    \n\n    /* test if stream is already set up */\n\n    if (rtp_c->rtp_ctx[stream_index]) {\n\n        rtsp_reply_error(c, RTSP_STATUS_STATE);\n\n        return;\n\n    }\n\n\n\n    /* check transport */\n\n    th = find_transport(h, rtp_c->rtp_protocol);\n\n    if (!th || (th->protocol == RTSP_PROTOCOL_RTP_UDP && \n\n                th->client_port_min <= 0)) {\n\n        rtsp_reply_error(c, RTSP_STATUS_TRANSPORT);\n\n        return;\n\n    }\n\n\n\n    /* setup default options */\n\n    setup.transport_option[0] = '\\0';\n\n    dest_addr = rtp_c->from_addr;\n\n    dest_addr.sin_port = htons(th->client_port_min);\n\n    \n\n    /* add transport option if needed */\n\n    if (ff_rtsp_callback) {\n\n        setup.ipaddr = ntohl(dest_addr.sin_addr.s_addr);\n\n        if (ff_rtsp_callback(RTSP_ACTION_SERVER_SETUP, rtp_c->session_id, \n\n                             (char *)&setup, sizeof(setup),\n\n                             stream->rtsp_option) < 0) {\n\n            rtsp_reply_error(c, RTSP_STATUS_TRANSPORT);\n\n            return;\n\n        }\n\n        dest_addr.sin_addr.s_addr = htonl(setup.ipaddr);\n\n    }\n\n    \n\n    /* setup stream */\n\n    if (rtp_new_av_stream(rtp_c, stream_index, &dest_addr, c) < 0) {\n\n        rtsp_reply_error(c, RTSP_STATUS_TRANSPORT);\n\n        return;\n\n    }\n\n\n\n    /* now everything is OK, so we can send the connection parameters */\n\n    rtsp_reply_header(c, RTSP_STATUS_OK);\n\n    /* session ID */\n\n    url_fprintf(c->pb, \"Session: %s\\r\\n\", rtp_c->session_id);\n\n\n\n    switch(rtp_c->rtp_protocol) {\n\n    case RTSP_PROTOCOL_RTP_UDP:\n\n        port = rtp_get_local_port(rtp_c->rtp_handles[stream_index]);\n\n        url_fprintf(c->pb, \"Transport: RTP/AVP/UDP;unicast;\"\n\n                    \"client_port=%d-%d;server_port=%d-%d\",\n\n                    th->client_port_min, th->client_port_min + 1,\n\n                    port, port + 1);\n\n        break;\n\n    case RTSP_PROTOCOL_RTP_TCP:\n\n        url_fprintf(c->pb, \"Transport: RTP/AVP/TCP;interleaved=%d-%d\",\n\n                    stream_index * 2, stream_index * 2 + 1);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n    if (setup.transport_option[0] != '\\0') {\n\n        url_fprintf(c->pb, \";%s\", setup.transport_option);\n\n    }\n\n    url_fprintf(c->pb, \"\\r\\n\");\n\n    \n\n\n\n    url_fprintf(c->pb, \"\\r\\n\");\n\n}\n", "idx": 9688, "_split": "valid", "_hash": "ea72f64789ec2af608d3858e3f6d6c43"}
{"project": "FFmpeg", "commit_id": "cbba331aa02f29870581ff0b7ded7477b279ae2c", "target": 0, "func": "static int show_format(WriterContext *w, AVFormatContext *fmt_ctx)\n\n{\n\n    char val_str[128];\n\n    int64_t size = fmt_ctx->pb ? avio_size(fmt_ctx->pb) : -1;\n\n    int ret = 0;\n\n\n\n    writer_print_section_header(w, SECTION_ID_FORMAT);\n\n    print_str(\"filename\",         fmt_ctx->filename);\n\n    print_int(\"nb_streams\",       fmt_ctx->nb_streams);\n\n    print_int(\"nb_programs\",      fmt_ctx->nb_programs);\n\n    print_str(\"format_name\",      fmt_ctx->iformat->name);\n\n    if (!do_bitexact) {\n\n        if (fmt_ctx->iformat->long_name) print_str    (\"format_long_name\", fmt_ctx->iformat->long_name);\n\n        else                             print_str_opt(\"format_long_name\", \"unknown\");\n\n    }\n\n    print_time(\"start_time\",      fmt_ctx->start_time, &AV_TIME_BASE_Q);\n\n    print_time(\"duration\",        fmt_ctx->duration,   &AV_TIME_BASE_Q);\n\n    if (size >= 0) print_val    (\"size\", size, unit_byte_str);\n\n    else           print_str_opt(\"size\", \"N/A\");\n\n    if (fmt_ctx->bit_rate > 0) print_val    (\"bit_rate\", fmt_ctx->bit_rate, unit_bit_per_second_str);\n\n    else                       print_str_opt(\"bit_rate\", \"N/A\");\n\n    print_int(\"probe_score\", av_format_get_probe_score(fmt_ctx));\n\n    ret = show_tags(w, fmt_ctx->metadata, SECTION_ID_FORMAT_TAGS);\n\n\n\n    writer_print_section_footer(w);\n\n    fflush(stdout);\n\n    return ret;\n\n}\n", "idx": 9689, "_split": "valid", "_hash": "72062b357dc75f354bd8fb97a3871317"}
{"project": "FFmpeg", "commit_id": "be8edff8d10104207062a332bb50973271e5fd00", "target": 0, "func": "int av_asrc_buffer_add_audio_buffer_ref(AVFilterContext *ctx,\n\n                                        AVFilterBufferRef *samplesref,\n\n                                        int av_unused flags)\n\n{\n\n    BufferSourceContext *abuffer = ctx->priv;\n\n    AVFilterLink *link;\n\n    int ret, logged = 0;\n\n\n\n    if (av_fifo_space(abuffer->fifo) < sizeof(samplesref)) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Buffering limit reached. Please consume some available frames \"\n\n               \"before adding new ones.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    // Normalize input\n\n\n\n    link = ctx->outputs[0];\n\n    if (samplesref->audio->sample_rate != link->sample_rate) {\n\n\n\n        log_input_change(ctx, link, samplesref);\n\n        logged = 1;\n\n\n\n        abuffer->sample_rate = samplesref->audio->sample_rate;\n\n\n\n        if (!abuffer->aresample) {\n\n            ret = insert_filter(abuffer, link, &abuffer->aresample, \"aresample\");\n\n            if (ret < 0) return ret;\n\n        } else {\n\n            link = abuffer->aresample->outputs[0];\n\n            if (samplesref->audio->sample_rate == link->sample_rate)\n\n                remove_filter(&abuffer->aresample);\n\n            else\n\n                if ((ret = reconfigure_filter(abuffer, abuffer->aresample)) < 0)\n\n                    return ret;\n\n        }\n\n    }\n\n\n\n    link = ctx->outputs[0];\n\n    if (samplesref->format                != link->format         ||\n\n        samplesref->audio->channel_layout != link->channel_layout ||\n\n        samplesref->audio->planar         != link->planar) {\n\n\n\n        if (!logged) log_input_change(ctx, link, samplesref);\n\n\n\n        abuffer->sample_format  = samplesref->format;\n\n        abuffer->channel_layout = samplesref->audio->channel_layout;\n\n        abuffer->packing_format = samplesref->audio->planar;\n\n\n\n        if (!abuffer->aconvert) {\n\n            ret = insert_filter(abuffer, link, &abuffer->aconvert, \"aconvert\");\n\n            if (ret < 0) return ret;\n\n        } else {\n\n            link = abuffer->aconvert->outputs[0];\n\n            if (samplesref->format                == link->format         &&\n\n                samplesref->audio->channel_layout == link->channel_layout &&\n\n                samplesref->audio->planar         == link->planar\n\n               )\n\n                remove_filter(&abuffer->aconvert);\n\n            else\n\n                if ((ret = reconfigure_filter(abuffer, abuffer->aconvert)) < 0)\n\n                    return ret;\n\n        }\n\n    }\n\n\n\n    if (sizeof(samplesref) != av_fifo_generic_write(abuffer->fifo, &samplesref,\n\n                                                    sizeof(samplesref), NULL)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Error while writing to FIFO\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 9747, "_split": "valid", "_hash": "32cfccffaafe77b5a15e16f4947e29d0"}
{"project": "FFmpeg", "commit_id": "5d5de3eba4c7890c2e8077f5b4ae569671d11cf8", "target": 0, "func": "static V4L2Buffer* v4l2_dequeue_v4l2buf(V4L2Context *ctx, int timeout)\n\n{\n\n    struct v4l2_plane planes[VIDEO_MAX_PLANES];\n\n    struct v4l2_buffer buf = { 0 };\n\n    V4L2Buffer* avbuf = NULL;\n\n    struct pollfd pfd = {\n\n        .events =  POLLIN | POLLRDNORM | POLLPRI | POLLOUT | POLLWRNORM, /* default blocking capture */\n\n        .fd = ctx_to_m2mctx(ctx)->fd,\n\n    };\n\n    int ret;\n\n\n\n    if (V4L2_TYPE_IS_OUTPUT(ctx->type))\n\n        pfd.events =  POLLOUT | POLLWRNORM;\n\n\n\n    for (;;) {\n\n        ret = poll(&pfd, 1, timeout);\n\n        if (ret > 0)\n\n            break;\n\n        if (errno == EINTR)\n\n            continue;\n\n\n\n        /* timeout is being used to indicate last valid bufer when draining */\n\n        if (ctx_to_m2mctx(ctx)->draining)\n\n            ctx->done = 1;\n\n\n\n        return NULL;\n\n    }\n\n\n\n    /* 0. handle errors */\n\n    if (pfd.revents & POLLERR) {\n\n        av_log(logger(ctx), AV_LOG_WARNING, \"%s POLLERR\\n\", ctx->name);\n\n        return NULL;\n\n    }\n\n\n\n    /* 1. handle resolution changes */\n\n    if (pfd.revents & POLLPRI) {\n\n        ret = v4l2_handle_event(ctx);\n\n        if (ret < 0) {\n\n            /* if re-init failed, abort */\n\n            ctx->done = EINVAL;\n\n            return NULL;\n\n        }\n\n        if (ret) {\n\n            /* if re-init was successful drop the buffer (if there was one)\n\n             * since we had to reconfigure capture (unmap all buffers)\n\n             */\n\n            return NULL;\n\n        }\n\n    }\n\n\n\n    /* 2. dequeue the buffer */\n\n    if (pfd.revents & (POLLIN | POLLRDNORM | POLLOUT | POLLWRNORM)) {\n\n\n\n        if (!V4L2_TYPE_IS_OUTPUT(ctx->type)) {\n\n            /* there is a capture buffer ready */\n\n            if (pfd.revents & (POLLIN | POLLRDNORM))\n\n                goto dequeue;\n\n\n\n            /* the driver is ready to accept more input; instead of waiting for the capture\n\n             * buffer to complete we return NULL so input can proceed (we are single threaded)\n\n             */\n\n            if (pfd.revents & (POLLOUT | POLLWRNORM))\n\n                return NULL;\n\n        }\n\n\n\ndequeue:\n\n        memset(&buf, 0, sizeof(buf));\n\n        buf.memory = V4L2_MEMORY_MMAP;\n\n        buf.type = ctx->type;\n\n        if (V4L2_TYPE_IS_MULTIPLANAR(ctx->type)) {\n\n            memset(planes, 0, sizeof(planes));\n\n            buf.length = VIDEO_MAX_PLANES;\n\n            buf.m.planes = planes;\n\n        }\n\n\n\n        ret = ioctl(ctx_to_m2mctx(ctx)->fd, VIDIOC_DQBUF, &buf);\n\n        if (ret) {\n\n            if (errno != EAGAIN) {\n\n                ctx->done = errno;\n\n                if (errno != EPIPE)\n\n                    av_log(logger(ctx), AV_LOG_DEBUG, \"%s VIDIOC_DQBUF, errno (%s)\\n\",\n\n                        ctx->name, av_err2str(AVERROR(errno)));\n\n            }\n\n        } else {\n\n            avbuf = &ctx->buffers[buf.index];\n\n            avbuf->status = V4L2BUF_AVAILABLE;\n\n            avbuf->buf = buf;\n\n            if (V4L2_TYPE_IS_MULTIPLANAR(ctx->type)) {\n\n                memcpy(avbuf->planes, planes, sizeof(planes));\n\n                avbuf->buf.m.planes = avbuf->planes;\n\n            }\n\n        }\n\n    }\n\n\n\n    return avbuf;\n\n}\n", "idx": 9748, "_split": "valid", "_hash": "83ce23f466b5389a48d6bfdd7c05bb0c"}
{"project": "FFmpeg", "commit_id": "cc13bc8c4f0f4afa30d0b94c3f3a369ccd2aaf0b", "target": 0, "func": "static int decode_extradata_ps(const uint8_t *data, int size, H264ParamSets *ps,\n\n                               int is_avc, void *logctx)\n\n{\n\n    H2645Packet pkt = { 0 };\n\n    int i, ret = 0;\n\n\n\n    ret = ff_h2645_packet_split(&pkt, data, size, logctx, is_avc, 2, AV_CODEC_ID_H264);\n\n    if (ret < 0) {\n\n        ret = 0;\n\n        goto fail;\n\n    }\n\n\n\n    for (i = 0; i < pkt.nb_nals; i++) {\n\n        H2645NAL *nal = &pkt.nals[i];\n\n        switch (nal->type) {\n\n        case H264_NAL_SPS:\n\n            ret = ff_h264_decode_seq_parameter_set(&nal->gb, logctx, ps, 0);\n\n            if (ret < 0)\n\n                goto fail;\n\n            break;\n\n        case H264_NAL_PPS:\n\n            ret = ff_h264_decode_picture_parameter_set(&nal->gb, logctx, ps,\n\n                                                       nal->size_bits);\n\n            if (ret < 0)\n\n                goto fail;\n\n            break;\n\n        default:\n\n            av_log(logctx, AV_LOG_VERBOSE, \"Ignoring NAL type %d in extradata\\n\",\n\n                   nal->type);\n\n            break;\n\n        }\n\n    }\n\n\n\nfail:\n\n    ff_h2645_packet_uninit(&pkt);\n\n    return ret;\n\n}\n", "idx": 9759, "_split": "valid", "_hash": "864a369eae0ec819c1466aea29b646ac"}
{"project": "FFmpeg", "commit_id": "22522d9c2c69624fe4d81d61ee65a56610f22f1d", "target": 1, "func": "int ff_qsv_decode_init(AVCodecContext *avctx, QSVContext *q, mfxSession session)\n\n{\n\n    mfxVideoParam param = { { 0 } };\n\n    int ret;\n\n\n\n    q->async_fifo = av_fifo_alloc((1 + q->async_depth) *\n\n                                  (sizeof(mfxSyncPoint) + sizeof(QSVFrame*)));\n\n    if (!q->async_fifo)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ret = qsv_init_session(avctx, q, session);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing an MFX session\\n\");\n\n        return ret;\n\n    }\n\n\n\n\n\n    ret = ff_qsv_codec_id_to_mfx(avctx->codec_id);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    param.mfx.CodecId      = ret;\n\n    param.mfx.CodecProfile = avctx->profile;\n\n    param.mfx.CodecLevel   = avctx->level;\n\n\n\n    param.mfx.FrameInfo.BitDepthLuma   = 8;\n\n    param.mfx.FrameInfo.BitDepthChroma = 8;\n\n    param.mfx.FrameInfo.Shift          = 0;\n\n    param.mfx.FrameInfo.FourCC         = MFX_FOURCC_NV12;\n\n    param.mfx.FrameInfo.Width          = avctx->coded_width;\n\n    param.mfx.FrameInfo.Height         = avctx->coded_height;\n\n    param.mfx.FrameInfo.ChromaFormat   = MFX_CHROMAFORMAT_YUV420;\n\n\n\n    param.IOPattern   = q->iopattern;\n\n    param.AsyncDepth  = q->async_depth;\n\n    param.ExtParam    = q->ext_buffers;\n\n    param.NumExtParam = q->nb_ext_buffers;\n\n\n\n    ret = MFXVideoDECODE_Init(q->session, &param);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing the MFX video decoder\\n\");\n\n        return ff_qsv_error(ret);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 9774, "_split": "valid", "_hash": "d52fff8e0f75c7cce31706254b358595"}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "int ff_msmpeg4_decode_init(MpegEncContext *s)\n\n{\n\n    static int done = 0;\n\n    int i;\n\n    MVTable *mv;\n\n\n\n    common_init(s);\n\n\n\n    if (!done) {\n\n        done = 1;\n\n\n\n        for(i=0;i<NB_RL_TABLES;i++) {\n\n            init_rl(&rl_table[i]);\n\n            init_vlc_rl(&rl_table[i]);\n\n        }\n\n        for(i=0;i<2;i++) {\n\n            mv = &mv_tables[i];\n\n            init_vlc(&mv->vlc, MV_VLC_BITS, mv->n + 1, \n\n                     mv->table_mv_bits, 1, 1,\n\n                     mv->table_mv_code, 2, 2);\n\n        }\n\n\n\n        init_vlc(&dc_lum_vlc[0], DC_VLC_BITS, 120, \n\n                 &table0_dc_lum[0][1], 8, 4,\n\n                 &table0_dc_lum[0][0], 8, 4);\n\n        init_vlc(&dc_chroma_vlc[0], DC_VLC_BITS, 120, \n\n                 &table0_dc_chroma[0][1], 8, 4,\n\n                 &table0_dc_chroma[0][0], 8, 4);\n\n        init_vlc(&dc_lum_vlc[1], DC_VLC_BITS, 120, \n\n                 &table1_dc_lum[0][1], 8, 4,\n\n                 &table1_dc_lum[0][0], 8, 4);\n\n        init_vlc(&dc_chroma_vlc[1], DC_VLC_BITS, 120, \n\n                 &table1_dc_chroma[0][1], 8, 4,\n\n                 &table1_dc_chroma[0][0], 8, 4);\n\n    \n\n        init_vlc(&v2_dc_lum_vlc, DC_VLC_BITS, 512, \n\n                 &v2_dc_lum_table[0][1], 8, 4,\n\n                 &v2_dc_lum_table[0][0], 8, 4);\n\n        init_vlc(&v2_dc_chroma_vlc, DC_VLC_BITS, 512, \n\n                 &v2_dc_chroma_table[0][1], 8, 4,\n\n                 &v2_dc_chroma_table[0][0], 8, 4);\n\n    \n\n        init_vlc(&cbpy_vlc, CBPY_VLC_BITS, 16,\n\n                 &cbpy_tab[0][1], 2, 1,\n\n                 &cbpy_tab[0][0], 2, 1);\n\n        init_vlc(&v2_intra_cbpc_vlc, V2_INTRA_CBPC_VLC_BITS, 4,\n\n                 &v2_intra_cbpc[0][1], 2, 1,\n\n                 &v2_intra_cbpc[0][0], 2, 1);\n\n        init_vlc(&v2_mb_type_vlc, V2_MB_TYPE_VLC_BITS, 8,\n\n                 &v2_mb_type[0][1], 2, 1,\n\n                 &v2_mb_type[0][0], 2, 1);\n\n        init_vlc(&v2_mv_vlc, V2_MV_VLC_BITS, 33,\n\n                 &mvtab[0][1], 2, 1,\n\n                 &mvtab[0][0], 2, 1);\n\n\n\n        for(i=0; i<4; i++){\n\n            init_vlc(&mb_non_intra_vlc[i], MB_NON_INTRA_VLC_BITS, 128, \n\n                     &wmv2_inter_table[i][0][1], 8, 4,\n\n                     &wmv2_inter_table[i][0][0], 8, 4); //FIXME name?\n\n        }\n\n        \n\n        init_vlc(&mb_intra_vlc, MB_INTRA_VLC_BITS, 64, \n\n                 &table_mb_intra[0][1], 4, 2,\n\n                 &table_mb_intra[0][0], 4, 2);\n\n        \n\n        init_vlc(&v1_intra_cbpc_vlc, V1_INTRA_CBPC_VLC_BITS, 8, \n\n                 intra_MCBPC_bits, 1, 1,\n\n                 intra_MCBPC_code, 1, 1);\n\n        init_vlc(&v1_inter_cbpc_vlc, V1_INTER_CBPC_VLC_BITS, 25, \n\n                 inter_MCBPC_bits, 1, 1,\n\n                 inter_MCBPC_code, 1, 1);\n\n        \n\n        init_vlc(&inter_intra_vlc, INTER_INTRA_VLC_BITS, 4, \n\n                 &table_inter_intra[0][1], 2, 1,\n\n                 &table_inter_intra[0][0], 2, 1);\n\n    }\n\n    \n\n    switch(s->msmpeg4_version){\n\n    case 1:\n\n    case 2:\n\n        s->decode_mb= msmpeg4v12_decode_mb;\n\n        break;\n\n    case 3:\n\n    case 4:\n\n        s->decode_mb= msmpeg4v34_decode_mb;\n\n        break;\n\n    case 5:\n\n        s->decode_mb= wmv2_decode_mb;\n\n        break;\n\n    }\n\n    \n\n    s->slice_height= s->mb_height; //to avoid 1/0 if the first frame isnt a keyframe\n\n    \n\n    return 0;\n\n}\n", "idx": 9779, "_split": "valid", "_hash": "64629e40e6aa371533c904548c1604b3"}
{"project": "FFmpeg", "commit_id": "06bf6d3bc04979bd39ecdc7311d0daf8aee7e10f", "target": 1, "func": "static void start_frame_overlay(AVFilterLink *inlink, AVFilterBufferRef *inpicref)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    OverlayContext *over = ctx->priv;\n\n\n\n    inpicref->pts = av_rescale_q(inpicref->pts, ctx->inputs[OVERLAY]->time_base,\n\n                                 ctx->outputs[0]->time_base);\n\n\n\n    if (!over->overpicref) over->overpicref      = inpicref;\n\n    else                   over->overpicref_next = inpicref;\n\n}\n", "idx": 9835, "_split": "valid", "_hash": "5eed0f98489b2d2401991354c5a5e87d"}
{"project": "FFmpeg", "commit_id": "aa7a5651019a2c603aff2c265777206ef4da742a", "target": 1, "func": "static int cllc_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_picture_ptr, AVPacket *avpkt)\n\n{\n\n    CLLCContext *ctx = avctx->priv_data;\n\n    AVFrame *pic = avctx->coded_frame;\n\n    uint8_t *src = avpkt->data;\n\n    uint8_t *swapped_buf_new;\n\n    uint32_t info_tag, info_offset;\n\n    GetBitContext gb;\n\n    int coding_type, ret;\n\n\n\n    if (pic->data[0])\n\n        avctx->release_buffer(avctx, pic);\n\n\n\n    pic->reference = 0;\n\n\n\n    /* Make sure our bswap16'd buffer is big enough */\n\n    swapped_buf_new = av_fast_realloc(ctx->swapped_buf,\n\n                                      &ctx->swapped_buf_size, avpkt->size);\n\n    if (!swapped_buf_new) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not realloc swapped buffer.\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    ctx->swapped_buf = swapped_buf_new;\n\n\n\n    /* Skip the INFO header if present */\n\n    info_offset = 0;\n\n    info_tag    = AV_RL32(src);\n\n    if (info_tag == MKTAG('I', 'N', 'F', 'O')) {\n\n        info_offset = AV_RL32(src + 4);\n\n        if (info_offset > UINT32_MAX - 8 || info_offset + 8 > avpkt->size) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Invalid INFO header offset: 0x%08X is too large.\\n\",\n\n                   info_offset);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        info_offset += 8;\n\n        src         += info_offset;\n\n\n\n        av_log(avctx, AV_LOG_DEBUG, \"Skipping INFO chunk.\\n\");\n\n    }\n\n\n\n    /* bswap16 the buffer since CLLC's bitreader works in 16-bit words */\n\n    ctx->dsp.bswap16_buf((uint16_t *) ctx->swapped_buf, (uint16_t *) src,\n\n                         (avpkt->size - info_offset) / 2);\n\n\n\n    init_get_bits(&gb, ctx->swapped_buf, (avpkt->size - info_offset) * 8);\n\n\n\n    /*\n\n     * Read in coding type. The types are as follows:\n\n     *\n\n     * 0 - YUY2\n\n     * 1 - BGR24 (Triples)\n\n     * 2 - BGR24 (Quads)\n\n     * 3 - BGRA\n\n     */\n\n    coding_type = (AV_RL32(src) >> 8) & 0xFF;\n\n    av_log(avctx, AV_LOG_DEBUG, \"Frame coding type: %d\\n\", coding_type);\n\n\n\n    switch (coding_type) {\n\n    case 1:\n\n    case 2:\n\n        avctx->pix_fmt             = PIX_FMT_RGB24;\n\n        avctx->bits_per_raw_sample = 8;\n\n\n\n        ret = avctx->get_buffer(avctx, pic);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Could not allocate buffer.\\n\");\n\n            return ret;\n\n        }\n\n\n\n        ret = decode_rgb24_frame(ctx, &gb, pic);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        break;\n\n    case 3:\n\n        avctx->pix_fmt             = PIX_FMT_ARGB;\n\n        avctx->bits_per_raw_sample = 8;\n\n\n\n        ret = avctx->get_buffer(avctx, pic);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Could not allocate buffer.\\n\");\n\n            return ret;\n\n        }\n\n\n\n        ret = decode_argb_frame(ctx, &gb, pic);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown coding type: %d.\\n\", coding_type);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    pic->key_frame = 1;\n\n    pic->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    *got_picture_ptr = 1;\n\n    *(AVFrame *)data = *pic;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 9880, "_split": "valid", "_hash": "fbaa06fa365ad8b445c556f4c58b309c"}
{"project": "FFmpeg", "commit_id": "e976e68fc5513fea05b45556cbe959e6675dbe7d", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, const uint8_t *databuf,\n\n                        float **out_samples)\n\n{\n\n    ATRAC3Context *q = avctx->priv_data;\n\n    int ret, i, ch;\n\n    uint8_t *ptr1;\n\n\n\n    if (q->coding_mode == JOINT_STEREO) {\n\n        /* channel coupling mode */\n\n\n\n        /* Decode sound unit pairs (channels are expected to be even).\n\n         * Multichannel joint stereo interleaves pairs (6ch: 2ch + 2ch + 2ch) */\n\n        const uint8_t *js_databuf;\n\n        int js_pair, js_block_align;\n\n\n\n        js_block_align = (avctx->block_align / avctx->channels) * 2; /* block pair */\n\n\n\n        for (ch = 0; ch < avctx->channels; ch = ch + 2) {\n\n            js_pair = ch/2;\n\n            js_databuf = databuf + js_pair * js_block_align; /* align to current pair */\n\n\n\n            /* Set the bitstream reader at the start of first channel sound unit. */\n\n            init_get_bits(&q->gb,\n\n                          js_databuf, js_block_align * 8);\n\n\n\n            /* decode Sound Unit 1 */\n\n            ret = decode_channel_sound_unit(q, &q->gb, &q->units[ch],\n\n                                            out_samples[ch], ch, JOINT_STEREO);\n\n            if (ret != 0)\n\n                return ret;\n\n\n\n            /* Framedata of the su2 in the joint-stereo mode is encoded in\n\n             * reverse byte order so we need to swap it first. */\n\n            if (js_databuf == q->decoded_bytes_buffer) {\n\n                uint8_t *ptr2 = q->decoded_bytes_buffer + js_block_align - 1;\n\n                ptr1          = q->decoded_bytes_buffer;\n\n                for (i = 0; i < js_block_align / 2; i++, ptr1++, ptr2--)\n\n                    FFSWAP(uint8_t, *ptr1, *ptr2);\n\n            } else {\n\n                const uint8_t *ptr2 = js_databuf + js_block_align - 1;\n\n                for (i = 0; i < js_block_align; i++)\n\n                    q->decoded_bytes_buffer[i] = *ptr2--;\n\n            }\n\n\n\n            /* Skip the sync codes (0xF8). */\n\n            ptr1 = q->decoded_bytes_buffer;\n\n            for (i = 4; *ptr1 == 0xF8; i++, ptr1++) {\n\n                if (i >= js_block_align)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n\n\n            /* set the bitstream reader at the start of the second Sound Unit */\n\n            init_get_bits8(&q->gb,\n\n                           ptr1, q->decoded_bytes_buffer + js_block_align - ptr1);\n\n\n\n            /* Fill the Weighting coeffs delay buffer */\n\n            memmove(q->weighting_delay[js_pair], &q->weighting_delay[js_pair][2],\n\n                    4 * sizeof(*q->weighting_delay[js_pair]));\n\n            q->weighting_delay[js_pair][4] = get_bits1(&q->gb);\n\n            q->weighting_delay[js_pair][5] = get_bits(&q->gb, 3);\n\n\n\n            for (i = 0; i < 4; i++) {\n\n                q->matrix_coeff_index_prev[js_pair][i] = q->matrix_coeff_index_now[js_pair][i];\n\n                q->matrix_coeff_index_now[js_pair][i]  = q->matrix_coeff_index_next[js_pair][i];\n\n                q->matrix_coeff_index_next[js_pair][i] = get_bits(&q->gb, 2);\n\n            }\n\n\n\n            /* Decode Sound Unit 2. */\n\n            ret = decode_channel_sound_unit(q, &q->gb, &q->units[ch+1],\n\n                                            out_samples[ch+1], ch+1, JOINT_STEREO);\n\n            if (ret != 0)\n\n                return ret;\n\n\n\n            /* Reconstruct the channel coefficients. */\n\n            reverse_matrixing(out_samples[ch], out_samples[ch+1],\n\n                              q->matrix_coeff_index_prev[js_pair],\n\n                              q->matrix_coeff_index_now[js_pair]);\n\n\n\n            channel_weighting(out_samples[ch], out_samples[ch+1], q->weighting_delay[js_pair]);\n\n        }\n\n    } else {\n\n        /* single channels */\n\n        /* Decode the channel sound units. */\n\n        for (i = 0; i < avctx->channels; i++) {\n\n            /* Set the bitstream reader at the start of a channel sound unit. */\n\n            init_get_bits(&q->gb,\n\n                          databuf + i * avctx->block_align / avctx->channels,\n\n                          avctx->block_align * 8 / avctx->channels);\n\n\n\n            ret = decode_channel_sound_unit(q, &q->gb, &q->units[i],\n\n                                            out_samples[i], i, q->coding_mode);\n\n            if (ret != 0)\n\n                return ret;\n\n        }\n\n    }\n\n\n\n    /* Apply the iQMF synthesis filter. */\n\n    for (i = 0; i < avctx->channels; i++) {\n\n        float *p1 = out_samples[i];\n\n        float *p2 = p1 + 256;\n\n        float *p3 = p2 + 256;\n\n        float *p4 = p3 + 256;\n\n        ff_atrac_iqmf(p1, p2, 256, p1, q->units[i].delay_buf1, q->temp_buf);\n\n        ff_atrac_iqmf(p4, p3, 256, p3, q->units[i].delay_buf2, q->temp_buf);\n\n        ff_atrac_iqmf(p1, p3, 512, p1, q->units[i].delay_buf3, q->temp_buf);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 9900, "_split": "valid", "_hash": "0a969c9deef83ae81063d091554097b1"}
{"project": "FFmpeg", "commit_id": "f1e173049ecc9de03817385ba8962d14cba779db", "target": 0, "func": "static void decode_refpass(Jpeg2000T1Context *t1, int width, int height,\n\n                           int bpno, int vert_causal_ctx_csty_symbol)\n\n{\n\n    int phalf, nhalf;\n\n    int y0, x, y;\n\n\n\n    phalf = 1 << (bpno - 1);\n\n    nhalf = -phalf;\n\n\n\n    for (y0 = 0; y0 < height; y0 += 4)\n\n        for (x = 0; x < width; x++)\n\n            for (y = y0; y < height && y < y0 + 4; y++)\n\n                if ((t1->flags[y + 1][x + 1] & (JPEG2000_T1_SIG | JPEG2000_T1_VIS)) == JPEG2000_T1_SIG) {\n\n                    int flags_mask = (vert_causal_ctx_csty_symbol && y == y0 + 3) ?\n\n                        ~(JPEG2000_T1_SIG_S | JPEG2000_T1_SIG_SW | JPEG2000_T1_SIG_SE | JPEG2000_T1_SGN_S) : -1;\n\n                    int ctxno = ff_jpeg2000_getrefctxno(t1->flags[y + 1][x + 1] & flags_mask);\n\n                    int r     = ff_mqc_decode(&t1->mqc,\n\n                                              t1->mqc.cx_states + ctxno)\n\n                                ? phalf : nhalf;\n\n                    t1->data[y][x]          += t1->data[y][x] < 0 ? -r : r;\n\n                    t1->flags[y + 1][x + 1] |= JPEG2000_T1_REF;\n\n                }\n\n}\n", "idx": 9901, "_split": "valid", "_hash": "c7a250870b266f38ad64062d9ba4e22f"}
{"project": "FFmpeg", "commit_id": "5ff998a233d759d0de83ea6f95c383d03d25d88e", "target": 1, "func": "static uint32_t find_subframe_rice_params(FlacEncodeContext *s,\n\n                                          FlacSubframe *sub, int pred_order)\n\n{\n\n    int pmin = get_max_p_order(s->options.min_partition_order,\n\n                               s->frame.blocksize, pred_order);\n\n    int pmax = get_max_p_order(s->options.max_partition_order,\n\n                               s->frame.blocksize, pred_order);\n\n\n\n    uint32_t bits = 8 + pred_order * sub->obits + 2 + 4;\n\n    if (sub->type == FLAC_SUBFRAME_LPC)\n\n        bits += 4 + 5 + pred_order * s->options.lpc_coeff_precision;\n\n    bits += calc_rice_params(&sub->rc, pmin, pmax, sub->residual,\n\n                             s->frame.blocksize, pred_order);\n\n    return bits;\n\n}\n", "idx": 9911, "_split": "valid", "_hash": "41395613e89417f8e99e81af90a6ca79"}
{"project": "FFmpeg", "commit_id": "b6db385922b79939b0dc124d53ddb4824afac040", "target": 0, "func": "static int mmap_start(AVFormatContext *ctx)\n\n{\n\n    struct video_data *s = ctx->priv_data;\n\n    enum v4l2_buf_type type;\n\n    int i, res;\n\n\n\n    for (i = 0; i < s->buffers; i++) {\n\n        struct v4l2_buffer buf;\n\n\n\n        memset(&buf, 0, sizeof(struct v4l2_buffer));\n\n        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;\n\n        buf.memory = V4L2_MEMORY_MMAP;\n\n        buf.index  = i;\n\n\n\n        res = ioctl(s->fd, VIDIOC_QBUF, &buf);\n\n        if (res < 0) {\n\n            av_log(ctx, AV_LOG_ERROR, \"ioctl(VIDIOC_QBUF): %s\\n\",\n\n                   strerror(errno));\n\n\n\n            return AVERROR(errno);\n\n        }\n\n    }\n\n\n\n    type = V4L2_BUF_TYPE_VIDEO_CAPTURE;\n\n    res = ioctl(s->fd, VIDIOC_STREAMON, &type);\n\n    if (res < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"ioctl(VIDIOC_STREAMON): %s\\n\",\n\n               strerror(errno));\n\n\n\n        return AVERROR(errno);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 9919, "_split": "valid", "_hash": "9080f9fd747fc881adf7494d80b8d76e"}
{"project": "FFmpeg", "commit_id": "58a830239d17dede16d9affdb4e6fc9135f94991", "target": 0, "func": "static int mxf_parse_mpeg2_frame(AVFormatContext *s, AVStream *st, AVPacket *pkt, int *flags)\n\n{\n\n    MXFStreamContext *sc = st->priv_data;\n\n    MXFContext *mxf = s->priv_data;\n\n    uint32_t c = -1;\n\n    int i;\n\n\n\n    *flags = 0;\n\n\n\n    for(i = 0; i < pkt->size - 4; i++) {\n\n        c = (c<<8) + pkt->data[i];\n\n        if (c == 0x1B5) {\n\n            if (i + 2 < pkt->size && (pkt->data[i+1] & 0xf0) == 0x10) { // seq ext\n\n                st->codec->profile = pkt->data[i+1] & 0x07;\n\n                st->codec->level   = pkt->data[i+2] >> 4;\n\n            } else if (i + 5 < pkt->size && (pkt->data[i+1] & 0xf0) == 0x80) { // pict coding ext\n\n                sc->interlaced = !(pkt->data[i+5] & 0x80); // progressive frame\n\n                break;\n\n            }\n\n        } else if (c == 0x1b8) { // gop\n\n            if (i + 4 < pkt->size) {\n\n                if (pkt->data[i+4]>>6 & 0x01) // closed\n\n                    *flags |= 0x80; // random access\n\n                if (!mxf->header_written) {\n\n                    unsigned hours   =  (pkt->data[i+1]>>2) & 0x1f;\n\n                    unsigned minutes = ((pkt->data[i+1] & 0x03) << 4) | (pkt->data[i+2]>>4);\n\n                    unsigned seconds = ((pkt->data[i+2] & 0x07) << 3) | (pkt->data[i+3]>>5);\n\n                    unsigned frames  = ((pkt->data[i+3] & 0x1f) << 1) | (pkt->data[i+4]>>7);\n\n                    mxf->timecode_drop_frame = !!(pkt->data[i+1] & 0x80);\n\n                    mxf->timecode_start = (hours*3600 + minutes*60 + seconds) *\n\n                        mxf->timecode_base + frames;\n\n                    if (mxf->timecode_drop_frame) {\n\n                        unsigned tminutes = 60 * hours + minutes;\n\n                        mxf->timecode_start -= 2 * (tminutes - tminutes / 10);\n\n                    }\n\n                    av_log(s, AV_LOG_DEBUG, \"frame %d %d:%d:%d%c%d\\n\", mxf->timecode_start,\n\n                           hours, minutes, seconds, mxf->timecode_drop_frame ? ';':':', frames);\n\n                }\n\n            }\n\n        } else if (c == 0x1b3) { // seq\n\n            *flags |= 0x40;\n\n            if (i + 4 < pkt->size) {\n\n                switch ((pkt->data[i+4]>>4) & 0xf) {\n\n                case 2:  sc->aspect_ratio = (AVRational){  4,  3}; break;\n\n                case 3:  sc->aspect_ratio = (AVRational){ 16,  9}; break;\n\n                case 4:  sc->aspect_ratio = (AVRational){221,100}; break;\n\n                default:\n\n                    av_reduce(&sc->aspect_ratio.num, &sc->aspect_ratio.den,\n\n                              st->codec->width, st->codec->height, 1024*1024);\n\n                }\n\n            }\n\n        } else if (c == 0x100) { // pic\n\n            int pict_type = (pkt->data[i+2]>>3) & 0x07;\n\n            if (pict_type == 2) { // P frame\n\n                *flags |= 0x22;\n\n                st->codec->gop_size = 1;\n\n            } else if (pict_type == 3) { // B frame\n\n                *flags |= 0x33;\n\n                sc->temporal_reordering = -1;\n\n            } else if (!pict_type) {\n\n                av_log(s, AV_LOG_ERROR, \"error parsing mpeg2 frame\\n\");\n\n                return 0;\n\n            }\n\n        }\n\n    }\n\n    if (s->oformat != &mxf_d10_muxer)\n\n        sc->codec_ul = mxf_get_mpeg2_codec_ul(st->codec);\n\n    return !!sc->codec_ul;\n\n}\n", "idx": 10034, "_split": "valid", "_hash": "f28445f830fafdbc9ff3a19ba2359edf"}
{"project": "FFmpeg", "commit_id": "4b1f5e5090abed6c618c8ba380cd7d28d140f867", "target": 0, "func": "int ffurl_register_protocol(URLProtocol *protocol)\n\n{\n\n    URLProtocol **p;\n\n    p = &first_protocol;\n\n    while (*p != NULL)\n\n        p = &(*p)->next;\n\n    *p             = protocol;\n\n    protocol->next = NULL;\n\n    return 0;\n\n}\n", "idx": 10060, "_split": "valid", "_hash": "b43b1ee8348af64ca0ce78b8d318f4b3"}
{"project": "FFmpeg", "commit_id": "856834a77f4145adc5951e8b08984981fed4463d", "target": 0, "func": "static av_cold int common_init(AVCodecContext *avctx){\n\n    FFV1Context *s = avctx->priv_data;\n\n\n\n    s->avctx= avctx;\n\n    s->flags= avctx->flags;\n\n\n\n    avcodec_get_frame_defaults(&s->picture);\n\n\n\n    ff_dsputil_init(&s->dsp, avctx);\n\n\n\n    s->width = avctx->width;\n\n    s->height= avctx->height;\n\n\n\n    assert(s->width && s->height);\n\n    //defaults\n\n    s->num_h_slices=1;\n\n    s->num_v_slices=1;\n\n\n\n\n\n    return 0;\n\n}\n", "idx": 10075, "_split": "valid", "_hash": "f0994acea095b7aafa642b6bc5f476c0"}
{"project": "FFmpeg", "commit_id": "aae6eead6a6e9bbab1c808d7552da5631ac78576", "target": 0, "func": "static int dca_decode_frame(AVCodecContext * avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n\n\n    int lfe_samples;\n\n    int num_core_channels = 0;\n\n    int i;\n\n    float   *samples_flt = data;\n\n    int16_t *samples_s16 = data;\n\n    int out_size;\n\n    DCAContext *s = avctx->priv_data;\n\n    int channels;\n\n    int core_ss_end;\n\n\n\n\n\n    s->xch_present = 0;\n\n\n\n    s->dca_buffer_size = dca_convert_bitstream(buf, buf_size, s->dca_buffer,\n\n                                               DCA_MAX_FRAME_SIZE + DCA_MAX_EXSS_HEADER_SIZE);\n\n    if (s->dca_buffer_size == AVERROR_INVALIDDATA) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Not a valid DCA frame\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    init_get_bits(&s->gb, s->dca_buffer, s->dca_buffer_size * 8);\n\n    if (dca_parse_frame_header(s) < 0) {\n\n        //seems like the frame is corrupt, try with the next one\n\n        *data_size=0;\n\n        return buf_size;\n\n    }\n\n    //set AVCodec values with parsed data\n\n    avctx->sample_rate = s->sample_rate;\n\n    avctx->bit_rate = s->bit_rate;\n\n    avctx->frame_size = s->sample_blocks * 32;\n\n\n\n    s->profile = FF_PROFILE_DTS;\n\n\n\n    for (i = 0; i < (s->sample_blocks / 8); i++) {\n\n        dca_decode_block(s, 0, i);\n\n    }\n\n\n\n    /* record number of core channels incase less than max channels are requested */\n\n    num_core_channels = s->prim_channels;\n\n\n\n    if (s->ext_coding)\n\n        s->core_ext_mask = dca_ext_audio_descr_mask[s->ext_descr];\n\n    else\n\n        s->core_ext_mask = 0;\n\n\n\n    core_ss_end = FFMIN(s->frame_size, s->dca_buffer_size) * 8;\n\n\n\n    /* only scan for extensions if ext_descr was unknown or indicated a\n\n     * supported XCh extension */\n\n    if (s->core_ext_mask < 0 || s->core_ext_mask & DCA_EXT_XCH) {\n\n\n\n        /* if ext_descr was unknown, clear s->core_ext_mask so that the\n\n         * extensions scan can fill it up */\n\n        s->core_ext_mask = FFMAX(s->core_ext_mask, 0);\n\n\n\n        /* extensions start at 32-bit boundaries into bitstream */\n\n        skip_bits_long(&s->gb, (-get_bits_count(&s->gb)) & 31);\n\n\n\n    while(core_ss_end - get_bits_count(&s->gb) >= 32) {\n\n        uint32_t bits = get_bits_long(&s->gb, 32);\n\n\n\n        switch(bits) {\n\n        case 0x5a5a5a5a: {\n\n            int ext_amode, xch_fsize;\n\n\n\n            s->xch_base_channel = s->prim_channels;\n\n\n\n            /* validate sync word using XCHFSIZE field */\n\n            xch_fsize = show_bits(&s->gb, 10);\n\n            if((s->frame_size != (get_bits_count(&s->gb) >> 3) - 4 + xch_fsize) &&\n\n               (s->frame_size != (get_bits_count(&s->gb) >> 3) - 4 + xch_fsize + 1))\n\n                continue;\n\n\n\n            /* skip length-to-end-of-frame field for the moment */\n\n            skip_bits(&s->gb, 10);\n\n\n\n            s->core_ext_mask |= DCA_EXT_XCH;\n\n\n\n            /* extension amode should == 1, number of channels in extension */\n\n            /* AFAIK XCh is not used for more channels */\n\n            if ((ext_amode = get_bits(&s->gb, 4)) != 1) {\n\n                av_log(avctx, AV_LOG_ERROR, \"XCh extension amode %d not\"\n\n                       \" supported!\\n\",ext_amode);\n\n                continue;\n\n            }\n\n\n\n            /* much like core primary audio coding header */\n\n            dca_parse_audio_coding_header(s, s->xch_base_channel);\n\n\n\n            for (i = 0; i < (s->sample_blocks / 8); i++) {\n\n                dca_decode_block(s, s->xch_base_channel, i);\n\n            }\n\n\n\n            s->xch_present = 1;\n\n            break;\n\n        }\n\n        case 0x47004a03:\n\n            /* XXCh: extended channels */\n\n            /* usually found either in core or HD part in DTS-HD HRA streams,\n\n             * but not in DTS-ES which contains XCh extensions instead */\n\n            s->core_ext_mask |= DCA_EXT_XXCH;\n\n            break;\n\n\n\n        case 0x1d95f262: {\n\n            int fsize96 = show_bits(&s->gb, 12) + 1;\n\n            if (s->frame_size != (get_bits_count(&s->gb) >> 3) - 4 + fsize96)\n\n                continue;\n\n\n\n            av_log(avctx, AV_LOG_DEBUG, \"X96 extension found at %d bits\\n\", get_bits_count(&s->gb));\n\n            skip_bits(&s->gb, 12);\n\n            av_log(avctx, AV_LOG_DEBUG, \"FSIZE96 = %d bytes\\n\", fsize96);\n\n            av_log(avctx, AV_LOG_DEBUG, \"REVNO = %d\\n\", get_bits(&s->gb, 4));\n\n\n\n            s->core_ext_mask |= DCA_EXT_X96;\n\n            break;\n\n        }\n\n        }\n\n\n\n        skip_bits_long(&s->gb, (-get_bits_count(&s->gb)) & 31);\n\n    }\n\n\n\n    } else {\n\n        /* no supported extensions, skip the rest of the core substream */\n\n        skip_bits_long(&s->gb, core_ss_end - get_bits_count(&s->gb));\n\n    }\n\n\n\n    if (s->core_ext_mask & DCA_EXT_X96)\n\n        s->profile = FF_PROFILE_DTS_96_24;\n\n    else if (s->core_ext_mask & (DCA_EXT_XCH | DCA_EXT_XXCH))\n\n        s->profile = FF_PROFILE_DTS_ES;\n\n\n\n    /* check for ExSS (HD part) */\n\n    if (s->dca_buffer_size - s->frame_size > 32\n\n        && get_bits_long(&s->gb, 32) == DCA_HD_MARKER)\n\n        dca_exss_parse_header(s);\n\n\n\n    avctx->profile = s->profile;\n\n\n\n    channels = s->prim_channels + !!s->lfe;\n\n\n\n    if (s->amode<16) {\n\n        avctx->channel_layout = dca_core_channel_layout[s->amode];\n\n\n\n        if (s->xch_present && (!avctx->request_channels ||\n\n                               avctx->request_channels > num_core_channels + !!s->lfe)) {\n\n            avctx->channel_layout |= AV_CH_BACK_CENTER;\n\n            if (s->lfe) {\n\n                avctx->channel_layout |= AV_CH_LOW_FREQUENCY;\n\n                s->channel_order_tab = dca_channel_reorder_lfe_xch[s->amode];\n\n            } else {\n\n                s->channel_order_tab = dca_channel_reorder_nolfe_xch[s->amode];\n\n            }\n\n        } else {\n\n            channels = num_core_channels + !!s->lfe;\n\n            s->xch_present = 0; /* disable further xch processing */\n\n            if (s->lfe) {\n\n                avctx->channel_layout |= AV_CH_LOW_FREQUENCY;\n\n                s->channel_order_tab = dca_channel_reorder_lfe[s->amode];\n\n            } else\n\n                s->channel_order_tab = dca_channel_reorder_nolfe[s->amode];\n\n        }\n\n\n\n        if (channels > !!s->lfe &&\n\n            s->channel_order_tab[channels - 1 - !!s->lfe] < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        if (avctx->request_channels == 2 && s->prim_channels > 2) {\n\n            channels = 2;\n\n            s->output = DCA_STEREO;\n\n            avctx->channel_layout = AV_CH_LAYOUT_STEREO;\n\n        }\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Non standard configuration %d !\\n\",s->amode);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n\n\n    /* There is nothing that prevents a dts frame to change channel configuration\n\n       but Libav doesn't support that so only set the channels if it is previously\n\n       unset. Ideally during the first probe for channels the crc should be checked\n\n       and only set avctx->channels when the crc is ok. Right now the decoder could\n\n       set the channels based on a broken first frame.*/\n\n    if (s->is_channels_set == 0) {\n\n        s->is_channels_set = 1;\n\n        avctx->channels = channels;\n\n    }\n\n    if (avctx->channels != channels) {\n\n        av_log(avctx, AV_LOG_ERROR, \"DCA decoder does not support number of \"\n\n               \"channels changing in stream. Skipping frame.\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    out_size = 256 / 8 * s->sample_blocks * channels *\n\n               av_get_bytes_per_sample(avctx->sample_fmt);\n\n    if (*data_size < out_size)\n\n        return AVERROR(EINVAL);\n\n    *data_size = out_size;\n\n\n\n    /* filter to get final output */\n\n    for (i = 0; i < (s->sample_blocks / 8); i++) {\n\n        dca_filter_channels(s, i);\n\n\n\n        /* If this was marked as a DTS-ES stream we need to subtract back- */\n\n        /* channel from SL & SR to remove matrixed back-channel signal */\n\n        if((s->source_pcm_res & 1) && s->xch_present) {\n\n            float* back_chan = s->samples + s->channel_order_tab[s->xch_base_channel] * 256;\n\n            float* lt_chan   = s->samples + s->channel_order_tab[s->xch_base_channel - 2] * 256;\n\n            float* rt_chan   = s->samples + s->channel_order_tab[s->xch_base_channel - 1] * 256;\n\n            s->dsp.vector_fmac_scalar(lt_chan, back_chan, -M_SQRT1_2, 256);\n\n            s->dsp.vector_fmac_scalar(rt_chan, back_chan, -M_SQRT1_2, 256);\n\n        }\n\n\n\n        if (avctx->sample_fmt == AV_SAMPLE_FMT_FLT) {\n\n            s->fmt_conv.float_interleave(samples_flt, s->samples_chanptr, 256,\n\n                                         channels);\n\n            samples_flt += 256 * channels;\n\n        } else {\n\n            s->fmt_conv.float_to_int16_interleave(samples_s16,\n\n                                                  s->samples_chanptr, 256,\n\n                                                  channels);\n\n            samples_s16 += 256 * channels;\n\n        }\n\n    }\n\n\n\n    /* update lfe history */\n\n    lfe_samples = 2 * s->lfe * (s->sample_blocks / 8);\n\n    for (i = 0; i < 2 * s->lfe * 4; i++) {\n\n        s->lfe_data[i] = s->lfe_data[i + lfe_samples];\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 10149, "_split": "valid", "_hash": "1ac8b7416180542b16b890d34ca8c0ca"}
{"project": "FFmpeg", "commit_id": "6d702dc072ffc255cd0f709132e55661698313e7", "target": 0, "func": "static int find_slice_quant(AVCodecContext *avctx, const AVFrame *pic,\n\n                            int trellis_node, int x, int y, int mbs_per_slice)\n\n{\n\n    ProresContext *ctx = avctx->priv_data;\n\n    int i, q, pq, xp, yp;\n\n    const uint16_t *src;\n\n    int slice_width_factor = av_log2(mbs_per_slice);\n\n    int num_cblocks[MAX_PLANES], pwidth;\n\n    int plane_factor[MAX_PLANES], is_chroma[MAX_PLANES];\n\n    const int min_quant = ctx->profile_info->min_quant;\n\n    const int max_quant = ctx->profile_info->max_quant;\n\n    int error, bits, bits_limit;\n\n    int mbs, prev, cur, new_score;\n\n    int slice_bits[TRELLIS_WIDTH], slice_score[TRELLIS_WIDTH];\n\n\n\n    mbs = x + mbs_per_slice;\n\n\n\n    for (i = 0; i < ctx->num_planes; i++) {\n\n        is_chroma[i]    = (i == 1 || i == 2);\n\n        plane_factor[i] = slice_width_factor + 2;\n\n        if (is_chroma[i])\n\n            plane_factor[i] += ctx->chroma_factor - 3;\n\n        if (!is_chroma[i] || ctx->chroma_factor == CFACTOR_Y444) {\n\n            xp             = x << 4;\n\n            yp             = y << 4;\n\n            num_cblocks[i] = 4;\n\n            pwidth         = avctx->width;\n\n        } else {\n\n            xp             = x << 3;\n\n            yp             = y << 4;\n\n            num_cblocks[i] = 2;\n\n            pwidth         = avctx->width >> 1;\n\n        }\n\n        src = (const uint16_t*)(pic->data[i] + yp * pic->linesize[i]) + xp;\n\n\n\n        get_slice_data(ctx, src, pic->linesize[i], xp, yp,\n\n                       pwidth, avctx->height, ctx->blocks[i],\n\n                       mbs_per_slice, num_cblocks[i]);\n\n    }\n\n\n\n    for (q = min_quant; q <= max_quant; q++) {\n\n        ctx->nodes[trellis_node + q].prev_node = -1;\n\n        ctx->nodes[trellis_node + q].quant     = q;\n\n    }\n\n\n\n    // todo: maybe perform coarser quantising to fit into frame size when needed\n\n    for (q = min_quant; q <= max_quant; q++) {\n\n        bits  = 0;\n\n        error = 0;\n\n        for (i = 0; i < ctx->num_planes; i++) {\n\n            bits += estimate_slice_plane(ctx, &error, i,\n\n                                         src, pic->linesize[i],\n\n                                         mbs_per_slice,\n\n                                         num_cblocks[i], plane_factor[i],\n\n                                         ctx->quants[q]);\n\n        }\n\n        if (bits > 65000 * 8) {\n\n            error = SCORE_LIMIT;\n\n            break;\n\n        }\n\n        slice_bits[q]  = bits;\n\n        slice_score[q] = error;\n\n    }\n\n\n\n    bits_limit = mbs * ctx->bits_per_mb;\n\n    for (pq = min_quant; pq <= max_quant; pq++) {\n\n        prev = trellis_node - TRELLIS_WIDTH + pq;\n\n\n\n        for (q = min_quant; q <= max_quant; q++) {\n\n            cur = trellis_node + q;\n\n\n\n            bits  = ctx->nodes[prev].bits + slice_bits[q];\n\n            error = slice_score[q];\n\n            if (bits > bits_limit)\n\n                error = SCORE_LIMIT;\n\n\n\n            if (ctx->nodes[prev].score < SCORE_LIMIT && error < SCORE_LIMIT)\n\n                new_score = ctx->nodes[prev].score + error;\n\n            else\n\n                new_score = SCORE_LIMIT;\n\n            if (ctx->nodes[cur].prev_node == -1 ||\n\n                ctx->nodes[cur].score >= new_score) {\n\n\n\n                ctx->nodes[cur].bits      = bits;\n\n                ctx->nodes[cur].score     = new_score;\n\n                ctx->nodes[cur].prev_node = prev;\n\n            }\n\n        }\n\n    }\n\n\n\n    error = ctx->nodes[trellis_node + min_quant].score;\n\n    pq    = trellis_node + min_quant;\n\n    for (q = min_quant + 1; q <= max_quant; q++) {\n\n        if (ctx->nodes[trellis_node + q].score <= error) {\n\n            error = ctx->nodes[trellis_node + q].score;\n\n            pq    = trellis_node + q;\n\n        }\n\n    }\n\n\n\n    return pq;\n\n}\n", "idx": 10221, "_split": "valid", "_hash": "07e4b191c3c23485330ea11ca5562712"}
{"project": "FFmpeg", "commit_id": "b53f89710b03c4c832bb03e4e132b1ace17fb4e4", "target": 0, "func": "static int alac_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    ALACContext *alac = avctx->priv_data;\n\n    enum RawDataBlockType element;\n\n    int channels;\n\n    int ch, ret, got_end;\n\n\n\n    init_get_bits(&alac->gb, avpkt->data, avpkt->size * 8);\n\n\n\n    got_end = 0;\n\n    alac->nb_samples = 0;\n\n    ch = 0;\n\n    while (get_bits_left(&alac->gb) >= 3) {\n\n        element = get_bits(&alac->gb, 3);\n\n        if (element == TYPE_END) {\n\n            got_end = 1;\n\n            break;\n\n        }\n\n        if (element > TYPE_CPE && element != TYPE_LFE) {\n\n            av_log(avctx, AV_LOG_ERROR, \"syntax element unsupported: %d\\n\", element);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n\n\n        channels = (element == TYPE_CPE) ? 2 : 1;\n\n        if (ch + channels > alac->channels) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid element channel count\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        ret = decode_element(avctx, data,\n\n                             alac_channel_layout_offsets[alac->channels - 1][ch],\n\n                             channels);\n\n        if (ret < 0 && get_bits_left(&alac->gb))\n\n            return ret;\n\n\n\n        ch += channels;\n\n    }\n\n    if (!got_end) {\n\n        av_log(avctx, AV_LOG_ERROR, \"no end tag found. incomplete packet.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avpkt->size * 8 - get_bits_count(&alac->gb) > 8) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error : %d bits left\\n\",\n\n               avpkt->size * 8 - get_bits_count(&alac->gb));\n\n    }\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = alac->frame;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 10232, "_split": "valid", "_hash": "be3d4f05f7f375fa42a951640417d928"}
{"project": "FFmpeg", "commit_id": "655b6dcb34b25d591e15ede17673ea6cb8074711", "target": 0, "func": "static void update_stream_timings(AVFormatContext *ic)\n\n{\n\n    int64_t start_time, start_time1, start_time_text, end_time, end_time1;\n\n    int64_t duration, duration1, filesize;\n\n    int i;\n\n    AVStream *st;\n\n    AVProgram *p;\n\n\n\n    start_time = INT64_MAX;\n\n    start_time_text = INT64_MAX;\n\n    end_time   = INT64_MIN;\n\n    duration   = INT64_MIN;\n\n    for (i = 0; i < ic->nb_streams; i++) {\n\n        st = ic->streams[i];\n\n        if (st->start_time != AV_NOPTS_VALUE && st->time_base.den) {\n\n            start_time1 = av_rescale_q(st->start_time, st->time_base,\n\n                                       AV_TIME_BASE_Q);\n\n            if (st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE || st->codec->codec_type == AVMEDIA_TYPE_DATA) {\n\n                if (start_time1 < start_time_text)\n\n                    start_time_text = start_time1;\n\n            } else\n\n                start_time = FFMIN(start_time, start_time1);\n\n            end_time1   = AV_NOPTS_VALUE;\n\n            if (st->duration != AV_NOPTS_VALUE) {\n\n                end_time1 = start_time1 +\n\n                            av_rescale_q(st->duration, st->time_base,\n\n                                         AV_TIME_BASE_Q);\n\n                end_time = FFMAX(end_time, end_time1);\n\n            }\n\n            for (p = NULL; (p = av_find_program_from_stream(ic, p, i)); ) {\n\n                if (p->start_time == AV_NOPTS_VALUE || p->start_time > start_time1)\n\n                    p->start_time = start_time1;\n\n                if (p->end_time < end_time1)\n\n                    p->end_time = end_time1;\n\n            }\n\n        }\n\n        if (st->duration != AV_NOPTS_VALUE) {\n\n            duration1 = av_rescale_q(st->duration, st->time_base,\n\n                                     AV_TIME_BASE_Q);\n\n            duration  = FFMAX(duration, duration1);\n\n        }\n\n    }\n\n    if (start_time == INT64_MAX || (start_time > start_time_text && start_time - start_time_text < AV_TIME_BASE))\n\n        start_time = start_time_text;\n\n    else if (start_time > start_time_text)\n\n        av_log(ic, AV_LOG_VERBOSE, \"Ignoring outlier non primary stream starttime %f\\n\", start_time_text / (float)AV_TIME_BASE);\n\n\n\n    if (start_time != INT64_MAX) {\n\n        ic->start_time = start_time;\n\n        if (end_time != INT64_MIN) {\n\n            if (ic->nb_programs) {\n\n                for (i = 0; i < ic->nb_programs; i++) {\n\n                    p = ic->programs[i];\n\n                    if (p->start_time != AV_NOPTS_VALUE && p->end_time > p->start_time)\n\n                        duration = FFMAX(duration, p->end_time - p->start_time);\n\n                }\n\n            } else\n\n                duration = FFMAX(duration, end_time - start_time);\n\n        }\n\n    }\n\n    if (duration != INT64_MIN && duration > 0 && ic->duration == AV_NOPTS_VALUE) {\n\n        ic->duration = duration;\n\n    }\n\n    if (ic->pb && (filesize = avio_size(ic->pb)) > 0 && ic->duration != AV_NOPTS_VALUE) {\n\n        /* compute the bitrate */\n\n        double bitrate = (double) filesize * 8.0 * AV_TIME_BASE /\n\n                         (double) ic->duration;\n\n        if (bitrate >= 0 && (!AV_HAVE_INCOMPATIBLE_LIBAV_ABI || bitrate <= INT_MAX))\n\n            ic->bit_rate = bitrate;\n\n    }\n\n}\n", "idx": 10399, "_split": "valid", "_hash": "2da21991c04dab66a9eaafc07a6aee93"}
{"project": "FFmpeg", "commit_id": "d05588e21e4744ae6a47192dc2da2844d6934a5d", "target": 0, "func": "AVInputFormat *av_probe_input_format3(AVProbeData *pd, int is_opened,\n\n                                      int *score_ret)\n\n{\n\n    AVProbeData lpd = *pd;\n\n    AVInputFormat *fmt1 = NULL, *fmt;\n\n    int score, nodat = 0, score_max = 0;\n\n    const static uint8_t zerobuffer[AVPROBE_PADDING_SIZE];\n\n\n\n    if (!lpd.buf)\n\n        lpd.buf = zerobuffer;\n\n\n\n    if (lpd.buf_size > 10 && ff_id3v2_match(lpd.buf, ID3v2_DEFAULT_MAGIC)) {\n\n        int id3len = ff_id3v2_tag_len(lpd.buf);\n\n        if (lpd.buf_size > id3len + 16) {\n\n            lpd.buf      += id3len;\n\n            lpd.buf_size -= id3len;\n\n        } else\n\n            nodat = 1;\n\n    }\n\n\n\n    fmt = NULL;\n\n    while ((fmt1 = av_iformat_next(fmt1))) {\n\n        if (!is_opened == !(fmt1->flags & AVFMT_NOFILE))\n\n            continue;\n\n        score = 0;\n\n        if (fmt1->read_probe) {\n\n            score = fmt1->read_probe(&lpd);\n\n            if (fmt1->extensions && av_match_ext(lpd.filename, fmt1->extensions))\n\n                score = FFMAX(score, nodat ? AVPROBE_SCORE_EXTENSION / 2 - 1 : 1);\n\n        } else if (fmt1->extensions) {\n\n            if (av_match_ext(lpd.filename, fmt1->extensions))\n\n                score = AVPROBE_SCORE_EXTENSION;\n\n        }\n\n        if (score > score_max) {\n\n            score_max = score;\n\n            fmt       = fmt1;\n\n        } else if (score == score_max)\n\n            fmt = NULL;\n\n    }\n\n    if (nodat)\n\n        score_max = FFMIN(AVPROBE_SCORE_EXTENSION / 2 - 1, score_max);\n\n    *score_ret = score_max;\n\n\n\n    return fmt;\n\n}\n", "idx": 10412, "_split": "valid", "_hash": "89867e9d1bdc58ec3774850eda8f72d5"}
{"project": "FFmpeg", "commit_id": "6c3fca647983a2bb47a79c82a9d797feac866a2f", "target": 0, "func": "static int rv34_decode_macroblock(RV34DecContext *r, int8_t *intra_types)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int cbp, cbp2;\n\n    int i, blknum, blkoff;\n\n    DCTELEM block16[64];\n\n    int luma_dc_quant;\n\n    int dist;\n\n    int mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n\n\n    // Calculate which neighbours are available. Maybe it's worth optimizing too.\n\n    memset(r->avail_cache, 0, sizeof(r->avail_cache));\n\n    fill_rectangle(r->avail_cache + 5, 2, 2, 4, 1, 4);\n\n    dist = (s->mb_x - s->resync_mb_x) + (s->mb_y - s->resync_mb_y) * s->mb_width;\n\n    if(s->mb_x && dist)\n\n        r->avail_cache[4] =\n\n        r->avail_cache[8] = s->current_picture_ptr->mb_type[mb_pos - 1];\n\n    if(dist >= s->mb_width)\n\n        r->avail_cache[1] =\n\n        r->avail_cache[2] = s->current_picture_ptr->mb_type[mb_pos - s->mb_stride];\n\n    if(((s->mb_x+1) < s->mb_width) && dist >= s->mb_width - 1)\n\n        r->avail_cache[3] = s->current_picture_ptr->mb_type[mb_pos - s->mb_stride + 1];\n\n    if(s->mb_x && dist > s->mb_width)\n\n        r->avail_cache[0] = s->current_picture_ptr->mb_type[mb_pos - s->mb_stride - 1];\n\n\n\n    s->qscale = r->si.quant;\n\n    cbp = cbp2 = rv34_decode_mb_header(r, intra_types);\n\n    r->cbp_luma  [s->mb_x + s->mb_y * s->mb_stride] = cbp;\n\n    r->cbp_chroma[s->mb_x + s->mb_y * s->mb_stride] = cbp >> 16;\n\n    if(s->pict_type == FF_I_TYPE)\n\n        r->deblock_coefs[mb_pos] = 0;\n\n    else\n\n        r->deblock_coefs[mb_pos] = rv34_set_deblock_coef(r);\n\n    s->current_picture_ptr->qscale_table[s->mb_x + s->mb_y * s->mb_stride] = s->qscale;\n\n\n\n    if(cbp == -1)\n\n        return -1;\n\n\n\n    luma_dc_quant = r->block_type == RV34_MB_P_MIX16x16 ? r->luma_dc_quant_p[s->qscale] : r->luma_dc_quant_i[s->qscale];\n\n    if(r->is16){\n\n        memset(block16, 0, sizeof(block16));\n\n        rv34_decode_block(block16, gb, r->cur_vlcs, 3, 0);\n\n        rv34_dequant4x4_16x16(block16, rv34_qscale_tab[luma_dc_quant],rv34_qscale_tab[s->qscale]);\n\n        rv34_inv_transform_noround(block16);\n\n    }\n\n\n\n    for(i = 0; i < 16; i++, cbp >>= 1){\n\n        if(!r->is16 && !(cbp & 1)) continue;\n\n        blknum = ((i & 2) >> 1) + ((i & 8) >> 2);\n\n        blkoff = ((i & 1) << 2) + ((i & 4) << 3);\n\n        if(cbp & 1)\n\n            rv34_decode_block(s->block[blknum] + blkoff, gb, r->cur_vlcs, r->luma_vlc, 0);\n\n        rv34_dequant4x4(s->block[blknum] + blkoff, rv34_qscale_tab[s->qscale],rv34_qscale_tab[s->qscale]);\n\n        if(r->is16) //FIXME: optimize\n\n            s->block[blknum][blkoff] = block16[(i & 3) | ((i & 0xC) << 1)];\n\n        rv34_inv_transform(s->block[blknum] + blkoff);\n\n    }\n\n    if(r->block_type == RV34_MB_P_MIX16x16)\n\n        r->cur_vlcs = choose_vlc_set(r->si.quant, r->si.vlc_set, 1);\n\n    for(; i < 24; i++, cbp >>= 1){\n\n        if(!(cbp & 1)) continue;\n\n        blknum = ((i & 4) >> 2) + 4;\n\n        blkoff = ((i & 1) << 2) + ((i & 2) << 4);\n\n        rv34_decode_block(s->block[blknum] + blkoff, gb, r->cur_vlcs, r->chroma_vlc, 1);\n\n        rv34_dequant4x4(s->block[blknum] + blkoff, rv34_qscale_tab[rv34_chroma_quant[1][s->qscale]],rv34_qscale_tab[rv34_chroma_quant[0][s->qscale]]);\n\n        rv34_inv_transform(s->block[blknum] + blkoff);\n\n    }\n\n    if(IS_INTRA(s->current_picture_ptr->mb_type[s->mb_x + s->mb_y*s->mb_stride]))\n\n        rv34_output_macroblock(r, intra_types, cbp2, r->is16);\n\n    else\n\n        rv34_apply_differences(r, cbp2);\n\n\n\n    return 0;\n\n}\n", "idx": 10470, "_split": "valid", "_hash": "b3130baa88dc0e786e6c270663ddce2c"}
{"project": "FFmpeg", "commit_id": "b754978a3b0aa17e7794f64c69bf4491762797fd", "target": 0, "func": "static int index_search_timestamp(AVIndexEntry *entries, \n\n                                  int nb_entries, int wanted_timestamp)\n\n{\n\n    int a, b, m;\n\n    int64_t timestamp;\n\n\n\n    if (nb_entries <= 0)\n\n        return -1;\n\n    \n\n    a = 0;\n\n    b = nb_entries - 1;\n\n    while (a <= b) {\n\n        m = (a + b) >> 1;\n\n        timestamp = entries[m].timestamp;\n\n        if (timestamp == wanted_timestamp)\n\n            goto found;\n\n        else if (timestamp > wanted_timestamp) {\n\n            b = m - 1;\n\n        } else {\n\n            a = m + 1;\n\n        }\n\n    }\n\n    m = a;\n\n    if (m > 0)\n\n        m--;\n\n found:\n\n    return m;\n\n}\n", "idx": 10471, "_split": "valid", "_hash": "186082bf45fa50c60deea9d1a7a71025"}
{"project": "FFmpeg", "commit_id": "af2ea724951b4b12b4522b462047eebbf9566b84", "target": 0, "func": "void av_aes_crypt(AVAES *a, uint8_t *dst_, const uint8_t *src_,\n\n                  int count, uint8_t *iv_, int decrypt)\n\n{\n\n    av_aes_block       *dst = (av_aes_block *) dst_;\n\n    const av_aes_block *src = (const av_aes_block *) src_;\n\n    av_aes_block        *iv = (av_aes_block *) iv_;\n\n\n\n    while (count--) {\n\n        addkey(&a->state[1], src, &a->round_key[a->rounds]);\n\n        if (decrypt) {\n\n            crypt(a, 0, inv_sbox, dec_multbl);\n\n            if (iv) {\n\n                addkey(&a->state[0], &a->state[0], iv);\n\n                memcpy(iv, src, 16);\n\n            }\n\n            addkey(dst, &a->state[0], &a->round_key[0]);\n\n        } else {\n\n            if (iv)\n\n                addkey(&a->state[1], &a->state[1], iv);\n\n            crypt(a, 2, sbox, enc_multbl);\n\n            addkey(dst, &a->state[0], &a->round_key[0]);\n\n            if (iv)\n\n                memcpy(iv, dst, 16);\n\n        }\n\n        src++;\n\n        dst++;\n\n    }\n\n}\n", "idx": 10596, "_split": "valid", "_hash": "669d9463e39f149e922b9b97033b4a1d"}
{"project": "FFmpeg", "commit_id": "037422178d7f1d0dd09e1ce424dd61a69e77668b", "target": 1, "func": "static int read_diff_float_data(ALSDecContext *ctx, unsigned int ra_frame) {\n\n    AVCodecContext *avctx   = ctx->avctx;\n\n    GetBitContext *gb       = &ctx->gb;\n\n    SoftFloat_IEEE754 *acf  = ctx->acf;\n\n    int *shift_value        = ctx->shift_value;\n\n    int *last_shift_value   = ctx->last_shift_value;\n\n    int *last_acf_mantissa  = ctx->last_acf_mantissa;\n\n    int **raw_mantissa      = ctx->raw_mantissa;\n\n    int *nbits              = ctx->nbits;\n\n    unsigned char *larray   = ctx->larray;\n\n    int frame_length        = ctx->cur_frame_length;\n\n    SoftFloat_IEEE754 scale = av_int2sf_ieee754(0x1u, 23);\n\n    unsigned int partA_flag;\n\n    unsigned int highest_byte;\n\n    unsigned int shift_amp;\n\n    uint32_t tmp_32;\n\n    int use_acf;\n\n    int nchars;\n\n    int i;\n\n    int c;\n\n    long k;\n\n    long nbits_aligned;\n\n    unsigned long acc;\n\n    unsigned long j;\n\n    uint32_t sign;\n\n    uint32_t e;\n\n    uint32_t mantissa;\n\n\n\n    skip_bits_long(gb, 32); //num_bytes_diff_float\n\n    use_acf = get_bits1(gb);\n\n\n\n    if (ra_frame) {\n\n        memset(last_acf_mantissa, 0, avctx->channels * sizeof(*last_acf_mantissa));\n\n        memset(last_shift_value,  0, avctx->channels * sizeof(*last_shift_value) );\n\n        ff_mlz_flush_dict(ctx->mlz);\n\n    }\n\n\n\n    for (c = 0; c < avctx->channels; ++c) {\n\n        if (use_acf) {\n\n            //acf_flag\n\n            if (get_bits1(gb)) {\n\n                tmp_32 = get_bits(gb, 23);\n\n                last_acf_mantissa[c] = tmp_32;\n\n            } else {\n\n                tmp_32 = last_acf_mantissa[c];\n\n            }\n\n            acf[c] = av_bits2sf_ieee754(tmp_32);\n\n        } else {\n\n            acf[c] = FLOAT_1;\n\n        }\n\n\n\n        highest_byte = get_bits(gb, 2);\n\n        partA_flag   = get_bits1(gb);\n\n        shift_amp    = get_bits1(gb);\n\n\n\n        if (shift_amp) {\n\n            shift_value[c] = get_bits(gb, 8);\n\n            last_shift_value[c] = shift_value[c];\n\n        } else {\n\n            shift_value[c] = last_shift_value[c];\n\n        }\n\n\n\n        if (partA_flag) {\n\n            if (!get_bits1(gb)) { //uncompressed\n\n                for (i = 0; i < frame_length; ++i) {\n\n                    if (ctx->raw_samples[c][i] == 0) {\n\n                        ctx->raw_mantissa[c][i] = get_bits_long(gb, 32);\n\n                    }\n\n                }\n\n            } else { //compressed\n\n                nchars = 0;\n\n                for (i = 0; i < frame_length; ++i) {\n\n                    if (ctx->raw_samples[c][i] == 0) {\n\n                        nchars += 4;\n\n                    }\n\n                }\n\n\n\n                tmp_32 = ff_mlz_decompression(ctx->mlz, gb, nchars, larray);\n\n                if(tmp_32 != nchars) {\n\n                    av_log(ctx->avctx, AV_LOG_ERROR, \"Error in MLZ decompression (%d, %d).\\n\", tmp_32, nchars);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                for (i = 0; i < frame_length; ++i) {\n\n                    ctx->raw_mantissa[c][i] = AV_RB32(larray);\n\n                }\n\n            }\n\n        }\n\n\n\n        //decode part B\n\n        if (highest_byte) {\n\n            for (i = 0; i < frame_length; ++i) {\n\n                if (ctx->raw_samples[c][i] != 0) {\n\n                    //The following logic is taken from Tabel 14.45 and 14.46 from the ISO spec\n\n                    if (av_cmp_sf_ieee754(acf[c], FLOAT_1)) {\n\n                        nbits[i] = 23 - av_log2(abs(ctx->raw_samples[c][i]));\n\n                    } else {\n\n                        nbits[i] = 23;\n\n                    }\n\n                    nbits[i] = FFMIN(nbits[i], highest_byte*8);\n\n                }\n\n            }\n\n\n\n            if (!get_bits1(gb)) { //uncompressed\n\n                for (i = 0; i < frame_length; ++i) {\n\n                    if (ctx->raw_samples[c][i] != 0) {\n\n                        raw_mantissa[c][i] = get_bits(gb, nbits[i]);\n\n                    }\n\n                }\n\n            } else { //compressed\n\n                nchars = 0;\n\n                for (i = 0; i < frame_length; ++i) {\n\n                    if (ctx->raw_samples[c][i]) {\n\n                        nchars += (int) nbits[i] / 8;\n\n                        if (nbits[i] & 7) {\n\n                            ++nchars;\n\n                        }\n\n                    }\n\n                }\n\n\n\n                tmp_32 = ff_mlz_decompression(ctx->mlz, gb, nchars, larray);\n\n                if(tmp_32 != nchars) {\n\n                    av_log(ctx->avctx, AV_LOG_ERROR, \"Error in MLZ decompression (%d, %d).\\n\", tmp_32, nchars);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                j = 0;\n\n                for (i = 0; i < frame_length; ++i) {\n\n                    if (ctx->raw_samples[c][i]) {\n\n                        if (nbits[i] & 7) {\n\n                            nbits_aligned = 8 * ((unsigned int)(nbits[i] / 8) + 1);\n\n                        } else {\n\n                            nbits_aligned = nbits[i];\n\n                        }\n\n                        acc = 0;\n\n                        for (k = 0; k < nbits_aligned/8; ++k) {\n\n                            acc = (acc << 8) + larray[j++];\n\n                        }\n\n                        acc >>= (nbits_aligned - nbits[i]);\n\n                        raw_mantissa[c][i] = acc;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        for (i = 0; i < frame_length; ++i) {\n\n            SoftFloat_IEEE754 pcm_sf = av_int2sf_ieee754(ctx->raw_samples[c][i], 0);\n\n            pcm_sf = av_div_sf_ieee754(pcm_sf, scale);\n\n\n\n            if (ctx->raw_samples[c][i] != 0) {\n\n                if (!av_cmp_sf_ieee754(acf[c], FLOAT_1)) {\n\n                    pcm_sf = multiply(acf[c], pcm_sf);\n\n                }\n\n\n\n                sign = pcm_sf.sign;\n\n                e = pcm_sf.exp;\n\n                mantissa = (pcm_sf.mant | 0x800000) + raw_mantissa[c][i];\n\n\n\n                while(mantissa >= 0x1000000) {\n\n                    e++;\n\n                    mantissa >>= 1;\n\n                }\n\n\n\n                if (mantissa) e += (shift_value[c] - 127);\n\n                mantissa &= 0x007fffffUL;\n\n\n\n                tmp_32 = (sign << 31) | ((e + EXP_BIAS) << 23) | (mantissa);\n\n                ctx->raw_samples[c][i] = tmp_32;\n\n            } else {\n\n                ctx->raw_samples[c][i] = raw_mantissa[c][i] & 0x007fffffUL;\n\n            }\n\n        }\n\n        align_get_bits(gb);\n\n    }\n\n    return 0;\n\n}\n", "idx": 10606, "_split": "valid", "_hash": "e8a4afbc0451dc3362d4a6bd53dedcdc"}
{"project": "FFmpeg", "commit_id": "5caa2de19ece830e32c95731bc92a423d55cff0c", "target": 1, "func": "static int X264_frame(AVCodecContext *ctx, uint8_t *buf,\n\n                      int bufsize, void *data)\n\n{\n\n    X264Context *x4 = ctx->priv_data;\n\n    AVFrame *frame = data;\n\n    x264_nal_t *nal;\n\n    int nnal, i;\n\n    x264_picture_t pic_out;\n\n\n\n    x264_picture_init( &x4->pic );\n\n    x4->pic.img.i_csp   = X264_CSP_I420;\n\n    x4->pic.img.i_plane = 3;\n\n\n\n    if (frame) {\n\n        for (i = 0; i < 3; i++) {\n\n            x4->pic.img.plane[i]    = frame->data[i];\n\n            x4->pic.img.i_stride[i] = frame->linesize[i];\n\n        }\n\n\n\n        x4->pic.i_pts  = frame->pts;\n\n        x4->pic.i_type =\n\n            frame->pict_type == AV_PICTURE_TYPE_I ? X264_TYPE_KEYFRAME :\n\n            frame->pict_type == AV_PICTURE_TYPE_P ? X264_TYPE_P :\n\n            frame->pict_type == AV_PICTURE_TYPE_B ? X264_TYPE_B :\n\n                                            X264_TYPE_AUTO;\n\n        if (x4->params.b_tff != frame->top_field_first) {\n\n            x4->params.b_tff = frame->top_field_first;\n\n            x264_encoder_reconfig(x4->enc, &x4->params);\n\n        }\n\n    }\n\n\n\n    do {\n\n    if (x264_encoder_encode(x4->enc, &nal, &nnal, frame? &x4->pic: NULL, &pic_out) < 0)\n\n        return -1;\n\n\n\n    bufsize = encode_nals(ctx, buf, bufsize, nal, nnal, 0);\n\n    if (bufsize < 0)\n\n        return -1;\n\n    } while (!bufsize && !frame && x264_encoder_delayed_frames(x4->enc));\n\n\n\n    /* FIXME: libx264 now provides DTS, but AVFrame doesn't have a field for it. */\n\n    x4->out_pic.pts = pic_out.i_pts;\n\n\n\n    switch (pic_out.i_type) {\n\n    case X264_TYPE_IDR:\n\n    case X264_TYPE_I:\n\n        x4->out_pic.pict_type = AV_PICTURE_TYPE_I;\n\n        break;\n\n    case X264_TYPE_P:\n\n        x4->out_pic.pict_type = AV_PICTURE_TYPE_P;\n\n        break;\n\n    case X264_TYPE_B:\n\n    case X264_TYPE_BREF:\n\n        x4->out_pic.pict_type = AV_PICTURE_TYPE_B;\n\n        break;\n\n    }\n\n\n\n    x4->out_pic.key_frame = pic_out.b_keyframe;\n\n    x4->out_pic.quality   = (pic_out.i_qpplus1 - 1) * FF_QP2LAMBDA;\n\n\n\n    return bufsize;\n\n}\n", "idx": 10608, "_split": "valid", "_hash": "5993095f3ba40f54f54694f2b75b6d34"}
{"project": "FFmpeg", "commit_id": "4b7ef5a1e6fa622fc85741c9c1ca11c798cda9cb", "target": 0, "func": "static int parse_keyframes_index(AVFormatContext *s, AVIOContext *ioc, AVStream *vstream, int64_t max_pos) {\n\n    unsigned int timeslen = 0, fileposlen = 0, i;\n\n    char str_val[256];\n\n    int64_t *times = NULL;\n\n    int64_t *filepositions = NULL;\n\n    int ret = AVERROR(ENOSYS);\n\n    int64_t initial_pos = avio_tell(ioc);\n\n    AVDictionaryEntry *creator = av_dict_get(s->metadata, \"metadatacreator\",\n\n                                             NULL, 0);\n\n\n\n    if (creator && !strcmp(creator->value, \"MEGA\")) {\n\n        /* Files with this metadatacreator tag seem to have filepositions\n\n         * pointing at the 4 trailer bytes of the previous packet,\n\n         * which isn't the norm (nor what we expect here, nor what\n\n         * jwplayer + lighttpd expect, nor what flvtool2 produces).\n\n         * Just ignore the index in this case, instead of risking trying\n\n         * to adjust it to something that might or might not work. */\n\n        return 0;\n\n    }\n\n\n\n    if(vstream->nb_index_entries>0){\n\n        av_log(s, AV_LOG_WARNING, \"Skiping duplicate index\\n\");\n\n        return 0;\n\n    }\n\n\n\n    while (avio_tell(ioc) < max_pos - 2 && amf_get_string(ioc, str_val, sizeof(str_val)) > 0) {\n\n        int64_t** current_array;\n\n        unsigned int arraylen;\n\n\n\n        // Expect array object in context\n\n        if (avio_r8(ioc) != AMF_DATA_TYPE_ARRAY)\n\n            break;\n\n\n\n        arraylen = avio_rb32(ioc);\n\n        if(arraylen>>28)\n\n            break;\n\n\n\n        if       (!strcmp(KEYFRAMES_TIMESTAMP_TAG , str_val) && !times){\n\n            current_array= &times;\n\n            timeslen= arraylen;\n\n        }else if (!strcmp(KEYFRAMES_BYTEOFFSET_TAG, str_val) && !filepositions){\n\n            current_array= &filepositions;\n\n            fileposlen= arraylen;\n\n        }else // unexpected metatag inside keyframes, will not use such metadata for indexing\n\n            break;\n\n\n\n        if (!(*current_array = av_mallocz(sizeof(**current_array) * arraylen))) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto finish;\n\n        }\n\n\n\n        for (i = 0; i < arraylen && avio_tell(ioc) < max_pos - 1; i++) {\n\n            if (avio_r8(ioc) != AMF_DATA_TYPE_NUMBER)\n\n                goto finish;\n\n            current_array[0][i] = av_int2dbl(avio_rb64(ioc));\n\n        }\n\n        if (times && filepositions) {\n\n            // All done, exiting at a position allowing amf_parse_object\n\n            // to finish parsing the object\n\n            ret = 0;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (timeslen == fileposlen) {\n\n         for(i = 0; i < timeslen; i++)\n\n             av_add_index_entry(vstream, filepositions[i], times[i]*1000, 0, 0, AVINDEX_KEYFRAME);\n\n    } else\n\n        av_log(s, AV_LOG_WARNING, \"Invalid keyframes object, skipping.\\n\");\n\n\n\nfinish:\n\n    av_freep(&times);\n\n    av_freep(&filepositions);\n\n    avio_seek(ioc, initial_pos, SEEK_SET);\n\n    return ret;\n\n}\n", "idx": 10622, "_split": "valid", "_hash": "3e0a1d1153cf9518e7d9094d57e59901"}
{"project": "FFmpeg", "commit_id": "a09bb3ba5e018b81a659c199a84cd1d80c07d869", "target": 0, "func": "void avcodec_default_release_buffer(AVCodecContext *s, AVFrame *pic){\n\n    int i;\n\n    InternalBuffer *buf, *last;\n\n    AVCodecInternal *avci = s->internal;\n\n\n\n    assert(s->codec_type == AVMEDIA_TYPE_VIDEO);\n\n\n\n    assert(pic->type==FF_BUFFER_TYPE_INTERNAL);\n\n    assert(avci->buffer_count);\n\n\n\n    if (avci->buffer) {\n\n        buf = NULL; /* avoids warning */\n\n        for (i = 0; i < avci->buffer_count; i++) { //just 3-5 checks so is not worth to optimize\n\n            buf = &avci->buffer[i];\n\n            if (buf->data[0] == pic->data[0])\n\n                break;\n\n        }\n\n        assert(i < avci->buffer_count);\n\n        avci->buffer_count--;\n\n        last = &avci->buffer[avci->buffer_count];\n\n\n\n        FFSWAP(InternalBuffer, *buf, *last);\n\n    }\n\n\n\n    for (i = 0; i < AV_NUM_DATA_POINTERS; i++) {\n\n        pic->data[i]=NULL;\n\n//        pic->base[i]=NULL;\n\n    }\n\n//printf(\"R%X\\n\", pic->opaque);\n\n\n\n    if(s->debug&FF_DEBUG_BUFFERS)\n\n        av_log(s, AV_LOG_DEBUG, \"default_release_buffer called on pic %p, %d \"\n\n               \"buffers used\\n\", pic, avci->buffer_count);\n\n}\n", "idx": 10659, "_split": "valid", "_hash": "55cca703b7bf98e7c2fa49380f12fb5f"}
{"project": "FFmpeg", "commit_id": "48df6a241532f0702fc4fd10ddcbfac435e4027c", "target": 1, "func": "static void iv_Decode_Chunk(Indeo3DecodeContext *s,\n\n        uint8_t *cur, uint8_t *ref, int width, int height,\n\n        const uint8_t *buf1, int cb_offset, const uint8_t *hdr,\n\n        const uint8_t *buf2, int min_width_160)\n\n{\n\n    uint8_t bit_buf;\n\n    unsigned int bit_pos, lv, lv1, lv2;\n\n    int *width_tbl, width_tbl_arr[10];\n\n    const signed char *ref_vectors;\n\n    uint8_t *cur_frm_pos, *ref_frm_pos, *cp, *cp2;\n\n\n    uint32_t *cur_lp, *ref_lp;\n\n    const uint32_t *correction_lp[2], *correctionloworder_lp[2], *correctionhighorder_lp[2];\n\n    uint8_t *correction_type_sp[2];\n\n    struct ustr strip_tbl[20], *strip;\n\n    int i, j, k, lp1, lp2, flag1, cmd, blks_width, blks_height, region_160_width,\n\n        rle_v1, rle_v2, rle_v3;\n\n    unsigned short res;\n\n\n\n    bit_buf = 0;\n\n    ref_vectors = NULL;\n\n\n\n    width_tbl = width_tbl_arr + 1;\n\n    i = (width < 0 ? width + 3 : width)/4;\n\n    for(j = -1; j < 8; j++)\n\n        width_tbl[j] = i * j;\n\n\n\n    strip = strip_tbl;\n\n\n\n    for(region_160_width = 0; region_160_width < (width - min_width_160); region_160_width += min_width_160);\n\n\n\n    strip->ypos = strip->xpos = 0;\n\n    for(strip->width = min_width_160; width > strip->width; strip->width *= 2);\n\n    strip->height = height;\n\n    strip->split_direction = 0;\n\n    strip->split_flag = 0;\n\n    strip->usl7 = 0;\n\n\n\n    bit_pos = 0;\n\n\n\n    rle_v1 = rle_v2 = rle_v3 = 0;\n\n\n\n    while(strip >= strip_tbl) {\n\n        if(bit_pos <= 0) {\n\n            bit_pos = 8;\n\n            bit_buf = *buf1++;\n\n        }\n\n\n\n        bit_pos -= 2;\n\n        cmd = (bit_buf >> bit_pos) & 0x03;\n\n\n\n        if(cmd == 0) {\n\n            strip++;\n\n            if(strip >= strip_tbl + FF_ARRAY_ELEMS(strip_tbl)) {\n\n                av_log(s->avctx, AV_LOG_WARNING, \"out of range strip\\n\");\n\n                break;\n\n            }\n\n            memcpy(strip, strip-1, sizeof(*strip));\n\n            strip->split_flag = 1;\n\n            strip->split_direction = 0;\n\n            strip->height = (strip->height > 8 ? ((strip->height+8)>>4)<<3 : 4);\n\n            continue;\n\n        } else if(cmd == 1) {\n\n            strip++;\n\n            if(strip >= strip_tbl + FF_ARRAY_ELEMS(strip_tbl)) {\n\n                av_log(s->avctx, AV_LOG_WARNING, \"out of range strip\\n\");\n\n                break;\n\n            }\n\n            memcpy(strip, strip-1, sizeof(*strip));\n\n            strip->split_flag = 1;\n\n            strip->split_direction = 1;\n\n            strip->width = (strip->width > 8 ? ((strip->width+8)>>4)<<3 : 4);\n\n            continue;\n\n        } else if(cmd == 2) {\n\n            if(strip->usl7 == 0) {\n\n                strip->usl7 = 1;\n\n                ref_vectors = NULL;\n\n                continue;\n\n            }\n\n        } else if(cmd == 3) {\n\n            if(strip->usl7 == 0) {\n\n                strip->usl7 = 1;\n\n                ref_vectors = (const signed char*)buf2 + (*buf1 * 2);\n\n                buf1++;\n\n                continue;\n\n            }\n\n        }\n\n\n\n        cur_frm_pos = cur + width * strip->ypos + strip->xpos;\n\n\n\n        if((blks_width = strip->width) < 0)\n\n            blks_width += 3;\n\n        blks_width >>= 2;\n\n        blks_height = strip->height;\n\n\n\n        if(ref_vectors != NULL) {\n\n            ref_frm_pos = ref + (ref_vectors[0] + strip->ypos) * width +\n\n                ref_vectors[1] + strip->xpos;\n\n        } else\n\n            ref_frm_pos = cur_frm_pos - width_tbl[4];\n\n\n\n        if(cmd == 2) {\n\n            if(bit_pos <= 0) {\n\n                bit_pos = 8;\n\n                bit_buf = *buf1++;\n\n            }\n\n\n\n            bit_pos -= 2;\n\n            cmd = (bit_buf >> bit_pos) & 0x03;\n\n\n\n            if(cmd == 0 || ref_vectors != NULL) {\n\n                for(lp1 = 0; lp1 < blks_width; lp1++) {\n\n                    for(i = 0, j = 0; i < blks_height; i++, j += width_tbl[1])\n\n                        ((uint32_t *)cur_frm_pos)[j] = ((uint32_t *)ref_frm_pos)[j];\n\n                    cur_frm_pos += 4;\n\n                    ref_frm_pos += 4;\n\n                }\n\n            } else if(cmd != 1)\n\n                return;\n\n        } else {\n\n            k = *buf1 >> 4;\n\n            j = *buf1 & 0x0f;\n\n            buf1++;\n\n            lv = j + cb_offset;\n\n\n\n            if((lv - 8) <= 7 && (k == 0 || k == 3 || k == 10)) {\n\n                cp2 = s->ModPred + ((lv - 8) << 7);\n\n                cp = ref_frm_pos;\n\n                for(i = 0; i < blks_width << 2; i++) {\n\n                    int v = *cp >> 1;\n\n                    *(cp++) = cp2[v];\n\n                }\n\n            }\n\n\n\n            if(k == 1 || k == 4) {\n\n                lv = (hdr[j] & 0xf) + cb_offset;\n\n                correction_type_sp[0] = s->corrector_type + (lv << 8);\n\n                correction_lp[0] = correction + (lv << 8);\n\n                lv = (hdr[j] >> 4) + cb_offset;\n\n                correction_lp[1] = correction + (lv << 8);\n\n                correction_type_sp[1] = s->corrector_type + (lv << 8);\n\n            } else {\n\n                correctionloworder_lp[0] = correctionloworder_lp[1] = correctionloworder + (lv << 8);\n\n                correctionhighorder_lp[0] = correctionhighorder_lp[1] = correctionhighorder + (lv << 8);\n\n                correction_type_sp[0] = correction_type_sp[1] = s->corrector_type + (lv << 8);\n\n                correction_lp[0] = correction_lp[1] = correction + (lv << 8);\n\n            }\n\n\n\n            switch(k) {\n\n            case 1:\n\n            case 0:                    /********** CASE 0 **********/\n\n                for( ; blks_height > 0; blks_height -= 4) {\n\n                    for(lp1 = 0; lp1 < blks_width; lp1++) {\n\n                        for(lp2 = 0; lp2 < 4; ) {\n\n                            k = *buf1++;\n\n                            cur_lp = ((uint32_t *)cur_frm_pos) + width_tbl[lp2];\n\n                            ref_lp = ((uint32_t *)ref_frm_pos) + width_tbl[lp2];\n\n                            if ((uint8_t *)cur_lp >= cur_end-3)\n\n                                break;\n\n\n\n                            switch(correction_type_sp[0][k]) {\n\n                            case 0:\n\n                                *cur_lp = av_le2ne32(((av_le2ne32(*ref_lp) >> 1) + correction_lp[lp2 & 0x01][k]) << 1);\n\n                                lp2++;\n\n                                break;\n\n                            case 1:\n\n                                res = ((av_le2ne16(((unsigned short *)(ref_lp))[0]) >> 1) + correction_lp[lp2 & 0x01][*buf1]) << 1;\n\n                                ((unsigned short *)cur_lp)[0] = av_le2ne16(res);\n\n                                res = ((av_le2ne16(((unsigned short *)(ref_lp))[1]) >> 1) + correction_lp[lp2 & 0x01][k]) << 1;\n\n                                ((unsigned short *)cur_lp)[1] = av_le2ne16(res);\n\n                                buf1++;\n\n                                lp2++;\n\n                                break;\n\n                            case 2:\n\n                                if(lp2 == 0) {\n\n                                    for(i = 0, j = 0; i < 2; i++, j += width_tbl[1])\n\n                                        cur_lp[j] = ref_lp[j];\n\n                                    lp2 += 2;\n\n                                }\n\n                                break;\n\n                            case 3:\n\n                                if(lp2 < 2) {\n\n                                    for(i = 0, j = 0; i < (3 - lp2); i++, j += width_tbl[1])\n\n                                        cur_lp[j] = ref_lp[j];\n\n                                    lp2 = 3;\n\n                                }\n\n                                break;\n\n                            case 8:\n\n                                if(lp2 == 0) {\n\n                                    RLE_V3_CHECK(buf1,rle_v1,rle_v2,rle_v3)\n\n\n\n                                    if(rle_v1 == 1 || ref_vectors != NULL) {\n\n                                        for(i = 0, j = 0; i < 4; i++, j += width_tbl[1])\n\n                                            cur_lp[j] = ref_lp[j];\n\n                                    }\n\n\n\n                                    RLE_V2_CHECK(buf1,rle_v2, rle_v3,lp2)\n\n                                    break;\n\n                                } else {\n\n                                    rle_v1 = 1;\n\n                                    rle_v2 = *buf1 - 1;\n\n                                }\n\n                            case 5:\n\n                                LP2_CHECK(buf1,rle_v3,lp2)\n\n                            case 4:\n\n                                for(i = 0, j = 0; i < (4 - lp2); i++, j += width_tbl[1])\n\n                                    cur_lp[j] = ref_lp[j];\n\n                                lp2 = 4;\n\n                                break;\n\n\n\n                            case 7:\n\n                                if(rle_v3 != 0)\n\n                                    rle_v3 = 0;\n\n                                else {\n\n                                    buf1--;\n\n                                    rle_v3 = 1;\n\n                                }\n\n                            case 6:\n\n                                if(ref_vectors != NULL) {\n\n                                    for(i = 0, j = 0; i < 4; i++, j += width_tbl[1])\n\n                                        cur_lp[j] = ref_lp[j];\n\n                                }\n\n                                lp2 = 4;\n\n                                break;\n\n\n\n                            case 9:\n\n                                lv1 = *buf1++;\n\n                                lv = (lv1 & 0x7F) << 1;\n\n                                lv += (lv << 8);\n\n                                lv += (lv << 16);\n\n                                for(i = 0, j = 0; i < 4; i++, j += width_tbl[1])\n\n                                    cur_lp[j] = lv;\n\n\n\n                                LV1_CHECK(buf1,rle_v3,lv1,lp2)\n\n                                break;\n\n                            default:\n\n                                return;\n\n                            }\n\n                        }\n\n\n\n                        cur_frm_pos += 4;\n\n                        ref_frm_pos += 4;\n\n                    }\n\n\n\n                    cur_frm_pos += ((width - blks_width) * 4);\n\n                    ref_frm_pos += ((width - blks_width) * 4);\n\n                }\n\n                break;\n\n\n\n            case 4:\n\n            case 3:                    /********** CASE 3 **********/\n\n                if(ref_vectors != NULL)\n\n                    return;\n\n                flag1 = 1;\n\n\n\n                for( ; blks_height > 0; blks_height -= 8) {\n\n                    for(lp1 = 0; lp1 < blks_width; lp1++) {\n\n                        for(lp2 = 0; lp2 < 4; ) {\n\n                            k = *buf1++;\n\n\n\n                            cur_lp = ((uint32_t *)cur_frm_pos) + width_tbl[lp2 * 2];\n\n                            ref_lp = ((uint32_t *)cur_frm_pos) + width_tbl[(lp2 * 2) - 1];\n\n\n\n                            switch(correction_type_sp[lp2 & 0x01][k]) {\n\n                            case 0:\n\n                                cur_lp[width_tbl[1]] = av_le2ne32(((av_le2ne32(*ref_lp) >> 1) + correction_lp[lp2 & 0x01][k]) << 1);\n\n                                if(lp2 > 0 || flag1 == 0 || strip->ypos != 0)\n\n                                    cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                else\n\n                                    cur_lp[0] = av_le2ne32(((av_le2ne32(*ref_lp) >> 1) + correction_lp[lp2 & 0x01][k]) << 1);\n\n                                lp2++;\n\n                                break;\n\n\n\n                            case 1:\n\n                                res = ((av_le2ne16(((unsigned short *)ref_lp)[0]) >> 1) + correction_lp[lp2 & 0x01][*buf1]) << 1;\n\n                                ((unsigned short *)cur_lp)[width_tbl[2]] = av_le2ne16(res);\n\n                                res = ((av_le2ne16(((unsigned short *)ref_lp)[1]) >> 1) + correction_lp[lp2 & 0x01][k]) << 1;\n\n                                ((unsigned short *)cur_lp)[width_tbl[2]+1] = av_le2ne16(res);\n\n\n\n                                if(lp2 > 0 || flag1 == 0 || strip->ypos != 0)\n\n                                    cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                else\n\n                                    cur_lp[0] = cur_lp[width_tbl[1]];\n\n                                buf1++;\n\n                                lp2++;\n\n                                break;\n\n\n\n                            case 2:\n\n                                if(lp2 == 0) {\n\n                                    for(i = 0, j = 0; i < 4; i++, j += width_tbl[1])\n\n                                        cur_lp[j] = *ref_lp;\n\n                                    lp2 += 2;\n\n                                }\n\n                                break;\n\n\n\n                            case 3:\n\n                                if(lp2 < 2) {\n\n                                    for(i = 0, j = 0; i < 6 - (lp2 * 2); i++, j += width_tbl[1])\n\n                                        cur_lp[j] = *ref_lp;\n\n                                    lp2 = 3;\n\n                                }\n\n                                break;\n\n\n\n                            case 6:\n\n                                lp2 = 4;\n\n                                break;\n\n\n\n                            case 7:\n\n                                if(rle_v3 != 0)\n\n                                    rle_v3 = 0;\n\n                                else {\n\n                                    buf1--;\n\n                                    rle_v3 = 1;\n\n                                }\n\n                                lp2 = 4;\n\n                                break;\n\n\n\n                            case 8:\n\n                                if(lp2 == 0) {\n\n                                    RLE_V3_CHECK(buf1,rle_v1,rle_v2,rle_v3)\n\n\n\n                                    if(rle_v1 == 1) {\n\n                                        for(i = 0, j = 0; i < 8; i++, j += width_tbl[1])\n\n                                            cur_lp[j] = ref_lp[j];\n\n                                    }\n\n\n\n                                    RLE_V2_CHECK(buf1,rle_v2, rle_v3,lp2)\n\n                                    break;\n\n                                } else {\n\n                                    rle_v2 = (*buf1) - 1;\n\n                                    rle_v1 = 1;\n\n                                }\n\n                            case 5:\n\n                                LP2_CHECK(buf1,rle_v3,lp2)\n\n                            case 4:\n\n                                for(i = 0, j = 0; i < 8 - (lp2 * 2); i++, j += width_tbl[1])\n\n                                    cur_lp[j] = *ref_lp;\n\n                                lp2 = 4;\n\n                                break;\n\n\n\n                            case 9:\n\n                                av_log(s->avctx, AV_LOG_ERROR, \"UNTESTED.\\n\");\n\n                                lv1 = *buf1++;\n\n                                lv = (lv1 & 0x7F) << 1;\n\n                                lv += (lv << 8);\n\n                                lv += (lv << 16);\n\n\n\n                                for(i = 0, j = 0; i < 4; i++, j += width_tbl[1])\n\n                                    cur_lp[j] = lv;\n\n\n\n                                LV1_CHECK(buf1,rle_v3,lv1,lp2)\n\n                                break;\n\n\n\n                            default:\n\n                                return;\n\n                            }\n\n                        }\n\n\n\n                        cur_frm_pos += 4;\n\n                    }\n\n\n\n                    cur_frm_pos += (((width * 2) - blks_width) * 4);\n\n                    flag1 = 0;\n\n                }\n\n                break;\n\n\n\n            case 10:                    /********** CASE 10 **********/\n\n                if(ref_vectors == NULL) {\n\n                    flag1 = 1;\n\n\n\n                    for( ; blks_height > 0; blks_height -= 8) {\n\n                        for(lp1 = 0; lp1 < blks_width; lp1 += 2) {\n\n                            for(lp2 = 0; lp2 < 4; ) {\n\n                                k = *buf1++;\n\n                                cur_lp = ((uint32_t *)cur_frm_pos) + width_tbl[lp2 * 2];\n\n                                ref_lp = ((uint32_t *)cur_frm_pos) + width_tbl[(lp2 * 2) - 1];\n\n                                lv1 = ref_lp[0];\n\n                                lv2 = ref_lp[1];\n\n                                if(lp2 == 0 && flag1 != 0) {\n\n#if HAVE_BIGENDIAN\n\n                                    lv1 = lv1 & 0xFF00FF00;\n\n                                    lv1 = (lv1 >> 8) | lv1;\n\n                                    lv2 = lv2 & 0xFF00FF00;\n\n                                    lv2 = (lv2 >> 8) | lv2;\n\n#else\n\n                                    lv1 = lv1 & 0x00FF00FF;\n\n                                    lv1 = (lv1 << 8) | lv1;\n\n                                    lv2 = lv2 & 0x00FF00FF;\n\n                                    lv2 = (lv2 << 8) | lv2;\n\n#endif\n\n                                }\n\n\n\n                                switch(correction_type_sp[lp2 & 0x01][k]) {\n\n                                case 0:\n\n                                    cur_lp[width_tbl[1]] = av_le2ne32(((av_le2ne32(lv1) >> 1) + correctionloworder_lp[lp2 & 0x01][k]) << 1);\n\n                                    cur_lp[width_tbl[1]+1] = av_le2ne32(((av_le2ne32(lv2) >> 1) + correctionhighorder_lp[lp2 & 0x01][k]) << 1);\n\n                                    if(lp2 > 0 || strip->ypos != 0 || flag1 == 0) {\n\n                                        cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                        cur_lp[1] = ((cur_lp[-width_tbl[1]+1] >> 1) + (cur_lp[width_tbl[1]+1] >> 1)) & 0xFEFEFEFE;\n\n                                    } else {\n\n                                        cur_lp[0] = cur_lp[width_tbl[1]];\n\n                                        cur_lp[1] = cur_lp[width_tbl[1]+1];\n\n                                    }\n\n                                    lp2++;\n\n                                    break;\n\n\n\n                                case 1:\n\n                                    cur_lp[width_tbl[1]] = av_le2ne32(((av_le2ne32(lv1) >> 1) + correctionloworder_lp[lp2 & 0x01][*buf1]) << 1);\n\n                                    cur_lp[width_tbl[1]+1] = av_le2ne32(((av_le2ne32(lv2) >> 1) + correctionloworder_lp[lp2 & 0x01][k]) << 1);\n\n                                    if(lp2 > 0 || strip->ypos != 0 || flag1 == 0) {\n\n                                        cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                        cur_lp[1] = ((cur_lp[-width_tbl[1]+1] >> 1) + (cur_lp[width_tbl[1]+1] >> 1)) & 0xFEFEFEFE;\n\n                                    } else {\n\n                                        cur_lp[0] = cur_lp[width_tbl[1]];\n\n                                        cur_lp[1] = cur_lp[width_tbl[1]+1];\n\n                                    }\n\n                                    buf1++;\n\n                                    lp2++;\n\n                                    break;\n\n\n\n                                case 2:\n\n                                    if(lp2 == 0) {\n\n                                        if(flag1 != 0) {\n\n                                            for(i = 0, j = width_tbl[1]; i < 3; i++, j += width_tbl[1]) {\n\n                                                cur_lp[j] = lv1;\n\n                                                cur_lp[j+1] = lv2;\n\n                                            }\n\n                                            cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                            cur_lp[1] = ((cur_lp[-width_tbl[1]+1] >> 1) + (cur_lp[width_tbl[1]+1] >> 1)) & 0xFEFEFEFE;\n\n                                        } else {\n\n                                            for(i = 0, j = 0; i < 4; i++, j += width_tbl[1]) {\n\n                                                cur_lp[j] = lv1;\n\n                                                cur_lp[j+1] = lv2;\n\n                                            }\n\n                                        }\n\n                                        lp2 += 2;\n\n                                    }\n\n                                    break;\n\n\n\n                                case 3:\n\n                                    if(lp2 < 2) {\n\n                                        if(lp2 == 0 && flag1 != 0) {\n\n                                            for(i = 0, j = width_tbl[1]; i < 5; i++, j += width_tbl[1]) {\n\n                                                cur_lp[j] = lv1;\n\n                                                cur_lp[j+1] = lv2;\n\n                                            }\n\n                                            cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                            cur_lp[1] = ((cur_lp[-width_tbl[1]+1] >> 1) + (cur_lp[width_tbl[1]+1] >> 1)) & 0xFEFEFEFE;\n\n                                        } else {\n\n                                            for(i = 0, j = 0; i < 6 - (lp2 * 2); i++, j += width_tbl[1]) {\n\n                                                cur_lp[j] = lv1;\n\n                                                cur_lp[j+1] = lv2;\n\n                                            }\n\n                                        }\n\n                                        lp2 = 3;\n\n                                    }\n\n                                    break;\n\n\n\n                                case 8:\n\n                                    if(lp2 == 0) {\n\n                                        RLE_V3_CHECK(buf1,rle_v1,rle_v2,rle_v3)\n\n                                        if(rle_v1 == 1) {\n\n                                            if(flag1 != 0) {\n\n                                                for(i = 0, j = width_tbl[1]; i < 7; i++, j += width_tbl[1]) {\n\n                                                    cur_lp[j] = lv1;\n\n                                                    cur_lp[j+1] = lv2;\n\n                                                }\n\n                                                cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                                cur_lp[1] = ((cur_lp[-width_tbl[1]+1] >> 1) + (cur_lp[width_tbl[1]+1] >> 1)) & 0xFEFEFEFE;\n\n                                            } else {\n\n                                                for(i = 0, j = 0; i < 8; i++, j += width_tbl[1]) {\n\n                                                    cur_lp[j] = lv1;\n\n                                                    cur_lp[j+1] = lv2;\n\n                                                }\n\n                                            }\n\n                                        }\n\n                                        RLE_V2_CHECK(buf1,rle_v2, rle_v3,lp2)\n\n                                        break;\n\n                                    } else {\n\n                                        rle_v1 = 1;\n\n                                        rle_v2 = (*buf1) - 1;\n\n                                    }\n\n                                case 5:\n\n                                    LP2_CHECK(buf1,rle_v3,lp2)\n\n                                case 4:\n\n                                    if(lp2 == 0 && flag1 != 0) {\n\n                                        for(i = 0, j = width_tbl[1]; i < 7; i++, j += width_tbl[1]) {\n\n                                            cur_lp[j] = lv1;\n\n                                            cur_lp[j+1] = lv2;\n\n                                        }\n\n                                        cur_lp[0] = ((cur_lp[-width_tbl[1]] >> 1) + (cur_lp[width_tbl[1]] >> 1)) & 0xFEFEFEFE;\n\n                                        cur_lp[1] = ((cur_lp[-width_tbl[1]+1] >> 1) + (cur_lp[width_tbl[1]+1] >> 1)) & 0xFEFEFEFE;\n\n                                    } else {\n\n                                        for(i = 0, j = 0; i < 8 - (lp2 * 2); i++, j += width_tbl[1]) {\n\n                                            cur_lp[j] = lv1;\n\n                                            cur_lp[j+1] = lv2;\n\n                                        }\n\n                                    }\n\n                                    lp2 = 4;\n\n                                    break;\n\n\n\n                                case 6:\n\n                                    lp2 = 4;\n\n                                    break;\n\n\n\n                                case 7:\n\n                                    if(lp2 == 0) {\n\n                                        if(rle_v3 != 0)\n\n                                            rle_v3 = 0;\n\n                                        else {\n\n                                            buf1--;\n\n                                            rle_v3 = 1;\n\n                                        }\n\n                                        lp2 = 4;\n\n                                    }\n\n                                    break;\n\n\n\n                                case 9:\n\n                                    av_log(s->avctx, AV_LOG_ERROR, \"UNTESTED.\\n\");\n\n                                    lv1 = *buf1;\n\n                                    lv = (lv1 & 0x7F) << 1;\n\n                                    lv += (lv << 8);\n\n                                    lv += (lv << 16);\n\n                                    for(i = 0, j = 0; i < 8; i++, j += width_tbl[1])\n\n                                        cur_lp[j] = lv;\n\n                                    LV1_CHECK(buf1,rle_v3,lv1,lp2)\n\n                                    break;\n\n\n\n                                default:\n\n                                    return;\n\n                                }\n\n                            }\n\n\n\n                            cur_frm_pos += 8;\n\n                        }\n\n\n\n                        cur_frm_pos += (((width * 2) - blks_width) * 4);\n\n                        flag1 = 0;\n\n                    }\n\n                } else {\n\n                    for( ; blks_height > 0; blks_height -= 8) {\n\n                        for(lp1 = 0; lp1 < blks_width; lp1 += 2) {\n\n                            for(lp2 = 0; lp2 < 4; ) {\n\n                                k = *buf1++;\n\n                                cur_lp = ((uint32_t *)cur_frm_pos) + width_tbl[lp2 * 2];\n\n                                ref_lp = ((uint32_t *)ref_frm_pos) + width_tbl[lp2 * 2];\n\n\n\n                                switch(correction_type_sp[lp2 & 0x01][k]) {\n\n                                case 0:\n\n                                    lv1 = correctionloworder_lp[lp2 & 0x01][k];\n\n                                    lv2 = correctionhighorder_lp[lp2 & 0x01][k];\n\n                                    cur_lp[0] = av_le2ne32(((av_le2ne32(ref_lp[0]) >> 1) + lv1) << 1);\n\n                                    cur_lp[1] = av_le2ne32(((av_le2ne32(ref_lp[1]) >> 1) + lv2) << 1);\n\n                                    cur_lp[width_tbl[1]] = av_le2ne32(((av_le2ne32(ref_lp[width_tbl[1]]) >> 1) + lv1) << 1);\n\n                                    cur_lp[width_tbl[1]+1] = av_le2ne32(((av_le2ne32(ref_lp[width_tbl[1]+1]) >> 1) + lv2) << 1);\n\n                                    lp2++;\n\n                                    break;\n\n\n\n                                case 1:\n\n                                    lv1 = correctionloworder_lp[lp2 & 0x01][*buf1++];\n\n                                    lv2 = correctionloworder_lp[lp2 & 0x01][k];\n\n                                    cur_lp[0] = av_le2ne32(((av_le2ne32(ref_lp[0]) >> 1) + lv1) << 1);\n\n                                    cur_lp[1] = av_le2ne32(((av_le2ne32(ref_lp[1]) >> 1) + lv2) << 1);\n\n                                    cur_lp[width_tbl[1]] = av_le2ne32(((av_le2ne32(ref_lp[width_tbl[1]]) >> 1) + lv1) << 1);\n\n                                    cur_lp[width_tbl[1]+1] = av_le2ne32(((av_le2ne32(ref_lp[width_tbl[1]+1]) >> 1) + lv2) << 1);\n\n                                    lp2++;\n\n                                    break;\n\n\n\n                                case 2:\n\n                                    if(lp2 == 0) {\n\n                                        for(i = 0, j = 0; i < 4; i++, j += width_tbl[1]) {\n\n                                            cur_lp[j] = ref_lp[j];\n\n                                            cur_lp[j+1] = ref_lp[j+1];\n\n                                        }\n\n                                        lp2 += 2;\n\n                                    }\n\n                                    break;\n\n\n\n                                case 3:\n\n                                    if(lp2 < 2) {\n\n                                        for(i = 0, j = 0; i < 6 - (lp2 * 2); i++, j += width_tbl[1]) {\n\n                                            cur_lp[j] = ref_lp[j];\n\n                                            cur_lp[j+1] = ref_lp[j+1];\n\n                                        }\n\n                                        lp2 = 3;\n\n                                    }\n\n                                    break;\n\n\n\n                                case 8:\n\n                                    if(lp2 == 0) {\n\n                                        RLE_V3_CHECK(buf1,rle_v1,rle_v2,rle_v3)\n\n                                        for(i = 0, j = 0; i < 8; i++, j += width_tbl[1]) {\n\n                                            ((uint32_t *)cur_frm_pos)[j] = ((uint32_t *)ref_frm_pos)[j];\n\n                                            ((uint32_t *)cur_frm_pos)[j+1] = ((uint32_t *)ref_frm_pos)[j+1];\n\n                                        }\n\n                                        RLE_V2_CHECK(buf1,rle_v2, rle_v3,lp2)\n\n                                        break;\n\n                                    } else {\n\n                                        rle_v1 = 1;\n\n                                        rle_v2 = (*buf1) - 1;\n\n                                    }\n\n                                case 5:\n\n                                case 7:\n\n                                    LP2_CHECK(buf1,rle_v3,lp2)\n\n                                case 6:\n\n                                case 4:\n\n                                    for(i = 0, j = 0; i < 8 - (lp2 * 2); i++, j += width_tbl[1]) {\n\n                                        cur_lp[j] = ref_lp[j];\n\n                                        cur_lp[j+1] = ref_lp[j+1];\n\n                                    }\n\n                                    lp2 = 4;\n\n                                    break;\n\n\n\n                                case 9:\n\n                                    av_log(s->avctx, AV_LOG_ERROR, \"UNTESTED.\\n\");\n\n                                    lv1 = *buf1;\n\n                                    lv = (lv1 & 0x7F) << 1;\n\n                                    lv += (lv << 8);\n\n                                    lv += (lv << 16);\n\n                                    for(i = 0, j = 0; i < 8; i++, j += width_tbl[1])\n\n                                        ((uint32_t *)cur_frm_pos)[j] = ((uint32_t *)cur_frm_pos)[j+1] = lv;\n\n                                    LV1_CHECK(buf1,rle_v3,lv1,lp2)\n\n                                    break;\n\n\n\n                                default:\n\n                                    return;\n\n                                }\n\n                            }\n\n\n\n                            cur_frm_pos += 8;\n\n                            ref_frm_pos += 8;\n\n                        }\n\n\n\n                        cur_frm_pos += (((width * 2) - blks_width) * 4);\n\n                        ref_frm_pos += (((width * 2) - blks_width) * 4);\n\n                    }\n\n                }\n\n                break;\n\n\n\n            case 11:                    /********** CASE 11 **********/\n\n                if(ref_vectors == NULL)\n\n                    return;\n\n\n\n                for( ; blks_height > 0; blks_height -= 8) {\n\n                    for(lp1 = 0; lp1 < blks_width; lp1++) {\n\n                        for(lp2 = 0; lp2 < 4; ) {\n\n                            k = *buf1++;\n\n                            cur_lp = ((uint32_t *)cur_frm_pos) + width_tbl[lp2 * 2];\n\n                            ref_lp = ((uint32_t *)ref_frm_pos) + width_tbl[lp2 * 2];\n\n\n\n                            switch(correction_type_sp[lp2 & 0x01][k]) {\n\n                            case 0:\n\n                                cur_lp[0] = av_le2ne32(((av_le2ne32(*ref_lp) >> 1) + correction_lp[lp2 & 0x01][k]) << 1);\n\n                                cur_lp[width_tbl[1]] = av_le2ne32(((av_le2ne32(ref_lp[width_tbl[1]]) >> 1) + correction_lp[lp2 & 0x01][k]) << 1);\n\n                                lp2++;\n\n                                break;\n\n\n\n                            case 1:\n\n                                lv1 = (unsigned short)(correction_lp[lp2 & 0x01][*buf1++]);\n\n                                lv2 = (unsigned short)(correction_lp[lp2 & 0x01][k]);\n\n                                res = (unsigned short)(((av_le2ne16(((unsigned short *)ref_lp)[0]) >> 1) + lv1) << 1);\n\n                                ((unsigned short *)cur_lp)[0] = av_le2ne16(res);\n\n                                res = (unsigned short)(((av_le2ne16(((unsigned short *)ref_lp)[1]) >> 1) + lv2) << 1);\n\n                                ((unsigned short *)cur_lp)[1] = av_le2ne16(res);\n\n                                res = (unsigned short)(((av_le2ne16(((unsigned short *)ref_lp)[width_tbl[2]]) >> 1) + lv1) << 1);\n\n                                ((unsigned short *)cur_lp)[width_tbl[2]] = av_le2ne16(res);\n\n                                res = (unsigned short)(((av_le2ne16(((unsigned short *)ref_lp)[width_tbl[2]+1]) >> 1) + lv2) << 1);\n\n                                ((unsigned short *)cur_lp)[width_tbl[2]+1] = av_le2ne16(res);\n\n                                lp2++;\n\n                                break;\n\n\n\n                            case 2:\n\n                                if(lp2 == 0) {\n\n                                    for(i = 0, j = 0; i < 4; i++, j += width_tbl[1])\n\n                                        cur_lp[j] = ref_lp[j];\n\n                                    lp2 += 2;\n\n                                }\n\n                                break;\n\n\n\n                            case 3:\n\n                                if(lp2 < 2) {\n\n                                    for(i = 0, j = 0; i < 6 - (lp2 * 2); i++, j += width_tbl[1])\n\n                                        cur_lp[j] = ref_lp[j];\n\n                                    lp2 = 3;\n\n                                }\n\n                                break;\n\n\n\n                            case 8:\n\n                                if(lp2 == 0) {\n\n                                    RLE_V3_CHECK(buf1,rle_v1,rle_v2,rle_v3)\n\n\n\n                                    for(i = 0, j = 0; i < 8; i++, j += width_tbl[1])\n\n                                        cur_lp[j] = ref_lp[j];\n\n\n\n                                    RLE_V2_CHECK(buf1,rle_v2, rle_v3,lp2)\n\n                                    break;\n\n                                } else {\n\n                                    rle_v1 = 1;\n\n                                    rle_v2 = (*buf1) - 1;\n\n                                }\n\n                            case 5:\n\n                            case 7:\n\n                                LP2_CHECK(buf1,rle_v3,lp2)\n\n                            case 4:\n\n                            case 6:\n\n                                for(i = 0, j = 0; i < 8 - (lp2 * 2); i++, j += width_tbl[1])\n\n                                    cur_lp[j] = ref_lp[j];\n\n                                lp2 = 4;\n\n                                break;\n\n\n\n                            case 9:\n\n                                av_log(s->avctx, AV_LOG_ERROR, \"UNTESTED.\\n\");\n\n                                lv1 = *buf1++;\n\n                                lv = (lv1 & 0x7F) << 1;\n\n                                lv += (lv << 8);\n\n                                lv += (lv << 16);\n\n                                for(i = 0, j = 0; i < 4; i++, j += width_tbl[1])\n\n                                    cur_lp[j] = lv;\n\n                                LV1_CHECK(buf1,rle_v3,lv1,lp2)\n\n                                break;\n\n\n\n                            default:\n\n                                return;\n\n                            }\n\n                        }\n\n\n\n                        cur_frm_pos += 4;\n\n                        ref_frm_pos += 4;\n\n                    }\n\n\n\n                    cur_frm_pos += (((width * 2) - blks_width) * 4);\n\n                    ref_frm_pos += (((width * 2) - blks_width) * 4);\n\n                }\n\n                break;\n\n\n\n            default:\n\n                return;\n\n            }\n\n        }\n\n\n\n        for( ; strip >= strip_tbl; strip--) {\n\n            if(strip->split_flag != 0) {\n\n                strip->split_flag = 0;\n\n                strip->usl7 = (strip-1)->usl7;\n\n\n\n                if(strip->split_direction) {\n\n                    strip->xpos += strip->width;\n\n                    strip->width = (strip-1)->width - strip->width;\n\n                    if(region_160_width <= strip->xpos && width < strip->width + strip->xpos)\n\n                        strip->width = width - strip->xpos;\n\n                } else {\n\n                    strip->ypos += strip->height;\n\n                    strip->height = (strip-1)->height - strip->height;\n\n                }\n\n                break;\n\n            }\n\n        }\n\n    }\n\n}", "idx": 10662, "_split": "valid", "_hash": "eba13a6984b5f600455cb2d6b7119890"}
{"project": "FFmpeg", "commit_id": "29112db8c0f65886e69cbbd6f4e5c44d2d14d238", "target": 1, "func": "static int bethsoftvid_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *data_size,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    BethsoftvidContext * vid = avctx->priv_data;\n\n    char block_type;\n\n    uint8_t * dst;\n\n    uint8_t * frame_end;\n\n    int remaining = avctx->width;          // number of bytes remaining on a line\n\n    const int wrap_to_next_line = vid->frame.linesize[0] - avctx->width;\n\n    int code;\n\n    int yoffset;\n\n\n\n    if (avctx->reget_buffer(avctx, &vid->frame)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n    dst = vid->frame.data[0];\n\n    frame_end = vid->frame.data[0] + vid->frame.linesize[0] * avctx->height;\n\n\n\n    switch(block_type = *buf++){\n\n        case PALETTE_BLOCK:\n\n            return set_palette(&vid->frame, buf, buf_size);\n\n        case VIDEO_YOFF_P_FRAME:\n\n            yoffset = bytestream_get_le16(&buf);\n\n            if(yoffset >= avctx->height)\n\n                return -1;\n\n            dst += vid->frame.linesize[0] * yoffset;\n\n    }\n\n\n\n    // main code\n\n    while((code = *buf++)){\n\n        int length = code & 0x7f;\n\n\n\n        // copy any bytes starting at the current position, and ending at the frame width\n\n        while(length > remaining){\n\n            if(code < 0x80)\n\n                bytestream_get_buffer(&buf, dst, remaining);\n\n            else if(block_type == VIDEO_I_FRAME)\n\n                memset(dst, buf[0], remaining);\n\n            length -= remaining;      // decrement the number of bytes to be copied\n\n            dst += remaining + wrap_to_next_line;    // skip over extra bytes at end of frame\n\n            remaining = avctx->width;\n\n            if(dst == frame_end)\n\n                goto end;\n\n        }\n\n\n\n        // copy any remaining bytes after / if line overflows\n\n        if(code < 0x80)\n\n            bytestream_get_buffer(&buf, dst, length);\n\n        else if(block_type == VIDEO_I_FRAME)\n\n            memset(dst, *buf++, length);\n\n        remaining -= length;\n\n        dst += length;\n\n    }\n\n    end:\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = vid->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 10673, "_split": "valid", "_hash": "bbcced16f644fb41dcafd85ae1e60301"}
{"project": "FFmpeg", "commit_id": "4ea7c179325f61736040f2ff22c2f27c702727d4", "target": 1, "func": "static int filter_frame(AVFilterLink *link, AVFilterBufferRef *picref)\n\n{\n\n    AVFilterContext *ctx = link->dst;\n\n    YADIFContext *yadif = ctx->priv;\n\n\n\n    av_assert0(picref);\n\n\n\n    if (picref->video->h < 3 || picref->video->w < 3) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Video of less than 3 columns or lines is not supported\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (yadif->frame_pending)\n\n        return_frame(ctx, 1);\n\n\n\n    if (yadif->prev)\n\n        avfilter_unref_buffer(yadif->prev);\n\n    yadif->prev = yadif->cur;\n\n    yadif->cur  = yadif->next;\n\n    yadif->next = picref;\n\n\n\n    if (!yadif->cur)\n\n        return 0;\n\n\n\n    if (yadif->auto_enable && !yadif->cur->video->interlaced) {\n\n        yadif->out  = avfilter_ref_buffer(yadif->cur, ~AV_PERM_WRITE);\n\n        if (!yadif->out)\n\n            return AVERROR(ENOMEM);\n\n\n\n        avfilter_unref_bufferp(&yadif->prev);\n\n        if (yadif->out->pts != AV_NOPTS_VALUE)\n\n            yadif->out->pts *= 2;\n\n        return ff_filter_frame(ctx->outputs[0], yadif->out);\n\n    }\n\n\n\n    if (!yadif->prev &&\n\n        !(yadif->prev = avfilter_ref_buffer(yadif->cur, ~AV_PERM_WRITE)))\n\n        return AVERROR(ENOMEM);\n\n\n\n    yadif->out = ff_get_video_buffer(ctx->outputs[0], PERM_RWP,\n\n                                     link->w, link->h);\n\n    if (!yadif->out)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avfilter_copy_buffer_ref_props(yadif->out, yadif->cur);\n\n    yadif->out->video->interlaced = 0;\n\n\n\n    if (yadif->out->pts != AV_NOPTS_VALUE)\n\n        yadif->out->pts *= 2;\n\n\n\n    return return_frame(ctx, 0);\n\n}\n", "idx": 10736, "_split": "valid", "_hash": "d571cde1d4f3b5d8d6a7dd26a7cc3c2b"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "void ff_put_h264_qpel16_mc23_msa(uint8_t *dst, const uint8_t *src,\n\n                                 ptrdiff_t stride)\n\n{\n\n    avc_luma_midv_qrt_16w_msa(src - (2 * stride) - 2,\n\n                              stride, dst, stride, 16, 1);\n\n}\n", "idx": 10739, "_split": "valid", "_hash": "836bc33910580dfc667f587da99e8e88"}
{"project": "FFmpeg", "commit_id": "d31dbec3742e488156621b9ca21069f8c05aabf0", "target": 0, "func": "static int init_duplicate_context(MpegEncContext *s, MpegEncContext *base){\n\n    int i;\n\n\n\n    // edge emu needs blocksize + filter length - 1 (=17x17 for halfpel / 21x21 for h264)\n\n    CHECKED_ALLOCZ(s->allocated_edge_emu_buffer, (s->width+64)*2*21*2); //(width + edge + align)*interlaced*MBsize*tolerance\n\n    s->edge_emu_buffer= s->allocated_edge_emu_buffer + (s->width+64)*2*21;\n\n\n\n     //FIXME should be linesize instead of s->width*2 but that is not known before get_buffer()\n\n    CHECKED_ALLOCZ(s->me.scratchpad,  (s->width+64)*4*16*2*sizeof(uint8_t))\n\n    s->me.temp=         s->me.scratchpad;\n\n    s->rd_scratchpad=   s->me.scratchpad;\n\n    s->b_scratchpad=    s->me.scratchpad;\n\n    s->obmc_scratchpad= s->me.scratchpad + 16;\n\n    if (s->encoding) {\n\n        CHECKED_ALLOCZ(s->me.map      , ME_MAP_SIZE*sizeof(uint32_t))\n\n        CHECKED_ALLOCZ(s->me.score_map, ME_MAP_SIZE*sizeof(uint32_t))\n\n        if(s->avctx->noise_reduction){\n\n            CHECKED_ALLOCZ(s->dct_error_sum, 2 * 64 * sizeof(int))\n\n        }\n\n    }\n\n    CHECKED_ALLOCZ(s->blocks, 64*12*2 * sizeof(DCTELEM))\n\n    s->block= s->blocks[0];\n\n\n\n    for(i=0;i<12;i++){\n\n        s->pblocks[i] = &s->block[i];\n\n    }\n\n    return 0;\n\nfail:\n\n    return -1; //free() through MPV_common_end()\n\n}\n", "idx": 10751, "_split": "valid", "_hash": "37c8f8b3dc4504968ee264e877691f97"}
{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "void ff_put_h264_qpel4_mc31_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_4w_msa(src - 2,\n\n                           src - (stride * 2) +\n\n                           sizeof(uint8_t), stride, dst, stride, 4);\n\n}\n", "idx": 10762, "_split": "valid", "_hash": "99cd763a7f5764cd9018f44fd705dafc"}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "yuv2rgb48_1_c_template(SwsContext *c, const uint16_t *buf0,\n\n                       const uint16_t *ubuf0, const uint16_t *ubuf1,\n\n                       const uint16_t *vbuf0, const uint16_t *vbuf1,\n\n                       const uint16_t *abuf0, uint8_t *dest, int dstW,\n\n                       int uvalpha, enum PixelFormat dstFormat,\n\n                       int flags, int y, enum PixelFormat target)\n\n{\n\n    int i;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 = buf0[i * 2]     >> 7;\n\n            int Y2 = buf0[i * 2 + 1] >> 7;\n\n            int U  = ubuf1[i]        >> 7;\n\n            int V  = vbuf1[i]        >> 7;\n\n            const uint8_t *r = (const uint8_t *) c->table_rV[V],\n\n                          *g = (const uint8_t *)(c->table_gU[U] + c->table_gV[V]),\n\n                          *b = (const uint8_t *) c->table_bU[U];\n\n\n\n            dest[ 0] = dest[ 1] = r_b[Y1];\n\n            dest[ 2] = dest[ 3] =   g[Y1];\n\n            dest[ 4] = dest[ 5] = b_r[Y1];\n\n            dest[ 6] = dest[ 7] = r_b[Y2];\n\n            dest[ 8] = dest[ 9] =   g[Y2];\n\n            dest[10] = dest[11] = b_r[Y2];\n\n            dest += 12;\n\n        }\n\n    } else {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 =  buf0[i * 2]          >> 7;\n\n            int Y2 =  buf0[i * 2 + 1]      >> 7;\n\n            int U  = (ubuf0[i] + ubuf1[i]) >> 8;\n\n            int V  = (vbuf0[i] + vbuf1[i]) >> 8;\n\n            const uint8_t *r = (const uint8_t *) c->table_rV[V],\n\n                          *g = (const uint8_t *)(c->table_gU[U] + c->table_gV[V]),\n\n                          *b = (const uint8_t *) c->table_bU[U];\n\n\n\n            dest[ 0] = dest[ 1] = r_b[Y1];\n\n            dest[ 2] = dest[ 3] =   g[Y1];\n\n            dest[ 4] = dest[ 5] = b_r[Y1];\n\n            dest[ 6] = dest[ 7] = r_b[Y2];\n\n            dest[ 8] = dest[ 9] =   g[Y2];\n\n            dest[10] = dest[11] = b_r[Y2];\n\n            dest += 12;\n\n        }\n\n    }\n\n}\n", "idx": 10778, "_split": "valid", "_hash": "559beeaca12af8c0b510a3367efa225c"}
{"project": "FFmpeg", "commit_id": "32baeafeee4f8446c2c3720b9223ad2166ca9d30", "target": 1, "func": "static void add_pixels_clamped_c(const int16_t *block, uint8_t *av_restrict pixels,\n\n                                 ptrdiff_t line_size)\n\n{\n\n    int i;\n\n\n\n    /* read the pixels */\n\n    for (i = 0; i < 8; i++) {\n\n        pixels[0] = av_clip_uint8(pixels[0] + block[0]);\n\n        pixels[1] = av_clip_uint8(pixels[1] + block[1]);\n\n        pixels[2] = av_clip_uint8(pixels[2] + block[2]);\n\n        pixels[3] = av_clip_uint8(pixels[3] + block[3]);\n\n        pixels[4] = av_clip_uint8(pixels[4] + block[4]);\n\n        pixels[5] = av_clip_uint8(pixels[5] + block[5]);\n\n        pixels[6] = av_clip_uint8(pixels[6] + block[6]);\n\n        pixels[7] = av_clip_uint8(pixels[7] + block[7]);\n\n        pixels   += line_size;\n\n        block    += 8;\n\n    }\n\n}\n", "idx": 10828, "_split": "valid", "_hash": "9acca24ddcce815980b1ae2aa30366f6"}
{"project": "FFmpeg", "commit_id": "2758cdedfb7ac61f8b5e4861f99218b6fd43491d", "target": 0, "func": "const char *avio_enum_protocols(void **opaque, int output)\n\n{\n\n    URLProtocol *p;\n\n    *opaque = ffurl_protocol_next(*opaque);\n\n    if (!(p = *opaque))\n\n        return NULL;\n\n    if ((output && p->url_write) || (!output && p->url_read))\n\n        return p->name;\n\n    return avio_enum_protocols(opaque, output);\n\n}\n", "idx": 10835, "_split": "valid", "_hash": "c0f95136a1a3ab5dde2b76afc4a4a94d"}
{"project": "FFmpeg", "commit_id": "cadab5a2a74d715fc16325bd89f8b8091def1083", "target": 1, "func": "static int read_highpass(AVCodecContext *avctx, uint8_t *ptr, int plane, AVFrame *frame)\n{\n    PixletContext *ctx = avctx->priv_data;\n    ptrdiff_t stride = frame->linesize[plane] / 2;\n    int i, ret;\n    for (i = 0; i < ctx->levels * 3; i++) {\n        int32_t a = bytestream2_get_be32(&ctx->gb);\n        int32_t b = bytestream2_get_be32(&ctx->gb);\n        int32_t c = bytestream2_get_be32(&ctx->gb);\n        int32_t d = bytestream2_get_be32(&ctx->gb);\n        int16_t *dest = (int16_t *)frame->data[plane] + ctx->band[plane][i + 1].x +\n                                               stride * ctx->band[plane][i + 1].y;\n        unsigned size = ctx->band[plane][i + 1].size;\n        uint32_t magic;\n        magic = bytestream2_get_be32(&ctx->gb);\n        if (magic != 0xDEADBEEF) {\n            av_log(avctx, AV_LOG_ERROR, \"wrong magic number: 0x%08\"PRIX32\n                   \" for plane %d, band %d\\n\", magic, plane, i);\n        }\n        ret = read_high_coeffs(avctx, ptr + bytestream2_tell(&ctx->gb), dest, size,\n                               c, (b >= FFABS(a)) ? b : a, d,\n                               ctx->band[plane][i + 1].width, stride);\n        if (ret < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"error in highpass coefficients for plane %d, band %d\\n\", plane, i);\n            return ret;\n        }\n        bytestream2_skip(&ctx->gb, ret);\n    }\n    return 0;\n}", "idx": 10840, "_split": "valid", "_hash": "a1e14565f79df13dedf0bd4a60ba8a3d"}
{"project": "FFmpeg", "commit_id": "eaff5fcb7cde8d1614755269773d471d3a3d1bfc", "target": 1, "func": "static int vp9_superframe_split_filter(AVBSFContext *ctx, AVPacket *out)\n\n{\n\n    VP9SFSplitContext *s = ctx->priv_data;\n\n    AVPacket *in;\n\n    int i, j, ret, marker;\n\n    int is_superframe = !!s->buffer_pkt;\n\n\n\n    if (!s->buffer_pkt) {\n\n        ret = ff_bsf_get_packet(ctx, &s->buffer_pkt);\n\n        if (ret < 0)\n\n            return ret;\n\n        in = s->buffer_pkt;\n\n\n\n        marker = in->data[in->size - 1];\n\n        if ((marker & 0xe0) == 0xc0) {\n\n            int length_size = 1 + ((marker >> 3) & 0x3);\n\n            int   nb_frames = 1 + (marker & 0x7);\n\n            int    idx_size = 2 + nb_frames * length_size;\n\n\n\n            if (in->size >= idx_size && in->data[in->size - idx_size] == marker) {\n\n                GetByteContext bc;\n\n                int total_size = 0;\n\n\n\n                bytestream2_init(&bc, in->data + in->size + 1 - idx_size,\n\n                                 nb_frames * length_size);\n\n\n\n                for (i = 0; i < nb_frames; i++) {\n\n                    int frame_size = 0;\n\n                    for (j = 0; j < length_size; j++)\n\n                        frame_size |= bytestream2_get_byte(&bc) << (j * 8);\n\n\n\n                    total_size += frame_size;\n\n                    if (total_size > in->size - idx_size) {\n\n                        av_log(ctx, AV_LOG_ERROR,\n\n                               \"Invalid frame size in a superframe: %d\\n\", frame_size);\n\n                        ret = AVERROR(EINVAL);\n\n                        goto fail;\n\n                    }\n\n                    s->sizes[i] = frame_size;\n\n                }\n\n                s->nb_frames         = nb_frames;\n\n                s->next_frame        = 0;\n\n                s->next_frame_offset = 0;\n\n                is_superframe        = 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (is_superframe) {\n\n        GetBitContext gb;\n\n        int profile, invisible = 0;\n\n\n\n        ret = av_packet_ref(out, s->buffer_pkt);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        out->data += s->next_frame_offset;\n\n        out->size  = s->sizes[s->next_frame];\n\n\n\n        s->next_frame_offset += out->size;\n\n        s->next_frame++;\n\n\n\n        if (s->next_frame >= s->nb_frames)\n\n            av_packet_free(&s->buffer_pkt);\n\n\n\n        ret = init_get_bits8(&gb, out->data, out->size);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        get_bits(&gb, 2); // frame_marker\n\n        profile  = get_bits1(&gb);\n\n        profile |= get_bits1(&gb) << 1;\n\n        if (profile == 3)\n\n            get_bits1(&gb);\n\n        if (!get_bits1(&gb)) {\n\n            get_bits1(&gb);\n\n            invisible = !get_bits1(&gb);\n\n        }\n\n\n\n        if (invisible)\n\n            out->pts = AV_NOPTS_VALUE;\n\n\n\n    } else {\n\n        av_packet_move_ref(out, s->buffer_pkt);\n\n        av_packet_free(&s->buffer_pkt);\n\n    }\n\n\n\n    return 0;\n\nfail:\n\n    av_packet_free(&s->buffer_pkt);\n\n    return ret;\n\n}\n", "idx": 10843, "_split": "valid", "_hash": "536a81563ba005e8b98a9eb853b563a7"}
{"project": "FFmpeg", "commit_id": "eba1ff31304e407db3cefd7532108408f364367b", "target": 1, "func": "static int decode_bytes(const uint8_t *input, uint8_t *out, int bytes)\n\n{\n\n    int i, off;\n\n    uint32_t c;\n\n    const uint32_t *buf;\n\n    uint32_t *output = (uint32_t *)out;\n\n\n\n    off = (intptr_t)input & 3;\n\n    buf = (const uint32_t *)(input - off);\n\n    c   = av_be2ne32((0x537F6103 >> (off * 8)) | (0x537F6103 << (32 - (off * 8))));\n\n    bytes += 3 + off;\n\n    for (i = 0; i < bytes / 4; i++)\n\n        output[i] = c ^ buf[i];\n\n\n\n    if (off)\n\n        avpriv_request_sample(NULL, \"Offset of %d\", off);\n\n\n\n    return off;\n\n}\n", "idx": 10862, "_split": "valid", "_hash": "c6b0e952b2ede22b14daf52d35cdadf3"}
{"project": "FFmpeg", "commit_id": "155ec6edf82692bcf3a5f87d2bc697404f4e5aaf", "target": 0, "func": "static int encode_frame(AVCodecContext *avctx, unsigned char *buf, int buf_size, void *data){\n\n    SnowContext *s = avctx->priv_data;\n\n    CABACContext * const c= &s->c;\n\n    AVFrame *pict = data;\n\n    const int width= s->avctx->width;\n\n    const int height= s->avctx->height;\n\n    int used_count= 0;\n\n    int log2_threshold, level, orientation, plane_index, i;\n\n\n\n    ff_init_cabac_encoder(c, buf, buf_size);\n\n    ff_init_cabac_states(c, ff_h264_lps_range, ff_h264_mps_state, ff_h264_lps_state, 64);\n\n    \n\n    s->input_picture = *pict;\n\n\n\n    memset(s->header_state, 0, sizeof(s->header_state));\n\n\n\n    s->keyframe=avctx->gop_size==0 || avctx->frame_number % avctx->gop_size == 0;\n\n    pict->pict_type= s->keyframe ? FF_I_TYPE : FF_P_TYPE;\n\n    \n\n    if(pict->quality){\n\n        s->qlog= rint(QROOT*log(pict->quality / (float)FF_QP2LAMBDA)/log(2));\n\n        //<64 >60\n\n        s->qlog += 61;\n\n    }else{\n\n        s->qlog= LOSSLESS_QLOG;\n\n    }\n\n\n\n    for(i=0; i<s->mb_band.stride * s->mb_band.height; i++){\n\n        s->mb_band.buf[i]= s->keyframe;\n\n    }\n\n    \n\n    frame_start(s);\n\n\n\n    if(pict->pict_type == P_TYPE){\n\n        int block_width = (width +15)>>4;\n\n        int block_height= (height+15)>>4;\n\n        int stride= s->current_picture.linesize[0];\n\n        uint8_t *src_plane= s->input_picture.data[0];\n\n        int src_stride= s->input_picture.linesize[0];\n\n        int x,y;\n\n        \n\n        assert(s->current_picture.data[0]);\n\n        assert(s->last_picture.data[0]);\n\n     \n\n        s->m.avctx= s->avctx;\n\n        s->m.current_picture.data[0]= s->current_picture.data[0];\n\n        s->m.   last_picture.data[0]= s->   last_picture.data[0];\n\n        s->m.    new_picture.data[0]= s->  input_picture.data[0];\n\n        s->m.current_picture_ptr= &s->m.current_picture;\n\n        s->m.   last_picture_ptr= &s->m.   last_picture;\n\n        s->m.linesize=\n\n        s->m.   last_picture.linesize[0]=\n\n        s->m.    new_picture.linesize[0]=\n\n        s->m.current_picture.linesize[0]= stride;\n\n        s->m.width = width;\n\n        s->m.height= height;\n\n        s->m.mb_width = block_width;\n\n        s->m.mb_height= block_height;\n\n        s->m.mb_stride=   s->m.mb_width+1;\n\n        s->m.b8_stride= 2*s->m.mb_width+1;\n\n        s->m.f_code=1;\n\n        s->m.pict_type= pict->pict_type;\n\n        s->m.me_method= s->avctx->me_method;\n\n        s->m.me.scene_change_score=0;\n\n        s->m.flags= s->avctx->flags;\n\n        s->m.quarter_sample= (s->avctx->flags & CODEC_FLAG_QPEL)!=0;\n\n        s->m.out_format= FMT_H263;\n\n        s->m.unrestricted_mv= 1;\n\n\n\n        s->m.lambda= pict->quality * 3/2; //FIXME bug somewhere else\n\n        s->m.qscale= (s->m.lambda*139 + FF_LAMBDA_SCALE*64) >> (FF_LAMBDA_SHIFT + 7);\n\n        s->m.lambda2= (s->m.lambda*s->m.lambda + FF_LAMBDA_SCALE/2) >> FF_LAMBDA_SHIFT;\n\n\n\n        if(!s->motion_val8){\n\n            s->motion_val8 = av_mallocz(s->m.b8_stride*block_height*2*2*sizeof(int16_t));\n\n            s->motion_val16= av_mallocz(s->m.mb_stride*block_height*2*sizeof(int16_t));\n\n        }\n\n        \n\n        s->m.mb_type= s->mb_type;\n\n        \n\n        //dummies, to avoid segfaults\n\n        s->m.current_picture.mb_mean  = s->mb_mean;\n\n        s->m.current_picture.mb_var   = (int16_t*)s->dummy;\n\n        s->m.current_picture.mc_mb_var= (int16_t*)s->dummy;\n\n        s->m.current_picture.mb_type  = s->dummy;\n\n        \n\n        s->m.current_picture.motion_val[0]= s->motion_val8;\n\n        s->m.p_mv_table= s->motion_val16;\n\n        s->m.dsp= s->dsp; //move\n\n        ff_init_me(&s->m);\n\n    \n\n        \n\n        s->m.me.pre_pass=1;\n\n        s->m.me.dia_size= s->avctx->pre_dia_size;\n\n        s->m.first_slice_line=1;\n\n        for(y= block_height-1; y >= 0; y--) {\n\n            uint8_t src[stride*16];\n\n\n\n            s->m.new_picture.data[0]= src - y*16*stride; //ugly\n\n            s->m.mb_y= y;\n\n            for(i=0; i<16 && i + 16*y<height; i++){\n\n                memcpy(&src[i*stride], &src_plane[(i+16*y)*src_stride], width);\n\n                for(x=width; x<16*block_width; x++)\n\n                    src[i*stride+x]= src[i*stride+x-1];\n\n            }\n\n            for(; i<16 && i + 16*y<16*block_height; i++)\n\n                memcpy(&src[i*stride], &src[(i-1)*stride], 16*block_width);\n\n\n\n            for(x=block_width-1; x >=0 ;x--) {\n\n                s->m.mb_x= x;\n\n                ff_init_block_index(&s->m);\n\n                ff_update_block_index(&s->m);\n\n                ff_pre_estimate_p_frame_motion(&s->m, x, y);\n\n            }\n\n            s->m.first_slice_line=0;\n\n        }        \n\n        s->m.me.pre_pass=0;\n\n        \n\n        \n\n        s->m.me.dia_size= s->avctx->dia_size;\n\n        s->m.first_slice_line=1;\n\n        for (y = 0; y < block_height; y++) {\n\n            uint8_t src[stride*16];\n\n\n\n            s->m.new_picture.data[0]= src - y*16*stride; //ugly\n\n            s->m.mb_y= y;\n\n            \n\n            assert(width <= stride);\n\n            assert(width <= 16*block_width);\n\n    \n\n            for(i=0; i<16 && i + 16*y<height; i++){\n\n                memcpy(&src[i*stride], &src_plane[(i+16*y)*src_stride], width);\n\n                for(x=width; x<16*block_width; x++)\n\n                    src[i*stride+x]= src[i*stride+x-1];\n\n            }\n\n            for(; i<16 && i + 16*y<16*block_height; i++)\n\n                memcpy(&src[i*stride], &src[(i-1)*stride], 16*block_width);\n\n    \n\n            for (x = 0; x < block_width; x++) {\n\n                int mb_xy= x + y*(s->mb_band.stride);\n\n                s->m.mb_x= x;\n\n                ff_init_block_index(&s->m);\n\n                ff_update_block_index(&s->m);\n\n                \n\n                ff_estimate_p_frame_motion(&s->m, x, y);\n\n                \n\n                s->mb_band   .buf[mb_xy]= (s->m.mb_type[x + y*s->m.mb_stride]&CANDIDATE_MB_TYPE_INTER)\n\n                 ? 0 : 2;\n\n                s->mv_band[0].buf[mb_xy]= s->motion_val16[x + y*s->m.mb_stride][0];\n\n                s->mv_band[1].buf[mb_xy]= s->motion_val16[x + y*s->m.mb_stride][1];\n\n                \n\n                if(s->mb_band   .buf[x + y*(s->mb_band.stride)]==2 && 0){\n\n                    int dc0=128, dc1=128, dc, dc2, dir;\n\n                    int offset= (s->avctx->flags & CODEC_FLAG_QPEL) ? 64 : 32;\n\n                    \n\n                    dc       =s->mb_mean[x +  y   *s->m.mb_stride    ];\n\n                    if(x) dc0=s->mb_mean[x +  y   *s->m.mb_stride - 1];\n\n                    if(y) dc1=s->mb_mean[x + (y-1)*s->m.mb_stride    ];\n\n                    dc2= (dc0+dc1)>>1;\n\n#if 0\n\n                    if     (ABS(dc0 - dc) < ABS(dc1 - dc) && ABS(dc0 - dc) < ABS(dc2 - dc))\n\n                        dir= 1;\n\n                    else if(ABS(dc0 - dc) >=ABS(dc1 - dc) && ABS(dc1 - dc) < ABS(dc2 - dc))\n\n                        dir=-1;\n\n                    else\n\n                        dir=0;\n\n#endif                    \n\n                    if(ABS(dc0 - dc) < ABS(dc1 - dc) && x){\n\n                        s->mv_band[0].buf[mb_xy]= s->mv_band[0].buf[x + y*(s->mb_band.stride)-1] - offset;\n\n                        s->mv_band[1].buf[mb_xy]= s->mv_band[1].buf[x + y*(s->mb_band.stride)-1];\n\n                        s->mb_mean[x +  y   *s->m.mb_stride    ]= dc0;\n\n                    }else if(y){\n\n                        s->mv_band[0].buf[mb_xy]= s->mv_band[0].buf[x + (y-1)*(s->mb_band.stride)];\n\n                        s->mv_band[1].buf[mb_xy]= s->mv_band[1].buf[x + (y-1)*(s->mb_band.stride)] - offset;\n\n                        s->mb_mean[x +  y   *s->m.mb_stride    ]= dc1;\n\n                    }\n\n                }\n\n//                s->mb_band   .buf[x + y*(s->mb_band.stride)]=1; //FIXME intra only test\n\n            }\n\n            s->m.first_slice_line=0;\n\n        }\n\n        assert(s->m.pict_type == P_TYPE);\n\n        if(s->m.me.scene_change_score > s->avctx->scenechange_threshold){\n\n            s->m.pict_type= \n\n            pict->pict_type =I_TYPE;\n\n            for(i=0; i<s->mb_band.stride * s->mb_band.height; i++){\n\n                s->mb_band.buf[i]= 1;\n\n                s->mv_band[0].buf[i]=\n\n                s->mv_band[1].buf[i]= 0;\n\n            }\n\n    //printf(\"Scene change detected, encoding as I Frame %d %d\\n\", s->current_picture.mb_var_sum, s->current_picture.mc_mb_var_sum);\n\n        }        \n\n    }\n\n        \n\n    s->m.first_slice_line=1;\n\n    \n\n    s->qbias= pict->pict_type == P_TYPE ? 2 : 0;\n\n\n\n    encode_header(s);\n\n    \n\n    decorrelate(s, &s->mb_band   , s->mb_band   .buf, s->mb_band   .stride, 0, 1);\n\n    decorrelate(s, &s->mv_band[0], s->mv_band[0].buf, s->mv_band[0].stride, 0, 1);\n\n    decorrelate(s, &s->mv_band[1], s->mv_band[1].buf, s->mv_band[1].stride, 0 ,1);\n\n    encode_subband(s, &s->mb_band   , s->mb_band   .buf, NULL, s->mb_band   .stride, 0);\n\n    encode_subband(s, &s->mv_band[0], s->mv_band[0].buf, NULL, s->mv_band[0].stride, 0);\n\n    encode_subband(s, &s->mv_band[1], s->mv_band[1].buf, NULL, s->mv_band[1].stride, 0);\n\n    \n\n//FIXME avoid this\n\n    correlate(s, &s->mb_band   , s->mb_band   .buf, s->mb_band   .stride, 1, 1);\n\n    correlate(s, &s->mv_band[0], s->mv_band[0].buf, s->mv_band[0].stride, 1, 1);\n\n    correlate(s, &s->mv_band[1], s->mv_band[1].buf, s->mv_band[1].stride, 1, 1);\n\n    \n\n    for(plane_index=0; plane_index<3; plane_index++){\n\n        Plane *p= &s->plane[plane_index];\n\n        int w= p->width;\n\n        int h= p->height;\n\n        int x, y;\n\n        int bits= put_bits_count(&s->c.pb);\n\n\n\n        //FIXME optimize\n\n     if(pict->data[plane_index]) //FIXME gray hack\n\n        for(y=0; y<h; y++){\n\n            for(x=0; x<w; x++){\n\n                s->spatial_dwt_buffer[y*w + x]= pict->data[plane_index][y*pict->linesize[plane_index] + x]<<8;\n\n            }\n\n        }\n\n        predict_plane(s, s->spatial_dwt_buffer, plane_index, 0);\n\n        if(s->qlog == LOSSLESS_QLOG){\n\n            for(y=0; y<h; y++){\n\n                for(x=0; x<w; x++){\n\n                    s->spatial_dwt_buffer[y*w + x]= (s->spatial_dwt_buffer[y*w + x] + 127)>>8;\n\n                }\n\n            }\n\n        }\n\n \n\n        ff_spatial_dwt(s->spatial_dwt_buffer, w, h, w, s->spatial_decomposition_type, s->spatial_decomposition_count);\n\n\n\n        for(level=0; level<s->spatial_decomposition_count; level++){\n\n            for(orientation=level ? 1 : 0; orientation<4; orientation++){\n\n                SubBand *b= &p->band[level][orientation];\n\n                \n\n                quantize(s, b, b->buf, b->stride, s->qbias);\n\n                if(orientation==0)\n\n                    decorrelate(s, b, b->buf, b->stride, pict->pict_type == P_TYPE, 0);\n\n                encode_subband(s, b, b->buf, b->parent ? b->parent->buf : NULL, b->stride, orientation);\n\n                assert(b->parent==NULL || b->parent->stride == b->stride*2);\n\n                if(orientation==0)\n\n                    correlate(s, b, b->buf, b->stride, 1, 0);\n\n            }\n\n        }\n\n//        av_log(NULL, AV_LOG_DEBUG, \"plane:%d bits:%d\\n\", plane_index, put_bits_count(&s->c.pb) - bits);\n\n\n\n        for(level=0; level<s->spatial_decomposition_count; level++){\n\n            for(orientation=level ? 1 : 0; orientation<4; orientation++){\n\n                SubBand *b= &p->band[level][orientation];\n\n\n\n                dequantize(s, b, b->buf, b->stride);\n\n            }\n\n        }\n\n\n\n        ff_spatial_idwt(s->spatial_dwt_buffer, w, h, w, s->spatial_decomposition_type, s->spatial_decomposition_count);\n\n        if(s->qlog == LOSSLESS_QLOG){\n\n            for(y=0; y<h; y++){\n\n                for(x=0; x<w; x++){\n\n                    s->spatial_dwt_buffer[y*w + x]<<=8;\n\n                }\n\n            }\n\n        }\n\n        predict_plane(s, s->spatial_dwt_buffer, plane_index, 1);\n\n        //FIXME optimize\n\n        for(y=0; y<h; y++){\n\n            for(x=0; x<w; x++){\n\n                int v= (s->spatial_dwt_buffer[y*w + x]+128)>>8;\n\n                if(v&(~255)) v= ~(v>>31);\n\n                s->current_picture.data[plane_index][y*s->current_picture.linesize[plane_index] + x]= v;\n\n            }\n\n        }\n\n        if(s->avctx->flags&CODEC_FLAG_PSNR){\n\n            int64_t error= 0;\n\n            \n\n    if(pict->data[plane_index]) //FIXME gray hack\n\n            for(y=0; y<h; y++){\n\n                for(x=0; x<w; x++){\n\n                    int d= s->current_picture.data[plane_index][y*s->current_picture.linesize[plane_index] + x] - pict->data[plane_index][y*pict->linesize[plane_index] + x];\n\n                    error += d*d;\n\n                }\n\n            }\n\n            s->avctx->error[plane_index] += error;\n\n            s->avctx->error[3] += error;\n\n        }\n\n    }\n\n\n\n    if(s->last_picture.data[0])\n\n        avctx->release_buffer(avctx, &s->last_picture);\n\n\n\n    emms_c();\n\n    \n\n    return put_cabac_terminate(c, 1);\n\n}\n", "idx": 10867, "_split": "valid", "_hash": "a1fdf6969cbbe60f09f92f335e8140a5"}
{"project": "FFmpeg", "commit_id": "5ad4335c2233d5a6d9487d2d56387b7484aecded", "target": 0, "func": "void inter_predict(VP8Context *s, uint8_t *dst[3], VP8Macroblock *mb,\n\n                   int mb_x, int mb_y)\n\n{\n\n    int x_off = mb_x << 4, y_off = mb_y << 4;\n\n    int width = 16*s->mb_width, height = 16*s->mb_height;\n\n    AVFrame *ref = s->framep[mb->ref_frame];\n\n    VP56mv *bmv = mb->bmv;\n\n\n\n    switch (mb->partitioning) {\n\n    case VP8_SPLITMVMODE_NONE:\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    0, 0, 16, 16, width, height, &mb->mv);\n\n        break;\n\n    case VP8_SPLITMVMODE_4x4: {\n\n        int x, y;\n\n        VP56mv uvmv;\n\n\n\n        /* Y */\n\n        for (y = 0; y < 4; y++) {\n\n            for (x = 0; x < 4; x++) {\n\n                vp8_mc(s, 1, dst[0] + 4*y*s->linesize + x*4,\n\n                       ref->data[0], &bmv[4*y + x],\n\n                       4*x + x_off, 4*y + y_off, 4, 4,\n\n                       width, height, s->linesize,\n\n                       s->put_pixels_tab[2]);\n\n            }\n\n        }\n\n\n\n        /* U/V */\n\n        x_off >>= 1; y_off >>= 1; width >>= 1; height >>= 1;\n\n        for (y = 0; y < 2; y++) {\n\n            for (x = 0; x < 2; x++) {\n\n                uvmv.x = mb->bmv[ 2*y    * 4 + 2*x  ].x +\n\n                         mb->bmv[ 2*y    * 4 + 2*x+1].x +\n\n                         mb->bmv[(2*y+1) * 4 + 2*x  ].x +\n\n                         mb->bmv[(2*y+1) * 4 + 2*x+1].x;\n\n                uvmv.y = mb->bmv[ 2*y    * 4 + 2*x  ].y +\n\n                         mb->bmv[ 2*y    * 4 + 2*x+1].y +\n\n                         mb->bmv[(2*y+1) * 4 + 2*x  ].y +\n\n                         mb->bmv[(2*y+1) * 4 + 2*x+1].y;\n\n                uvmv.x = (uvmv.x + 2 + (uvmv.x >> (INT_BIT-1))) >> 2;\n\n                uvmv.y = (uvmv.y + 2 + (uvmv.y >> (INT_BIT-1))) >> 2;\n\n                if (s->profile == 3) {\n\n                    uvmv.x &= ~7;\n\n                    uvmv.y &= ~7;\n\n                }\n\n                vp8_mc(s, 0, dst[1] + 4*y*s->uvlinesize + x*4,\n\n                       ref->data[1], &uvmv,\n\n                       4*x + x_off, 4*y + y_off, 4, 4,\n\n                       width, height, s->uvlinesize,\n\n                       s->put_pixels_tab[2]);\n\n                vp8_mc(s, 0, dst[2] + 4*y*s->uvlinesize + x*4,\n\n                       ref->data[2], &uvmv,\n\n                       4*x + x_off, 4*y + y_off, 4, 4,\n\n                       width, height, s->uvlinesize,\n\n                       s->put_pixels_tab[2]);\n\n            }\n\n        }\n\n        break;\n\n    }\n\n    case VP8_SPLITMVMODE_16x8:\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    0, 0, 16, 8, width, height, &bmv[0]);\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    0, 8, 16, 8, width, height, &bmv[1]);\n\n        break;\n\n    case VP8_SPLITMVMODE_8x16:\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    0, 0, 8, 16, width, height, &bmv[0]);\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    8, 0, 8, 16, width, height, &bmv[1]);\n\n        break;\n\n    case VP8_SPLITMVMODE_8x8:\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    0, 0, 8, 8, width, height, &bmv[0]);\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    8, 0, 8, 8, width, height, &bmv[1]);\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    0, 8, 8, 8, width, height, &bmv[2]);\n\n        vp8_mc_part(s, dst, ref, x_off, y_off,\n\n                    8, 8, 8, 8, width, height, &bmv[3]);\n\n        break;\n\n    }\n\n}\n", "idx": 10928, "_split": "valid", "_hash": "8796b3dae0c16cc57024440c0bea0802"}
{"project": "FFmpeg", "commit_id": "8c3b026a0eeb49464d957b61b0c01cceecc416fd", "target": 1, "func": "int av_probe_input_buffer2(AVIOContext *pb, AVInputFormat **fmt,\n\n                          const char *filename, void *logctx,\n\n                          unsigned int offset, unsigned int max_probe_size)\n\n{\n\n    AVProbeData pd = { filename ? filename : \"\", NULL, -offset };\n\n    uint8_t *buf = NULL;\n\n    uint8_t *mime_type;\n\n    int ret = 0, probe_size, buf_offset = 0;\n\n    int score = 0;\n\n\n\n    if (!max_probe_size) {\n\n        max_probe_size = PROBE_BUF_MAX;\n\n    } else if (max_probe_size > PROBE_BUF_MAX) {\n\n        max_probe_size = PROBE_BUF_MAX;\n\n    } else if (max_probe_size < PROBE_BUF_MIN) {\n\n        av_log(logctx, AV_LOG_ERROR,\n\n               \"Specified probe size value %u cannot be < %u\\n\", max_probe_size, PROBE_BUF_MIN);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (offset >= max_probe_size) {\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (!*fmt && pb->av_class && av_opt_get(pb, \"mime_type\", AV_OPT_SEARCH_CHILDREN, &mime_type) >= 0 && mime_type) {\n\n        if (!av_strcasecmp(mime_type, \"audio/aacp\")) {\n\n            *fmt = av_find_input_format(\"aac\");\n\n        }\n\n        av_freep(&mime_type);\n\n    }\n\n\n\n    for(probe_size= PROBE_BUF_MIN; probe_size<=max_probe_size && !*fmt;\n\n        probe_size = FFMIN(probe_size<<1, FFMAX(max_probe_size, probe_size+1))) {\n\n\n\n        if (probe_size < offset) {\n\n            continue;\n\n        }\n\n        score = probe_size < max_probe_size ? AVPROBE_SCORE_RETRY : 0;\n\n\n\n        /* read probe data */\n\n        if ((ret = av_reallocp(&buf, probe_size + AVPROBE_PADDING_SIZE)) < 0)\n\n            return ret;\n\n        if ((ret = avio_read(pb, buf + buf_offset, probe_size - buf_offset)) < 0) {\n\n            /* fail if error was not end of file, otherwise, lower score */\n\n            if (ret != AVERROR_EOF) {\n\n                av_free(buf);\n\n                return ret;\n\n            }\n\n            score = 0;\n\n            ret = 0;            /* error was end of file, nothing read */\n\n        }\n\n        buf_offset += ret;\n\n        pd.buf_size = buf_offset - offset;\n\n        pd.buf = &buf[offset];\n\n\n\n        memset(pd.buf + pd.buf_size, 0, AVPROBE_PADDING_SIZE);\n\n\n\n        /* guess file format */\n\n        *fmt = av_probe_input_format2(&pd, 1, &score);\n\n        if(*fmt){\n\n            if(score <= AVPROBE_SCORE_RETRY){ //this can only be true in the last iteration\n\n                av_log(logctx, AV_LOG_WARNING, \"Format %s detected only with low score of %d, misdetection possible!\\n\", (*fmt)->name, score);\n\n            }else\n\n                av_log(logctx, AV_LOG_DEBUG, \"Format %s probed with size=%d and score=%d\\n\", (*fmt)->name, probe_size, score);\n\n#if 0\n\n            FILE *f = fopen(\"probestat.tmp\", \"ab\");\n\n            fprintf(f, \"probe_size:%d format:%s score:%d filename:%s\\n\", probe_size, (*fmt)->name, score, filename);\n\n            fclose(f);\n\n#endif\n\n        }\n\n    }\n\n\n\n    if (!*fmt) {\n\n        av_free(buf);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* rewind. reuse probe buffer to avoid seeking */\n\n    ret = ffio_rewind_with_probe_data(pb, &buf, pd.buf_size);\n\n\n\n    return ret < 0 ? ret : score;\n\n}\n", "idx": 10960, "_split": "valid", "_hash": "dfaa13a0c17de1c22c91dfc4256362cf"}
{"project": "FFmpeg", "commit_id": "dc6b99d6b20e832a7d353474c2d093f8b2fb17d2", "target": 0, "func": "static int mov_write_ms_tag(AVIOContext *pb, MOVTrack *track)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    avio_wb32(pb, 0);\n\n    avio_wl32(pb, track->tag); // store it byteswapped\n\n    track->enc->codec_tag = av_bswap16(track->tag >> 16);\n\n    ff_put_wav_header(pb, track->enc, 0);\n\n    return update_size(pb, pos);\n\n}\n", "idx": 11019, "_split": "valid", "_hash": "d44778cbaa97332074189fc725f22185"}
{"project": "FFmpeg", "commit_id": "d1f558b3628d3ab99fd93a98b5758ef1be45a5da", "target": 0, "func": "static int copy_to_pbr(DCAXllDecoder *s, uint8_t *data, int size, int delay)\n\n{\n\n    if (size > DCA_XLL_PBR_BUFFER_MAX)\n\n        return AVERROR(ENOSPC);\n\n\n\n    if (!s->pbr_buffer && !(s->pbr_buffer = av_malloc(DCA_XLL_PBR_BUFFER_MAX + DCA_BUFFER_PADDING_SIZE)))\n\n        return AVERROR(ENOMEM);\n\n\n\n    memcpy(s->pbr_buffer, data, size);\n\n    s->pbr_length = size;\n\n    s->pbr_delay = delay;\n\n    return 0;\n\n}\n", "idx": 11023, "_split": "valid", "_hash": "b74204fc6846818a85b5ca121f2c4ae1"}
{"project": "FFmpeg", "commit_id": "89523beea45e265d985aace8be79b45e94f21e6b", "target": 0, "func": "static void sigill_handler (int sig)\n\n{\n\n    if (!canjump) {\n\n        signal (sig, SIG_DFL);\n\n        raise (sig);\n\n    }\n\n\n\n    canjump = 0;\n\n    siglongjmp (jmpbuf, 1);\n\n}\n", "idx": 11027, "_split": "valid", "_hash": "63ada7ef9ade2add79c881fdcf8a2e51"}
{"project": "FFmpeg", "commit_id": "350ed1829268d343b791208c8fd1cddd44d52a8e", "target": 0, "func": "static int hevc_handle_packet(AVFormatContext *ctx, PayloadContext *rtp_hevc_ctx,\n\n                              AVStream *st, AVPacket *pkt, uint32_t *timestamp,\n\n                              const uint8_t *buf, int len, uint16_t seq,\n\n                              int flags)\n\n{\n\n    const uint8_t *rtp_pl = buf;\n\n    int tid, lid, nal_type;\n\n    int first_fragment, last_fragment, fu_type;\n\n    uint8_t new_nal_header[2];\n\n    int res = 0;\n\n\n\n    /* sanity check for size of input packet: 1 byte payload at least */\n\n    if (len < RTP_HEVC_PAYLOAD_HEADER_SIZE + 1) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Too short RTP/HEVC packet, got %d bytes\\n\", len);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /*\n\n      decode the HEVC payload header according to section 4 of draft version 6:\n\n\n\n         0                   1\n\n         0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\n\n        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n        |F|   Type    |  LayerId  | TID |\n\n        +-------------+-----------------+\n\n\n\n           Forbidden zero (F): 1 bit\n\n           NAL unit type (Type): 6 bits\n\n           NUH layer ID (LayerId): 6 bits\n\n           NUH temporal ID plus 1 (TID): 3 bits\n\n    */\n\n    nal_type =  (buf[0] >> 1) & 0x3f;\n\n    lid  = ((buf[0] << 5) & 0x20) | ((buf[1] >> 3) & 0x1f);\n\n    tid  =   buf[1] & 0x07;\n\n\n\n    /* sanity check for correct layer ID */\n\n    if (lid) {\n\n        /* future scalable or 3D video coding extensions */\n\n        avpriv_report_missing_feature(ctx, \"Multi-layer HEVC coding\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    /* sanity check for correct temporal ID */\n\n    if (!tid) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Illegal temporal ID in RTP/HEVC packet\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* sanity check for correct NAL unit type */\n\n    if (nal_type > 50) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Unsupported (HEVC) NAL type (%d)\\n\", nal_type);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (nal_type) {\n\n    /* aggregated packets (AP) */\n\n    case 48:\n\n        /* pass the HEVC payload header */\n\n        buf += RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n        len -= RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n\n\n        /* pass the HEVC DONL field */\n\n        if (rtp_hevc_ctx->using_donl_field) {\n\n            buf += RTP_HEVC_DONL_FIELD_SIZE;\n\n            len -= RTP_HEVC_DONL_FIELD_SIZE;\n\n        }\n\n\n\n        /* fall-through */\n\n    /* video parameter set (VPS) */\n\n    case 32:\n\n    /* sequence parameter set (SPS) */\n\n    case 33:\n\n    /* picture parameter set (PPS) */\n\n    case 34:\n\n    /*  supplemental enhancement information (SEI) */\n\n    case 39:\n\n    /* single NAL unit packet */\n\n    default:\n\n        /* sanity check for size of input packet: 1 byte payload at least */\n\n        if (len < 1) {\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Too short RTP/HEVC packet, got %d bytes of NAL unit type %d\\n\",\n\n                   len, nal_type);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        /* create A/V packet */\n\n        if ((res = av_new_packet(pkt, sizeof(start_sequence) + len)) < 0)\n\n            return res;\n\n        /* A/V packet: copy start sequence */\n\n        memcpy(pkt->data, start_sequence, sizeof(start_sequence));\n\n        /* A/V packet: copy NAL unit data */\n\n        memcpy(pkt->data + sizeof(start_sequence), buf, len);\n\n\n\n        break;\n\n    /* fragmentation unit (FU) */\n\n    case 49:\n\n        /* pass the HEVC payload header */\n\n        buf += RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n        len -= RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n\n\n        if (len < 1)\n\n            return AVERROR_INVALIDDATA;\n\n        /*\n\n             decode the FU header\n\n\n\n              0 1 2 3 4 5 6 7\n\n             +-+-+-+-+-+-+-+-+\n\n             |S|E|  FuType   |\n\n             +---------------+\n\n\n\n                Start fragment (S): 1 bit\n\n                End fragment (E): 1 bit\n\n                FuType: 6 bits\n\n        */\n\n        first_fragment = buf[0] & 0x80;\n\n        last_fragment  = buf[0] & 0x40;\n\n        fu_type        = buf[0] & 0x3f;\n\n\n\n        /* pass the HEVC FU header */\n\n        buf += RTP_HEVC_FU_HEADER_SIZE;\n\n        len -= RTP_HEVC_FU_HEADER_SIZE;\n\n\n\n        /* pass the HEVC DONL field */\n\n        if (rtp_hevc_ctx->using_donl_field) {\n\n            buf += RTP_HEVC_DONL_FIELD_SIZE;\n\n            len -= RTP_HEVC_DONL_FIELD_SIZE;\n\n        }\n\n\n\n        av_dlog(ctx, \" FU type %d with %d bytes\\n\", fu_type, len);\n\n\n\n        if (len > 0) {\n\n            new_nal_header[0] = (rtp_pl[0] & 0x81) | (fu_type << 1);\n\n            new_nal_header[1] = rtp_pl[1];\n\n\n\n            /* start fragment vs. subsequent fragments */\n\n            if (first_fragment) {\n\n                if (!last_fragment) {\n\n                    /* create A/V packet which is big enough */\n\n                    if ((res = av_new_packet(pkt, sizeof(start_sequence) + sizeof(new_nal_header) + len)) < 0)\n\n                        return res;\n\n                    /* A/V packet: copy start sequence */\n\n                    memcpy(pkt->data, start_sequence, sizeof(start_sequence));\n\n                    /* A/V packet: copy new NAL header */\n\n                    memcpy(pkt->data + sizeof(start_sequence), new_nal_header, sizeof(new_nal_header));\n\n                    /* A/V packet: copy NAL unit data */\n\n                    memcpy(pkt->data + sizeof(start_sequence) + sizeof(new_nal_header), buf, len);\n\n                } else {\n\n                    av_log(ctx, AV_LOG_ERROR, \"Illegal combination of S and E bit in RTP/HEVC packet\\n\");\n\n                    res = AVERROR_INVALIDDATA;\n\n                }\n\n            } else {\n\n                /* create A/V packet */\n\n                if ((res = av_new_packet(pkt, len)) < 0)\n\n                    return res;\n\n                /* A/V packet: copy NAL unit data */\n\n                memcpy(pkt->data, buf, len);\n\n            }\n\n        } else {\n\n            /* sanity check for size of input packet: 1 byte payload at least */\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Too short RTP/HEVC packet, got %d bytes of NAL unit type %d\\n\",\n\n                   len, nal_type);\n\n            res = AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        break;\n\n    /* PACI packet */\n\n    case 50:\n\n        /* Temporal scalability control information (TSCI) */\n\n        avpriv_report_missing_feature(ctx, \"PACI packets for RTP/HEVC\\n\");\n\n        res = AVERROR_PATCHWELCOME;\n\n        break;\n\n    }\n\n\n\n    pkt->stream_index = st->index;\n\n\n\n    return res;\n\n}\n", "idx": 11066, "_split": "valid", "_hash": "5ef83049a1c4372e5214133bbcf52e23"}
{"project": "FFmpeg", "commit_id": "0a60f83075883f5d73c7f7f20d00ad31897178c2", "target": 0, "func": "static int process_line(URLContext *h, char *line, int line_count,\n\n                        int *new_location)\n\n{\n\n    HTTPContext *s = h->priv_data;\n\n    char *tag, *p, *end;\n\n\n\n    /* end of header */\n\n    if (line[0] == '\\0') {\n\n        s->end_header = 1;\n\n        return 0;\n\n    }\n\n\n\n    p = line;\n\n    if (line_count == 0) {\n\n        while (!isspace(*p) && *p != '\\0')\n\n            p++;\n\n        while (isspace(*p))\n\n            p++;\n\n        s->http_code = strtol(p, &end, 10);\n\n\n\n        av_dlog(NULL, \"http_code=%d\\n\", s->http_code);\n\n\n\n        /* error codes are 4xx and 5xx, but regard 401 as a success, so we\n\n         * don't abort until all headers have been parsed. */\n\n        if (s->http_code >= 400 && s->http_code < 600 && (s->http_code != 401\n\n            || s->auth_state.auth_type != HTTP_AUTH_NONE) &&\n\n            (s->http_code != 407 || s->proxy_auth_state.auth_type != HTTP_AUTH_NONE)) {\n\n            end += strspn(end, SPACE_CHARS);\n\n            av_log(h, AV_LOG_WARNING, \"HTTP error %d %s\\n\",\n\n                   s->http_code, end);\n\n            return -1;\n\n        }\n\n    } else {\n\n        while (*p != '\\0' && *p != ':')\n\n            p++;\n\n        if (*p != ':')\n\n            return 1;\n\n\n\n        *p = '\\0';\n\n        tag = line;\n\n        p++;\n\n        while (isspace(*p))\n\n            p++;\n\n        if (!av_strcasecmp(tag, \"Location\")) {\n\n            av_strlcpy(s->location, p, sizeof(s->location));\n\n            *new_location = 1;\n\n        } else if (!av_strcasecmp (tag, \"Content-Length\") && s->filesize == -1) {\n\n            s->filesize = strtoll(p, NULL, 10);\n\n        } else if (!av_strcasecmp (tag, \"Content-Range\")) {\n\n            /* \"bytes $from-$to/$document_size\" */\n\n            const char *slash;\n\n            if (!strncmp (p, \"bytes \", 6)) {\n\n                p += 6;\n\n                s->off = strtoll(p, NULL, 10);\n\n                if ((slash = strchr(p, '/')) && strlen(slash) > 0)\n\n                    s->filesize = strtoll(slash+1, NULL, 10);\n\n            }\n\n            if (s->seekable == -1 && (!s->is_akamai || s->filesize != 2147483647))\n\n                h->is_streamed = 0; /* we _can_ in fact seek */\n\n        } else if (!av_strcasecmp(tag, \"Accept-Ranges\") && !strncmp(p, \"bytes\", 5) && s->seekable == -1) {\n\n            h->is_streamed = 0;\n\n        } else if (!av_strcasecmp (tag, \"Transfer-Encoding\") && !av_strncasecmp(p, \"chunked\", 7)) {\n\n            s->filesize = -1;\n\n            s->chunksize = 0;\n\n        } else if (!av_strcasecmp (tag, \"WWW-Authenticate\")) {\n\n            ff_http_auth_handle_header(&s->auth_state, tag, p);\n\n        } else if (!av_strcasecmp (tag, \"Authentication-Info\")) {\n\n            ff_http_auth_handle_header(&s->auth_state, tag, p);\n\n        } else if (!av_strcasecmp (tag, \"Proxy-Authenticate\")) {\n\n            ff_http_auth_handle_header(&s->proxy_auth_state, tag, p);\n\n        } else if (!av_strcasecmp (tag, \"Connection\")) {\n\n            if (!strcmp(p, \"close\"))\n\n                s->willclose = 1;\n\n        } else if (!av_strcasecmp (tag, \"Server\") && !av_strcasecmp (p, \"AkamaiGHost\")) {\n\n            s->is_akamai = 1;\n\n        } else if (!av_strcasecmp (tag, \"Content-Type\") && p) {\n\n            av_free(s->mime_type); s->mime_type = av_strdup(p);\n\n        }\n\n    }\n\n    return 1;\n\n}\n", "idx": 11087, "_split": "valid", "_hash": "0cfc373496286afd2570ed13fcbcf092"}
{"project": "FFmpeg", "commit_id": "c33030bd7b81f7ef7d7ff9da9bfa1a3b4bfbafa1", "target": 0, "func": "static int gif_encode_frame(AVCodecContext *avctx, unsigned char *outbuf, int buf_size, void *data)\n\n{\n\n    GIFContext *s = avctx->priv_data;\n\n    AVFrame *pict = data;\n\n    AVFrame *const p = (AVFrame *)&s->picture;\n\n    uint8_t *outbuf_ptr = outbuf;\n\n\n\n    *p = *pict;\n\n    p->pict_type = FF_I_TYPE;\n\n    p->key_frame = 1;\n\n    gif_image_write_header(&outbuf_ptr, avctx->width, avctx->height, -1, (uint32_t *)pict->data[1]);\n\n    gif_image_write_image(&outbuf_ptr, 0, 0, avctx->width, avctx->height, pict->data[0], pict->linesize[0], PIX_FMT_PAL8);\n\n    return outbuf_ptr - outbuf;\n\n}\n", "idx": 11151, "_split": "valid", "_hash": "90f668812916cc95aacc5b623dbdd4e3"}
{"project": "FFmpeg", "commit_id": "b76d853697a8b558e597ed4a6fc5a088b6c602c7", "target": 0, "func": "av_cold int avcodec_close(AVCodecContext *avctx)\n\n{\n\n    int ret = ff_lock_avcodec(avctx);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (avcodec_is_open(avctx)) {\n\n        FramePool *pool = avctx->internal->pool;\n\n        int i;\n\n        if (HAVE_THREADS && avctx->internal->frame_thread_encoder && avctx->thread_count > 1) {\n\n            ff_unlock_avcodec();\n\n            ff_frame_thread_encoder_free(avctx);\n\n            ff_lock_avcodec(avctx);\n\n        }\n\n        if (HAVE_THREADS && avctx->thread_opaque)\n\n            ff_thread_free(avctx);\n\n        if (avctx->codec && avctx->codec->close)\n\n            avctx->codec->close(avctx);\n\n        avctx->coded_frame = NULL;\n\n        avctx->internal->byte_buffer_size = 0;\n\n        av_freep(&avctx->internal->byte_buffer);\n\n        if (!avctx->refcounted_frames)\n\n            av_frame_unref(&avctx->internal->to_free);\n\n        for (i = 0; i < FF_ARRAY_ELEMS(pool->pools); i++)\n\n            av_buffer_pool_uninit(&pool->pools[i]);\n\n        av_freep(&avctx->internal->pool);\n\n        av_freep(&avctx->internal);\n\n    }\n\n\n\n    if (avctx->priv_data && avctx->codec && avctx->codec->priv_class)\n\n        av_opt_free(avctx->priv_data);\n\n    av_opt_free(avctx);\n\n    av_freep(&avctx->priv_data);\n\n    if (av_codec_is_encoder(avctx->codec))\n\n        av_freep(&avctx->extradata);\n\n    avctx->codec = NULL;\n\n    avctx->active_thread_type = 0;\n\n\n\n    ff_unlock_avcodec();\n\n    return 0;\n\n}\n", "idx": 11158, "_split": "valid", "_hash": "dacda1d4a87d50c638578bad2ca3ffaf"}
{"project": "FFmpeg", "commit_id": "c2fa6bb0e8703a7a6aa10e11f9ab36094416d83f", "target": 1, "func": "static void mpeg_decode_picture_coding_extension(Mpeg1Context *s1)\n\n{\n\n    MpegEncContext *s = &s1->mpeg_enc_ctx;\n\n\n\n    s->full_pel[0]       = s->full_pel[1] = 0;\n\n    s->mpeg_f_code[0][0] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[0][1] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[1][0] = get_bits(&s->gb, 4);\n\n    s->mpeg_f_code[1][1] = get_bits(&s->gb, 4);\n\n    if (!s->pict_type && s1->mpeg_enc_ctx_allocated) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Missing picture start code, guessing missing values\\n\");\n\n        if (s->mpeg_f_code[1][0] == 15 && s->mpeg_f_code[1][1] == 15) {\n\n            if (s->mpeg_f_code[0][0] == 15 && s->mpeg_f_code[0][1] == 15)\n\n                s->pict_type = AV_PICTURE_TYPE_I;\n\n            else\n\n                s->pict_type = AV_PICTURE_TYPE_P;\n\n        } else\n\n            s->pict_type = AV_PICTURE_TYPE_B;\n\n        s->current_picture.f->pict_type = s->pict_type;\n\n        s->current_picture.f->key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n    }\n\n    s->intra_dc_precision         = get_bits(&s->gb, 2);\n\n    s->picture_structure          = get_bits(&s->gb, 2);\n\n    s->top_field_first            = get_bits1(&s->gb);\n\n    s->frame_pred_frame_dct       = get_bits1(&s->gb);\n\n    s->concealment_motion_vectors = get_bits1(&s->gb);\n\n    s->q_scale_type               = get_bits1(&s->gb);\n\n    s->intra_vlc_format           = get_bits1(&s->gb);\n\n    s->alternate_scan             = get_bits1(&s->gb);\n\n    s->repeat_first_field         = get_bits1(&s->gb);\n\n    s->chroma_420_type            = get_bits1(&s->gb);\n\n    s->progressive_frame          = get_bits1(&s->gb);\n\n\n\n    if (s->progressive_sequence && !s->progressive_frame) {\n\n        s->progressive_frame = 1;\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"interlaced frame in progressive sequence, ignoring\\n\");\n\n    }\n\n\n\n    if (s->picture_structure == 0 ||\n\n        (s->progressive_frame && s->picture_structure != PICT_FRAME)) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"picture_structure %d invalid, ignoring\\n\",\n\n               s->picture_structure);\n\n        s->picture_structure = PICT_FRAME;\n\n    }\n\n\n\n    if (s->progressive_sequence && !s->frame_pred_frame_dct)\n\n        av_log(s->avctx, AV_LOG_WARNING, \"invalid frame_pred_frame_dct\\n\");\n\n\n\n    if (s->picture_structure == PICT_FRAME) {\n\n        s->first_field = 0;\n\n        s->v_edge_pos  = 16 * s->mb_height;\n\n    } else {\n\n        s->first_field ^= 1;\n\n        s->v_edge_pos   = 8 * s->mb_height;\n\n        memset(s->mbskip_table, 0, s->mb_stride * s->mb_height);\n\n    }\n\n\n\n    if (s->alternate_scan) {\n\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable, ff_alternate_vertical_scan);\n\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable, ff_alternate_vertical_scan);\n\n    } else {\n\n        ff_init_scantable(s->idsp.idct_permutation, &s->inter_scantable, ff_zigzag_direct);\n\n        ff_init_scantable(s->idsp.idct_permutation, &s->intra_scantable, ff_zigzag_direct);\n\n    }\n\n\n\n    /* composite display not parsed */\n\n    ff_dlog(s->avctx, \"intra_dc_precision=%d\\n\", s->intra_dc_precision);\n\n    ff_dlog(s->avctx, \"picture_structure=%d\\n\", s->picture_structure);\n\n    ff_dlog(s->avctx, \"top field first=%d\\n\", s->top_field_first);\n\n    ff_dlog(s->avctx, \"repeat first field=%d\\n\", s->repeat_first_field);\n\n    ff_dlog(s->avctx, \"conceal=%d\\n\", s->concealment_motion_vectors);\n\n    ff_dlog(s->avctx, \"intra_vlc_format=%d\\n\", s->intra_vlc_format);\n\n    ff_dlog(s->avctx, \"alternate_scan=%d\\n\", s->alternate_scan);\n\n    ff_dlog(s->avctx, \"frame_pred_frame_dct=%d\\n\", s->frame_pred_frame_dct);\n\n    ff_dlog(s->avctx, \"progressive_frame=%d\\n\", s->progressive_frame);\n\n}\n", "idx": 11194, "_split": "valid", "_hash": "855ae3ce23c98d4ed0d79ec6b861b7cc"}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "static av_always_inline void mc_dir_part(H264Context *h, Picture *pic,\n\n                                         int n, int square, int height,\n\n                                         int delta, int list,\n\n                                         uint8_t *dest_y, uint8_t *dest_cb,\n\n                                         uint8_t *dest_cr,\n\n                                         int src_x_offset, int src_y_offset,\n\n                                         qpel_mc_func *qpix_op,\n\n                                         h264_chroma_mc_func chroma_op,\n\n                                         int pixel_shift, int chroma_idc)\n\n{\n\n    const int mx      = h->mv_cache[list][scan8[n]][0] + src_x_offset * 8;\n\n    int my            = h->mv_cache[list][scan8[n]][1] + src_y_offset * 8;\n\n    const int luma_xy = (mx & 3) + ((my & 3) << 2);\n\n    int offset        = ((mx >> 2) << pixel_shift) + (my >> 2) * h->mb_linesize;\n\n    uint8_t *src_y    = pic->f.data[0] + offset;\n\n    uint8_t *src_cb, *src_cr;\n\n    int extra_width  = 0;\n\n    int extra_height = 0;\n\n    int emu = 0;\n\n    const int full_mx    = mx >> 2;\n\n    const int full_my    = my >> 2;\n\n    const int pic_width  = 16 * h->mb_width;\n\n    const int pic_height = 16 * h->mb_height >> MB_FIELD(h);\n\n    int ysh;\n\n\n\n    if (mx & 7)\n\n        extra_width -= 3;\n\n    if (my & 7)\n\n        extra_height -= 3;\n\n\n\n    if (full_mx                <          0 - extra_width  ||\n\n        full_my                <          0 - extra_height ||\n\n        full_mx + 16 /*FIXME*/ > pic_width  + extra_width  ||\n\n        full_my + 16 /*FIXME*/ > pic_height + extra_height) {\n\n        h->vdsp.emulated_edge_mc(h->edge_emu_buffer,\n\n                                 src_y - (2 << pixel_shift) - 2 * h->mb_linesize,\n\n                                 h->mb_linesize,\n\n                                 16 + 5, 16 + 5 /*FIXME*/, full_mx - 2,\n\n                                 full_my - 2, pic_width, pic_height);\n\n        src_y = h->edge_emu_buffer + (2 << pixel_shift) + 2 * h->mb_linesize;\n\n        emu   = 1;\n\n    }\n\n\n\n    qpix_op[luma_xy](dest_y, src_y, h->mb_linesize); // FIXME try variable height perhaps?\n\n    if (!square)\n\n        qpix_op[luma_xy](dest_y + delta, src_y + delta, h->mb_linesize);\n\n\n\n    if (CONFIG_GRAY && h->flags & CODEC_FLAG_GRAY)\n\n        return;\n\n\n\n    if (chroma_idc == 3 /* yuv444 */) {\n\n        src_cb = pic->f.data[1] + offset;\n\n        if (emu) {\n\n            h->vdsp.emulated_edge_mc(h->edge_emu_buffer,\n\n                                     src_cb - (2 << pixel_shift) - 2 * h->mb_linesize,\n\n                                     h->mb_linesize,\n\n                                     16 + 5, 16 + 5 /*FIXME*/,\n\n                                     full_mx - 2, full_my - 2,\n\n                                     pic_width, pic_height);\n\n            src_cb = h->edge_emu_buffer + (2 << pixel_shift) + 2 * h->mb_linesize;\n\n        }\n\n        qpix_op[luma_xy](dest_cb, src_cb, h->mb_linesize); // FIXME try variable height perhaps?\n\n        if (!square)\n\n            qpix_op[luma_xy](dest_cb + delta, src_cb + delta, h->mb_linesize);\n\n\n\n        src_cr = pic->f.data[2] + offset;\n\n        if (emu) {\n\n            h->vdsp.emulated_edge_mc(h->edge_emu_buffer,\n\n                                     src_cr - (2 << pixel_shift) - 2 * h->mb_linesize,\n\n                                     h->mb_linesize,\n\n                                     16 + 5, 16 + 5 /*FIXME*/,\n\n                                     full_mx - 2, full_my - 2,\n\n                                     pic_width, pic_height);\n\n            src_cr = h->edge_emu_buffer + (2 << pixel_shift) + 2 * h->mb_linesize;\n\n        }\n\n        qpix_op[luma_xy](dest_cr, src_cr, h->mb_linesize); // FIXME try variable height perhaps?\n\n        if (!square)\n\n            qpix_op[luma_xy](dest_cr + delta, src_cr + delta, h->mb_linesize);\n\n        return;\n\n    }\n\n\n\n    ysh = 3 - (chroma_idc == 2 /* yuv422 */);\n\n    if (chroma_idc == 1 /* yuv420 */ && MB_FIELD(h)) {\n\n        // chroma offset when predicting from a field of opposite parity\n\n        my  += 2 * ((h->mb_y & 1) - (pic->reference - 1));\n\n        emu |= (my >> 3) < 0 || (my >> 3) + 8 >= (pic_height >> 1);\n\n    }\n\n\n\n    src_cb = pic->f.data[1] + ((mx >> 3) << pixel_shift) +\n\n             (my >> ysh) * h->mb_uvlinesize;\n\n    src_cr = pic->f.data[2] + ((mx >> 3) << pixel_shift) +\n\n             (my >> ysh) * h->mb_uvlinesize;\n\n\n\n    if (emu) {\n\n        h->vdsp.emulated_edge_mc(h->edge_emu_buffer, src_cb, h->mb_uvlinesize,\n\n                                 9, 8 * chroma_idc + 1, (mx >> 3), (my >> ysh),\n\n                                 pic_width >> 1, pic_height >> (chroma_idc == 1 /* yuv420 */));\n\n        src_cb = h->edge_emu_buffer;\n\n    }\n\n    chroma_op(dest_cb, src_cb, h->mb_uvlinesize,\n\n              height >> (chroma_idc == 1 /* yuv420 */),\n\n              mx & 7, (my << (chroma_idc == 2 /* yuv422 */)) & 7);\n\n\n\n    if (emu) {\n\n        h->vdsp.emulated_edge_mc(h->edge_emu_buffer, src_cr, h->mb_uvlinesize,\n\n                                 9, 8 * chroma_idc + 1, (mx >> 3), (my >> ysh),\n\n                                 pic_width >> 1, pic_height >> (chroma_idc == 1 /* yuv420 */));\n\n        src_cr = h->edge_emu_buffer;\n\n    }\n\n    chroma_op(dest_cr, src_cr, h->mb_uvlinesize, height >> (chroma_idc == 1 /* yuv420 */),\n\n              mx & 7, (my << (chroma_idc == 2 /* yuv422 */)) & 7);\n\n}\n", "idx": 11197, "_split": "valid", "_hash": "487b2c6ea732518ab322997d113d26f2"}
{"project": "FFmpeg", "commit_id": "8dd0a2c5cf40a8a49faae985adc11750b6429132", "target": 1, "func": "static int av_cold libopus_encode_init(AVCodecContext *avctx)\n\n{\n\n    LibopusEncContext *opus = avctx->priv_data;\n\n    const uint8_t *channel_mapping;\n\n    OpusMSEncoder *enc;\n\n    int ret = OPUS_OK;\n\n    int coupled_stream_count, header_size, frame_size;\n\n\n\n    coupled_stream_count = opus_coupled_streams[avctx->channels - 1];\n\n    opus->stream_count   = avctx->channels - coupled_stream_count;\n\n    channel_mapping      = libav_libopus_channel_map[avctx->channels - 1];\n\n\n\n    /* FIXME: Opus can handle up to 255 channels. However, the mapping for\n\n     * anything greater than 8 is undefined. */\n\n    if (avctx->channels > 8)\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Channel layout undefined for %d channels.\\n\", avctx->channels);\n\n\n\n    if (!avctx->bit_rate) {\n\n        /* Sane default copied from opusenc */\n\n        avctx->bit_rate = 64000 * opus->stream_count +\n\n                          32000 * coupled_stream_count;\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"No bit rate set. Defaulting to %d bps.\\n\", avctx->bit_rate);\n\n    }\n\n\n\n    if (avctx->bit_rate < 500 || avctx->bit_rate > 256000 * avctx->channels) {\n\n        av_log(avctx, AV_LOG_ERROR, \"The bit rate %d bps is unsupported. \"\n\n               \"Please choose a value between 500 and %d.\\n\", avctx->bit_rate,\n\n               256000 * avctx->channels);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    frame_size = opus->opts.frame_duration * 48000 / 1000;\n\n    switch (frame_size) {\n\n    case 120:\n\n    case 240:\n\n        if (opus->opts.application != OPUS_APPLICATION_RESTRICTED_LOWDELAY)\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"LPC mode cannot be used with a frame duration of less \"\n\n                   \"than 10ms. Enabling restricted low-delay mode.\\n\"\n\n                   \"Use a longer frame duration if this is not what you want.\\n\");\n\n        /* Frame sizes less than 10 ms can only use MDCT mode, so switching to\n\n         * RESTRICTED_LOWDELAY avoids an unnecessary extra 2.5ms lookahead. */\n\n        opus->opts.application = OPUS_APPLICATION_RESTRICTED_LOWDELAY;\n\n    case 480:\n\n    case 960:\n\n    case 1920:\n\n    case 2880:\n\n        opus->opts.packet_size =\n\n        avctx->frame_size      = frame_size * avctx->sample_rate / 48000;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid frame duration: %g.\\n\"\n\n               \"Frame duration must be exactly one of: 2.5, 5, 10, 20, 40 or 60.\\n\",\n\n               opus->opts.frame_duration);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (avctx->compression_level < 0 || avctx->compression_level > 10) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Compression level must be in the range 0 to 10. \"\n\n               \"Defaulting to 10.\\n\");\n\n        opus->opts.complexity = 10;\n\n    } else {\n\n        opus->opts.complexity = avctx->compression_level;\n\n    }\n\n\n\n    if (avctx->cutoff) {\n\n        switch (avctx->cutoff) {\n\n        case  4000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_NARROWBAND;\n\n            break;\n\n        case  6000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_MEDIUMBAND;\n\n            break;\n\n        case  8000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_WIDEBAND;\n\n            break;\n\n        case 12000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_SUPERWIDEBAND;\n\n            break;\n\n        case 20000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_FULLBAND;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"Invalid frequency cutoff: %d. Using default maximum bandwidth.\\n\"\n\n                   \"Cutoff frequency must be exactly one of: 4000, 6000, 8000, 12000 or 20000.\\n\",\n\n                   avctx->cutoff);\n\n            avctx->cutoff = 0;\n\n        }\n\n    }\n\n\n\n    enc = opus_multistream_encoder_create(avctx->sample_rate, avctx->channels,\n\n                                          opus->stream_count,\n\n                                          coupled_stream_count,\n\n                                          channel_mapping,\n\n                                          opus->opts.application, &ret);\n\n    if (ret != OPUS_OK) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Failed to create encoder: %s\\n\", opus_strerror(ret));\n\n        return ff_opus_error_to_averror(ret);\n\n    }\n\n\n\n    ret = libopus_configure_encoder(avctx, enc, &opus->opts);\n\n    if (ret != OPUS_OK) {\n\n        ret = ff_opus_error_to_averror(ret);\n\n        goto fail;\n\n    }\n\n\n\n    header_size = 19 + (avctx->channels > 2 ? 2 + avctx->channels : 0);\n\n    avctx->extradata = av_malloc(header_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!avctx->extradata) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to allocate extradata.\\n\");\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    avctx->extradata_size = header_size;\n\n\n\n    opus->samples = av_mallocz(frame_size * avctx->channels *\n\n                               av_get_bytes_per_sample(avctx->sample_fmt));\n\n    if (!opus->samples) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to allocate samples buffer.\\n\");\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    ret = opus_multistream_encoder_ctl(enc, OPUS_GET_LOOKAHEAD(&avctx->initial_padding));\n\n    if (ret != OPUS_OK)\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Unable to get number of lookahead samples: %s\\n\",\n\n               opus_strerror(ret));\n\n\n\n    libopus_write_header(avctx, opus->stream_count, coupled_stream_count,\n\n                         opus_vorbis_channel_map[avctx->channels - 1]);\n\n\n\n    ff_af_queue_init(avctx, &opus->afq);\n\n\n\n    opus->enc = enc;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    opus_multistream_encoder_destroy(enc);\n\n    av_freep(&avctx->extradata);\n\n    return ret;\n\n}\n", "idx": 11241, "_split": "valid", "_hash": "9755c9d622096c07b94343010df75ccd"}
{"project": "FFmpeg", "commit_id": "4a722a5cab15d5aefbf4dd83baa8be5a046580ca", "target": 1, "func": "static int common_end(HYuvContext *s)\n\n{\n\n    int i;\n\n\n\n    for(i = 0; i < 3; i++) {\n\n        av_freep(&s->temp[i]);\n\n    }\n\n    return 0;\n\n}\n", "idx": 11248, "_split": "valid", "_hash": "ca6e047b1c9738ca9d48f45e6090f0ea"}
{"project": "FFmpeg", "commit_id": "c619ff6daf93a8f3c03decf2d3345d2474c3db91", "target": 0, "func": "static always_inline int dv_rl2vlc(int run, int l, uint32_t* vlc)\n\n{\n\n    *vlc = dv_vlc_map[run][((uint16_t)l)&0x1ff].vlc;\n\n    return dv_vlc_map[run][((uint16_t)l)&0x1ff].size;\n\n}\n", "idx": 11261, "_split": "valid", "_hash": "a1352fbef72389de55edb7c7ddbe43cd"}
{"project": "FFmpeg", "commit_id": "295a7c0238e84b0ffa8f21ed938d45f51f54a4cd", "target": 1, "func": "static int decode_i2_frame(FourXContext *f, const uint8_t *buf, int length){\n\n    int x, y, x2, y2;\n\n    const int width= f->avctx->width;\n\n    const int height= f->avctx->height;\n\n    uint16_t *dst= (uint16_t*)f->current_picture.data[0];\n\n    const int stride= f->current_picture.linesize[0]>>1;\n\n\n\n    for(y=0; y<height; y+=16){\n\n        for(x=0; x<width; x+=16){\n\n            unsigned int color[4], bits;\n\n            memset(color, 0, sizeof(color));\n\n//warning following is purely guessed ...\n\n            color[0]= bytestream_get_le16(&buf);\n\n            color[1]= bytestream_get_le16(&buf);\n\n\n\n            if(color[0]&0x8000) av_log(NULL, AV_LOG_ERROR, \"unk bit 1\\n\");\n\n            if(color[1]&0x8000) av_log(NULL, AV_LOG_ERROR, \"unk bit 2\\n\");\n\n\n\n            color[2]= mix(color[0], color[1]);\n\n            color[3]= mix(color[1], color[0]);\n\n\n\n            bits= bytestream_get_le32(&buf);\n\n            for(y2=0; y2<16; y2++){\n\n                for(x2=0; x2<16; x2++){\n\n                    int index= 2*(x2>>2) + 8*(y2>>2);\n\n                    dst[y2*stride+x2]= color[(bits>>index)&3];\n\n                }\n\n            }\n\n            dst+=16;\n\n        }\n\n        dst += 16 * stride - x;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 11293, "_split": "valid", "_hash": "6bce508eaf10acc8465753126885ecb4"}
{"project": "FFmpeg", "commit_id": "ad5807f8aa883bee5431186dc1f24c5435d722d3", "target": 1, "func": "static int apc_read_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n\n\n    avio_rl32(pb); /* CRYO */\n\n    avio_rl32(pb); /* _APC */\n\n    avio_rl32(pb); /* 1.20 */\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codecpar->codec_id = AV_CODEC_ID_ADPCM_IMA_APC;\n\n\n\n    avio_rl32(pb); /* number of samples */\n\n    st->codecpar->sample_rate = avio_rl32(pb);\n\n\n\n    /* initial predictor values for adpcm decoder */\n\n    if (ff_get_extradata(s, st->codecpar, pb, 2 * 4) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (avio_rl32(pb)) {\n\n        st->codecpar->channels       = 2;\n\n        st->codecpar->channel_layout = AV_CH_LAYOUT_STEREO;\n\n    } else {\n\n        st->codecpar->channels       = 1;\n\n        st->codecpar->channel_layout = AV_CH_LAYOUT_MONO;\n\n    }\n\n\n\n    st->codecpar->bits_per_coded_sample = 4;\n\n    st->codecpar->bit_rate = st->codecpar->bits_per_coded_sample * st->codecpar->channels\n\n                          * st->codecpar->sample_rate;\n\n    st->codecpar->block_align = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 11295, "_split": "valid", "_hash": "80ac111246f198d1bf44b63ac63262bf"}
{"project": "FFmpeg", "commit_id": "486f0b0cfc800cd38ec06635630539431d296774", "target": 1, "func": "void *ff_png_zalloc(void *opaque, unsigned int items, unsigned int size)\n\n{\n\n    if(items >= UINT_MAX / size)\n\n        return NULL;\n\n    return av_malloc(items * size);\n\n}\n", "idx": 11326, "_split": "valid", "_hash": "a48810722f8f987aee1eb8d355fabdcf"}
{"project": "FFmpeg", "commit_id": "53c05b1eacd5f7dbfa3651b45e797adaea0a5ff8", "target": 0, "func": "static inline void fill_caches(H264Context *h, int mb_type){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;\n\n    int topleft_xy, top_xy, topright_xy, left_xy[2];\n\n    int topleft_type, top_type, topright_type, left_type[2];\n\n    int left_block[4];\n\n    int i;\n\n\n\n    //wow what a mess, why didnt they simplify the interlacing&intra stuff, i cant imagine that these complex rules are worth it \n\n    \n\n    if(h->sps.mb_aff){\n\n    //FIXME\n\n        topleft_xy = 0; /* avoid warning */\n\n        top_xy = 0; /* avoid warning */\n\n        topright_xy = 0; /* avoid warning */\n\n    }else{\n\n        topleft_xy = mb_xy-1 - s->mb_stride;\n\n        top_xy     = mb_xy   - s->mb_stride;\n\n        topright_xy= mb_xy+1 - s->mb_stride;\n\n        left_xy[0]   = mb_xy-1;\n\n        left_xy[1]   = mb_xy-1;\n\n        left_block[0]= 0;\n\n        left_block[1]= 1;\n\n        left_block[2]= 2;\n\n        left_block[3]= 3;\n\n    }\n\n\n\n    topleft_type = h->slice_table[topleft_xy ] == h->slice_num ? s->current_picture.mb_type[topleft_xy] : 0;\n\n    top_type     = h->slice_table[top_xy     ] == h->slice_num ? s->current_picture.mb_type[top_xy]     : 0;\n\n    topright_type= h->slice_table[topright_xy] == h->slice_num ? s->current_picture.mb_type[topright_xy]: 0;\n\n    left_type[0] = h->slice_table[left_xy[0] ] == h->slice_num ? s->current_picture.mb_type[left_xy[0]] : 0;\n\n    left_type[1] = h->slice_table[left_xy[1] ] == h->slice_num ? s->current_picture.mb_type[left_xy[1]] : 0;\n\n\n\n    if(IS_INTRA(mb_type)){\n\n        h->topleft_samples_available= \n\n        h->top_samples_available= \n\n        h->left_samples_available= 0xFFFF;\n\n        h->topright_samples_available= 0xEEEA;\n\n\n\n        if(!IS_INTRA(top_type) && (top_type==0 || h->pps.constrained_intra_pred)){\n\n            h->topleft_samples_available= 0xB3FF;\n\n            h->top_samples_available= 0x33FF;\n\n            h->topright_samples_available= 0x26EA;\n\n        }\n\n        for(i=0; i<2; i++){\n\n            if(!IS_INTRA(left_type[i]) && (left_type[i]==0 || h->pps.constrained_intra_pred)){\n\n                h->topleft_samples_available&= 0xDF5F;\n\n                h->left_samples_available&= 0x5F5F;\n\n            }\n\n        }\n\n        \n\n        if(!IS_INTRA(topleft_type) && (topleft_type==0 || h->pps.constrained_intra_pred))\n\n            h->topleft_samples_available&= 0x7FFF;\n\n        \n\n        if(!IS_INTRA(topright_type) && (topright_type==0 || h->pps.constrained_intra_pred))\n\n            h->topright_samples_available&= 0xFBFF;\n\n    \n\n        if(IS_INTRA4x4(mb_type)){\n\n            if(IS_INTRA4x4(top_type)){\n\n                h->intra4x4_pred_mode_cache[4+8*0]= h->intra4x4_pred_mode[top_xy][4];\n\n                h->intra4x4_pred_mode_cache[5+8*0]= h->intra4x4_pred_mode[top_xy][5];\n\n                h->intra4x4_pred_mode_cache[6+8*0]= h->intra4x4_pred_mode[top_xy][6];\n\n                h->intra4x4_pred_mode_cache[7+8*0]= h->intra4x4_pred_mode[top_xy][3];\n\n            }else{\n\n                int pred;\n\n                if(IS_INTRA16x16(top_type) || (IS_INTER(top_type) && !h->pps.constrained_intra_pred))\n\n                    pred= 2;\n\n                else{\n\n                    pred= -1;\n\n                }\n\n                h->intra4x4_pred_mode_cache[4+8*0]=\n\n                h->intra4x4_pred_mode_cache[5+8*0]=\n\n                h->intra4x4_pred_mode_cache[6+8*0]=\n\n                h->intra4x4_pred_mode_cache[7+8*0]= pred;\n\n            }\n\n            for(i=0; i<2; i++){\n\n                if(IS_INTRA4x4(left_type[i])){\n\n                    h->intra4x4_pred_mode_cache[3+8*1 + 2*8*i]= h->intra4x4_pred_mode[left_xy[i]][left_block[0+2*i]];\n\n                    h->intra4x4_pred_mode_cache[3+8*2 + 2*8*i]= h->intra4x4_pred_mode[left_xy[i]][left_block[1+2*i]];\n\n                }else{\n\n                    int pred;\n\n                    if(IS_INTRA16x16(left_type[i]) || (IS_INTER(left_type[i]) && !h->pps.constrained_intra_pred))\n\n                        pred= 2;\n\n                    else{\n\n                        pred= -1;\n\n                    }\n\n                    h->intra4x4_pred_mode_cache[3+8*1 + 2*8*i]=\n\n                    h->intra4x4_pred_mode_cache[3+8*2 + 2*8*i]= pred;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    \n\n    \n\n/*\n\n0 . T T. T T T T \n\n1 L . .L . . . . \n\n2 L . .L . . . . \n\n3 . T TL . . . . \n\n4 L . .L . . . . \n\n5 L . .. . . . . \n\n*/\n\n//FIXME constraint_intra_pred & partitioning & nnz (lets hope this is just a typo in the spec)\n\n    if(top_type){\n\n        h->non_zero_count_cache[4+8*0]= h->non_zero_count[top_xy][10];\n\n        h->non_zero_count_cache[5+8*0]= h->non_zero_count[top_xy][11];\n\n        h->non_zero_count_cache[6+8*0]= h->non_zero_count[top_xy][14];\n\n        h->non_zero_count_cache[7+8*0]= h->non_zero_count[top_xy][15];\n\n    \n\n        h->non_zero_count_cache[1+8*0]= h->non_zero_count[top_xy][18];\n\n        h->non_zero_count_cache[2+8*0]= h->non_zero_count[top_xy][19];\n\n    \n\n        h->non_zero_count_cache[1+8*3]= h->non_zero_count[top_xy][22];\n\n        h->non_zero_count_cache[2+8*3]= h->non_zero_count[top_xy][23];\n\n    }else{\n\n        h->non_zero_count_cache[4+8*0]=      \n\n        h->non_zero_count_cache[5+8*0]=\n\n        h->non_zero_count_cache[6+8*0]=\n\n        h->non_zero_count_cache[7+8*0]=\n\n    \n\n        h->non_zero_count_cache[1+8*0]=\n\n        h->non_zero_count_cache[2+8*0]=\n\n    \n\n        h->non_zero_count_cache[1+8*3]=\n\n        h->non_zero_count_cache[2+8*3]= 64;\n\n    }\n\n    \n\n    if(left_type[0]){\n\n        h->non_zero_count_cache[3+8*1]= h->non_zero_count[left_xy[0]][5];\n\n        h->non_zero_count_cache[3+8*2]= h->non_zero_count[left_xy[0]][7];\n\n        h->non_zero_count_cache[0+8*1]= h->non_zero_count[left_xy[0]][17]; //FIXME left_block\n\n        h->non_zero_count_cache[0+8*4]= h->non_zero_count[left_xy[0]][21];\n\n    }else{\n\n        h->non_zero_count_cache[3+8*1]= \n\n        h->non_zero_count_cache[3+8*2]= \n\n        h->non_zero_count_cache[0+8*1]= \n\n        h->non_zero_count_cache[0+8*4]= 64;\n\n    }\n\n    \n\n    if(left_type[1]){\n\n        h->non_zero_count_cache[3+8*3]= h->non_zero_count[left_xy[1]][13];\n\n        h->non_zero_count_cache[3+8*4]= h->non_zero_count[left_xy[1]][15];\n\n        h->non_zero_count_cache[0+8*2]= h->non_zero_count[left_xy[1]][19];\n\n        h->non_zero_count_cache[0+8*5]= h->non_zero_count[left_xy[1]][23];\n\n    }else{\n\n        h->non_zero_count_cache[3+8*3]= \n\n        h->non_zero_count_cache[3+8*4]= \n\n        h->non_zero_count_cache[0+8*2]= \n\n        h->non_zero_count_cache[0+8*5]= 64;\n\n    }\n\n    \n\n#if 1\n\n    if(IS_INTER(mb_type)){\n\n        int list;\n\n        for(list=0; list<2; list++){\n\n            if((!IS_8X8(mb_type)) && !USES_LIST(mb_type, list)){\n\n                /*if(!h->mv_cache_clean[list]){\n\n                    memset(h->mv_cache [list],  0, 8*5*2*sizeof(int16_t)); //FIXME clean only input? clean at all?\n\n                    memset(h->ref_cache[list], PART_NOT_AVAILABLE, 8*5*sizeof(int8_t));\n\n                    h->mv_cache_clean[list]= 1;\n\n                }*/\n\n                continue; //FIXME direct mode ...\n\n            }\n\n            h->mv_cache_clean[list]= 0;\n\n            \n\n            if(IS_INTER(topleft_type)){\n\n                const int b_xy = h->mb2b_xy[topleft_xy] + 3 + 3*h->b_stride;\n\n                const int b8_xy= h->mb2b8_xy[topleft_xy] + 1 + h->b8_stride;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy];\n\n                h->ref_cache[list][scan8[0] - 1 - 1*8]= s->current_picture.ref_index[list][b8_xy];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 - 1*8]= 0;\n\n                h->ref_cache[list][scan8[0] - 1 - 1*8]= topleft_type ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n            \n\n            if(IS_INTER(top_type)){\n\n                const int b_xy= h->mb2b_xy[top_xy] + 3*h->b_stride;\n\n                const int b8_xy= h->mb2b8_xy[top_xy] + h->b8_stride;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 0 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 0];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 1 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 1];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 2 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 2];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 3 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + 3];\n\n                h->ref_cache[list][scan8[0] + 0 - 1*8]=\n\n                h->ref_cache[list][scan8[0] + 1 - 1*8]= s->current_picture.ref_index[list][b8_xy + 0];\n\n                h->ref_cache[list][scan8[0] + 2 - 1*8]=\n\n                h->ref_cache[list][scan8[0] + 3 - 1*8]= s->current_picture.ref_index[list][b8_xy + 1];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 0 - 1*8]= \n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 1 - 1*8]= \n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 2 - 1*8]= \n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 3 - 1*8]= 0;\n\n                *(uint32_t*)&h->ref_cache[list][scan8[0] + 0 - 1*8]= ((top_type ? LIST_NOT_USED : PART_NOT_AVAILABLE)&0xFF)*0x01010101;\n\n            }\n\n\n\n            if(IS_INTER(topright_type)){\n\n                const int b_xy= h->mb2b_xy[topright_xy] + 3*h->b_stride;\n\n                const int b8_xy= h->mb2b8_xy[topright_xy] + h->b8_stride;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] + 4 - 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy];\n\n                h->ref_cache[list][scan8[0] + 4 - 1*8]= s->current_picture.ref_index[list][b8_xy];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] + 4 - 1*8]= 0;\n\n                h->ref_cache[list][scan8[0] + 4 - 1*8]= topright_type ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n            \n\n            //FIXME unify cleanup or sth\n\n            if(IS_INTER(left_type[0])){\n\n                const int b_xy= h->mb2b_xy[left_xy[0]] + 3;\n\n                const int b8_xy= h->mb2b8_xy[left_xy[0]] + 1;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 0*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[0]];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 1*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[1]];\n\n                h->ref_cache[list][scan8[0] - 1 + 0*8]= \n\n                h->ref_cache[list][scan8[0] - 1 + 1*8]= s->current_picture.ref_index[list][b8_xy + h->b8_stride*(left_block[0]>>1)];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 0*8]=\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 1*8]= 0;\n\n                h->ref_cache[list][scan8[0] - 1 + 0*8]=\n\n                h->ref_cache[list][scan8[0] - 1 + 1*8]= left_type[0] ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n            \n\n            if(IS_INTER(left_type[1])){\n\n                const int b_xy= h->mb2b_xy[left_xy[1]] + 3;\n\n                const int b8_xy= h->mb2b8_xy[left_xy[1]] + 1;\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 2*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[2]];\n\n                *(uint32_t*)h->mv_cache[list][scan8[0] - 1 + 3*8]= *(uint32_t*)s->current_picture.motion_val[list][b_xy + h->b_stride*left_block[3]];\n\n                h->ref_cache[list][scan8[0] - 1 + 2*8]= \n\n                h->ref_cache[list][scan8[0] - 1 + 3*8]= s->current_picture.ref_index[list][b8_xy + h->b8_stride*(left_block[2]>>1)];\n\n            }else{\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 2*8]=\n\n                *(uint32_t*)h->mv_cache [list][scan8[0] - 1 + 3*8]= 0;\n\n                h->ref_cache[list][scan8[0] - 1 + 2*8]=\n\n                h->ref_cache[list][scan8[0] - 1 + 3*8]= left_type[0] ? LIST_NOT_USED : PART_NOT_AVAILABLE;\n\n            }\n\n\n\n            h->ref_cache[list][scan8[5 ]+1] = \n\n            h->ref_cache[list][scan8[7 ]+1] = \n\n            h->ref_cache[list][scan8[13]+1] =  //FIXME remove past 3 (init somewher else)\n\n            h->ref_cache[list][scan8[4 ]] = \n\n            h->ref_cache[list][scan8[12]] = PART_NOT_AVAILABLE;\n\n            *(uint32_t*)h->mv_cache [list][scan8[5 ]+1]=\n\n            *(uint32_t*)h->mv_cache [list][scan8[7 ]+1]=\n\n            *(uint32_t*)h->mv_cache [list][scan8[13]+1]= //FIXME remove past 3 (init somewher else)\n\n            *(uint32_t*)h->mv_cache [list][scan8[4 ]]=\n\n            *(uint32_t*)h->mv_cache [list][scan8[12]]= 0;\n\n        }\n\n//FIXME\n\n\n\n    }\n\n#endif\n\n}\n", "idx": 11354, "_split": "valid", "_hash": "18a85ef78edc5bde182ca40b5219ce59"}
{"project": "FFmpeg", "commit_id": "0422af7e49dbd3ac1d552edcd7972e266e0202a4", "target": 0, "func": "static void opt_input_file(const char *filename)\n\n{\n\n    AVFormatContext *ic;\n\n    AVFormatParameters params, *ap = &params;\n\n    AVInputFormat *file_iformat = NULL;\n\n    int err, i, ret, rfps, rfps_base;\n\n    int64_t timestamp;\n\n\n\n    if (last_asked_format) {\n\n        if (!(file_iformat = av_find_input_format(last_asked_format))) {\n\n            fprintf(stderr, \"Unknown input format: '%s'\\n\", last_asked_format);\n\n            ffmpeg_exit(1);\n\n        }\n\n        last_asked_format = NULL;\n\n    }\n\n\n\n    if (!strcmp(filename, \"-\"))\n\n        filename = \"pipe:\";\n\n\n\n    using_stdin |= !strncmp(filename, \"pipe:\", 5) ||\n\n                    !strcmp(filename, \"/dev/stdin\");\n\n\n\n    /* get default parameters from command line */\n\n    ic = avformat_alloc_context();\n\n    if (!ic) {\n\n        print_error(filename, AVERROR(ENOMEM));\n\n        ffmpeg_exit(1);\n\n    }\n\n\n\n    memset(ap, 0, sizeof(*ap));\n\n    ap->prealloced_context = 1;\n\n    ap->sample_rate = audio_sample_rate;\n\n    ap->channels = audio_channels;\n\n    ap->time_base.den = frame_rate.num;\n\n    ap->time_base.num = frame_rate.den;\n\n    ap->width = frame_width;\n\n    ap->height = frame_height;\n\n    ap->pix_fmt = frame_pix_fmt;\n\n   // ap->sample_fmt = audio_sample_fmt; //FIXME:not implemented in libavformat\n\n    ap->channel = video_channel;\n\n    ap->standard = video_standard;\n\n\n\n    set_context_opts(ic, avformat_opts, AV_OPT_FLAG_DECODING_PARAM, NULL);\n\n\n\n    ic->video_codec_id   =\n\n        find_codec_or_die(video_codec_name   , AVMEDIA_TYPE_VIDEO   , 0,\n\n                          avcodec_opts[AVMEDIA_TYPE_VIDEO   ]->strict_std_compliance);\n\n    ic->audio_codec_id   =\n\n        find_codec_or_die(audio_codec_name   , AVMEDIA_TYPE_AUDIO   , 0,\n\n                          avcodec_opts[AVMEDIA_TYPE_AUDIO   ]->strict_std_compliance);\n\n    ic->subtitle_codec_id=\n\n        find_codec_or_die(subtitle_codec_name, AVMEDIA_TYPE_SUBTITLE, 0,\n\n                          avcodec_opts[AVMEDIA_TYPE_SUBTITLE]->strict_std_compliance);\n\n    ic->flags |= AVFMT_FLAG_NONBLOCK;\n\n\n\n    if(pgmyuv_compatibility_hack)\n\n        ic->video_codec_id= CODEC_ID_PGMYUV;\n\n\n\n    /* open the input file with generic libav function */\n\n    err = av_open_input_file(&ic, filename, file_iformat, 0, ap);\n\n    if (err < 0) {\n\n        print_error(filename, err);\n\n        ffmpeg_exit(1);\n\n    }\n\n    if(opt_programid) {\n\n        int i, j;\n\n        int found=0;\n\n        for(i=0; i<ic->nb_streams; i++){\n\n            ic->streams[i]->discard= AVDISCARD_ALL;\n\n        }\n\n        for(i=0; i<ic->nb_programs; i++){\n\n            AVProgram *p= ic->programs[i];\n\n            if(p->id != opt_programid){\n\n                p->discard = AVDISCARD_ALL;\n\n            }else{\n\n                found=1;\n\n                for(j=0; j<p->nb_stream_indexes; j++){\n\n                    ic->streams[p->stream_index[j]]->discard= AVDISCARD_DEFAULT;\n\n                }\n\n            }\n\n        }\n\n        if(!found){\n\n            fprintf(stderr, \"Specified program id not found\\n\");\n\n            ffmpeg_exit(1);\n\n        }\n\n        opt_programid=0;\n\n    }\n\n\n\n    ic->loop_input = loop_input;\n\n\n\n    /* If not enough info to get the stream parameters, we decode the\n\n       first frames to get it. (used in mpeg case for example) */\n\n    ret = av_find_stream_info(ic);\n\n    if (ret < 0 && verbose >= 0) {\n\n        fprintf(stderr, \"%s: could not find codec parameters\\n\", filename);\n\n        av_close_input_file(ic);\n\n        ffmpeg_exit(1);\n\n    }\n\n\n\n    timestamp = start_time;\n\n    /* add the stream start time */\n\n    if (ic->start_time != AV_NOPTS_VALUE)\n\n        timestamp += ic->start_time;\n\n\n\n    /* if seeking requested, we execute it */\n\n    if (start_time != 0) {\n\n        ret = av_seek_frame(ic, -1, timestamp, AVSEEK_FLAG_BACKWARD);\n\n        if (ret < 0) {\n\n            fprintf(stderr, \"%s: could not seek to position %0.3f\\n\",\n\n                    filename, (double)timestamp / AV_TIME_BASE);\n\n        }\n\n        /* reset seek info */\n\n        start_time = 0;\n\n    }\n\n\n\n    /* update the current parameters so that they match the one of the input stream */\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        AVStream *st = ic->streams[i];\n\n        AVCodecContext *dec = st->codec;\n\n        avcodec_thread_init(dec, thread_count);\n\n        input_codecs = grow_array(input_codecs, sizeof(*input_codecs), &nb_input_codecs, nb_input_codecs + 1);\n\n        switch (dec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            input_codecs[nb_input_codecs-1] = avcodec_find_decoder_by_name(audio_codec_name);\n\n            set_context_opts(dec, avcodec_opts[AVMEDIA_TYPE_AUDIO], AV_OPT_FLAG_AUDIO_PARAM | AV_OPT_FLAG_DECODING_PARAM, input_codecs[nb_input_codecs-1]);\n\n            //fprintf(stderr, \"\\nInput Audio channels: %d\", dec->channels);\n\n            channel_layout    = dec->channel_layout;\n\n            audio_channels    = dec->channels;\n\n            audio_sample_rate = dec->sample_rate;\n\n            audio_sample_fmt  = dec->sample_fmt;\n\n            if(audio_disable)\n\n                st->discard= AVDISCARD_ALL;\n\n            /* Note that av_find_stream_info can add more streams, and we\n\n             * currently have no chance of setting up lowres decoding\n\n             * early enough for them. */\n\n            if (dec->lowres)\n\n                audio_sample_rate >>= dec->lowres;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            input_codecs[nb_input_codecs-1] = avcodec_find_decoder_by_name(video_codec_name);\n\n            set_context_opts(dec, avcodec_opts[AVMEDIA_TYPE_VIDEO], AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM, input_codecs[nb_input_codecs-1]);\n\n            frame_height = dec->height;\n\n            frame_width  = dec->width;\n\n            if(ic->streams[i]->sample_aspect_ratio.num)\n\n                frame_aspect_ratio=av_q2d(ic->streams[i]->sample_aspect_ratio);\n\n            else\n\n                frame_aspect_ratio=av_q2d(dec->sample_aspect_ratio);\n\n            frame_aspect_ratio *= (float) dec->width / dec->height;\n\n            frame_pix_fmt = dec->pix_fmt;\n\n            rfps      = ic->streams[i]->r_frame_rate.num;\n\n            rfps_base = ic->streams[i]->r_frame_rate.den;\n\n            if (dec->lowres) {\n\n                dec->flags |= CODEC_FLAG_EMU_EDGE;\n\n                frame_height >>= dec->lowres;\n\n                frame_width  >>= dec->lowres;\n\n            }\n\n            if(me_threshold)\n\n                dec->debug |= FF_DEBUG_MV;\n\n\n\n            if (dec->time_base.den != rfps*dec->ticks_per_frame || dec->time_base.num != rfps_base) {\n\n\n\n                if (verbose >= 0)\n\n                    fprintf(stderr,\"\\nSeems stream %d codec frame rate differs from container frame rate: %2.2f (%d/%d) -> %2.2f (%d/%d)\\n\",\n\n                            i, (float)dec->time_base.den / dec->time_base.num, dec->time_base.den, dec->time_base.num,\n\n\n\n                    (float)rfps / rfps_base, rfps, rfps_base);\n\n            }\n\n            /* update the current frame rate to match the stream frame rate */\n\n            frame_rate.num = rfps;\n\n            frame_rate.den = rfps_base;\n\n\n\n            if(video_disable)\n\n                st->discard= AVDISCARD_ALL;\n\n            else if(video_discard)\n\n                st->discard= video_discard;\n\n            break;\n\n        case AVMEDIA_TYPE_DATA:\n\n            break;\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            input_codecs[nb_input_codecs-1] = avcodec_find_decoder_by_name(subtitle_codec_name);\n\n            if(subtitle_disable)\n\n                st->discard = AVDISCARD_ALL;\n\n            break;\n\n        case AVMEDIA_TYPE_ATTACHMENT:\n\n        case AVMEDIA_TYPE_UNKNOWN:\n\n            break;\n\n        default:\n\n            abort();\n\n        }\n\n    }\n\n\n\n    input_files[nb_input_files] = ic;\n\n    input_files_ts_offset[nb_input_files] = input_ts_offset - (copy_ts ? 0 : timestamp);\n\n    /* dump the file content */\n\n    if (verbose >= 0)\n\n        dump_format(ic, nb_input_files, filename, 0);\n\n\n\n    nb_input_files++;\n\n\n\n    video_channel = 0;\n\n\n\n    av_freep(&video_codec_name);\n\n    av_freep(&audio_codec_name);\n\n    av_freep(&subtitle_codec_name);\n\n}\n", "idx": 11388, "_split": "valid", "_hash": "f58ce77c7034bbcb3f898e234f226bed"}
{"project": "FFmpeg", "commit_id": "cd823ff950cf81d54965eceedb64569fee79ab36", "target": 0, "func": "static int alloc_frame_buffer(MpegEncContext *s, Picture *pic)\n\n{\n\n    int r;\n\n\n\n    if (s->avctx->hwaccel) {\n\n        assert(!pic->hwaccel_data_private);\n\n        if (s->avctx->hwaccel->priv_data_size) {\n\n            pic->hwaccel_data_private = av_malloc(s->avctx->hwaccel->priv_data_size);\n\n            if (!pic->hwaccel_data_private) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"alloc_frame_buffer() failed (hwaccel private data allocation)\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n    }\n\n\n\n    r = s->avctx->get_buffer(s->avctx, (AVFrame*)pic);\n\n\n\n    if (r<0 || !pic->age || !pic->type || !pic->data[0]) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed (%d %d %d %p)\\n\", r, pic->age, pic->type, pic->data[0]);\n\n        av_freep(&pic->hwaccel_data_private);\n\n        return -1;\n\n    }\n\n\n\n    if (s->linesize && (s->linesize != pic->linesize[0] || s->uvlinesize != pic->linesize[1])) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed (stride changed)\\n\");\n\n        free_frame_buffer(s, pic);\n\n        return -1;\n\n    }\n\n\n\n    if (pic->linesize[1] != pic->linesize[2]) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed (uv stride mismatch)\\n\");\n\n        free_frame_buffer(s, pic);\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 11446, "_split": "valid", "_hash": "806c464ce98d3d3e78d8907a06fc435e"}
{"project": "FFmpeg", "commit_id": "207609554981be37db35e4390f49d38d68e890d9", "target": 0, "func": "static int asf_parse_packet(AVFormatContext *s, AVIOContext *pb, AVPacket *pkt)\n\n{\n\n    ASFContext *asf   = s->priv_data;\n\n    ASFStream *asf_st = 0;\n\n    for (;;) {\n\n        int ret;\n\n        if (avio_feof(pb))\n\n            return AVERROR_EOF;\n\n        if (asf->packet_size_left < FRAME_HEADER_SIZE ||\n\n            asf->packet_segments < 1 && asf->packet_time_start == 0) {\n\n            int ret = asf->packet_size_left + asf->packet_padsize;\n\n\n\n            assert(ret >= 0);\n\n            /* fail safe */\n\n            avio_skip(pb, ret);\n\n\n\n            asf->packet_pos = avio_tell(pb);\n\n            if (asf->data_object_size != (uint64_t)-1 &&\n\n                (asf->packet_pos - asf->data_object_offset >= asf->data_object_size))\n\n                return AVERROR_EOF;  /* Do not exceed the size of the data object */\n\n            return 1;\n\n        }\n\n        if (asf->packet_time_start == 0) {\n\n            if (asf_read_frame_header(s, pb) < 0) {\n\n                asf->packet_time_start = asf->packet_segments = 0;\n\n                continue;\n\n            }\n\n            if (asf->stream_index < 0 ||\n\n                s->streams[asf->stream_index]->discard >= AVDISCARD_ALL ||\n\n                (!asf->packet_key_frame &&\n\n                 (s->streams[asf->stream_index]->discard >= AVDISCARD_NONKEY || asf->streams[s->streams[asf->stream_index]->id].skip_to_key))) {\n\n                asf->packet_time_start = 0;\n\n                /* unhandled packet (should not happen) */\n\n                avio_skip(pb, asf->packet_frag_size);\n\n                asf->packet_size_left -= asf->packet_frag_size;\n\n                if (asf->stream_index < 0)\n\n                    av_log(s, AV_LOG_ERROR, \"ff asf skip %d (unknown stream)\\n\",\n\n                           asf->packet_frag_size);\n\n                continue;\n\n            }\n\n            asf->asf_st = &asf->streams[s->streams[asf->stream_index]->id];\n\n            asf->asf_st->skip_to_key = 0;\n\n        }\n\n        asf_st = asf->asf_st;\n\n        av_assert0(asf_st);\n\n\n\n        if (!asf_st->frag_offset && asf->packet_frag_offset) {\n\n            av_dlog(s, \"skipping asf data pkt with fragment offset for \"\n\n                    \"stream:%d, expected:%d but got %d from pkt)\\n\",\n\n                    asf->stream_index, asf_st->frag_offset,\n\n                    asf->packet_frag_offset);\n\n            avio_skip(pb, asf->packet_frag_size);\n\n            asf->packet_size_left -= asf->packet_frag_size;\n\n            continue;\n\n        }\n\n\n\n        if (asf->packet_replic_size == 1) {\n\n            // frag_offset is here used as the beginning timestamp\n\n            asf->packet_frag_timestamp = asf->packet_time_start;\n\n            asf->packet_time_start    += asf->packet_time_delta;\n\n            asf_st->packet_obj_size    = asf->packet_frag_size = avio_r8(pb);\n\n            asf->packet_size_left--;\n\n            asf->packet_multi_size--;\n\n            if (asf->packet_multi_size < asf_st->packet_obj_size) {\n\n                asf->packet_time_start = 0;\n\n                avio_skip(pb, asf->packet_multi_size);\n\n                asf->packet_size_left -= asf->packet_multi_size;\n\n                continue;\n\n            }\n\n            asf->packet_multi_size -= asf_st->packet_obj_size;\n\n        }\n\n\n\n        if (asf_st->pkt.size != asf_st->packet_obj_size ||\n\n            // FIXME is this condition sufficient?\n\n            asf_st->frag_offset + asf->packet_frag_size > asf_st->pkt.size) {\n\n            if (asf_st->pkt.data) {\n\n                av_log(s, AV_LOG_INFO,\n\n                       \"freeing incomplete packet size %d, new %d\\n\",\n\n                       asf_st->pkt.size, asf_st->packet_obj_size);\n\n                asf_st->frag_offset = 0;\n\n                av_free_packet(&asf_st->pkt);\n\n            }\n\n            /* new packet */\n\n            av_new_packet(&asf_st->pkt, asf_st->packet_obj_size);\n\n            asf_st->seq              = asf->packet_seq;\n\n            if (asf->ts_is_pts) {\n\n                asf_st->pkt.pts          = asf->packet_frag_timestamp - asf->hdr.preroll;\n\n            } else\n\n                asf_st->pkt.dts          = asf->packet_frag_timestamp - asf->hdr.preroll;\n\n            asf_st->pkt.stream_index = asf->stream_index;\n\n            asf_st->pkt.pos          = asf_st->packet_pos = asf->packet_pos;\n\n            asf_st->pkt_clean        = 0;\n\n\n\n            if (asf_st->pkt.data && asf_st->palette_changed) {\n\n                uint8_t *pal;\n\n                pal = av_packet_new_side_data(&asf_st->pkt, AV_PKT_DATA_PALETTE,\n\n                                              AVPALETTE_SIZE);\n\n                if (!pal) {\n\n                    av_log(s, AV_LOG_ERROR, \"Cannot append palette to packet\\n\");\n\n                } else {\n\n                    memcpy(pal, asf_st->palette, AVPALETTE_SIZE);\n\n                    asf_st->palette_changed = 0;\n\n                }\n\n            }\n\n            av_dlog(asf, \"new packet: stream:%d key:%d packet_key:%d audio:%d size:%d\\n\",\n\n                    asf->stream_index, asf->packet_key_frame,\n\n                    asf_st->pkt.flags & AV_PKT_FLAG_KEY,\n\n                    s->streams[asf->stream_index]->codec->codec_type == AVMEDIA_TYPE_AUDIO,\n\n                    asf_st->packet_obj_size);\n\n            if (s->streams[asf->stream_index]->codec->codec_type == AVMEDIA_TYPE_AUDIO)\n\n                asf->packet_key_frame = 1;\n\n            if (asf->packet_key_frame)\n\n                asf_st->pkt.flags |= AV_PKT_FLAG_KEY;\n\n        }\n\n\n\n        /* read data */\n\n        av_dlog(asf, \"READ PACKET s:%d  os:%d  o:%d,%d  l:%d   DATA:%p\\n\",\n\n                s->packet_size, asf_st->pkt.size, asf->packet_frag_offset,\n\n                asf_st->frag_offset, asf->packet_frag_size, asf_st->pkt.data);\n\n        asf->packet_size_left -= asf->packet_frag_size;\n\n        if (asf->packet_size_left < 0)\n\n            continue;\n\n\n\n        if (asf->packet_frag_offset >= asf_st->pkt.size ||\n\n            asf->packet_frag_size > asf_st->pkt.size - asf->packet_frag_offset) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"packet fragment position invalid %u,%u not in %u\\n\",\n\n                   asf->packet_frag_offset, asf->packet_frag_size,\n\n                   asf_st->pkt.size);\n\n            continue;\n\n        }\n\n\n\n        if (asf->packet_frag_offset != asf_st->frag_offset && !asf_st->pkt_clean) {\n\n            memset(asf_st->pkt.data + asf_st->frag_offset, 0, asf_st->pkt.size - asf_st->frag_offset);\n\n            asf_st->pkt_clean = 1;\n\n        }\n\n\n\n        ret = avio_read(pb, asf_st->pkt.data + asf->packet_frag_offset,\n\n                        asf->packet_frag_size);\n\n        if (ret != asf->packet_frag_size) {\n\n            if (ret < 0 || asf->packet_frag_offset + ret == 0)\n\n                return ret < 0 ? ret : AVERROR_EOF;\n\n\n\n            if (asf_st->ds_span > 1) {\n\n                // scrambling, we can either drop it completely or fill the remainder\n\n                // TODO: should we fill the whole packet instead of just the current\n\n                // fragment?\n\n                memset(asf_st->pkt.data + asf->packet_frag_offset + ret, 0,\n\n                       asf->packet_frag_size - ret);\n\n                ret = asf->packet_frag_size;\n\n            } else {\n\n                // no scrambling, so we can return partial packets\n\n                av_shrink_packet(&asf_st->pkt, asf->packet_frag_offset + ret);\n\n            }\n\n        }\n\n        if (s->key && s->keylen == 20)\n\n            ff_asfcrypt_dec(s->key, asf_st->pkt.data + asf->packet_frag_offset,\n\n                            ret);\n\n        asf_st->frag_offset += ret;\n\n        /* test if whole packet is read */\n\n        if (asf_st->frag_offset == asf_st->pkt.size) {\n\n            // workaround for macroshit radio DVR-MS files\n\n            if (s->streams[asf->stream_index]->codec->codec_id == AV_CODEC_ID_MPEG2VIDEO &&\n\n                asf_st->pkt.size > 100) {\n\n                int i;\n\n                for (i = 0; i < asf_st->pkt.size && !asf_st->pkt.data[i]; i++)\n\n                    ;\n\n                if (i == asf_st->pkt.size) {\n\n                    av_log(s, AV_LOG_DEBUG, \"discarding ms fart\\n\");\n\n                    asf_st->frag_offset = 0;\n\n                    av_free_packet(&asf_st->pkt);\n\n                    continue;\n\n                }\n\n            }\n\n\n\n            /* return packet */\n\n            if (asf_st->ds_span > 1) {\n\n                if (asf_st->pkt.size != asf_st->ds_packet_size * asf_st->ds_span) {\n\n                    av_log(s, AV_LOG_ERROR,\n\n                           \"pkt.size != ds_packet_size * ds_span (%d %d %d)\\n\",\n\n                           asf_st->pkt.size, asf_st->ds_packet_size,\n\n                           asf_st->ds_span);\n\n                } else {\n\n                    /* packet descrambling */\n\n                    AVBufferRef *buf = av_buffer_alloc(asf_st->pkt.size +\n\n                                                       FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (buf) {\n\n                        uint8_t *newdata = buf->data;\n\n                        int offset = 0;\n\n                        memset(newdata + asf_st->pkt.size, 0,\n\n                               FF_INPUT_BUFFER_PADDING_SIZE);\n\n                        while (offset < asf_st->pkt.size) {\n\n                            int off = offset / asf_st->ds_chunk_size;\n\n                            int row = off / asf_st->ds_span;\n\n                            int col = off % asf_st->ds_span;\n\n                            int idx = row + col * asf_st->ds_packet_size / asf_st->ds_chunk_size;\n\n                            assert(offset + asf_st->ds_chunk_size <= asf_st->pkt.size);\n\n                            assert(idx + 1 <= asf_st->pkt.size / asf_st->ds_chunk_size);\n\n                            memcpy(newdata + offset,\n\n                                   asf_st->pkt.data + idx * asf_st->ds_chunk_size,\n\n                                   asf_st->ds_chunk_size);\n\n                            offset += asf_st->ds_chunk_size;\n\n                        }\n\n                        av_buffer_unref(&asf_st->pkt.buf);\n\n                        asf_st->pkt.buf  = buf;\n\n                        asf_st->pkt.data = buf->data;\n\n                    }\n\n                }\n\n            }\n\n            asf_st->frag_offset         = 0;\n\n            *pkt                        = asf_st->pkt;\n\n#if FF_API_DESTRUCT_PACKET\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n            asf_st->pkt.destruct        = NULL;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n            asf_st->pkt.buf             = 0;\n\n            asf_st->pkt.size            = 0;\n\n            asf_st->pkt.data            = 0;\n\n            asf_st->pkt.side_data_elems = 0;\n\n            asf_st->pkt.side_data       = NULL;\n\n            break; // packet completed\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 11448, "_split": "valid", "_hash": "d11a718f91780c30f0da6416984ffdcb"}
{"project": "FFmpeg", "commit_id": "933aa91e31d5cbf9dbc0cf416a988e6011bc4a40", "target": 1, "func": "static int hls_decode_entry(AVCodecContext *avctxt, void *isFilterThread)\n\n{\n\n    HEVCContext *s  = avctxt->priv_data;\n\n    int ctb_size    = 1 << s->ps.sps->log2_ctb_size;\n\n    int more_data   = 1;\n\n    int x_ctb       = 0;\n\n    int y_ctb       = 0;\n\n    int ctb_addr_ts = s->ps.pps->ctb_addr_rs_to_ts[s->sh.slice_ctb_addr_rs];\n\n\n\n    if (!ctb_addr_ts && s->sh.dependent_slice_segment_flag) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Impossible initial tile.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->sh.dependent_slice_segment_flag) {\n\n        int prev_rs = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts - 1];\n\n        if (s->tab_slice_address[prev_rs] != s->sh.slice_addr) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Previous slice segment missing\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    while (more_data && ctb_addr_ts < s->ps.sps->ctb_size) {\n\n        int ctb_addr_rs = s->ps.pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n\n\n\n        x_ctb = (ctb_addr_rs % ((s->ps.sps->width + ctb_size - 1) >> s->ps.sps->log2_ctb_size)) << s->ps.sps->log2_ctb_size;\n\n        y_ctb = (ctb_addr_rs / ((s->ps.sps->width + ctb_size - 1) >> s->ps.sps->log2_ctb_size)) << s->ps.sps->log2_ctb_size;\n\n        hls_decode_neighbour(s, x_ctb, y_ctb, ctb_addr_ts);\n\n\n\n        ff_hevc_cabac_init(s, ctb_addr_ts);\n\n\n\n        hls_sao_param(s, x_ctb >> s->ps.sps->log2_ctb_size, y_ctb >> s->ps.sps->log2_ctb_size);\n\n\n\n        s->deblock[ctb_addr_rs].beta_offset = s->sh.beta_offset;\n\n        s->deblock[ctb_addr_rs].tc_offset   = s->sh.tc_offset;\n\n        s->filter_slice_edges[ctb_addr_rs]  = s->sh.slice_loop_filter_across_slices_enabled_flag;\n\n\n\n        more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->ps.sps->log2_ctb_size, 0);\n\n        if (more_data < 0) {\n\n            s->tab_slice_address[ctb_addr_rs] = -1;\n\n            return more_data;\n\n        }\n\n\n\n\n\n        ctb_addr_ts++;\n\n        ff_hevc_save_states(s, ctb_addr_ts);\n\n        ff_hevc_hls_filters(s, x_ctb, y_ctb, ctb_size);\n\n    }\n\n\n\n    if (x_ctb + ctb_size >= s->ps.sps->width &&\n\n        y_ctb + ctb_size >= s->ps.sps->height)\n\n        ff_hevc_hls_filter(s, x_ctb, y_ctb, ctb_size);\n\n\n\n    return ctb_addr_ts;\n\n}\n", "idx": 11450, "_split": "valid", "_hash": "1747a2d3213fbd1cc8e506cb230645cd"}
{"project": "FFmpeg", "commit_id": "33dc1913ab7aaefc991b3e665d1d0b5d0b088672", "target": 1, "func": "static void reset_packet_state(AVFormatContext *s)\n\n{\n\n    ASFContext *asf        = s->priv_data;\n\n    int i;\n\n\n\n    asf->state             = PARSE_PACKET_HEADER;\n\n    asf->offset            = 0;\n\n    asf->return_subpayload = 0;\n\n    asf->sub_left          = 0;\n\n    asf->sub_header_offset = 0;\n\n    asf->packet_offset     = asf->first_packet_offset;\n\n    asf->pad_len           = 0;\n\n    asf->rep_data_len      = 0;\n\n    asf->dts_delta         = 0;\n\n    asf->mult_sub_len      = 0;\n\n    asf->nb_mult_left      = 0;\n\n    asf->nb_sub            = 0;\n\n    asf->prop_flags        = 0;\n\n    asf->sub_dts           = 0;\n\n    asf->dts               = 0;\n\n    for (i = 0; i < asf->nb_streams; i++) {\n\n        ASFPacket *pkt = &asf->asf_st[i]->pkt;\n\n        pkt->size_left = 0;\n\n        pkt->data_size = 0;\n\n        pkt->duration  = 0;\n\n        pkt->flags     = 0;\n\n        pkt->dts       = 0;\n\n        pkt->duration  = 0;\n\n        av_free_packet(&pkt->avpkt);\n\n        av_init_packet(&pkt->avpkt);\n\n    }\n\n}\n", "idx": 11451, "_split": "valid", "_hash": "6493d69138ddd1d5c9050c3ba4beda21"}
{"project": "FFmpeg", "commit_id": "d934de5c5d9ff1d228d0113e31e182efe2a853aa", "target": 0, "func": "static int cavs_decode_frame(AVCodecContext * avctx,void *data, int *data_size,\n\n                             const uint8_t * buf, int buf_size) {\n\n    AVSContext *h = avctx->priv_data;\n\n    MpegEncContext *s = &h->s;\n\n    int input_size;\n\n    const uint8_t *buf_end;\n\n    const uint8_t *buf_ptr;\n\n    AVFrame *picture = data;\n\n    uint32_t stc = -1;\n\n\n\n    s->avctx = avctx;\n\n\n\n    if (buf_size == 0) {\n\n        if(!s->low_delay && h->DPB[0].data[0]) {\n\n            *data_size = sizeof(AVPicture);\n\n            *picture = *(AVFrame *) &h->DPB[0];\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n    for(;;) {\n\n        buf_ptr = ff_find_start_code(buf_ptr,buf_end, &stc);\n\n        if(stc & 0xFFFFFE00)\n\n            return FFMAX(0, buf_ptr - buf - s->parse_context.last_index);\n\n        input_size = (buf_end - buf_ptr)*8;\n\n        switch(stc) {\n\n        case CAVS_START_CODE:\n\n            init_get_bits(&s->gb, buf_ptr, input_size);\n\n            decode_seq_header(h);\n\n            break;\n\n        case PIC_I_START_CODE:\n\n            if(!h->got_keyframe) {\n\n                if(h->DPB[0].data[0])\n\n                    avctx->release_buffer(avctx, (AVFrame *)&h->DPB[0]);\n\n                if(h->DPB[1].data[0])\n\n                    avctx->release_buffer(avctx, (AVFrame *)&h->DPB[1]);\n\n                h->got_keyframe = 1;\n\n            }\n\n        case PIC_PB_START_CODE:\n\n            *data_size = 0;\n\n            if(!h->got_keyframe)\n\n                break;\n\n            init_get_bits(&s->gb, buf_ptr, input_size);\n\n            h->stc = stc;\n\n            if(decode_pic(h))\n\n                break;\n\n            *data_size = sizeof(AVPicture);\n\n            if(h->pic_type != FF_B_TYPE) {\n\n                if(h->DPB[1].data[0]) {\n\n                    *picture = *(AVFrame *) &h->DPB[1];\n\n                } else {\n\n                    *data_size = 0;\n\n                }\n\n            } else\n\n                *picture = *(AVFrame *) &h->picture;\n\n            break;\n\n        case EXT_START_CODE:\n\n            //mpeg_decode_extension(avctx,buf_ptr, input_size);\n\n            break;\n\n        case USER_START_CODE:\n\n            //mpeg_decode_user_data(avctx,buf_ptr, input_size);\n\n            break;\n\n        default:\n\n            if (stc >= SLICE_MIN_START_CODE &&\n\n                stc <= SLICE_MAX_START_CODE) {\n\n                init_get_bits(&s->gb, buf_ptr, input_size);\n\n                decode_slice_header(h, &s->gb);\n\n            }\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 11469, "_split": "valid", "_hash": "7acce18947435cc0823b3a2dd3f0489a"}
{"project": "FFmpeg", "commit_id": "0314dead4e7c058568e792842405190c06d71da5", "target": 1, "func": "AVEvalExpr * ff_parse(const char *s, const char * const *const_name,\n\n               double (**func1)(void *, double), const char **func1_name,\n\n               double (**func2)(void *, double, double), const char **func2_name,\n\n               const char **error){\n\n    Parser p;\n\n    AVEvalExpr * e;\n\n    char w[strlen(s) + 1], * wp = w;\n\n\n\n    while (*s)\n\n        if (!isspace(*s++)) *wp++ = s[-1];\n\n    *wp++ = 0;\n\n\n\n    p.stack_index=100;\n\n    p.s= w;\n\n    p.const_name = const_name;\n\n    p.func1      = func1;\n\n    p.func1_name = func1_name;\n\n    p.func2      = func2;\n\n    p.func2_name = func2_name;\n\n    p.error= error;\n\n\n\n    e = parse_expr(&p);\n\n    if (!verify_expr(e)) {\n\n        ff_eval_free(e);\n\n        return NULL;\n\n    }\n\n    return e;\n\n}\n", "idx": 11492, "_split": "valid", "_hash": "88252124623014aa67f3222a35912ac0"}
{"project": "FFmpeg", "commit_id": "e87190f5d20d380608f792ceb14d0def1d80e24b", "target": 0, "func": "static void read_packets(WriterContext *w, AVFormatContext *fmt_ctx)\n\n{\n\n    int i, ret = 0;\n\n    int64_t cur_ts = fmt_ctx->start_time;\n\n\n\n    if (read_intervals_nb == 0) {\n\n        ReadInterval interval = (ReadInterval) { .has_start = 0, .has_end = 0 };\n\n        ret = read_interval_packets(w, fmt_ctx, &interval, &cur_ts);\n\n    } else {\n\n        for (i = 0; i < read_intervals_nb; i++) {\n\n            ret = read_interval_packets(w, fmt_ctx, &read_intervals[i], &cur_ts);\n\n            if (ret < 0)\n\n                break;\n\n        }\n\n    }\n\n}\n", "idx": 11528, "_split": "valid", "_hash": "4aa84fa8c84b0bf7b5db7d7265d06366"}
{"project": "FFmpeg", "commit_id": "e021eeb9f06f4f4d83690d07b47cdcc4172a61e1", "target": 0, "func": "int av_opt_set_from_string(void *ctx, const char *opts,\n\n                           const char *const *shorthand,\n\n                           const char *key_val_sep, const char *pairs_sep)\n\n{\n\n    int ret, count = 0;\n\n    const char *dummy_shorthand = NULL;\n\n    char key_buf[68], *value;\n\n    const char *key;\n\n\n\n    if (!opts)\n\n        return 0;\n\n    if (!shorthand)\n\n        shorthand = &dummy_shorthand;\n\n\n\n    while (*opts) {\n\n        if ((ret = get_key(&opts, key_val_sep, key_buf, sizeof(key_buf))) < 0) {\n\n            if (*shorthand) {\n\n                key = *(shorthand++);\n\n            } else {\n\n                av_log(ctx, AV_LOG_ERROR, \"No option name near '%s'\\n\", opts);\n\n                return AVERROR(EINVAL);\n\n            }\n\n        } else {\n\n            key = key_buf;\n\n            while (*shorthand) /* discard all remaining shorthand */\n\n                shorthand++;\n\n        }\n\n\n\n        if (!(value = av_get_token(&opts, pairs_sep)))\n\n            return AVERROR(ENOMEM);\n\n        if (*opts && strchr(pairs_sep, *opts))\n\n            opts++;\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"Setting '%s' to value '%s'\\n\", key, value);\n\n        if ((ret = av_opt_set(ctx, key, value, 0)) < 0) {\n\n            if (ret == AVERROR_OPTION_NOT_FOUND)\n\n                av_log(ctx, AV_LOG_ERROR, \"Option '%s' not found\\n\", key);\n\n            av_free(value);\n\n            return ret;\n\n        }\n\n\n\n        av_free(value);\n\n        count++;\n\n    }\n\n    return count;\n\n}\n", "idx": 11570, "_split": "valid", "_hash": "c670e9fa6a5c09610e05d4215e5d66cc"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int targa_encode_init(AVCodecContext *avctx)\n\n{\n\n    avctx->coded_frame = av_frame_alloc();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->coded_frame->key_frame = 1;\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    return 0;\n\n}\n", "idx": 11688, "_split": "valid", "_hash": "010d5fd3f774f7eb3ae97c5e11f334d0"}
{"project": "FFmpeg", "commit_id": "3e56db892600c2fbe34782c6140f1ee832a2c344", "target": 1, "func": "static int y216_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame, AVPacket *avpkt)\n\n{\n\n    AVFrame *pic = data;\n\n    const uint16_t *src = (uint16_t *)avpkt->data;\n\n    uint16_t *y, *u, *v, aligned_width = FFALIGN(avctx->width, 4);\n\n    int i, j, ret;\n\n\n\n    if (avpkt->size < 4 * avctx->height * aligned_width) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Insufficient input data.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if ((ret = ff_get_buffer(avctx, pic, 0)) < 0)\n\n        return ret;\n\n\n\n    pic->key_frame = 1;\n\n    pic->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    y = (uint16_t *)pic->data[0];\n\n    u = (uint16_t *)pic->data[1];\n\n    v = (uint16_t *)pic->data[2];\n\n\n\n    for (i = 0; i < avctx->height; i++) {\n\n        for (j = 0; j < avctx->width >> 1; j++) {\n\n            u[    j    ] = src[4 * j    ] << 2 | src[4 * j    ] >> 14;\n\n            y[2 * j    ] = src[4 * j + 1] << 2 | src[4 * j + 1] >> 14;\n\n            v[    j    ] = src[4 * j + 2] << 2 | src[4 * j + 2] >> 14;\n\n            y[2 * j + 1] = src[4 * j + 3] << 2 | src[4 * j + 3] >> 14;\n\n        }\n\n\n\n        y += pic->linesize[0] >> 1;\n\n        u += pic->linesize[1] >> 1;\n\n        v += pic->linesize[2] >> 1;\n\n        src += aligned_width << 1;\n\n    }\n\n\n\n    *got_frame = 1;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 11723, "_split": "valid", "_hash": "e6c5848a06b48688c92b735eb0c70f6d"}
{"project": "FFmpeg", "commit_id": "1c0e205fab4bd5bbfa0399af2cd5e281b414b3d5", "target": 1, "func": "void audio_decode_example(const char *outfilename, const char *filename)\n\n{\n\n    AVCodec *codec;\n\n    AVCodecContext *c= NULL;\n\n    int out_size, size, len;\n\n    FILE *f, *outfile;\n\n    uint8_t *outbuf;\n\n    uint8_t inbuf[INBUF_SIZE + FF_INPUT_BUFFER_PADDING_SIZE], *inbuf_ptr;\n\n\n\n    printf(\"Audio decoding\\n\");\n\n    \n\n    /* set end of buffer to 0 (this ensures that no overreading happens for damaged mpeg streams) */\n\n    memset(inbuf + INBUF_SIZE, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    /* find the mpeg audio decoder */\n\n    codec = avcodec_find_decoder(CODEC_ID_MP2);\n\n    if (!codec) {\n\n        fprintf(stderr, \"codec not found\\n\");\n\n        exit(1);\n\n    }\n\n\n\n    c= avcodec_alloc_context();\n\n\n\n    /* open it */\n\n    if (avcodec_open(c, codec) < 0) {\n\n        fprintf(stderr, \"could not open codec\\n\");\n\n        exit(1);\n\n    }\n\n    \n\n    outbuf = malloc(AVCODEC_MAX_AUDIO_FRAME_SIZE);\n\n\n\n    f = fopen(filename, \"r\");\n\n    if (!f) {\n\n        fprintf(stderr, \"could not open %s\\n\", filename);\n\n        exit(1);\n\n    }\n\n    outfile = fopen(outfilename, \"w\");\n\n    if (!outfile) {\n\n        free(c);\n\n        exit(1);\n\n    }\n\n        \n\n    /* decode until eof */\n\n    inbuf_ptr = inbuf;\n\n    for(;;) {\n\n        size = fread(inbuf, 1, INBUF_SIZE, f);\n\n        if (size == 0)\n\n            break;\n\n\n\n        inbuf_ptr = inbuf;\n\n        while (size > 0) {\n\n            len = avcodec_decode_audio(c, (short *)outbuf, &out_size, \n\n                                       inbuf_ptr, size);\n\n            if (len < 0) {\n\n                fprintf(stderr, \"Error while decoding\\n\");\n\n                exit(1);\n\n            }\n\n            if (out_size > 0) {\n\n                /* if a frame has been decoded, output it */\n\n                fwrite(outbuf, 1, out_size, outfile);\n\n            }\n\n            size -= len;\n\n            inbuf_ptr += len;\n\n        }\n\n    }\n\n\n\n    fclose(outfile);\n\n    fclose(f);\n\n    free(outbuf);\n\n\n\n    avcodec_close(c);\n\n    free(c);\n\n}\n", "idx": 11745, "_split": "valid", "_hash": "9018cb9a0aac30440db82b9344587c70"}
{"project": "FFmpeg", "commit_id": "a930cd0d195ea1c33b6b97b3f3f60703f899e739", "target": 0, "func": "static int nprobe(AVFormatContext *s, uint8_t *enc_header, const uint8_t *n_val)\n\n{\n\n    OMAContext *oc = s->priv_data;\n\n    uint32_t pos, taglen, datalen;\n\n    struct AVDES av_des;\n\n\n\n    if (!enc_header || !n_val)\n\n        return -1;\n\n\n\n    pos = OMA_ENC_HEADER_SIZE + oc->k_size;\n\n    if (!memcmp(&enc_header[pos], \"EKB \", 4))\n\n        pos += 32;\n\n\n\n    if (AV_RB32(&enc_header[pos]) != oc->rid)\n\n        av_log(s, AV_LOG_DEBUG, \"Mismatching RID\\n\");\n\n\n\n    taglen = AV_RB32(&enc_header[pos+32]);\n\n    datalen = AV_RB32(&enc_header[pos+36]) >> 4;\n\n\n\n    pos += 44 + taglen;\n\n\n\n    av_des_init(&av_des, n_val, 192, 1);\n\n    while (datalen-- > 0) {\n\n        av_des_crypt(&av_des, oc->r_val, &enc_header[pos], 2, NULL, 1);\n\n        kset(s, oc->r_val, NULL, 16);\n\n        if (!rprobe(s, enc_header, oc->r_val))\n\n            return 0;\n\n        pos += 16;\n\n    }\n\n\n\n    return -1;\n\n}\n", "idx": 11825, "_split": "valid", "_hash": "e79696f51a6e726e02d36366bc7cd356"}
{"project": "FFmpeg", "commit_id": "b0a18c2f0a6d54b522a8f21538801e152ddf7fb8", "target": 0, "func": "static void compute_pkt_fields(AVFormatContext *s, AVStream *st,\n\n                               AVCodecParserContext *pc, AVPacket *pkt)\n\n{\n\n    int num, den, presentation_delayed, delay, i;\n\n    int64_t offset;\n\n\n\n    if (s->flags & AVFMT_FLAG_NOFILLIN)\n\n        return;\n\n\n\n    if((s->flags & AVFMT_FLAG_IGNDTS) && pkt->pts != AV_NOPTS_VALUE)\n\n        pkt->dts= AV_NOPTS_VALUE;\n\n\n\n    if (st->codec->codec_id != CODEC_ID_H264 && pc && pc->pict_type == FF_B_TYPE)\n\n        //FIXME Set low_delay = 0 when has_b_frames = 1\n\n        st->codec->has_b_frames = 1;\n\n\n\n    /* do we have a video B-frame ? */\n\n    delay= st->codec->has_b_frames;\n\n    presentation_delayed = 0;\n\n    /* XXX: need has_b_frame, but cannot get it if the codec is\n\n        not initialized */\n\n    if (delay &&\n\n        pc && pc->pict_type != FF_B_TYPE)\n\n        presentation_delayed = 1;\n\n\n\n    if(pkt->pts != AV_NOPTS_VALUE && pkt->dts != AV_NOPTS_VALUE && pkt->dts > pkt->pts && st->pts_wrap_bits<63\n\n       /*&& pkt->dts-(1LL<<st->pts_wrap_bits) < pkt->pts*/){\n\n        pkt->dts -= 1LL<<st->pts_wrap_bits;\n\n    }\n\n\n\n    // some mpeg2 in mpeg-ps lack dts (issue171 / input_file.mpg)\n\n    // we take the conservative approach and discard both\n\n    // Note, if this is misbehaving for a H.264 file then possibly presentation_delayed is not set correctly.\n\n    if(delay==1 && pkt->dts == pkt->pts && pkt->dts != AV_NOPTS_VALUE && presentation_delayed){\n\n        av_log(s, AV_LOG_WARNING, \"invalid dts/pts combination\\n\");\n\n        pkt->dts= pkt->pts= AV_NOPTS_VALUE;\n\n    }\n\n\n\n    if (pkt->duration == 0) {\n\n        compute_frame_duration(&num, &den, st, pc, pkt);\n\n        if (den && num) {\n\n            pkt->duration = av_rescale_rnd(1, num * (int64_t)st->time_base.den, den * (int64_t)st->time_base.num, AV_ROUND_DOWN);\n\n\n\n            if(pkt->duration != 0 && s->packet_buffer)\n\n                update_initial_durations(s, st, pkt);\n\n        }\n\n    }\n\n\n\n    /* correct timestamps with byte offset if demuxers only have timestamps\n\n       on packet boundaries */\n\n    if(pc && st->need_parsing == AVSTREAM_PARSE_TIMESTAMPS && pkt->size){\n\n        /* this will estimate bitrate based on this frame's duration and size */\n\n        offset = av_rescale(pc->offset, pkt->duration, pkt->size);\n\n        if(pkt->pts != AV_NOPTS_VALUE)\n\n            pkt->pts += offset;\n\n        if(pkt->dts != AV_NOPTS_VALUE)\n\n            pkt->dts += offset;\n\n    }\n\n\n\n    if (pc && pc->dts_sync_point >= 0) {\n\n        // we have synchronization info from the parser\n\n        int64_t den = st->codec->time_base.den * (int64_t) st->time_base.num;\n\n        if (den > 0) {\n\n            int64_t num = st->codec->time_base.num * (int64_t) st->time_base.den;\n\n            if (pkt->dts != AV_NOPTS_VALUE) {\n\n                // got DTS from the stream, update reference timestamp\n\n                st->reference_dts = pkt->dts - pc->dts_ref_dts_delta * num / den;\n\n                pkt->pts = pkt->dts + pc->pts_dts_delta * num / den;\n\n            } else if (st->reference_dts != AV_NOPTS_VALUE) {\n\n                // compute DTS based on reference timestamp\n\n                pkt->dts = st->reference_dts + pc->dts_ref_dts_delta * num / den;\n\n                pkt->pts = pkt->dts + pc->pts_dts_delta * num / den;\n\n            }\n\n            if (pc->dts_sync_point > 0)\n\n                st->reference_dts = pkt->dts; // new reference\n\n        }\n\n    }\n\n\n\n    /* This may be redundant, but it should not hurt. */\n\n    if(pkt->dts != AV_NOPTS_VALUE && pkt->pts != AV_NOPTS_VALUE && pkt->pts > pkt->dts)\n\n        presentation_delayed = 1;\n\n\n\n//    av_log(NULL, AV_LOG_DEBUG, \"IN delayed:%d pts:%\"PRId64\", dts:%\"PRId64\" cur_dts:%\"PRId64\" st:%d pc:%p\\n\", presentation_delayed, pkt->pts, pkt->dts, st->cur_dts, pkt->stream_index, pc);\n\n    /* interpolate PTS and DTS if they are not present */\n\n    //We skip H264 currently because delay and has_b_frames are not reliably set\n\n    if((delay==0 || (delay==1 && pc)) && st->codec->codec_id != CODEC_ID_H264){\n\n        if (presentation_delayed) {\n\n            /* DTS = decompression timestamp */\n\n            /* PTS = presentation timestamp */\n\n            if (pkt->dts == AV_NOPTS_VALUE)\n\n                pkt->dts = st->last_IP_pts;\n\n            update_initial_timestamps(s, pkt->stream_index, pkt->dts, pkt->pts);\n\n            if (pkt->dts == AV_NOPTS_VALUE)\n\n                pkt->dts = st->cur_dts;\n\n\n\n            /* this is tricky: the dts must be incremented by the duration\n\n            of the frame we are displaying, i.e. the last I- or P-frame */\n\n            if (st->last_IP_duration == 0)\n\n                st->last_IP_duration = pkt->duration;\n\n            if(pkt->dts != AV_NOPTS_VALUE)\n\n                st->cur_dts = pkt->dts + st->last_IP_duration;\n\n            st->last_IP_duration  = pkt->duration;\n\n            st->last_IP_pts= pkt->pts;\n\n            /* cannot compute PTS if not present (we can compute it only\n\n            by knowing the future */\n\n        } else if(pkt->pts != AV_NOPTS_VALUE || pkt->dts != AV_NOPTS_VALUE || pkt->duration){\n\n            if(pkt->pts != AV_NOPTS_VALUE && pkt->duration){\n\n                int64_t old_diff= FFABS(st->cur_dts - pkt->duration - pkt->pts);\n\n                int64_t new_diff= FFABS(st->cur_dts - pkt->pts);\n\n                if(old_diff < new_diff && old_diff < (pkt->duration>>3)){\n\n                    pkt->pts += pkt->duration;\n\n    //                av_log(NULL, AV_LOG_DEBUG, \"id:%d old:%\"PRId64\" new:%\"PRId64\" dur:%d cur:%\"PRId64\" size:%d\\n\", pkt->stream_index, old_diff, new_diff, pkt->duration, st->cur_dts, pkt->size);\n\n                }\n\n            }\n\n\n\n            /* presentation is not delayed : PTS and DTS are the same */\n\n            if(pkt->pts == AV_NOPTS_VALUE)\n\n                pkt->pts = pkt->dts;\n\n            update_initial_timestamps(s, pkt->stream_index, pkt->pts, pkt->pts);\n\n            if(pkt->pts == AV_NOPTS_VALUE)\n\n                pkt->pts = st->cur_dts;\n\n            pkt->dts = pkt->pts;\n\n            if(pkt->pts != AV_NOPTS_VALUE)\n\n                st->cur_dts = pkt->pts + pkt->duration;\n\n        }\n\n    }\n\n\n\n    if(pkt->pts != AV_NOPTS_VALUE && delay <= MAX_REORDER_DELAY){\n\n        st->pts_buffer[0]= pkt->pts;\n\n        for(i=0; i<delay && st->pts_buffer[i] > st->pts_buffer[i+1]; i++)\n\n            FFSWAP(int64_t, st->pts_buffer[i], st->pts_buffer[i+1]);\n\n        if(pkt->dts == AV_NOPTS_VALUE)\n\n            pkt->dts= st->pts_buffer[0];\n\n        if(st->codec->codec_id == CODEC_ID_H264){ //we skiped it above so we try here\n\n            update_initial_timestamps(s, pkt->stream_index, pkt->dts, pkt->pts); // this should happen on the first packet\n\n        }\n\n        if(pkt->dts > st->cur_dts)\n\n            st->cur_dts = pkt->dts;\n\n    }\n\n\n\n//    av_log(NULL, AV_LOG_ERROR, \"OUTdelayed:%d/%d pts:%\"PRId64\", dts:%\"PRId64\" cur_dts:%\"PRId64\"\\n\", presentation_delayed, delay, pkt->pts, pkt->dts, st->cur_dts);\n\n\n\n    /* update flags */\n\n    if(is_intra_only(st->codec))\n\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\n    else if (pc) {\n\n        pkt->flags = 0;\n\n        /* keyframe computation */\n\n        if (pc->key_frame == 1)\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n        else if (pc->key_frame == -1 && pc->pict_type == FF_I_TYPE)\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n    }\n\n    if (pc)\n\n        pkt->convergence_duration = pc->convergence_duration;\n\n}\n", "idx": 11871, "_split": "valid", "_hash": "12ef954a2b17706ec8d562903e2ea7ca"}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_biwgt_8width_msa(uint8_t *src, int32_t src_stride,\n\n                                 uint8_t *dst, int32_t dst_stride,\n\n                                 int32_t height, int32_t log2_denom,\n\n                                 int32_t src_weight, int32_t dst_weight,\n\n                                 int32_t offset_in)\n\n{\n\n    uint8_t cnt;\n\n    v16i8 src_wgt, dst_wgt, wgt;\n\n    v16i8 src0, src1, src2, src3;\n\n    v16i8 dst0, dst1, dst2, dst3;\n\n    v8i16 temp0, temp1, temp2, temp3;\n\n    v8i16 denom, offset, add_val;\n\n    int32_t val = 128 * (src_weight + dst_weight);\n\n\n\n    offset_in = ((offset_in + 1) | 1) << log2_denom;\n\n\n\n    src_wgt = __msa_fill_b(src_weight);\n\n    dst_wgt = __msa_fill_b(dst_weight);\n\n    offset = __msa_fill_h(offset_in);\n\n    denom = __msa_fill_h(log2_denom + 1);\n\n    add_val = __msa_fill_h(val);\n\n    offset += add_val;\n\n\n\n    wgt = __msa_ilvev_b(dst_wgt, src_wgt);\n\n\n\n    for (cnt = height / 4; cnt--;) {\n\n        LOAD_4VECS_SB(src, src_stride, src0, src1, src2, src3);\n\n        src += (4 * src_stride);\n\n\n\n        LOAD_4VECS_SB(dst, dst_stride, dst0, dst1, dst2, dst3);\n\n\n\n        XORI_B_4VECS_SB(src0, src1, src2, src3, src0, src1, src2, src3, 128);\n\n\n\n        XORI_B_4VECS_SB(dst0, dst1, dst2, dst3, dst0, dst1, dst2, dst3, 128);\n\n\n\n        ILVR_B_4VECS_SH(src0, src1, src2, src3, dst0, dst1, dst2, dst3,\n\n                        temp0, temp1, temp2, temp3);\n\n\n\n        temp0 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp0);\n\n        temp1 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp1);\n\n        temp2 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp2);\n\n        temp3 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp3);\n\n\n\n        SRA_4VECS(temp0, temp1, temp2, temp3,\n\n                  temp0, temp1, temp2, temp3, denom);\n\n\n\n        temp0 = CLIP_UNSIGNED_CHAR_H(temp0);\n\n        temp1 = CLIP_UNSIGNED_CHAR_H(temp1);\n\n        temp2 = CLIP_UNSIGNED_CHAR_H(temp2);\n\n        temp3 = CLIP_UNSIGNED_CHAR_H(temp3);\n\n\n\n        PCKEV_B_STORE_8_BYTES_4(temp0, temp1, temp2, temp3, dst, dst_stride);\n\n        dst += 4 * dst_stride;\n\n    }\n\n}\n", "idx": 11882, "_split": "valid", "_hash": "13d71d6f0c6e5e2f06c5fcd65f09bc47"}
{"project": "FFmpeg", "commit_id": "cb2bd91413af28ca9a0202e9b92ee7c1e3d9dd2e", "target": 0, "func": "static void add_input_streams(OptionsContext *o, AVFormatContext *ic)\n\n{\n\n    int i;\n\n    char *next, *codec_tag = NULL;\n\n\n\n    for (i = 0; i < ic->nb_streams; i++) {\n\n        AVStream *st = ic->streams[i];\n\n        AVCodecContext *dec = st->codec;\n\n        InputStream *ist = av_mallocz(sizeof(*ist));\n\n        char *framerate = NULL;\n\n\n\n        if (!ist)\n\n            exit(1);\n\n\n\n        GROW_ARRAY(input_streams, nb_input_streams);\n\n        input_streams[nb_input_streams - 1] = ist;\n\n\n\n        ist->st = st;\n\n        ist->file_index = nb_input_files;\n\n        ist->discard = 1;\n\n        st->discard  = AVDISCARD_ALL;\n\n\n\n        ist->ts_scale = 1.0;\n\n        MATCH_PER_STREAM_OPT(ts_scale, dbl, ist->ts_scale, ic, st);\n\n\n\n        MATCH_PER_STREAM_OPT(codec_tags, str, codec_tag, ic, st);\n\n        if (codec_tag) {\n\n            uint32_t tag = strtol(codec_tag, &next, 0);\n\n            if (*next)\n\n                tag = AV_RL32(codec_tag);\n\n            st->codec->codec_tag = tag;\n\n        }\n\n\n\n        ist->dec = choose_decoder(o, ic, st);\n\n        ist->opts = filter_codec_opts(o->g->codec_opts, ist->st->codec->codec_id, ic, st, ist->dec);\n\n\n\n        ist->reinit_filters = -1;\n\n        MATCH_PER_STREAM_OPT(reinit_filters, i, ist->reinit_filters, ic, st);\n\n\n\n        ist->filter_in_rescale_delta_last = AV_NOPTS_VALUE;\n\n\n\n        switch (dec->codec_type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if(!ist->dec)\n\n                ist->dec = avcodec_find_decoder(dec->codec_id);\n\n            if (dec->lowres) {\n\n                dec->flags |= CODEC_FLAG_EMU_EDGE;\n\n            }\n\n\n\n            ist->resample_height  = dec->height;\n\n            ist->resample_width   = dec->width;\n\n            ist->resample_pix_fmt = dec->pix_fmt;\n\n\n\n            MATCH_PER_STREAM_OPT(frame_rates, str, framerate, ic, st);\n\n            if (framerate && av_parse_video_rate(&ist->framerate,\n\n                                                 framerate) < 0) {\n\n                av_log(NULL, AV_LOG_ERROR, \"Error parsing framerate %s.\\n\",\n\n                       framerate);\n\n                exit(1);\n\n            }\n\n\n\n            ist->top_field_first = -1;\n\n            MATCH_PER_STREAM_OPT(top_field_first, i, ist->top_field_first, ic, st);\n\n\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ist->guess_layout_max = INT_MAX;\n\n            MATCH_PER_STREAM_OPT(guess_layout_max, i, ist->guess_layout_max, ic, st);\n\n            guess_input_channel_layout(ist);\n\n\n\n            ist->resample_sample_fmt     = dec->sample_fmt;\n\n            ist->resample_sample_rate    = dec->sample_rate;\n\n            ist->resample_channels       = dec->channels;\n\n            ist->resample_channel_layout = dec->channel_layout;\n\n\n\n            break;\n\n        case AVMEDIA_TYPE_DATA:\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            if(!ist->dec)\n\n                ist->dec = avcodec_find_decoder(dec->codec_id);\n\n            MATCH_PER_STREAM_OPT(fix_sub_duration, i, ist->fix_sub_duration, ic, st);\n\n            break;\n\n        case AVMEDIA_TYPE_ATTACHMENT:\n\n        case AVMEDIA_TYPE_UNKNOWN:\n\n            break;\n\n        default:\n\n            abort();\n\n        }\n\n    }\n\n}\n", "idx": 11883, "_split": "valid", "_hash": "06cda51ad6515417ef0033ec5f3cabc7"}
{"project": "FFmpeg", "commit_id": "e48ded8551172b58a78f30303a81dfce125344e0", "target": 0, "func": "static av_cold int asink_init(AVFilterContext *ctx, void *opaque)\n\n{\n\n    BufferSinkContext *buf = ctx->priv;\n\n    AVABufferSinkParams *params = opaque;\n\n\n\n    if (params && params->sample_fmts) {\n\n        buf->sample_fmts = ff_copy_int_list(params->sample_fmts);\n\n        if (!buf->sample_fmts)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    if (params && params->sample_rates) {\n\n        buf->sample_rates = ff_copy_int_list(params->sample_rates);\n\n        if (!buf->sample_rates)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    if (params && (params->channel_layouts || params->channel_counts)) {\n\n        if (params->all_channel_counts) {\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Conflicting all_channel_counts and list in parameters\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        buf->channel_layouts = concat_channels_lists(params->channel_layouts,\n\n                                                     params->channel_counts);\n\n        if (!buf->channel_layouts)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    if (params)\n\n        buf->all_channel_counts = params->all_channel_counts;\n\n    return common_init(ctx);\n\n}\n", "idx": 11895, "_split": "valid", "_hash": "703f13f6f5254358c42731465cab5655"}
{"project": "FFmpeg", "commit_id": "9a2e79116d6235c53d8e9663a8d30d1950d7431a", "target": 1, "func": "static int rv30_decode_intra_types(RV34DecContext *r, GetBitContext *gb, int8_t *dst)\n\n{\n\n    int i, j, k;\n\n\n\n    for(i = 0; i < 4; i++, dst += r->intra_types_stride - 4){\n\n        for(j = 0; j < 4; j+= 2){\n\n            int code = svq3_get_ue_golomb(gb) << 1;\n\n            if(code >= 81*2){\n\n                av_log(r->s.avctx, AV_LOG_ERROR, \"Incorrect intra prediction code\\n\");\n\n                return -1;\n\n            }\n\n            for(k = 0; k < 2; k++){\n\n                int A = dst[-r->intra_types_stride] + 1;\n\n                int B = dst[-1] + 1;\n\n                *dst++ = rv30_itype_from_context[A * 90 + B * 9 + rv30_itype_code[code + k]];\n\n                if(dst[-1] == 9){\n\n                    av_log(r->s.avctx, AV_LOG_ERROR, \"Incorrect intra prediction mode\\n\");\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 11927, "_split": "valid", "_hash": "978df0da6f8ac019599cac217e49557f"}
{"project": "FFmpeg", "commit_id": "8745e9c45865a4409272d78db1e1af86a8b955e9", "target": 0, "func": "static av_cold int set_channel_info(AC3EncodeContext *s, int channels,\n\n                                    int64_t *channel_layout)\n\n{\n\n    int ch_layout;\n\n\n\n    if (channels < 1 || channels > AC3_MAX_CHANNELS)\n\n        return AVERROR(EINVAL);\n\n    if ((uint64_t)*channel_layout > 0x7FF)\n\n        return AVERROR(EINVAL);\n\n    ch_layout = *channel_layout;\n\n    if (!ch_layout)\n\n        ch_layout = avcodec_guess_channel_layout(channels, CODEC_ID_AC3, NULL);\n\n    if (av_get_channel_layout_nb_channels(ch_layout) != channels)\n\n        return AVERROR(EINVAL);\n\n\n\n    s->lfe_on       = !!(ch_layout & AV_CH_LOW_FREQUENCY);\n\n    s->channels     = channels;\n\n    s->fbw_channels = channels - s->lfe_on;\n\n    s->lfe_channel  = s->lfe_on ? s->fbw_channels : -1;\n\n    if (s->lfe_on)\n\n        ch_layout -= AV_CH_LOW_FREQUENCY;\n\n\n\n    switch (ch_layout) {\n\n    case AV_CH_LAYOUT_MONO:           s->channel_mode = AC3_CHMODE_MONO;   break;\n\n    case AV_CH_LAYOUT_STEREO:         s->channel_mode = AC3_CHMODE_STEREO; break;\n\n    case AV_CH_LAYOUT_SURROUND:       s->channel_mode = AC3_CHMODE_3F;     break;\n\n    case AV_CH_LAYOUT_2_1:            s->channel_mode = AC3_CHMODE_2F1R;   break;\n\n    case AV_CH_LAYOUT_4POINT0:        s->channel_mode = AC3_CHMODE_3F1R;   break;\n\n    case AV_CH_LAYOUT_QUAD:\n\n    case AV_CH_LAYOUT_2_2:            s->channel_mode = AC3_CHMODE_2F2R;   break;\n\n    case AV_CH_LAYOUT_5POINT0:\n\n    case AV_CH_LAYOUT_5POINT0_BACK:   s->channel_mode = AC3_CHMODE_3F2R;   break;\n\n    default:\n\n        return AVERROR(EINVAL);\n\n    }\n\n    s->has_center   = (s->channel_mode & 0x01) && s->channel_mode != AC3_CHMODE_MONO;\n\n    s->has_surround =  s->channel_mode & 0x04;\n\n\n\n    s->channel_map  = ff_ac3_enc_channel_map[s->channel_mode][s->lfe_on];\n\n    *channel_layout = ch_layout;\n\n    if (s->lfe_on)\n\n        *channel_layout |= AV_CH_LOW_FREQUENCY;\n\n\n\n    return 0;\n\n}\n", "idx": 11941, "_split": "valid", "_hash": "b687477cfb1f122624a5664ab5af39e8"}
{"project": "FFmpeg", "commit_id": "10f865c9b753c296055c3d86060bd98411fb4f68", "target": 0, "func": "static int cinepak_decode (CinepakContext *s)\n\n{\n\n    uint8_t      *eod = (s->data + s->size);\n\n    int           i, result, strip_size, frame_flags, num_strips;\n\n    int           y0 = 0;\n\n    int           encoded_buf_size;\n\n    /* if true, Cinepak data is from a Sega FILM/CPK file */\n\n    int           sega_film_data = 0;\n\n\n\n    if (s->size < 10)\n\n        return -1;\n\n\n\n    frame_flags = s->data[0];\n\n    num_strips  = BE_16 (&s->data[8]);\n\n    encoded_buf_size = ((s->data[1] << 16) | BE_16 (&s->data[2]));\n\n    if (encoded_buf_size != s->size)\n\n        sega_film_data = 1;\n\n    if (sega_film_data)\n\n        s->data    += 12;\n\n    else\n\n        s->data    += 10;\n\n\n\n    if (num_strips > MAX_STRIPS)\n\n        num_strips = MAX_STRIPS;\n\n\n\n    for (i=0; i < num_strips; i++) {\n\n        if ((s->data + 12) > eod)\n\n            return -1;\n\n\n\n        s->strips[i].id = BE_16 (s->data);\n\n        s->strips[i].y1 = y0;\n\n        s->strips[i].x1 = 0;\n\n        s->strips[i].y2 = y0 + BE_16 (&s->data[8]);\n\n        s->strips[i].x2 = s->avctx->width;\n\n\n\n        strip_size = BE_16 (&s->data[2]) - 12;\n\n        s->data   += 12;\n\n        strip_size = ((s->data + strip_size) > eod) ? (eod - s->data) : strip_size;\n\n\n\n        if ((i > 0) && !(frame_flags & 0x01)) {\n\n            memcpy (s->strips[i].v4_codebook, s->strips[i-1].v4_codebook,\n\n                sizeof(s->strips[i].v4_codebook));\n\n            memcpy (s->strips[i].v1_codebook, s->strips[i-1].v1_codebook,\n\n                sizeof(s->strips[i].v1_codebook));\n\n        }\n\n\n\n        result = cinepak_decode_strip (s, &s->strips[i], s->data, strip_size);\n\n\n\n        if (result != 0)\n\n            return result;\n\n\n\n        s->data += strip_size;\n\n        y0    = s->strips[i].y2;\n\n    }\n\n    return 0;\n\n}\n", "idx": 11981, "_split": "valid", "_hash": "fe17146bedd8e2629339d6e6f030bbb9"}
{"project": "FFmpeg", "commit_id": "8f3a9603538b8633fb873fcee7ffcec72e849c42", "target": 0, "func": "int configure_filtergraph(FilterGraph *fg)\n\n{\n\n    AVFilterInOut *inputs, *outputs, *cur;\n\n    int ret, i, simple = !fg->graph_desc;\n\n    const char *graph_desc = simple ? fg->outputs[0]->ost->avfilter :\n\n                                      fg->graph_desc;\n\n\n\n    avfilter_graph_free(&fg->graph);\n\n    if (!(fg->graph = avfilter_graph_alloc()))\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (simple) {\n\n        OutputStream *ost = fg->outputs[0]->ost;\n\n        char args[512];\n\n        AVDictionaryEntry *e = NULL;\n\n\n\n        args[0] = 0;\n\n        while ((e = av_dict_get(ost->sws_dict, \"\", e,\n\n                                AV_DICT_IGNORE_SUFFIX))) {\n\n            av_strlcatf(args, sizeof(args), \"%s=%s:\", e->key, e->value);\n\n        }\n\n        if (strlen(args))\n\n            args[strlen(args)-1] = 0;\n\n        fg->graph->scale_sws_opts = av_strdup(args);\n\n\n\n        args[0] = 0;\n\n        while ((e = av_dict_get(ost->swr_opts, \"\", e,\n\n                                AV_DICT_IGNORE_SUFFIX))) {\n\n            av_strlcatf(args, sizeof(args), \"%s=%s:\", e->key, e->value);\n\n        }\n\n        if (strlen(args))\n\n            args[strlen(args)-1] = 0;\n\n        av_opt_set(fg->graph, \"aresample_swr_opts\", args, 0);\n\n\n\n        args[0] = '\\0';\n\n        while ((e = av_dict_get(fg->outputs[0]->ost->resample_opts, \"\", e,\n\n                                AV_DICT_IGNORE_SUFFIX))) {\n\n            av_strlcatf(args, sizeof(args), \"%s=%s:\", e->key, e->value);\n\n        }\n\n        if (strlen(args))\n\n            args[strlen(args) - 1] = '\\0';\n\n        fg->graph->resample_lavr_opts = av_strdup(args);\n\n\n\n        e = av_dict_get(ost->encoder_opts, \"threads\", NULL, 0);\n\n        if (e)\n\n            av_opt_set(fg->graph, \"threads\", e->value, 0);\n\n    }\n\n\n\n    if ((ret = avfilter_graph_parse2(fg->graph, graph_desc, &inputs, &outputs)) < 0)\n\n        return ret;\n\n\n\n    if (simple && (!inputs || inputs->next || !outputs || outputs->next)) {\n\n        const char *num_inputs;\n\n        const char *num_outputs;\n\n        if (!outputs) {\n\n            num_outputs = \"0\";\n\n        } else if (outputs->next) {\n\n            num_outputs = \">1\";\n\n        } else {\n\n            num_outputs = \"1\";\n\n        }\n\n        if (!inputs) {\n\n            num_inputs = \"0\";\n\n        } else if (inputs->next) {\n\n            num_inputs = \">1\";\n\n        } else {\n\n            num_inputs = \"1\";\n\n        }\n\n        av_log(NULL, AV_LOG_ERROR, \"Simple filtergraph '%s' was expected \"\n\n               \"to have exactly 1 input and 1 output.\"\n\n               \" However, it had %s input(s) and %s output(s).\"\n\n               \" Please adjust, or use a complex filtergraph (-filter_complex) instead.\\n\",\n\n               graph_desc, num_inputs, num_outputs);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    for (cur = inputs, i = 0; cur; cur = cur->next, i++)\n\n        if ((ret = configure_input_filter(fg, fg->inputs[i], cur)) < 0) {\n\n            avfilter_inout_free(&inputs);\n\n            avfilter_inout_free(&outputs);\n\n            return ret;\n\n        }\n\n    avfilter_inout_free(&inputs);\n\n\n\n    for (cur = outputs, i = 0; cur; cur = cur->next, i++)\n\n        configure_output_filter(fg, fg->outputs[i], cur);\n\n    avfilter_inout_free(&outputs);\n\n\n\n    if ((ret = avfilter_graph_config(fg->graph, NULL)) < 0)\n\n        return ret;\n\n\n\n    fg->reconfiguration = 1;\n\n\n\n    for (i = 0; i < fg->nb_outputs; i++) {\n\n        OutputStream *ost = fg->outputs[i]->ost;\n\n        if (!ost->enc) {\n\n            /* identical to the same check in ffmpeg.c, needed because\n\n               complex filter graphs are initialized earlier */\n\n            av_log(NULL, AV_LOG_ERROR, \"Encoder (codec %s) not found for output stream #%d:%d\\n\",\n\n                     avcodec_get_name(ost->st->codec->codec_id), ost->file_index, ost->index);\n\n            return AVERROR(EINVAL);\n\n        }\n\n        if (ost &&\n\n            ost->enc->type == AVMEDIA_TYPE_AUDIO &&\n\n            !(ost->enc->capabilities & AV_CODEC_CAP_VARIABLE_FRAME_SIZE))\n\n            av_buffersink_set_frame_size(ost->filter->filter,\n\n                                         ost->enc_ctx->frame_size);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 12006, "_split": "valid", "_hash": "73902181eb4e133eebeb7f4382c1a80d"}
{"project": "FFmpeg", "commit_id": "e767c9e8f2eaa116b61b8b6881b401b54bd320f5", "target": 1, "func": "static int flv_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVIOContext *pb      = s->pb;\n\n    AVCodecContext *enc  = s->streams[pkt->stream_index]->codec;\n\n    FLVContext *flv      = s->priv_data;\n\n    FLVStreamContext *sc = s->streams[pkt->stream_index]->priv_data;\n\n    unsigned ts;\n\n    int size = pkt->size;\n\n    uint8_t *data = NULL;\n\n    int flags = 0, flags_size;\n\n\n\n    if (enc->codec_id == AV_CODEC_ID_VP6F || enc->codec_id == AV_CODEC_ID_VP6A ||\n\n        enc->codec_id == AV_CODEC_ID_AAC)\n\n        flags_size = 2;\n\n    else if (enc->codec_id == AV_CODEC_ID_H264)\n\n        flags_size = 5;\n\n    else\n\n        flags_size = 1;\n\n\n\n    if (flv->delay == AV_NOPTS_VALUE)\n\n        flv->delay = -pkt->dts;\n\n\n\n    if (pkt->dts < -flv->delay) {\n\n        av_log(s, AV_LOG_WARNING,\n\n               \"Packets are not in the proper order with respect to DTS\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    ts = pkt->dts + flv->delay; // add delay to force positive dts\n\n\n\n    if (s->event_flags & AVSTREAM_EVENT_FLAG_METADATA_UPDATED) {\n\n        write_metadata(s, ts);\n\n        s->event_flags &= ~AVSTREAM_EVENT_FLAG_METADATA_UPDATED;\n\n    }\n\n\n\n    switch (enc->codec_type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        avio_w8(pb, FLV_TAG_TYPE_VIDEO);\n\n\n\n        flags = enc->codec_tag;\n\n        if (flags == 0) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"video codec %X not compatible with flv\\n\",\n\n                   enc->codec_id);\n\n            return -1;\n\n        }\n\n\n\n        flags |= pkt->flags & AV_PKT_FLAG_KEY ? FLV_FRAME_KEY : FLV_FRAME_INTER;\n\n        break;\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        flags = get_audio_flags(s, enc);\n\n\n\n        assert(size);\n\n\n\n        avio_w8(pb, FLV_TAG_TYPE_AUDIO);\n\n        break;\n\n    case AVMEDIA_TYPE_DATA:\n\n        avio_w8(pb, FLV_TAG_TYPE_META);\n\n        break;\n\n    default:\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (enc->codec_id == AV_CODEC_ID_H264)\n\n        /* check if extradata looks like MP4 */\n\n        if (enc->extradata_size > 0 && *(uint8_t*)enc->extradata != 1)\n\n            if (ff_avc_parse_nal_units_buf(pkt->data, &data, &size) < 0)\n\n                return -1;\n\n\n\n    /* check Speex packet duration */\n\n    if (enc->codec_id == AV_CODEC_ID_SPEEX && ts - sc->last_ts > 160)\n\n        av_log(s, AV_LOG_WARNING, \"Warning: Speex stream has more than \"\n\n                                  \"8 frames per packet. Adobe Flash \"\n\n                                  \"Player cannot handle this!\\n\");\n\n\n\n    if (sc->last_ts < ts)\n\n        sc->last_ts = ts;\n\n\n\n    avio_wb24(pb, size + flags_size);\n\n    avio_wb24(pb, ts);\n\n    avio_w8(pb, (ts >> 24) & 0x7F); // timestamps are 32 bits _signed_\n\n    avio_wb24(pb, flv->reserved);\n\n\n\n    if (enc->codec_type == AVMEDIA_TYPE_DATA) {\n\n        int data_size;\n\n        int64_t metadata_size_pos = avio_tell(pb);\n\n        avio_w8(pb, AMF_DATA_TYPE_STRING);\n\n        put_amf_string(pb, \"onTextData\");\n\n        avio_w8(pb, AMF_DATA_TYPE_MIXEDARRAY);\n\n        avio_wb32(pb, 2);\n\n        put_amf_string(pb, \"type\");\n\n        avio_w8(pb, AMF_DATA_TYPE_STRING);\n\n        put_amf_string(pb, \"Text\");\n\n        put_amf_string(pb, \"text\");\n\n        avio_w8(pb, AMF_DATA_TYPE_STRING);\n\n        put_amf_string(pb, pkt->data);\n\n        put_amf_string(pb, \"\");\n\n        avio_w8(pb, AMF_END_OF_OBJECT);\n\n        /* write total size of tag */\n\n        data_size = avio_tell(pb) - metadata_size_pos;\n\n        avio_seek(pb, metadata_size_pos - 10, SEEK_SET);\n\n        avio_wb24(pb, data_size);\n\n        avio_seek(pb, data_size + 10 - 3, SEEK_CUR);\n\n        avio_wb32(pb, data_size + 11);\n\n    } else {\n\n        avio_w8(pb,flags);\n\n        if (enc->codec_id == AV_CODEC_ID_VP6F || enc->codec_id == AV_CODEC_ID_VP6A) {\n\n            if (enc->extradata_size)\n\n                avio_w8(pb, enc->extradata[0]);\n\n            else\n\n                avio_w8(pb, ((FFALIGN(enc->width,  16) - enc->width) << 4) |\n\n                             (FFALIGN(enc->height, 16) - enc->height));\n\n        } else if (enc->codec_id == AV_CODEC_ID_AAC)\n\n            avio_w8(pb, 1); // AAC raw\n\n        else if (enc->codec_id == AV_CODEC_ID_H264) {\n\n            avio_w8(pb, 1); // AVC NALU\n\n            avio_wb24(pb, pkt->pts - pkt->dts);\n\n        }\n\n\n\n        avio_write(pb, data ? data : pkt->data, size);\n\n\n\n        avio_wb32(pb, size + flags_size + 11); // previous tag size\n\n        flv->duration = FFMAX(flv->duration,\n\n                              pkt->pts + flv->delay + pkt->duration);\n\n    }\n\n\n\n    av_free(data);\n\n\n\n    return pb->error;\n\n}\n", "idx": 12055, "_split": "valid", "_hash": "1c155d2f48617932cdbd492086007be5"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "matroska_probe (AVProbeData *p)\n\n{\n\n    uint64_t total = 0;\n\n    int len_mask = 0x80, size = 1, n = 1;\n\n    uint8_t probe_data[] = { 'm', 'a', 't', 'r', 'o', 's', 'k', 'a' };\n\n\n\n    if (p->buf_size < 5)\n\n        return 0;\n\n\n\n    /* ebml header? */\n\n    if ((p->buf[0] << 24 | p->buf[1] << 16 |\n\n         p->buf[2] << 8 | p->buf[3]) != EBML_ID_HEADER)\n\n        return 0;\n\n\n\n    /* length of header */\n\n    total = p->buf[4];\n\n    while (size <= 8 && !(total & len_mask)) {\n\n        size++;\n\n        len_mask >>= 1;\n\n    }\n\n    if (size > 8)\n\n      return 0;\n\n    total &= (len_mask - 1);\n\n    while (n < size)\n\n        total = (total << 8) | p->buf[4 + n++];\n\n\n\n    /* does the probe data contain the whole header? */\n\n    if (p->buf_size < 4 + size + total)\n\n      return 0;\n\n\n\n    /* the header must contain the document type 'matroska'. For now,\n\n     * we don't parse the whole header but simply check for the\n\n     * availability of that array of characters inside the header.\n\n     * Not fully fool-proof, but good enough. */\n\n    for (n = 4 + size; n <= 4 + size + total - sizeof(probe_data); n++)\n\n        if (!memcmp (&p->buf[n], probe_data, sizeof(probe_data)))\n\n            return AVPROBE_SCORE_MAX;\n\n\n\n    return 0;\n\n}\n", "idx": 12056, "_split": "valid", "_hash": "b804070f4062dc9769910a9e3b4046ea"}
{"project": "FFmpeg", "commit_id": "8a0d446ad618ff89e2e212beb7e6ebee125a85a4", "target": 1, "func": "static int siff_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    SIFFContext *c = s->priv_data;\n\n    int size;\n\n\n\n    if (c->has_video){\n\n        if (c->cur_frame >= c->frames)\n\n            return AVERROR_EOF;\n\n        if (c->curstrm == -1){\n\n            c->pktsize = avio_rl32(s->pb) - 4;\n\n            c->flags = avio_rl16(s->pb);\n\n            c->gmcsize = (c->flags & VB_HAS_GMC) ? 4 : 0;\n\n            if (c->gmcsize)\n\n                avio_read(s->pb, c->gmc, c->gmcsize);\n\n            c->sndsize = (c->flags & VB_HAS_AUDIO) ? avio_rl32(s->pb): 0;\n\n            c->curstrm = !!(c->flags & VB_HAS_AUDIO);\n\n        }\n\n\n\n        if (!c->curstrm){\n\n            size = c->pktsize - c->sndsize - c->gmcsize - 2;\n\n            size = ffio_limit(s->pb, size);\n\n            if(size < 0 || c->pktsize < c->sndsize)\n\n                return AVERROR_INVALIDDATA;\n\n            if (av_new_packet(pkt, size + c->gmcsize + 2) < 0)\n\n                return AVERROR(ENOMEM);\n\n            AV_WL16(pkt->data, c->flags);\n\n            if (c->gmcsize)\n\n                memcpy(pkt->data + 2, c->gmc, c->gmcsize);\n\n            avio_read(s->pb, pkt->data + 2 + c->gmcsize, size);\n\n            pkt->stream_index = 0;\n\n            c->curstrm = -1;\n\n        }else{\n\n            if ((size = av_get_packet(s->pb, pkt, c->sndsize - 4)) < 0)\n\n                return AVERROR(EIO);\n\n            pkt->stream_index = 1;\n\n            pkt->duration     = size;\n\n            c->curstrm = 0;\n\n        }\n\n        if(!c->cur_frame || c->curstrm)\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n        if (c->curstrm == -1)\n\n            c->cur_frame++;\n\n    }else{\n\n        size = av_get_packet(s->pb, pkt, c->block_align);\n\n        if(!size)\n\n            return AVERROR_EOF;\n\n        if(size < 0)\n\n            return AVERROR(EIO);\n\n        pkt->duration = size;\n\n    }\n\n    return pkt->size;\n\n}\n", "idx": 12068, "_split": "valid", "_hash": "eb1f34bf92ea53b3899bfcd7db1f1dc9"}
{"project": "FFmpeg", "commit_id": "8bedbb82cee4463a43e60eb22674c8bf927280ef", "target": 1, "func": "static void dequantization_float(int x, int y, Jpeg2000Cblk *cblk,\n\n                                 Jpeg2000Component *comp,\n\n                                 Jpeg2000T1Context *t1, Jpeg2000Band *band)\n\n{\n\n    int i, j, idx;\n\n    float *datap = &comp->data[(comp->coord[0][1] - comp->coord[0][0]) * y + x];\n\n    for (j = 0; j < (cblk->coord[1][1] - cblk->coord[1][0]); ++j)\n\n        for (i = 0; i < (cblk->coord[0][1] - cblk->coord[0][0]); ++i) {\n\n            idx        = (comp->coord[0][1] - comp->coord[0][0]) * j + i;\n\n            datap[idx] = (float)(t1->data[j][i]) * band->f_stepsize;\n\n        }\n\n}\n", "idx": 12082, "_split": "valid", "_hash": "d16c0a17a36b321c805b5214baf9bc4b"}
{"project": "FFmpeg", "commit_id": "f8bed30d8b176fa030f6737765338bb4a2bcabc9", "target": 0, "func": "av_cold void ff_vc1dsp_init(VC1DSPContext* dsp) {\n\n    dsp->vc1_inv_trans_8x8 = vc1_inv_trans_8x8_c;\n\n    dsp->vc1_inv_trans_4x8 = vc1_inv_trans_4x8_c;\n\n    dsp->vc1_inv_trans_8x4 = vc1_inv_trans_8x4_c;\n\n    dsp->vc1_inv_trans_4x4 = vc1_inv_trans_4x4_c;\n\n    dsp->vc1_inv_trans_8x8_dc = vc1_inv_trans_8x8_dc_c;\n\n    dsp->vc1_inv_trans_4x8_dc = vc1_inv_trans_4x8_dc_c;\n\n    dsp->vc1_inv_trans_8x4_dc = vc1_inv_trans_8x4_dc_c;\n\n    dsp->vc1_inv_trans_4x4_dc = vc1_inv_trans_4x4_dc_c;\n\n    dsp->vc1_h_overlap = vc1_h_overlap_c;\n\n    dsp->vc1_v_overlap = vc1_v_overlap_c;\n\n    dsp->vc1_v_loop_filter4 = vc1_v_loop_filter4_c;\n\n    dsp->vc1_h_loop_filter4 = vc1_h_loop_filter4_c;\n\n    dsp->vc1_v_loop_filter8 = vc1_v_loop_filter8_c;\n\n    dsp->vc1_h_loop_filter8 = vc1_h_loop_filter8_c;\n\n    dsp->vc1_v_loop_filter16 = vc1_v_loop_filter16_c;\n\n    dsp->vc1_h_loop_filter16 = vc1_h_loop_filter16_c;\n\n\n\n    dsp->put_vc1_mspel_pixels_tab[ 0] = ff_put_pixels8x8_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 1] = put_vc1_mspel_mc10_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 2] = put_vc1_mspel_mc20_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 3] = put_vc1_mspel_mc30_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 4] = put_vc1_mspel_mc01_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 5] = put_vc1_mspel_mc11_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 6] = put_vc1_mspel_mc21_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 7] = put_vc1_mspel_mc31_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 8] = put_vc1_mspel_mc02_c;\n\n    dsp->put_vc1_mspel_pixels_tab[ 9] = put_vc1_mspel_mc12_c;\n\n    dsp->put_vc1_mspel_pixels_tab[10] = put_vc1_mspel_mc22_c;\n\n    dsp->put_vc1_mspel_pixels_tab[11] = put_vc1_mspel_mc32_c;\n\n    dsp->put_vc1_mspel_pixels_tab[12] = put_vc1_mspel_mc03_c;\n\n    dsp->put_vc1_mspel_pixels_tab[13] = put_vc1_mspel_mc13_c;\n\n    dsp->put_vc1_mspel_pixels_tab[14] = put_vc1_mspel_mc23_c;\n\n    dsp->put_vc1_mspel_pixels_tab[15] = put_vc1_mspel_mc33_c;\n\n\n\n    dsp->avg_vc1_mspel_pixels_tab[ 0] = ff_avg_pixels8x8_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 1] = avg_vc1_mspel_mc10_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 2] = avg_vc1_mspel_mc20_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 3] = avg_vc1_mspel_mc30_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 4] = avg_vc1_mspel_mc01_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 5] = avg_vc1_mspel_mc11_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 6] = avg_vc1_mspel_mc21_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 7] = avg_vc1_mspel_mc31_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 8] = avg_vc1_mspel_mc02_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[ 9] = avg_vc1_mspel_mc12_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[10] = avg_vc1_mspel_mc22_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[11] = avg_vc1_mspel_mc32_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[12] = avg_vc1_mspel_mc03_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[13] = avg_vc1_mspel_mc13_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[14] = avg_vc1_mspel_mc23_c;\n\n    dsp->avg_vc1_mspel_pixels_tab[15] = avg_vc1_mspel_mc33_c;\n\n\n\n    dsp->put_no_rnd_vc1_chroma_pixels_tab[0]= put_no_rnd_vc1_chroma_mc8_c;\n\n    dsp->avg_no_rnd_vc1_chroma_pixels_tab[0]= avg_no_rnd_vc1_chroma_mc8_c;\n\n\n\n    if (HAVE_ALTIVEC)\n\n        ff_vc1dsp_init_altivec(dsp);\n\n    if (HAVE_MMX)\n\n        ff_vc1dsp_init_mmx(dsp);\n\n}\n", "idx": 12098, "_split": "valid", "_hash": "c870bb1e0c3482491af50962ef57e5ac"}
{"project": "FFmpeg", "commit_id": "d6737539e77e78fca9a04914d51996cfd1ccc55c", "target": 0, "func": "static void intra_predict_vert_8x8_msa(uint8_t *src, uint8_t *dst,\n\n                                       int32_t dst_stride)\n\n{\n\n    uint32_t row;\n\n    uint32_t src_data1, src_data2;\n\n\n\n    src_data1 = LW(src);\n\n    src_data2 = LW(src + 4);\n\n\n\n    for (row = 8; row--;) {\n\n        SW(src_data1, dst);\n\n        SW(src_data2, (dst + 4));\n\n        dst += dst_stride;\n\n    }\n\n}\n", "idx": 12101, "_split": "valid", "_hash": "fc9a474935484e0d939f1ae42ea6ed38"}
{"project": "FFmpeg", "commit_id": "196b885a5f0aa3ca022c1fa99509f47341239784", "target": 0, "func": "static int swr_convert_internal(struct SwrContext *s, AudioData *out, int out_count,\n\n                                                      AudioData *in , int  in_count){\n\n    AudioData *postin, *midbuf, *preout;\n\n    int ret/*, in_max*/;\n\n    AudioData preout_tmp, midbuf_tmp;\n\n\n\n    if(s->full_convert){\n\n        av_assert0(!s->resample);\n\n        swri_audio_convert(s->full_convert, out, in, in_count);\n\n        return out_count;\n\n    }\n\n\n\n//     in_max= out_count*(int64_t)s->in_sample_rate / s->out_sample_rate + resample_filter_taps;\n\n//     in_count= FFMIN(in_count, in_in + 2 - s->hist_buffer_count);\n\n\n\n    if((ret=swri_realloc_audio(&s->postin, in_count))<0)\n\n        return ret;\n\n    if(s->resample_first){\n\n        av_assert0(s->midbuf.ch_count == s->used_ch_count);\n\n        if((ret=swri_realloc_audio(&s->midbuf, out_count))<0)\n\n            return ret;\n\n    }else{\n\n        av_assert0(s->midbuf.ch_count ==  s->out.ch_count);\n\n        if((ret=swri_realloc_audio(&s->midbuf,  in_count))<0)\n\n            return ret;\n\n    }\n\n    if((ret=swri_realloc_audio(&s->preout, out_count))<0)\n\n        return ret;\n\n\n\n    postin= &s->postin;\n\n\n\n    midbuf_tmp= s->midbuf;\n\n    midbuf= &midbuf_tmp;\n\n    preout_tmp= s->preout;\n\n    preout= &preout_tmp;\n\n\n\n    if(s->int_sample_fmt == s-> in_sample_fmt && s->in.planar && !s->channel_map)\n\n        postin= in;\n\n\n\n    if(s->resample_first ? !s->resample : !s->rematrix)\n\n        midbuf= postin;\n\n\n\n    if(s->resample_first ? !s->rematrix : !s->resample)\n\n        preout= midbuf;\n\n\n\n    if(s->int_sample_fmt == s->out_sample_fmt && s->out.planar\n\n       && !(s->out_sample_fmt==AV_SAMPLE_FMT_S32P && (s->dither.output_sample_bits&31))){\n\n        if(preout==in){\n\n            out_count= FFMIN(out_count, in_count); //TODO check at the end if this is needed or redundant\n\n            av_assert0(s->in.planar); //we only support planar internally so it has to be, we support copying non planar though\n\n            copy(out, in, out_count);\n\n            return out_count;\n\n        }\n\n        else if(preout==postin) preout= midbuf= postin= out;\n\n        else if(preout==midbuf) preout= midbuf= out;\n\n        else                    preout= out;\n\n    }\n\n\n\n    if(in != postin){\n\n        swri_audio_convert(s->in_convert, postin, in, in_count);\n\n    }\n\n\n\n    if(s->resample_first){\n\n        if(postin != midbuf)\n\n            out_count= resample(s, midbuf, out_count, postin, in_count);\n\n        if(midbuf != preout)\n\n            swri_rematrix(s, preout, midbuf, out_count, preout==out);\n\n    }else{\n\n        if(postin != midbuf)\n\n            swri_rematrix(s, midbuf, postin, in_count, midbuf==out);\n\n        if(midbuf != preout)\n\n            out_count= resample(s, preout, out_count, midbuf, in_count);\n\n    }\n\n\n\n    if(preout != out && out_count){\n\n        AudioData *conv_src = preout;\n\n        if(s->dither.method){\n\n            int ch;\n\n            int dither_count= FFMAX(out_count, 1<<16);\n\n\n\n            if (preout == in) {\n\n                conv_src = &s->dither.temp;\n\n                if((ret=swri_realloc_audio(&s->dither.temp, dither_count))<0)\n\n                    return ret;\n\n            }\n\n\n\n            if((ret=swri_realloc_audio(&s->dither.noise, dither_count))<0)\n\n                return ret;\n\n            if(ret)\n\n                for(ch=0; ch<s->dither.noise.ch_count; ch++)\n\n                    swri_get_dither(s, s->dither.noise.ch[ch], s->dither.noise.count, 12345678913579<<ch, s->dither.noise.fmt);\n\n            av_assert0(s->dither.noise.ch_count == preout->ch_count);\n\n\n\n            if(s->dither.noise_pos + out_count > s->dither.noise.count)\n\n                s->dither.noise_pos = 0;\n\n\n\n            if (s->dither.method < SWR_DITHER_NS){\n\n                if (s->mix_2_1_simd) {\n\n                    int len1= out_count&~15;\n\n                    int off = len1 * preout->bps;\n\n\n\n                    if(len1)\n\n                        for(ch=0; ch<preout->ch_count; ch++)\n\n                            s->mix_2_1_simd(conv_src->ch[ch], preout->ch[ch], s->dither.noise.ch[ch] + s->dither.noise.bps * s->dither.noise_pos, s->native_simd_one, 0, 0, len1);\n\n                    if(out_count != len1)\n\n                        for(ch=0; ch<preout->ch_count; ch++)\n\n                            s->mix_2_1_f(conv_src->ch[ch] + off, preout->ch[ch] + off, s->dither.noise.ch[ch] + s->dither.noise.bps * s->dither.noise_pos + off + len1, s->native_one, 0, 0, out_count - len1);\n\n                } else {\n\n                    for(ch=0; ch<preout->ch_count; ch++)\n\n                        s->mix_2_1_f(conv_src->ch[ch], preout->ch[ch], s->dither.noise.ch[ch] + s->dither.noise.bps * s->dither.noise_pos, s->native_one, 0, 0, out_count);\n\n                }\n\n            } else {\n\n                switch(s->int_sample_fmt) {\n\n                case AV_SAMPLE_FMT_S16P :swri_noise_shaping_int16(s, conv_src, preout, &s->dither.noise, out_count); break;\n\n                case AV_SAMPLE_FMT_S32P :swri_noise_shaping_int32(s, conv_src, preout, &s->dither.noise, out_count); break;\n\n                case AV_SAMPLE_FMT_FLTP :swri_noise_shaping_float(s, conv_src, preout, &s->dither.noise, out_count); break;\n\n                case AV_SAMPLE_FMT_DBLP :swri_noise_shaping_double(s,conv_src, preout, &s->dither.noise, out_count); break;\n\n                }\n\n            }\n\n            s->dither.noise_pos += out_count;\n\n        }\n\n//FIXME packed doesn't need more than 1 chan here!\n\n        swri_audio_convert(s->out_convert, out, conv_src, out_count);\n\n    }\n\n    return out_count;\n\n}\n", "idx": 12117, "_split": "valid", "_hash": "ef9604a0a96736b5c8bb30cd66420cf4"}
{"project": "FFmpeg", "commit_id": "f5cf0ea93a55f43b553aa7d6698936e48c6a94df", "target": 1, "func": "static int asf_parse_packet(AVFormatContext *s, AVIOContext *pb, AVPacket *pkt)\n\n{\n\n    ASFContext *asf   = s->priv_data;\n\n    ASFStream *asf_st = 0;\n\n    for (;;) {\n\n        int ret;\n\n        if (url_feof(pb))\n\n            return AVERROR_EOF;\n\n\n\n        if (asf->packet_size_left < FRAME_HEADER_SIZE) {\n\n            int ret = asf->packet_size_left + asf->packet_padsize;\n\n\n\n            assert(ret >= 0);\n\n            /* fail safe */\n\n            avio_skip(pb, ret);\n\n\n\n            asf->packet_pos = avio_tell(pb);\n\n            if (asf->data_object_size != (uint64_t)-1 &&\n\n                (asf->packet_pos - asf->data_object_offset >= asf->data_object_size))\n\n                return AVERROR_EOF;  /* Do not exceed the size of the data object */\n\n            return 1;\n\n        }\n\n        if (asf->packet_time_start == 0) {\n\n            if (asf_read_frame_header(s, pb) < 0) {\n\n                asf->packet_time_start = asf->packet_segments = 0;\n\n                continue;\n\n            }\n\n            if (asf->stream_index < 0 ||\n\n                s->streams[asf->stream_index]->discard >= AVDISCARD_ALL ||\n\n                (!asf->packet_key_frame &&\n\n                 (s->streams[asf->stream_index]->discard >= AVDISCARD_NONKEY || asf->streams[s->streams[asf->stream_index]->id].skip_to_key))) {\n\n                asf->packet_time_start = 0;\n\n                /* unhandled packet (should not happen) */\n\n                avio_skip(pb, asf->packet_frag_size);\n\n                asf->packet_size_left -= asf->packet_frag_size;\n\n                if (asf->stream_index < 0)\n\n                    av_log(s, AV_LOG_ERROR, \"ff asf skip %d (unknown stream)\\n\",\n\n                           asf->packet_frag_size);\n\n                continue;\n\n            }\n\n            asf->asf_st = &asf->streams[s->streams[asf->stream_index]->id];\n\n            asf->asf_st->skip_to_key = 0;\n\n        }\n\n        asf_st = asf->asf_st;\n\n        av_assert0(asf_st);\n\n\n\n        if (asf->packet_replic_size == 1) {\n\n            // frag_offset is here used as the beginning timestamp\n\n            asf->packet_frag_timestamp = asf->packet_time_start;\n\n            asf->packet_time_start    += asf->packet_time_delta;\n\n            asf_st->packet_obj_size    = asf->packet_frag_size = avio_r8(pb);\n\n            asf->packet_size_left--;\n\n            asf->packet_multi_size--;\n\n            if (asf->packet_multi_size < asf_st->packet_obj_size) {\n\n                asf->packet_time_start = 0;\n\n                avio_skip(pb, asf->packet_multi_size);\n\n                asf->packet_size_left -= asf->packet_multi_size;\n\n                continue;\n\n            }\n\n            asf->packet_multi_size -= asf_st->packet_obj_size;\n\n        }\n\n\n\n        if (asf_st->pkt.size != asf_st->packet_obj_size ||\n\n            // FIXME is this condition sufficient?\n\n            asf_st->frag_offset + asf->packet_frag_size > asf_st->pkt.size) {\n\n            if (asf_st->pkt.data) {\n\n                av_log(s, AV_LOG_INFO,\n\n                       \"freeing incomplete packet size %d, new %d\\n\",\n\n                       asf_st->pkt.size, asf_st->packet_obj_size);\n\n                asf_st->frag_offset = 0;\n\n                av_free_packet(&asf_st->pkt);\n\n            }\n\n            /* new packet */\n\n            av_new_packet(&asf_st->pkt, asf_st->packet_obj_size);\n\n            asf_st->seq              = asf->packet_seq;\n\n            asf_st->pkt.dts          = asf->packet_frag_timestamp - asf->hdr.preroll;\n\n            asf_st->pkt.stream_index = asf->stream_index;\n\n            asf_st->pkt.pos          = asf_st->packet_pos = asf->packet_pos;\n\n\n\n\n            if (asf_st->pkt.data && asf_st->palette_changed) {\n\n                uint8_t *pal;\n\n                pal = av_packet_new_side_data(&asf_st->pkt, AV_PKT_DATA_PALETTE,\n\n                                              AVPALETTE_SIZE);\n\n                if (!pal) {\n\n                    av_log(s, AV_LOG_ERROR, \"Cannot append palette to packet\\n\");\n\n                } else {\n\n                    memcpy(pal, asf_st->palette, AVPALETTE_SIZE);\n\n                    asf_st->palette_changed = 0;\n\n                }\n\n            }\n\n            av_dlog(asf, \"new packet: stream:%d key:%d packet_key:%d audio:%d size:%d\\n\",\n\n                    asf->stream_index, asf->packet_key_frame,\n\n                    asf_st->pkt.flags & AV_PKT_FLAG_KEY,\n\n                    s->streams[asf->stream_index]->codec->codec_type == AVMEDIA_TYPE_AUDIO,\n\n                    asf_st->packet_obj_size);\n\n            if (s->streams[asf->stream_index]->codec->codec_type == AVMEDIA_TYPE_AUDIO)\n\n                asf->packet_key_frame = 1;\n\n            if (asf->packet_key_frame)\n\n                asf_st->pkt.flags |= AV_PKT_FLAG_KEY;\n\n        }\n\n\n\n        /* read data */\n\n        av_dlog(asf, \"READ PACKET s:%d  os:%d  o:%d,%d  l:%d   DATA:%p\\n\",\n\n                s->packet_size, asf_st->pkt.size, asf->packet_frag_offset,\n\n                asf_st->frag_offset, asf->packet_frag_size, asf_st->pkt.data);\n\n        asf->packet_size_left -= asf->packet_frag_size;\n\n        if (asf->packet_size_left < 0)\n\n            continue;\n\n\n\n        if (asf->packet_frag_offset >= asf_st->pkt.size ||\n\n            asf->packet_frag_size > asf_st->pkt.size - asf->packet_frag_offset) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"packet fragment position invalid %u,%u not in %u\\n\",\n\n                   asf->packet_frag_offset, asf->packet_frag_size,\n\n                   asf_st->pkt.size);\n\n            continue;\n\n        }\n\n\n\n        if (asf->packet_frag_offset != asf_st->frag_offset && !asf_st->pkt_clean) {\n\n            memset(asf_st->pkt.data + asf_st->frag_offset, 0, asf_st->pkt.size - asf_st->frag_offset);\n\n            asf_st->pkt_clean = 1;\n\n        }\n\n\n\n        ret = avio_read(pb, asf_st->pkt.data + asf->packet_frag_offset,\n\n                        asf->packet_frag_size);\n\n        if (ret != asf->packet_frag_size) {\n\n            if (ret < 0 || asf->packet_frag_offset + ret == 0)\n\n                return ret < 0 ? ret : AVERROR_EOF;\n\n\n\n            if (asf_st->ds_span > 1) {\n\n                // scrambling, we can either drop it completely or fill the remainder\n\n                // TODO: should we fill the whole packet instead of just the current\n\n                // fragment?\n\n                memset(asf_st->pkt.data + asf->packet_frag_offset + ret, 0,\n\n                       asf->packet_frag_size - ret);\n\n                ret = asf->packet_frag_size;\n\n            } else {\n\n                // no scrambling, so we can return partial packets\n\n                av_shrink_packet(&asf_st->pkt, asf->packet_frag_offset + ret);\n\n            }\n\n        }\n\n        if (s->key && s->keylen == 20)\n\n            ff_asfcrypt_dec(s->key, asf_st->pkt.data + asf->packet_frag_offset,\n\n                            ret);\n\n        asf_st->frag_offset += ret;\n\n        /* test if whole packet is read */\n\n        if (asf_st->frag_offset == asf_st->pkt.size) {\n\n            // workaround for macroshit radio DVR-MS files\n\n            if (s->streams[asf->stream_index]->codec->codec_id == AV_CODEC_ID_MPEG2VIDEO &&\n\n                asf_st->pkt.size > 100) {\n\n                int i;\n\n                for (i = 0; i < asf_st->pkt.size && !asf_st->pkt.data[i]; i++)\n\n                    ;\n\n                if (i == asf_st->pkt.size) {\n\n                    av_log(s, AV_LOG_DEBUG, \"discarding ms fart\\n\");\n\n                    asf_st->frag_offset = 0;\n\n                    av_free_packet(&asf_st->pkt);\n\n                    continue;\n\n                }\n\n            }\n\n\n\n            /* return packet */\n\n            if (asf_st->ds_span > 1) {\n\n                if (asf_st->pkt.size != asf_st->ds_packet_size * asf_st->ds_span) {\n\n                    av_log(s, AV_LOG_ERROR,\n\n                           \"pkt.size != ds_packet_size * ds_span (%d %d %d)\\n\",\n\n                           asf_st->pkt.size, asf_st->ds_packet_size,\n\n                           asf_st->ds_span);\n\n                } else {\n\n                    /* packet descrambling */\n\n                    AVBufferRef *buf = av_buffer_alloc(asf_st->pkt.size +\n\n                                                       FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (buf) {\n\n                        uint8_t *newdata = buf->data;\n\n                        int offset = 0;\n\n                        memset(newdata + asf_st->pkt.size, 0,\n\n                               FF_INPUT_BUFFER_PADDING_SIZE);\n\n                        while (offset < asf_st->pkt.size) {\n\n                            int off = offset / asf_st->ds_chunk_size;\n\n                            int row = off / asf_st->ds_span;\n\n                            int col = off % asf_st->ds_span;\n\n                            int idx = row + col * asf_st->ds_packet_size / asf_st->ds_chunk_size;\n\n                            assert(offset + asf_st->ds_chunk_size <= asf_st->pkt.size);\n\n                            assert(idx + 1 <= asf_st->pkt.size / asf_st->ds_chunk_size);\n\n                            memcpy(newdata + offset,\n\n                                   asf_st->pkt.data + idx * asf_st->ds_chunk_size,\n\n                                   asf_st->ds_chunk_size);\n\n                            offset += asf_st->ds_chunk_size;\n\n                        }\n\n                        av_buffer_unref(&asf_st->pkt.buf);\n\n                        asf_st->pkt.buf  = buf;\n\n                        asf_st->pkt.data = buf->data;\n\n                    }\n\n                }\n\n            }\n\n            asf_st->frag_offset         = 0;\n\n            *pkt                        = asf_st->pkt;\n\n#if FF_API_DESTRUCT_PACKET\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n            asf_st->pkt.destruct        = NULL;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n            asf_st->pkt.buf             = 0;\n\n            asf_st->pkt.size            = 0;\n\n            asf_st->pkt.data            = 0;\n\n            asf_st->pkt.side_data_elems = 0;\n\n            asf_st->pkt.side_data       = NULL;\n\n            break; // packet completed\n\n        }\n\n    }\n\n    return 0;\n\n}", "idx": 12212, "_split": "valid", "_hash": "dc5f8e54f42b328b60737be84cdb27fc"}
{"project": "FFmpeg", "commit_id": "d8b45f7961dd7ad73fbe703f5b7ab600c876cde3", "target": 1, "func": "static int flic_decode_frame_8BPP(AVCodecContext *avctx,\n\n                                  void *data, int *data_size,\n\n                                  uint8_t *buf, int buf_size)\n\n{\n\n    FlicDecodeContext *s = (FlicDecodeContext *)avctx->priv_data;\n\n\n\n    int stream_ptr = 0;\n\n    int stream_ptr_after_color_chunk;\n\n    int pixel_ptr;\n\n    int palette_ptr;\n\n    unsigned char palette_idx1;\n\n    unsigned char palette_idx2;\n\n\n\n    unsigned int frame_size;\n\n    int num_chunks;\n\n\n\n    unsigned int chunk_size;\n\n    int chunk_type;\n\n\n\n    int i, j;\n\n\n\n    int color_packets;\n\n    int color_changes;\n\n    int color_shift;\n\n    unsigned char r, g, b;\n\n\n\n    int lines;\n\n    int compressed_lines;\n\n    int starting_line;\n\n    signed short line_packets;\n\n    int y_ptr;\n\n    signed char byte_run;\n\n    int pixel_skip;\n\n    int pixel_countdown;\n\n    unsigned char *pixels;\n\n    int pixel_limit;\n\n\n\n    s->frame.reference = 1;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pixels = s->frame.data[0];\n\n    pixel_limit = s->avctx->height * s->frame.linesize[0];\n\n\n\n    frame_size = LE_32(&buf[stream_ptr]);\n\n    stream_ptr += 6;  /* skip the magic number */\n\n    num_chunks = LE_16(&buf[stream_ptr]);\n\n    stream_ptr += 10;  /* skip padding */\n\n\n\n    frame_size -= 16;\n\n\n\n    /* iterate through the chunks */\n\n    while ((frame_size > 0) && (num_chunks > 0)) {\n\n        chunk_size = LE_32(&buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n        chunk_type = LE_16(&buf[stream_ptr]);\n\n        stream_ptr += 2;\n\n\n\n        switch (chunk_type) {\n\n        case FLI_256_COLOR:\n\n        case FLI_COLOR:\n\n            stream_ptr_after_color_chunk = stream_ptr + chunk_size - 6;\n\n\n\n            /* check special case: If this file is from the Magic Carpet\n\n             * game and uses 6-bit colors even though it reports 256-color\n\n             * chunks in a 0xAF12-type file (fli_type is set to 0xAF13 during\n\n             * initialization) */\n\n            if ((chunk_type == FLI_256_COLOR) && (s->fli_type != FLC_MAGIC_CARPET_SYNTHETIC_TYPE_CODE))\n\n                color_shift = 0;\n\n            else\n\n                color_shift = 2;\n\n            /* set up the palette */\n\n            color_packets = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            palette_ptr = 0;\n\n            for (i = 0; i < color_packets; i++) {\n\n                /* first byte is how many colors to skip */\n\n                palette_ptr += buf[stream_ptr++];\n\n\n\n                /* next byte indicates how many entries to change */\n\n                color_changes = buf[stream_ptr++];\n\n\n\n                /* if there are 0 color changes, there are actually 256 */\n\n                if (color_changes == 0)\n\n                    color_changes = 256;\n\n\n\n                for (j = 0; j < color_changes; j++) {\n\n                    unsigned int entry;\n\n\n\n                    /* wrap around, for good measure */\n\n                    if ((unsigned)palette_ptr >= 256)\n\n                        palette_ptr = 0;\n\n\n\n                    r = buf[stream_ptr++] << color_shift;\n\n                    g = buf[stream_ptr++] << color_shift;\n\n                    b = buf[stream_ptr++] << color_shift;\n\n                    entry = (r << 16) | (g << 8) | b;\n\n                    if (s->palette[palette_ptr] != entry)\n\n                        s->new_palette = 1;\n\n                    s->palette[palette_ptr++] = entry;\n\n                }\n\n            }\n\n\n\n            /* color chunks sometimes have weird 16-bit alignment issues;\n\n             * therefore, take the hardline approach and set the stream_ptr\n\n             * to the value calculated w.r.t. the size specified by the color\n\n             * chunk header */\n\n            stream_ptr = stream_ptr_after_color_chunk;\n\n\n\n            break;\n\n\n\n        case FLI_DELTA:\n\n            y_ptr = 0;\n\n            compressed_lines = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                line_packets = LE_16(&buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n                if (line_packets < 0) {\n\n                    line_packets = -line_packets;\n\n                    y_ptr += line_packets * s->frame.linesize[0];\n\n                } else {\n\n                    compressed_lines--;\n\n                    pixel_ptr = y_ptr;\n\n                    pixel_countdown = s->avctx->width;\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += pixel_skip;\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = buf[stream_ptr++];\n\n                        if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            palette_idx2 = buf[stream_ptr++];\n\n                            CHECK_PIXEL_PTR(byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                                pixels[pixel_ptr++] = palette_idx2;\n\n                            }\n\n                        } else {\n\n                            CHECK_PIXEL_PTR(byte_run * 2);\n\n                            for (j = 0; j < byte_run * 2; j++, pixel_countdown--) {\n\n                                palette_idx1 = buf[stream_ptr++];\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    y_ptr += s->frame.linesize[0];\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_LC:\n\n            /* line compressed */\n\n            starting_line = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            y_ptr = 0;\n\n            y_ptr += starting_line * s->frame.linesize[0];\n\n\n\n            compressed_lines = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                pixel_ptr = y_ptr;\n\n                pixel_countdown = s->avctx->width;\n\n                line_packets = buf[stream_ptr++];\n\n                if (line_packets > 0) {\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += pixel_skip;\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = buf[stream_ptr++];\n\n                        if (byte_run > 0) {\n\n                            CHECK_PIXEL_PTR(byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                palette_idx1 = buf[stream_ptr++];\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        } else {\n\n                            byte_run = -byte_run;\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            CHECK_PIXEL_PTR(byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n                compressed_lines--;\n\n            }\n\n            break;\n\n\n\n        case FLI_BLACK:\n\n            /* set the whole frame to color 0 (which is usually black) */\n\n            memset(pixels, 0,\n\n                s->frame.linesize[0] * s->avctx->height);\n\n            break;\n\n\n\n        case FLI_BRUN:\n\n            /* Byte run compression: This chunk type only occurs in the first\n\n             * FLI frame and it will update the entire frame. */\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                stream_ptr++;\n\n                pixel_countdown = s->avctx->width;\n\n                while (pixel_countdown > 0) {\n\n                    byte_run = buf[stream_ptr++];\n\n                    if (byte_run > 0) {\n\n                        palette_idx1 = buf[stream_ptr++];\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    } else {  /* copy bytes if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_COPY:\n\n            /* copy the chunk (uncompressed frame) */\n\n            if (chunk_size - 6 > s->avctx->width * s->avctx->height) {\n\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n\n                       \"bigger than image, skipping chunk\\n\", chunk_size - 6);\n\n                stream_ptr += chunk_size - 6;\n\n            } else {\n\n                for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;\n\n                     y_ptr += s->frame.linesize[0]) {\n\n                    memcpy(&pixels[y_ptr], &buf[stream_ptr],\n\n                        s->avctx->width);\n\n                    stream_ptr += s->avctx->width;\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_MINI:\n\n            /* some sort of a thumbnail? disregard this chunk... */\n\n            stream_ptr += chunk_size - 6;\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n\n            break;\n\n        }\n\n\n\n        frame_size -= chunk_size;\n\n        num_chunks--;\n\n    }\n\n\n\n    /* by the end of the chunk, the stream ptr should equal the frame\n\n     * size (minus 1, possibly); if it doesn't, issue a warning */\n\n    if ((stream_ptr != buf_size) && (stream_ptr != buf_size - 1))\n\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n\n               \"and final chunk ptr = %d\\n\", buf_size, stream_ptr);\n\n\n\n    /* make the palette available on the way out */\n\n    memcpy(s->frame.data[1], s->palette, AVPALETTE_SIZE);\n\n    if (s->new_palette) {\n\n        s->frame.palette_has_changed = 1;\n\n        s->new_palette = 0;\n\n    }\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 12231, "_split": "valid", "_hash": "622e51a8eafd04fa6d4e9cb9fe1479e4"}
{"project": "FFmpeg", "commit_id": "9694695a21d08ae470b2db6278f92c5c31d07b41", "target": 0, "func": "int av_probe_input_buffer2(AVIOContext *pb, AVInputFormat **fmt,\n\n                          const char *filename, void *logctx,\n\n                          unsigned int offset, unsigned int max_probe_size)\n\n{\n\n    AVProbeData pd = { filename ? filename : \"\" };\n\n    uint8_t *buf = NULL;\n\n    uint8_t *mime_type;\n\n    int ret = 0, probe_size, buf_offset = 0;\n\n    int score = 0;\n\n\n\n    if (!max_probe_size)\n\n        max_probe_size = PROBE_BUF_MAX;\n\n    else if (max_probe_size < PROBE_BUF_MIN) {\n\n        av_log(logctx, AV_LOG_ERROR,\n\n               \"Specified probe size value %u cannot be < %u\\n\", max_probe_size, PROBE_BUF_MIN);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (offset >= max_probe_size)\n\n        return AVERROR(EINVAL);\n\n\n\n#ifdef FF_API_PROBE_MIME\n\n    if (pb->av_class)\n\n        av_opt_get(pb, \"mime_type\", AV_OPT_SEARCH_CHILDREN, &pd.mime_type);\n\n#endif\n\n\n\n#if !FF_API_PROBE_MIME\n\n    if (!*fmt && pb->av_class && av_opt_get(pb, \"mime_type\", AV_OPT_SEARCH_CHILDREN, &mime_type) >= 0 && mime_type) {\n\n        if (!av_strcasecmp(mime_type, \"audio/aacp\")) {\n\n            *fmt = av_find_input_format(\"aac\");\n\n        }\n\n        av_freep(&mime_type);\n\n    }\n\n#endif\n\n\n\n    for (probe_size = PROBE_BUF_MIN; probe_size <= max_probe_size && !*fmt;\n\n         probe_size = FFMIN(probe_size << 1,\n\n                            FFMAX(max_probe_size, probe_size + 1))) {\n\n        score = probe_size < max_probe_size ? AVPROBE_SCORE_RETRY : 0;\n\n\n\n        /* Read probe data. */\n\n        if ((ret = av_reallocp(&buf, probe_size + AVPROBE_PADDING_SIZE)) < 0)\n\n            goto fail;\n\n        if ((ret = avio_read(pb, buf + buf_offset,\n\n                             probe_size - buf_offset)) < 0) {\n\n            /* Fail if error was not end of file, otherwise, lower score. */\n\n            if (ret != AVERROR_EOF)\n\n                goto fail;\n\n\n\n            score = 0;\n\n            ret   = 0;          /* error was end of file, nothing read */\n\n        }\n\n        buf_offset += ret;\n\n        if (buf_offset < offset)\n\n            continue;\n\n        pd.buf_size = buf_offset - offset;\n\n        pd.buf = &buf[offset];\n\n\n\n        memset(pd.buf + pd.buf_size, 0, AVPROBE_PADDING_SIZE);\n\n\n\n        /* Guess file format. */\n\n        *fmt = av_probe_input_format2(&pd, 1, &score);\n\n        if (*fmt) {\n\n            /* This can only be true in the last iteration. */\n\n            if (score <= AVPROBE_SCORE_RETRY) {\n\n                av_log(logctx, AV_LOG_WARNING,\n\n                       \"Format %s detected only with low score of %d, \"\n\n                       \"misdetection possible!\\n\", (*fmt)->name, score);\n\n            } else\n\n                av_log(logctx, AV_LOG_DEBUG,\n\n                       \"Format %s probed with size=%d and score=%d\\n\",\n\n                       (*fmt)->name, probe_size, score);\n\n#if 0\n\n            FILE *f = fopen(\"probestat.tmp\", \"ab\");\n\n            fprintf(f, \"probe_size:%d format:%s score:%d filename:%s\\n\", probe_size, (*fmt)->name, score, filename);\n\n            fclose(f);\n\n#endif\n\n        }\n\n    }\n\n\n\n    if (!*fmt)\n\n        ret = AVERROR_INVALIDDATA;\n\n\n\nfail:\n\n    /* Rewind. Reuse probe buffer to avoid seeking. */\n\n    if (ret >= 0)\n\n        ret = ffio_rewind_with_probe_data(pb, &buf, buf_offset);\n\n\n\n#ifdef FF_API_PROBE_MIME\n\n    av_free(pd.mime_type);\n\n#endif\n\n    return ret < 0 ? ret : score;\n\n}\n", "idx": 12351, "_split": "valid", "_hash": "d4b9ff949d89f877a6fcd3d08ec1274a"}
{"project": "FFmpeg", "commit_id": "70d54392f5015b9c6594fcae558f59f952501e3b", "target": 0, "func": "static int mjpeg_decode_scan(MJpegDecodeContext *s, int nb_components, int Ah,\n\n                             int Al, const uint8_t *mb_bitmask,\n\n                             const AVFrame *reference)\n\n{\n\n    int i, mb_x, mb_y;\n\n    uint8_t *data[MAX_COMPONENTS];\n\n    const uint8_t *reference_data[MAX_COMPONENTS];\n\n    int linesize[MAX_COMPONENTS];\n\n    GetBitContext mb_bitmask_gb;\n\n\n\n    if (mb_bitmask)\n\n        init_get_bits(&mb_bitmask_gb, mb_bitmask, s->mb_width * s->mb_height);\n\n\n\n    if (s->flipped && s->avctx->flags & CODEC_FLAG_EMU_EDGE) {\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"Can not flip image with CODEC_FLAG_EMU_EDGE set!\\n\");\n\n        s->flipped = 0;\n\n    }\n\n    if (s->flipped && s->avctx->lowres) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Can not flip image with lowres\\n\");\n\n        s->flipped = 0;\n\n    }\n\n\n\n    for (i = 0; i < nb_components; i++) {\n\n        int c   = s->comp_index[i];\n\n        data[c] = s->picture_ptr->data[c];\n\n        reference_data[c] = reference ? reference->data[c] : NULL;\n\n        linesize[c] = s->linesize[c];\n\n        s->coefs_finished[c] |= 1;\n\n        if (s->flipped) {\n\n            // picture should be flipped upside-down for this codec\n\n            int offset = (linesize[c] * (s->v_scount[i] *\n\n                         (8 * s->mb_height - ((s->height / s->v_max) & 7)) - 1));\n\n            data[c]           += offset;\n\n            reference_data[c] += offset;\n\n            linesize[c]       *= -1;\n\n        }\n\n    }\n\n\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            const int copy_mb = mb_bitmask && !get_bits1(&mb_bitmask_gb);\n\n\n\n            if (s->restart_interval && !s->restart_count)\n\n                s->restart_count = s->restart_interval;\n\n\n\n            if (get_bits_left(&s->gb) < 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"overread %d\\n\",\n\n                       -get_bits_left(&s->gb));\n\n                return -1;\n\n            }\n\n            for (i = 0; i < nb_components; i++) {\n\n                uint8_t *ptr;\n\n                int n, h, v, x, y, c, j;\n\n                int block_offset;\n\n                n = s->nb_blocks[i];\n\n                c = s->comp_index[i];\n\n                h = s->h_scount[i];\n\n                v = s->v_scount[i];\n\n                x = 0;\n\n                y = 0;\n\n                for (j = 0; j < n; j++) {\n\n                    block_offset = ((linesize[c] * (v * mb_y + y) * 8) +\n\n                                    (h * mb_x + x) * 8);\n\n\n\n                    if (s->interlaced && s->bottom_field)\n\n                        block_offset += linesize[c] >> 1;\n\n                    ptr = data[c] + block_offset;\n\n                    if (!s->progressive) {\n\n                        if (copy_mb)\n\n                            copy_block8(ptr, reference_data[c] + block_offset,\n\n                                        linesize[c], linesize[c], 8);\n\n                        else {\n\n                            s->dsp.clear_block(s->block);\n\n                            if (decode_block(s, s->block, i,\n\n                                             s->dc_index[i], s->ac_index[i],\n\n                                             s->quant_matrixes[s->quant_index[c]]) < 0) {\n\n                                av_log(s->avctx, AV_LOG_ERROR,\n\n                                       \"error y=%d x=%d\\n\", mb_y, mb_x);\n\n                                return -1;\n\n                            }\n\n                            s->dsp.idct_put(ptr, linesize[c], s->block);\n\n                        }\n\n                    } else {\n\n                        int block_idx  = s->block_stride[c] * (v * mb_y + y) +\n\n                                         (h * mb_x + x);\n\n                        DCTELEM *block = s->blocks[c][block_idx];\n\n                        if (Ah)\n\n                            block[0] += get_bits1(&s->gb) *\n\n                                        s->quant_matrixes[s->quant_index[c]][0] << Al;\n\n                        else if (decode_dc_progressive(s, block, i, s->dc_index[i],\n\n                                                       s->quant_matrixes[s->quant_index[c]],\n\n                                                       Al) < 0) {\n\n                            av_log(s->avctx, AV_LOG_ERROR,\n\n                                   \"error y=%d x=%d\\n\", mb_y, mb_x);\n\n                            return -1;\n\n                        }\n\n                    }\n\n                    // av_log(s->avctx, AV_LOG_DEBUG, \"mb: %d %d processed\\n\",\n\n                    //        mb_y, mb_x);\n\n                    // av_log(NULL, AV_LOG_DEBUG, \"%d %d %d %d %d %d %d %d \\n\",\n\n                    //        mb_x, mb_y, x, y, c, s->bottom_field,\n\n                    //        (v * mb_y + y) * 8, (h * mb_x + x) * 8);\n\n                    if (++x == h) {\n\n                        x = 0;\n\n                        y++;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (s->restart_interval) {\n\n                s->restart_count--;\n\n                if(s->restart_count == 0 && s->avctx->codec_id == CODEC_ID_THP){\n\n                    align_get_bits(&s->gb);\n\n                    for (i = 0; i < nb_components; i++) /* reset dc */\n\n                        s->last_dc[i] = 1024;\n\n                }\n\n\n\n                i = 8 + ((-get_bits_count(&s->gb)) & 7);\n\n                /* skip RSTn */\n\n                if (show_bits(&s->gb, i) == (1 << i) - 1) {\n\n                    int pos = get_bits_count(&s->gb);\n\n                    align_get_bits(&s->gb);\n\n                    while (get_bits_left(&s->gb) >= 8 && show_bits(&s->gb, 8) == 0xFF)\n\n                        skip_bits(&s->gb, 8);\n\n                    if (get_bits_left(&s->gb) >= 8 && (get_bits(&s->gb, 8) & 0xF8) == 0xD0) {\n\n                        for (i = 0; i < nb_components; i++) /* reset dc */\n\n                            s->last_dc[i] = 1024;\n\n                    } else\n\n                        skip_bits_long(&s->gb, pos - get_bits_count(&s->gb));\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 12364, "_split": "valid", "_hash": "e18dc4ed024a2bbdcf347cf84a12610d"}
{"project": "FFmpeg", "commit_id": "bca11e75fbc6b922438670733c6cb418c70433b4", "target": 0, "func": "static inline void RENAME(yuv2packedX)(SwsContext *c, int16_t *lumFilter, int16_t **lumSrc, int lumFilterSize,\n\n\t\t\t\t    int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,\n\n\t\t\t    uint8_t *dest, long dstW, long dstY)\n\n{\n\n\tlong dummy=0;\n\n\tswitch(c->dstFormat)\n\n\t{\n\n#ifdef HAVE_MMX\n\n\tcase IMGFMT_BGR32:\n\n\t\t{\n\n\t\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2RGBX\n\n\t\t\t\tWRITEBGR32(%4, %5, %%REGa)\n\n\n\n\t\t\t:: \"r\" (&c->redDither), \n\n\t\t\t   \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n\t\t\t   \"r\" (dest), \"m\" (dstW)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_d, \"%\"REG_S\n\n\t\t\t);\n\n\t\t}\n\n\t\tbreak;\n\n\tcase IMGFMT_BGR24:\n\n\t\t{\n\n\t\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2RGBX\n\n\t\t\t\t\"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_b\"\\n\\t\" //FIXME optimize\n\n\t\t\t\t\"add %4, %%\"REG_b\"\t\t\t\\n\\t\"\n\n\t\t\t\tWRITEBGR24(%%REGb, %5, %%REGa)\n\n\n\n\t\t\t:: \"r\" (&c->redDither), \n\n\t\t\t   \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n\t\t\t   \"r\" (dest), \"m\" (dstW)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_b, \"%\"REG_d, \"%\"REG_S //FIXME ebx\n\n\t\t\t);\n\n\t\t}\n\n\t\tbreak;\n\n\tcase IMGFMT_BGR15:\n\n\t\t{\n\n\t\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2RGBX\n\n\t\t/* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n\t\t\t\t\"paddusb \"MANGLE(b5Dither)\", %%mm2\\n\\t\"\n\n\t\t\t\t\"paddusb \"MANGLE(g5Dither)\", %%mm4\\n\\t\"\n\n\t\t\t\t\"paddusb \"MANGLE(r5Dither)\", %%mm5\\n\\t\"\n\n#endif\n\n\n\n\t\t\t\tWRITEBGR15(%4, %5, %%REGa)\n\n\n\n\t\t\t:: \"r\" (&c->redDither), \n\n\t\t\t   \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n\t\t\t   \"r\" (dest), \"m\" (dstW)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_d, \"%\"REG_S\n\n\t\t\t);\n\n\t\t}\n\n\t\tbreak;\n\n\tcase IMGFMT_BGR16:\n\n\t\t{\n\n\t\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2RGBX\n\n\t\t/* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n\t\t\t\t\"paddusb \"MANGLE(b5Dither)\", %%mm2\\n\\t\"\n\n\t\t\t\t\"paddusb \"MANGLE(g6Dither)\", %%mm4\\n\\t\"\n\n\t\t\t\t\"paddusb \"MANGLE(r5Dither)\", %%mm5\\n\\t\"\n\n#endif\n\n\n\n\t\t\t\tWRITEBGR16(%4, %5, %%REGa)\n\n\n\n\t\t\t:: \"r\" (&c->redDither), \n\n\t\t\t   \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n\t\t\t   \"r\" (dest), \"m\" (dstW)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_d, \"%\"REG_S\n\n\t\t\t);\n\n\t\t}\n\n\t\tbreak;\n\n\tcase IMGFMT_YUY2:\n\n\t\t{\n\n\t\t\tasm volatile(\n\n\t\t\t\tYSCALEYUV2PACKEDX\n\n\t\t/* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n\n\n\t\t\t\t\"psraw $3, %%mm3\t\t\\n\\t\"\n\n\t\t\t\t\"psraw $3, %%mm4\t\t\\n\\t\"\n\n\t\t\t\t\"psraw $3, %%mm1\t\t\\n\\t\"\n\n\t\t\t\t\"psraw $3, %%mm7\t\t\\n\\t\"\n\n\t\t\t\tWRITEYUY2(%4, %5, %%REGa)\n\n\n\n\t\t\t:: \"r\" (&c->redDither), \n\n\t\t\t   \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n\t\t\t   \"r\" (dest), \"m\" (dstW)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_d, \"%\"REG_S\n\n\t\t\t);\n\n\t\t}\n\n\t\tbreak;\n\n#endif\n\n\tdefault:\n\n#ifdef HAVE_ALTIVEC\n\n\t\t/* The following list of supported dstFormat values should\n\n\t\t   match what's found in the body of altivec_yuv2packedX() */\n\n\t\tif(c->dstFormat==IMGFMT_ABGR  || c->dstFormat==IMGFMT_BGRA  ||\n\n\t\t   c->dstFormat==IMGFMT_BGR24 || c->dstFormat==IMGFMT_RGB24 ||\n\n\t\t   c->dstFormat==IMGFMT_RGBA  || c->dstFormat==IMGFMT_ARGB)\n\n\t\t\taltivec_yuv2packedX (c, lumFilter, lumSrc, lumFilterSize,\n\n\t\t\t\t    chrFilter, chrSrc, chrFilterSize,\n\n\t\t\t\t    dest, dstW, dstY);\n\n\t\telse\n\n#endif\n\n\t\t\tyuv2packedXinC(c, lumFilter, lumSrc, lumFilterSize,\n\n\t\t\t\t    chrFilter, chrSrc, chrFilterSize,\n\n\t\t\t\t    dest, dstW, dstY);\n\n\t\tbreak;\n\n\t}\n\n}\n", "idx": 12396, "_split": "valid", "_hash": "f6742b82736ef6a496f70654bf0292d8"}
{"project": "FFmpeg", "commit_id": "9bcbb250e23959075765edd3cb4c1fcb46736d7d", "target": 0, "func": "static inline void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,\n\n                                        int dstWidth, const uint8_t *src, int srcW,\n\n                                        int xInc)\n\n{\n\n    int32_t *filterPos = c->hLumFilterPos;\n\n    int16_t *filter    = c->hLumFilter;\n\n    void    *mmx2FilterCode= c->lumMmx2FilterCode;\n\n    int i;\n\n#if defined(PIC)\n\n    DECLARE_ALIGNED(8, uint64_t, ebxsave);\n\n#endif\n\n\n\n    __asm__ volatile(\n\n#if defined(PIC)\n\n        \"mov               %%\"REG_b\", %5        \\n\\t\"\n\n#endif\n\n        \"pxor                  %%mm7, %%mm7     \\n\\t\"\n\n        \"mov                      %0, %%\"REG_c\" \\n\\t\"\n\n        \"mov                      %1, %%\"REG_D\" \\n\\t\"\n\n        \"mov                      %2, %%\"REG_d\" \\n\\t\"\n\n        \"mov                      %3, %%\"REG_b\" \\n\\t\"\n\n        \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\" // i\n\n        PREFETCH\"        (%%\"REG_c\")            \\n\\t\"\n\n        PREFETCH\"      32(%%\"REG_c\")            \\n\\t\"\n\n        PREFETCH\"      64(%%\"REG_c\")            \\n\\t\"\n\n\n\n#if ARCH_X86_64\n\n#define CALL_MMX2_FILTER_CODE \\\n\n        \"movl            (%%\"REG_b\"), %%esi     \\n\\t\"\\\n\n        \"call                    *%4            \\n\\t\"\\\n\n        \"movl (%%\"REG_b\", %%\"REG_a\"), %%esi     \\n\\t\"\\\n\n        \"add               %%\"REG_S\", %%\"REG_c\" \\n\\t\"\\\n\n        \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n        \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#else\n\n#define CALL_MMX2_FILTER_CODE \\\n\n        \"movl (%%\"REG_b\"), %%esi        \\n\\t\"\\\n\n        \"call         *%4                       \\n\\t\"\\\n\n        \"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\" \\n\\t\"\\\n\n        \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n        \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#endif /* ARCH_X86_64 */\n\n\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n        CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n        \"mov                      %5, %%\"REG_b\" \\n\\t\"\n\n#endif\n\n        :: \"m\" (src), \"m\" (dst), \"m\" (filter), \"m\" (filterPos),\n\n           \"m\" (mmx2FilterCode)\n\n#if defined(PIC)\n\n          ,\"m\" (ebxsave)\n\n#endif\n\n        : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n         ,\"%\"REG_b\n\n#endif\n\n    );\n\n\n\n    for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n        dst[i] = src[srcW-1]*128;\n\n}\n", "idx": 12397, "_split": "valid", "_hash": "451cbec77c21e994636ea617c191aa06"}
{"project": "FFmpeg", "commit_id": "5e600185453e1a0ded70a59701f60a0022a88e42", "target": 0, "func": "int avfilter_parse_graph(AVFilterGraph *graph, const char *filters,\n\n                         AVFilterInOut *openLinks, AVClass *log_ctx)\n\n{\n\n    int index = 0;\n\n    char chr = 0;\n\n    int pad = 0;\n\n\n\n    AVFilterInOut *currInputs = NULL;\n\n\n\n    do {\n\n        AVFilterContext *filter;\n\n        filters += consume_whitespace(filters);\n\n\n\n        pad = parse_inputs(&filters, &currInputs, &openLinks, log_ctx);\n\n\n\n        if(pad < 0)\n\n            goto fail;\n\n\n\n        if(!(filter = parse_filter(&filters, graph, index, log_ctx)))\n\n            goto fail;\n\n\n\n        if(filter->input_count == 1 && !currInputs && !index) {\n\n            // First input can be ommitted if it is \"[in]\"\n\n            const char *tmp = \"[in]\";\n\n            pad = parse_inputs(&tmp, &currInputs, &openLinks, log_ctx);\n\n            if(pad < 0)\n\n                goto fail;\n\n        }\n\n\n\n        if(link_filter_inouts(filter, &currInputs, &openLinks, log_ctx) < 0)\n\n            goto fail;\n\n\n\n        pad = parse_outputs(&filters, &currInputs, &openLinks, log_ctx);\n\n\n\n        if(pad < 0)\n\n            goto fail;\n\n\n\n        filters += consume_whitespace(filters);\n\n        chr = *filters++;\n\n\n\n        if(chr == ';' && currInputs) {\n\n            av_log(log_ctx, AV_LOG_ERROR,\n\n                   \"Could not find a output to link when parsing \\\"%s\\\"\\n\",\n\n                   filters - 1);\n\n            goto fail;\n\n        }\n\n        index++;\n\n    } while(chr == ',' || chr == ';');\n\n\n\n    if(openLinks && !strcmp(openLinks->name, \"out\") && currInputs) {\n\n        // Last output can be ommitted if it is \"[out]\"\n\n        const char *tmp = \"[out]\";\n\n        if(parse_outputs(&tmp, &currInputs, &openLinks, log_ctx) < 0)\n\n            goto fail;\n\n    }\n\n\n\n    return 0;\n\n\n\n fail:\n\n    avfilter_destroy_graph(graph);\n\n    free_inout(openLinks);\n\n    free_inout(currInputs);\n\n    return -1;\n\n}\n", "idx": 12399, "_split": "valid", "_hash": "985e5a4af20775eb73863f1dc623bbe2"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int qtrle_encode_init(AVCodecContext *avctx)\n\n{\n\n    QtrleEncContext *s = avctx->priv_data;\n\n\n\n    if (av_image_check_size(avctx->width, avctx->height, 0, avctx) < 0) {\n\n        return -1;\n\n    }\n\n    s->avctx=avctx;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_RGB555BE:\n\n        s->pixel_size = 2;\n\n        break;\n\n    case AV_PIX_FMT_RGB24:\n\n        s->pixel_size = 3;\n\n        break;\n\n    case AV_PIX_FMT_ARGB:\n\n        s->pixel_size = 4;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported colorspace.\\n\");\n\n        break;\n\n    }\n\n    avctx->bits_per_coded_sample = s->pixel_size*8;\n\n\n\n    s->rlecode_table = av_mallocz(s->avctx->width);\n\n    s->skip_table    = av_mallocz(s->avctx->width);\n\n    s->length_table  = av_mallocz((s->avctx->width + 1)*sizeof(int));\n\n    if (!s->skip_table || !s->length_table || !s->rlecode_table) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error allocating memory.\\n\");\n\n        return -1;\n\n    }\n\n    if (avpicture_alloc(&s->previous_frame, avctx->pix_fmt, avctx->width, avctx->height) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error allocating picture\\n\");\n\n        return -1;\n\n    }\n\n\n\n    s->max_buf_size = s->avctx->width*s->avctx->height*s->pixel_size*2 /* image base material */\n\n                      + 15                                           /* header + footer */\n\n                      + s->avctx->height*2                           /* skip code+rle end */\n\n                      + s->avctx->width/MAX_RLE_BULK + 1             /* rle codes */;\n\n\n\n    avctx->coded_frame = av_frame_alloc();\n\n    if (!avctx->coded_frame) {\n\n        qtrle_encode_end(avctx);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 12418, "_split": "valid", "_hash": "69813c8a6d30638e8754197787807adf"}
{"project": "FFmpeg", "commit_id": "88db5551cf1ced4ea3e5e8bd5b684d2dc74b1ed2", "target": 0, "func": "static inline void check_for_slice(AVSContext *h) {\n\n    GetBitContext *gb = &h->s.gb;\n\n    int align;\n\n\n\n    if(h->mbx)\n\n        return;\n\n    align = (-get_bits_count(gb)) & 7;\n\n    if((show_bits_long(gb,24+align) & 0xFFFFFF) == 0x000001) {\n\n        skip_bits_long(gb,24+align);\n\n        h->stc = get_bits(gb,8);\n\n        decode_slice_header(h,gb);\n\n    }\n\n}\n", "idx": 12419, "_split": "valid", "_hash": "53571d78bc3474058e1789de124dceee"}
{"project": "FFmpeg", "commit_id": "41fe750f4b130f08f41ce0e5126046315c891cae", "target": 1, "func": "void av_bitstream_filter_close(AVBitStreamFilterContext *bsfc){\n\n\n\n    if(bsfc->filter->close)\n\n        bsfc->filter->close(bsfc);\n\n    av_freep(&bsfc->priv_data);\n\n    av_parser_close(bsfc->parser);\n\n    av_free(bsfc);\n\n}", "idx": 12518, "_split": "valid", "_hash": "4b10fd2196ad2e5b0ed8a2f35f377097"}
{"project": "FFmpeg", "commit_id": "ae413a48e64274b9740c3b27398fea92108a0f0e", "target": 1, "func": "static void mov_text_cleanup_ftab(MovTextContext *m)\n\n{\n\n    int i;\n\n    for(i = 0; i < m->count_f; i++) {\n\n        av_freep(&m->ftab[i]->font);\n\n        av_freep(&m->ftab[i]);\n\n    }\n\n    av_freep(&m->ftab);\n\n}\n", "idx": 12520, "_split": "valid", "_hash": "a38352a4725cbad42a0e5bf0da05c128"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static int fill_filter_caches(const H264Context *h, H264SliceContext *sl, int mb_type)\n\n{\n\n    const int mb_xy = sl->mb_xy;\n\n    int top_xy, left_xy[LEFT_MBS];\n\n    int top_type, left_type[LEFT_MBS];\n\n    uint8_t *nnz;\n\n    uint8_t *nnz_cache;\n\n\n\n    top_xy = mb_xy - (h->mb_stride << MB_FIELD(sl));\n\n\n\n    /* Wow, what a mess, why didn't they simplify the interlacing & intra\n\n     * stuff, I can't imagine that these complex rules are worth it. */\n\n\n\n    left_xy[LBOT] = left_xy[LTOP] = mb_xy - 1;\n\n    if (FRAME_MBAFF(h)) {\n\n        const int left_mb_field_flag = IS_INTERLACED(h->cur_pic.mb_type[mb_xy - 1]);\n\n        const int curr_mb_field_flag = IS_INTERLACED(mb_type);\n\n        if (sl->mb_y & 1) {\n\n            if (left_mb_field_flag != curr_mb_field_flag)\n\n                left_xy[LTOP] -= h->mb_stride;\n\n        } else {\n\n            if (curr_mb_field_flag)\n\n                top_xy += h->mb_stride &\n\n                          (((h->cur_pic.mb_type[top_xy] >> 7) & 1) - 1);\n\n            if (left_mb_field_flag != curr_mb_field_flag)\n\n                left_xy[LBOT] += h->mb_stride;\n\n        }\n\n    }\n\n\n\n    sl->top_mb_xy        = top_xy;\n\n    sl->left_mb_xy[LTOP] = left_xy[LTOP];\n\n    sl->left_mb_xy[LBOT] = left_xy[LBOT];\n\n    {\n\n        /* For sufficiently low qp, filtering wouldn't do anything.\n\n         * This is a conservative estimate: could also check beta_offset\n\n         * and more accurate chroma_qp. */\n\n        int qp_thresh = sl->qp_thresh; // FIXME strictly we should store qp_thresh for each mb of a slice\n\n        int qp        = h->cur_pic.qscale_table[mb_xy];\n\n        if (qp <= qp_thresh &&\n\n            (left_xy[LTOP] < 0 ||\n\n             ((qp + h->cur_pic.qscale_table[left_xy[LTOP]] + 1) >> 1) <= qp_thresh) &&\n\n            (top_xy < 0 ||\n\n             ((qp + h->cur_pic.qscale_table[top_xy] + 1) >> 1) <= qp_thresh)) {\n\n            if (!FRAME_MBAFF(h))\n\n                return 1;\n\n            if ((left_xy[LTOP] < 0 ||\n\n                 ((qp + h->cur_pic.qscale_table[left_xy[LBOT]] + 1) >> 1) <= qp_thresh) &&\n\n                (top_xy < h->mb_stride ||\n\n                 ((qp + h->cur_pic.qscale_table[top_xy - h->mb_stride] + 1) >> 1) <= qp_thresh))\n\n                return 1;\n\n        }\n\n    }\n\n\n\n    top_type        = h->cur_pic.mb_type[top_xy];\n\n    left_type[LTOP] = h->cur_pic.mb_type[left_xy[LTOP]];\n\n    left_type[LBOT] = h->cur_pic.mb_type[left_xy[LBOT]];\n\n    if (sl->deblocking_filter == 2) {\n\n        if (h->slice_table[top_xy] != sl->slice_num)\n\n            top_type = 0;\n\n        if (h->slice_table[left_xy[LBOT]] != sl->slice_num)\n\n            left_type[LTOP] = left_type[LBOT] = 0;\n\n    } else {\n\n        if (h->slice_table[top_xy] == 0xFFFF)\n\n            top_type = 0;\n\n        if (h->slice_table[left_xy[LBOT]] == 0xFFFF)\n\n            left_type[LTOP] = left_type[LBOT] = 0;\n\n    }\n\n    sl->top_type        = top_type;\n\n    sl->left_type[LTOP] = left_type[LTOP];\n\n    sl->left_type[LBOT] = left_type[LBOT];\n\n\n\n    if (IS_INTRA(mb_type))\n\n        return 0;\n\n\n\n    fill_filter_caches_inter(h, sl, mb_type, top_xy, left_xy,\n\n                             top_type, left_type, mb_xy, 0);\n\n    if (sl->list_count == 2)\n\n        fill_filter_caches_inter(h, sl, mb_type, top_xy, left_xy,\n\n                                 top_type, left_type, mb_xy, 1);\n\n\n\n    nnz       = h->non_zero_count[mb_xy];\n\n    nnz_cache = sl->non_zero_count_cache;\n\n    AV_COPY32(&nnz_cache[4 + 8 * 1], &nnz[0]);\n\n    AV_COPY32(&nnz_cache[4 + 8 * 2], &nnz[4]);\n\n    AV_COPY32(&nnz_cache[4 + 8 * 3], &nnz[8]);\n\n    AV_COPY32(&nnz_cache[4 + 8 * 4], &nnz[12]);\n\n    sl->cbp = h->cbp_table[mb_xy];\n\n\n\n    if (top_type) {\n\n        nnz = h->non_zero_count[top_xy];\n\n        AV_COPY32(&nnz_cache[4 + 8 * 0], &nnz[3 * 4]);\n\n    }\n\n\n\n    if (left_type[LTOP]) {\n\n        nnz = h->non_zero_count[left_xy[LTOP]];\n\n        nnz_cache[3 + 8 * 1] = nnz[3 + 0 * 4];\n\n        nnz_cache[3 + 8 * 2] = nnz[3 + 1 * 4];\n\n        nnz_cache[3 + 8 * 3] = nnz[3 + 2 * 4];\n\n        nnz_cache[3 + 8 * 4] = nnz[3 + 3 * 4];\n\n    }\n\n\n\n    /* CAVLC 8x8dct requires NNZ values for residual decoding that differ\n\n     * from what the loop filter needs */\n\n    if (!CABAC(h) && h->pps.transform_8x8_mode) {\n\n        if (IS_8x8DCT(top_type)) {\n\n            nnz_cache[4 + 8 * 0] =\n\n            nnz_cache[5 + 8 * 0] = (h->cbp_table[top_xy] & 0x4000) >> 12;\n\n            nnz_cache[6 + 8 * 0] =\n\n            nnz_cache[7 + 8 * 0] = (h->cbp_table[top_xy] & 0x8000) >> 12;\n\n        }\n\n        if (IS_8x8DCT(left_type[LTOP])) {\n\n            nnz_cache[3 + 8 * 1] =\n\n            nnz_cache[3 + 8 * 2] = (h->cbp_table[left_xy[LTOP]] & 0x2000) >> 12; // FIXME check MBAFF\n\n        }\n\n        if (IS_8x8DCT(left_type[LBOT])) {\n\n            nnz_cache[3 + 8 * 3] =\n\n            nnz_cache[3 + 8 * 4] = (h->cbp_table[left_xy[LBOT]] & 0x8000) >> 12; // FIXME check MBAFF\n\n        }\n\n\n\n        if (IS_8x8DCT(mb_type)) {\n\n            nnz_cache[scan8[0]] =\n\n            nnz_cache[scan8[1]] =\n\n            nnz_cache[scan8[2]] =\n\n            nnz_cache[scan8[3]] = (sl->cbp & 0x1000) >> 12;\n\n\n\n            nnz_cache[scan8[0 + 4]] =\n\n            nnz_cache[scan8[1 + 4]] =\n\n            nnz_cache[scan8[2 + 4]] =\n\n            nnz_cache[scan8[3 + 4]] = (sl->cbp & 0x2000) >> 12;\n\n\n\n            nnz_cache[scan8[0 + 8]] =\n\n            nnz_cache[scan8[1 + 8]] =\n\n            nnz_cache[scan8[2 + 8]] =\n\n            nnz_cache[scan8[3 + 8]] = (sl->cbp & 0x4000) >> 12;\n\n\n\n            nnz_cache[scan8[0 + 12]] =\n\n            nnz_cache[scan8[1 + 12]] =\n\n            nnz_cache[scan8[2 + 12]] =\n\n            nnz_cache[scan8[3 + 12]] = (sl->cbp & 0x8000) >> 12;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 12542, "_split": "valid", "_hash": "2f7bcb0dcddfcac3167d769b4affbfa7"}
{"project": "FFmpeg", "commit_id": "92dbd65700334ac9c77bf085fca7b72dd7445ffd", "target": 1, "func": "static int h264_parse(AVCodecParserContext *s,\n\n                      AVCodecContext *avctx,\n\n                      const uint8_t **poutbuf, int *poutbuf_size,\n\n                      const uint8_t *buf, int buf_size)\n\n{\n\n    H264ParseContext *p = s->priv_data;\n\n    ParseContext *pc = &p->pc;\n\n    int next;\n\n\n\n    if (!p->got_first) {\n\n        p->got_first = 1;\n\n        if (avctx->extradata_size) {\n\n            ff_h264_decode_extradata(avctx->extradata, avctx->extradata_size,\n\n                                     &p->ps, &p->is_avc, &p->nal_length_size,\n\n                                     avctx->err_recognition, avctx);\n\n        }\n\n    }\n\n\n\n    if (s->flags & PARSER_FLAG_COMPLETE_FRAMES) {\n\n        next = buf_size;\n\n    } else {\n\n        next = h264_find_frame_end(p, buf, buf_size, avctx);\n\n\n\n        if (ff_combine_frame(pc, next, &buf, &buf_size) < 0) {\n\n            *poutbuf      = NULL;\n\n            *poutbuf_size = 0;\n\n            return buf_size;\n\n        }\n\n\n\n        if (next < 0 && next != END_NOT_FOUND) {\n\n            av_assert1(pc->last_index + next >= 0);\n\n            h264_find_frame_end(p, &pc->buffer[pc->last_index + next], -next, avctx); // update state\n\n        }\n\n    }\n\n\n\n    parse_nal_units(s, avctx, buf, buf_size);\n\n\n\n    if (avctx->framerate.num)\n\n        avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n\n    if (p->sei.picture_timing.cpb_removal_delay >= 0) {\n\n        s->dts_sync_point    = p->sei.buffering_period.present;\n\n        s->dts_ref_dts_delta = p->sei.picture_timing.cpb_removal_delay;\n\n        s->pts_dts_delta     = p->sei.picture_timing.dpb_output_delay;\n\n    } else {\n\n        s->dts_sync_point    = INT_MIN;\n\n        s->dts_ref_dts_delta = INT_MIN;\n\n        s->pts_dts_delta     = INT_MIN;\n\n    }\n\n\n\n    if (s->flags & PARSER_FLAG_ONCE) {\n\n        s->flags &= PARSER_FLAG_COMPLETE_FRAMES;\n\n    }\n\n\n\n    if (s->dts_sync_point >= 0) {\n\n        int64_t den = avctx->time_base.den * avctx->pkt_timebase.num;\n\n        if (den > 0) {\n\n            int64_t num = avctx->time_base.num * avctx->pkt_timebase.den;\n\n            if (s->dts != AV_NOPTS_VALUE) {\n\n                // got DTS from the stream, update reference timestamp\n\n                p->reference_dts = s->dts - av_rescale(s->dts_ref_dts_delta, num, den);\n\n            } else if (p->reference_dts != AV_NOPTS_VALUE) {\n\n                // compute DTS based on reference timestamp\n\n                s->dts = p->reference_dts + av_rescale(s->dts_ref_dts_delta, num, den);\n\n            }\n\n\n\n            if (p->reference_dts != AV_NOPTS_VALUE && s->pts == AV_NOPTS_VALUE)\n\n                s->pts = s->dts + av_rescale(s->pts_dts_delta, num, den);\n\n\n\n            if (s->dts_sync_point > 0)\n\n                p->reference_dts = s->dts; // new reference\n\n        }\n\n    }\n\n\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return next;\n\n}\n", "idx": 12579, "_split": "valid", "_hash": "acc5c35662b66f72af97064d5ffc2c75"}
{"project": "FFmpeg", "commit_id": "6d789f50d261e4c0c2a8b02edbb86fd77247322c", "target": 1, "func": "static int flv_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    FLVContext *flv = s->priv_data;\n\n    int ret, i, type, size, flags;\n\n    int stream_type=-1;\n\n    int64_t next, pos;\n\n    int64_t dts, pts = AV_NOPTS_VALUE;\n\n    AVStream *st = NULL;\n\n\n\n for(;;avio_skip(s->pb, 4)){ /* pkt size is repeated at end. skip it */\n\n    pos = avio_tell(s->pb);\n\n    type = avio_r8(s->pb);\n\n    size = avio_rb24(s->pb);\n\n    dts = avio_rb24(s->pb);\n\n    dts |= avio_r8(s->pb) << 24;\n\n    av_dlog(s, \"type:%d, size:%d, dts:%\"PRId64\"\\n\", type, size, dts);\n\n    if (url_feof(s->pb))\n\n        return AVERROR_EOF;\n\n    avio_skip(s->pb, 3); /* stream id, always 0 */\n\n    flags = 0;\n\n\n\n    if(size == 0)\n\n        continue;\n\n\n\n    next= size + avio_tell(s->pb);\n\n\n\n    if (type == FLV_TAG_TYPE_AUDIO) {\n\n        stream_type=FLV_STREAM_TYPE_AUDIO;\n\n        flags = avio_r8(s->pb);\n\n        size--;\n\n    } else if (type == FLV_TAG_TYPE_VIDEO) {\n\n        stream_type=FLV_STREAM_TYPE_VIDEO;\n\n        flags = avio_r8(s->pb);\n\n        size--;\n\n        if ((flags & 0xf0) == 0x50) /* video info / command frame */\n\n            goto skip;\n\n    } else if (type == FLV_TAG_TYPE_META) {\n\n        if (size > 13+1+4 && dts == 0) { // Header-type metadata stuff\n\n            flv_read_metabody(s, next);\n\n            goto skip;\n\n        } else if (dts != 0) { // Script-data \"special\" metadata frames - don't skip\n\n            stream_type=FLV_STREAM_TYPE_DATA;\n\n        } else {\n\n            goto skip;\n\n        }\n\n    } else {\n\n        av_log(s, AV_LOG_DEBUG, \"skipping flv packet: type %d, size %d, flags %d\\n\", type, size, flags);\n\n    skip:\n\n        avio_seek(s->pb, next, SEEK_SET);\n\n        continue;\n\n    }\n\n\n\n    /* skip empty data packets */\n\n    if (!size)\n\n        continue;\n\n\n\n    /* now find stream */\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        st = s->streams[i];\n\n        if (st->id == stream_type)\n\n            break;\n\n    }\n\n    if(i == s->nb_streams){\n\n        av_log(s, AV_LOG_WARNING, \"Stream discovered after head already parsed\\n\");\n\n        st= create_stream(s, stream_type);\n\n        s->ctx_flags &= ~AVFMTCTX_NOHEADER;\n\n    }\n\n    av_dlog(s, \"%d %X %d \\n\", stream_type, flags, st->discard);\n\n    if(  (st->discard >= AVDISCARD_NONKEY && !((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY || (stream_type == FLV_STREAM_TYPE_AUDIO)))\n\n       ||(st->discard >= AVDISCARD_BIDIR  &&  ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_DISP_INTER && (stream_type == FLV_STREAM_TYPE_VIDEO)))\n\n       || st->discard >= AVDISCARD_ALL\n\n       ){\n\n        avio_seek(s->pb, next, SEEK_SET);\n\n        continue;\n\n    }\n\n    if ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY)\n\n        av_add_index_entry(st, pos, dts, size, 0, AVINDEX_KEYFRAME);\n\n    break;\n\n }\n\n\n\n    // if not streamed and no duration from metadata then seek to end to find the duration from the timestamps\n\n    if(s->pb->seekable && (!s->duration || s->duration==AV_NOPTS_VALUE)){\n\n        int size;\n\n        const int64_t pos= avio_tell(s->pb);\n\n        const int64_t fsize= avio_size(s->pb);\n\n        avio_seek(s->pb, fsize-4, SEEK_SET);\n\n        size= avio_rb32(s->pb);\n\n        avio_seek(s->pb, fsize-3-size, SEEK_SET);\n\n        if(size == avio_rb24(s->pb) + 11){\n\n            uint32_t ts = avio_rb24(s->pb);\n\n            ts |= avio_r8(s->pb) << 24;\n\n            s->duration = ts * (int64_t)AV_TIME_BASE / 1000;\n\n        }\n\n        avio_seek(s->pb, pos, SEEK_SET);\n\n    }\n\n\n\n    if(stream_type == FLV_STREAM_TYPE_AUDIO){\n\n        if(!st->codec->channels || !st->codec->sample_rate || !st->codec->bits_per_coded_sample) {\n\n            st->codec->channels = (flags & FLV_AUDIO_CHANNEL_MASK) == FLV_STEREO ? 2 : 1;\n\n            st->codec->sample_rate = (44100 << ((flags & FLV_AUDIO_SAMPLERATE_MASK) >> FLV_AUDIO_SAMPLERATE_OFFSET) >> 3);\n\n            st->codec->bits_per_coded_sample = (flags & FLV_AUDIO_SAMPLESIZE_MASK) ? 16 : 8;\n\n        }\n\n        if(!st->codec->codec_id){\n\n            flv_set_audio_codec(s, st, flags & FLV_AUDIO_CODECID_MASK);\n\n        }\n\n    } else if(stream_type == FLV_STREAM_TYPE_VIDEO) {\n\n        size -= flv_set_video_codec(s, st, flags & FLV_VIDEO_CODECID_MASK);\n\n    }\n\n\n\n    if (st->codec->codec_id == CODEC_ID_AAC ||\n\n        st->codec->codec_id == CODEC_ID_H264 ||\n\n        st->codec->codec_id == CODEC_ID_MPEG4) {\n\n        int type = avio_r8(s->pb);\n\n        size--;\n\n        if (st->codec->codec_id == CODEC_ID_H264 || st->codec->codec_id == CODEC_ID_MPEG4) {\n\n            int32_t cts = (avio_rb24(s->pb)+0xff800000)^0xff800000; // sign extension\n\n            pts = dts + cts;\n\n            if (cts < 0) { // dts are wrong\n\n                flv->wrong_dts = 1;\n\n                av_log(s, AV_LOG_WARNING, \"negative cts, previous timestamps might be wrong\\n\");\n\n            }\n\n            if (flv->wrong_dts)\n\n                dts = AV_NOPTS_VALUE;\n\n        }\n\n        if (type == 0) {\n\n            if ((ret = flv_get_extradata(s, st, size)) < 0)\n\n                return ret;\n\n            if (st->codec->codec_id == CODEC_ID_AAC) {\n\n                MPEG4AudioConfig cfg;\n\n                ff_mpeg4audio_get_config(&cfg, st->codec->extradata,\n\n                                         st->codec->extradata_size);\n\n                st->codec->channels = cfg.channels;\n\n                if (cfg.ext_sample_rate)\n\n                    st->codec->sample_rate = cfg.ext_sample_rate;\n\n                else\n\n                    st->codec->sample_rate = cfg.sample_rate;\n\n                av_dlog(s, \"mp4a config channels %d sample rate %d\\n\",\n\n                        st->codec->channels, st->codec->sample_rate);\n\n            }\n\n\n\n            ret = AVERROR(EAGAIN);\n\n            goto leave;\n\n        }\n\n    }\n\n\n\n    /* skip empty data packets */\n\n    if (!size) {\n\n        ret = AVERROR(EAGAIN);\n\n        goto leave;\n\n    }\n\n\n\n    ret= av_get_packet(s->pb, pkt, size);\n\n    if (ret < 0) {\n\n        return AVERROR(EIO);\n\n    }\n\n    /* note: we need to modify the packet size here to handle the last\n\n       packet */\n\n    pkt->size = ret;\n\n    pkt->dts = dts;\n\n    pkt->pts = pts == AV_NOPTS_VALUE ? dts : pts;\n\n    pkt->stream_index = st->index;\n\n\n\n    if (    stream_type == FLV_STREAM_TYPE_AUDIO ||\n\n            ((flags & FLV_VIDEO_FRAMETYPE_MASK) == FLV_FRAME_KEY) ||\n\n            stream_type == FLV_STREAM_TYPE_DATA)\n\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\n\n\nleave:\n\n    avio_skip(s->pb, 4);\n\n    return ret;\n\n}\n", "idx": 12614, "_split": "valid", "_hash": "12dc9e82c25fa33e2cfe53c56b91512d"}
{"project": "FFmpeg", "commit_id": "07d84a4e9f37a42a390418928cc086246f846e3f", "target": 0, "func": "static int MPA_encode_init(AVCodecContext *avctx)\n\n{\n\n    MpegAudioContext *s = avctx->priv_data;\n\n    int freq = avctx->sample_rate;\n\n    int bitrate = avctx->bit_rate;\n\n    int channels = avctx->channels;\n\n    int i, v, table;\n\n    float a;\n\n\n\n    if (channels > 2)\n\n        return -1;\n\n    bitrate = bitrate / 1000;\n\n    s->nb_channels = channels;\n\n    s->freq = freq;\n\n    s->bit_rate = bitrate * 1000;\n\n    avctx->frame_size = MPA_FRAME_SIZE;\n\n\n\n    /* encoding freq */\n\n    s->lsf = 0;\n\n    for(i=0;i<3;i++) {\n\n        if (mpa_freq_tab[i] == freq)\n\n            break;\n\n        if ((mpa_freq_tab[i] / 2) == freq) {\n\n            s->lsf = 1;\n\n            break;\n\n        }\n\n    }\n\n    if (i == 3){\n\n        av_log(avctx, AV_LOG_ERROR, \"Sampling rate %d is not allowed in mp2\\n\", freq);\n\n        return -1;\n\n    }\n\n    s->freq_index = i;\n\n\n\n    /* encoding bitrate & frequency */\n\n    for(i=0;i<15;i++) {\n\n        if (mpa_bitrate_tab[s->lsf][1][i] == bitrate)\n\n            break;\n\n    }\n\n    if (i == 15){\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate %d is not allowed in mp2\\n\", bitrate);\n\n        return -1;\n\n    }\n\n    s->bitrate_index = i;\n\n\n\n    /* compute total header size & pad bit */\n\n\n\n    a = (float)(bitrate * 1000 * MPA_FRAME_SIZE) / (freq * 8.0);\n\n    s->frame_size = ((int)a) * 8;\n\n\n\n    /* frame fractional size to compute padding */\n\n    s->frame_frac = 0;\n\n    s->frame_frac_incr = (int)((a - floor(a)) * 65536.0);\n\n\n\n    /* select the right allocation table */\n\n    table = l2_select_table(bitrate, s->nb_channels, freq, s->lsf);\n\n\n\n    /* number of used subbands */\n\n    s->sblimit = sblimit_table[table];\n\n    s->alloc_table = alloc_tables[table];\n\n\n\n#ifdef DEBUG\n\n    av_log(avctx, AV_LOG_DEBUG, \"%d kb/s, %d Hz, frame_size=%d bits, table=%d, padincr=%x\\n\",\n\n           bitrate, freq, s->frame_size, table, s->frame_frac_incr);\n\n#endif\n\n\n\n    for(i=0;i<s->nb_channels;i++)\n\n        s->samples_offset[i] = 0;\n\n\n\n    for(i=0;i<257;i++) {\n\n        int v;\n\n        v = mpa_enwindow[i];\n\n#if WFRAC_BITS != 16\n\n        v = (v + (1 << (16 - WFRAC_BITS - 1))) >> (16 - WFRAC_BITS);\n\n#endif\n\n        filter_bank[i] = v;\n\n        if ((i & 63) != 0)\n\n            v = -v;\n\n        if (i != 0)\n\n            filter_bank[512 - i] = v;\n\n    }\n\n\n\n    for(i=0;i<64;i++) {\n\n        v = (int)(pow(2.0, (3 - i) / 3.0) * (1 << 20));\n\n        if (v <= 0)\n\n            v = 1;\n\n        scale_factor_table[i] = v;\n\n#ifdef USE_FLOATS\n\n        scale_factor_inv_table[i] = pow(2.0, -(3 - i) / 3.0) / (float)(1 << 20);\n\n#else\n\n#define P 15\n\n        scale_factor_shift[i] = 21 - P - (i / 3);\n\n        scale_factor_mult[i] = (1 << P) * pow(2.0, (i % 3) / 3.0);\n\n#endif\n\n    }\n\n    for(i=0;i<128;i++) {\n\n        v = i - 64;\n\n        if (v <= -3)\n\n            v = 0;\n\n        else if (v < 0)\n\n            v = 1;\n\n        else if (v == 0)\n\n            v = 2;\n\n        else if (v < 3)\n\n            v = 3;\n\n        else\n\n            v = 4;\n\n        scale_diff_table[i] = v;\n\n    }\n\n\n\n    for(i=0;i<17;i++) {\n\n        v = quant_bits[i];\n\n        if (v < 0)\n\n            v = -v;\n\n        else\n\n            v = v * 3;\n\n        total_quant_bits[i] = 12 * v;\n\n    }\n\n\n\n    avctx->coded_frame= avcodec_alloc_frame();\n\n    avctx->coded_frame->key_frame= 1;\n\n\n\n    return 0;\n\n}\n", "idx": 12651, "_split": "valid", "_hash": "747ffda9fa86d3f0a4b1488027fd9728"}
{"project": "FFmpeg", "commit_id": "7b6883898ff9000b9a9e71fc1fb6e842ec850a79", "target": 0, "func": "static void frame_thread_free(AVCodecContext *avctx, int thread_count)\n\n{\n\n    FrameThreadContext *fctx = avctx->thread_opaque;\n\n    AVCodec *codec = avctx->codec;\n\n    int i;\n\n\n\n    park_frame_worker_threads(fctx, thread_count);\n\n\n\n    if (fctx->prev_thread)\n\n        update_context_from_thread(fctx->threads->avctx, fctx->prev_thread->avctx, 0);\n\n\n\n    fctx->die = 1;\n\n\n\n    for (i = 0; i < thread_count; i++) {\n\n        PerThreadContext *p = &fctx->threads[i];\n\n\n\n        pthread_mutex_lock(&p->mutex);\n\n        pthread_cond_signal(&p->input_cond);\n\n        pthread_mutex_unlock(&p->mutex);\n\n\n\n        pthread_join(p->thread, NULL);\n\n\n\n        if (codec->close)\n\n            codec->close(p->avctx);\n\n\n\n        avctx->codec = NULL;\n\n\n\n        release_delayed_buffers(p);\n\n    }\n\n\n\n    for (i = 0; i < thread_count; i++) {\n\n        PerThreadContext *p = &fctx->threads[i];\n\n\n\n        avcodec_default_free_buffers(p->avctx);\n\n\n\n        pthread_mutex_destroy(&p->mutex);\n\n        pthread_mutex_destroy(&p->progress_mutex);\n\n        pthread_cond_destroy(&p->input_cond);\n\n        pthread_cond_destroy(&p->progress_cond);\n\n        pthread_cond_destroy(&p->output_cond);\n\n        av_freep(&p->avpkt.data);\n\n\n\n        if (i)\n\n            av_freep(&p->avctx->priv_data);\n\n\n\n        av_freep(&p->avctx);\n\n    }\n\n\n\n    av_freep(&fctx->threads);\n\n    pthread_mutex_destroy(&fctx->buffer_mutex);\n\n    av_freep(&avctx->thread_opaque);\n\n}\n", "idx": 12680, "_split": "valid", "_hash": "a77cce4a4d8727fc089cab26b3fc3cdb"}
{"project": "FFmpeg", "commit_id": "76c4a644eef92f1a15af11825486f5593bfb0051", "target": 0, "func": "static av_cold int mpc8_decode_init(AVCodecContext * avctx)\n\n{\n\n    int i;\n\n    MPCContext *c = avctx->priv_data;\n\n    GetBitContext gb;\n\n    static int vlc_initialized = 0;\n\n\n\n    static VLC_TYPE band_table[542][2];\n\n    static VLC_TYPE q1_table[520][2];\n\n    static VLC_TYPE q9up_table[524][2];\n\n    static VLC_TYPE scfi0_table[1 << MPC8_SCFI0_BITS][2];\n\n    static VLC_TYPE scfi1_table[1 << MPC8_SCFI1_BITS][2];\n\n    static VLC_TYPE dscf0_table[560][2];\n\n    static VLC_TYPE dscf1_table[598][2];\n\n    static VLC_TYPE q3_0_table[512][2];\n\n    static VLC_TYPE q3_1_table[516][2];\n\n    static VLC_TYPE codes_table[5708][2];\n\n\n\n    if(avctx->extradata_size < 2){\n\n        av_log(avctx, AV_LOG_ERROR, \"Too small extradata size (%i)!\\n\", avctx->extradata_size);\n\n        return -1;\n\n    }\n\n    memset(c->oldDSCF, 0, sizeof(c->oldDSCF));\n\n    av_lfg_init(&c->rnd, 0xDEADBEEF);\n\n    dsputil_init(&c->dsp, avctx);\n\n\n\n    ff_mpc_init();\n\n\n\n    init_get_bits(&gb, avctx->extradata, 16);\n\n\n\n    skip_bits(&gb, 3);//sample rate\n\n    c->maxbands = get_bits(&gb, 5) + 1;\n\n    skip_bits(&gb, 4);//channels\n\n    c->MSS = get_bits1(&gb);\n\n    c->frames = 1 << (get_bits(&gb, 3) * 2);\n\n\n\n    if(vlc_initialized) return 0;\n\n    av_log(avctx, AV_LOG_DEBUG, \"Initing VLC\\n\");\n\n\n\n    band_vlc.table = band_table;\n\n    band_vlc.table_allocated = 542;\n\n    init_vlc(&band_vlc, MPC8_BANDS_BITS, MPC8_BANDS_SIZE,\n\n             mpc8_bands_bits,  1, 1,\n\n             mpc8_bands_codes, 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n\n\n    q1_vlc.table = q1_table;\n\n    q1_vlc.table_allocated = 520;\n\n    init_vlc(&q1_vlc, MPC8_Q1_BITS, MPC8_Q1_SIZE,\n\n             mpc8_q1_bits,  1, 1,\n\n             mpc8_q1_codes, 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n    q9up_vlc.table = q9up_table;\n\n    q9up_vlc.table_allocated = 524;\n\n    init_vlc(&q9up_vlc, MPC8_Q9UP_BITS, MPC8_Q9UP_SIZE,\n\n             mpc8_q9up_bits,  1, 1,\n\n             mpc8_q9up_codes, 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n\n\n    scfi_vlc[0].table = scfi0_table;\n\n    scfi_vlc[0].table_allocated = 1 << MPC8_SCFI0_BITS;\n\n    init_vlc(&scfi_vlc[0], MPC8_SCFI0_BITS, MPC8_SCFI0_SIZE,\n\n             mpc8_scfi0_bits,  1, 1,\n\n             mpc8_scfi0_codes, 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n    scfi_vlc[1].table = scfi1_table;\n\n    scfi_vlc[1].table_allocated = 1 << MPC8_SCFI1_BITS;\n\n    init_vlc(&scfi_vlc[1], MPC8_SCFI1_BITS, MPC8_SCFI1_SIZE,\n\n             mpc8_scfi1_bits,  1, 1,\n\n             mpc8_scfi1_codes, 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n\n\n    dscf_vlc[0].table = dscf0_table;\n\n    dscf_vlc[0].table_allocated = 560;\n\n    init_vlc(&dscf_vlc[0], MPC8_DSCF0_BITS, MPC8_DSCF0_SIZE,\n\n             mpc8_dscf0_bits,  1, 1,\n\n             mpc8_dscf0_codes, 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n    dscf_vlc[1].table = dscf1_table;\n\n    dscf_vlc[1].table_allocated = 598;\n\n    init_vlc(&dscf_vlc[1], MPC8_DSCF1_BITS, MPC8_DSCF1_SIZE,\n\n             mpc8_dscf1_bits,  1, 1,\n\n             mpc8_dscf1_codes, 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n\n\n    q3_vlc[0].table = q3_0_table;\n\n    q3_vlc[0].table_allocated = 512;\n\n    init_vlc_sparse(&q3_vlc[0], MPC8_Q3_BITS, MPC8_Q3_SIZE,\n\n             mpc8_q3_bits,  1, 1,\n\n             mpc8_q3_codes, 1, 1,\n\n             mpc8_q3_syms,  1, 1, INIT_VLC_USE_NEW_STATIC);\n\n    q3_vlc[1].table = q3_1_table;\n\n    q3_vlc[1].table_allocated = 516;\n\n    init_vlc_sparse(&q3_vlc[1], MPC8_Q4_BITS, MPC8_Q4_SIZE,\n\n             mpc8_q4_bits,  1, 1,\n\n             mpc8_q4_codes, 1, 1,\n\n             mpc8_q4_syms,  1, 1, INIT_VLC_USE_NEW_STATIC);\n\n\n\n    for(i = 0; i < 2; i++){\n\n        res_vlc[i].table = &codes_table[vlc_offsets[0+i]];\n\n        res_vlc[i].table_allocated = vlc_offsets[1+i] - vlc_offsets[0+i];\n\n        init_vlc(&res_vlc[i], MPC8_RES_BITS, MPC8_RES_SIZE,\n\n                 &mpc8_res_bits[i],  1, 1,\n\n                 &mpc8_res_codes[i], 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n\n\n        q2_vlc[i].table = &codes_table[vlc_offsets[2+i]];\n\n        q2_vlc[i].table_allocated = vlc_offsets[3+i] - vlc_offsets[2+i];\n\n        init_vlc(&q2_vlc[i], MPC8_Q2_BITS, MPC8_Q2_SIZE,\n\n                 &mpc8_q2_bits[i],  1, 1,\n\n                 &mpc8_q2_codes[i], 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n\n\n        quant_vlc[0][i].table = &codes_table[vlc_offsets[4+i]];\n\n        quant_vlc[0][i].table_allocated = vlc_offsets[5+i] - vlc_offsets[4+i];\n\n        init_vlc(&quant_vlc[0][i], MPC8_Q5_BITS, MPC8_Q5_SIZE,\n\n                 &mpc8_q5_bits[i],  1, 1,\n\n                 &mpc8_q5_codes[i], 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n        quant_vlc[1][i].table = &codes_table[vlc_offsets[6+i]];\n\n        quant_vlc[1][i].table_allocated = vlc_offsets[7+i] - vlc_offsets[6+i];\n\n        init_vlc(&quant_vlc[1][i], MPC8_Q6_BITS, MPC8_Q6_SIZE,\n\n                 &mpc8_q6_bits[i],  1, 1,\n\n                 &mpc8_q6_codes[i], 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n        quant_vlc[2][i].table = &codes_table[vlc_offsets[8+i]];\n\n        quant_vlc[2][i].table_allocated = vlc_offsets[9+i] - vlc_offsets[8+i];\n\n        init_vlc(&quant_vlc[2][i], MPC8_Q7_BITS, MPC8_Q7_SIZE,\n\n                 &mpc8_q7_bits[i],  1, 1,\n\n                 &mpc8_q7_codes[i], 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n        quant_vlc[3][i].table = &codes_table[vlc_offsets[10+i]];\n\n        quant_vlc[3][i].table_allocated = vlc_offsets[11+i] - vlc_offsets[10+i];\n\n        init_vlc(&quant_vlc[3][i], MPC8_Q8_BITS, MPC8_Q8_SIZE,\n\n                 &mpc8_q8_bits[i],  1, 1,\n\n                 &mpc8_q8_codes[i], 1, 1, INIT_VLC_USE_NEW_STATIC);\n\n    }\n\n    vlc_initialized = 1;\n\n    avctx->sample_fmt = SAMPLE_FMT_S16;\n\n    avctx->channel_layout = (avctx->channels==2) ? CH_LAYOUT_STEREO : CH_LAYOUT_MONO;\n\n    return 0;\n\n}\n", "idx": 12718, "_split": "valid", "_hash": "21bf7ed1637264709bb65c49e5c3edc6"}
{"project": "FFmpeg", "commit_id": "a466e345e41253aa2c8cf9d62ff32be8d2cde0fa", "target": 0, "func": "static void unpack_modes(Vp3DecodeContext *s, GetBitContext *gb)\n\n{\n\n    int i, j, k;\n\n    int scheme;\n\n    int current_macroblock;\n\n    int current_fragment;\n\n    int coding_mode;\n\n\n\n    debug_vp3(\"  vp3: unpacking encoding modes\\n\");\n\n\n\n    if (s->keyframe) {\n\n        debug_vp3(\"    keyframe-- all blocks are coded as INTRA\\n\");\n\n\n\n        for (i = 0; i < s->fragment_count; i++)\n\n            s->all_fragments[i].coding_method = MODE_INTRA;\n\n\n\n    } else {\n\n\n\n        /* fetch the mode coding scheme for this frame */\n\n        scheme = get_bits(gb, 3);\n\n        debug_modes(\"    using mode alphabet %d\\n\", scheme);\n\n\n\n        /* is it a custom coding scheme? */\n\n        if (scheme == 0) {\n\n            debug_modes(\"    custom mode alphabet ahead:\\n\");\n\n            for (i = 0; i < 8; i++)\n\n                ModeAlphabet[0][i] = get_bits(gb, 3);\n\n        }\n\n\n\n        for (i = 0; i < 8; i++)\n\n            debug_modes(\"      mode[%d][%d] = %d\\n\", scheme, i, \n\n                ModeAlphabet[scheme][i]);\n\n\n\n        /* iterate through all of the macroblocks that contain 1 or more\n\n         * coded fragments */\n\n        for (i = 0; i < s->u_superblock_start; i++) {\n\n\n\n            for (j = 0; j < 4; j++) {\n\n                current_macroblock = s->superblock_macroblocks[i * 4 + j];\n\n                if ((current_macroblock == -1) ||\n\n                    (!s->macroblock_coded[current_macroblock]))\n\n                    continue;\n\n\n\n                /* mode 7 means get 3 bits for each coding mode */\n\n                if (scheme == 7)\n\n                    coding_mode = get_bits(gb, 3);\n\n                else\n\n                    coding_mode = ModeAlphabet[scheme][get_mode_code(gb)];\n\n\n\n                for (k = 0; k < 6; k++) {\n\n                    current_fragment = \n\n                        s->macroblock_fragments[current_macroblock * 6 + k];\n\n                    if (s->all_fragments[current_fragment].coding_method != \n\n                        MODE_COPY)\n\n                        s->all_fragments[current_fragment].coding_method =\n\n                            coding_mode;\n\n                }\n\n\n\n                debug_modes(\"    coding method for macroblock starting @ fragment %d = %d\\n\",\n\n                    s->macroblock_fragments[current_macroblock * 6], coding_mode);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 12775, "_split": "valid", "_hash": "835e203b332bcb7d531cbcc1a343ec1a"}
{"project": "FFmpeg", "commit_id": "22e49e6edead9c83696f20127988f659b952ce65", "target": 0, "func": "static int dds_decode(AVCodecContext *avctx, void *data,\n\n                      int *got_frame, AVPacket *avpkt)\n\n{\n\n    DDSContext *ctx = avctx->priv_data;\n\n    GetByteContext *gbc = &ctx->gbc;\n\n    AVFrame *frame = data;\n\n    int mipmap;\n\n    int ret;\n\n\n\n    ff_texturedsp_init(&ctx->texdsp);\n\n    bytestream2_init(gbc, avpkt->data, avpkt->size);\n\n\n\n    if (bytestream2_get_bytes_left(gbc) < 128) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Frame is too small (%d).\\n\",\n\n               bytestream2_get_bytes_left(gbc));\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (bytestream2_get_le32(gbc) != MKTAG('D', 'D', 'S', ' ') ||\n\n        bytestream2_get_le32(gbc) != 124) { // header size\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid DDS header.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bytestream2_skip(gbc, 4); // flags\n\n\n\n    avctx->height = bytestream2_get_le32(gbc);\n\n    avctx->width  = bytestream2_get_le32(gbc);\n\n    ret = av_image_check_size(avctx->width, avctx->height, 0, avctx);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid image size %dx%d.\\n\",\n\n               avctx->width, avctx->height);\n\n        return ret;\n\n    }\n\n\n\n    /* Since codec is based on 4x4 blocks, size is aligned to 4. */\n\n    avctx->coded_width  = FFALIGN(avctx->width,  TEXTURE_BLOCK_W);\n\n    avctx->coded_height = FFALIGN(avctx->height, TEXTURE_BLOCK_H);\n\n\n\n    bytestream2_skip(gbc, 4); // pitch\n\n    bytestream2_skip(gbc, 4); // depth\n\n    mipmap = bytestream2_get_le32(gbc);\n\n    if (mipmap != 0)\n\n        av_log(avctx, AV_LOG_VERBOSE, \"Found %d mipmaps (ignored).\\n\", mipmap);\n\n\n\n    /* Extract pixel format information, considering additional elements\n\n     * in reserved1 and reserved2. */\n\n    ret = parse_pixel_format(avctx);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    ret = ff_get_buffer(avctx, frame, 0);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (ctx->compressed) {\n\n        int size = (avctx->coded_height / TEXTURE_BLOCK_H) *\n\n                   (avctx->coded_width / TEXTURE_BLOCK_W) * ctx->tex_ratio;\n\n        ctx->slice_count = av_clip(avctx->thread_count, 1,\n\n                                   avctx->coded_height / TEXTURE_BLOCK_H);\n\n\n\n        if (bytestream2_get_bytes_left(gbc) < size) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Compressed Buffer is too small (%d < %d).\\n\",\n\n                   bytestream2_get_bytes_left(gbc), size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        /* Use the decompress function on the texture, one block per thread. */\n\n        ctx->tex_data = gbc->buffer;\n\n        avctx->execute2(avctx, decompress_texture_thread, frame, NULL, ctx->slice_count);\n\n    } else {\n\n        int linesize = av_image_get_linesize(avctx->pix_fmt, frame->width, 0);\n\n\n\n        if (ctx->paletted) {\n\n            int i;\n\n            uint32_t *p = (uint32_t*) frame->data[1];\n\n\n\n            /* Use the first 1024 bytes as palette, then copy the rest. */\n\n            for (i = 0; i < 256; i++) {\n\n                uint32_t rgba = 0;\n\n                rgba |= bytestream2_get_byte(gbc) << 16;\n\n                rgba |= bytestream2_get_byte(gbc) << 8;\n\n                rgba |= bytestream2_get_byte(gbc) << 0;\n\n                rgba |= bytestream2_get_byte(gbc) << 24;\n\n                p[i] = rgba;\n\n            }\n\n\n\n            frame->palette_has_changed = 1;\n\n        }\n\n\n\n        if (bytestream2_get_bytes_left(gbc) < frame->height * linesize) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Buffer is too small (%d < %d).\\n\",\n\n                   bytestream2_get_bytes_left(gbc), frame->height * linesize);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        av_image_copy_plane(frame->data[0], frame->linesize[0],\n\n                            gbc->buffer, linesize,\n\n                            linesize, frame->height);\n\n    }\n\n\n\n    /* Run any post processing here if needed. */\n\n    if (avctx->pix_fmt == AV_PIX_FMT_BGRA ||\n\n        avctx->pix_fmt == AV_PIX_FMT_RGBA ||\n\n        avctx->pix_fmt == AV_PIX_FMT_YA8)\n\n        run_postproc(avctx, frame);\n\n\n\n    /* Frame is ready to be output. */\n\n    frame->pict_type = AV_PICTURE_TYPE_I;\n\n    frame->key_frame = 1;\n\n    *got_frame = 1;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 12862, "_split": "valid", "_hash": "5a1ed71eb7e27b6e2ff08626ec7dc1d6"}
{"project": "FFmpeg", "commit_id": "041086191fc08ab162ad6117b07a5f39639d5d9d", "target": 0, "func": "static double get_video_clock(VideoState *is)\n\n{\n\n    double delta;\n\n    if (is->paused) { //FIXME timing gets messed after pause\n\n        delta = 0;\n\n    } else {\n\n        delta = (av_gettime() - is->video_current_pts_time) / 1000000.0;\n\n    }\n\n    return is->video_current_pts + delta;\n\n}\n", "idx": 12921, "_split": "valid", "_hash": "e2af4b4b77ba44f19794dcce7eeb1198"}
{"project": "FFmpeg", "commit_id": "d8870f120ea5f46940bac63a90424ca6a6000ad9", "target": 0, "func": "static void set_downmix_coeffs(AC3DecodeContext *s)\n\n{\n\n    int i;\n\n    float cmix = gain_levels[s->center_mix_level];\n\n    float smix = gain_levels[s->surround_mix_level];\n\n\n\n    for(i=0; i<s->fbw_channels; i++) {\n\n        s->downmix_coeffs[i][0] = gain_levels[ac3_default_coeffs[s->channel_mode][i][0]];\n\n        s->downmix_coeffs[i][1] = gain_levels[ac3_default_coeffs[s->channel_mode][i][1]];\n\n    }\n\n    if(s->channel_mode > 1 && s->channel_mode & 1) {\n\n        s->downmix_coeffs[1][0] = s->downmix_coeffs[1][1] = cmix;\n\n    }\n\n    if(s->channel_mode == AC3_CHMODE_2F1R || s->channel_mode == AC3_CHMODE_3F1R) {\n\n        int nf = s->channel_mode - 2;\n\n        s->downmix_coeffs[nf][0] = s->downmix_coeffs[nf][1] = smix * LEVEL_MINUS_3DB;\n\n    }\n\n    if(s->channel_mode == AC3_CHMODE_2F2R || s->channel_mode == AC3_CHMODE_3F2R) {\n\n        int nf = s->channel_mode - 4;\n\n        s->downmix_coeffs[nf][0] = s->downmix_coeffs[nf+1][1] = smix;\n\n    }\n\n\n\n    s->downmix_coeff_sum[0] = s->downmix_coeff_sum[1] = 0.0f;\n\n    for(i=0; i<s->fbw_channels; i++) {\n\n        s->downmix_coeff_sum[0] += s->downmix_coeffs[i][0];\n\n        s->downmix_coeff_sum[1] += s->downmix_coeffs[i][1];\n\n    }\n\n}\n", "idx": 12936, "_split": "valid", "_hash": "63dba99fd2ea2e0e2c437e2a0965381f"}
{"project": "FFmpeg", "commit_id": "0ad5ef674b65fe87bb948e1c200f0c320db2f869", "target": 1, "func": "static void calc_diffs(const DecimateContext *dm, struct qitem *q,\n\n                       const AVFrame *f1, const AVFrame *f2)\n\n{\n\n    int64_t maxdiff = -1;\n\n    int64_t *bdiffs = dm->bdiffs;\n\n    int plane, i, j;\n\n\n\n    memset(bdiffs, 0, dm->bdiffsize * sizeof(*bdiffs));\n\n\n\n    for (plane = 0; plane < (dm->chroma ? 3 : 1); plane++) {\n\n        int x, y, xl;\n\n        const int linesize1 = f1->linesize[plane];\n\n        const int linesize2 = f2->linesize[plane];\n\n        const uint8_t *f1p = f1->data[plane];\n\n        const uint8_t *f2p = f2->data[plane];\n\n        int width    = plane ? FF_CEIL_RSHIFT(f1->width,  dm->hsub) : f1->width;\n\n        int height   = plane ? FF_CEIL_RSHIFT(f1->height, dm->vsub) : f1->height;\n\n        int hblockx  = dm->blockx / 2;\n\n        int hblocky  = dm->blocky / 2;\n\n\n\n        if (plane) {\n\n            hblockx >>= dm->hsub;\n\n            hblocky >>= dm->vsub;\n\n        }\n\n\n\n        for (y = 0; y < height; y++) {\n\n            int ydest = y / hblocky;\n\n            int xdest = 0;\n\n\n\n#define CALC_DIFF(nbits) do {                               \\\n\n    for (x = 0; x < width; x += hblockx) {                  \\\n\n        int64_t acc = 0;                                    \\\n\n        int m = FFMIN(width, x + hblockx);                  \\\n\n        for (xl = x; xl < m; xl++)                          \\\n\n            acc += abs(((const uint##nbits##_t *)f1p)[xl] - \\\n\n                       ((const uint##nbits##_t *)f2p)[xl]); \\\n\n        bdiffs[ydest * dm->nxblocks + xdest] += acc;        \\\n\n        xdest++;                                            \\\n\n    }                                                       \\\n\n} while (0)\n\n            if (dm->depth == 8) CALC_DIFF(8);\n\n            else                CALC_DIFF(16);\n\n\n\n            f1p += linesize1;\n\n            f2p += linesize2;\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < dm->nyblocks - 1; i++) {\n\n        for (j = 0; j < dm->nxblocks - 1; j++) {\n\n            int64_t tmp = bdiffs[      i * dm->nxblocks + j    ]\n\n                        + bdiffs[      i * dm->nxblocks + j + 1]\n\n                        + bdiffs[(i + 1) * dm->nxblocks + j    ]\n\n                        + bdiffs[(i + 1) * dm->nxblocks + j + 1];\n\n            if (tmp > maxdiff)\n\n                maxdiff = tmp;\n\n        }\n\n    }\n\n\n\n    q->totdiff = 0;\n\n    for (i = 0; i < dm->bdiffsize; i++)\n\n        q->totdiff += bdiffs[i];\n\n    q->maxbdiff = maxdiff;\n\n}\n", "idx": 12938, "_split": "valid", "_hash": "1013081b9aeedbe0f86ca434feb8bc0f"}
{"project": "FFmpeg", "commit_id": "08a747afb98c11da48b89339c2f1c5fdc56ced7e", "target": 0, "func": "static void compute_exp_strategy(AC3EncodeContext *s)\n\n{\n\n    int ch, blk, blk1;\n\n\n\n    for (ch = !s->cpl_on; ch <= s->fbw_channels; ch++) {\n\n        uint8_t *exp_strategy = s->exp_strategy[ch];\n\n        uint8_t *exp          = s->blocks[0].exp[ch];\n\n        int exp_diff;\n\n\n\n        /* estimate if the exponent variation & decide if they should be\n\n           reused in the next frame */\n\n        exp_strategy[0] = EXP_NEW;\n\n        exp += AC3_MAX_COEFS;\n\n        for (blk = 1; blk < AC3_MAX_BLOCKS; blk++, exp += AC3_MAX_COEFS) {\n\n            if ((ch == CPL_CH && (!s->blocks[blk].cpl_in_use || !s->blocks[blk-1].cpl_in_use)) ||\n\n                (ch  > CPL_CH && (s->blocks[blk].channel_in_cpl[ch] != s->blocks[blk-1].channel_in_cpl[ch]))) {\n\n                exp_strategy[blk] = EXP_NEW;\n\n                continue;\n\n            }\n\n            exp_diff = s->dsp.sad[0](NULL, exp, exp - AC3_MAX_COEFS, 16, 16);\n\n            exp_strategy[blk] = EXP_REUSE;\n\n            if (ch == CPL_CH && exp_diff > (EXP_DIFF_THRESHOLD * (s->blocks[blk].end_freq[ch] - s->start_freq[ch]) / AC3_MAX_COEFS))\n\n                exp_strategy[blk] = EXP_NEW;\n\n            else if (ch > CPL_CH && exp_diff > EXP_DIFF_THRESHOLD)\n\n                exp_strategy[blk] = EXP_NEW;\n\n        }\n\n\n\n        /* now select the encoding strategy type : if exponents are often\n\n           recoded, we use a coarse encoding */\n\n        blk = 0;\n\n        while (blk < AC3_MAX_BLOCKS) {\n\n            blk1 = blk + 1;\n\n            while (blk1 < AC3_MAX_BLOCKS && exp_strategy[blk1] == EXP_REUSE)\n\n                blk1++;\n\n            switch (blk1 - blk) {\n\n            case 1:  exp_strategy[blk] = EXP_D45; break;\n\n            case 2:\n\n            case 3:  exp_strategy[blk] = EXP_D25; break;\n\n            default: exp_strategy[blk] = EXP_D15; break;\n\n            }\n\n            blk = blk1;\n\n        }\n\n    }\n\n    if (s->lfe_on) {\n\n        ch = s->lfe_channel;\n\n        s->exp_strategy[ch][0] = EXP_D15;\n\n        for (blk = 1; blk < AC3_MAX_BLOCKS; blk++)\n\n            s->exp_strategy[ch][blk] = EXP_REUSE;\n\n    }\n\n}\n", "idx": 12988, "_split": "valid", "_hash": "07ee2b247c59ea6cbce1c22b18462336"}
{"project": "FFmpeg", "commit_id": "7548783bc5cfd67f1fba9aedd75ac54d43ac01d3", "target": 0, "func": "static void put_frame(\n\n                    AVFormatContext *s,\n\n                    ASFStream       *stream,\n\n                    AVStream        *avst,\n\n                    int             timestamp,\n\n                    const uint8_t   *buf,\n\n                    int             m_obj_size,\n\n                    int             flags\n\n                )\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    int m_obj_offset, payload_len, frag_len1;\n\n\n\n    m_obj_offset = 0;\n\n    while (m_obj_offset < m_obj_size) {\n\n        payload_len = m_obj_size - m_obj_offset;\n\n        if (asf->packet_timestamp_start == -1) {\n\n            asf->multi_payloads_present = (payload_len < MULTI_PAYLOAD_CONSTANT);\n\n\n\n            asf->packet_size_left = PACKET_SIZE;\n\n            if (asf->multi_payloads_present){\n\n                frag_len1 = MULTI_PAYLOAD_CONSTANT - 1;\n\n            }\n\n            else {\n\n                frag_len1 = SINGLE_PAYLOAD_DATA_LENGTH;\n\n            }\n\n            asf->packet_timestamp_start = timestamp;\n\n        }\n\n        else {\n\n            // multi payloads\n\n            frag_len1 = asf->packet_size_left - PAYLOAD_HEADER_SIZE_MULTIPLE_PAYLOADS - PACKET_HEADER_MIN_SIZE - 1;\n\n\n\n            asf->packet_timestamp_start = timestamp;\n\n\n\n            if(frag_len1 < payload_len && avst->codec->codec_type == CODEC_TYPE_AUDIO){\n\n                flush_packet(s);\n\n                continue;\n\n            }\n\n        }\n\n        if (frag_len1 > 0) {\n\n            if (payload_len > frag_len1)\n\n                payload_len = frag_len1;\n\n            else if (payload_len == (frag_len1 - 1))\n\n                payload_len = frag_len1 - 2;  //additional byte need to put padding length\n\n\n\n            put_payload_header(s, stream, timestamp+PREROLL_TIME, m_obj_size, m_obj_offset, payload_len, flags);\n\n            put_buffer(&asf->pb, buf, payload_len);\n\n\n\n            if (asf->multi_payloads_present)\n\n                asf->packet_size_left -= (payload_len + PAYLOAD_HEADER_SIZE_MULTIPLE_PAYLOADS);\n\n            else\n\n                asf->packet_size_left -= (payload_len + PAYLOAD_HEADER_SIZE_SINGLE_PAYLOAD);\n\n            asf->packet_timestamp_end = timestamp;\n\n\n\n            asf->packet_nb_payloads++;\n\n        } else {\n\n            payload_len = 0;\n\n        }\n\n        m_obj_offset += payload_len;\n\n        buf += payload_len;\n\n\n\n        if (!asf->multi_payloads_present)\n\n            flush_packet(s);\n\n        else if (asf->packet_size_left <= (PAYLOAD_HEADER_SIZE_MULTIPLE_PAYLOADS + PACKET_HEADER_MIN_SIZE + 1))\n\n            flush_packet(s);\n\n    }\n\n    stream->seq++;\n\n}\n", "idx": 13027, "_split": "valid", "_hash": "6cde1769034eb94c340d6445420130a1"}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static void render_fragments(Vp3DecodeContext *s,\n                             int first_fragment,\n                             int width,\n                             int height,\n                             int plane /* 0 = Y, 1 = U, 2 = V */) \n{\n    int x, y;\n    int m, n;\n    int i = first_fragment;\n    int16_t *dequantizer;\n    DCTELEM __align16 output_samples[64];\n    unsigned char *output_plane;\n    unsigned char *last_plane;\n    unsigned char *golden_plane;\n    int stride;\n    int motion_x = 0xdeadbeef, motion_y = 0xdeadbeef;\n    int upper_motion_limit, lower_motion_limit;\n    int motion_halfpel_index;\n    uint8_t *motion_source;\n    debug_vp3(\"  vp3: rendering final fragments for %s\\n\",\n        (plane == 0) ? \"Y plane\" : (plane == 1) ? \"U plane\" : \"V plane\");\n    /* set up plane-specific parameters */\n    if (plane == 0) {\n        dequantizer = s->intra_y_dequant;\n        output_plane = s->current_frame.data[0];\n        last_plane = s->last_frame.data[0];\n        golden_plane = s->golden_frame.data[0];\n        stride = s->current_frame.linesize[0];\n\tif (!s->flipped_image) stride = -stride;\n        upper_motion_limit = 7 * s->current_frame.linesize[0];\n        lower_motion_limit = height * s->current_frame.linesize[0] + width - 8;\n    } else if (plane == 1) {\n        dequantizer = s->intra_c_dequant;\n        output_plane = s->current_frame.data[1];\n        last_plane = s->last_frame.data[1];\n        golden_plane = s->golden_frame.data[1];\n        stride = s->current_frame.linesize[1];\n\tif (!s->flipped_image) stride = -stride;\n        upper_motion_limit = 7 * s->current_frame.linesize[1];\n        lower_motion_limit = height * s->current_frame.linesize[1] + width - 8;\n    } else {\n        dequantizer = s->intra_c_dequant;\n        output_plane = s->current_frame.data[2];\n        last_plane = s->last_frame.data[2];\n        golden_plane = s->golden_frame.data[2];\n        stride = s->current_frame.linesize[2];\n\tif (!s->flipped_image) stride = -stride;\n        upper_motion_limit = 7 * s->current_frame.linesize[2];\n        lower_motion_limit = height * s->current_frame.linesize[2] + width - 8;\n    }\n    /* for each fragment row... */\n    for (y = 0; y < height; y += 8) {\n        /* for each fragment in a row... */\n        for (x = 0; x < width; x += 8, i++) {\n            if ((i < 0) || (i >= s->fragment_count)) {\n                av_log(s->avctx, AV_LOG_ERROR, \"  vp3:render_fragments(): bad fragment number (%d)\\n\", i);\n                return;\n            }\n            /* transform if this block was coded */\n            if ((s->all_fragments[i].coding_method != MODE_COPY) &&\n\t\t!((s->avctx->flags & CODEC_FLAG_GRAY) && plane)) {\n                if ((s->all_fragments[i].coding_method == MODE_USING_GOLDEN) ||\n                    (s->all_fragments[i].coding_method == MODE_GOLDEN_MV))\n                    motion_source= golden_plane;\n                else \n                    motion_source= last_plane;\n                motion_source += s->all_fragments[i].first_pixel;\n                motion_halfpel_index = 0;\n                /* sort out the motion vector if this fragment is coded\n                 * using a motion vector method */\n                if ((s->all_fragments[i].coding_method > MODE_INTRA) &&\n                    (s->all_fragments[i].coding_method != MODE_USING_GOLDEN)) {\n                    int src_x, src_y;\n                    motion_x = s->all_fragments[i].motion_x;\n                    motion_y = s->all_fragments[i].motion_y;\n                    if(plane){\n                        motion_x= (motion_x>>1) | (motion_x&1);\n                        motion_y= (motion_y>>1) | (motion_y&1);\n                    }\n                    src_x= (motion_x>>1) + x;\n                    src_y= (motion_y>>1) + y;\nif ((motion_x == 0xbeef) || (motion_y == 0xbeef))\nav_log(s->avctx, AV_LOG_ERROR, \" help! got beefy vector! (%X, %X)\\n\", motion_x, motion_y);\n                    motion_halfpel_index = motion_x & 0x01;\n                    motion_source += (motion_x >> 1);\n//                    motion_y = -motion_y;\n                    motion_halfpel_index |= (motion_y & 0x01) << 1;\n                    motion_source += ((motion_y >> 1) * stride);\n                    if(src_x<0 || src_y<0 || src_x + 9 >= width || src_y + 9 >= height){\n                        uint8_t *temp= s->edge_emu_buffer;\n                        if(stride<0) temp -= 9*stride;\n\t\t\telse temp += 9*stride;\n                        ff_emulated_edge_mc(temp, motion_source, stride, 9, 9, src_x, src_y, width, height);\n                        motion_source= temp;\n                    }\n                }\n                /* first, take care of copying a block from either the\n                 * previous or the golden frame */\n                if (s->all_fragments[i].coding_method != MODE_INTRA) {\n                    //Note, it is possible to implement all MC cases with put_no_rnd_pixels_l2 which would look more like the VP3 source but this would be slower as put_no_rnd_pixels_tab is better optimzed\n                    if(motion_halfpel_index != 3){\n                        s->dsp.put_no_rnd_pixels_tab[1][motion_halfpel_index](\n                            output_plane + s->all_fragments[i].first_pixel,\n                            motion_source, stride, 8);\n                    }else{\n                        int d= (motion_x ^ motion_y)>>31; // d is 0 if motion_x and _y have the same sign, else -1\n                        s->dsp.put_no_rnd_pixels_l2[1](\n                            output_plane + s->all_fragments[i].first_pixel,\n                            motion_source - d, \n                            motion_source + stride + 1 + d, \n                            stride, 8);\n                    }\n                }\n                /* dequantize the DCT coefficients */\n                debug_idct(\"fragment %d, coding mode %d, DC = %d, dequant = %d:\\n\", \n                    i, s->all_fragments[i].coding_method, \n                    s->all_fragments[i].coeffs[0], dequantizer[0]);\n                /* invert DCT and place (or add) in final output */\n                s->dsp.vp3_idct(s->all_fragments[i].coeffs,\n                    dequantizer,\n                    s->all_fragments[i].coeff_count,\n                    output_samples);\n                if (s->all_fragments[i].coding_method == MODE_INTRA) {\n                    s->dsp.put_signed_pixels_clamped(output_samples,\n                        output_plane + s->all_fragments[i].first_pixel,\n                        stride);\n                } else {\n                    s->dsp.add_pixels_clamped(output_samples,\n                        output_plane + s->all_fragments[i].first_pixel,\n                        stride);\n                }\n                debug_idct(\"block after idct_%s():\\n\",\n                    (s->all_fragments[i].coding_method == MODE_INTRA)?\n                    \"put\" : \"add\");\n                for (m = 0; m < 8; m++) {\n                    for (n = 0; n < 8; n++) {\n                        debug_idct(\" %3d\", *(output_plane + \n                            s->all_fragments[i].first_pixel + (m * stride + n)));\n                    }\n                    debug_idct(\"\\n\");\n                }\n                debug_idct(\"\\n\");\n            } else {\n                /* copy directly from the previous frame */\n                s->dsp.put_pixels_tab[1][0](\n                    output_plane + s->all_fragments[i].first_pixel,\n                    last_plane + s->all_fragments[i].first_pixel,\n                    stride, 8);\n            }\n        }\n    }\n    emms_c();\n}", "idx": 13034, "_split": "valid", "_hash": "7aea908c3ca9cf94be754f8d2e83eb7d"}
{"project": "FFmpeg", "commit_id": "7da9f4523159670d577a2808d4481e64008a8894", "target": 1, "func": "static av_cold int cinepak_encode_end(AVCodecContext *avctx)\n\n{\n\n    CinepakEncContext *s = avctx->priv_data;\n\n    int x;\n\n\n\n    av_free(s->codebook_input);\n\n    av_free(s->codebook_closest);\n\n    av_free(s->strip_buf);\n\n    av_free(s->frame_buf);\n\n    av_free(s->mb);\n\n#ifdef CINEPAKENC_DEBUG\n\n    av_free(s->best_mb);\n\n#endif\n\n\n\n    for(x = 0; x < 3; x++)\n\n        av_free(s->pict_bufs[x]);\n\n\n\n    av_log(avctx, AV_LOG_INFO, \"strip coding stats: %i V1 mode, %i V4 mode, %i MC mode (%i V1 encs, %i V4 encs, %i skips)\\n\",\n\n        s->num_v1_mode, s->num_v4_mode, s->num_mc_mode, s->num_v1_encs, s->num_v4_encs, s->num_skips);\n\n\n\n    return 0;\n\n}\n", "idx": 13039, "_split": "valid", "_hash": "7d31e7f77e3ac72fa6974593792158aa"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static void RENAME(lumRangeFromJpeg)(int16_t *dst, int width)\n\n{\n\n    int i;\n\n    for (i = 0; i < width; i++)\n\n        dst[i] = (dst[i]*14071 + 33561947)>>14;\n\n}\n", "idx": 13083, "_split": "valid", "_hash": "d79f52f640e005339128eb08fafc6474"}
{"project": "FFmpeg", "commit_id": "96d0494123a05fb78a0fd3f03b0b5aaefc170b1c", "target": 0, "func": "static int lag_decode_zero_run_line(LagarithContext *l, uint8_t *dst,\n\n                                    const uint8_t *src, int width,\n\n                                    int esc_count)\n\n{\n\n    int i = 0;\n\n    int count;\n\n    uint8_t zero_run = 0;\n\n    const uint8_t *start = src;\n\n    uint8_t mask1 = -(esc_count < 2);\n\n    uint8_t mask2 = -(esc_count < 3);\n\n    uint8_t *end = dst + (width - 2);\n\n\n\noutput_zeros:\n\n    if (l->zeros_rem) {\n\n        count = FFMIN(l->zeros_rem, width - i);\n\n        memset(dst, 0, count);\n\n        l->zeros_rem -= count;\n\n        dst += count;\n\n    }\n\n\n\n    while (dst < end) {\n\n        i = 0;\n\n        while (!zero_run && dst + i < end) {\n\n            i++;\n\n            zero_run =\n\n                !(src[i] | (src[i + 1] & mask1) | (src[i + 2] & mask2));\n\n        }\n\n        if (zero_run) {\n\n            zero_run = 0;\n\n            i += esc_count;\n\n            memcpy(dst, src, i);\n\n            dst += i;\n\n            l->zeros_rem = lag_calc_zero_run(src[i]);\n\n\n\n            src += i + 1;\n\n            goto output_zeros;\n\n        } else {\n\n            memcpy(dst, src, i);\n\n            src += i;\n\n        }\n\n    }\n\n    return  src - start;\n\n}\n", "idx": 13110, "_split": "valid", "_hash": "988feb7acf6a0f789df5851de00b2a87"}
{"project": "FFmpeg", "commit_id": "68aefbe81cb3b9dd002108782bb8d798e1c12806", "target": 1, "func": "static int stream_component_open(VideoState *is, int stream_index)\n\n{\n\n    AVFormatContext *ic = is->ic;\n\n    AVCodecContext *enc;\n\n    AVCodec *codec;\n\n    SDL_AudioSpec wanted_spec, spec;\n\n\n\n    if (stream_index < 0 || stream_index >= ic->nb_streams)\n\n        return -1;\n\n    enc = ic->streams[stream_index]->codec;\n\n\n\n    /* prepare audio output */\n\n    if (enc->codec_type == CODEC_TYPE_AUDIO) {\n\n        if (enc->channels > 0) {\n\n            enc->request_channels = FFMIN(2, enc->channels);\n\n        } else {\n\n            enc->request_channels = 2;\n\n        }\n\n    }\n\n\n\n    codec = avcodec_find_decoder(enc->codec_id);\n\n    enc->debug_mv = debug_mv;\n\n    enc->debug = debug;\n\n    enc->workaround_bugs = workaround_bugs;\n\n    enc->lowres = lowres;\n\n    if(lowres) enc->flags |= CODEC_FLAG_EMU_EDGE;\n\n    enc->idct_algo= idct;\n\n    if(fast) enc->flags2 |= CODEC_FLAG2_FAST;\n\n    enc->skip_frame= skip_frame;\n\n    enc->skip_idct= skip_idct;\n\n    enc->skip_loop_filter= skip_loop_filter;\n\n    enc->error_recognition= error_recognition;\n\n    enc->error_concealment= error_concealment;\n\n    avcodec_thread_init(enc, thread_count);\n\n\n\n    set_context_opts(enc, avcodec_opts[enc->codec_type], 0);\n\n\n\n    if (!codec ||\n\n        avcodec_open(enc, codec) < 0)\n\n        return -1;\n\n\n\n    /* prepare audio output */\n\n    if (enc->codec_type == CODEC_TYPE_AUDIO) {\n\n        wanted_spec.freq = enc->sample_rate;\n\n        wanted_spec.format = AUDIO_S16SYS;\n\n        wanted_spec.channels = enc->channels;\n\n        wanted_spec.silence = 0;\n\n        wanted_spec.samples = SDL_AUDIO_BUFFER_SIZE;\n\n        wanted_spec.callback = sdl_audio_callback;\n\n        wanted_spec.userdata = is;\n\n        if (SDL_OpenAudio(&wanted_spec, &spec) < 0) {\n\n            fprintf(stderr, \"SDL_OpenAudio: %s\\n\", SDL_GetError());\n\n            return -1;\n\n        }\n\n        is->audio_hw_buf_size = spec.size;\n\n        is->audio_src_fmt= SAMPLE_FMT_S16;\n\n    }\n\n\n\n    ic->streams[stream_index]->discard = AVDISCARD_DEFAULT;\n\n    switch(enc->codec_type) {\n\n    case CODEC_TYPE_AUDIO:\n\n        is->audio_stream = stream_index;\n\n        is->audio_st = ic->streams[stream_index];\n\n        is->audio_buf_size = 0;\n\n        is->audio_buf_index = 0;\n\n\n\n        /* init averaging filter */\n\n        is->audio_diff_avg_coef = exp(log(0.01) / AUDIO_DIFF_AVG_NB);\n\n        is->audio_diff_avg_count = 0;\n\n        /* since we do not have a precise anough audio fifo fullness,\n\n           we correct audio sync only if larger than this threshold */\n\n        is->audio_diff_threshold = 2.0 * SDL_AUDIO_BUFFER_SIZE / enc->sample_rate;\n\n\n\n        memset(&is->audio_pkt, 0, sizeof(is->audio_pkt));\n\n        packet_queue_init(&is->audioq);\n\n        SDL_PauseAudio(0);\n\n        break;\n\n    case CODEC_TYPE_VIDEO:\n\n        is->video_stream = stream_index;\n\n        is->video_st = ic->streams[stream_index];\n\n\n\n        is->frame_last_delay = 40e-3;\n\n        is->frame_timer = (double)av_gettime() / 1000000.0;\n\n        is->video_current_pts_time = av_gettime();\n\n\n\n        packet_queue_init(&is->videoq);\n\n        is->video_tid = SDL_CreateThread(video_thread, is);\n\n        break;\n\n    case CODEC_TYPE_SUBTITLE:\n\n        is->subtitle_stream = stream_index;\n\n        is->subtitle_st = ic->streams[stream_index];\n\n        packet_queue_init(&is->subtitleq);\n\n\n\n        is->subtitle_tid = SDL_CreateThread(subtitle_thread, is);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 13121, "_split": "valid", "_hash": "78a30eb15c27893e54084c9caed20cb0"}
{"project": "FFmpeg", "commit_id": "dc5d1515681b57a257443ba72bb81fb3e6e6621b", "target": 0, "func": "static int sls_flags_filename_process(struct AVFormatContext *s, HLSContext *hls,\n\n                                      VariantStream *vs, HLSSegment *en,\n\n                                      double duration, int64_t pos, int64_t size)\n\n{\n\n    if ((hls->flags & (HLS_SECOND_LEVEL_SEGMENT_SIZE | HLS_SECOND_LEVEL_SEGMENT_DURATION)) &&\n\n        strlen(vs->current_segment_final_filename_fmt)) {\n\n        av_strlcpy(vs->avf->filename, vs->current_segment_final_filename_fmt, sizeof(vs->avf->filename));\n\n        if (hls->flags & HLS_SECOND_LEVEL_SEGMENT_SIZE) {\n\n            char * filename = av_strdup(vs->avf->filename);  // %%s will be %s after strftime\n\n            if (!filename) {\n\n                av_free(en);\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            if (replace_int_data_in_filename(vs->avf->filename, sizeof(vs->avf->filename),\n\n                filename, 's', pos + size) < 1) {\n\n                av_log(hls, AV_LOG_ERROR,\n\n                       \"Invalid second level segment filename template '%s', \"\n\n                        \"you can try to remove second_level_segment_size flag\\n\",\n\n                       filename);\n\n                av_free(filename);\n\n                av_free(en);\n\n                return AVERROR(EINVAL);\n\n            }\n\n            av_free(filename);\n\n        }\n\n        if (hls->flags & HLS_SECOND_LEVEL_SEGMENT_DURATION) {\n\n            char * filename = av_strdup(vs->avf->filename);  // %%t will be %t after strftime\n\n            if (!filename) {\n\n                av_free(en);\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            if (replace_int_data_in_filename(vs->avf->filename, sizeof(vs->avf->filename),\n\n                filename, 't',  (int64_t)round(duration * HLS_MICROSECOND_UNIT)) < 1) {\n\n                av_log(hls, AV_LOG_ERROR,\n\n                       \"Invalid second level segment filename template '%s', \"\n\n                        \"you can try to remove second_level_segment_time flag\\n\",\n\n                       filename);\n\n                av_free(filename);\n\n                av_free(en);\n\n                return AVERROR(EINVAL);\n\n            }\n\n            av_free(filename);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 13147, "_split": "valid", "_hash": "bffc22c6b1054c1b0195f70eaff94653"}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static void do_downmix(AC3DecodeContext *ctx)\n\n{\n\n    int from = ctx->bsi.acmod;\n\n    int to = ctx->output;\n\n\n\n    switch (from) {\n\n        case AC3_INPUT_DUALMONO:\n\n            switch (to) {\n\n                case AC3_OUTPUT_MONO:\n\n                    mix_dualmono_to_mono(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_STEREO: /* We Assume that sum of both mono channels is requested */\n\n                    mix_dualmono_to_stereo(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n        case AC3_INPUT_MONO:\n\n            switch (to) {\n\n                case AC3_OUTPUT_STEREO:\n\n                    upmix_mono_to_stereo(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n        case AC3_INPUT_STEREO:\n\n            switch (to) {\n\n                case AC3_OUTPUT_MONO:\n\n                    mix_stereo_to_mono(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n        case AC3_INPUT_3F:\n\n            switch (to) {\n\n                case AC3_OUTPUT_MONO:\n\n                    mix_3f_to_mono(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_STEREO:\n\n                    mix_3f_to_stereo(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n        case AC3_INPUT_2F_1R:\n\n            switch (to) {\n\n                case AC3_OUTPUT_MONO:\n\n                    mix_2f_1r_to_mono(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_STEREO:\n\n                    mix_2f_1r_to_stereo(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_DOLBY:\n\n                    mix_2f_1r_to_dolby(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n        case AC3_INPUT_3F_1R:\n\n            switch (to) {\n\n                case AC3_OUTPUT_MONO:\n\n                    mix_3f_1r_to_mono(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_STEREO:\n\n                    mix_3f_1r_to_stereo(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_DOLBY:\n\n                    mix_3f_1r_to_dolby(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n        case AC3_INPUT_2F_2R:\n\n            switch (to) {\n\n                case AC3_OUTPUT_MONO:\n\n                    mix_2f_2r_to_mono(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_STEREO:\n\n                    mix_2f_2r_to_stereo(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_DOLBY:\n\n                    mix_2f_2r_to_dolby(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n        case AC3_INPUT_3F_2R:\n\n            switch (to) {\n\n                case AC3_OUTPUT_MONO:\n\n                    mix_3f_2r_to_mono(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_STEREO:\n\n                    mix_3f_2r_to_stereo(ctx);\n\n                    break;\n\n                case AC3_OUTPUT_DOLBY:\n\n                    mix_3f_2r_to_dolby(ctx);\n\n                    break;\n\n            }\n\n            break;\n\n    }\n\n}\n", "idx": 13186, "_split": "valid", "_hash": "2e5688d8783da462b5d9f23a18858233"}
{"project": "FFmpeg", "commit_id": "f3296b945464b41aa067949b24dfcfeb0db9d875", "target": 1, "func": "static int get_avc_nalsize(H264Context *h, const uint8_t *buf,\n\n                           int buf_size, int *buf_index)\n\n{\n\n    int i, nalsize = 0;\n\n\n\n    if (*buf_index >= buf_size - h->nal_length_size)\n\n        return -1;\n\n\n\n    for (i = 0; i < h->nal_length_size; i++)\n\n        nalsize = (nalsize << 8) | buf[(*buf_index)++];\n\n    if (nalsize <= 0 || nalsize > buf_size - *buf_index) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"AVC: nal size %d\\n\", nalsize);\n\n        return -1;\n\n    }\n\n    return nalsize;\n\n}\n", "idx": 13213, "_split": "valid", "_hash": "866e46b23bbe991ebc52f723bde7ca2b"}
{"project": "FFmpeg", "commit_id": "5a5c1b244281c3edcffca322b0c664ed620b1e24", "target": 1, "func": "static int decode_13(AVCodecContext *avctx, DxaDecContext *c, uint8_t* dst,\n\n                     int stride, uint8_t *src, uint8_t *ref)\n\n{\n\n    uint8_t *code, *data, *mv, *msk, *tmp, *tmp2;\n\n    int i, j, k;\n\n    int type, x, y, d, d2;\n\n    uint32_t mask;\n\n\n\n    code = src  + 12;\n\n    data = code + ((avctx->width * avctx->height) >> 4);\n\n    mv   = data + AV_RB32(src + 0);\n\n    msk  = mv   + AV_RB32(src + 4);\n\n\n\n    for(j = 0; j < avctx->height; j += 4){\n\n        for(i = 0; i < avctx->width; i += 4){\n\n            tmp  = dst + i;\n\n            tmp2 = ref + i;\n\n            type = *code++;\n\n            switch(type){\n\n            case 4: // motion compensation\n\n                x = (*mv) >> 4;    if(x & 8) x = 8 - x;\n\n                y = (*mv++) & 0xF; if(y & 8) y = 8 - y;\n\n                if (i < -x || avctx->width  - i - 4 < x ||\n\n                    j < -y || avctx->height - j - 4 < y) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"MV %d %d out of bounds\\n\", x,y);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                tmp2 += x + y*stride;\n\n            case 0: // skip\n\n            case 5: // skip in method 12\n\n                for(y = 0; y < 4; y++){\n\n                    memcpy(tmp, tmp2, 4);\n\n                    tmp  += stride;\n\n                    tmp2 += stride;\n\n                }\n\n                break;\n\n            case 1:  // masked change\n\n            case 10: // masked change with only half of pixels changed\n\n            case 11: // cases 10-15 are for method 12 only\n\n            case 12:\n\n            case 13:\n\n            case 14:\n\n            case 15:\n\n                if(type == 1){\n\n                    mask = AV_RB16(msk);\n\n                    msk += 2;\n\n                }else{\n\n                    type -= 10;\n\n                    mask = ((msk[0] & 0xF0) << shift1[type]) | ((msk[0] & 0xF) << shift2[type]);\n\n                    msk++;\n\n                }\n\n                for(y = 0; y < 4; y++){\n\n                    for(x = 0; x < 4; x++){\n\n                        tmp[x] = (mask & 0x8000) ? *data++ : tmp2[x];\n\n                        mask <<= 1;\n\n                    }\n\n                    tmp  += stride;\n\n                    tmp2 += stride;\n\n                }\n\n                break;\n\n            case 2: // fill block\n\n                for(y = 0; y < 4; y++){\n\n                    memset(tmp, data[0], 4);\n\n                    tmp += stride;\n\n                }\n\n                data++;\n\n                break;\n\n            case 3: // raw block\n\n                for(y = 0; y < 4; y++){\n\n                    memcpy(tmp, data, 4);\n\n                    data += 4;\n\n                    tmp  += stride;\n\n                }\n\n                break;\n\n            case 8: // subblocks - method 13 only\n\n                mask = *msk++;\n\n                for(k = 0; k < 4; k++){\n\n                    d  = ((k & 1) << 1) + ((k & 2) * stride);\n\n                    d2 = ((k & 1) << 1) + ((k & 2) * stride);\n\n                    tmp2 = ref + i + d2;\n\n                    switch(mask & 0xC0){\n\n                    case 0x80: // motion compensation\n\n                        x = (*mv) >> 4;    if(x & 8) x = 8 - x;\n\n                        y = (*mv++) & 0xF; if(y & 8) y = 8 - y;\n\n                        if (i + 2*(k & 1) < -x || avctx->width  - i - 2*(k & 1) - 2 < x ||\n\n                            j +   (k & 2) < -y || avctx->height - j -   (k & 2) - 2 < y) {\n\n                            av_log(avctx, AV_LOG_ERROR, \"MV %d %d out of bounds\\n\", x,y);\n\n                            return AVERROR_INVALIDDATA;\n\n                        }\n\n                        tmp2 += x + y*stride;\n\n                    case 0x00: // skip\n\n                        tmp[d + 0         ] = tmp2[0];\n\n                        tmp[d + 1         ] = tmp2[1];\n\n                        tmp[d + 0 + stride] = tmp2[0 + stride];\n\n                        tmp[d + 1 + stride] = tmp2[1 + stride];\n\n                        break;\n\n                    case 0x40: // fill\n\n                        tmp[d + 0         ] = data[0];\n\n                        tmp[d + 1         ] = data[0];\n\n                        tmp[d + 0 + stride] = data[0];\n\n                        tmp[d + 1 + stride] = data[0];\n\n                        data++;\n\n                        break;\n\n                    case 0xC0: // raw\n\n                        tmp[d + 0         ] = *data++;\n\n                        tmp[d + 1         ] = *data++;\n\n                        tmp[d + 0 + stride] = *data++;\n\n                        tmp[d + 1 + stride] = *data++;\n\n                        break;\n\n                    }\n\n                    mask <<= 2;\n\n                }\n\n                break;\n\n            case 32: // vector quantization - 2 colors\n\n                mask = AV_RB16(msk);\n\n                msk += 2;\n\n                for(y = 0; y < 4; y++){\n\n                    for(x = 0; x < 4; x++){\n\n                        tmp[x] = data[mask & 1];\n\n                        mask >>= 1;\n\n                    }\n\n                    tmp  += stride;\n\n                    tmp2 += stride;\n\n                }\n\n                data += 2;\n\n                break;\n\n            case 33: // vector quantization - 3 or 4 colors\n\n            case 34:\n\n                mask = AV_RB32(msk);\n\n                msk += 4;\n\n                for(y = 0; y < 4; y++){\n\n                    for(x = 0; x < 4; x++){\n\n                        tmp[x] = data[mask & 3];\n\n                        mask >>= 2;\n\n                    }\n\n                    tmp  += stride;\n\n                    tmp2 += stride;\n\n                }\n\n                data += type - 30;\n\n                break;\n\n            default:\n\n                av_log(avctx, AV_LOG_ERROR, \"Unknown opcode %d\\n\", type);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n        dst += stride * 4;\n\n        ref += stride * 4;\n\n    }\n\n    return 0;\n\n}\n", "idx": 13223, "_split": "valid", "_hash": "6dd69426cd909b4c216b2c693d848cf4"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void palette8tobgr32(const uint8_t *src, uint8_t *dst, long num_pixels, const uint8_t *palette)\n\n{\n\n\tlong i;\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t\t#ifdef WORDS_BIGENDIAN\n\n\t\t\tdst[3]= palette[ src[i]*4+0 ];\n\n\t\t\tdst[2]= palette[ src[i]*4+1 ];\n\n\t\t\tdst[1]= palette[ src[i]*4+2 ];\n\n\t\t#else\n\n\t\t\t//FIXME slow?\n\n\t\t\tdst[0]= palette[ src[i]*4+0 ];\n\n\t\t\tdst[1]= palette[ src[i]*4+1 ];\n\n\t\t\tdst[2]= palette[ src[i]*4+2 ];\n\n\t\t\t//dst[3]= 0; /* do we need this cleansing? */\n\n\t\t#endif\n\n\n\n\t\tdst+= 4;\n\n\t}\n\n}\n", "idx": 13225, "_split": "valid", "_hash": "84ae8cf3f978d48c78f6c1834d89106e"}
{"project": "FFmpeg", "commit_id": "f5498ef38daa541f03b9c8d3985579394c8407e5", "target": 0, "func": "static int flic_decode_frame_15_16BPP(AVCodecContext *avctx,\n\n                                      void *data, int *got_frame,\n\n                                      const uint8_t *buf, int buf_size)\n\n{\n\n    /* Note, the only difference between the 15Bpp and 16Bpp */\n\n    /* Format is the pixel format, the packets are processed the same. */\n\n    FlicDecodeContext *s = avctx->priv_data;\n\n\n\n    GetByteContext g2;\n\n    int pixel_ptr;\n\n    unsigned char palette_idx1;\n\n\n\n    unsigned int frame_size;\n\n    int num_chunks;\n\n\n\n    unsigned int chunk_size;\n\n    int chunk_type;\n\n\n\n    int i, j, ret;\n\n\n\n    int lines;\n\n    int compressed_lines;\n\n    signed short line_packets;\n\n    int y_ptr;\n\n    int byte_run;\n\n    int pixel_skip;\n\n    int pixel_countdown;\n\n    unsigned char *pixels;\n\n    int pixel;\n\n    unsigned int pixel_limit;\n\n\n\n    bytestream2_init(&g2, buf, buf_size);\n\n\n\n    if ((ret = ff_reget_buffer(avctx, &s->frame)) < 0)\n\n        return ret;\n\n\n\n    pixels = s->frame.data[0];\n\n    pixel_limit = s->avctx->height * s->frame.linesize[0];\n\n\n\n    frame_size = bytestream2_get_le32(&g2);\n\n    bytestream2_skip(&g2, 2);  /* skip the magic number */\n\n    num_chunks = bytestream2_get_le16(&g2);\n\n    bytestream2_skip(&g2, 8);  /* skip padding */\n\n    if (frame_size > buf_size)\n\n        frame_size = buf_size;\n\n\n\n    frame_size -= 16;\n\n\n\n    /* iterate through the chunks */\n\n    while ((frame_size > 0) && (num_chunks > 0)) {\n\n        int stream_ptr_after_chunk;\n\n        chunk_size = bytestream2_get_le32(&g2);\n\n        if (chunk_size > frame_size) {\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"Invalid chunk_size = %u > frame_size = %u\\n\", chunk_size, frame_size);\n\n            chunk_size = frame_size;\n\n        }\n\n        stream_ptr_after_chunk = bytestream2_tell(&g2) - 4 + chunk_size;\n\n\n\n        chunk_type = bytestream2_get_le16(&g2);\n\n\n\n\n\n        switch (chunk_type) {\n\n        case FLI_256_COLOR:\n\n        case FLI_COLOR:\n\n            /* For some reason, it seems that non-palettized flics do\n\n             * include one of these chunks in their first frame.\n\n             * Why I do not know, it seems rather extraneous. */\n\n            av_dlog(avctx,\n\n                    \"Unexpected Palette chunk %d in non-palettized FLC\\n\",\n\n                    chunk_type);\n\n            bytestream2_skip(&g2, chunk_size - 6);\n\n            break;\n\n\n\n        case FLI_DELTA:\n\n        case FLI_DTA_LC:\n\n            y_ptr = 0;\n\n            compressed_lines = bytestream2_get_le16(&g2);\n\n            while (compressed_lines > 0) {\n\n                if (bytestream2_tell(&g2) + 2 > stream_ptr_after_chunk)\n\n                    break;\n\n                line_packets = bytestream2_get_le16(&g2);\n\n                if (line_packets < 0) {\n\n                    line_packets = -line_packets;\n\n                    y_ptr += line_packets * s->frame.linesize[0];\n\n                } else {\n\n                    compressed_lines--;\n\n                    pixel_ptr = y_ptr;\n\n                    CHECK_PIXEL_PTR(0);\n\n                    pixel_countdown = s->avctx->width;\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        if (bytestream2_tell(&g2) + 2 > stream_ptr_after_chunk)\n\n                            break;\n\n                        pixel_skip = bytestream2_get_byte(&g2);\n\n                        pixel_ptr += (pixel_skip*2); /* Pixel is 2 bytes wide */\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n\n                        if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            pixel    = bytestream2_get_le16(&g2);\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        } else {\n\n                            if (bytestream2_tell(&g2) + 2*byte_run > stream_ptr_after_chunk)\n\n                                break;\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = bytestream2_get_le16(&g2);\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    y_ptr += s->frame.linesize[0];\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_LC:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unexpected FLI_LC chunk in non-palettized FLC\\n\");\n\n            bytestream2_skip(&g2, chunk_size - 6);\n\n            break;\n\n\n\n        case FLI_BLACK:\n\n            /* set the whole frame to 0x0000 which is black in both 15Bpp and 16Bpp modes. */\n\n            memset(pixels, 0x0000,\n\n                   s->frame.linesize[0] * s->avctx->height);\n\n            break;\n\n\n\n        case FLI_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                bytestream2_skip(&g2, 1);\n\n                pixel_countdown = (s->avctx->width * 2);\n\n\n\n                while (pixel_countdown > 0) {\n\n                    if (bytestream2_tell(&g2) + 1 > stream_ptr_after_chunk)\n\n                        break;\n\n                    byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n\n                    if (byte_run > 0) {\n\n                        palette_idx1 = bytestream2_get_byte(&g2);\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) (linea%d)\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    } else {  /* copy bytes if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        if (bytestream2_tell(&g2) + byte_run > stream_ptr_after_chunk)\n\n                            break;\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            palette_idx1 = bytestream2_get_byte(&g2);\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                /* Now FLX is strange, in that it is \"byte\" as opposed to \"pixel\" run length compressed.\n\n                 * This does not give us any good opportunity to perform word endian conversion\n\n                 * during decompression. So if it is required (i.e., this is not a LE target, we do\n\n                 * a second pass over the line here, swapping the bytes.\n\n                 */\n\n#if HAVE_BIGENDIAN\n\n                pixel_ptr = y_ptr;\n\n                pixel_countdown = s->avctx->width;\n\n                while (pixel_countdown > 0) {\n\n                    *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[pixel_ptr]);\n\n                    pixel_ptr += 2;\n\n                }\n\n#endif\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_DTA_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                bytestream2_skip(&g2, 1);\n\n                pixel_countdown = s->avctx->width; /* Width is in pixels, not bytes */\n\n\n\n                while (pixel_countdown > 0) {\n\n                    if (bytestream2_tell(&g2) + 1 > stream_ptr_after_chunk)\n\n                        break;\n\n                    byte_run = sign_extend(bytestream2_get_byte(&g2), 8);\n\n                    if (byte_run > 0) {\n\n                        pixel    = bytestream2_get_le16(&g2);\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                            pixel_ptr += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    } else {  /* copy pixels if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        if (bytestream2_tell(&g2) + 2 * byte_run > stream_ptr_after_chunk)\n\n                            break;\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = bytestream2_get_le16(&g2);\n\n                            pixel_ptr  += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_COPY:\n\n        case FLI_DTA_COPY:\n\n            /* copy the chunk (uncompressed frame) */\n\n            if (chunk_size - 6 > (unsigned int)(s->avctx->width * s->avctx->height)*2) {\n\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n\n                       \"bigger than image, skipping chunk\\n\", chunk_size - 6);\n\n                bytestream2_skip(&g2, chunk_size - 6);\n\n            } else {\n\n\n\n                for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;\n\n                     y_ptr += s->frame.linesize[0]) {\n\n\n\n                    pixel_countdown = s->avctx->width;\n\n                    pixel_ptr = 0;\n\n                    while (pixel_countdown > 0) {\n\n                      *((signed short*)(&pixels[y_ptr + pixel_ptr])) = bytestream2_get_le16(&g2);\n\n                      pixel_ptr += 2;\n\n                      pixel_countdown--;\n\n                    }\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_MINI:\n\n            /* some sort of a thumbnail? disregard this chunk... */\n\n            bytestream2_skip(&g2, chunk_size - 6);\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n\n            break;\n\n        }\n\n\n\n        frame_size -= chunk_size;\n\n        num_chunks--;\n\n    }\n\n\n\n    /* by the end of the chunk, the stream ptr should equal the frame\n\n     * size (minus 1, possibly); if it doesn't, issue a warning */\n\n    if ((bytestream2_get_bytes_left(&g2) != 0) && (bytestream2_get_bytes_left(&g2) != 1))\n\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n\n               \"and final chunk ptr = %d\\n\", buf_size, bytestream2_tell(&g2));\n\n\n\n    if ((ret = av_frame_ref(data, &s->frame)) < 0)\n\n        return ret;\n\n\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 13250, "_split": "valid", "_hash": "f0f5184164c760fc65f00d9635e06ebd"}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "int check_intra_pred4x4_mode_emuedge(int mode, int mb_x, int mb_y, int *copy_buf)\n\n{\n\n    switch (mode) {\n\n    case VERT_PRED:\n\n        if (!mb_x && mb_y) {\n\n            *copy_buf = 1;\n\n            return mode;\n\n        }\n\n        /* fall-through */\n\n    case DIAG_DOWN_LEFT_PRED:\n\n    case VERT_LEFT_PRED:\n\n        return !mb_y ? DC_127_PRED : mode;\n\n    case HOR_PRED:\n\n        if (!mb_y) {\n\n            *copy_buf = 1;\n\n            return mode;\n\n        }\n\n        /* fall-through */\n\n    case HOR_UP_PRED:\n\n        return !mb_x ? DC_129_PRED : mode;\n\n    case TM_VP8_PRED:\n\n        return check_tm_pred4x4_mode(mode, mb_x, mb_y);\n\n    case DC_PRED: /* 4x4 DC doesn't use the same \"H.264-style\" exceptions\n\n                   * as 16x16/8x8 DC */\n\n    case DIAG_DOWN_RIGHT_PRED:\n\n    case VERT_RIGHT_PRED:\n\n    case HOR_DOWN_PRED:\n\n        if (!mb_y || !mb_x)\n\n            *copy_buf = 1;\n\n        return mode;\n\n    }\n\n    return mode;\n\n}\n", "idx": 13278, "_split": "valid", "_hash": "ce1507ff94ba3912ddebf83390f9c8d2"}
{"project": "FFmpeg", "commit_id": "5cdd3b995c9dd79ab6ab852a27e75a21c0eb4f5f", "target": 0, "func": "static int open_input(struct variant *var)\n\n{\n\n    struct segment *seg = var->segments[var->cur_seq_no - var->start_seq_no];\n\n    if (seg->key_type == KEY_NONE) {\n\n        return ffurl_open(&var->input, seg->url, AVIO_FLAG_READ,\n\n                          &var->parent->interrupt_callback, NULL);\n\n    } else if (seg->key_type == KEY_AES_128) {\n\n        char iv[33], key[33], url[MAX_URL_SIZE];\n\n        int ret;\n\n        if (strcmp(seg->key, var->key_url)) {\n\n            URLContext *uc;\n\n            if (ffurl_open(&uc, seg->key, AVIO_FLAG_READ,\n\n                           &var->parent->interrupt_callback, NULL) == 0) {\n\n                if (ffurl_read_complete(uc, var->key, sizeof(var->key))\n\n                    != sizeof(var->key)) {\n\n                    av_log(NULL, AV_LOG_ERROR, \"Unable to read key file %s\\n\",\n\n                           seg->key);\n\n                }\n\n                ffurl_close(uc);\n\n            } else {\n\n                av_log(NULL, AV_LOG_ERROR, \"Unable to open key file %s\\n\",\n\n                       seg->key);\n\n            }\n\n            av_strlcpy(var->key_url, seg->key, sizeof(var->key_url));\n\n        }\n\n        ff_data_to_hex(iv, seg->iv, sizeof(seg->iv), 0);\n\n        ff_data_to_hex(key, var->key, sizeof(var->key), 0);\n\n        iv[32] = key[32] = '\\0';\n\n        if (strstr(seg->url, \"://\"))\n\n            snprintf(url, sizeof(url), \"crypto+%s\", seg->url);\n\n        else\n\n            snprintf(url, sizeof(url), \"crypto:%s\", seg->url);\n\n        if ((ret = ffurl_alloc(&var->input, url, AVIO_FLAG_READ,\n\n                               &var->parent->interrupt_callback)) < 0)\n\n            return ret;\n\n        av_opt_set(var->input->priv_data, \"key\", key, 0);\n\n        av_opt_set(var->input->priv_data, \"iv\", iv, 0);\n\n        if ((ret = ffurl_connect(var->input, NULL)) < 0) {\n\n            ffurl_close(var->input);\n\n            var->input = NULL;\n\n            return ret;\n\n        }\n\n        return 0;\n\n    }\n\n    return AVERROR(ENOSYS);\n\n}\n", "idx": 13282, "_split": "valid", "_hash": "4e2d11d7349ff88e610ac03e233cfa7c"}
{"project": "FFmpeg", "commit_id": "3aad94bf2b140cfba8ae69d018da05d4948ef37f", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                        AVPacket *avpkt)\n{\n    AVFrame *frame = data;\n    const uint8_t *buf = avpkt->data;\n    const uint8_t *buf_end = buf + avpkt->size;\n    KgvContext * const c = avctx->priv_data;\n    int offsets[8];\n    uint8_t *out, *prev;\n    int outcnt = 0, maxcnt;\n    int w, h, i, res;\n    if (avpkt->size < 2)\n    w = (buf[0] + 1) * 8;\n    h = (buf[1] + 1) * 8;\n    buf += 2;\n    if (w != avctx->width || h != avctx->height) {\n        av_freep(&c->frame_buffer);\n        av_freep(&c->last_frame_buffer);\n        if ((res = ff_set_dimensions(avctx, w, h)) < 0)\n            return res;\n    }\n    if (!c->frame_buffer) {\n        c->frame_buffer      = av_mallocz(avctx->width * avctx->height * 2);\n        c->last_frame_buffer = av_mallocz(avctx->width * avctx->height * 2);\n        if (!c->frame_buffer || !c->last_frame_buffer) {\n            decode_flush(avctx);\n            return AVERROR(ENOMEM);\n        }\n    }\n    maxcnt = w * h;\n    if ((res = ff_get_buffer(avctx, frame, 0)) < 0)\n        return res;\n    out  = (uint8_t*)c->frame_buffer;\n    prev = (uint8_t*)c->last_frame_buffer;\n    for (i = 0; i < 8; i++)\n        offsets[i] = -1;\n    while (outcnt < maxcnt && buf_end - 2 >= buf) {\n        int code = AV_RL16(buf);\n        buf += 2;\n        if (!(code & 0x8000)) {\n            AV_WN16A(&out[2 * outcnt], code); // rgb555 pixel coded directly\n            outcnt++;\n        } else {\n            int count;\n            if ((code & 0x6000) == 0x6000) {\n                // copy from previous frame\n                int oidx = (code >> 10) & 7;\n                int start;\n                count = (code & 0x3FF) + 3;\n                if (offsets[oidx] < 0) {\n                    if (buf_end - 3 < buf)\n                        break;\n                    offsets[oidx] = AV_RL24(buf);\n                    buf += 3;\n                }\n                start = (outcnt + offsets[oidx]) % maxcnt;\n                if (maxcnt - start < count || maxcnt - outcnt < count)\n                    break;\n                if (!prev) {\n                    av_log(avctx, AV_LOG_ERROR,\n                           \"Frame reference does not exist\\n\");\n                    break;\n                }\n                memcpy(out + 2 * outcnt, prev + 2 * start, 2 * count);\n            } else {\n                // copy from earlier in this frame\n                int offset = (code & 0x1FFF) + 1;\n                if (!(code & 0x6000)) {\n                    count = 2;\n                } else if ((code & 0x6000) == 0x2000) {\n                    count = 3;\n                } else {\n                    if (buf_end - 1 < buf)\n                        break;\n                    count = 4 + *buf++;\n                }\n                if (outcnt < offset || maxcnt - outcnt < count)\n                    break;\n                av_memcpy_backptr(out + 2 * outcnt, 2 * offset, 2 * count);\n            }\n            outcnt += count;\n        }\n    }\n    if (outcnt - maxcnt)\n        av_log(avctx, AV_LOG_DEBUG, \"frame finished with %d diff\\n\", outcnt - maxcnt);\n    av_image_copy_plane(frame->data[0], frame->linesize[0],\n                        (const uint8_t*)c->frame_buffer,  avctx->width * 2,\n                        avctx->width * 2, avctx->height);\n    FFSWAP(uint16_t *, c->frame_buffer, c->last_frame_buffer);\n    *got_frame = 1;\n    return avpkt->size;\n}", "idx": 13302, "_split": "valid", "_hash": "97bf63f8653783cdb5f0f6863875644a"}
{"project": "FFmpeg", "commit_id": "6fdbaa2b7fb56623ab2163f861952bc1408c39b3", "target": 1, "func": "void clamp_mv(VP8Context *s, VP56mv *dst, const VP56mv *src)\n\n{\n\n    dst->x = av_clip(src->x, s->mv_min.x, s->mv_max.x);\n\n    dst->y = av_clip(src->y, s->mv_min.y, s->mv_max.y);\n\n}\n", "idx": 13307, "_split": "valid", "_hash": "804ec1b48c7a21a292a5db048ba09c32"}
{"project": "FFmpeg", "commit_id": "e9af732a1a4c28f81959f19d434c9be609cff22a", "target": 1, "func": "AVFilterBufferRef *avfilter_default_get_audio_buffer(AVFilterLink *link, int perms,\n\n                                                     int nb_samples)\n\n{\n\n    AVFilterBufferRef *samplesref = NULL;\n\n    int linesize[8];\n\n    uint8_t *data[8];\n\n    int nb_channels = av_get_channel_layout_nb_channels(link->channel_layout);\n\n\n\n    /* Calculate total buffer size, round to multiple of 16 to be SIMD friendly */\n\n    if (av_samples_alloc(data, linesize,\n\n                         nb_channels, nb_samples, link->format,\n\n                         16) < 0)\n\n        return NULL;\n\n\n\n    samplesref =\n\n        avfilter_get_audio_buffer_ref_from_arrays(data, linesize, perms,\n\n                                                  nb_samples, link->format,\n\n                                                  link->channel_layout, link->planar);\n\n    if (!samplesref) {\n\n        av_free(data[0]);\n\n        return NULL;\n\n    }\n\n\n\n    return samplesref;\n\n}\n", "idx": 13334, "_split": "valid", "_hash": "1284a8c7c8d84807a3b880760edae976"}
{"project": "FFmpeg", "commit_id": "657875b145c788d29b8e3bf38f79264e657932ae", "target": 0, "func": "static int aic_decode_coeffs(GetBitContext *gb, int16_t *dst,\n\n                             int band, int slice_width)\n\n{\n\n    int has_skips, coeff_type, coeff_bits, skip_type, skip_bits;\n\n    const int num_coeffs = aic_num_band_coeffs[band];\n\n    const uint8_t *scan = aic_scan[band];\n\n    int mb, idx, val;\n\n\n\n    has_skips  = get_bits1(gb);\n\n    coeff_type = get_bits1(gb);\n\n    coeff_bits = get_bits(gb, 3);\n\n\n\n    if (has_skips) {\n\n        skip_type = get_bits1(gb);\n\n        skip_bits = get_bits(gb, 3);\n\n\n\n        for (mb = 0; mb < slice_width; mb++) {\n\n            idx = -1;\n\n            do {\n\n                GET_CODE(val, skip_type, skip_bits);\n\n                idx += val + 1;\n\n                if (idx >= num_coeffs)\n\n                    break;\n\n                GET_CODE(val, coeff_type, coeff_bits);\n\n                val++;\n\n                if (val >= 0x10000)\n\n                    return AVERROR_INVALIDDATA;\n\n                dst[scan[idx]] = val;\n\n            } while (idx < num_coeffs - 1);\n\n            dst += num_coeffs;\n\n        }\n\n    } else {\n\n        for (mb = 0; mb < slice_width; mb++) {\n\n            for (idx = 0; idx < num_coeffs; idx++) {\n\n                GET_CODE(val, coeff_type, coeff_bits);\n\n                if (val >= 0x10000)\n\n                    return AVERROR_INVALIDDATA;\n\n                dst[scan[idx]] = val;\n\n            }\n\n            dst += num_coeffs;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 13361, "_split": "valid", "_hash": "a20d54d9ad55b734d7cf0053e672df1e"}
{"project": "FFmpeg", "commit_id": "c89658008705d949c319df3fa6f400c481ad73e1", "target": 0, "func": "static int sdp_probe(AVProbeData *p1)\n\n{\n\n    const char *p = p1->buf, *p_end = p1->buf + p1->buf_size;\n\n\n\n    /* we look for a line beginning \"c=IN IP4\" */\n\n    while (p < p_end && *p != '\\0') {\n\n        if (p + sizeof(\"c=IN IP4\") - 1 < p_end && av_strstart(p, \"c=IN IP4\", NULL))\n\n            return AVPROBE_SCORE_MAX / 2;\n\n\n\n        while(p < p_end - 1 && *p != '\\n') p++;\n\n        if (++p >= p_end)\n\n            break;\n\n        if (*p == '\\r')\n\n            p++;\n\n    }\n\n    return 0;\n\n}\n", "idx": 13372, "_split": "valid", "_hash": "c9323543ccaef13ea2056447719b1f3c"}
{"project": "FFmpeg", "commit_id": "891b1f15a7e45a2a5f91cb4c27d11259ef8e012f", "target": 0, "func": "void decode_mvs(VP8Context *s, VP8Macroblock *mb, int mb_x, int mb_y)\n\n{\n\n    VP8Macroblock *mb_edge[3] = { mb + 2 /* top */,\n\n                                  mb - 1 /* left */,\n\n                                  mb + 1 /* top-left */ };\n\n    enum { CNT_ZERO, CNT_NEAREST, CNT_NEAR, CNT_SPLITMV };\n\n    enum { EDGE_TOP, EDGE_LEFT, EDGE_TOPLEFT };\n\n    int idx = CNT_ZERO;\n\n    int cur_sign_bias = s->sign_bias[mb->ref_frame];\n\n    int *sign_bias = s->sign_bias;\n\n    VP56mv near_mv[4];\n\n    uint8_t cnt[4] = { 0 };\n\n    VP56RangeCoder *c = &s->c;\n\n\n\n    AV_ZERO32(&near_mv[0]);\n\n    AV_ZERO32(&near_mv[1]);\n\n    AV_ZERO32(&near_mv[2]);\n\n\n\n    /* Process MB on top, left and top-left */\n\n    #define MV_EDGE_CHECK(n)\\\n\n    {\\\n\n        VP8Macroblock *edge = mb_edge[n];\\\n\n        int edge_ref = edge->ref_frame;\\\n\n        if (edge_ref != VP56_FRAME_CURRENT) {\\\n\n            uint32_t mv = AV_RN32A(&edge->mv);\\\n\n            if (mv) {\\\n\n                if (cur_sign_bias != sign_bias[edge_ref]) {\\\n\n                    /* SWAR negate of the values in mv. */\\\n\n                    mv = ~mv;\\\n\n                    mv = ((mv&0x7fff7fff) + 0x00010001) ^ (mv&0x80008000);\\\n\n                }\\\n\n                if (!n || mv != AV_RN32A(&near_mv[idx]))\\\n\n                    AV_WN32A(&near_mv[++idx], mv);\\\n\n                cnt[idx]      += 1 + (n != 2);\\\n\n            } else\\\n\n                cnt[CNT_ZERO] += 1 + (n != 2);\\\n\n        }\\\n\n    }\n\n\n\n    MV_EDGE_CHECK(0)\n\n    MV_EDGE_CHECK(1)\n\n    MV_EDGE_CHECK(2)\n\n\n\n    mb->partitioning = VP8_SPLITMVMODE_NONE;\n\n    if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_ZERO]][0])) {\n\n        mb->mode = VP8_MVMODE_MV;\n\n\n\n        /* If we have three distinct MVs, merge first and last if they're the same */\n\n        if (cnt[CNT_SPLITMV] && AV_RN32A(&near_mv[1+EDGE_TOP]) == AV_RN32A(&near_mv[1+EDGE_TOPLEFT]))\n\n            cnt[CNT_NEAREST] += 1;\n\n\n\n        /* Swap near and nearest if necessary */\n\n        if (cnt[CNT_NEAR] > cnt[CNT_NEAREST]) {\n\n            FFSWAP(uint8_t,     cnt[CNT_NEAREST],     cnt[CNT_NEAR]);\n\n            FFSWAP( VP56mv, near_mv[CNT_NEAREST], near_mv[CNT_NEAR]);\n\n        }\n\n\n\n        if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAREST]][1])) {\n\n            if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAR]][2])) {\n\n\n\n                /* Choose the best mv out of 0,0 and the nearest mv */\n\n                clamp_mv(s, &mb->mv, &near_mv[CNT_ZERO + (cnt[CNT_NEAREST] >= cnt[CNT_ZERO])]);\n\n                cnt[CNT_SPLITMV] = ((mb_edge[EDGE_LEFT]->mode    == VP8_MVMODE_SPLIT) +\n\n                                    (mb_edge[EDGE_TOP]->mode     == VP8_MVMODE_SPLIT)) * 2 +\n\n                                    (mb_edge[EDGE_TOPLEFT]->mode == VP8_MVMODE_SPLIT);\n\n\n\n                if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_SPLITMV]][3])) {\n\n                    mb->mode = VP8_MVMODE_SPLIT;\n\n                    mb->mv = mb->bmv[decode_splitmvs(s, c, mb) - 1];\n\n                } else {\n\n                    mb->mv.y += read_mv_component(c, s->prob->mvc[0]);\n\n                    mb->mv.x += read_mv_component(c, s->prob->mvc[1]);\n\n                    mb->bmv[0] = mb->mv;\n\n                }\n\n            } else {\n\n                clamp_mv(s, &mb->mv, &near_mv[CNT_NEAR]);\n\n                mb->bmv[0] = mb->mv;\n\n            }\n\n        } else {\n\n            clamp_mv(s, &mb->mv, &near_mv[CNT_NEAREST]);\n\n            mb->bmv[0] = mb->mv;\n\n        }\n\n    } else {\n\n        mb->mode = VP8_MVMODE_ZERO;\n\n        AV_ZERO32(&mb->mv);\n\n        mb->bmv[0] = mb->mv;\n\n    }\n\n}\n", "idx": 13385, "_split": "valid", "_hash": "c947e909a37559d91ab907c50e4bd0b4"}
{"project": "FFmpeg", "commit_id": "c988f97566cdf536ba0dcbc0d77d885456852060", "target": 0, "func": "int ff_h264_alloc_tables(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    const int big_mb_num= s->mb_stride * (s->mb_height+1);\n\n    int x,y;\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->intra4x4_pred_mode, big_mb_num * 8  * sizeof(uint8_t), fail)\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->non_zero_count    , big_mb_num * 16 * sizeof(uint8_t), fail)\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->slice_table_base  , (big_mb_num+s->mb_stride) * sizeof(*h->slice_table_base), fail)\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->cbp_table, big_mb_num * sizeof(uint16_t), fail)\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->chroma_pred_mode_table, big_mb_num * sizeof(uint8_t), fail)\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mvd_table[0], 32*big_mb_num * sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mvd_table[1], 32*big_mb_num * sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->direct_table, 32*big_mb_num * sizeof(uint8_t) , fail);\n\n\n\n    memset(h->slice_table_base, -1, (big_mb_num+s->mb_stride)  * sizeof(*h->slice_table_base));\n\n    h->slice_table= h->slice_table_base + s->mb_stride*2 + 1;\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mb2b_xy  , big_mb_num * sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mb2b8_xy , big_mb_num * sizeof(uint32_t), fail);\n\n    for(y=0; y<s->mb_height; y++){\n\n        for(x=0; x<s->mb_width; x++){\n\n            const int mb_xy= x + y*s->mb_stride;\n\n            const int b_xy = 4*x + 4*y*h->b_stride;\n\n            const int b8_xy= 2*x + 2*y*h->b8_stride;\n\n\n\n            h->mb2b_xy [mb_xy]= b_xy;\n\n            h->mb2b8_xy[mb_xy]= b8_xy;\n\n        }\n\n    }\n\n\n\n    s->obmc_scratchpad = NULL;\n\n\n\n    if(!h->dequant4_coeff[0])\n\n        init_dequant_tables(h);\n\n\n\n    return 0;\n\nfail:\n\n    free_tables(h);\n\n    return -1;\n\n}\n", "idx": 13389, "_split": "valid", "_hash": "fec42b565f508304dac6dbef6ab36b33"}
{"project": "FFmpeg", "commit_id": "0c46e958d1fd3817b8e9fa048d0450d509c80378", "target": 1, "func": "static int mxf_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    KLVPacket klv;\n\n\n\n    while (!s->pb->eof_reached) {\n\n        if (klv_read_packet(&klv, s->pb) < 0)\n\n            return -1;\n\n        PRINT_KEY(s, \"read packet\", klv.key);\n\n        av_dlog(s, \"size %\"PRIu64\" offset %#\"PRIx64\"\\n\", klv.length, klv.offset);\n\n        if (IS_KLV_KEY(klv.key, mxf_encrypted_triplet_key)) {\n\n            int res = mxf_decrypt_triplet(s, pkt, &klv);\n\n            if (res < 0) {\n\n                av_log(s, AV_LOG_ERROR, \"invalid encoded triplet\\n\");\n\n                return -1;\n\n            }\n\n            return 0;\n\n        }\n\n        if (IS_KLV_KEY(klv.key, mxf_essence_element_key)) {\n\n            int index = mxf_get_stream_index(s, &klv);\n\n            if (index < 0) {\n\n                av_log(s, AV_LOG_ERROR, \"error getting stream index %d\\n\", AV_RB32(klv.key+12));\n\n                goto skip;\n\n            }\n\n            if (s->streams[index]->discard == AVDISCARD_ALL)\n\n                goto skip;\n\n            /* check for 8 channels AES3 element */\n\n            if (klv.key[12] == 0x06 && klv.key[13] == 0x01 && klv.key[14] == 0x10) {\n\n                if (mxf_get_d10_aes3_packet(s->pb, s->streams[index], pkt, klv.length) < 0) {\n\n                    av_log(s, AV_LOG_ERROR, \"error reading D-10 aes3 frame\\n\");\n\n                    return -1;\n\n                }\n\n            } else\n\n                av_get_packet(s->pb, pkt, klv.length);\n\n            pkt->stream_index = index;\n\n            pkt->pos = klv.offset;\n\n            return 0;\n\n        } else\n\n        skip:\n\n            avio_skip(s->pb, klv.length);\n\n    }\n\n    return AVERROR_EOF;\n\n}\n", "idx": 13457, "_split": "valid", "_hash": "ba26c5a722ea904f63f67307aead9925"}
{"project": "FFmpeg", "commit_id": "6d556e8327f6275c807c6da7257f617c256fe759", "target": 1, "func": "void ff_ivi_recompose_haar(const IVIPlaneDesc *plane, uint8_t *dst,\n\n                           const int dst_pitch, const int num_bands)\n\n{\n\n    int             x, y, indx, b0, b1, b2, b3, p0, p1, p2, p3;\n\n    const IDWTELEM *b0_ptr, *b1_ptr, *b2_ptr, *b3_ptr;\n\n    int32_t         pitch;\n\n\n\n    /* all bands should have the same pitch */\n\n    pitch = plane->bands[0].pitch;\n\n\n\n    /* get pointers to the wavelet bands */\n\n    b0_ptr = plane->bands[0].buf;\n\n    b1_ptr = plane->bands[1].buf;\n\n    b2_ptr = plane->bands[2].buf;\n\n    b3_ptr = plane->bands[3].buf;\n\n\n\n    for (y = 0; y < plane->height; y += 2) {\n\n        for (x = 0, indx = 0; x < plane->width; x += 2, indx++) {\n\n            /* load coefficients */\n\n            b0 = b0_ptr[indx]; //should be: b0 = (num_bands > 0) ? b0_ptr[indx] : 0;\n\n            b1 = b1_ptr[indx]; //should be: b1 = (num_bands > 1) ? b1_ptr[indx] : 0;\n\n            b2 = b2_ptr[indx]; //should be: b2 = (num_bands > 2) ? b2_ptr[indx] : 0;\n\n            b3 = b3_ptr[indx]; //should be: b3 = (num_bands > 3) ? b3_ptr[indx] : 0;\n\n\n\n            /* haar wavelet recomposition */\n\n            p0 = (b0 + b1 + b2 + b3 + 2) >> 2;\n\n            p1 = (b0 + b1 - b2 - b3 + 2) >> 2;\n\n            p2 = (b0 - b1 + b2 - b3 + 2) >> 2;\n\n            p3 = (b0 - b1 - b2 + b3 + 2) >> 2;\n\n\n\n            /* bias, convert and output four pixels */\n\n            dst[x]                 = av_clip_uint8(p0 + 128);\n\n            dst[x + 1]             = av_clip_uint8(p1 + 128);\n\n            dst[dst_pitch + x]     = av_clip_uint8(p2 + 128);\n\n            dst[dst_pitch + x + 1] = av_clip_uint8(p3 + 128);\n\n        }// for x\n\n\n\n        dst += dst_pitch << 1;\n\n\n\n        b0_ptr += pitch;\n\n        b1_ptr += pitch;\n\n        b2_ptr += pitch;\n\n        b3_ptr += pitch;\n\n    }// for y\n\n}\n", "idx": 13460, "_split": "valid", "_hash": "5472527c46e0c40e72d76e0bf0c6da21"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int find_smallest_bounding_rectangle(AVSubtitle *s)\n\n{\n\n    uint8_t transp_color[256] = { 0 };\n\n    int y1, y2, x1, x2, y, w, h, i;\n\n    uint8_t *bitmap;\n\n\n\n    if (s->num_rects == 0 || s->rects == NULL || s->rects[0]->w <= 0 || s->rects[0]->h <= 0)\n\n        return 0;\n\n\n\n    for(i = 0; i < s->rects[0]->nb_colors; i++) {\n\n        if ((((uint32_t*)s->rects[0]->pict.data[1])[i] >> 24) == 0)\n\n            transp_color[i] = 1;\n\n    }\n\n    y1 = 0;\n\n    while (y1 < s->rects[0]->h && is_transp(s->rects[0]->pict.data[0] + y1 * s->rects[0]->pict.linesize[0],\n\n                                  1, s->rects[0]->w, transp_color))\n\n        y1++;\n\n    if (y1 == s->rects[0]->h) {\n\n        av_freep(&s->rects[0]->pict.data[0]);\n\n        s->rects[0]->w = s->rects[0]->h = 0;\n\n        return 0;\n\n    }\n\n\n\n    y2 = s->rects[0]->h - 1;\n\n    while (y2 > 0 && is_transp(s->rects[0]->pict.data[0] + y2 * s->rects[0]->pict.linesize[0], 1,\n\n                               s->rects[0]->w, transp_color))\n\n        y2--;\n\n    x1 = 0;\n\n    while (x1 < (s->rects[0]->w - 1) && is_transp(s->rects[0]->pict.data[0] + x1, s->rects[0]->pict.linesize[0],\n\n                                        s->rects[0]->h, transp_color))\n\n        x1++;\n\n    x2 = s->rects[0]->w - 1;\n\n    while (x2 > 0 && is_transp(s->rects[0]->pict.data[0] + x2, s->rects[0]->pict.linesize[0], s->rects[0]->h,\n\n                                  transp_color))\n\n        x2--;\n\n    w = x2 - x1 + 1;\n\n    h = y2 - y1 + 1;\n\n    bitmap = av_malloc(w * h);\n\n    if (!bitmap)\n\n        return 1;\n\n    for(y = 0; y < h; y++) {\n\n        memcpy(bitmap + w * y, s->rects[0]->pict.data[0] + x1 + (y1 + y) * s->rects[0]->pict.linesize[0], w);\n\n    }\n\n    av_freep(&s->rects[0]->pict.data[0]);\n\n    s->rects[0]->pict.data[0] = bitmap;\n\n    s->rects[0]->pict.linesize[0] = w;\n\n    s->rects[0]->w = w;\n\n    s->rects[0]->h = h;\n\n    s->rects[0]->x += x1;\n\n    s->rects[0]->y += y1;\n\n    return 1;\n\n}\n", "idx": 13521, "_split": "valid", "_hash": "e2ef436336fdc19e326980d7b3173913"}
{"project": "FFmpeg", "commit_id": "478455d66b80e335bdabc00df5dee298d630cbab", "target": 1, "func": "static av_cold int allocate_buffers(AVCodecContext *avctx)\n\n{\n\n    int blk, ch;\n\n    AC3EncodeContext *s = avctx->priv_data;\n\n    int channels = s->channels + 1; /* includes coupling channel */\n\n\n\n    FF_ALLOC_OR_GOTO(avctx, s->planar_samples, s->channels * sizeof(*s->planar_samples),\n\n                     alloc_fail);\n\n    for (ch = 0; ch < s->channels; ch++) {\n\n        FF_ALLOCZ_OR_GOTO(avctx, s->planar_samples[ch],\n\n                          (AC3_FRAME_SIZE+AC3_BLOCK_SIZE) * sizeof(**s->planar_samples),\n\n                          alloc_fail);\n\n    }\n\n    FF_ALLOC_OR_GOTO(avctx, s->bap_buffer,  AC3_MAX_BLOCKS * channels *\n\n                     AC3_MAX_COEFS * sizeof(*s->bap_buffer),  alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->bap1_buffer, AC3_MAX_BLOCKS * channels *\n\n                     AC3_MAX_COEFS * sizeof(*s->bap1_buffer), alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->mdct_coef_buffer, AC3_MAX_BLOCKS * channels *\n\n                     AC3_MAX_COEFS * sizeof(*s->mdct_coef_buffer), alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->exp_buffer, AC3_MAX_BLOCKS * channels *\n\n                     AC3_MAX_COEFS * sizeof(*s->exp_buffer), alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->grouped_exp_buffer, AC3_MAX_BLOCKS * channels *\n\n                     128 * sizeof(*s->grouped_exp_buffer), alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->psd_buffer, AC3_MAX_BLOCKS * channels *\n\n                     AC3_MAX_COEFS * sizeof(*s->psd_buffer), alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->band_psd_buffer, AC3_MAX_BLOCKS * channels *\n\n                     64 * sizeof(*s->band_psd_buffer), alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->mask_buffer, AC3_MAX_BLOCKS * channels *\n\n                     64 * sizeof(*s->mask_buffer), alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, s->qmant_buffer, AC3_MAX_BLOCKS * channels *\n\n                     AC3_MAX_COEFS * sizeof(*s->qmant_buffer), alloc_fail);\n\n    if (s->cpl_enabled) {\n\n        FF_ALLOC_OR_GOTO(avctx, s->cpl_coord_exp_buffer, AC3_MAX_BLOCKS * channels *\n\n                         16 * sizeof(*s->cpl_coord_exp_buffer), alloc_fail);\n\n        FF_ALLOC_OR_GOTO(avctx, s->cpl_coord_mant_buffer, AC3_MAX_BLOCKS * channels *\n\n                         16 * sizeof(*s->cpl_coord_mant_buffer), alloc_fail);\n\n    }\n\n    for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n        AC3Block *block = &s->blocks[blk];\n\n        FF_ALLOC_OR_GOTO(avctx, block->bap, channels * sizeof(*block->bap),\n\n                         alloc_fail);\n\n        FF_ALLOCZ_OR_GOTO(avctx, block->mdct_coef, channels * sizeof(*block->mdct_coef),\n\n                          alloc_fail);\n\n        FF_ALLOCZ_OR_GOTO(avctx, block->exp, channels * sizeof(*block->exp),\n\n                          alloc_fail);\n\n        FF_ALLOCZ_OR_GOTO(avctx, block->grouped_exp, channels * sizeof(*block->grouped_exp),\n\n                          alloc_fail);\n\n        FF_ALLOCZ_OR_GOTO(avctx, block->psd, channels * sizeof(*block->psd),\n\n                          alloc_fail);\n\n        FF_ALLOCZ_OR_GOTO(avctx, block->band_psd, channels * sizeof(*block->band_psd),\n\n                          alloc_fail);\n\n        FF_ALLOCZ_OR_GOTO(avctx, block->mask, channels * sizeof(*block->mask),\n\n                          alloc_fail);\n\n        FF_ALLOCZ_OR_GOTO(avctx, block->qmant, channels * sizeof(*block->qmant),\n\n                          alloc_fail);\n\n        if (s->cpl_enabled) {\n\n            FF_ALLOCZ_OR_GOTO(avctx, block->cpl_coord_exp, channels * sizeof(*block->cpl_coord_exp),\n\n                              alloc_fail);\n\n            FF_ALLOCZ_OR_GOTO(avctx, block->cpl_coord_mant, channels * sizeof(*block->cpl_coord_mant),\n\n                              alloc_fail);\n\n        }\n\n\n\n        for (ch = 0; ch < channels; ch++) {\n\n            /* arrangement: block, channel, coeff */\n\n            block->bap[ch]         = &s->bap_buffer        [AC3_MAX_COEFS * (blk * channels + ch)];\n\n            block->grouped_exp[ch] = &s->grouped_exp_buffer[128           * (blk * channels + ch)];\n\n            block->psd[ch]         = &s->psd_buffer        [AC3_MAX_COEFS * (blk * channels + ch)];\n\n            block->band_psd[ch]    = &s->band_psd_buffer   [64            * (blk * channels + ch)];\n\n            block->mask[ch]        = &s->mask_buffer       [64            * (blk * channels + ch)];\n\n            block->qmant[ch]       = &s->qmant_buffer      [AC3_MAX_COEFS * (blk * channels + ch)];\n\n            if (s->cpl_enabled) {\n\n                block->cpl_coord_exp[ch]  = &s->cpl_coord_exp_buffer [16  * (blk * channels + ch)];\n\n                block->cpl_coord_mant[ch] = &s->cpl_coord_mant_buffer[16  * (blk * channels + ch)];\n\n            }\n\n\n\n            /* arrangement: channel, block, coeff */\n\n            block->exp[ch]         = &s->exp_buffer        [AC3_MAX_COEFS * (AC3_MAX_BLOCKS * ch + blk)];\n\n            block->mdct_coef[ch]   = &s->mdct_coef_buffer  [AC3_MAX_COEFS * (AC3_MAX_BLOCKS * ch + blk)];\n\n        }\n\n    }\n\n\n\n    if (CONFIG_AC3ENC_FLOAT) {\n\n        FF_ALLOC_OR_GOTO(avctx, s->fixed_coef_buffer, AC3_MAX_BLOCKS * channels *\n\n                         AC3_MAX_COEFS * sizeof(*s->fixed_coef_buffer), alloc_fail);\n\n        for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n            AC3Block *block = &s->blocks[blk];\n\n            FF_ALLOCZ_OR_GOTO(avctx, block->fixed_coef, channels *\n\n                              sizeof(*block->fixed_coef), alloc_fail);\n\n            for (ch = 0; ch < channels; ch++)\n\n                block->fixed_coef[ch] = &s->fixed_coef_buffer[AC3_MAX_COEFS * (AC3_MAX_BLOCKS * ch + blk)];\n\n        }\n\n    } else {\n\n        for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n            AC3Block *block = &s->blocks[blk];\n\n            FF_ALLOCZ_OR_GOTO(avctx, block->fixed_coef, channels *\n\n                              sizeof(*block->fixed_coef), alloc_fail);\n\n            for (ch = 0; ch < channels; ch++)\n\n                block->fixed_coef[ch] = (int32_t *)block->mdct_coef[ch];\n\n        }\n\n    }\n\n\n\n    return 0;\n\nalloc_fail:\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 13552, "_split": "valid", "_hash": "b128d580b2d714b8f27802ef31009dfe"}
{"project": "FFmpeg", "commit_id": "bd8e16f2e6f069dd8f63b5c22821b581ffe3151a", "target": 0, "func": "static void build_file_streams(void)\n\n{\n\n    FFServerStream *stream, *stream_next;\n\n    int i, ret;\n\n\n\n    /* gather all streams */\n\n    for(stream = config.first_stream; stream; stream = stream_next) {\n\n        AVFormatContext *infile = NULL;\n\n        stream_next = stream->next;\n\n        if (stream->stream_type == STREAM_TYPE_LIVE &&\n\n            !stream->feed) {\n\n            /* the stream comes from a file */\n\n            /* try to open the file */\n\n            /* open stream */\n\n            if (stream->fmt && !strcmp(stream->fmt->name, \"rtp\")) {\n\n                /* specific case : if transport stream output to RTP,\n\n                   we use a raw transport stream reader */\n\n                av_dict_set(&stream->in_opts, \"mpeg2ts_compute_pcr\", \"1\", 0);\n\n            }\n\n\n\n            if (!stream->feed_filename[0]) {\n\n                http_log(\"Unspecified feed file for stream '%s'\\n\",\n\n                         stream->filename);\n\n                goto fail;\n\n            }\n\n\n\n            http_log(\"Opening feed file '%s' for stream '%s'\\n\",\n\n                     stream->feed_filename, stream->filename);\n\n            if ((ret = avformat_open_input(&infile, stream->feed_filename, stream->ifmt, &stream->in_opts)) < 0) {\n\n                http_log(\"Could not open '%s': %s\\n\", stream->feed_filename,\n\n                         av_err2str(ret));\n\n                /* remove stream (no need to spend more time on it) */\n\n            fail:\n\n                remove_stream(stream);\n\n            } else {\n\n                /* find all the AVStreams inside and reference them in\n\n                   'stream' */\n\n                if (avformat_find_stream_info(infile, NULL) < 0) {\n\n                    http_log(\"Could not find codec parameters from '%s'\\n\",\n\n                             stream->feed_filename);\n\n                    avformat_close_input(&infile);\n\n                    goto fail;\n\n                }\n\n                extract_mpeg4_header(infile);\n\n\n\n                for(i=0;i<infile->nb_streams;i++)\n\n                    add_av_stream1(stream, infile->streams[i]->codec, 1);\n\n\n\n                avformat_close_input(&infile);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 13612, "_split": "valid", "_hash": "98433690855bb3a7ad2d237279e26516"}
{"project": "FFmpeg", "commit_id": "7b03b65bf0d02519c86750d2da33f413e11cf0c6", "target": 1, "func": "int av_interleaved_write_frame(AVFormatContext *s, AVPacket *pkt)\n{\n    int ret, flush = 0;\n    if (pkt) {\n        AVStream *st = s->streams[pkt->stream_index];\n        //FIXME/XXX/HACK drop zero sized packets\n        if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO && pkt->size == 0)\n            return 0;\n        av_dlog(s, \"av_interleaved_write_frame size:%d dts:%\" PRId64 \" pts:%\" PRId64 \"\\n\",\n                pkt->size, pkt->dts, pkt->pts);\n        if ((ret = compute_pkt_fields2(s, st, pkt)) < 0 && !(s->oformat->flags & AVFMT_NOTIMESTAMPS))\n        if (pkt->dts == AV_NOPTS_VALUE && !(s->oformat->flags & AVFMT_NOTIMESTAMPS))\n            return AVERROR(EINVAL);\n    } else {\n        av_dlog(s, \"av_interleaved_write_frame FLUSH\\n\");\n        flush = 1;\n    }\n    for (;; ) {\n        AVPacket opkt;\n        int ret = interleave_packet(s, &opkt, pkt, flush);\n        if (ret <= 0) //FIXME cleanup needed for ret<0 ?\n        ret = write_packet(s, &opkt);\n        if (ret >= 0)\n            s->streams[opkt.stream_index]->nb_frames++;\n        av_free_packet(&opkt);\n        pkt = NULL;\n    }\n}", "idx": 13623, "_split": "valid", "_hash": "0114499c7333014cab85b18f0288aca1"}
{"project": "FFmpeg", "commit_id": "be2b927a6f5311cd5dbf25bd34a029c5d376d9cd", "target": 0, "func": "static void unref_buffer(InputStream *ist, FrameBuffer *buf)\n\n{\n\n    av_assert0(buf->refcount);\n\n    buf->refcount--;\n\n    if (!buf->refcount) {\n\n        buf->next = ist->buffer_pool;\n\n        ist->buffer_pool = buf;\n\n    }\n\n}\n", "idx": 13648, "_split": "valid", "_hash": "bf9a8ba18315773a77d7896cf7e7d33d"}
{"project": "FFmpeg", "commit_id": "4fd34e639d15b44e02686c9b4ef58c9c3c9b0a69", "target": 0, "func": "static void loop_filter(const H264Context *h, H264SliceContext *sl, int start_x, int end_x)\n\n{\n\n    uint8_t *dest_y, *dest_cb, *dest_cr;\n\n    int linesize, uvlinesize, mb_x, mb_y;\n\n    const int end_mb_y       = sl->mb_y + FRAME_MBAFF(h);\n\n    const int old_slice_type = sl->slice_type;\n\n    const int pixel_shift    = h->pixel_shift;\n\n    const int block_h        = 16 >> h->chroma_y_shift;\n\n\n\n    if (h->postpone_filter)\n\n        return;\n\n\n\n    if (sl->deblocking_filter) {\n\n        for (mb_x = start_x; mb_x < end_x; mb_x++)\n\n            for (mb_y = end_mb_y - FRAME_MBAFF(h); mb_y <= end_mb_y; mb_y++) {\n\n                int mb_xy, mb_type;\n\n                mb_xy         = sl->mb_xy = mb_x + mb_y * h->mb_stride;\n\n                sl->slice_num = h->slice_table[mb_xy];\n\n                mb_type       = h->cur_pic.mb_type[mb_xy];\n\n                sl->list_count = h->list_counts[mb_xy];\n\n\n\n                if (FRAME_MBAFF(h))\n\n                    sl->mb_mbaff               =\n\n                    sl->mb_field_decoding_flag = !!IS_INTERLACED(mb_type);\n\n\n\n                sl->mb_x = mb_x;\n\n                sl->mb_y = mb_y;\n\n                dest_y  = h->cur_pic.f->data[0] +\n\n                          ((mb_x << pixel_shift) + mb_y * sl->linesize) * 16;\n\n                dest_cb = h->cur_pic.f->data[1] +\n\n                          (mb_x << pixel_shift) * (8 << CHROMA444(h)) +\n\n                          mb_y * sl->uvlinesize * block_h;\n\n                dest_cr = h->cur_pic.f->data[2] +\n\n                          (mb_x << pixel_shift) * (8 << CHROMA444(h)) +\n\n                          mb_y * sl->uvlinesize * block_h;\n\n                // FIXME simplify above\n\n\n\n                if (MB_FIELD(sl)) {\n\n                    linesize   = sl->mb_linesize   = sl->linesize   * 2;\n\n                    uvlinesize = sl->mb_uvlinesize = sl->uvlinesize * 2;\n\n                    if (mb_y & 1) { // FIXME move out of this function?\n\n                        dest_y  -= sl->linesize   * 15;\n\n                        dest_cb -= sl->uvlinesize * (block_h - 1);\n\n                        dest_cr -= sl->uvlinesize * (block_h - 1);\n\n                    }\n\n                } else {\n\n                    linesize   = sl->mb_linesize   = sl->linesize;\n\n                    uvlinesize = sl->mb_uvlinesize = sl->uvlinesize;\n\n                }\n\n                backup_mb_border(h, sl, dest_y, dest_cb, dest_cr, linesize,\n\n                                 uvlinesize, 0);\n\n                if (fill_filter_caches(h, sl, mb_type))\n\n                    continue;\n\n                sl->chroma_qp[0] = get_chroma_qp(h, 0, h->cur_pic.qscale_table[mb_xy]);\n\n                sl->chroma_qp[1] = get_chroma_qp(h, 1, h->cur_pic.qscale_table[mb_xy]);\n\n\n\n                if (FRAME_MBAFF(h)) {\n\n                    ff_h264_filter_mb(h, sl, mb_x, mb_y, dest_y, dest_cb, dest_cr,\n\n                                      linesize, uvlinesize);\n\n                } else {\n\n                    ff_h264_filter_mb_fast(h, sl, mb_x, mb_y, dest_y, dest_cb,\n\n                                           dest_cr, linesize, uvlinesize);\n\n                }\n\n            }\n\n    }\n\n    sl->slice_type  = old_slice_type;\n\n    sl->mb_x         = end_x;\n\n    sl->mb_y         = end_mb_y - FRAME_MBAFF(h);\n\n    sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n    sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n}\n", "idx": 13649, "_split": "valid", "_hash": "7e81a7d6d51b53133437a7a0ea7137e5"}
{"project": "FFmpeg", "commit_id": "3b199d29cd597a3518136d78860e172060b9e83d", "target": 0, "func": "static av_cold int flashsv_decode_init(AVCodecContext *avctx)\n\n{\n\n    FlashSVContext *s = avctx->priv_data;\n\n    int zret; // Zlib return code\n\n\n\n    s->avctx          = avctx;\n\n    s->zstream.zalloc = Z_NULL;\n\n    s->zstream.zfree  = Z_NULL;\n\n    s->zstream.opaque = Z_NULL;\n\n    zret = inflateInit(&s->zstream);\n\n    if (zret != Z_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Inflate init error: %d\\n\", zret);\n\n        return 1;\n\n    }\n\n    avctx->pix_fmt = AV_PIX_FMT_BGR24;\n\n    s->frame.data[0] = NULL;\n\n\n\n    return 0;\n\n}\n", "idx": 13673, "_split": "valid", "_hash": "d8da58038b903f8058eb9573e7e4ba18"}
{"project": "FFmpeg", "commit_id": "9a5ac36b69ede4563e9ecd734141b12ea3280fbc", "target": 1, "func": "static int mov_write_trak_tag(AVIOContext *pb, MOVMuxContext *mov,\n\n                              MOVTrack *track, AVStream *st)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* size */\n\n    ffio_wfourcc(pb, \"trak\");\n\n    mov_write_tkhd_tag(pb, mov, track, st);\n\n    if (track->mode == MODE_PSP || track->flags & MOV_TRACK_CTTS ||\n\n        (track->entry && track->cluster[0].dts) ||\n\n        is_clcp_track(track)) {\n\n        if (mov->use_editlist)\n\n            mov_write_edts_tag(pb, mov, track);  // PSP Movies require edts box\n\n        else if ((track->entry && track->cluster[0].dts) || track->mode == MODE_PSP || is_clcp_track(track))\n\n            av_log(mov->fc, AV_LOG_WARNING,\n\n                   \"Not writing any edit list even though one would have been required\\n\");\n\n    }\n\n    if (track->tref_tag)\n\n        mov_write_tref_tag(pb, track);\n\n    mov_write_mdia_tag(pb, mov, track);\n\n    if (track->mode == MODE_PSP)\n\n        mov_write_uuid_tag_psp(pb, track); // PSP Movies require this uuid box\n\n    if (track->tag == MKTAG('r','t','p',' '))\n\n        mov_write_udta_sdp(pb, track);\n\n    if (track->mode == MODE_MOV) {\n\n        if (track->enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            double sample_aspect_ratio = av_q2d(st->sample_aspect_ratio);\n\n            if ((0.0 != sample_aspect_ratio && 1.0 != sample_aspect_ratio)) {\n\n                mov_write_tapt_tag(pb, track);\n\n            }\n\n        }\n\n        if (is_clcp_track(track)) {\n\n            mov_write_tapt_tag(pb, track);\n\n        }\n\n    }\n\n    mov_write_track_udta_tag(pb, mov, st);\n\n    return update_size(pb, pos);\n\n}\n", "idx": 13678, "_split": "valid", "_hash": "aa0e30af35460e965080e44bf7259356"}
{"project": "FFmpeg", "commit_id": "87eebb3454ff0cd6af6ebf9e1d31bdfd1c3b601b", "target": 0, "func": "const uint8_t *ff_h264_decode_nal(H264Context *h, const uint8_t *src, int *dst_length, int *consumed, int length){\n\n    int i, si, di;\n\n    uint8_t *dst;\n\n    int bufidx;\n\n\n\n//    src[0]&0x80;                //forbidden bit\n\n    h->nal_ref_idc= src[0]>>5;\n\n    h->nal_unit_type= src[0]&0x1F;\n\n\n\n    src++; length--;\n\n\n\n#if HAVE_FAST_UNALIGNED\n\n# if HAVE_FAST_64BIT\n\n#   define RS 7\n\n    for(i=0; i+1<length; i+=9){\n\n        if(!((~AV_RN64A(src+i) & (AV_RN64A(src+i) - 0x0100010001000101ULL)) & 0x8000800080008080ULL))\n\n# else\n\n#   define RS 3\n\n    for(i=0; i+1<length; i+=5){\n\n        if(!((~AV_RN32A(src+i) & (AV_RN32A(src+i) - 0x01000101U)) & 0x80008080U))\n\n# endif\n\n            continue;\n\n        if(i>0 && !src[i]) i--;\n\n        while(src[i]) i++;\n\n#else\n\n#   define RS 0\n\n    for(i=0; i+1<length; i+=2){\n\n        if(src[i]) continue;\n\n        if(i>0 && src[i-1]==0) i--;\n\n#endif\n\n        if(i+2<length && src[i+1]==0 && src[i+2]<=3){\n\n            if(src[i+2]!=3){\n\n                /* startcode, so we must be past the end */\n\n                length=i;\n\n            }\n\n            break;\n\n        }\n\n        i-= RS;\n\n    }\n\n\n\n    if(i>=length-1){ //no escaped 0\n\n        *dst_length= length;\n\n        *consumed= length+1; //+1 for the header\n\n        return src;\n\n    }\n\n\n\n    bufidx = h->nal_unit_type == NAL_DPC ? 1 : 0; // use second escape buffer for inter data\n\n    av_fast_malloc(&h->rbsp_buffer[bufidx], &h->rbsp_buffer_size[bufidx], length+FF_INPUT_BUFFER_PADDING_SIZE);\n\n    dst= h->rbsp_buffer[bufidx];\n\n\n\n    if (dst == NULL){\n\n        return NULL;\n\n    }\n\n\n\n//printf(\"decoding esc\\n\");\n\n    memcpy(dst, src, i);\n\n    si=di=i;\n\n    while(si+2<length){\n\n        //remove escapes (very rare 1:2^22)\n\n        if(src[si+2]>3){\n\n            dst[di++]= src[si++];\n\n            dst[di++]= src[si++];\n\n        }else if(src[si]==0 && src[si+1]==0){\n\n            if(src[si+2]==3){ //escape\n\n                dst[di++]= 0;\n\n                dst[di++]= 0;\n\n                si+=3;\n\n                continue;\n\n            }else //next start code\n\n                goto nsc;\n\n        }\n\n\n\n        dst[di++]= src[si++];\n\n    }\n\n    while(si<length)\n\n        dst[di++]= src[si++];\n\nnsc:\n\n\n\n    memset(dst+di, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    *dst_length= di;\n\n    *consumed= si + 1;//+1 for the header\n\n//FIXME store exact number of bits in the getbitcontext (it is needed for decoding)\n\n    return dst;\n\n}\n", "idx": 13683, "_split": "valid", "_hash": "94e45e3195633f9029bb8a81d477f731"}
{"project": "FFmpeg", "commit_id": "d208d1eba3799c58fd6d3602d31de3e686f14aec", "target": 1, "func": "static void derive_spatial_merge_candidates(HEVCContext *s, int x0, int y0,\n\n                                            int nPbW, int nPbH,\n\n                                            int log2_cb_size,\n\n                                            int singleMCLFlag, int part_idx,\n\n                                            int merge_idx,\n\n                                            struct MvField mergecandlist[])\n\n{\n\n    HEVCLocalContext *lc   = &s->HEVClc;\n\n    RefPicList *refPicList = s->ref->refPicList;\n\n    MvField *tab_mvf       = s->ref->tab_mvf;\n\n\n\n    const int min_pu_width = s->sps->min_pu_width;\n\n\n\n    const int cand_bottom_left = lc->na.cand_bottom_left;\n\n    const int cand_left        = lc->na.cand_left;\n\n    const int cand_up_left     = lc->na.cand_up_left;\n\n    const int cand_up          = lc->na.cand_up;\n\n    const int cand_up_right    = lc->na.cand_up_right_sap;\n\n\n\n    const int xA1    = x0 - 1;\n\n    const int yA1    = y0 + nPbH - 1;\n\n    const int xA1_pu = xA1 >> s->sps->log2_min_pu_size;\n\n    const int yA1_pu = yA1 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xB1    = x0 + nPbW - 1;\n\n    const int yB1    = y0 - 1;\n\n    const int xB1_pu = xB1 >> s->sps->log2_min_pu_size;\n\n    const int yB1_pu = yB1 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xB0    = x0 + nPbW;\n\n    const int yB0    = y0 - 1;\n\n    const int xB0_pu = xB0 >> s->sps->log2_min_pu_size;\n\n    const int yB0_pu = yB0 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xA0    = x0 - 1;\n\n    const int yA0    = y0 + nPbH;\n\n    const int xA0_pu = xA0 >> s->sps->log2_min_pu_size;\n\n    const int yA0_pu = yA0 >> s->sps->log2_min_pu_size;\n\n\n\n    const int xB2    = x0 - 1;\n\n    const int yB2    = y0 - 1;\n\n    const int xB2_pu = xB2 >> s->sps->log2_min_pu_size;\n\n    const int yB2_pu = yB2 >> s->sps->log2_min_pu_size;\n\n\n\n    const int nb_refs = (s->sh.slice_type == P_SLICE) ?\n\n                        s->sh.nb_refs[0] : FFMIN(s->sh.nb_refs[0], s->sh.nb_refs[1]);\n\n    int check_MER   = 1;\n\n    int check_MER_1 = 1;\n\n\n\n    int zero_idx = 0;\n\n\n\n    int nb_merge_cand = 0;\n\n    int nb_orig_merge_cand = 0;\n\n\n\n    int is_available_a0;\n\n    int is_available_a1;\n\n    int is_available_b0;\n\n    int is_available_b1;\n\n    int is_available_b2;\n\n    int check_B0;\n\n    int check_A0;\n\n\n\n    //first left spatial merge candidate\n\n    is_available_a1 = AVAILABLE(cand_left, A1);\n\n\n\n    if (!singleMCLFlag && part_idx == 1 &&\n\n        (lc->cu.part_mode == PART_Nx2N ||\n\n         lc->cu.part_mode == PART_nLx2N ||\n\n         lc->cu.part_mode == PART_nRx2N) ||\n\n        isDiffMER(s, xA1, yA1, x0, y0)) {\n\n        is_available_a1 = 0;\n\n    }\n\n\n\n    if (is_available_a1) {\n\n        mergecandlist[0] = TAB_MVF_PU(A1);\n\n        if (merge_idx == 0)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // above spatial merge candidate\n\n    is_available_b1 = AVAILABLE(cand_up, B1);\n\n\n\n    if (!singleMCLFlag && part_idx == 1 &&\n\n        (lc->cu.part_mode == PART_2NxN ||\n\n         lc->cu.part_mode == PART_2NxnU ||\n\n         lc->cu.part_mode == PART_2NxnD) ||\n\n        isDiffMER(s, xB1, yB1, x0, y0)) {\n\n        is_available_b1 = 0;\n\n    }\n\n\n\n    if (is_available_a1 && is_available_b1)\n\n        check_MER = !COMPARE_MV_REFIDX(B1, A1);\n\n\n\n    if (is_available_b1 && check_MER)\n\n        mergecandlist[nb_merge_cand++] = TAB_MVF_PU(B1);\n\n\n\n    // above right spatial merge candidate\n\n    check_MER = 1;\n\n    check_B0  = PRED_BLOCK_AVAILABLE(B0);\n\n\n\n    is_available_b0 = check_B0 && AVAILABLE(cand_up_right, B0);\n\n\n\n    if (isDiffMER(s, xB0, yB0, x0, y0))\n\n        is_available_b0 = 0;\n\n\n\n    if (is_available_b1 && is_available_b0)\n\n        check_MER = !COMPARE_MV_REFIDX(B0, B1);\n\n\n\n    if (is_available_b0 && check_MER) {\n\n        mergecandlist[nb_merge_cand] = TAB_MVF_PU(B0);\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // left bottom spatial merge candidate\n\n    check_MER = 1;\n\n    check_A0  = PRED_BLOCK_AVAILABLE(A0);\n\n\n\n    is_available_a0 = check_A0 && AVAILABLE(cand_bottom_left, A0);\n\n\n\n    if (isDiffMER(s, xA0, yA0, x0, y0))\n\n        is_available_a0 = 0;\n\n\n\n    if (is_available_a1 && is_available_a0)\n\n        check_MER = !COMPARE_MV_REFIDX(A0, A1);\n\n\n\n    if (is_available_a0 && check_MER) {\n\n        mergecandlist[nb_merge_cand] = TAB_MVF_PU(A0);\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // above left spatial merge candidate\n\n    check_MER = 1;\n\n\n\n    is_available_b2 = AVAILABLE(cand_up_left, B2);\n\n\n\n    if (isDiffMER(s, xB2, yB2, x0, y0))\n\n        is_available_b2 = 0;\n\n\n\n    if (is_available_a1 && is_available_b2)\n\n        check_MER = !COMPARE_MV_REFIDX(B2, A1);\n\n\n\n    if (is_available_b1 && is_available_b2)\n\n        check_MER_1 = !COMPARE_MV_REFIDX(B2, B1);\n\n\n\n    if (is_available_b2 && check_MER && check_MER_1 && nb_merge_cand != 4) {\n\n        mergecandlist[nb_merge_cand] = TAB_MVF_PU(B2);\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n    }\n\n\n\n    // temporal motion vector candidate\n\n    if (s->sh.slice_temporal_mvp_enabled_flag &&\n\n        nb_merge_cand < s->sh.max_num_merge_cand) {\n\n        Mv mv_l0_col, mv_l1_col;\n\n        int available_l0 = temporal_luma_motion_vector(s, x0, y0, nPbW, nPbH,\n\n                                                       0, &mv_l0_col, 0);\n\n        int available_l1 = (s->sh.slice_type == B_SLICE) ?\n\n                           temporal_luma_motion_vector(s, x0, y0, nPbW, nPbH,\n\n                                                       0, &mv_l1_col, 1) : 0;\n\n\n\n        if (available_l0 || available_l1) {\n\n            mergecandlist[nb_merge_cand].is_intra     = 0;\n\n            mergecandlist[nb_merge_cand].pred_flag[0] = available_l0;\n\n            mergecandlist[nb_merge_cand].pred_flag[1] = available_l1;\n\n            if (available_l0) {\n\n                mergecandlist[nb_merge_cand].mv[0]      = mv_l0_col;\n\n                mergecandlist[nb_merge_cand].ref_idx[0] = 0;\n\n            }\n\n            if (available_l1) {\n\n                mergecandlist[nb_merge_cand].mv[1]      = mv_l1_col;\n\n                mergecandlist[nb_merge_cand].ref_idx[1] = 0;\n\n            }\n\n            if (merge_idx == nb_merge_cand)\n\n                return;\n\n            nb_merge_cand++;\n\n        }\n\n    }\n\n\n\n    nb_orig_merge_cand = nb_merge_cand;\n\n\n\n    // combined bi-predictive merge candidates  (applies for B slices)\n\n    if (s->sh.slice_type == B_SLICE && nb_orig_merge_cand > 1 &&\n\n        nb_orig_merge_cand < s->sh.max_num_merge_cand) {\n\n        int comb_idx;\n\n\n\n        for (comb_idx = 0; nb_merge_cand < s->sh.max_num_merge_cand &&\n\n                           comb_idx < nb_orig_merge_cand * (nb_orig_merge_cand - 1); comb_idx++) {\n\n            int l0_cand_idx = l0_l1_cand_idx[comb_idx][0];\n\n            int l1_cand_idx = l0_l1_cand_idx[comb_idx][1];\n\n            MvField l0_cand = mergecandlist[l0_cand_idx];\n\n            MvField l1_cand = mergecandlist[l1_cand_idx];\n\n\n\n            if (l0_cand.pred_flag[0] && l1_cand.pred_flag[1] &&\n\n                (refPicList[0].list[l0_cand.ref_idx[0]] !=\n\n                 refPicList[1].list[l1_cand.ref_idx[1]] ||\n\n                 AV_RN32A(&l0_cand.mv[0]) != AV_RN32A(&l1_cand.mv[1]))) {\n\n                mergecandlist[nb_merge_cand].ref_idx[0]   = l0_cand.ref_idx[0];\n\n                mergecandlist[nb_merge_cand].ref_idx[1]   = l1_cand.ref_idx[1];\n\n                mergecandlist[nb_merge_cand].pred_flag[0] = 1;\n\n                mergecandlist[nb_merge_cand].pred_flag[1] = 1;\n\n                AV_COPY32(&mergecandlist[nb_merge_cand].mv[0], &l0_cand.mv[0]);\n\n                AV_COPY32(&mergecandlist[nb_merge_cand].mv[1], &l1_cand.mv[1]);\n\n                mergecandlist[nb_merge_cand].is_intra     = 0;\n\n                if (merge_idx == nb_merge_cand)\n\n                    return;\n\n                nb_merge_cand++;\n\n            }\n\n        }\n\n    }\n\n\n\n    // append Zero motion vector candidates\n\n    while (nb_merge_cand < s->sh.max_num_merge_cand) {\n\n        mergecandlist[nb_merge_cand].pred_flag[0] = 1;\n\n        mergecandlist[nb_merge_cand].pred_flag[1] = s->sh.slice_type == B_SLICE;\n\n        AV_ZERO32(mergecandlist[nb_merge_cand].mv + 0);\n\n        AV_ZERO32(mergecandlist[nb_merge_cand].mv + 1);\n\n        mergecandlist[nb_merge_cand].is_intra     = 0;\n\n        mergecandlist[nb_merge_cand].ref_idx[0]   = zero_idx < nb_refs ? zero_idx : 0;\n\n        mergecandlist[nb_merge_cand].ref_idx[1]   = zero_idx < nb_refs ? zero_idx : 0;\n\n\n\n        if (merge_idx == nb_merge_cand)\n\n            return;\n\n        nb_merge_cand++;\n\n        zero_idx++;\n\n    }\n\n}\n", "idx": 13725, "_split": "valid", "_hash": "629cb1828f8dce9792342ea2a2403a97"}
{"project": "FFmpeg", "commit_id": "1dd488e9559bbe411c6933fd8ff02450a4b3be7e", "target": 0, "func": "static void hl_decode_mb(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy= h->mb_xy;\n\n    const int mb_type= s->current_picture.mb_type[mb_xy];\n\n    int is_complex = h->is_complex || IS_INTRA_PCM(mb_type) || s->qscale == 0;\n\n\n\n    if(ENABLE_H264_ENCODER && !s->decode)\n\n        return;\n\n\n\n    if (is_complex)\n\n        hl_decode_mb_complex(h);\n\n    else hl_decode_mb_simple(h);\n\n}\n", "idx": 13833, "_split": "valid", "_hash": "987dd4850c76fb2fb3ada23f1caaff81"}
{"project": "FFmpeg", "commit_id": "2f11aa141a01f97c5d2a015bd9dbdb27314b79c4", "target": 1, "func": "static int query_format(struct vf_instance *vf, unsigned int fmt)\n\n{\n\n        /* FIXME - really any YUV 4:2:0 input format should work */\n\n        switch (fmt) {\n\n        case IMGFMT_YV12:\n\n        case IMGFMT_IYUV:\n\n        case IMGFMT_I420:\n\n                return ff_vf_next_query_format(vf, IMGFMT_YV12);\n\n        }\n\n        return 0;\n\n}\n", "idx": 13836, "_split": "valid", "_hash": "763ee913327ff4e21e7906b6c2cca451"}
{"project": "FFmpeg", "commit_id": "32baeafeee4f8446c2c3720b9223ad2166ca9d30", "target": 1, "func": "void ff_jref_idct_add(uint8_t *dest, ptrdiff_t line_size, int16_t *block)\n\n{\n\n    ff_j_rev_dct(block);\n\n    ff_add_pixels_clamped(block, dest, line_size);\n\n}\n", "idx": 13857, "_split": "valid", "_hash": "4cc89a0bbe90d817c599248d2799c601"}
{"project": "FFmpeg", "commit_id": "5331773cc33ba26b9e26ace643d926219e46a17b", "target": 0, "func": "static void get_id3_tag(AVFormatContext *s, int len)\n\n{\n\n    ID3v2ExtraMeta *id3v2_extra_meta = NULL;\n\n\n\n    ff_id3v2_read(s, ID3v2_DEFAULT_MAGIC, &id3v2_extra_meta);\n\n    if (id3v2_extra_meta)\n\n        ff_id3v2_parse_apic(s, &id3v2_extra_meta);\n\n    ff_id3v2_free_extra_meta(&id3v2_extra_meta);\n\n}\n", "idx": 13869, "_split": "valid", "_hash": "dea12b6d6d9878cc62501707070b4b48"}
{"project": "FFmpeg", "commit_id": "465e1dadbef7596a3eb87089a66bb4ecdc26d3c4", "target": 0, "func": "static void flush_buffer(ByteIOContext *s)\n\n{\n\n    if (s->buf_ptr > s->buffer) {\n\n        if (s->write_packet)\n\n            s->write_packet(s->opaque, s->buffer, s->buf_ptr - s->buffer);\n\n        if(s->checksum_ptr){\n\n            s->checksum= s->update_checksum(s->checksum, s->checksum_ptr, s->buf_ptr - s->checksum_ptr);\n\n            s->checksum_ptr= s->buffer;\n\n        }\n\n        s->pos += s->buf_ptr - s->buffer;\n\n    }\n\n    s->buf_ptr = s->buffer;\n\n}\n", "idx": 13893, "_split": "valid", "_hash": "b79216ec4c1b92961ad5eba44f568351"}
{"project": "FFmpeg", "commit_id": "679a315424e6ffaafd21ebf7a86108bd4e743793", "target": 1, "func": "static int daala_packet(AVFormatContext *s, int idx)\n\n{\n\n    int seg, duration = 1;\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_stream *os = ogg->streams + idx;\n\n\n\n    /*\n\n     * first packet handling: here we parse the duration of each packet in the\n\n     * first page and compare the total duration to the page granule to find the\n\n     * encoder delay and set the first timestamp\n\n     */\n\n\n\n    if ((!os->lastpts || os->lastpts == AV_NOPTS_VALUE) && !(os->flags & OGG_FLAG_EOS)) {\n\n        for (seg = os->segp; seg < os->nsegs; seg++)\n\n            if (os->segments[seg] < 255)\n\n                duration++;\n\n\n\n        os->lastpts = os->lastdts = daala_gptopts(s, idx, os->granule, NULL) - duration;\n\n        if(s->streams[idx]->start_time == AV_NOPTS_VALUE) {\n\n            s->streams[idx]->start_time = os->lastpts;\n\n            if (s->streams[idx]->duration)\n\n                s->streams[idx]->duration -= s->streams[idx]->start_time;\n\n        }\n\n    }\n\n\n\n    /* parse packet duration */\n\n    if (os->psize > 0)\n\n        os->pduration = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 13914, "_split": "valid", "_hash": "a72af0f0751d2b807a745df280f3a402"}
{"project": "FFmpeg", "commit_id": "f0efd795f460aa64d06bb542c6eadd113c2585c2", "target": 1, "func": "static int clv_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    CLVContext *c = avctx->priv_data;\n\n    GetByteContext gb;\n\n    uint32_t frame_type;\n\n    int i, j;\n\n    int ret;\n\n    int mb_ret = 0;\n\n\n\n    bytestream2_init(&gb, buf, buf_size);\n\n    if (avctx->codec_tag == MKTAG('C','L','V','1')) {\n\n        int skip = bytestream2_get_byte(&gb);\n\n        bytestream2_skip(&gb, (skip + 1) * 8);\n\n    }\n\n\n\n    frame_type = bytestream2_get_byte(&gb);\n\n    if ((ret = ff_reget_buffer(avctx, c->pic)) < 0)\n\n        return ret;\n\n\n\n    c->pic->key_frame = frame_type & 0x20 ? 1 : 0;\n\n    c->pic->pict_type = frame_type & 0x20 ? AV_PICTURE_TYPE_I : AV_PICTURE_TYPE_P;\n\n\n\n    if (frame_type & 0x2) {\n\n        if (buf_size < c->mb_width * c->mb_height) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet too small\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        bytestream2_get_be32(&gb); // frame size;\n\n        c->ac_quant        = bytestream2_get_byte(&gb);\n\n        c->luma_dc_quant   = 32;\n\n        c->chroma_dc_quant = 32;\n\n\n\n        if ((ret = init_get_bits8(&c->gb, buf + bytestream2_tell(&gb),\n\n                                  (buf_size - bytestream2_tell(&gb)))) < 0)\n\n            return ret;\n\n\n\n        for (i = 0; i < 3; i++)\n\n            c->top_dc[i] = 32;\n\n        for (i = 0; i < 4; i++)\n\n            c->left_dc[i] = 32;\n\n\n\n        for (j = 0; j < c->mb_height; j++) {\n\n            for (i = 0; i < c->mb_width; i++) {\n\n                ret = decode_mb(c, i, j);\n\n                if (ret < 0)\n\n                    mb_ret = ret;\n\n            }\n\n        }\n\n    } else {\n\n    }\n\n\n\n    if ((ret = av_frame_ref(data, c->pic)) < 0)\n\n        return ret;\n\n\n\n    *got_frame = 1;\n\n\n\n    return mb_ret < 0 ? mb_ret : buf_size;\n\n}\n", "idx": 13938, "_split": "valid", "_hash": "2cc981cf9a682aa64b0352a473b92785"}
{"project": "FFmpeg", "commit_id": "3632f35c8e163f6aa6d63c317e3e1fca6a4a5fab", "target": 1, "func": "static int read_frame(BVID_DemuxContext *vid, AVIOContext *pb, AVPacket *pkt,\n\n                      uint8_t block_type, AVFormatContext *s)\n\n{\n\n    uint8_t * vidbuf_start = NULL;\n\n    int vidbuf_nbytes = 0;\n\n    int code;\n\n    int bytes_copied = 0;\n\n    int position, duration, npixels;\n\n    unsigned int vidbuf_capacity;\n\n    int ret = 0;\n\n    AVStream *st;\n\n\n\n    if (vid->video_index < 0) {\n\n        st = avformat_new_stream(s, NULL);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        vid->video_index = st->index;\n\n        if (vid->audio_index < 0) {\n\n            av_log_ask_for_sample(s, \"No audio packet before first video \"\n\n                                  \"packet. Using default video time base.\\n\");\n\n        }\n\n        avpriv_set_pts_info(st, 64, 185, vid->sample_rate);\n\n        st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        st->codec->codec_id   = AV_CODEC_ID_BETHSOFTVID;\n\n        st->codec->width      = vid->width;\n\n        st->codec->height     = vid->height;\n\n    }\n\n    st      = s->streams[vid->video_index];\n\n    npixels = st->codec->width * st->codec->height;\n\n\n\n    vidbuf_start = av_malloc(vidbuf_capacity = BUFFER_PADDING_SIZE);\n\n    if(!vidbuf_start)\n\n        return AVERROR(ENOMEM);\n\n\n\n    // save the file position for the packet, include block type\n\n    position = avio_tell(pb) - 1;\n\n\n\n    vidbuf_start[vidbuf_nbytes++] = block_type;\n\n\n\n    // get the current packet duration\n\n    duration = vid->bethsoft_global_delay + avio_rl16(pb);\n\n\n\n    // set the y offset if it exists (decoder header data should be in data section)\n\n    if(block_type == VIDEO_YOFF_P_FRAME){\n\n        if (avio_read(pb, &vidbuf_start[vidbuf_nbytes], 2) != 2) {\n\n            ret = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n        vidbuf_nbytes += 2;\n\n    }\n\n\n\n    do{\n\n        vidbuf_start = av_fast_realloc(vidbuf_start, &vidbuf_capacity, vidbuf_nbytes + BUFFER_PADDING_SIZE);\n\n        if(!vidbuf_start)\n\n            return AVERROR(ENOMEM);\n\n\n\n        code = avio_r8(pb);\n\n        vidbuf_start[vidbuf_nbytes++] = code;\n\n\n\n        if(code >= 0x80){ // rle sequence\n\n            if(block_type == VIDEO_I_FRAME)\n\n                vidbuf_start[vidbuf_nbytes++] = avio_r8(pb);\n\n        } else if(code){ // plain sequence\n\n            if (avio_read(pb, &vidbuf_start[vidbuf_nbytes], code) != code) {\n\n                ret = AVERROR(EIO);\n\n                goto fail;\n\n            }\n\n            vidbuf_nbytes += code;\n\n        }\n\n        bytes_copied += code & 0x7F;\n\n        if(bytes_copied == npixels){ // sometimes no stop character is given, need to keep track of bytes copied\n\n            // may contain a 0 byte even if read all pixels\n\n            if(avio_r8(pb))\n\n                avio_seek(pb, -1, SEEK_CUR);\n\n            break;\n\n        }\n\n        if (bytes_copied > npixels) {\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n    } while(code);\n\n\n\n    // copy data into packet\n\n    if ((ret = av_new_packet(pkt, vidbuf_nbytes)) < 0)\n\n        goto fail;\n\n    memcpy(pkt->data, vidbuf_start, vidbuf_nbytes);\n\n    av_free(vidbuf_start);\n\n\n\n    pkt->pos = position;\n\n    pkt->stream_index = vid->video_index;\n\n    pkt->duration = duration;\n\n    if (block_type == VIDEO_I_FRAME)\n\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\n\n\n    /* if there is a new palette available, add it to packet side data */\n\n    if (vid->palette) {\n\n        uint8_t *pdata = av_packet_new_side_data(pkt, AV_PKT_DATA_PALETTE,\n\n                                                 BVID_PALETTE_SIZE);\n\n        memcpy(pdata, vid->palette, BVID_PALETTE_SIZE);\n\n        av_freep(&vid->palette);\n\n    }\n\n\n\n    vid->nframes--;  // used to check if all the frames were read\n\n    return 0;\n\nfail:\n\n    av_free(vidbuf_start);\n\n    return ret;\n\n}\n", "idx": 14001, "_split": "valid", "_hash": "057efbda9ed7c3be4b68902a2c05d11a"}
{"project": "FFmpeg", "commit_id": "b93d96a07be40f8e5d267d55fe961285586c0fd7", "target": 1, "func": "static int nvdec_vp8_start_frame(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)\n\n{\n\n    VP8Context *h = avctx->priv_data;\n\n\n\n    NVDECContext      *ctx = avctx->internal->hwaccel_priv_data;\n\n    CUVIDPICPARAMS     *pp = &ctx->pic_params;\n\n    FrameDecodeData *fdd;\n\n    NVDECFrame *cf;\n\n    AVFrame *cur_frame = h->framep[VP56_FRAME_CURRENT]->tf.f;\n\n\n\n    int ret;\n\n\n\n    ret = ff_nvdec_start_frame(avctx, cur_frame);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    fdd = (FrameDecodeData*)cur_frame->private_ref->data;\n\n    cf  = (NVDECFrame*)fdd->hwaccel_priv;\n\n\n\n    *pp = (CUVIDPICPARAMS) {\n\n        .PicWidthInMbs     = (cur_frame->width  + 15) / 16,\n\n        .FrameHeightInMbs  = (cur_frame->height + 15) / 16,\n\n        .CurrPicIdx        = cf->idx,\n\n\n\n        .CodecSpecific.vp8 = {\n\n            .width                       = cur_frame->width,\n\n            .height                      = cur_frame->height,\n\n\n\n            .first_partition_size        = h->header_partition_size,\n\n\n\n            .LastRefIdx                  = safe_get_ref_idx(h->framep[VP56_FRAME_PREVIOUS]),\n\n            .GoldenRefIdx                = safe_get_ref_idx(h->framep[VP56_FRAME_GOLDEN]),\n\n            .AltRefIdx                   = safe_get_ref_idx(h->framep[VP56_FRAME_GOLDEN2]),\n\n\n\n            .frame_type                  = !h->keyframe,\n\n            .version                     = h->profile,\n\n            .show_frame                  = !h->invisible,\n\n            .update_mb_segmentation_data = h->segmentation.enabled ? h->segmentation.update_feature_data : 0,\n\n       }\n\n    };\n\n\n\n    return 0;\n\n}\n", "idx": 14030, "_split": "valid", "_hash": "e4edcbbc3f8e4074b2322bec77d150b8"}
{"project": "FFmpeg", "commit_id": "525782f33ff4be92bb27967c021fc244c92bdebc", "target": 1, "func": "int msmpeg4_decode_mb(MpegEncContext *s, \n\n                      DCTELEM block[6][64])\n\n{\n\n    int cbp, code, i;\n\n    int pred, val;\n\n    UINT8 *coded_val;\n\n\n\n    /* special slice handling */\n\n    if (s->mb_x == 0) {\n\n        if ((s->mb_y % s->slice_height) == 0) {\n\n            int wrap;\n\n            /* reset DC pred (set previous line to 1024) */\n\n            wrap = 2 * s->mb_width + 2;\n\n            memsetw(&s->dc_val[0][(1) + (2 * s->mb_y) * wrap], \n\n                    1024, 2 * s->mb_width);\n\n            wrap = s->mb_width + 2;\n\n            memsetw(&s->dc_val[1][(1) + (s->mb_y) * wrap], \n\n                    1024, s->mb_width);\n\n            memsetw(&s->dc_val[2][(1) + (s->mb_y) * wrap], \n\n                    1024, s->mb_width);\n\n\n\n            s->first_slice_line = 1;\n\n        } else {\n\n            s->first_slice_line = 0; \n\n        }\n\n    }\n\n\n\n    if (s->pict_type == P_TYPE) {\n\n        set_stat(ST_INTER_MB);\n\n        if (s->use_skip_mb_code) {\n\n            if (get_bits1(&s->gb)) {\n\n                /* skip mb */\n\n                s->mb_intra = 0;\n\n                for(i=0;i<6;i++)\n\n                    s->block_last_index[i] = -1;\n\n                s->mv_dir = MV_DIR_FORWARD;\n\n                s->mv_type = MV_TYPE_16X16;\n\n                s->mv[0][0][0] = 0;\n\n                s->mv[0][0][1] = 0;\n\n                s->mb_skiped = 1;\n\n                return 0;\n\n            }\n\n        }\n\n        \n\n        code = get_vlc(&s->gb, &mb_non_intra_vlc);\n\n        if (code < 0)\n\n            return -1;\n\n        if (code & 0x40)\n\n            s->mb_intra = 0;\n\n        else\n\n            s->mb_intra = 1;\n\n            \n\n        cbp = code & 0x3f;\n\n    } else {\n\n        set_stat(ST_INTRA_MB);\n\n        s->mb_intra = 1;\n\n        code = get_vlc(&s->gb, &mb_intra_vlc);\n\n        if (code < 0)\n\n            return -1;\n\n        /* predict coded block pattern */\n\n        cbp = 0;\n\n        for(i=0;i<6;i++) {\n\n            val = ((code >> (5 - i)) & 1);\n\n            if (i < 4) {\n\n                pred = coded_block_pred(s, i, &coded_val);\n\n                val = val ^ pred;\n\n                *coded_val = val;\n\n            }\n\n            cbp |= val << (5 - i);\n\n        }\n\n    }\n\n\n\n    if (!s->mb_intra) {\n\n        int mx, my;\n\n        set_stat(ST_MV);\n\n        h263_pred_motion(s, 0, &mx, &my);\n\n        if (msmpeg4_decode_motion(s, &mx, &my) < 0)\n\n            return -1;\n\n        s->mv_dir = MV_DIR_FORWARD;\n\n        s->mv_type = MV_TYPE_16X16;\n\n        s->mv[0][0][0] = mx;\n\n        s->mv[0][0][1] = my;\n\n    } else {\n\n        set_stat(ST_INTRA_MB);\n\n        s->ac_pred = get_bits1(&s->gb);\n\n    }\n\n\n\n    for (i = 0; i < 6; i++) {\n\n        if (msmpeg4_decode_block(s, block[i], i, (cbp >> (5 - i)) & 1) < 0)\n\n            return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 14046, "_split": "valid", "_hash": "e99d75d01c2d7fab1077ca5da23ad311"}
{"project": "FFmpeg", "commit_id": "18ca491bf13b76fc022373110ccac385fee0557c", "target": 1, "func": "static int matroska_parse_block(MatroskaDemuxContext *matroska, uint8_t *data,\n\n                                int size, int64_t pos, uint64_t cluster_time,\n\n                                uint64_t duration, int is_keyframe,\n\n                                int64_t cluster_pos)\n\n{\n\n    uint64_t timecode = AV_NOPTS_VALUE;\n\n    MatroskaTrack *track;\n\n    int res = 0;\n\n    AVStream *st;\n\n    AVPacket *pkt;\n\n    int16_t block_time;\n\n    uint32_t *lace_size = NULL;\n\n    int n, flags, laces = 0;\n\n    uint64_t num;\n\n\n\n    if ((n = matroska_ebmlnum_uint(matroska, data, size, &num)) < 0) {\n\n        av_log(matroska->ctx, AV_LOG_ERROR, \"EBML block data error\\n\");\n\n        return res;\n\n    }\n\n    data += n;\n\n    size -= n;\n\n\n\n    track = matroska_find_track_by_num(matroska, num);\n\n    if (size <= 3 || !track || !track->stream) {\n\n        av_log(matroska->ctx, AV_LOG_INFO,\n\n               \"Invalid stream %\"PRIu64\" or size %u\\n\", num, size);\n\n        return res;\n\n    }\n\n    st = track->stream;\n\n    if (st->discard >= AVDISCARD_ALL)\n\n        return res;\n\n    if (duration == AV_NOPTS_VALUE)\n\n        duration = track->default_duration / matroska->time_scale;\n\n\n\n    block_time = AV_RB16(data);\n\n    data += 2;\n\n    flags = *data++;\n\n    size -= 3;\n\n    if (is_keyframe == -1)\n\n        is_keyframe = flags & 0x80 ? PKT_FLAG_KEY : 0;\n\n\n\n    if (cluster_time != (uint64_t)-1\n\n        && (block_time >= 0 || cluster_time >= -block_time)) {\n\n        timecode = cluster_time + block_time;\n\n        if (track->type == MATROSKA_TRACK_TYPE_SUBTITLE\n\n            && timecode < track->end_timecode)\n\n            is_keyframe = 0;  /* overlapping subtitles are not key frame */\n\n        if (is_keyframe)\n\n            av_add_index_entry(st, cluster_pos, timecode, 0,0,AVINDEX_KEYFRAME);\n\n        track->end_timecode = FFMAX(track->end_timecode, timecode+duration);\n\n    }\n\n\n\n    if (matroska->skip_to_keyframe && track->type != MATROSKA_TRACK_TYPE_SUBTITLE) {\n\n        if (!is_keyframe || timecode < matroska->skip_to_timecode)\n\n            return res;\n\n        matroska->skip_to_keyframe = 0;\n\n    }\n\n\n\n    switch ((flags & 0x06) >> 1) {\n\n        case 0x0: /* no lacing */\n\n            laces = 1;\n\n            lace_size = av_mallocz(sizeof(int));\n\n            lace_size[0] = size;\n\n            break;\n\n\n\n        case 0x1: /* Xiph lacing */\n\n        case 0x2: /* fixed-size lacing */\n\n        case 0x3: /* EBML lacing */\n\n            assert(size>0); // size <=3 is checked before size-=3 above\n\n            laces = (*data) + 1;\n\n            data += 1;\n\n            size -= 1;\n\n            lace_size = av_mallocz(laces * sizeof(int));\n\n\n\n            switch ((flags & 0x06) >> 1) {\n\n                case 0x1: /* Xiph lacing */ {\n\n                    uint8_t temp;\n\n                    uint32_t total = 0;\n\n                    for (n = 0; res == 0 && n < laces - 1; n++) {\n\n                        while (1) {\n\n                            if (size == 0) {\n\n                                res = -1;\n\n                                break;\n\n                            }\n\n                            temp = *data;\n\n                            lace_size[n] += temp;\n\n                            data += 1;\n\n                            size -= 1;\n\n                            if (temp != 0xff)\n\n                                break;\n\n                        }\n\n                        total += lace_size[n];\n\n                    }\n\n                    lace_size[n] = size - total;\n\n                    break;\n\n                }\n\n\n\n                case 0x2: /* fixed-size lacing */\n\n                    for (n = 0; n < laces; n++)\n\n                        lace_size[n] = size / laces;\n\n                    break;\n\n\n\n                case 0x3: /* EBML lacing */ {\n\n                    uint32_t total;\n\n                    n = matroska_ebmlnum_uint(matroska, data, size, &num);\n\n                    if (n < 0) {\n\n                        av_log(matroska->ctx, AV_LOG_INFO,\n\n                               \"EBML block data error\\n\");\n\n                        break;\n\n                    }\n\n                    data += n;\n\n                    size -= n;\n\n                    total = lace_size[0] = num;\n\n                    for (n = 1; res == 0 && n < laces - 1; n++) {\n\n                        int64_t snum;\n\n                        int r;\n\n                        r = matroska_ebmlnum_sint(matroska, data, size, &snum);\n\n                        if (r < 0) {\n\n                            av_log(matroska->ctx, AV_LOG_INFO,\n\n                                   \"EBML block data error\\n\");\n\n                            break;\n\n                        }\n\n                        data += r;\n\n                        size -= r;\n\n                        lace_size[n] = lace_size[n - 1] + snum;\n\n                        total += lace_size[n];\n\n                    }\n\n                    lace_size[n] = size - total;\n\n                    break;\n\n                }\n\n            }\n\n            break;\n\n    }\n\n\n\n    if (res == 0) {\n\n        for (n = 0; n < laces; n++) {\n\n            if (st->codec->codec_id == CODEC_ID_RA_288 ||\n\n                st->codec->codec_id == CODEC_ID_COOK ||\n\n                st->codec->codec_id == CODEC_ID_ATRAC3) {\n\n                int a = st->codec->block_align;\n\n                int sps = track->audio.sub_packet_size;\n\n                int cfs = track->audio.coded_framesize;\n\n                int h = track->audio.sub_packet_h;\n\n                int y = track->audio.sub_packet_cnt;\n\n                int w = track->audio.frame_size;\n\n                int x;\n\n\n\n                if (!track->audio.pkt_cnt) {\n\n                    if (st->codec->codec_id == CODEC_ID_RA_288)\n\n                        for (x=0; x<h/2; x++)\n\n                            memcpy(track->audio.buf+x*2*w+y*cfs,\n\n                                   data+x*cfs, cfs);\n\n                    else\n\n                        for (x=0; x<w/sps; x++)\n\n                            memcpy(track->audio.buf+sps*(h*x+((h+1)/2)*(y&1)+(y>>1)), data+x*sps, sps);\n\n\n\n                    if (++track->audio.sub_packet_cnt >= h) {\n\n                        track->audio.sub_packet_cnt = 0;\n\n                        track->audio.pkt_cnt = h*w / a;\n\n                    }\n\n                }\n\n                while (track->audio.pkt_cnt) {\n\n                    pkt = av_mallocz(sizeof(AVPacket));\n\n                    av_new_packet(pkt, a);\n\n                    memcpy(pkt->data, track->audio.buf\n\n                           + a * (h*w / a - track->audio.pkt_cnt--), a);\n\n                    pkt->pos = pos;\n\n                    pkt->stream_index = st->index;\n\n                    dynarray_add(&matroska->packets,&matroska->num_packets,pkt);\n\n                }\n\n            } else {\n\n                MatroskaTrackEncoding *encodings = track->encodings.elem;\n\n                int offset = 0, pkt_size = lace_size[n];\n\n                uint8_t *pkt_data = data;\n\n\n\n                if (encodings && encodings->scope & 1) {\n\n                    offset = matroska_decode_buffer(&pkt_data,&pkt_size, track);\n\n                    if (offset < 0)\n\n                        continue;\n\n                }\n\n\n\n                pkt = av_mallocz(sizeof(AVPacket));\n\n                /* XXX: prevent data copy... */\n\n                if (av_new_packet(pkt, pkt_size+offset) < 0) {\n\n                    av_free(pkt);\n\n                    res = AVERROR(ENOMEM);\n\n                    break;\n\n                }\n\n                if (offset)\n\n                    memcpy (pkt->data, encodings->compression.settings.data, offset);\n\n                memcpy (pkt->data+offset, pkt_data, pkt_size);\n\n\n\n                if (pkt_data != data)\n\n                    av_free(pkt_data);\n\n\n\n                if (n == 0)\n\n                    pkt->flags = is_keyframe;\n\n                pkt->stream_index = st->index;\n\n\n\n                pkt->pts = timecode;\n\n                pkt->pos = pos;\n\n                if (st->codec->codec_id == CODEC_ID_TEXT)\n\n                    pkt->convergence_duration = duration;\n\n                else if (track->type != MATROSKA_TRACK_TYPE_SUBTITLE)\n\n                    pkt->duration = duration;\n\n\n\n                if (st->codec->codec_id == CODEC_ID_SSA)\n\n                    matroska_fix_ass_packet(matroska, pkt, duration);\n\n\n\n                if (matroska->prev_pkt &&\n\n                    timecode != AV_NOPTS_VALUE &&\n\n                    matroska->prev_pkt->pts == timecode &&\n\n                    matroska->prev_pkt->stream_index == st->index)\n\n                    matroska_merge_packets(matroska->prev_pkt, pkt);\n\n                else {\n\n                    dynarray_add(&matroska->packets,&matroska->num_packets,pkt);\n\n                    matroska->prev_pkt = pkt;\n\n                }\n\n            }\n\n\n\n            if (timecode != AV_NOPTS_VALUE)\n\n                timecode = duration ? timecode + duration : AV_NOPTS_VALUE;\n\n            data += lace_size[n];\n\n        }\n\n    }\n\n\n\n    av_free(lace_size);\n\n    return res;\n\n}\n", "idx": 14063, "_split": "valid", "_hash": "bab789487a339cf2ad233fc980d57e37"}
{"project": "FFmpeg", "commit_id": "1bc1cfdddf7ab8ef50d0fc888808d6b609eb5d8d", "target": 1, "func": "static void rtsp_cmd_pause(HTTPContext *c, const char *url, RTSPHeader *h)\n\n{\n\n    HTTPContext *rtp_c;\n\n\n\n    rtp_c = find_rtp_session_with_url(url, h->session_id);\n\n    if (!rtp_c) {\n\n        rtsp_reply_error(c, RTSP_STATUS_SESSION);\n\n        return;\n\n    }\n\n    \n\n    if (rtp_c->state != HTTPSTATE_SEND_DATA &&\n\n        rtp_c->state != HTTPSTATE_WAIT_FEED) {\n\n        rtsp_reply_error(c, RTSP_STATUS_STATE);\n\n        return;\n\n    }\n\n    \n\n    rtp_c->state = HTTPSTATE_READY;\n\n    \n\n    /* now everything is OK, so we can send the connection parameters */\n\n    rtsp_reply_header(c, RTSP_STATUS_OK);\n\n    /* session ID */\n\n    url_fprintf(c->pb, \"Session: %s\\r\\n\", rtp_c->session_id);\n\n    url_fprintf(c->pb, \"\\r\\n\");\n\n}\n", "idx": 14102, "_split": "valid", "_hash": "9cd6ccb45b4877d2e626c95480398975"}
{"project": "FFmpeg", "commit_id": "27c7ca9c12bb42d5c44d46f24cd970469d0ef55a", "target": 0, "func": "AVParserState *ff_store_parser_state(AVFormatContext *s)\n\n{\n\n    int i;\n\n    AVStream *st;\n\n    AVParserStreamState *ss;\n\n    AVParserState *state = av_malloc(sizeof(AVParserState));\n\n    if (!state)\n\n        return NULL;\n\n\n\n    state->stream_states = av_malloc(sizeof(AVParserStreamState) * s->nb_streams);\n\n    if (!state->stream_states) {\n\n        av_free(state);\n\n        return NULL;\n\n    }\n\n\n\n    state->fpos = avio_tell(s->pb);\n\n\n\n    // copy context structures\n\n    state->cur_st                           = s->cur_st;\n\n    state->packet_buffer                    = s->packet_buffer;\n\n    state->raw_packet_buffer                = s->raw_packet_buffer;\n\n    state->raw_packet_buffer_remaining_size = s->raw_packet_buffer_remaining_size;\n\n\n\n    s->cur_st                               = NULL;\n\n    s->packet_buffer                        = NULL;\n\n    s->raw_packet_buffer                    = NULL;\n\n    s->raw_packet_buffer_remaining_size     = RAW_PACKET_BUFFER_SIZE;\n\n\n\n    // copy stream structures\n\n    state->nb_streams = s->nb_streams;\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        st = s->streams[i];\n\n        ss = &state->stream_states[i];\n\n\n\n        ss->parser        = st->parser;\n\n        ss->last_IP_pts   = st->last_IP_pts;\n\n        ss->cur_dts       = st->cur_dts;\n\n        ss->reference_dts = st->reference_dts;\n\n        ss->cur_ptr       = st->cur_ptr;\n\n        ss->cur_len       = st->cur_len;\n\n        ss->probe_packets = st->probe_packets;\n\n        ss->cur_pkt       = st->cur_pkt;\n\n\n\n        st->parser        = NULL;\n\n        st->last_IP_pts   = AV_NOPTS_VALUE;\n\n        st->cur_dts       = AV_NOPTS_VALUE;\n\n        st->reference_dts = AV_NOPTS_VALUE;\n\n        st->cur_ptr       = NULL;\n\n        st->cur_len       = 0;\n\n        st->probe_packets = MAX_PROBE_PACKETS;\n\n        av_init_packet(&st->cur_pkt);\n\n    }\n\n\n\n    return state;\n\n}\n", "idx": 14136, "_split": "valid", "_hash": "65100d8910e807d719e398a713f30987"}
{"project": "FFmpeg", "commit_id": "a717f9904227d7979473bad40c50eb40af41d01d", "target": 1, "func": "void ff_mpegts_parse_close(MpegTSContext *ts)\n\n{\n\n    int i;\n\n\n\n    for(i=0;i<NB_PID_MAX;i++)\n\n        av_free(ts->pids[i]);\n\n    av_free(ts);\n\n}\n", "idx": 14146, "_split": "valid", "_hash": "51630d03269cfcee41a2ff0038835411"}
{"project": "FFmpeg", "commit_id": "3735b5c616770429572f86aabdaec39c6ebb8818", "target": 0, "func": "static int config_input(AVFilterLink *inlink)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    PadContext *s = ctx->priv;\n\n    const AVPixFmtDescriptor *pix_desc = av_pix_fmt_desc_get(inlink->format);\n\n    uint8_t rgba_color[4];\n\n    int ret, is_packed_rgba;\n\n    double var_values[VARS_NB], res;\n\n    char *expr;\n\n\n\n    s->hsub = pix_desc->log2_chroma_w;\n\n    s->vsub = pix_desc->log2_chroma_h;\n\n\n\n    var_values[VAR_PI]    = M_PI;\n\n    var_values[VAR_PHI]   = M_PHI;\n\n    var_values[VAR_E]     = M_E;\n\n    var_values[VAR_IN_W]  = var_values[VAR_IW] = inlink->w;\n\n    var_values[VAR_IN_H]  = var_values[VAR_IH] = inlink->h;\n\n    var_values[VAR_OUT_W] = var_values[VAR_OW] = NAN;\n\n    var_values[VAR_OUT_H] = var_values[VAR_OH] = NAN;\n\n    var_values[VAR_A]     = (double) inlink->w / inlink->h;\n\n    var_values[VAR_HSUB]  = 1<<s->hsub;\n\n    var_values[VAR_VSUB]  = 1<<s->vsub;\n\n\n\n    /* evaluate width and height */\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = s->w_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)\n\n        goto eval_fail;\n\n    s->w = var_values[VAR_OUT_W] = var_values[VAR_OW] = res;\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = s->h_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)\n\n        goto eval_fail;\n\n    s->h = var_values[VAR_OUT_H] = var_values[VAR_OH] = res;\n\n    /* evaluate the width again, as it may depend on the evaluated output height */\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = s->w_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)\n\n        goto eval_fail;\n\n    s->w = var_values[VAR_OUT_W] = var_values[VAR_OW] = res;\n\n\n\n    /* evaluate x and y */\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = s->x_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)\n\n        goto eval_fail;\n\n    s->x = var_values[VAR_X] = res;\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = s->y_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)\n\n        goto eval_fail;\n\n    s->y = var_values[VAR_Y] = res;\n\n    /* evaluate x again, as it may depend on the evaluated y value */\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = s->x_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, ctx)) < 0)\n\n        goto eval_fail;\n\n    s->x = var_values[VAR_X] = res;\n\n\n\n    /* sanity check params */\n\n    if (s->w < 0 || s->h < 0 || s->x < 0 || s->y < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Negative values are not acceptable.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (!s->w)\n\n        s->w = inlink->w;\n\n    if (!s->h)\n\n        s->h = inlink->h;\n\n\n\n    s->w &= ~((1 << s->hsub) - 1);\n\n    s->h &= ~((1 << s->vsub) - 1);\n\n    s->x &= ~((1 << s->hsub) - 1);\n\n    s->y &= ~((1 << s->vsub) - 1);\n\n\n\n    s->in_w = inlink->w & ~((1 << s->hsub) - 1);\n\n    s->in_h = inlink->h & ~((1 << s->vsub) - 1);\n\n\n\n    memcpy(rgba_color, s->color, sizeof(rgba_color));\n\n    ff_fill_line_with_color(s->line, s->line_step, s->w, s->color,\n\n                            inlink->format, rgba_color, &is_packed_rgba, NULL);\n\n\n\n    av_log(ctx, AV_LOG_VERBOSE, \"w:%d h:%d -> w:%d h:%d x:%d y:%d color:0x%02X%02X%02X%02X[%s]\\n\",\n\n           inlink->w, inlink->h, s->w, s->h, s->x, s->y,\n\n           s->color[0], s->color[1], s->color[2], s->color[3],\n\n           is_packed_rgba ? \"rgba\" : \"yuva\");\n\n\n\n    if (s->x <  0 || s->y <  0                      ||\n\n        s->w <= 0 || s->h <= 0                      ||\n\n        (unsigned)s->x + (unsigned)inlink->w > s->w ||\n\n        (unsigned)s->y + (unsigned)inlink->h > s->h) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Input area %d:%d:%d:%d not within the padded area 0:0:%d:%d or zero-sized\\n\",\n\n               s->x, s->y, s->x + inlink->w, s->y + inlink->h, s->w, s->h);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    return 0;\n\n\n\neval_fail:\n\n    av_log(NULL, AV_LOG_ERROR,\n\n           \"Error when evaluating the expression '%s'\\n\", expr);\n\n    return ret;\n\n\n\n}\n", "idx": 14172, "_split": "valid", "_hash": "5c879773fc636ae69b5ca8982fe30f6a"}
{"project": "FFmpeg", "commit_id": "e8f814a907036e43f755f35e885bfadf94c4d63b", "target": 1, "func": "AVRational av_guess_frame_rate(AVFormatContext *format, AVStream *st, AVFrame *frame)\n\n{\n\n    AVRational fr = st->r_frame_rate;\n\n    AVRational codec_fr = st->codec->framerate;\n\n    AVRational   avg_fr = st->avg_frame_rate;\n\n\n\n    if (avg_fr.num > 0 && avg_fr.den > 0 && fr.num > 0 && fr.den > 0 &&\n\n        av_q2d(avg_fr) < 70 && av_q2d(fr) > 210) {\n\n        fr = avg_fr;\n\n    }\n\n\n\n\n\n    if (st->codec->ticks_per_frame > 1) {\n\n        if (   codec_fr.num > 0 && codec_fr.den > 0 && av_q2d(codec_fr) < av_q2d(fr)*0.7\n\n            && fabs(1.0 - av_q2d(av_div_q(avg_fr, fr))) > 0.1)\n\n            fr = codec_fr;\n\n    }\n\n\n\n    return fr;\n\n}\n", "idx": 14180, "_split": "valid", "_hash": "9154fbf871e751fc9d74faab6a27d349"}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static void apply_mid_side_stereo(ChannelElement *cpe)\n\n{\n\n    int w, w2, g, i;\n\n    IndividualChannelStream *ics = &cpe->ch[0].ics;\n\n    if (!cpe->common_window)\n\n        return;\n\n    for (w = 0; w < ics->num_windows; w += ics->group_len[w]) {\n\n        for (w2 =  0; w2 < ics->group_len[w]; w2++) {\n\n            int start = (w+w2) * 128;\n\n            for (g = 0; g < ics->num_swb; g++) {\n\n                if (!cpe->ms_mask[w*16 + g]) {\n\n                    start += ics->swb_sizes[g];\n\n                    continue;\n\n                }\n\n                for (i = 0; i < ics->swb_sizes[g]; i++) {\n\n                    float L = (cpe->ch[0].coeffs[start+i] + cpe->ch[1].coeffs[start+i]) * 0.5f;\n\n                    float R = L - cpe->ch[1].coeffs[start+i];\n\n                    cpe->ch[0].coeffs[start+i] = L;\n\n                    cpe->ch[1].coeffs[start+i] = R;\n\n                }\n\n                start += ics->swb_sizes[g];\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 14192, "_split": "valid", "_hash": "1ebb7985aa963207e20c39f4e086e8bc"}
{"project": "FFmpeg", "commit_id": "ab89dbd43e2898c7af99387cfb15fff608b02ab5", "target": 0, "func": "static int ea_read_header(AVFormatContext *s,\n\n                          AVFormatParameters *ap)\n\n{\n\n    EaDemuxContext *ea = s->priv_data;\n\n    AVStream *st;\n\n\n\n    if (!process_ea_header(s))\n\n        return AVERROR(EIO);\n\n\n\n    if (ea->time_base.num && ea->time_base.den) {\n\n        /* initialize the video decoder stream */\n\n        st = av_new_stream(s, 0);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        ea->video_stream_index = st->index;\n\n        st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n        st->codec->codec_id = ea->video_codec;\n\n        st->codec->codec_tag = 0;  /* no fourcc */\n\n        st->codec->time_base = ea->time_base;\n\n    }\n\n\n\n    if (ea->audio_codec) {\n\n        /* initialize the audio decoder stream */\n\n        st = av_new_stream(s, 0);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        av_set_pts_info(st, 33, 1, ea->sample_rate);\n\n        st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n        st->codec->codec_id = ea->audio_codec;\n\n        st->codec->codec_tag = 0;  /* no tag */\n\n        st->codec->channels = ea->num_channels;\n\n        st->codec->sample_rate = ea->sample_rate;\n\n        st->codec->bits_per_sample = ea->bytes * 8;\n\n        st->codec->bit_rate = st->codec->channels * st->codec->sample_rate *\n\n            st->codec->bits_per_sample / 4;\n\n        st->codec->block_align = st->codec->channels*st->codec->bits_per_sample;\n\n        ea->audio_stream_index = st->index;\n\n        ea->audio_frame_counter = 0;\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 14194, "_split": "valid", "_hash": "0cccd21a22074fd55ea136d4a8adf40e"}
{"project": "FFmpeg", "commit_id": "c9ff32215b433d505f251c1f212b1fa0a5e17b73", "target": 0, "func": "static int set_format(void *obj, const char *name, int fmt, int search_flags,\n\n                      enum AVOptionType type, const char *desc, int max)\n\n{\n\n    void *target_obj;\n\n    const AVOption *o = av_opt_find2(obj, name, NULL, 0,\n\n                                     search_flags, &target_obj);\n\n    if (!o || !target_obj)\n\n        return AVERROR_OPTION_NOT_FOUND;\n\n    if (o->type != type) {\n\n        av_log(obj, AV_LOG_ERROR,\n\n               \"The value set by option '%s' is not a %s format\", name, desc);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (fmt < -1 || fmt > max) {\n\n        av_log(obj, AV_LOG_ERROR,\n\n               \"Value %d for parameter '%s' out of %s format range [-1 - %d]\\n\",\n\n               fmt, name, desc, max);\n\n        return AVERROR(ERANGE);\n\n    }\n\n    *(int *)(((uint8_t *)target_obj) + o->offset) = fmt;\n\n    return 0;\n\n}\n", "idx": 14240, "_split": "valid", "_hash": "2abdea712715844d427b3b3312082f4b"}
{"project": "FFmpeg", "commit_id": "a5ef7960fc96ed773acc4149104d6acf534e8a87", "target": 1, "func": "static int ape_read_packet(AVFormatContext * s, AVPacket * pkt)\n\n{\n\n    int ret;\n\n    int nblocks;\n\n    APEContext *ape = s->priv_data;\n\n    uint32_t extra_size = 8;\n\n\n\n    if (url_feof(s->pb))\n\n        return AVERROR_EOF;\n\n    if (ape->currentframe >= ape->totalframes)\n\n        return AVERROR_EOF;\n\n\n\n    if (avio_seek(s->pb, ape->frames[ape->currentframe].pos, SEEK_SET) < 0)\n\n        return AVERROR(EIO);\n\n\n\n    /* Calculate how many blocks there are in this frame */\n\n    if (ape->currentframe == (ape->totalframes - 1))\n\n        nblocks = ape->finalframeblocks;\n\n    else\n\n        nblocks = ape->blocksperframe;\n\n\n\n    if (ape->frames[ape->currentframe].size <= 0 ||\n\n        ape->frames[ape->currentframe].size > INT_MAX - extra_size) {\n\n        av_log(s, AV_LOG_ERROR, \"invalid packet size: %d\\n\",\n\n               ape->frames[ape->currentframe].size);\n\n        ape->currentframe++;\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    if (av_new_packet(pkt,  ape->frames[ape->currentframe].size + extra_size) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    AV_WL32(pkt->data    , nblocks);\n\n    AV_WL32(pkt->data + 4, ape->frames[ape->currentframe].skip);\n\n    ret = avio_read(s->pb, pkt->data + extra_size, ape->frames[ape->currentframe].size);\n\n\n\n\n\n    pkt->pts = ape->frames[ape->currentframe].pts;\n\n    pkt->stream_index = 0;\n\n\n\n    /* note: we need to modify the packet size here to handle the last\n\n       packet */\n\n    pkt->size = ret + extra_size;\n\n\n\n    ape->currentframe++;\n\n\n\n    return 0;\n\n}", "idx": 14254, "_split": "valid", "_hash": "48544aaca3d99036d694ac20651035b4"}
{"project": "FFmpeg", "commit_id": "e91ba2efa949470e9157b652535d207a101f91e0", "target": 0, "func": "static int svq1_decode_frame_header(AVCodecContext *avctx, AVFrame *frame)\n\n{\n\n    SVQ1Context *s = avctx->priv_data;\n\n    GetBitContext *bitbuf = &s->gb;\n\n    int frame_size_code;\n\n    int width  = s->width;\n\n    int height = s->height;\n\n\n\n    skip_bits(bitbuf, 8); /* temporal_reference */\n\n\n\n    /* frame type */\n\n    s->nonref = 0;\n\n    switch (get_bits(bitbuf, 2)) {\n\n    case 0:\n\n        frame->pict_type = AV_PICTURE_TYPE_I;\n\n        break;\n\n    case 2:\n\n        s->nonref = 1;\n\n    case 1:\n\n        frame->pict_type = AV_PICTURE_TYPE_P;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid frame type.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (frame->pict_type == AV_PICTURE_TYPE_I) {\n\n        /* unknown fields */\n\n        if (s->frame_code == 0x50 || s->frame_code == 0x60) {\n\n            int csum = get_bits(bitbuf, 16);\n\n\n\n            csum = ff_svq1_packet_checksum(bitbuf->buffer,\n\n                                           bitbuf->size_in_bits >> 3,\n\n                                           csum);\n\n\n\n            av_dlog(avctx, \"%s checksum (%02x) for packet data\\n\",\n\n                    (csum == 0) ? \"correct\" : \"incorrect\", csum);\n\n        }\n\n\n\n        if ((s->frame_code ^ 0x10) >= 0x50) {\n\n            uint8_t msg[256];\n\n\n\n            svq1_parse_string(bitbuf, msg);\n\n\n\n            av_log(avctx, AV_LOG_INFO,\n\n                   \"embedded message:\\n%s\\n\", (char *)msg);\n\n        }\n\n\n\n        skip_bits(bitbuf, 2);\n\n        skip_bits(bitbuf, 2);\n\n        skip_bits1(bitbuf);\n\n\n\n        /* load frame size */\n\n        frame_size_code = get_bits(bitbuf, 3);\n\n\n\n        if (frame_size_code == 7) {\n\n            /* load width, height (12 bits each) */\n\n            width  = get_bits(bitbuf, 12);\n\n            height = get_bits(bitbuf, 12);\n\n\n\n            if (!width || !height)\n\n                return AVERROR_INVALIDDATA;\n\n        } else {\n\n            /* get width, height from table */\n\n            width  = ff_svq1_frame_size_table[frame_size_code][0];\n\n            height = ff_svq1_frame_size_table[frame_size_code][1];\n\n        }\n\n    }\n\n\n\n    /* unknown fields */\n\n    if (get_bits1(bitbuf)) {\n\n        skip_bits1(bitbuf);    /* use packet checksum if (1) */\n\n        skip_bits1(bitbuf);    /* component checksums after image data if (1) */\n\n\n\n        if (get_bits(bitbuf, 2) != 0)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (get_bits1(bitbuf)) {\n\n        skip_bits1(bitbuf);\n\n        skip_bits(bitbuf, 4);\n\n        skip_bits1(bitbuf);\n\n        skip_bits(bitbuf, 2);\n\n\n\n        if (skip_1stop_8data_bits(bitbuf) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    s->width  = width;\n\n    s->height = height;\n\n    return 0;\n\n}\n", "idx": 14333, "_split": "valid", "_hash": "ba18c089b031f1279fe27c62b9bfd713"}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int64_t ftp_seek(URLContext *h, int64_t pos, int whence)\n\n{\n\n    FTPContext *s = h->priv_data;\n\n    int err;\n\n    int64_t new_pos, fake_pos;\n\n\n\n    av_dlog(h, \"ftp protocol seek %\"PRId64\" %d\\n\", pos, whence);\n\n\n\n    switch(whence) {\n\n    case AVSEEK_SIZE:\n\n        return s->filesize;\n\n    case SEEK_SET:\n\n        new_pos = pos;\n\n        break;\n\n    case SEEK_CUR:\n\n        new_pos = s->position + pos;\n\n        break;\n\n    case SEEK_END:\n\n        if (s->filesize < 0)\n\n            return AVERROR(EIO);\n\n        new_pos = s->filesize + pos;\n\n        break;\n\n    default:\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (h->is_streamed)\n\n        return AVERROR(EIO);\n\n\n\n    if (new_pos < 0) {\n\n        av_log(h, AV_LOG_ERROR, \"Seeking to nagative position.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    fake_pos = s->filesize != -1 ? FFMIN(new_pos, s->filesize) : new_pos;\n\n    if (fake_pos != s->position) {\n\n        if ((err = ftp_abort(h)) < 0)\n\n            return err;\n\n        s->position = fake_pos;\n\n    }\n\n    return new_pos;\n\n}\n", "idx": 14405, "_split": "valid", "_hash": "c1a26b1418fa5dc8708e39aba070b04b"}
{"project": "FFmpeg", "commit_id": "bcaf64b605442e1622d16da89d4ec0e7730b8a8c", "target": 0, "func": "static int encode_superframe(AVCodecContext *avctx, AVPacket *avpkt,\n\n                             const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    WMACodecContext *s = avctx->priv_data;\n\n    int i, total_gain, ret, error;\n\n\n\n    s->block_len_bits= s->frame_len_bits; //required by non variable block len\n\n    s->block_len = 1 << s->block_len_bits;\n\n\n\n    apply_window_and_mdct(avctx, frame);\n\n\n\n    if (s->ms_stereo) {\n\n        float a, b;\n\n        int i;\n\n\n\n        for(i = 0; i < s->block_len; i++) {\n\n            a = s->coefs[0][i]*0.5;\n\n            b = s->coefs[1][i]*0.5;\n\n            s->coefs[0][i] = a + b;\n\n            s->coefs[1][i] = a - b;\n\n        }\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, 2 * MAX_CODED_SUPERFRAME_SIZE)))\n\n        return ret;\n\n\n\n    total_gain= 128;\n\n    for(i=64; i; i>>=1){\n\n        error = encode_frame(s, s->coefs, avpkt->data, avpkt->size,\n\n                                 total_gain - i);\n\n        if(error<=0)\n\n            total_gain-= i;\n\n    }\n\n\n\n    while(total_gain <= 128 && error > 0)\n\n        error = encode_frame(s, s->coefs, avpkt->data, avpkt->size, total_gain++);\n\n    av_assert0((put_bits_count(&s->pb) & 7) == 0);\n\n    i= avctx->block_align - (put_bits_count(&s->pb)+7)/8;\n\n    av_assert0(i>=0);\n\n    while(i--)\n\n        put_bits(&s->pb, 8, 'N');\n\n\n\n    flush_put_bits(&s->pb);\n\n    av_assert0(put_bits_ptr(&s->pb) - s->pb.buf == avctx->block_align);\n\n\n\n    if (frame->pts != AV_NOPTS_VALUE)\n\n        avpkt->pts = frame->pts - ff_samples_to_time_base(avctx, avctx->delay);\n\n\n\n    avpkt->size = avctx->block_align;\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 14427, "_split": "valid", "_hash": "1ebd1b6bb883348af1b4449405ac75dc"}
{"project": "FFmpeg", "commit_id": "8992029fc0a4dd9df16f8cb46cfb641c98fc9f6c", "target": 0, "func": "static int g729_parse(AVCodecParserContext *s1, AVCodecContext *avctx,\n\n                     const uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size)\n\n{\n\n    G729ParseContext *s = s1->priv_data;\n\n    ParseContext *pc = &s->pc;\n\n    int next;\n\n\n\n    if (!s->block_size) {\n\n        switch (avctx->codec_id) {\n\n        case AV_CODEC_ID_G729:\n\n            /* FIXME: replace this heuristic block_size with more precise estimate */\n\n            s->block_size = (avctx->bit_rate < 8000) ? G729D_6K4_BLOCK_SIZE : G729_8K_BLOCK_SIZE;\n\n            s->duration   = avctx->frame_size;\n\n            break;\n\n        default:\n\n            *poutbuf      = buf;\n\n            *poutbuf_size = buf_size;\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid codec_id\\n\");\n\n            return buf_size;\n\n        }\n\n    }\n\n\n\n    if (!s->remaining)\n\n        s->remaining = s->block_size;\n\n    if (s->remaining <= buf_size) {\n\n        next = s->remaining;\n\n        s->remaining = 0;\n\n    } else {\n\n        next = END_NOT_FOUND;\n\n        s->remaining -= buf_size;\n\n    }\n\n\n\n    if (ff_combine_frame(pc, next, &buf, &buf_size) < 0 || !buf_size) {\n\n        *poutbuf      = NULL;\n\n        *poutbuf_size = 0;\n\n        return buf_size;\n\n    }\n\n\n\n    s1->duration = s->duration;\n\n\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return next;\n\n}\n", "idx": 14509, "_split": "valid", "_hash": "a5efd74dd49468013ce72092d862dbdf"}
{"project": "FFmpeg", "commit_id": "72a6244b5d554d7fdfdeb04c174750c7a2c52f83", "target": 0, "func": "static int decode_audio_block(AC3DecodeContext *s, int blk)\n\n{\n\n    int fbw_channels = s->fbw_channels;\n\n    int channel_mode = s->channel_mode;\n\n    int i, bnd, seg, ch;\n\n    int different_transforms;\n\n    int downmix_output;\n\n    int cpl_in_use;\n\n    GetBitContext *gbc = &s->gbc;\n\n    uint8_t bit_alloc_stages[AC3_MAX_CHANNELS];\n\n\n\n    memset(bit_alloc_stages, 0, AC3_MAX_CHANNELS);\n\n\n\n    /* block switch flags */\n\n    different_transforms = 0;\n\n    if (s->block_switch_syntax) {\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->block_switch[ch] = get_bits1(gbc);\n\n            if(ch > 1 && s->block_switch[ch] != s->block_switch[1])\n\n                different_transforms = 1;\n\n        }\n\n    }\n\n\n\n    /* dithering flags */\n\n    if (s->dither_flag_syntax) {\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->dither_flag[ch] = get_bits1(gbc);\n\n        }\n\n    }\n\n\n\n    /* dynamic range */\n\n    i = !(s->channel_mode);\n\n    do {\n\n        if(get_bits1(gbc)) {\n\n            s->dynamic_range[i] = ((dynamic_range_tab[get_bits(gbc, 8)]-1.0) *\n\n                                  s->avctx->drc_scale)+1.0;\n\n        } else if(blk == 0) {\n\n            s->dynamic_range[i] = 1.0f;\n\n        }\n\n    } while(i--);\n\n\n\n    /* spectral extension strategy */\n\n    if (s->eac3 && (!blk || get_bits1(gbc))) {\n\n        if (get_bits1(gbc)) {\n\n            av_log_missing_feature(s->avctx, \"Spectral extension\", 1);\n\n            return -1;\n\n        }\n\n        /* TODO: parse spectral extension strategy info */\n\n    }\n\n\n\n    /* TODO: spectral extension coordinates */\n\n\n\n    /* coupling strategy */\n\n    if (s->eac3 ? s->cpl_strategy_exists[blk] : get_bits1(gbc)) {\n\n        memset(bit_alloc_stages, 3, AC3_MAX_CHANNELS);\n\n        if (!s->eac3)\n\n            s->cpl_in_use[blk] = get_bits1(gbc);\n\n        if (s->cpl_in_use[blk]) {\n\n            /* coupling in use */\n\n            int cpl_start_subband, cpl_end_subband;\n\n\n\n            if (channel_mode < AC3_CHMODE_STEREO) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"coupling not allowed in mono or dual-mono\\n\");\n\n                return -1;\n\n            }\n\n\n\n            /* check for enhanced coupling */\n\n            if (s->eac3 && get_bits1(gbc)) {\n\n                /* TODO: parse enhanced coupling strategy info */\n\n                av_log_missing_feature(s->avctx, \"Enhanced coupling\", 1);\n\n                return -1;\n\n            }\n\n\n\n            /* determine which channels are coupled */\n\n            if (s->eac3 && s->channel_mode == AC3_CHMODE_STEREO) {\n\n                s->channel_in_cpl[1] = 1;\n\n                s->channel_in_cpl[2] = 1;\n\n            } else {\n\n                for (ch = 1; ch <= fbw_channels; ch++)\n\n                    s->channel_in_cpl[ch] = get_bits1(gbc);\n\n            }\n\n\n\n            /* phase flags in use */\n\n            if (channel_mode == AC3_CHMODE_STEREO)\n\n                s->phase_flags_in_use = get_bits1(gbc);\n\n\n\n            /* coupling frequency range */\n\n            /* TODO: modify coupling end freq if spectral extension is used */\n\n            cpl_start_subband = get_bits(gbc, 4);\n\n            cpl_end_subband   = get_bits(gbc, 4) + 3;\n\n            s->num_cpl_subbands = cpl_end_subband - cpl_start_subband;\n\n            if (s->num_cpl_subbands < 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"invalid coupling range (%d > %d)\\n\",\n\n                       cpl_start_subband, cpl_end_subband);\n\n                return -1;\n\n            }\n\n            s->start_freq[CPL_CH] = cpl_start_subband * 12 + 37;\n\n            s->end_freq[CPL_CH]   = cpl_end_subband   * 12 + 37;\n\n\n\n           decode_band_structure(gbc, blk, s->eac3, 0,\n\n                                 cpl_start_subband, cpl_end_subband,\n\n                                 ff_eac3_default_cpl_band_struct,\n\n                                 s->cpl_band_struct, &s->num_cpl_subbands,\n\n                                 &s->num_cpl_bands, NULL);\n\n        } else {\n\n            /* coupling not in use */\n\n            for (ch = 1; ch <= fbw_channels; ch++) {\n\n                s->channel_in_cpl[ch] = 0;\n\n                s->first_cpl_coords[ch] = 1;\n\n            }\n\n            s->first_cpl_leak = s->eac3;\n\n            s->phase_flags_in_use = 0;\n\n        }\n\n    } else if (!s->eac3) {\n\n        if(!blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new coupling strategy must be present in block 0\\n\");\n\n            return -1;\n\n        } else {\n\n            s->cpl_in_use[blk] = s->cpl_in_use[blk-1];\n\n        }\n\n    }\n\n    cpl_in_use = s->cpl_in_use[blk];\n\n\n\n    /* coupling coordinates */\n\n    if (cpl_in_use) {\n\n        int cpl_coords_exist = 0;\n\n\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            if (s->channel_in_cpl[ch]) {\n\n                if ((s->eac3 && s->first_cpl_coords[ch]) || get_bits1(gbc)) {\n\n                    int master_cpl_coord, cpl_coord_exp, cpl_coord_mant;\n\n                    s->first_cpl_coords[ch] = 0;\n\n                    cpl_coords_exist = 1;\n\n                    master_cpl_coord = 3 * get_bits(gbc, 2);\n\n                    for (bnd = 0; bnd < s->num_cpl_bands; bnd++) {\n\n                        cpl_coord_exp = get_bits(gbc, 4);\n\n                        cpl_coord_mant = get_bits(gbc, 4);\n\n                        if (cpl_coord_exp == 15)\n\n                            s->cpl_coords[ch][bnd] = cpl_coord_mant << 22;\n\n                        else\n\n                            s->cpl_coords[ch][bnd] = (cpl_coord_mant + 16) << 21;\n\n                        s->cpl_coords[ch][bnd] >>= (cpl_coord_exp + master_cpl_coord);\n\n                    }\n\n                } else if (!blk) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"new coupling coordinates must be present in block 0\\n\");\n\n                    return -1;\n\n                }\n\n            } else {\n\n                /* channel not in coupling */\n\n                s->first_cpl_coords[ch] = 1;\n\n            }\n\n        }\n\n        /* phase flags */\n\n        if (channel_mode == AC3_CHMODE_STEREO && cpl_coords_exist) {\n\n            for (bnd = 0; bnd < s->num_cpl_bands; bnd++) {\n\n                s->phase_flags[bnd] = s->phase_flags_in_use? get_bits1(gbc) : 0;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* stereo rematrixing strategy and band structure */\n\n    if (channel_mode == AC3_CHMODE_STEREO) {\n\n        if ((s->eac3 && !blk) || get_bits1(gbc)) {\n\n            s->num_rematrixing_bands = 4;\n\n            if(cpl_in_use && s->start_freq[CPL_CH] <= 61)\n\n                s->num_rematrixing_bands -= 1 + (s->start_freq[CPL_CH] == 37);\n\n            for(bnd=0; bnd<s->num_rematrixing_bands; bnd++)\n\n                s->rematrixing_flags[bnd] = get_bits1(gbc);\n\n        } else if (!blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new rematrixing strategy must be present in block 0\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    /* exponent strategies for each channel */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (!s->eac3)\n\n            s->exp_strategy[blk][ch] = get_bits(gbc, 2 - (ch == s->lfe_ch));\n\n        if(s->exp_strategy[blk][ch] != EXP_REUSE)\n\n            bit_alloc_stages[ch] = 3;\n\n    }\n\n\n\n    /* channel bandwidth */\n\n    for (ch = 1; ch <= fbw_channels; ch++) {\n\n        s->start_freq[ch] = 0;\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE) {\n\n            int group_size;\n\n            int prev = s->end_freq[ch];\n\n            if (s->channel_in_cpl[ch])\n\n                s->end_freq[ch] = s->start_freq[CPL_CH];\n\n            else {\n\n                int bandwidth_code = get_bits(gbc, 6);\n\n                if (bandwidth_code > 60) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"bandwidth code = %d > 60\\n\", bandwidth_code);\n\n                    return -1;\n\n                }\n\n                s->end_freq[ch] = bandwidth_code * 3 + 73;\n\n            }\n\n            group_size = 3 << (s->exp_strategy[blk][ch] - 1);\n\n            s->num_exp_groups[ch] = (s->end_freq[ch]+group_size-4) / group_size;\n\n            if(blk > 0 && s->end_freq[ch] != prev)\n\n                memset(bit_alloc_stages, 3, AC3_MAX_CHANNELS);\n\n        }\n\n    }\n\n    if (cpl_in_use && s->exp_strategy[blk][CPL_CH] != EXP_REUSE) {\n\n        s->num_exp_groups[CPL_CH] = (s->end_freq[CPL_CH] - s->start_freq[CPL_CH]) /\n\n                                    (3 << (s->exp_strategy[blk][CPL_CH] - 1));\n\n    }\n\n\n\n    /* decode exponents for each channel */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE) {\n\n            s->dexps[ch][0] = get_bits(gbc, 4) << !ch;\n\n            if (decode_exponents(gbc, s->exp_strategy[blk][ch],\n\n                                 s->num_exp_groups[ch], s->dexps[ch][0],\n\n                                 &s->dexps[ch][s->start_freq[ch]+!!ch])) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"exponent out-of-range\\n\");\n\n                return -1;\n\n            }\n\n            if(ch != CPL_CH && ch != s->lfe_ch)\n\n                skip_bits(gbc, 2); /* skip gainrng */\n\n        }\n\n    }\n\n\n\n    /* bit allocation information */\n\n    if (s->bit_allocation_syntax) {\n\n        if (get_bits1(gbc)) {\n\n            s->bit_alloc_params.slow_decay = ff_ac3_slow_decay_tab[get_bits(gbc, 2)] >> s->bit_alloc_params.sr_shift;\n\n            s->bit_alloc_params.fast_decay = ff_ac3_fast_decay_tab[get_bits(gbc, 2)] >> s->bit_alloc_params.sr_shift;\n\n            s->bit_alloc_params.slow_gain  = ff_ac3_slow_gain_tab[get_bits(gbc, 2)];\n\n            s->bit_alloc_params.db_per_bit = ff_ac3_db_per_bit_tab[get_bits(gbc, 2)];\n\n            s->bit_alloc_params.floor  = ff_ac3_floor_tab[get_bits(gbc, 3)];\n\n            for(ch=!cpl_in_use; ch<=s->channels; ch++)\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        } else if (!blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new bit allocation info must be present in block 0\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    /* signal-to-noise ratio offsets and fast gains (signal-to-mask ratios) */\n\n    if(!s->eac3 || !blk){\n\n        if(s->snr_offset_strategy && get_bits1(gbc)) {\n\n            int snr = 0;\n\n            int csnr;\n\n            csnr = (get_bits(gbc, 6) - 15) << 4;\n\n            for (i = ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n                /* snr offset */\n\n                if (ch == i || s->snr_offset_strategy == 2)\n\n                    snr = (csnr + get_bits(gbc, 4)) << 2;\n\n                /* run at least last bit allocation stage if snr offset changes */\n\n                if(blk && s->snr_offset[ch] != snr) {\n\n                    bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 1);\n\n                }\n\n                s->snr_offset[ch] = snr;\n\n\n\n                /* fast gain (normal AC-3 only) */\n\n                if (!s->eac3) {\n\n                    int prev = s->fast_gain[ch];\n\n                    s->fast_gain[ch] = ff_ac3_fast_gain_tab[get_bits(gbc, 3)];\n\n                    /* run last 2 bit allocation stages if fast gain changes */\n\n                    if(blk && prev != s->fast_gain[ch])\n\n                        bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n                }\n\n            }\n\n        } else if (!s->eac3 && !blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new snr offsets must be present in block 0\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    /* fast gain (E-AC-3 only) */\n\n    if (s->fast_gain_syntax && get_bits1(gbc)) {\n\n        for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n            int prev = s->fast_gain[ch];\n\n            s->fast_gain[ch] = ff_ac3_fast_gain_tab[get_bits(gbc, 3)];\n\n            /* run last 2 bit allocation stages if fast gain changes */\n\n            if(blk && prev != s->fast_gain[ch])\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        }\n\n    } else if (s->eac3 && !blk) {\n\n        for (ch = !cpl_in_use; ch <= s->channels; ch++)\n\n            s->fast_gain[ch] = ff_ac3_fast_gain_tab[4];\n\n    }\n\n\n\n    /* E-AC-3 to AC-3 converter SNR offset */\n\n    if (s->frame_type == EAC3_FRAME_TYPE_INDEPENDENT && get_bits1(gbc)) {\n\n        skip_bits(gbc, 10); // skip converter snr offset\n\n    }\n\n\n\n    /* coupling leak information */\n\n    if (cpl_in_use) {\n\n        if (s->first_cpl_leak || get_bits1(gbc)) {\n\n            int fl = get_bits(gbc, 3);\n\n            int sl = get_bits(gbc, 3);\n\n            /* run last 2 bit allocation stages for coupling channel if\n\n               coupling leak changes */\n\n            if(blk && (fl != s->bit_alloc_params.cpl_fast_leak ||\n\n                       sl != s->bit_alloc_params.cpl_slow_leak)) {\n\n                bit_alloc_stages[CPL_CH] = FFMAX(bit_alloc_stages[CPL_CH], 2);\n\n            }\n\n            s->bit_alloc_params.cpl_fast_leak = fl;\n\n            s->bit_alloc_params.cpl_slow_leak = sl;\n\n        } else if (!s->eac3 && !blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new coupling leak info must be present in block 0\\n\");\n\n            return -1;\n\n        }\n\n        s->first_cpl_leak = 0;\n\n    }\n\n\n\n    /* delta bit allocation information */\n\n    if (s->dba_syntax && get_bits1(gbc)) {\n\n        /* delta bit allocation exists (strategy) */\n\n        for (ch = !cpl_in_use; ch <= fbw_channels; ch++) {\n\n            s->dba_mode[ch] = get_bits(gbc, 2);\n\n            if (s->dba_mode[ch] == DBA_RESERVED) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"delta bit allocation strategy reserved\\n\");\n\n                return -1;\n\n            }\n\n            bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        }\n\n        /* channel delta offset, len and bit allocation */\n\n        for (ch = !cpl_in_use; ch <= fbw_channels; ch++) {\n\n            if (s->dba_mode[ch] == DBA_NEW) {\n\n                s->dba_nsegs[ch] = get_bits(gbc, 3);\n\n                for (seg = 0; seg <= s->dba_nsegs[ch]; seg++) {\n\n                    s->dba_offsets[ch][seg] = get_bits(gbc, 5);\n\n                    s->dba_lengths[ch][seg] = get_bits(gbc, 4);\n\n                    s->dba_values[ch][seg] = get_bits(gbc, 3);\n\n                }\n\n                /* run last 2 bit allocation stages if new dba values */\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n            }\n\n        }\n\n    } else if(blk == 0) {\n\n        for(ch=0; ch<=s->channels; ch++) {\n\n            s->dba_mode[ch] = DBA_NONE;\n\n        }\n\n    }\n\n\n\n    /* Bit allocation */\n\n    for(ch=!cpl_in_use; ch<=s->channels; ch++) {\n\n        if(bit_alloc_stages[ch] > 2) {\n\n            /* Exponent mapping into PSD and PSD integration */\n\n            ff_ac3_bit_alloc_calc_psd(s->dexps[ch],\n\n                                      s->start_freq[ch], s->end_freq[ch],\n\n                                      s->psd[ch], s->band_psd[ch]);\n\n        }\n\n        if(bit_alloc_stages[ch] > 1) {\n\n            /* Compute excitation function, Compute masking curve, and\n\n               Apply delta bit allocation */\n\n            ff_ac3_bit_alloc_calc_mask(&s->bit_alloc_params, s->band_psd[ch],\n\n                                       s->start_freq[ch], s->end_freq[ch],\n\n                                       s->fast_gain[ch], (ch == s->lfe_ch),\n\n                                       s->dba_mode[ch], s->dba_nsegs[ch],\n\n                                       s->dba_offsets[ch], s->dba_lengths[ch],\n\n                                       s->dba_values[ch], s->mask[ch]);\n\n        }\n\n        if(bit_alloc_stages[ch] > 0) {\n\n            /* Compute bit allocation */\n\n            const uint8_t *bap_tab = s->channel_uses_aht[ch] ?\n\n                                     ff_eac3_hebap_tab : ff_ac3_bap_tab;\n\n            ff_ac3_bit_alloc_calc_bap(s->mask[ch], s->psd[ch],\n\n                                      s->start_freq[ch], s->end_freq[ch],\n\n                                      s->snr_offset[ch],\n\n                                      s->bit_alloc_params.floor,\n\n                                      bap_tab, s->bap[ch]);\n\n        }\n\n    }\n\n\n\n    /* unused dummy data */\n\n    if (s->skip_syntax && get_bits1(gbc)) {\n\n        int skipl = get_bits(gbc, 9);\n\n        while(skipl--)\n\n            skip_bits(gbc, 8);\n\n    }\n\n\n\n    /* unpack the transform coefficients\n\n       this also uncouples channels if coupling is in use. */\n\n    decode_transform_coeffs(s, blk);\n\n\n\n    /* TODO: generate enhanced coupling coordinates and uncouple */\n\n\n\n    /* TODO: apply spectral extension */\n\n\n\n    /* recover coefficients if rematrixing is in use */\n\n    if(s->channel_mode == AC3_CHMODE_STEREO)\n\n        do_rematrixing(s);\n\n\n\n    /* apply scaling to coefficients (headroom, dynrng) */\n\n    for(ch=1; ch<=s->channels; ch++) {\n\n        float gain = s->mul_bias / 4194304.0f;\n\n        if(s->channel_mode == AC3_CHMODE_DUALMONO) {\n\n            gain *= s->dynamic_range[ch-1];\n\n        } else {\n\n            gain *= s->dynamic_range[0];\n\n        }\n\n        s->dsp.int32_to_float_fmul_scalar(s->transform_coeffs[ch], s->fixed_coeffs[ch], gain, 256);\n\n    }\n\n\n\n    /* downmix and MDCT. order depends on whether block switching is used for\n\n       any channel in this block. this is because coefficients for the long\n\n       and short transforms cannot be mixed. */\n\n    downmix_output = s->channels != s->out_channels &&\n\n                     !((s->output_mode & AC3_OUTPUT_LFEON) &&\n\n                     s->fbw_channels == s->out_channels);\n\n    if(different_transforms) {\n\n        /* the delay samples have already been downmixed, so we upmix the delay\n\n           samples in order to reconstruct all channels before downmixing. */\n\n        if(s->downmixed) {\n\n            s->downmixed = 0;\n\n            ac3_upmix_delay(s);\n\n        }\n\n\n\n        do_imdct(s, s->channels);\n\n\n\n        if(downmix_output) {\n\n            s->dsp.ac3_downmix(s->output, s->downmix_coeffs, s->out_channels, s->fbw_channels, 256);\n\n        }\n\n    } else {\n\n        if(downmix_output) {\n\n            s->dsp.ac3_downmix(s->transform_coeffs+1, s->downmix_coeffs, s->out_channels, s->fbw_channels, 256);\n\n        }\n\n\n\n        if(downmix_output && !s->downmixed) {\n\n            s->downmixed = 1;\n\n            s->dsp.ac3_downmix(s->delay, s->downmix_coeffs, s->out_channels, s->fbw_channels, 128);\n\n        }\n\n\n\n        do_imdct(s, s->out_channels);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 14535, "_split": "valid", "_hash": "4f13a6a0144d6ed81f67ecf955dd9df5"}
{"project": "FFmpeg", "commit_id": "179308768a8742d215eb8450f0718dc2ee8ea133", "target": 0, "func": "static int mxf_write_header_metadata_sets(AVFormatContext *s)\n\n{\n\n    AVStream *st;\n\n    MXFStreamContext *sc = NULL;\n\n    int i;\n\n\n\n    mxf_write_preface(s);\n\n    mxf_write_identification(s);\n\n    mxf_write_content_storage(s);\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        st = s->streams[i];\n\n        sc = av_mallocz(sizeof(MXFStreamContext));\n\n        if (!sc)\n\n            return AVERROR(ENOMEM);\n\n        st->priv_data = sc;\n\n        // set pts information\n\n        if (st->codec->codec_type == CODEC_TYPE_VIDEO)\n\n            av_set_pts_info(st, 64, 1, st->codec->time_base.den);\n\n        else if (st->codec->codec_type == CODEC_TYPE_AUDIO)\n\n            av_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n    }\n\n\n\n    mxf_build_structural_metadata(s, MaterialPackage);\n\n    mxf_build_structural_metadata(s, SourcePackage);\n\n    return 0;\n\n}\n", "idx": 14611, "_split": "valid", "_hash": "eb5ae8341bcbdb3cc7323af8ca5cd9fc"}
{"project": "FFmpeg", "commit_id": "57d77b3963ce1023eaf5ada8cba58b9379405cc8", "target": 0, "func": "int av_opencl_buffer_write_image(cl_mem dst_cl_buf, size_t cl_buffer_size, int dst_cl_offset,\n\n                                                    uint8_t **src_data, int *plane_size, int plane_num)\n\n{\n\n    int i, buffer_size = 0;\n\n    uint8_t *temp;\n\n    cl_int status;\n\n    void *mapped;\n\n    if ((unsigned int)plane_num > 8) {\n\n        return AVERROR(EINVAL);\n\n    }\n\n    for (i = 0;i < plane_num;i++) {\n\n        buffer_size += plane_size[i];\n\n    }\n\n    if (buffer_size > cl_buffer_size) {\n\n        av_log(&openclutils, AV_LOG_ERROR, \"Cannot write image to OpenCL buffer: buffer too small\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    mapped = clEnqueueMapBuffer(gpu_env.command_queue, dst_cl_buf,\n\n                                      CL_TRUE,CL_MAP_WRITE, 0, buffer_size + dst_cl_offset,\n\n                                      0, NULL, NULL, &status);\n\n    if (status != CL_SUCCESS) {\n\n        av_log(&openclutils, AV_LOG_ERROR, \"Could not map OpenCL buffer: %s\\n\", opencl_errstr(status));\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n    temp = mapped;\n\n    temp += dst_cl_offset;\n\n    for (i = 0; i < plane_num; i++) {\n\n        memcpy(temp, src_data[i], plane_size[i]);\n\n        temp += plane_size[i];\n\n    }\n\n    status = clEnqueueUnmapMemObject(gpu_env.command_queue, dst_cl_buf, mapped, 0, NULL, NULL);\n\n    if (status != CL_SUCCESS) {\n\n        av_log(&openclutils, AV_LOG_ERROR, \"Could not unmap OpenCL buffer: %s\\n\", opencl_errstr(status));\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n    return 0;\n\n}\n", "idx": 14622, "_split": "valid", "_hash": "2e06870a1d6b3bafbb2f672794898987"}
{"project": "FFmpeg", "commit_id": "24e7a22e1fda8b5b18307a35f0511e659de76389", "target": 1, "func": "int ff_get_wav_header(AVIOContext *pb, AVCodecContext *codec, int size)\n\n{\n\n    int id;\n\n\n\n    id = avio_rl16(pb);\n\n    codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    codec->channels = avio_rl16(pb);\n\n    codec->sample_rate = avio_rl32(pb);\n\n    codec->bit_rate = avio_rl32(pb) * 8;\n\n    codec->block_align = avio_rl16(pb);\n\n    if (size == 14) {  /* We're dealing with plain vanilla WAVEFORMAT */\n\n        codec->bits_per_coded_sample = 8;\n\n    }else\n\n        codec->bits_per_coded_sample = avio_rl16(pb);\n\n    if (id == 0xFFFE) {\n\n        codec->codec_tag = 0;\n\n    } else {\n\n        codec->codec_tag = id;\n\n        codec->codec_id = ff_wav_codec_get_id(id, codec->bits_per_coded_sample);\n\n    }\n\n    if (size >= 18) {  /* We're obviously dealing with WAVEFORMATEX */\n\n        int cbSize = avio_rl16(pb); /* cbSize */\n\n        size -= 18;\n\n        cbSize = FFMIN(size, cbSize);\n\n        if (cbSize >= 22 && id == 0xfffe) { /* WAVEFORMATEXTENSIBLE */\n\n            ff_asf_guid subformat;\n\n            codec->bits_per_coded_sample = avio_rl16(pb);\n\n            codec->channel_layout = avio_rl32(pb); /* dwChannelMask */\n\n            ff_get_guid(pb, &subformat);\n\n            if (!memcmp(subformat + 4, (const uint8_t[]){FF_MEDIASUBTYPE_BASE_GUID}, 12)) {\n\n                codec->codec_tag = AV_RL32(subformat);\n\n                codec->codec_id = ff_wav_codec_get_id(codec->codec_tag, codec->bits_per_coded_sample);\n\n            } else {\n\n                codec->codec_id = ff_codec_guid_get_id(ff_codec_wav_guids, subformat);\n\n                if (!codec->codec_id)\n\n                    av_log(codec, AV_LOG_WARNING, \"unknown subformat:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(subformat));\n\n            }\n\n            cbSize -= 22;\n\n            size -= 22;\n\n        }\n\n        codec->extradata_size = cbSize;\n\n        if (cbSize > 0) {\n\n            av_free(codec->extradata);\n\n            codec->extradata = av_mallocz(codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!codec->extradata)\n\n                return AVERROR(ENOMEM);\n\n            avio_read(pb, codec->extradata, codec->extradata_size);\n\n            size -= cbSize;\n\n        }\n\n\n\n        /* It is possible for the chunk to contain garbage at the end */\n\n        if (size > 0)\n\n            avio_skip(pb, size);\n\n    }\n\n    if (codec->codec_id == CODEC_ID_AAC_LATM) {\n\n        /* channels and sample_rate values are those prior to applying SBR and/or PS */\n\n        codec->channels    = 0;\n\n        codec->sample_rate = 0;\n\n    }\n\n    /* override bits_per_coded_sample for G.726 */\n\n    if (codec->codec_id == CODEC_ID_ADPCM_G726)\n\n        codec->bits_per_coded_sample = codec->bit_rate / codec->sample_rate;\n\n\n\n    return 0;\n\n}\n", "idx": 14624, "_split": "valid", "_hash": "7051f3201e7ec27e4eca3d8dc0969d12"}
{"project": "FFmpeg", "commit_id": "5bc223b15d064e328ff90b0241fa1191f1d2786d", "target": 1, "func": "static int r3d_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    R3DContext *r3d = s->priv_data;\n\n    Atom atom;\n\n    int err = 0;\n\n\n\n    while (!err) {\n\n        if (read_atom(s, &atom) < 0) {\n\n            err = -1;\n\n            break;\n\n        }\n\n        switch (atom.tag) {\n\n        case MKTAG('R','E','D','V'):\n\n            if (s->streams[0]->discard == AVDISCARD_ALL)\n\n                goto skip;\n\n            if (!(err = r3d_read_redv(s, pkt, &atom)))\n\n                return 0;\n\n            break;\n\n        case MKTAG('R','E','D','A'):\n\n            if (!r3d->audio_channels)\n\n                return -1;\n\n            if (s->streams[1]->discard == AVDISCARD_ALL)\n\n                goto skip;\n\n            if (!(err = r3d_read_reda(s, pkt, &atom)))\n\n                return 0;\n\n            break;\n\n        default:\n\n        skip:\n\n            avio_skip(s->pb, atom.size-8);\n\n        }\n\n    }\n\n    return err;\n\n}\n", "idx": 14630, "_split": "valid", "_hash": "3d01dde01980b2c3b57d353e8d9ca238"}
{"project": "FFmpeg", "commit_id": "3518925a9127e368b6d0c7e8fd86510d34af40a1", "target": 1, "func": "static int mov_create_timecode_track(AVFormatContext *s, int index, int src_index, const char *tcstr)\n\n{\n\n    int ret;\n\n    MOVMuxContext *mov  = s->priv_data;\n\n    MOVTrack *track     = &mov->tracks[index];\n\n    AVStream *src_st    = s->streams[src_index];\n\n    AVTimecode tc;\n\n    AVPacket pkt    = {.stream_index = index, .flags = AV_PKT_FLAG_KEY, .size = 4};\n\n    AVRational rate = find_fps(s, src_st);\n\n\n\n    /* compute the frame number */\n\n    ret = av_timecode_init_from_string(&tc, rate, tcstr, s);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* tmcd track based on video stream */\n\n    track->mode      = mov->mode;\n\n    track->tag       = MKTAG('t','m','c','d');\n\n    track->src_track = src_index;\n\n    track->timescale = mov->tracks[src_index].timescale;\n\n    if (tc.flags & AV_TIMECODE_FLAG_DROPFRAME)\n\n        track->timecode_flags |= MOV_TIMECODE_FLAG_DROPFRAME;\n\n\n\n    /* set st to src_st for metadata access*/\n\n    track->st = src_st;\n\n\n\n    /* encode context: tmcd data stream */\n\n    track->enc = avcodec_alloc_context3(NULL);\n\n\n\n    track->enc->codec_type = AVMEDIA_TYPE_DATA;\n\n    track->enc->codec_tag  = track->tag;\n\n    track->enc->time_base  = av_inv_q(rate);\n\n\n\n    /* the tmcd track just contains one packet with the frame number */\n\n    pkt.data = av_malloc(pkt.size);\n\n\n\n    AV_WB32(pkt.data, tc.start);\n\n    ret = ff_mov_write_packet(s, &pkt);\n\n    av_free(pkt.data);\n\n    return ret;\n\n}", "idx": 14653, "_split": "valid", "_hash": "092cf16add2dfc5829a584d49683e8b7"}
{"project": "FFmpeg", "commit_id": "956472a3236cc8eaeba5147c55b51bde6005c898", "target": 1, "func": "static int rv40_decode_intra_types(RV34DecContext *r, GetBitContext *gb, int8_t *dst)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    int i, j, k, v;\n\n    int A, B, C;\n\n    int pattern;\n\n    int8_t *ptr;\n\n\n\n    for(i = 0; i < 4; i++, dst += r->intra_types_stride){\n\n        if(!i && s->first_slice_line){\n\n            pattern = get_vlc2(gb, aic_top_vlc.table, AIC_TOP_BITS, 1);\n\n            dst[0] = (pattern >> 2) & 2;\n\n            dst[1] = (pattern >> 1) & 2;\n\n            dst[2] =  pattern       & 2;\n\n            dst[3] = (pattern << 1) & 2;\n\n            continue;\n\n        }\n\n        ptr = dst;\n\n        for(j = 0; j < 4; j++){\n\n            /* Coefficients are read using VLC chosen by the prediction pattern\n\n             * The first one (used for retrieving a pair of coefficients) is\n\n             * constructed from the top, top right and left coefficients\n\n             * The second one (used for retrieving only one coefficient) is\n\n             * top + 10 * left.\n\n             */\n\n            A = ptr[-r->intra_types_stride + 1]; // it won't be used for the last coefficient in a row\n\n            B = ptr[-r->intra_types_stride];\n\n            C = ptr[-1];\n\n            pattern = A + (B << 4) + (C << 8);\n\n            for(k = 0; k < MODE2_PATTERNS_NUM; k++)\n\n                if(pattern == rv40_aic_table_index[k])\n\n                    break;\n\n            if(j < 3 && k < MODE2_PATTERNS_NUM){ //pattern is found, decoding 2 coefficients\n\n                v = get_vlc2(gb, aic_mode2_vlc[k].table, AIC_MODE2_BITS, 2);\n\n                *ptr++ = v/9;\n\n                *ptr++ = v%9;\n\n                j++;\n\n            }else{\n\n                if(B != -1 && C != -1)\n\n                    v = get_vlc2(gb, aic_mode1_vlc[B + C*10].table, AIC_MODE1_BITS, 1);\n\n                else{ // tricky decoding\n\n                    v = 0;\n\n                    switch(C){\n\n                    case -1: // code 0 -> 1, 1 -> 0\n\n                        if(B < 2)\n\n                            v = get_bits1(gb) ^ 1;\n\n                        break;\n\n                    case  0:\n\n                    case  2: // code 0 -> 2, 1 -> 0\n\n                        v = (get_bits1(gb) ^ 1) << 1;\n\n                        break;\n\n                    }\n\n                }\n\n                *ptr++ = v;\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 14657, "_split": "valid", "_hash": "6dc780308aa2eaad2827ba28e7276f5f"}
{"project": "FFmpeg", "commit_id": "34b16e2d364cf86960eac09e451dae6ae8792e08", "target": 1, "func": "static int update_wrap_reference(AVFormatContext *s, AVStream *st, int stream_index, AVPacket *pkt)\n\n{\n\n    int64_t ref = pkt->dts;\n\n\n\n    if (ref == AV_NOPTS_VALUE)\n\n        ref = pkt->pts;\n\n    if (ref == AV_NOPTS_VALUE)\n\n        return 0;\n\n    ref &= (1LL<<st->pts_wrap_bits)-1;\n\n\n\n    if (s->correct_ts_overflow && st->pts_wrap_bits < 63 &&\n\n        st->pts_wrap_reference == AV_NOPTS_VALUE) {\n\n        int i;\n\n\n\n        // reference time stamp should be 60 s before first time stamp\n\n        int64_t pts_wrap_reference = ref - av_rescale(60, st->time_base.den, st->time_base.num);\n\n        // if first time stamp is not more than 1/8 and 60s before the wrap point, subtract rather than add wrap offset\n\n        int pts_wrap_behavior = (ref < (1LL<<st->pts_wrap_bits) - (1LL<<st->pts_wrap_bits-3)) ||\n\n            (ref < (1LL<<st->pts_wrap_bits) - av_rescale(60, st->time_base.den, st->time_base.num)) ?\n\n            AV_PTS_WRAP_ADD_OFFSET : AV_PTS_WRAP_SUB_OFFSET;\n\n\n\n        AVProgram *first_program = av_find_program_from_stream(s, NULL, stream_index);\n\n\n\n        if (!first_program) {\n\n            int default_stream_index = av_find_default_stream_index(s);\n\n            if (s->streams[default_stream_index]->pts_wrap_reference == AV_NOPTS_VALUE) {\n\n                for (i=0; i<s->nb_streams; i++) {\n\n                    s->streams[i]->pts_wrap_reference = pts_wrap_reference;\n\n                    s->streams[i]->pts_wrap_behavior = pts_wrap_behavior;\n\n                }\n\n            }\n\n            else {\n\n                st->pts_wrap_reference = s->streams[default_stream_index]->pts_wrap_reference;\n\n                st->pts_wrap_behavior = s->streams[default_stream_index]->pts_wrap_behavior;\n\n            }\n\n        }\n\n        else {\n\n            AVProgram *program = first_program;\n\n            while (program) {\n\n                if (program->pts_wrap_reference != AV_NOPTS_VALUE) {\n\n                    pts_wrap_reference = program->pts_wrap_reference;\n\n                    pts_wrap_behavior = program->pts_wrap_behavior;\n\n                    break;\n\n                }\n\n                program = av_find_program_from_stream(s, program, stream_index);\n\n            }\n\n\n\n            // update every program with differing pts_wrap_reference\n\n            program = first_program;\n\n            while(program) {\n\n                if (program->pts_wrap_reference != pts_wrap_reference) {\n\n                    for (i=0; i<program->nb_stream_indexes; i++) {\n\n                        s->streams[program->stream_index[i]]->pts_wrap_reference = pts_wrap_reference;\n\n                        s->streams[program->stream_index[i]]->pts_wrap_behavior = pts_wrap_behavior;\n\n                    }\n\n\n\n                    program->pts_wrap_reference = pts_wrap_reference;\n\n                    program->pts_wrap_behavior = pts_wrap_behavior;\n\n                }\n\n                program = av_find_program_from_stream(s, program, stream_index);\n\n            }\n\n        }\n\n        return 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 14671, "_split": "valid", "_hash": "30d5facbc26e28ea223c7369d24d2f00"}
{"project": "FFmpeg", "commit_id": "28bf81c90d36a55cf76e2be913c5215ebebf61f2", "target": 1, "func": "void SwScale_YV12slice(unsigned char* srcptr[],int stride[], int srcSliceY ,\n\n\t\t\t     int srcSliceH, uint8_t* dstptr[], int dststride, int dstbpp,\n\n\t\t\t     int srcW, int srcH, int dstW, int dstH){\n\n\n\n#ifdef RUNTIME_CPUDETECT\n\n#ifdef CAN_COMPILE_X86_ASM\n\n\t// ordered per speed fasterst first\n\n\tif(gCpuCaps.hasMMX2)\n\n\t\tSwScale_YV12slice_MMX2(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n\telse if(gCpuCaps.has3DNow)\n\n\t\tSwScale_YV12slice_3DNow(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n\telse if(gCpuCaps.hasMMX)\n\n\t\tSwScale_YV12slice_MMX(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n\telse\n\n\t\tSwScale_YV12slice_C(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n#else\n\n\t\tSwScale_YV12slice_C(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n#endif\n\n#else //RUNTIME_CPUDETECT\n\n#ifdef HAVE_MMX2\n\n\t\tSwScale_YV12slice_MMX2(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n#elif defined (HAVE_3DNOW)\n\n\t\tSwScale_YV12slice_3DNow(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n#elif defined (HAVE_MMX)\n\n\t\tSwScale_YV12slice_MMX(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n#else\n\n\t\tSwScale_YV12slice_C(srcptr, stride, srcSliceY, srcSliceH, dstptr, dststride, dstbpp, srcW, srcH, dstW, dstH);\n\n#endif\n\n#endif //!RUNTIME_CPUDETECT\n\n\n\n}\n", "idx": 14688, "_split": "valid", "_hash": "783e3032584d78e99020c42645fc1991"}
{"project": "FFmpeg", "commit_id": "3c8c94b403977eb7c65a07081b55cc9bc5005ced", "target": 1, "func": "static int flic_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    FlicDecodeContext *s = (FlicDecodeContext *)avctx->priv_data;\n\n\n\n    int stream_ptr = 0;\n\n    int stream_ptr_after_color_chunk;\n\n    int pixel_ptr;\n\n    int palette_ptr;\n\n    unsigned char palette_idx1;\n\n    unsigned char palette_idx2;\n\n\n\n    unsigned int frame_size;\n\n    int num_chunks;\n\n\n\n    unsigned int chunk_size;\n\n    int chunk_type;\n\n\n\n    int i, j;\n\n\n\n    int color_packets;\n\n    int color_changes;\n\n    int color_shift;\n\n    unsigned char r, g, b;\n\n\n\n    int lines;\n\n    int compressed_lines;\n\n    int starting_line;\n\n    signed short line_packets;\n\n    int y_ptr;\n\n    signed char byte_run;\n\n    int pixel_skip;\n\n    int pixel_countdown;\n\n    unsigned char *pixels;\n\n    int pixel_limit;\n\n\n\n    s->frame.reference = 1;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pixels = s->frame.data[0];\n\n    pixel_limit = s->avctx->height * s->frame.linesize[0];\n\n\n\n    frame_size = LE_32(&buf[stream_ptr]);\n\n    stream_ptr += 6;  /* skip the magic number */\n\n    num_chunks = LE_16(&buf[stream_ptr]);\n\n    stream_ptr += 10;  /* skip padding */\n\n\n\n    frame_size -= 16;\n\n\n\n    /* iterate through the chunks */\n\n    while ((frame_size > 0) && (num_chunks > 0)) {\n\n        chunk_size = LE_32(&buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n        chunk_type = LE_16(&buf[stream_ptr]);\n\n        stream_ptr += 2;\n\n\n\n        switch (chunk_type) {\n\n        case FLI_256_COLOR:\n\n        case FLI_COLOR:\n\n            stream_ptr_after_color_chunk = stream_ptr + chunk_size - 6;\n\n            s->new_palette = 1;\n\n\n\n            /* check special case: If this file is from the Magic Carpet \n\n             * game and uses 6-bit colors even though it reports 256-color \n\n             * chunks in a 0xAF12-type file (fli_type is set to 0xAF13 during\n\n             * initialization) */\n\n            if ((chunk_type == FLI_256_COLOR) && (s->fli_type != 0xAF13))\n\n                color_shift = 0;\n\n            else\n\n                color_shift = 2;\n\n            /* set up the palette */\n\n            color_packets = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            palette_ptr = 0;\n\n            for (i = 0; i < color_packets; i++) {\n\n                /* first byte is how many colors to skip */\n\n                palette_ptr += buf[stream_ptr++];\n\n\n\n                /* next byte indicates how many entries to change */\n\n                color_changes = buf[stream_ptr++];\n\n\n\n                /* if there are 0 color changes, there are actually 256 */\n\n                if (color_changes == 0)\n\n                    color_changes = 256;\n\n\n\n                for (j = 0; j < color_changes; j++) {\n\n\n\n                    /* wrap around, for good measure */\n\n                    if ((unsigned)palette_ptr >= 256)\n\n                        palette_ptr = 0;\n\n\n\n                    r = buf[stream_ptr++] << color_shift;\n\n                    g = buf[stream_ptr++] << color_shift;\n\n                    b = buf[stream_ptr++] << color_shift;\n\n                    s->palette[palette_ptr++] = (r << 16) | (g << 8) | b;\n\n                }\n\n            }\n\n\n\n            /* color chunks sometimes have weird 16-bit alignment issues;\n\n             * therefore, take the hardline approach and set the stream_ptr\n\n             * to the value calculated w.r.t. the size specified by the color\n\n             * chunk header */\n\n            stream_ptr = stream_ptr_after_color_chunk;\n\n\n\n            break;\n\n\n\n        case FLI_DELTA:\n\n            y_ptr = 0;\n\n            compressed_lines = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                line_packets = LE_16(&buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n                if (line_packets < 0) {\n\n                    line_packets = -line_packets;\n\n                    y_ptr += line_packets * s->frame.linesize[0];\n\n                } else {\n\n                    compressed_lines--;\n\n                    pixel_ptr = y_ptr;\n\n                    pixel_countdown = s->avctx->width;\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += pixel_skip;\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = buf[stream_ptr++];\n\n                        if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            palette_idx2 = buf[stream_ptr++];\n\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                                pixels[pixel_ptr++] = palette_idx2;\n\n                            }\n\n                        } else {\n\n\n                            for (j = 0; j < byte_run * 2; j++, pixel_countdown--) {\n\n                                palette_idx1 = buf[stream_ptr++];\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    y_ptr += s->frame.linesize[0];\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_LC:\n\n            /* line compressed */\n\n            starting_line = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            y_ptr = 0;\n\n            y_ptr += starting_line * s->frame.linesize[0];\n\n\n\n            compressed_lines = LE_16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                pixel_ptr = y_ptr;\n\n                pixel_countdown = s->avctx->width;\n\n                line_packets = buf[stream_ptr++];\n\n                if (line_packets > 0) {\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += pixel_skip;\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = buf[stream_ptr++];\n\n                        if (byte_run > 0) {\n\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                palette_idx1 = buf[stream_ptr++];\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        } else {\n\n                            byte_run = -byte_run;\n\n                            palette_idx1 = buf[stream_ptr++];\n\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                pixels[pixel_ptr++] = palette_idx1;\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n                compressed_lines--;\n\n            }\n\n            break;\n\n\n\n        case FLI_BLACK:\n\n            /* set the whole frame to color 0 (which is usually black) */\n\n            memset(pixels, 0,\n\n                s->frame.linesize[0] * s->avctx->height);\n\n            break;\n\n\n\n        case FLI_BRUN:\n\n            /* Byte run compression: This chunk type only occurs in the first\n\n             * FLI frame and it will update the entire frame. */\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                stream_ptr++;\n\n                pixel_countdown = s->avctx->width;\n\n                while (pixel_countdown > 0) {\n\n                    byte_run = buf[stream_ptr++];\n\n                    if (byte_run > 0) {\n\n                        palette_idx1 = buf[stream_ptr++];\n\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    } else {  /* copy bytes if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_COPY:\n\n            /* copy the chunk (uncompressed frame) */\n\n            if (chunk_size - 6 > s->avctx->width * s->avctx->height) {\n\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n\n                       \"bigger than image, skipping chunk\\n\", chunk_size - 6);\n\n                stream_ptr += chunk_size - 6;\n\n            } else {\n\n                for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;\n\n                     y_ptr += s->frame.linesize[0]) {\n\n                    memcpy(&pixels[y_ptr], &buf[stream_ptr],\n\n                        s->avctx->width);\n\n                    stream_ptr += s->avctx->width;\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_MINI:\n\n            /* some sort of a thumbnail? disregard this chunk... */\n\n            stream_ptr += chunk_size - 6;\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n\n            break;\n\n        }\n\n\n\n        frame_size -= chunk_size;\n\n        num_chunks--;\n\n    }\n\n\n\n    /* by the end of the chunk, the stream ptr should equal the frame\n\n     * size (minus 1, possibly); if it doesn't, issue a warning */\n\n    if ((stream_ptr != buf_size) && (stream_ptr != buf_size - 1))\n\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n\n               \"and final chunk ptr = %d\\n\", buf_size, stream_ptr);\n\n\n\n    /* make the palette available on the way out */\n\n//    if (s->new_palette) {\n\n    if (1) {\n\n        memcpy(s->frame.data[1], s->palette, AVPALETTE_SIZE);\n\n        s->frame.palette_has_changed = 1;\n\n        s->new_palette = 0;\n\n    }\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    return buf_size;\n\n}", "idx": 14740, "_split": "valid", "_hash": "7e394f382e36fd885993fdc11d2f9924"}
{"project": "FFmpeg", "commit_id": "dfc4fdedf8cfc56a505579b1f2c1c5efbce4b97e", "target": 1, "func": "static int encode_superframe(AVCodecContext *avctx,\n                            unsigned char *buf, int buf_size, void *data){\n    WMACodecContext *s = avctx->priv_data;\n    const short *samples = data;\n    int i, total_gain;\n    s->block_len_bits= s->frame_len_bits; //required by non variable block len\n    s->block_len = 1 << s->block_len_bits;\n    apply_window_and_mdct(avctx, samples, avctx->frame_size);\n    if (s->ms_stereo) {\n        float a, b;\n        int i;\n        for(i = 0; i < s->block_len; i++) {\n            a = s->coefs[0][i]*0.5;\n            b = s->coefs[1][i]*0.5;\n            s->coefs[0][i] = a + b;\n            s->coefs[1][i] = a - b;\n#if 1\n    total_gain= 128;\n    for(i=64; i; i>>=1){\n        int error= encode_frame(s, s->coefs, buf, buf_size, total_gain-i);\n        if(error<0)\n            total_gain-= i;\n#else\n    total_gain= 90;\n    best= encode_frame(s, s->coefs, buf, buf_size, total_gain);\n    for(i=32; i; i>>=1){\n        int scoreL= encode_frame(s, s->coefs, buf, buf_size, total_gain-i);\n        int scoreR= encode_frame(s, s->coefs, buf, buf_size, total_gain+i);\n        av_log(NULL, AV_LOG_ERROR, \"%d %d %d (%d)\\n\", scoreL, best, scoreR, total_gain);\n        if(scoreL < FFMIN(best, scoreR)){\n            best = scoreL;\n            total_gain -= i;\n        }else if(scoreR < best){\n            best = scoreR;\n            total_gain += i;\n#endif\n    encode_frame(s, s->coefs, buf, buf_size, total_gain);\n    assert((put_bits_count(&s->pb) & 7) == 0);\n    i= s->block_align - (put_bits_count(&s->pb)+7)/8;\n    assert(i>=0);\n    while(i--)\n        put_bits(&s->pb, 8, 'N');\n    flush_put_bits(&s->pb);\n    return put_bits_ptr(&s->pb) - s->pb.buf;", "idx": 14758, "_split": "valid", "_hash": "f1830bc13b10721008b46b0dbfae0af5"}
{"project": "FFmpeg", "commit_id": "ef0d779706c77ca9007527bd8d41e9400682f4e4", "target": 1, "func": "static int ogg_save(AVFormatContext *s)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_state *ost =\n\n        av_malloc(sizeof (*ost) + (ogg->nstreams-1) * sizeof (*ogg->streams));\n\n    int i;\n\n    ost->pos = avio_tell (s->pb);\n\n    ost->curidx = ogg->curidx;\n\n    ost->next = ogg->state;\n\n    ost->nstreams = ogg->nstreams;\n\n    memcpy(ost->streams, ogg->streams, ogg->nstreams * sizeof(*ogg->streams));\n\n\n\n    for (i = 0; i < ogg->nstreams; i++){\n\n        struct ogg_stream *os = ogg->streams + i;\n\n        os->buf = av_malloc (os->bufsize);\n\n        memset (os->buf, 0, os->bufsize);\n\n        memcpy (os->buf, ost->streams[i].buf, os->bufpos);\n\n    }\n\n\n\n    ogg->state = ost;\n\n\n\n    return 0;\n\n}\n", "idx": 14772, "_split": "valid", "_hash": "c513c6aa721949bb46e57c8bc7cfbf12"}
{"project": "FFmpeg", "commit_id": "a392bf657015c9a79a5a13adfbfb15086c1943b9", "target": 1, "func": "static int dxtory_decode_v1_444(AVCodecContext *avctx, AVFrame *pic,\n\n                                const uint8_t *src, int src_size)\n\n{\n\n    int h, w;\n\n    uint8_t *Y, *U, *V;\n\n    int ret;\n\n\n\n    if (src_size < avctx->width * avctx->height * 3) {\n\n        av_log(avctx, AV_LOG_ERROR, \"packet too small\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_YUV444P;\n\n    if ((ret = ff_get_buffer(avctx, pic, 0)) < 0)\n\n        return ret;\n\n\n\n    Y = pic->data[0];\n\n    U = pic->data[1];\n\n    V = pic->data[2];\n\n    for (h = 0; h < avctx->height; h++) {\n\n        for (w = 0; w < avctx->width; w++) {\n\n            Y[w] = *src++;\n\n            U[w] = *src++ ^ 0x80;\n\n            V[w] = *src++ ^ 0x80;\n\n        }\n\n        Y += pic->linesize[0];\n\n        U += pic->linesize[1];\n\n        V += pic->linesize[2];\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 14776, "_split": "valid", "_hash": "30cd2e71949daf649e5782d9b7dc52c2"}
{"project": "FFmpeg", "commit_id": "c8241e730f116f1c9cfc0b34110aa7f052e05332", "target": 0, "func": "static av_cold int vaapi_encode_h265_init(AVCodecContext *avctx)\n\n{\n\n    return ff_vaapi_encode_init(avctx, &vaapi_encode_type_h265);\n\n}\n", "idx": 14791, "_split": "valid", "_hash": "10339835cca155de27d3b1e0d7650b0c"}
{"project": "FFmpeg", "commit_id": "1acd7d594c15aa491729c837ad3519d3469e620a", "target": 0, "func": "static av_noinline void FUNC(hl_decode_mb)(H264Context *h)\n\n{\n\n    const int mb_x    = h->mb_x;\n\n    const int mb_y    = h->mb_y;\n\n    const int mb_xy   = h->mb_xy;\n\n    const int mb_type = h->cur_pic.f.mb_type[mb_xy];\n\n    uint8_t *dest_y, *dest_cb, *dest_cr;\n\n    int linesize, uvlinesize /*dct_offset*/;\n\n    int i, j;\n\n    int *block_offset = &h->block_offset[0];\n\n    const int transform_bypass = !SIMPLE && (h->qscale == 0 && h->sps.transform_bypass);\n\n    /* is_h264 should always be true if SVQ3 is disabled. */\n\n    const int is_h264 = !CONFIG_SVQ3_DECODER || SIMPLE || h->avctx->codec_id == AV_CODEC_ID_H264;\n\n    void (*idct_add)(uint8_t *dst, int16_t *block, int stride);\n\n    const int block_h   = 16 >> h->chroma_y_shift;\n\n    const int chroma422 = CHROMA422;\n\n\n\n    dest_y  = h->cur_pic.f.data[0] + ((mb_x << PIXEL_SHIFT)     + mb_y * h->linesize)  * 16;\n\n    dest_cb = h->cur_pic.f.data[1] +  (mb_x << PIXEL_SHIFT) * 8 + mb_y * h->uvlinesize * block_h;\n\n    dest_cr = h->cur_pic.f.data[2] +  (mb_x << PIXEL_SHIFT) * 8 + mb_y * h->uvlinesize * block_h;\n\n\n\n    h->vdsp.prefetch(dest_y  + (h->mb_x & 3) * 4 * h->linesize   + (64 << PIXEL_SHIFT), h->linesize,       4);\n\n    h->vdsp.prefetch(dest_cb + (h->mb_x & 7)     * h->uvlinesize + (64 << PIXEL_SHIFT), dest_cr - dest_cb, 2);\n\n\n\n    h->list_counts[mb_xy] = h->list_count;\n\n\n\n    if (!SIMPLE && MB_FIELD) {\n\n        linesize     = h->mb_linesize = h->linesize * 2;\n\n        uvlinesize   = h->mb_uvlinesize = h->uvlinesize * 2;\n\n        block_offset = &h->block_offset[48];\n\n        if (mb_y & 1) { // FIXME move out of this function?\n\n            dest_y  -= h->linesize * 15;\n\n            dest_cb -= h->uvlinesize * (block_h - 1);\n\n            dest_cr -= h->uvlinesize * (block_h - 1);\n\n        }\n\n        if (FRAME_MBAFF) {\n\n            int list;\n\n            for (list = 0; list < h->list_count; list++) {\n\n                if (!USES_LIST(mb_type, list))\n\n                    continue;\n\n                if (IS_16X16(mb_type)) {\n\n                    int8_t *ref = &h->ref_cache[list][scan8[0]];\n\n                    fill_rectangle(ref, 4, 4, 8, (16 + *ref) ^ (h->mb_y & 1), 1);\n\n                } else {\n\n                    for (i = 0; i < 16; i += 4) {\n\n                        int ref = h->ref_cache[list][scan8[i]];\n\n                        if (ref >= 0)\n\n                            fill_rectangle(&h->ref_cache[list][scan8[i]], 2, 2,\n\n                                           8, (16 + ref) ^ (h->mb_y & 1), 1);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    } else {\n\n        linesize   = h->mb_linesize   = h->linesize;\n\n        uvlinesize = h->mb_uvlinesize = h->uvlinesize;\n\n        // dct_offset = s->linesize * 16;\n\n    }\n\n\n\n    if (!SIMPLE && IS_INTRA_PCM(mb_type)) {\n\n        const int bit_depth = h->sps.bit_depth_luma;\n\n        if (PIXEL_SHIFT) {\n\n            int j;\n\n            GetBitContext gb;\n\n            init_get_bits(&gb, (uint8_t *)h->intra_pcm_ptr,\n\n                          ff_h264_mb_sizes[h->sps.chroma_format_idc] * bit_depth);\n\n\n\n            for (i = 0; i < 16; i++) {\n\n                uint16_t *tmp_y = (uint16_t *)(dest_y + i * linesize);\n\n                for (j = 0; j < 16; j++)\n\n                    tmp_y[j] = get_bits(&gb, bit_depth);\n\n            }\n\n            if (SIMPLE || !CONFIG_GRAY || !(h->flags & CODEC_FLAG_GRAY)) {\n\n                if (!h->sps.chroma_format_idc) {\n\n                    for (i = 0; i < block_h; i++) {\n\n                        uint16_t *tmp_cb = (uint16_t *)(dest_cb + i * uvlinesize);\n\n                        uint16_t *tmp_cr = (uint16_t *)(dest_cr + i * uvlinesize);\n\n                        for (j = 0; j < 8; j++) {\n\n                            tmp_cb[j] = tmp_cr[j] = 1 << (bit_depth - 1);\n\n                        }\n\n                    }\n\n                } else {\n\n                    for (i = 0; i < block_h; i++) {\n\n                        uint16_t *tmp_cb = (uint16_t *)(dest_cb + i * uvlinesize);\n\n                        for (j = 0; j < 8; j++)\n\n                            tmp_cb[j] = get_bits(&gb, bit_depth);\n\n                    }\n\n                    for (i = 0; i < block_h; i++) {\n\n                        uint16_t *tmp_cr = (uint16_t *)(dest_cr + i * uvlinesize);\n\n                        for (j = 0; j < 8; j++)\n\n                            tmp_cr[j] = get_bits(&gb, bit_depth);\n\n                    }\n\n                }\n\n            }\n\n        } else {\n\n            for (i = 0; i < 16; i++)\n\n                memcpy(dest_y + i * linesize, (uint8_t *)h->intra_pcm_ptr + i * 16, 16);\n\n            if (SIMPLE || !CONFIG_GRAY || !(h->flags & CODEC_FLAG_GRAY)) {\n\n                if (!h->sps.chroma_format_idc) {\n\n                    for (i = 0; i < 8; i++) {\n\n                        memset(dest_cb + i*uvlinesize, 1 << (bit_depth - 1), 8);\n\n                        memset(dest_cr + i*uvlinesize, 1 << (bit_depth - 1), 8);\n\n                    }\n\n                } else {\n\n                    uint8_t *src_cb = (uint8_t *)h->intra_pcm_ptr + 256;\n\n                    uint8_t *src_cr = (uint8_t *)h->intra_pcm_ptr + 256 + block_h * 8;\n\n                    for (i = 0; i < block_h; i++) {\n\n                        memcpy(dest_cb + i * uvlinesize, src_cb + i * 8, 8);\n\n                        memcpy(dest_cr + i * uvlinesize, src_cr + i * 8, 8);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    } else {\n\n        if (IS_INTRA(mb_type)) {\n\n            if (h->deblocking_filter)\n\n                xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize,\n\n                               uvlinesize, 1, 0, SIMPLE, PIXEL_SHIFT);\n\n\n\n            if (SIMPLE || !CONFIG_GRAY || !(h->flags & CODEC_FLAG_GRAY)) {\n\n                h->hpc.pred8x8[h->chroma_pred_mode](dest_cb, uvlinesize);\n\n                h->hpc.pred8x8[h->chroma_pred_mode](dest_cr, uvlinesize);\n\n            }\n\n\n\n            hl_decode_mb_predict_luma(h, mb_type, is_h264, SIMPLE,\n\n                                      transform_bypass, PIXEL_SHIFT,\n\n                                      block_offset, linesize, dest_y, 0);\n\n\n\n            if (h->deblocking_filter)\n\n                xchg_mb_border(h, dest_y, dest_cb, dest_cr, linesize,\n\n                               uvlinesize, 0, 0, SIMPLE, PIXEL_SHIFT);\n\n        } else if (is_h264) {\n\n            if (chroma422) {\n\n                FUNC(hl_motion_422)(h, dest_y, dest_cb, dest_cr,\n\n                              h->me.qpel_put, h->h264chroma.put_h264_chroma_pixels_tab,\n\n                              h->me.qpel_avg, h->h264chroma.avg_h264_chroma_pixels_tab,\n\n                              h->h264dsp.weight_h264_pixels_tab,\n\n                              h->h264dsp.biweight_h264_pixels_tab);\n\n            } else {\n\n                FUNC(hl_motion_420)(h, dest_y, dest_cb, dest_cr,\n\n                              h->me.qpel_put, h->h264chroma.put_h264_chroma_pixels_tab,\n\n                              h->me.qpel_avg, h->h264chroma.avg_h264_chroma_pixels_tab,\n\n                              h->h264dsp.weight_h264_pixels_tab,\n\n                              h->h264dsp.biweight_h264_pixels_tab);\n\n            }\n\n        }\n\n\n\n        hl_decode_mb_idct_luma(h, mb_type, is_h264, SIMPLE, transform_bypass,\n\n                               PIXEL_SHIFT, block_offset, linesize, dest_y, 0);\n\n\n\n        if ((SIMPLE || !CONFIG_GRAY || !(h->flags & CODEC_FLAG_GRAY)) &&\n\n            (h->cbp & 0x30)) {\n\n            uint8_t *dest[2] = { dest_cb, dest_cr };\n\n            if (transform_bypass) {\n\n                if (IS_INTRA(mb_type) && h->sps.profile_idc == 244 &&\n\n                    (h->chroma_pred_mode == VERT_PRED8x8 ||\n\n                     h->chroma_pred_mode == HOR_PRED8x8)) {\n\n                    h->hpc.pred8x8_add[h->chroma_pred_mode](dest[0],\n\n                                                            block_offset + 16,\n\n                                                            h->mb + (16 * 16 * 1 << PIXEL_SHIFT),\n\n                                                            uvlinesize);\n\n                    h->hpc.pred8x8_add[h->chroma_pred_mode](dest[1],\n\n                                                            block_offset + 32,\n\n                                                            h->mb + (16 * 16 * 2 << PIXEL_SHIFT),\n\n                                                            uvlinesize);\n\n                } else {\n\n                    idct_add = h->h264dsp.h264_add_pixels4;\n\n                    for (j = 1; j < 3; j++) {\n\n                        for (i = j * 16; i < j * 16 + 4; i++)\n\n                            if (h->non_zero_count_cache[scan8[i]] ||\n\n                                dctcoef_get(h->mb, PIXEL_SHIFT, i * 16))\n\n                                idct_add(dest[j - 1] + block_offset[i],\n\n                                         h->mb + (i * 16 << PIXEL_SHIFT),\n\n                                         uvlinesize);\n\n                        if (chroma422) {\n\n                            for (i = j * 16 + 4; i < j * 16 + 8; i++)\n\n                                if (h->non_zero_count_cache[scan8[i + 4]] ||\n\n                                    dctcoef_get(h->mb, PIXEL_SHIFT, i * 16))\n\n                                    idct_add(dest[j - 1] + block_offset[i + 4],\n\n                                             h->mb + (i * 16 << PIXEL_SHIFT),\n\n                                             uvlinesize);\n\n                        }\n\n                    }\n\n                }\n\n            } else {\n\n                if (is_h264) {\n\n                    int qp[2];\n\n                    if (chroma422) {\n\n                        qp[0] = h->chroma_qp[0] + 3;\n\n                        qp[1] = h->chroma_qp[1] + 3;\n\n                    } else {\n\n                        qp[0] = h->chroma_qp[0];\n\n                        qp[1] = h->chroma_qp[1];\n\n                    }\n\n                    if (h->non_zero_count_cache[scan8[CHROMA_DC_BLOCK_INDEX + 0]])\n\n                        h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + (16 * 16 * 1 << PIXEL_SHIFT),\n\n                                                               h->dequant4_coeff[IS_INTRA(mb_type) ? 1 : 4][qp[0]][0]);\n\n                    if (h->non_zero_count_cache[scan8[CHROMA_DC_BLOCK_INDEX + 1]])\n\n                        h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + (16 * 16 * 2 << PIXEL_SHIFT),\n\n                                                               h->dequant4_coeff[IS_INTRA(mb_type) ? 2 : 5][qp[1]][0]);\n\n                    h->h264dsp.h264_idct_add8(dest, block_offset,\n\n                                              h->mb, uvlinesize,\n\n                                              h->non_zero_count_cache);\n\n                } else if (CONFIG_SVQ3_DECODER) {\n\n                    h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + 16 * 16 * 1,\n\n                                                           h->dequant4_coeff[IS_INTRA(mb_type) ? 1 : 4][h->chroma_qp[0]][0]);\n\n                    h->h264dsp.h264_chroma_dc_dequant_idct(h->mb + 16 * 16 * 2,\n\n                                                           h->dequant4_coeff[IS_INTRA(mb_type) ? 2 : 5][h->chroma_qp[1]][0]);\n\n                    for (j = 1; j < 3; j++) {\n\n                        for (i = j * 16; i < j * 16 + 4; i++)\n\n                            if (h->non_zero_count_cache[scan8[i]] || h->mb[i * 16]) {\n\n                                uint8_t *const ptr = dest[j - 1] + block_offset[i];\n\n                                ff_svq3_add_idct_c(ptr, h->mb + i * 16,\n\n                                                   uvlinesize,\n\n                                                   ff_h264_chroma_qp[0][h->qscale + 12] - 12, 2);\n\n                            }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        if (h->cbp || IS_INTRA(mb_type)) {\n\n            h->dsp.clear_blocks(h->mb);\n\n            h->dsp.clear_blocks(h->mb + (24 * 16 << PIXEL_SHIFT));\n\n        }\n\n    }\n\n}\n", "idx": 14819, "_split": "valid", "_hash": "61f4c124c9fcff2b4519a87ee1349d06"}
{"project": "FFmpeg", "commit_id": "2df0c32ea12ddfa72ba88309812bfb13b674130f", "target": 0, "func": "static av_cold int mp3lame_encode_init(AVCodecContext *avctx)\n\n{\n\n    LAMEContext *s = avctx->priv_data;\n\n    int ret;\n\n\n\n    s->avctx = avctx;\n\n\n\n    /* initialize LAME and get defaults */\n\n    if (!(s->gfp = lame_init()))\n\n        return AVERROR(ENOMEM);\n\n\n\n    lame_set_num_channels(s->gfp, avctx->channels);\n\n    lame_set_mode(s->gfp, avctx->channels > 1 ? s->joint_stereo ? JOINT_STEREO : STEREO : MONO);\n\n\n\n    /* sample rate */\n\n    lame_set_in_samplerate (s->gfp, avctx->sample_rate);\n\n    lame_set_out_samplerate(s->gfp, avctx->sample_rate);\n\n\n\n    /* algorithmic quality */\n\n    if (avctx->compression_level == FF_COMPRESSION_DEFAULT)\n\n        lame_set_quality(s->gfp, 5);\n\n    else\n\n        lame_set_quality(s->gfp, avctx->compression_level);\n\n\n\n    /* rate control */\n\n    if (avctx->flags & CODEC_FLAG_QSCALE) { // VBR\n\n        lame_set_VBR(s->gfp, vbr_default);\n\n        lame_set_VBR_quality(s->gfp, avctx->global_quality / (float)FF_QP2LAMBDA);\n\n    } else {\n\n        if (avctx->bit_rate) {\n\n            if (s->abr) {                   // ABR\n\n                lame_set_VBR(s->gfp, vbr_abr);\n\n                lame_set_VBR_mean_bitrate_kbps(s->gfp, avctx->bit_rate / 1000);\n\n            } else                          // CBR\n\n                lame_set_brate(s->gfp, avctx->bit_rate / 1000);\n\n        }\n\n    }\n\n\n\n    /* do not get a Xing VBR header frame from LAME */\n\n    lame_set_bWriteVbrTag(s->gfp,0);\n\n\n\n    /* bit reservoir usage */\n\n    lame_set_disable_reservoir(s->gfp, !s->reservoir);\n\n\n\n    /* set specified parameters */\n\n    if (lame_init_params(s->gfp) < 0) {\n\n        ret = -1;\n\n        goto error;\n\n    }\n\n\n\n    /* get encoder delay */\n\n    avctx->delay = lame_get_encoder_delay(s->gfp) + 528 + 1;\n\n    ff_af_queue_init(avctx, &s->afq);\n\n\n\n    avctx->frame_size  = lame_get_framesize(s->gfp);\n\n\n\n    /* allocate float sample buffers */\n\n    if (avctx->sample_fmt == AV_SAMPLE_FMT_FLTP) {\n\n        int ch;\n\n        for (ch = 0; ch < avctx->channels; ch++) {\n\n            s->samples_flt[ch] = av_malloc(avctx->frame_size *\n\n                                           sizeof(*s->samples_flt[ch]));\n\n            if (!s->samples_flt[ch]) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto error;\n\n            }\n\n        }\n\n    }\n\n\n\n    ret = realloc_buffer(s);\n\n    if (ret < 0)\n\n        goto error;\n\n\n\n    avpriv_float_dsp_init(&s->fdsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n\n\n    return 0;\n\nerror:\n\n    mp3lame_encode_close(avctx);\n\n    return ret;\n\n}\n", "idx": 14870, "_split": "valid", "_hash": "0335188b6540e20c5788e91dacc36dc2"}
{"project": "FFmpeg", "commit_id": "1731c3530bffb876deb9e00dfffdf9841a8412cd", "target": 1, "func": "static int read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    MmDemuxContext *mm = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    unsigned char preamble[MM_PREAMBLE_SIZE];\n\n    unsigned int type, length;\n\n\n\n    while(1) {\n\n\n\n        if (avio_read(pb, preamble, MM_PREAMBLE_SIZE) != MM_PREAMBLE_SIZE) {\n\n            return AVERROR(EIO);\n\n\n\n\n        type = AV_RL16(&preamble[0]);\n\n        length = AV_RL16(&preamble[2]);\n\n\n\n        switch(type) {\n\n        case MM_TYPE_PALETTE :\n\n        case MM_TYPE_INTER :\n\n        case MM_TYPE_INTRA :\n\n        case MM_TYPE_INTRA_HH :\n\n        case MM_TYPE_INTER_HH :\n\n        case MM_TYPE_INTRA_HHV :\n\n        case MM_TYPE_INTER_HHV :\n\n            /* output preamble + data */\n\n            if (av_new_packet(pkt, length + MM_PREAMBLE_SIZE))\n\n                return AVERROR(ENOMEM);\n\n            memcpy(pkt->data, preamble, MM_PREAMBLE_SIZE);\n\n            if (avio_read(pb, pkt->data + MM_PREAMBLE_SIZE, length) != length)\n\n                return AVERROR(EIO);\n\n            pkt->size = length + MM_PREAMBLE_SIZE;\n\n            pkt->stream_index = 0;\n\n            pkt->pts = mm->video_pts;\n\n            if (type!=MM_TYPE_PALETTE)\n\n                mm->video_pts++;\n\n            return 0;\n\n\n\n        case MM_TYPE_AUDIO :\n\n\n\n\n\n\n\n            if (av_get_packet(s->pb, pkt, length)<0)\n\n                return AVERROR(ENOMEM);\n\n            pkt->size = length;\n\n            pkt->stream_index = 1;\n\n            pkt->pts = mm->audio_pts++;\n\n            return 0;\n\n\n\n        default :\n\n            av_log(s, AV_LOG_INFO, \"unknown chunk type 0x%x\\n\", type);\n\n\n\n", "idx": 14947, "_split": "valid", "_hash": "4bf6cf8303f1cbeee9b725f9ff26d200"}
{"project": "FFmpeg", "commit_id": "f90c9c306f4e8334f29972b6c90201929ccce546", "target": 0, "func": "static void * attribute_align_arg worker(void *v){\n\n    AVCodecContext *avctx = v;\n\n    ThreadContext *c = avctx->internal->frame_thread_encoder;\n\n    AVPacket *pkt = NULL;\n\n\n\n    while(!c->exit){\n\n        int got_packet, ret;\n\n        AVFrame *frame;\n\n        Task task;\n\n\n\n        if(!pkt) pkt= av_mallocz(sizeof(*pkt));\n\n        if(!pkt) continue;\n\n        av_init_packet(pkt);\n\n\n\n        pthread_mutex_lock(&c->task_fifo_mutex);\n\n        while (av_fifo_size(c->task_fifo) <= 0 || c->exit) {\n\n            if(c->exit){\n\n                pthread_mutex_unlock(&c->task_fifo_mutex);\n\n                goto end;\n\n            }\n\n            pthread_cond_wait(&c->task_fifo_cond, &c->task_fifo_mutex);\n\n        }\n\n        av_fifo_generic_read(c->task_fifo, &task, sizeof(task), NULL);\n\n        pthread_mutex_unlock(&c->task_fifo_mutex);\n\n        frame = task.indata;\n\n\n\n        ret = avcodec_encode_video2(avctx, pkt, frame, &got_packet);\n\n        pthread_mutex_lock(&c->buffer_mutex);\n\n        av_frame_unref(frame);\n\n        pthread_mutex_unlock(&c->buffer_mutex);\n\n        av_frame_free(&frame);\n\n        if(got_packet) {\n\n            av_dup_packet(pkt);\n\n        } else {\n\n            pkt->data = NULL;\n\n            pkt->size = 0;\n\n        }\n\n        pthread_mutex_lock(&c->finished_task_mutex);\n\n        c->finished_tasks[task.index].outdata = pkt; pkt = NULL;\n\n        c->finished_tasks[task.index].return_code = ret;\n\n        pthread_cond_signal(&c->finished_task_cond);\n\n        pthread_mutex_unlock(&c->finished_task_mutex);\n\n    }\n\nend:\n\n    av_free(pkt);\n\n    pthread_mutex_lock(&c->buffer_mutex);\n\n    avcodec_close(avctx);\n\n    pthread_mutex_unlock(&c->buffer_mutex);\n\n    av_freep(&avctx);\n\n    return NULL;\n\n}\n", "idx": 14963, "_split": "valid", "_hash": "baae8f0dbe7a9acf518fbea2aa0e1558"}
{"project": "FFmpeg", "commit_id": "0cf3505930913d3584b215f6912de04ff41366e0", "target": 0, "func": "int ff_audio_mix_set_matrix(AudioMix *am, const double *matrix, int stride)\n\n{\n\n    int i, o;\n\n\n\n    if ( am->in_channels <= 0 ||  am->in_channels > AVRESAMPLE_MAX_CHANNELS ||\n\n        am->out_channels <= 0 || am->out_channels > AVRESAMPLE_MAX_CHANNELS) {\n\n        av_log(am, AV_LOG_ERROR, \"Invalid channel counts\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (am->matrix) {\n\n        av_free(am->matrix[0]);\n\n        am->matrix = NULL;\n\n    }\n\n\n\n#define CONVERT_MATRIX(type, expr)                                          \\\n\n    am->matrix_## type[0] = av_mallocz(am->out_channels * am->in_channels * \\\n\n                                       sizeof(*am->matrix_## type[0]));     \\\n\n    if (!am->matrix_## type[0])                                             \\\n\n        return AVERROR(ENOMEM);                                             \\\n\n    for (o = 0; o < am->out_channels; o++) {                                \\\n\n        if (o > 0)                                                          \\\n\n            am->matrix_## type[o] = am->matrix_## type[o - 1] +             \\\n\n                                    am->in_channels;                        \\\n\n        for (i = 0; i < am->in_channels; i++) {                             \\\n\n            double v = matrix[o * stride + i];                              \\\n\n            am->matrix_## type[o][i] = expr;                                \\\n\n        }                                                                   \\\n\n    }                                                                       \\\n\n    am->matrix = (void **)am->matrix_## type;\n\n\n\n    switch (am->coeff_type) {\n\n    case AV_MIX_COEFF_TYPE_Q8:\n\n        CONVERT_MATRIX(q8, av_clip_int16(lrint(256.0 * v)))\n\n        break;\n\n    case AV_MIX_COEFF_TYPE_Q15:\n\n        CONVERT_MATRIX(q15, av_clipl_int32(llrint(32768.0 * v)))\n\n        break;\n\n    case AV_MIX_COEFF_TYPE_FLT:\n\n        CONVERT_MATRIX(flt, v)\n\n        break;\n\n    default:\n\n        av_log(am, AV_LOG_ERROR, \"Invalid mix coeff type\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* TODO: detect situations where we can just swap around pointers\n\n             instead of doing matrix multiplications with 0.0 and 1.0 */\n\n\n\n    return 0;\n\n}\n", "idx": 14985, "_split": "valid", "_hash": "88dffcacce00827ca448da5e3c65f42a"}
{"project": "FFmpeg", "commit_id": "d584533cf38141172e20bae5436629ee17c8ce50", "target": 0, "func": "static int queue_attached_pictures(AVFormatContext *s)\n\n{\n\n    int i;\n\n    for (i = 0; i < s->nb_streams; i++)\n\n        if (s->streams[i]->disposition & AV_DISPOSITION_ATTACHED_PIC &&\n\n            s->streams[i]->discard < AVDISCARD_ALL) {\n\n            AVPacket copy = s->streams[i]->attached_pic;\n\n            copy.buf = av_buffer_ref(copy.buf);\n\n            if (!copy.buf)\n\n                return AVERROR(ENOMEM);\n\n\n\n            add_to_pktbuf(&s->internal->raw_packet_buffer, &copy,\n\n                          &s->internal->raw_packet_buffer_end);\n\n        }\n\n    return 0;\n\n}\n", "idx": 14988, "_split": "valid", "_hash": "7d25e76c656bb0c7137245e0ad8eddd6"}
{"project": "FFmpeg", "commit_id": "0c22311b56e66115675c4a96e4c78547886a4171", "target": 0, "func": "static void opt_frame_pad_top(const char *arg)\n\n{\n\n    frame_padtop = atoi(arg);\n\n    if (frame_padtop < 0) {\n\n        fprintf(stderr, \"Incorrect top pad size\\n\");\n\n        av_exit(1);\n\n    }\n\n}\n", "idx": 15022, "_split": "valid", "_hash": "33753695b7ac2471fed4cfc058071c2d"}
{"project": "FFmpeg", "commit_id": "11a631d4a76859e09cd413856e32df6363d25eea", "target": 1, "func": "static void set_frame_data(MIContext *mi_ctx, int alpha, AVFrame *avf_out)\n\n{\n\n    int x, y, plane;\n\n\n\n    for (plane = 0; plane < mi_ctx->nb_planes; plane++) {\n\n        int width = avf_out->width;\n\n        int height = avf_out->height;\n\n        int chroma = plane == 1 || plane == 2;\n\n\n\n        for (y = 0; y < height; y++)\n\n            for (x = 0; x < width; x++) {\n\n                int x_mv, y_mv;\n\n                int weight_sum = 0;\n\n                int i, val = 0;\n\n                Pixel *pixel = &mi_ctx->pixels[x + y * avf_out->width];\n\n\n\n                for (i = 0; i < pixel->nb; i++)\n\n                    weight_sum += pixel->weights[i];\n\n\n\n                if (!weight_sum || !pixel->nb) {\n\n                    pixel->weights[0] = ALPHA_MAX - alpha;\n\n                    pixel->refs[0] = 1;\n\n                    pixel->mvs[0][0] = 0;\n\n                    pixel->mvs[0][1] = 0;\n\n                    pixel->weights[1] = alpha;\n\n                    pixel->refs[1] = 2;\n\n                    pixel->mvs[1][0] = 0;\n\n                    pixel->mvs[1][1] = 0;\n\n                    pixel->nb = 2;\n\n\n\n                    weight_sum = ALPHA_MAX;\n\n                }\n\n\n\n                for (i = 0; i < pixel->nb; i++) {\n\n                    Frame *frame = &mi_ctx->frames[pixel->refs[i]];\n\n                    if (chroma) {\n\n                        x_mv = (x >> mi_ctx->chroma_h_shift) + (pixel->mvs[i][0] >> mi_ctx->chroma_h_shift);\n\n                        y_mv = (y >> mi_ctx->chroma_v_shift) + (pixel->mvs[i][1] >> mi_ctx->chroma_v_shift);\n\n                    } else {\n\n                        x_mv = x + pixel->mvs[i][0];\n\n                        y_mv = y + pixel->mvs[i][1];\n\n                    }\n\n\n\n                    val += pixel->weights[i] * frame->avf->data[plane][x_mv + y_mv * frame->avf->linesize[plane]];\n\n                }\n\n\n\n                val = ROUNDED_DIV(val, weight_sum);\n\n\n\n                if (chroma)\n\n                    avf_out->data[plane][(x >> mi_ctx->chroma_h_shift) + (y >> mi_ctx->chroma_v_shift) * avf_out->linesize[plane]] = val;\n\n                else\n\n                    avf_out->data[plane][x + y * avf_out->linesize[plane]] = val;\n\n            }\n\n    }\n\n}\n", "idx": 15116, "_split": "valid", "_hash": "59ccc2dffced62c65a9bedf3fadee29b"}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static void svq1_encode_plane(SVQ1Context *s, int plane, unsigned char *src_plane, unsigned char *ref_plane, unsigned char *decoded_plane,\n\n    int width, int height, int src_stride, int stride)\n\n{\n\n    int x, y;\n\n    int i;\n\n    int block_width, block_height;\n\n    int level;\n\n    int threshold[6];\n\n    const int lambda= (s->picture.quality*s->picture.quality) >> (2*FF_LAMBDA_SHIFT);\n\n\n\n    /* figure out the acceptable level thresholds in advance */\n\n    threshold[5] = QUALITY_THRESHOLD;\n\n    for (level = 4; level >= 0; level--)\n\n        threshold[level] = threshold[level + 1] * THRESHOLD_MULTIPLIER;\n\n\n\n    block_width = (width + 15) / 16;\n\n    block_height = (height + 15) / 16;\n\n\n\n    if(s->picture.pict_type == P_TYPE){\n\n        s->m.avctx= s->avctx;\n\n        s->m.current_picture_ptr= &s->m.current_picture;\n\n        s->m.last_picture_ptr   = &s->m.last_picture;\n\n        s->m.last_picture.data[0]= ref_plane;\n\n        s->m.linesize=\n\n        s->m.last_picture.linesize[0]= \n\n        s->m.new_picture.linesize[0]= \n\n        s->m.current_picture.linesize[0]= stride;\n\n        s->m.width= width;\n\n        s->m.height= height;\n\n        s->m.mb_width= block_width;\n\n        s->m.mb_height= block_height;\n\n        s->m.mb_stride= s->m.mb_width+1;\n\n        s->m.b8_stride= 2*s->m.mb_width+1;\n\n        s->m.f_code=1;\n\n        s->m.pict_type= s->picture.pict_type;\n\n        s->m.qscale= s->picture.quality/FF_QP2LAMBDA;\n\n        s->m.me_method= s->avctx->me_method;\n\n        \n\n        if(!s->motion_val8[plane]){\n\n            s->motion_val8 [plane]= av_mallocz((s->m.b8_stride*block_height*2 + 2)*2*sizeof(int16_t));\n\n            s->motion_val16[plane]= av_mallocz((s->m.mb_stride*(block_height + 2) + 1)*2*sizeof(int16_t));\n\n        }\n\n\n\n        s->m.mb_type= s->mb_type;\n\n        \n\n        //dummies, to avoid segfaults\n\n        s->m.current_picture.mb_mean=   (uint8_t *)s->dummy;\n\n        s->m.current_picture.mb_var=    (uint16_t*)s->dummy;\n\n        s->m.current_picture.mc_mb_var= (uint16_t*)s->dummy;\n\n        s->m.current_picture.mb_type= s->dummy;\n\n        \n\n        s->m.current_picture.motion_val[0]= s->motion_val8[plane] + 2;\n\n        s->m.p_mv_table= s->motion_val16[plane] + s->m.mb_stride + 1;\n\n        s->m.dsp= s->dsp; //move\n\n        ff_init_me(&s->m);\n\n    \n\n        s->m.me.dia_size= s->avctx->dia_size;\n\n        s->m.first_slice_line=1;\n\n        for (y = 0; y < block_height; y++) {\n\n            uint8_t src[stride*16];\n\n            \n\n            s->m.new_picture.data[0]= src - y*16*stride; //ugly\n\n            s->m.mb_y= y;\n\n    \n\n            for(i=0; i<16 && i + 16*y<height; i++){\n\n                memcpy(&src[i*stride], &src_plane[(i+16*y)*src_stride], width);\n\n                for(x=width; x<16*block_width; x++)\n\n                    src[i*stride+x]= src[i*stride+x-1];\n\n            }\n\n            for(; i<16 && i + 16*y<16*block_height; i++)\n\n                memcpy(&src[i*stride], &src[(i-1)*stride], 16*block_width);\n\n    \n\n            for (x = 0; x < block_width; x++) {\n\n                s->m.mb_x= x;\n\n                ff_init_block_index(&s->m);\n\n                ff_update_block_index(&s->m);\n\n                \n\n                ff_estimate_p_frame_motion(&s->m, x, y);\n\n            }\n\n            s->m.first_slice_line=0;\n\n        }\n\n    \n\n        ff_fix_long_p_mvs(&s->m);\n\n        ff_fix_long_mvs(&s->m, NULL, 0, s->m.p_mv_table, s->m.f_code, CANDIDATE_MB_TYPE_INTER, 0);\n\n    }\n\n        \n\n    s->m.first_slice_line=1;\n\n    for (y = 0; y < block_height; y++) {\n\n        uint8_t src[stride*16];\n\n        \n\n        for(i=0; i<16 && i + 16*y<height; i++){\n\n            memcpy(&src[i*stride], &src_plane[(i+16*y)*src_stride], width);\n\n            for(x=width; x<16*block_width; x++)\n\n                src[i*stride+x]= src[i*stride+x-1];\n\n        }\n\n        for(; i<16 && i + 16*y<16*block_height; i++)\n\n            memcpy(&src[i*stride], &src[(i-1)*stride], 16*block_width);\n\n\n\n        s->m.mb_y= y;\n\n        for (x = 0; x < block_width; x++) {\n\n            uint8_t reorder_buffer[3][6][7*32];\n\n            int count[3][6];\n\n            int offset = y * 16 * stride + x * 16;\n\n            uint8_t *decoded= decoded_plane + offset;\n\n            uint8_t *ref= ref_plane + offset;\n\n            int score[4]={0,0,0,0}, best;\n\n            uint8_t temp[16*stride];\n\n\n\n            s->m.mb_x= x;\n\n            ff_init_block_index(&s->m);\n\n            ff_update_block_index(&s->m);\n\n            \n\n            if(s->picture.pict_type == I_TYPE || (s->m.mb_type[x + y*s->m.mb_stride]&CANDIDATE_MB_TYPE_INTRA)){\n\n                for(i=0; i<6; i++){\n\n                    init_put_bits(&s->reorder_pb[i], reorder_buffer[0][i], 7*32);\n\n                }\n\n                if(s->picture.pict_type == P_TYPE){\n\n                    const uint8_t *vlc= svq1_block_type_vlc[SVQ1_BLOCK_INTRA];\n\n                    put_bits(&s->reorder_pb[5], vlc[1], vlc[0]);\n\n                    score[0]= vlc[1]*lambda;\n\n                }\n\n                score[0]+= encode_block(s, src+16*x, NULL, temp, stride, 5, 64, lambda, 1);\n\n                for(i=0; i<6; i++){\n\n                    count[0][i]= put_bits_count(&s->reorder_pb[i]);\n\n                    flush_put_bits(&s->reorder_pb[i]);\n\n                }\n\n            }else\n\n                score[0]= INT_MAX;\n\n            \n\n            best=0;\n\n            \n\n            if(s->picture.pict_type == P_TYPE){\n\n                const uint8_t *vlc= svq1_block_type_vlc[SVQ1_BLOCK_INTER];\n\n                int mx, my, pred_x, pred_y, dxy;\n\n                int16_t *motion_ptr;\n\n\n\n                motion_ptr= h263_pred_motion(&s->m, 0, 0, &pred_x, &pred_y);\n\n                if(s->m.mb_type[x + y*s->m.mb_stride]&CANDIDATE_MB_TYPE_INTER){\n\n                    for(i=0; i<6; i++)\n\n                        init_put_bits(&s->reorder_pb[i], reorder_buffer[1][i], 7*32);\n\n\n\n                    put_bits(&s->reorder_pb[5], vlc[1], vlc[0]);\n\n    \n\n                    s->m.pb= s->reorder_pb[5];                \n\n                    mx= motion_ptr[0];\n\n                    my= motion_ptr[1];\n\n                    assert(mx>=-32 && mx<=31);\n\n                    assert(my>=-32 && my<=31);\n\n                    assert(pred_x>=-32 && pred_x<=31);\n\n                    assert(pred_y>=-32 && pred_y<=31);\n\n                    ff_h263_encode_motion(&s->m, mx - pred_x, 1);\n\n                    ff_h263_encode_motion(&s->m, my - pred_y, 1);\n\n                    s->reorder_pb[5]= s->m.pb;\n\n                    score[1] += lambda*put_bits_count(&s->reorder_pb[5]);\n\n    \n\n                    dxy= (mx&1) + 2*(my&1);\n\n                    \n\n                    s->dsp.put_pixels_tab[0][dxy](temp+16, ref + (mx>>1) + stride*(my>>1), stride, 16);\n\n                    \n\n                    score[1]+= encode_block(s, src+16*x, temp+16, decoded, stride, 5, 64, lambda, 0);\n\n                    best= score[1] <= score[0];\n\n\n\n                    vlc= svq1_block_type_vlc[SVQ1_BLOCK_SKIP];\n\n                    score[2]= s->dsp.sse[0](NULL, src+16*x, ref, stride, 16);\n\n                    score[2]+= vlc[1]*lambda;\n\n                    if(score[2] < score[best] && mx==0 && my==0){\n\n                        best=2;\n\n                        s->dsp.put_pixels_tab[0][0](decoded, ref, stride, 16);\n\n                        for(i=0; i<6; i++){\n\n                            count[2][i]=0;\n\n                        }\n\n                        put_bits(&s->pb, vlc[1], vlc[0]);\n\n                    }\n\n                }\n\n\n\n                if(best==1){\n\n                    for(i=0; i<6; i++){\n\n                        count[1][i]= put_bits_count(&s->reorder_pb[i]);\n\n                        flush_put_bits(&s->reorder_pb[i]);\n\n                    }\n\n                }else{\n\n                    motion_ptr[0                 ] = motion_ptr[1                 ]=\n\n                    motion_ptr[2                 ] = motion_ptr[3                 ]=\n\n                    motion_ptr[0+2*s->m.b8_stride] = motion_ptr[1+2*s->m.b8_stride]=\n\n                    motion_ptr[2+2*s->m.b8_stride] = motion_ptr[3+2*s->m.b8_stride]=0;\n\n                }\n\n            }\n\n                \n\n            s->rd_total += score[best];\n\n\n\n            for(i=5; i>=0; i--){\n\n                ff_copy_bits(&s->pb, reorder_buffer[best][i], count[best][i]);\n\n            }\n\n            if(best==0){\n\n                s->dsp.put_pixels_tab[0][0](decoded, temp, stride, 16);\n\n            }\n\n        }\n\n        s->m.first_slice_line=0;\n\n    }\n\n}\n", "idx": 15134, "_split": "valid", "_hash": "6abfc81654dbf74a0da8719f2112c5ad"}
{"project": "FFmpeg", "commit_id": "57c0da6fe4ebd7c2d58a28248d84a18d45fce0ee", "target": 1, "func": "static int smka_decode_frame(AVCodecContext *avctx, void *data,\n                             int *got_frame_ptr, AVPacket *avpkt)\n{\n    SmackerAudioContext *s = avctx->priv_data;\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    GetBitContext gb;\n    HuffContext h[4] = { { 0 } };\n    VLC vlc[4]       = { { 0 } };\n    int16_t *samples;\n    uint8_t *samples8;\n    int val;\n    int i, res, ret;\n    int unp_size;\n    int bits, stereo;\n    int pred[2] = {0, 0};\n    if (buf_size <= 4) {\n        av_log(avctx, AV_LOG_ERROR, \"packet is too small\\n\");\n        return AVERROR(EINVAL);\n    unp_size = AV_RL32(buf);\n    init_get_bits(&gb, buf + 4, (buf_size - 4) * 8);\n    if(!get_bits1(&gb)){\n        av_log(avctx, AV_LOG_INFO, \"Sound: no data\\n\");\n        *got_frame_ptr = 0;\n        return 1;\n    stereo = get_bits1(&gb);\n    bits = get_bits1(&gb);\n    if (stereo ^ (avctx->channels != 1)) {\n        av_log(avctx, AV_LOG_ERROR, \"channels mismatch\\n\");\n        return AVERROR(EINVAL);\n    if (bits && avctx->sample_fmt == AV_SAMPLE_FMT_U8) {\n        av_log(avctx, AV_LOG_ERROR, \"sample format mismatch\\n\");\n        return AVERROR(EINVAL);\n    /* get output buffer */\n    s->frame.nb_samples = unp_size / (avctx->channels * (bits + 1));\n    if ((ret = avctx->get_buffer(avctx, &s->frame)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n        return ret;\n    samples  = (int16_t *)s->frame.data[0];\n    samples8 =            s->frame.data[0];\n    // Initialize\n    for(i = 0; i < (1 << (bits + stereo)); i++) {\n        h[i].length = 256;\n        h[i].maxlength = 0;\n        h[i].current = 0;\n        h[i].bits = av_mallocz(256 * 4);\n        h[i].lengths = av_mallocz(256 * sizeof(int));\n        h[i].values = av_mallocz(256 * sizeof(int));\n        skip_bits1(&gb);\n        smacker_decode_tree(&gb, &h[i], 0, 0);\n        skip_bits1(&gb);\n        if(h[i].current > 1) {\n            res = init_vlc(&vlc[i], SMKTREE_BITS, h[i].length,\n                    h[i].lengths, sizeof(int), sizeof(int),\n                    h[i].bits, sizeof(uint32_t), sizeof(uint32_t), INIT_VLC_LE);\n            if(res < 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Cannot build VLC table\\n\");\n    if(bits) { //decode 16-bit data\n        for(i = stereo; i >= 0; i--)\n            pred[i] = sign_extend(av_bswap16(get_bits(&gb, 16)), 16);\n        for(i = 0; i <= stereo; i++)\n            *samples++ = pred[i];\n        for(; i < unp_size / 2; i++) {\n            if(get_bits_left(&gb)<0)\n            if(i & stereo) {\n                if(vlc[2].table)\n                    res = get_vlc2(&gb, vlc[2].table, SMKTREE_BITS, 3);\n                else\n                    res = 0;\n                if (res < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid vlc\\n\");\n                val  = h[2].values[res];\n                if(vlc[3].table)\n                    res = get_vlc2(&gb, vlc[3].table, SMKTREE_BITS, 3);\n                else\n                    res = 0;\n                if (res < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid vlc\\n\");\n                val |= h[3].values[res] << 8;\n                pred[1] += sign_extend(val, 16);\n                *samples++ = av_clip_int16(pred[1]);\n            } else {\n                if(vlc[0].table)\n                    res = get_vlc2(&gb, vlc[0].table, SMKTREE_BITS, 3);\n                else\n                    res = 0;\n                if (res < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid vlc\\n\");\n                val  = h[0].values[res];\n                if(vlc[1].table)\n                    res = get_vlc2(&gb, vlc[1].table, SMKTREE_BITS, 3);\n                else\n                    res = 0;\n                if (res < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid vlc\\n\");\n                val |= h[1].values[res] << 8;\n                pred[0] += sign_extend(val, 16);\n                *samples++ = av_clip_int16(pred[0]);\n    } else { //8-bit data\n        for(i = stereo; i >= 0; i--)\n            pred[i] = get_bits(&gb, 8);\n        for(i = 0; i <= stereo; i++)\n            *samples8++ = pred[i];\n        for(; i < unp_size; i++) {\n            if(get_bits_left(&gb)<0)\n            if(i & stereo){\n                if(vlc[1].table)\n                    res = get_vlc2(&gb, vlc[1].table, SMKTREE_BITS, 3);\n                else\n                    res = 0;\n                if (res < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid vlc\\n\");\n                pred[1] += sign_extend(h[1].values[res], 8);\n                *samples8++ = av_clip_uint8(pred[1]);\n            } else {\n                if(vlc[0].table)\n                    res = get_vlc2(&gb, vlc[0].table, SMKTREE_BITS, 3);\n                else\n                    res = 0;\n                if (res < 0) {\n                    av_log(avctx, AV_LOG_ERROR, \"invalid vlc\\n\");\n                pred[0] += sign_extend(h[0].values[res], 8);\n                *samples8++ = av_clip_uint8(pred[0]);\n    for(i = 0; i < 4; i++) {\n        if(vlc[i].table)\n            ff_free_vlc(&vlc[i]);\n        av_free(h[i].bits);\n        av_free(h[i].lengths);\n        av_free(h[i].values);\n    *got_frame_ptr   = 1;\n    *(AVFrame *)data = s->frame;\n    return buf_size;", "idx": 15159, "_split": "valid", "_hash": "eb6fa019d3e0879f3ecfbe756dafb820"}
{"project": "FFmpeg", "commit_id": "d150a147dac67faeaf6b1f25a523ae330168ee1e", "target": 0, "func": "static int decode_rle(AVCodecContext *avctx, AVSubtitle *sub,\n\n                      const uint8_t *buf, unsigned int buf_size)\n\n{\n\n    const uint8_t *rle_bitmap_end;\n\n    int pixel_count, line_count;\n\n\n\n    rle_bitmap_end = buf + buf_size;\n\n\n\n    sub->rects[0]->pict.data[0] = av_malloc(sub->rects[0]->w * sub->rects[0]->h);\n\n\n\n    if (!sub->rects[0]->pict.data[0])\n\n        return -1;\n\n\n\n    pixel_count = 0;\n\n    line_count  = 0;\n\n\n\n    while (buf < rle_bitmap_end && line_count < sub->rects[0]->h) {\n\n        uint8_t flags, color;\n\n        int run;\n\n\n\n        color = bytestream_get_byte(&buf);\n\n        run   = 1;\n\n\n\n        if (color == 0x00) {\n\n            flags = bytestream_get_byte(&buf);\n\n            run   = flags & 0x3f;\n\n            if (flags & 0x40)\n\n                run = (run << 8) + bytestream_get_byte(&buf);\n\n            color = flags & 0x80 ? bytestream_get_byte(&buf) : 0;\n\n        }\n\n\n\n        if (run > 0 && pixel_count + run <= sub->rects[0]->w * sub->rects[0]->h) {\n\n            memset(sub->rects[0]->pict.data[0] + pixel_count, color, run);\n\n            pixel_count += run;\n\n        } else if (!run) {\n\n            /*\n\n             * New Line. Check if correct pixels decoded, if not display warning\n\n             * and adjust bitmap pointer to correct new line position.\n\n             */\n\n            if (pixel_count % sub->rects[0]->w > 0)\n\n                av_log(avctx, AV_LOG_ERROR, \"Decoded %d pixels, when line should be %d pixels\\n\",\n\n                       pixel_count % sub->rects[0]->w, sub->rects[0]->w);\n\n            line_count++;\n\n        }\n\n    }\n\n\n\n    if (pixel_count < sub->rects[0]->w * sub->rects[0]->h) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Insufficient RLE data for subtitle\\n\");\n\n        return -1;\n\n    }\n\n\n\n    av_dlog(avctx, \"Pixel Count = %d, Area = %d\\n\", pixel_count, sub->rects[0]->w * sub->rects[0]->h);\n\n\n\n    return 0;\n\n}\n", "idx": 15163, "_split": "valid", "_hash": "1002db13c3d6560b6de440a1660aa090"}
{"project": "FFmpeg", "commit_id": "e5cf100d3daaf3fa48d44ae575af916473f85544", "target": 0, "func": "static int mpegvideo_probe(AVProbeData *p)\n\n{\n\n    uint32_t code= -1;\n\n    int pic=0, seq=0, slice=0, pspack=0, vpes=0, apes=0, res=0;\n\n    int i;\n\n\n\n    for(i=0; i<p->buf_size; i++){\n\n        code = (code<<8) + p->buf[i];\n\n        if ((code & 0xffffff00) == 0x100) {\n\n            switch(code){\n\n            case     SEQ_START_CODE:   seq++; break;\n\n            case PICTURE_START_CODE:   pic++; break;\n\n            case    PACK_START_CODE: pspack++; break;\n\n            case              0x1b6:\n\n                                        res++; break;\n\n            }\n\n            if (code >= SLICE_START_CODE && code <= 0x1af) slice++;\n\n            if     ((code & 0x1f0) == VIDEO_ID)   vpes++;\n\n            else if((code & 0x1e0) == AUDIO_ID)   apes++;\n\n        }\n\n    }\n\n    if(seq && seq*9<=pic*10 && pic*9<=slice*10 && !pspack && !apes && !res) {\n\n        if(vpes) return AVPROBE_SCORE_MAX/8;\n\n        else     return pic>1 ? AVPROBE_SCORE_MAX/2+1 : AVPROBE_SCORE_MAX/4; // +1 for .mpg\n\n    }\n\n    return 0;\n\n}\n", "idx": 15219, "_split": "valid", "_hash": "2bf45345e8af7356ac96a4dba669d44d"}
{"project": "FFmpeg", "commit_id": "fb93e61e2b7baa44ff991bc0ce96291490a0188e", "target": 0, "func": "av_cold void ff_yadif_init_x86(YADIFContext *yadif)\n\n{\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (HAVE_MMX && cpu_flags & AV_CPU_FLAG_MMX)\n\n        yadif->filter_line = yadif_filter_line_mmx;\n\n    if (HAVE_SSE && cpu_flags & AV_CPU_FLAG_SSE2)\n\n        yadif->filter_line = yadif_filter_line_sse2;\n\n    if (HAVE_SSSE3 && cpu_flags & AV_CPU_FLAG_SSSE3)\n\n        yadif->filter_line = yadif_filter_line_ssse3;\n\n}\n", "idx": 15222, "_split": "valid", "_hash": "7c887018fcfdf8ff628e8e4a34fe107f"}
{"project": "FFmpeg", "commit_id": "feb6a94f740bccc8e369f8b74714b940490f3901", "target": 1, "func": "void av_frame_unref(AVFrame *frame)\n{\n    int i;\n    wipe_side_data(frame);\n    for (i = 0; i < FF_ARRAY_ELEMS(frame->buf); i++)\n        av_buffer_unref(&frame->buf[i]);\n    for (i = 0; i < frame->nb_extended_buf; i++)\n        av_buffer_unref(&frame->extended_buf[i]);\n    av_freep(&frame->extended_buf);\n    av_dict_free(&frame->metadata);\n    av_buffer_unref(&frame->qp_table_buf);\n    get_frame_defaults(frame);\n}", "idx": 15225, "_split": "valid", "_hash": "9ef4ba247b07946e0e61b8103467a6a0"}
{"project": "FFmpeg", "commit_id": "dcf9bae4a93f54cb5767bc97db4a809efd396f8b", "target": 1, "func": "static int decode_ics(AACContext *ac, SingleChannelElement *sce,\n\n                      GetBitContext *gb, int common_window, int scale_flag)\n\n{\n\n    Pulse pulse;\n\n    TemporalNoiseShaping    *tns = &sce->tns;\n\n    IndividualChannelStream *ics = &sce->ics;\n\n    INTFLOAT *out = sce->coeffs;\n\n    int global_gain, eld_syntax, er_syntax, pulse_present = 0;\n\n    int ret;\n\n\n\n    eld_syntax = ac->oc[1].m4ac.object_type == AOT_ER_AAC_ELD;\n\n    er_syntax  = ac->oc[1].m4ac.object_type == AOT_ER_AAC_LC ||\n\n                 ac->oc[1].m4ac.object_type == AOT_ER_AAC_LTP ||\n\n                 ac->oc[1].m4ac.object_type == AOT_ER_AAC_LD ||\n\n                 ac->oc[1].m4ac.object_type == AOT_ER_AAC_ELD;\n\n\n\n    /* This assignment is to silence a GCC warning about the variable being used\n\n     * uninitialized when in fact it always is.\n\n     */\n\n    pulse.num_pulse = 0;\n\n\n\n    global_gain = get_bits(gb, 8);\n\n\n\n    if (!common_window && !scale_flag) {\n\n        if (decode_ics_info(ac, ics, gb) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((ret = decode_band_types(ac, sce->band_type,\n\n                                 sce->band_type_run_end, gb, ics)) < 0)\n\n        return ret;\n\n    if ((ret = decode_scalefactors(ac, sce->sf, gb, global_gain, ics,\n\n                                  sce->band_type, sce->band_type_run_end)) < 0)\n\n        return ret;\n\n\n\n    pulse_present = 0;\n\n    if (!scale_flag) {\n\n        if (!eld_syntax && (pulse_present = get_bits1(gb))) {\n\n            if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n                av_log(ac->avctx, AV_LOG_ERROR,\n\n                       \"Pulse tool not allowed in eight short sequence.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (decode_pulses(&pulse, gb, ics->swb_offset, ics->num_swb)) {\n\n                av_log(ac->avctx, AV_LOG_ERROR,\n\n                       \"Pulse data corrupt or invalid.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n        tns->present = get_bits1(gb);\n\n        if (tns->present && !er_syntax)\n\n            if (decode_tns(ac, tns, gb, ics) < 0)\n\n                return AVERROR_INVALIDDATA;\n\n        if (!eld_syntax && get_bits1(gb)) {\n\n            avpriv_request_sample(ac->avctx, \"SSR\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        // I see no textual basis in the spec for this occurring after SSR gain\n\n        // control, but this is what both reference and real implmentations do\n\n        if (tns->present && er_syntax)\n\n            if (decode_tns(ac, tns, gb, ics) < 0)\n\n                return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (decode_spectrum_and_dequant(ac, out, gb, sce->sf, pulse_present,\n\n                                    &pulse, ics, sce->band_type) < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (ac->oc[1].m4ac.object_type == AOT_AAC_MAIN && !common_window)\n\n        apply_prediction(ac, sce);\n\n\n\n    return 0;\n\n}\n", "idx": 15258, "_split": "valid", "_hash": "f09fbcede06425f3e50377d718c78e77"}
{"project": "FFmpeg", "commit_id": "e1ba29c76430ce511fd901c8b7a1bd199b169dc0", "target": 1, "func": "static int decode_i_block(FourXContext *f, DCTELEM *block){\n    int code, i, j, level, val;\n    /* DC coef */\n    val = get_vlc2(&f->pre_gb, f->pre_vlc.table, ACDC_VLC_BITS, 3);\n    if (val>>4){\n        av_log(f->avctx, AV_LOG_ERROR, \"error dc run != 0\\n\");\n    if(val)\n        val = get_xbits(&f->gb, val);\n    val = val * dequant_table[0] + f->last_dc;\n    f->last_dc =\n    block[0] = val;\n    /* AC coefs */\n    i = 1;\n    for(;;) {\n        code = get_vlc2(&f->pre_gb, f->pre_vlc.table, ACDC_VLC_BITS, 3);\n        /* EOB */\n        if (code == 0)\n            break;\n        if (code == 0xf0) {\n            i += 16;\n        } else {\n            level = get_xbits(&f->gb, code & 0xf);\n            i += code >> 4;\n            if (i >= 64) {\n                av_log(f->avctx, AV_LOG_ERROR, \"run %d oveflow\\n\", i);\n                return 0;\n            j= ff_zigzag_direct[i];\n            block[j] = level * dequant_table[j];\n            i++;\n            if (i >= 64)\n                break;\n    return 0;", "idx": 15262, "_split": "valid", "_hash": "3b86c9346924c6e2b2655b1a212ae588"}
{"project": "FFmpeg", "commit_id": "ba39303050c1e10c595a5495ab89f6a9e63fb667", "target": 1, "func": "static int gxf_write_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    GXFContext *gxf = s->priv_data;\n\n    GXFStreamContext *vsc = NULL;\n\n    uint8_t tracks[255] = {0};\n\n    int i, media_info = 0;\n\n    AVDictionaryEntry *tcr = av_dict_get(s->metadata, \"timecode\", NULL, 0);\n\n\n\n    if (!pb->seekable) {\n\n        av_log(s, AV_LOG_ERROR, \"gxf muxer does not support streamed output, patch welcome\\n\");\n\n        return -1;\n\n    }\n\n\n\n    gxf->flags |= 0x00080000; /* material is simple clip */\n\n    for (i = 0; i < s->nb_streams; ++i) {\n\n        AVStream *st = s->streams[i];\n\n        GXFStreamContext *sc = av_mallocz(sizeof(*sc));\n\n        if (!sc)\n\n            return AVERROR(ENOMEM);\n\n        st->priv_data = sc;\n\n\n\n        sc->media_type = ff_codec_get_tag(gxf_media_types, st->codec->codec_id);\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (st->codec->codec_id != AV_CODEC_ID_PCM_S16LE) {\n\n                av_log(s, AV_LOG_ERROR, \"only 16 BIT PCM LE allowed for now\\n\");\n\n                return -1;\n\n            }\n\n            if (st->codec->sample_rate != 48000) {\n\n                av_log(s, AV_LOG_ERROR, \"only 48000hz sampling rate is allowed\\n\");\n\n                return -1;\n\n            }\n\n            if (st->codec->channels != 1) {\n\n                av_log(s, AV_LOG_ERROR, \"only mono tracks are allowed\\n\");\n\n                return -1;\n\n            }\n\n            sc->track_type = 2;\n\n            sc->sample_rate = st->codec->sample_rate;\n\n            avpriv_set_pts_info(st, 64, 1, sc->sample_rate);\n\n            sc->sample_size = 16;\n\n            sc->frame_rate_index = -2;\n\n            sc->lines_index = -2;\n\n            sc->fields = -2;\n\n            gxf->audio_tracks++;\n\n            gxf->flags |= 0x04000000; /* audio is 16 bit pcm */\n\n            media_info = 'A';\n\n        } else if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            if (i != 0) {\n\n                av_log(s, AV_LOG_ERROR, \"video stream must be the first track\\n\");\n\n                return -1;\n\n            }\n\n            /* FIXME check from time_base ? */\n\n            if (st->codec->height == 480 || st->codec->height == 512) { /* NTSC or NTSC+VBI */\n\n                sc->frame_rate_index = 5;\n\n                sc->sample_rate = 60;\n\n                gxf->flags |= 0x00000080;\n\n                gxf->time_base = (AVRational){ 1001, 60000 };\n\n            } else if (st->codec->height == 576 || st->codec->height == 608) { /* PAL or PAL+VBI */\n\n                sc->frame_rate_index = 6;\n\n                sc->media_type++;\n\n                sc->sample_rate = 50;\n\n                gxf->flags |= 0x00000040;\n\n                gxf->time_base = (AVRational){ 1, 50 };\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"unsupported video resolution, \"\n\n                       \"gxf muxer only accepts PAL or NTSC resolutions currently\\n\");\n\n                return -1;\n\n            }\n\n            if (!tcr)\n\n                tcr = av_dict_get(st->metadata, \"timecode\", NULL, 0);\n\n            avpriv_set_pts_info(st, 64, gxf->time_base.num, gxf->time_base.den);\n\n            if (gxf_find_lines_index(st) < 0)\n\n                sc->lines_index = -1;\n\n            sc->sample_size = st->codec->bit_rate;\n\n            sc->fields = 2; /* interlaced */\n\n\n\n            vsc = sc;\n\n\n\n            switch (st->codec->codec_id) {\n\n            case AV_CODEC_ID_MJPEG:\n\n                sc->track_type = 1;\n\n                gxf->flags |= 0x00004000;\n\n                media_info = 'J';\n\n                break;\n\n            case AV_CODEC_ID_MPEG1VIDEO:\n\n                sc->track_type = 9;\n\n                gxf->mpeg_tracks++;\n\n                media_info = 'L';\n\n                break;\n\n            case AV_CODEC_ID_MPEG2VIDEO:\n\n                sc->first_gop_closed = -1;\n\n                sc->track_type = 4;\n\n                gxf->mpeg_tracks++;\n\n                gxf->flags |= 0x00008000;\n\n                media_info = 'M';\n\n                break;\n\n            case AV_CODEC_ID_DVVIDEO:\n\n                if (st->codec->pix_fmt == AV_PIX_FMT_YUV422P) {\n\n                    sc->media_type += 2;\n\n                    sc->track_type = 6;\n\n                    gxf->flags |= 0x00002000;\n\n                    media_info = 'E';\n\n                } else {\n\n                    sc->track_type = 5;\n\n                    gxf->flags |= 0x00001000;\n\n                    media_info = 'D';\n\n                }\n\n                break;\n\n            default:\n\n                av_log(s, AV_LOG_ERROR, \"video codec not supported\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n        /* FIXME first 10 audio tracks are 0 to 9 next 22 are A to V */\n\n        sc->media_info = media_info<<8 | ('0'+tracks[media_info]++);\n\n        sc->order = s->nb_streams - st->index;\n\n    }\n\n\n\n    if (ff_audio_interleave_init(s, GXF_samples_per_frame, (AVRational){ 1, 48000 }) < 0)\n\n        return -1;\n\n\n\n    if (tcr)\n\n        gxf_init_timecode(s, &gxf->tc, tcr->value, vsc->fields);\n\n\n\n    gxf_init_timecode_track(&gxf->timecode_track, vsc);\n\n    gxf->flags |= 0x200000; // time code track is non-drop frame\n\n\n\n    gxf_write_map_packet(s, 0);\n\n    gxf_write_flt_packet(s);\n\n    gxf_write_umf_packet(s);\n\n\n\n    gxf->packet_count = 3;\n\n\n\n    avio_flush(pb);\n\n    return 0;\n\n}\n", "idx": 15279, "_split": "valid", "_hash": "27bf42b41f96911302bb31dc9482f4ae"}
{"project": "FFmpeg", "commit_id": "f738140807f504c9af7850042067777832f05e88", "target": 1, "func": "static int decode_nal_sei_prefix(GetBitContext *gb, HEVCSEIContext *s, const HEVCParamSets *ps,\n\n                                 int type, int size, void *logctx)\n\n{\n\n    switch (type) {\n\n    case 256:  // Mismatched value from HM 8.1\n\n        return decode_nal_sei_decoded_picture_hash(&s->picture_hash, gb);\n\n    case HEVC_SEI_TYPE_FRAME_PACKING:\n\n        return decode_nal_sei_frame_packing_arrangement(&s->frame_packing, gb);\n\n    case HEVC_SEI_TYPE_DISPLAY_ORIENTATION:\n\n        return decode_nal_sei_display_orientation(&s->display_orientation, gb);\n\n    case HEVC_SEI_TYPE_PICTURE_TIMING:\n\n        {\n\n            int ret = decode_pic_timing(s, gb, ps, logctx);\n\n            av_log(logctx, AV_LOG_DEBUG, \"Skipped PREFIX SEI %d\\n\", type);\n\n            skip_bits(gb, 8 * size);\n\n            return ret;\n\n        }\n\n    case HEVC_SEI_TYPE_MASTERING_DISPLAY_INFO:\n\n        return decode_nal_sei_mastering_display_info(&s->mastering_display, gb);\n\n    case HEVC_SEI_TYPE_CONTENT_LIGHT_LEVEL_INFO:\n\n        return decode_nal_sei_content_light_info(&s->content_light, gb);\n\n    case HEVC_SEI_TYPE_ACTIVE_PARAMETER_SETS:\n\n        active_parameter_sets(s, gb, logctx);\n\n        av_log(logctx, AV_LOG_DEBUG, \"Skipped PREFIX SEI %d\\n\", type);\n\n        return 0;\n\n    case HEVC_SEI_TYPE_USER_DATA_REGISTERED_ITU_T_T35:\n\n        return decode_nal_sei_user_data_registered_itu_t_t35(s, gb, size);\n\n    default:\n\n        av_log(logctx, AV_LOG_DEBUG, \"Skipped PREFIX SEI %d\\n\", type);\n\n        skip_bits_long(gb, 8 * size);\n\n        return 0;\n\n    }\n\n}\n", "idx": 15296, "_split": "valid", "_hash": "881ec4015926e59a92f01c51f4b4bc9b"}
{"project": "FFmpeg", "commit_id": "c617c669e9fce59905915c3ba1053f535add6a06", "target": 1, "func": "static int xv_write_trailer(AVFormatContext *s)\n\n{\n\n    XVContext *xv = s->priv_data;\n\n\n\n    XShmDetach(xv->display, &xv->yuv_shminfo);\n\n    shmdt(xv->yuv_image->data);\n\n    XFree(xv->yuv_image);\n\n\n    XCloseDisplay(xv->display);\n\n    return 0;\n\n}", "idx": 15319, "_split": "valid", "_hash": "c8f4fd3429bdfd1618b4df4f77b65b4e"}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "void ff_biweight_h264_pixels16_8_msa(uint8_t *dst, uint8_t *src,\n\n                                     int stride, int height,\n\n                                     int log2_denom, int weight_dst,\n\n                                     int weight_src, int offset)\n\n{\n\n    avc_biwgt_16width_msa(src, stride,\n\n                          dst, stride,\n\n                          height, log2_denom,\n\n                          weight_src, weight_dst, offset);\n\n}\n", "idx": 15330, "_split": "valid", "_hash": "512ac7cb501b0434088dcc77ab3c1997"}
{"project": "FFmpeg", "commit_id": "6a4832caaede15e3d918b1408ff83fe30324507b", "target": 0, "func": "void ff_put_dirac_pixels32_sse2(uint8_t *dst, const uint8_t *src[5], int stride, int h)\n\n{\n\n    if (h&3) {\n\n        ff_put_dirac_pixels32_c(dst, src, stride, h);\n\n    } else {\n\n    ff_put_pixels16_sse2(dst   , src[0]   , stride, h);\n\n    ff_put_pixels16_sse2(dst+16, src[0]+16, stride, h);\n\n    }\n\n}\n", "idx": 15403, "_split": "valid", "_hash": "6103f37b0b9500a84575c39ecd9b9579"}
{"project": "FFmpeg", "commit_id": "c6779c513117a347214a47f7bda0a3b0b93a5884", "target": 0, "func": "static void vc1_put_signed_blocks_clamped(VC1Context *v)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    int topleft_mb_pos, top_mb_pos;\n\n    int stride_y, fieldtx;\n\n    int v_dist;\n\n\n\n    /* The put pixels loop is always one MB row behind the decoding loop,\n\n     * because we can only put pixels when overlap filtering is done, and\n\n     * for filtering of the bottom edge of a MB, we need the next MB row\n\n     * present as well.\n\n     * Within the row, the put pixels loop is also one MB col behind the\n\n     * decoding loop. The reason for this is again, because for filtering\n\n     * of the right MB edge, we need the next MB present. */\n\n    if (!s->first_slice_line) {\n\n        if (s->mb_x) {\n\n            topleft_mb_pos = (s->mb_y - 1) * s->mb_stride + s->mb_x - 1;\n\n            fieldtx        = v->fieldtx_plane[topleft_mb_pos];\n\n            stride_y       = s->linesize << fieldtx;\n\n            v_dist         = (16 - fieldtx) >> (fieldtx == 0);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->topleft_blk_idx][0],\n\n                                             s->dest[0] - 16 * s->linesize - 16,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->topleft_blk_idx][1],\n\n                                             s->dest[0] - 16 * s->linesize - 8,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->topleft_blk_idx][2],\n\n                                             s->dest[0] - v_dist * s->linesize - 16,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->topleft_blk_idx][3],\n\n                                             s->dest[0] - v_dist * s->linesize - 8,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->topleft_blk_idx][4],\n\n                                             s->dest[1] - 8 * s->uvlinesize - 8,\n\n                                             s->uvlinesize);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->topleft_blk_idx][5],\n\n                                             s->dest[2] - 8 * s->uvlinesize - 8,\n\n                                             s->uvlinesize);\n\n        }\n\n        if (s->mb_x == s->mb_width - 1) {\n\n            top_mb_pos = (s->mb_y - 1) * s->mb_stride + s->mb_x;\n\n            fieldtx    = v->fieldtx_plane[top_mb_pos];\n\n            stride_y   = s->linesize << fieldtx;\n\n            v_dist     = fieldtx ? 15 : 8;\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->top_blk_idx][0],\n\n                                             s->dest[0] - 16 * s->linesize,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->top_blk_idx][1],\n\n                                             s->dest[0] - 16 * s->linesize + 8,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->top_blk_idx][2],\n\n                                             s->dest[0] - v_dist * s->linesize,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->top_blk_idx][3],\n\n                                             s->dest[0] - v_dist * s->linesize + 8,\n\n                                             stride_y);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->top_blk_idx][4],\n\n                                             s->dest[1] - 8 * s->uvlinesize,\n\n                                             s->uvlinesize);\n\n            s->dsp.put_signed_pixels_clamped(v->block[v->top_blk_idx][5],\n\n                                             s->dest[2] - 8 * s->uvlinesize,\n\n                                             s->uvlinesize);\n\n        }\n\n    }\n\n\n\n#define inc_blk_idx(idx) do { \\\n\n        idx++; \\\n\n        if (idx >= v->n_allocated_blks) \\\n\n            idx = 0; \\\n\n    } while (0)\n\n\n\n    inc_blk_idx(v->topleft_blk_idx);\n\n    inc_blk_idx(v->top_blk_idx);\n\n    inc_blk_idx(v->left_blk_idx);\n\n    inc_blk_idx(v->cur_blk_idx);\n\n}\n", "idx": 15463, "_split": "valid", "_hash": "a13aa61d8e6bd46556e87b42efb2e812"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "int ff_h264_get_profile(SPS *sps)\n\n{\n\n    int profile = sps->profile_idc;\n\n\n\n    switch (sps->profile_idc) {\n\n    case FF_PROFILE_H264_BASELINE:\n\n        // constraint_set1_flag set to 1\n\n        profile |= (sps->constraint_set_flags & 1 << 1) ? FF_PROFILE_H264_CONSTRAINED : 0;\n\n        break;\n\n    case FF_PROFILE_H264_HIGH_10:\n\n    case FF_PROFILE_H264_HIGH_422:\n\n    case FF_PROFILE_H264_HIGH_444_PREDICTIVE:\n\n        // constraint_set3_flag set to 1\n\n        profile |= (sps->constraint_set_flags & 1 << 3) ? FF_PROFILE_H264_INTRA : 0;\n\n        break;\n\n    }\n\n\n\n    return profile;\n\n}\n", "idx": 15476, "_split": "valid", "_hash": "25103b93bc13657af729edb8b66ecf62"}
{"project": "FFmpeg", "commit_id": "723b6baaf8db43d0872bad504c4f4c780b53516b", "target": 1, "func": "static int decode_iccp_chunk(PNGDecContext *s, int length, AVFrame *f)\n\n{\n\n    int ret, cnt = 0;\n\n    uint8_t *data, profile_name[82];\n\n    AVBPrint bp;\n\n    AVFrameSideData *sd;\n\n\n\n    while ((profile_name[cnt++] = bytestream2_get_byte(&s->gb)) && cnt < 81);\n\n    if (cnt > 80) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"iCCP with invalid name!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    length = FFMAX(length - cnt, 0);\n\n\n\n    if (bytestream2_get_byte(&s->gb) != 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"iCCP with invalid compression!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    length = FFMAX(length - 1, 0);\n\n\n\n    if ((ret = decode_zbuf(&bp, s->gb.buffer, s->gb.buffer + length)) < 0)\n\n        return ret;\n\n\n\n    av_bprint_finalize(&bp, (char **)&data);\n\n\n\n\n\n    sd = av_frame_new_side_data(f, AV_FRAME_DATA_ICC_PROFILE, bp.len);\n\n    if (!sd) {\n\n        av_free(data);\n\n\n    }\n\n\n\n    av_dict_set(&sd->metadata, \"name\", profile_name, 0);\n\n    memcpy(sd->data, data, bp.len);\n\n    av_free(data);\n\n\n\n    /* ICC compressed data and CRC */\n\n    bytestream2_skip(&s->gb, length + 4);\n\n\n\n    return 0;\n\n}", "idx": 15514, "_split": "valid", "_hash": "0f5708cd6487d0328a6b4fe0128e2590"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static int decode_buffering_period(H264Context *h)\n\n{\n\n    unsigned int sps_id;\n\n    int sched_sel_idx;\n\n    SPS *sps;\n\n\n\n    sps_id = get_ue_golomb_31(&h->gb);\n\n    if (sps_id > 31 || !h->sps_buffers[sps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing SPS %d referenced in buffering period\\n\", sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sps = h->sps_buffers[sps_id];\n\n\n\n    // NOTE: This is really so duplicated in the standard... See H.264, D.1.1\n\n    if (sps->nal_hrd_parameters_present_flag) {\n\n        for (sched_sel_idx = 0; sched_sel_idx < sps->cpb_cnt; sched_sel_idx++) {\n\n            h->initial_cpb_removal_delay[sched_sel_idx] =\n\n                get_bits(&h->gb, sps->initial_cpb_removal_delay_length);\n\n            // initial_cpb_removal_delay_offset\n\n            skip_bits(&h->gb, sps->initial_cpb_removal_delay_length);\n\n        }\n\n    }\n\n    if (sps->vcl_hrd_parameters_present_flag) {\n\n        for (sched_sel_idx = 0; sched_sel_idx < sps->cpb_cnt; sched_sel_idx++) {\n\n            h->initial_cpb_removal_delay[sched_sel_idx] =\n\n                get_bits(&h->gb, sps->initial_cpb_removal_delay_length);\n\n            // initial_cpb_removal_delay_offset\n\n            skip_bits(&h->gb, sps->initial_cpb_removal_delay_length);\n\n        }\n\n    }\n\n\n\n    h->sei_buffering_period_present = 1;\n\n    return 0;\n\n}\n", "idx": 15567, "_split": "valid", "_hash": "f5a0e63c32dff2beb40a701ac2f38e78"}
{"project": "FFmpeg", "commit_id": "b399816d9c3d0fc3efd742b04f269c1055cc6e2b", "target": 1, "func": "static int ism_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    SmoothStreamingContext *c = s->priv_data;\n\n    AVStream *st = s->streams[pkt->stream_index];\n\n    OutputStream *os = &c->streams[pkt->stream_index];\n\n    int64_t end_dts = (c->nb_fragments + 1) * c->min_frag_duration;\n\n    int ret;\n\n\n\n    if (st->first_dts == AV_NOPTS_VALUE)\n\n        st->first_dts = pkt->dts;\n\n\n\n    if ((!c->has_video || st->codec->codec_type == AVMEDIA_TYPE_VIDEO) &&\n\n        av_compare_ts(pkt->dts - st->first_dts, st->time_base,\n\n                      end_dts, AV_TIME_BASE_Q) >= 0 &&\n\n        pkt->flags & AV_PKT_FLAG_KEY && os->packets_written) {\n\n\n\n        if ((ret = ism_flush(s, 0)) < 0)\n\n            return ret;\n\n        c->nb_fragments++;\n\n    }\n\n\n\n    os->packets_written++;\n\n    return ff_write_chained(os->ctx, 0, pkt, s);\n\n}\n", "idx": 15577, "_split": "valid", "_hash": "84ef79fedfb751416d1f955554c0745f"}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "static void avc_luma_midh_qrt_and_aver_dst_4w_msa(const uint8_t *src,\n\n                                                  int32_t src_stride,\n\n                                                  uint8_t *dst,\n\n                                                  int32_t dst_stride,\n\n                                                  int32_t height,\n\n                                                  uint8_t horiz_offset)\n\n{\n\n    uint32_t row;\n\n    v16i8 src0, src1, src2, src3, src4, src5, src6;\n\n    v16u8 dst0, dst1, res;\n\n    v8i16 vt_res0, vt_res1, vt_res2, vt_res3;\n\n    v4i32 hz_res0, hz_res1;\n\n    v8i16 res0, res1;\n\n    v8i16 shf_vec0, shf_vec1, shf_vec2, shf_vec3, shf_vec4, shf_vec5;\n\n    v8i16 mask0 = { 0, 5, 1, 6, 2, 7, 3, 8 };\n\n    v8i16 mask1 = { 1, 4, 2, 5, 3, 6, 4, 7 };\n\n    v8i16 mask2 = { 2, 3, 3, 4, 4, 5, 5, 6 };\n\n    v8i16 minus5h = __msa_ldi_h(-5);\n\n    v8i16 plus20h = __msa_ldi_h(20);\n\n    v8i16 zeros = { 0 };\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n\n\n    for (row = (height >> 1); row--;) {\n\n        LD_SB2(src, src_stride, src5, src6);\n\n        src += (2 * src_stride);\n\n\n\n        XORI_B2_128_SB(src5, src6);\n\n        LD_UB2(dst, dst_stride, dst0, dst1);\n\n\n\n        dst0 = (v16u8) __msa_ilvr_w((v4i32) dst1, (v4i32) dst0);\n\n\n\n        AVC_CALC_DPADD_B_6PIX_2COEFF_SH(src0, src1, src2, src3, src4, src5,\n\n                                        vt_res0, vt_res1);\n\n        AVC_CALC_DPADD_B_6PIX_2COEFF_SH(src1, src2, src3, src4, src5, src6,\n\n                                        vt_res2, vt_res3);\n\n        VSHF_H3_SH(vt_res0, vt_res1, vt_res0, vt_res1, vt_res0, vt_res1,\n\n                   mask0, mask1, mask2, shf_vec0, shf_vec1, shf_vec2);\n\n        VSHF_H3_SH(vt_res2, vt_res3, vt_res2, vt_res3, vt_res2, vt_res3,\n\n                   mask0, mask1, mask2, shf_vec3, shf_vec4, shf_vec5);\n\n\n\n        hz_res0 = __msa_hadd_s_w(shf_vec0, shf_vec0);\n\n        DPADD_SH2_SW(shf_vec1, shf_vec2, minus5h, plus20h, hz_res0, hz_res0);\n\n\n\n        hz_res1 = __msa_hadd_s_w(shf_vec3, shf_vec3);\n\n        DPADD_SH2_SW(shf_vec4, shf_vec5, minus5h, plus20h, hz_res1, hz_res1);\n\n\n\n        SRARI_W2_SW(hz_res0, hz_res1, 10);\n\n        SAT_SW2_SW(hz_res0, hz_res1, 7);\n\n\n\n        res0 = __msa_srari_h(shf_vec2, 5);\n\n        res1 = __msa_srari_h(shf_vec5, 5);\n\n\n\n        SAT_SH2_SH(res0, res1, 7);\n\n\n\n        if (horiz_offset) {\n\n            res0 = __msa_ilvod_h(zeros, res0);\n\n            res1 = __msa_ilvod_h(zeros, res1);\n\n        } else {\n\n            ILVEV_H2_SH(res0, zeros, res1, zeros, res0, res1);\n\n        }\n\n        hz_res0 = __msa_aver_s_w(hz_res0, (v4i32) res0);\n\n        hz_res1 = __msa_aver_s_w(hz_res1, (v4i32) res1);\n\n        res0 = __msa_pckev_h((v8i16) hz_res1, (v8i16) hz_res0);\n\n\n\n        res = PCKEV_XORI128_UB(res0, res0);\n\n\n\n        dst0 = __msa_aver_u_b(res, dst0);\n\n\n\n        ST4x2_UB(dst0, dst, dst_stride);\n\n        dst += (2 * dst_stride);\n\n\n\n        src0 = src2;\n\n        src1 = src3;\n\n        src2 = src4;\n\n        src3 = src5;\n\n        src4 = src6;\n\n    }\n\n}\n", "idx": 15578, "_split": "valid", "_hash": "8804e8a060e662c2df89c51466b82c8e"}
{"project": "FFmpeg", "commit_id": "e938637b2ca7587c2b349458189f1f7d7da87040", "target": 0, "func": "static int truespeech_decode_frame(AVCodecContext *avctx,\n\n                void *data, int *data_size,\n\n                uint8_t *buf, int buf_size)\n\n{\n\n    TSContext *c = avctx->priv_data;\n\n\n\n    int i;\n\n    short *samples = data;\n\n    int consumed = 0;\n\n    int16_t out_buf[240];\n\n\n\n    if (!buf_size)\n\n        return 0;\n\n\n\n    while (consumed < buf_size) {\n\n        truespeech_read_frame(c, buf + consumed);\n\n        consumed += 32;\n\n\n\n        truespeech_correlate_filter(c);\n\n        truespeech_filters_merge(c);\n\n\n\n        memset(out_buf, 0, 240 * 2);\n\n        for(i = 0; i < 4; i++) {\n\n            truespeech_apply_twopoint_filter(c, i);\n\n            truespeech_place_pulses(c, out_buf + i * 60, i);\n\n            truespeech_update_filters(c, out_buf + i * 60, i);\n\n            truespeech_synth(c, out_buf + i * 60, i);\n\n        }\n\n\n\n        truespeech_save_prevvec(c);\n\n\n\n        /* finally output decoded frame */\n\n        for(i = 0; i < 240; i++)\n\n            *samples++ = out_buf[i];\n\n\n\n    }\n\n\n\n    *data_size = consumed * 15;\n\n\n\n    return buf_size;\n\n}\n", "idx": 15635, "_split": "valid", "_hash": "a286c72d46bee7799b2210c08a100785"}
{"project": "FFmpeg", "commit_id": "a6ca08f1af31badb7fef93bc1cbfa78bffae6be7", "target": 0, "func": "static int gxf_write_trailer(AVFormatContext *s)\n\n{\n\n    GXFContext *gxf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int64_t end;\n\n    int i;\n\n\n\n    ff_audio_interleave_close(s);\n\n\n\n    gxf_write_eos_packet(pb);\n\n    end = avio_tell(pb);\n\n    avio_seek(pb, 0, SEEK_SET);\n\n    /* overwrite map, flt and umf packets with new values */\n\n    gxf_write_map_packet(s, 1);\n\n    gxf_write_flt_packet(s);\n\n    gxf_write_umf_packet(s);\n\n    avio_flush(pb);\n\n    /* update duration in all map packets */\n\n    for (i = 1; i < gxf->map_offsets_nb; i++) {\n\n        avio_seek(pb, gxf->map_offsets[i], SEEK_SET);\n\n        gxf_write_map_packet(s, 1);\n\n        avio_flush(pb);\n\n    }\n\n\n\n    avio_seek(pb, end, SEEK_SET);\n\n\n\n    av_freep(&gxf->flt_entries);\n\n    av_freep(&gxf->map_offsets);\n\n\n\n    return 0;\n\n}\n", "idx": 15693, "_split": "valid", "_hash": "8565d5877020c93b7a20c53eebb213e9"}
{"project": "FFmpeg", "commit_id": "6ff0ad6bfd0f00a3d54705811ee91a7ce3c22cda", "target": 0, "func": "void in_asm_used_var_warning_killer()\n\n{\n\n volatile int i= yCoeff+vrCoeff+ubCoeff+vgCoeff+ugCoeff+bF8+bFC+w400+w80+w10+\n\n bm00001111+bm00000111+bm11111000+b16Mask+g16Mask+r16Mask+b15Mask+g15Mask+r15Mask+asm_yalpha1+ asm_uvalpha1+\n\n M24A+M24B+M24C+w02 + b5Dither+g5Dither+r5Dither+g6Dither+dither4[0]+dither8[0];\n\n if(i) i=0;\n\n}\n", "idx": 15748, "_split": "valid", "_hash": "3ac33f9a11ff524d67d0ff18d0953586"}
{"project": "FFmpeg", "commit_id": "22d13e4290c8fdba57485e1b501f6a92283a10db", "target": 0, "func": "static double setup_compress_thresh(double threshold)\n\n{\n\n    if ((threshold > DBL_EPSILON) && (threshold < (1.0 - DBL_EPSILON))) {\n\n        double current_threshold = threshold;\n\n        double step_size = 1.0;\n\n\n\n        while (step_size > DBL_EPSILON) {\n\n            while ((current_threshold + step_size > current_threshold) &&\n\n                   (bound(current_threshold + step_size, 1.0) <= threshold)) {\n\n                current_threshold += step_size;\n\n            }\n\n\n\n            step_size /= 2.0;\n\n        }\n\n\n\n        return current_threshold;\n\n    } else {\n\n        return threshold;\n\n    }\n\n}\n", "idx": 15750, "_split": "valid", "_hash": "ee1b483526305c1d1e7681ebf3927e1a"}
{"project": "FFmpeg", "commit_id": "5626e812d2c1c202f749824905b70cdb8a845e7b", "target": 1, "func": "static av_always_inline int get_decoded_frame(AVFormatContext *fmt_ctx,\n\n                                              AVFrame *frame, int *got_frame,\n\n                                              AVPacket *pkt)\n\n{\n\n    AVCodecContext *dec_ctx = fmt_ctx->streams[pkt->stream_index]->codec;\n\n    int ret = 0;\n\n\n\n    *got_frame = 0;\n\n    if (dec_ctx->codec) {\n\n    switch (dec_ctx->codec_type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        ret = avcodec_decode_video2(dec_ctx, frame, got_frame, pkt);\n\n        break;\n\n\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        ret = avcodec_decode_audio4(dec_ctx, frame, got_frame, pkt);\n\n        break;\n\n\n\n\n\n    return ret;\n", "idx": 15754, "_split": "valid", "_hash": "c6be0df55958112d9227704cdf7c100c"}
{"project": "FFmpeg", "commit_id": "fe21f78d2bf1ac5b5400570a8a4031be3493aa7d", "target": 0, "func": "static int mpegps_probe(AVProbeData *p)\n\n{\n\n    uint32_t code= -1;\n\n    int sys=0, pspack=0, priv1=0, vid=0, audio=0, invalid=0;\n\n    int i;\n\n    int score=0;\n\n\n\n    for(i=0; i<p->buf_size; i++){\n\n        code = (code<<8) + p->buf[i];\n\n        if ((code & 0xffffff00) == 0x100) {\n\n            int len= p->buf[i+1] << 8 | p->buf[i+2];\n\n            int pes= check_pes(p->buf+i, p->buf+p->buf_size);\n\n\n\n            if(code == SYSTEM_HEADER_START_CODE) sys++;\n\n            else if(code == PACK_START_CODE)     pspack++;\n\n            else if((code & 0xf0) == VIDEO_ID &&  pes) vid++;\n\n            // skip pes payload to avoid start code emulation for private\n\n            // and audio streams\n\n            else if((code & 0xe0) == AUDIO_ID &&  pes) {audio++; i+=len;}\n\n            else if(code == PRIVATE_STREAM_1  &&  pes) {priv1++; i+=len;}\n\n\n\n            else if((code & 0xf0) == VIDEO_ID && !pes) invalid++;\n\n            else if((code & 0xe0) == AUDIO_ID && !pes) invalid++;\n\n            else if(code == PRIVATE_STREAM_1  && !pes) invalid++;\n\n        }\n\n    }\n\n\n\n    if(vid+audio > invalid)     /* invalid VDR files nd short PES streams */\n\n        score= AVPROBE_SCORE_MAX/4;\n\n\n\n//av_log(NULL, AV_LOG_ERROR, \"%d %d %d %d %d %d len:%d\\n\", sys, priv1, pspack,vid, audio, invalid, p->buf_size);\n\n    if(sys>invalid && sys*9 <= pspack*10)\n\n        return pspack > 2 ? AVPROBE_SCORE_MAX/2+2 : AVPROBE_SCORE_MAX/4; // +1 for .mpg\n\n    if(pspack > invalid && (priv1+vid+audio)*10 >= pspack*9)\n\n        return pspack > 2 ? AVPROBE_SCORE_MAX/2+2 : AVPROBE_SCORE_MAX/4; // +1 for .mpg\n\n    if((!!vid ^ !!audio) && (audio > 4 || vid > 1) && !sys && !pspack && p->buf_size>2048 && vid + audio > invalid) /* PES stream */\n\n        return (audio > 12 || vid > 3) ? AVPROBE_SCORE_MAX/2+2 : AVPROBE_SCORE_MAX/4;\n\n\n\n    //02-Penguin.flac has sys:0 priv1:0 pspack:0 vid:0 audio:1\n\n    //mp3_misidentified_2.mp3 has sys:0 priv1:0 pspack:0 vid:0 audio:6\n\n    return score;\n\n}\n", "idx": 15820, "_split": "valid", "_hash": "ec5ce2e625839bfc62d35ca255c631ec"}
{"project": "FFmpeg", "commit_id": "4ba6a534dc94bd4ff44503de9c7985a456cfe503", "target": 0, "func": "static int64_t http_seek(URLContext *h, int64_t off, int whence)\n\n{\n\n    HTTPContext *s = h->priv_data;\n\n    URLContext *old_hd = s->hd;\n\n    int64_t old_off = s->off;\n\n    uint8_t old_buf[BUFFER_SIZE];\n\n    int old_buf_size;\n\n    AVDictionary *options = NULL;\n\n\n\n    if (whence == AVSEEK_SIZE)\n\n        return s->filesize;\n\n    else if ((whence == SEEK_CUR && off == 0) || (whence == SEEK_SET && off == s->off))\n\n        return s->off;\n\n    else if ((s->filesize == -1 && whence == SEEK_END) || h->is_streamed)\n\n        return -1;\n\n\n\n    /* we save the old context in case the seek fails */\n\n    old_buf_size = s->buf_end - s->buf_ptr;\n\n    memcpy(old_buf, s->buf_ptr, old_buf_size);\n\n    s->hd = NULL;\n\n    if (whence == SEEK_CUR)\n\n        off += s->off;\n\n    else if (whence == SEEK_END)\n\n        off += s->filesize;\n\n    s->off = off;\n\n\n\n    /* if it fails, continue on old connection */\n\n    av_dict_copy(&options, s->chained_options, 0);\n\n    if (http_open_cnx(h, &options) < 0) {\n\n        av_dict_free(&options);\n\n        memcpy(s->buffer, old_buf, old_buf_size);\n\n        s->buf_ptr = s->buffer;\n\n        s->buf_end = s->buffer + old_buf_size;\n\n        s->hd = old_hd;\n\n        s->off = old_off;\n\n        return -1;\n\n    }\n\n    av_dict_free(&options);\n\n    ffurl_close(old_hd);\n\n    return off;\n\n}\n", "idx": 15931, "_split": "valid", "_hash": "0980db5313460a9ee0ef90248d914464"}
{"project": "FFmpeg", "commit_id": "c619e14c314b44d86a8d552259afb957c0b6775d", "target": 0, "func": "static int opus_packet(AVFormatContext *avf, int idx)\n\n{\n\n    struct ogg *ogg              = avf->priv_data;\n\n    struct ogg_stream *os        = &ogg->streams[idx];\n\n    AVStream *st                 = avf->streams[idx];\n\n    struct oggopus_private *priv = os->private;\n\n    uint8_t *packet              = os->buf + os->pstart;\n\n\n\n    if (!os->psize)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if ((!os->lastpts || os->lastpts == AV_NOPTS_VALUE) && !(os->flags & OGG_FLAG_EOS)) {\n\n        int seg, d;\n\n        int duration;\n\n        uint8_t *last_pkt  = os->buf + os->pstart;\n\n        uint8_t *next_pkt  = last_pkt;\n\n\n\n        duration = 0;\n\n        seg = os->segp;\n\n        d = opus_duration(last_pkt, os->psize);\n\n        if (d < 0) {\n\n            os->pflags |= AV_PKT_FLAG_CORRUPT;\n\n            return 0;\n\n        }\n\n        duration += d;\n\n        last_pkt = next_pkt =  next_pkt + os->psize;\n\n        for (; seg < os->nsegs; seg++) {\n\n            if (os->segments[seg] < 255) {\n\n                int d = opus_duration(last_pkt, os->segments[seg]);\n\n                if (d < 0) {\n\n                    duration = os->granule;\n\n                    break;\n\n                }\n\n                duration += d;\n\n                last_pkt  = next_pkt + os->segments[seg];\n\n            }\n\n            next_pkt += os->segments[seg];\n\n        }\n\n        os->lastpts                 =\n\n        os->lastdts                 = os->granule - duration;\n\n    }\n\n\n\n    os->pduration = opus_duration(packet, os->psize);\n\n    if (os->lastpts != AV_NOPTS_VALUE) {\n\n        if (st->start_time == AV_NOPTS_VALUE)\n\n            st->start_time = os->lastpts;\n\n        priv->cur_dts = os->lastdts = os->lastpts -= priv->pre_skip;\n\n    }\n\n\n\n    priv->cur_dts += os->pduration;\n\n    if ((os->flags & OGG_FLAG_EOS)) {\n\n        int64_t skip = priv->cur_dts - os->granule + priv->pre_skip;\n\n        skip = FFMIN(skip, os->pduration);\n\n        if (skip > 0) {\n\n            os->pduration = skip < os->pduration ? os->pduration - skip : 1;\n\n            os->end_trimming = skip;\n\n            av_log(avf, AV_LOG_DEBUG,\n\n                   \"Last packet was truncated to %d due to end trimming.\\n\",\n\n                   os->pduration);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 15986, "_split": "valid", "_hash": "48d86270abf6126058d82a37f02a745a"}
{"project": "FFmpeg", "commit_id": "8d7ce5cdb707d4b22749f72d3f118e62e2b95cd3", "target": 0, "func": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n\n{\n\n    NSVContext *nsv = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st[2] = {NULL, NULL};\n\n    NSVStream *nst;\n\n    AVPacket *pkt;\n\n    int i, err = 0;\n\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n\n    uint32_t vsize;\n\n    uint16_t asize;\n\n    uint16_t auxsize;\n\n\n\n    av_dlog(s, \"%s(%d)\\n\", __FUNCTION__, fill_header);\n\n\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\n\n\nnull_chunk_retry:\n\n    if (avio_feof(pb))\n\n        return -1;\n\n\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n\n        err = nsv_resync(s);\n\n    if (err < 0)\n\n        return err;\n\n    if (nsv->state == NSV_FOUND_NSVS)\n\n        err = nsv_parse_NSVs_header(s);\n\n    if (err < 0)\n\n        return err;\n\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n\n        return -1;\n\n\n\n    auxcount = avio_r8(pb);\n\n    vsize = avio_rl16(pb);\n\n    asize = avio_rl16(pb);\n\n    vsize = (vsize << 4) | (auxcount >> 4);\n\n    auxcount &= 0x0f;\n\n    av_dlog(s, \"NSV CHUNK %d aux, %u bytes video, %d bytes audio\\n\", auxcount, vsize, asize);\n\n    /* skip aux stuff */\n\n    for (i = 0; i < auxcount; i++) {\n\n        uint32_t av_unused auxtag;\n\n        auxsize = avio_rl16(pb);\n\n        auxtag = avio_rl32(pb);\n\n        av_dlog(s, \"NSV aux data: '%c%c%c%c', %d bytes\\n\",\n\n              (auxtag & 0x0ff),\n\n              ((auxtag >> 8) & 0x0ff),\n\n              ((auxtag >> 16) & 0x0ff),\n\n              ((auxtag >> 24) & 0x0ff),\n\n              auxsize);\n\n        avio_skip(pb, auxsize);\n\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming braindead */\n\n    }\n\n\n\n    if (avio_feof(pb))\n\n        return -1;\n\n    if (!vsize && !asize) {\n\n        nsv->state = NSV_UNSYNC;\n\n        goto null_chunk_retry;\n\n    }\n\n\n\n    /* map back streams to v,a */\n\n    if (s->nb_streams > 0)\n\n        st[s->streams[0]->id] = s->streams[0];\n\n    if (s->nb_streams > 1)\n\n        st[s->streams[1]->id] = s->streams[1];\n\n\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n\n        int ret;\n\n        nst = st[NSV_ST_VIDEO]->priv_data;\n\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n\n        if ((ret = av_get_packet(pb, pkt, vsize)) < 0)\n\n            return ret;\n\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n\n        pkt->dts = nst->frame_offset;\n\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n\n        for (i = 0; i < FFMIN(8, vsize); i++)\n\n            av_dlog(s, \"NSV video: [%d] = %02x\\n\", i, pkt->data[i]);\n\n    }\n\n    if(st[NSV_ST_VIDEO])\n\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n\n\n    if (asize && st[NSV_ST_AUDIO]) {\n\n        nst = st[NSV_ST_AUDIO]->priv_data;\n\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n\n        /* read raw audio specific header on the first audio chunk... */\n\n        /* on ALL audio chunks ?? seems so! */\n\n        if (asize && st[NSV_ST_AUDIO]->codec->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n\n            uint8_t bps;\n\n            uint8_t channels;\n\n            uint16_t samplerate;\n\n            bps = avio_r8(pb);\n\n            channels = avio_r8(pb);\n\n            samplerate = avio_rl16(pb);\n\n            asize-=4;\n\n            av_dlog(s, \"NSV RAWAUDIO: bps %d, nchan %d, srate %d\\n\", bps, channels, samplerate);\n\n            if (fill_header) {\n\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n\n                if (bps != 16) {\n\n                    av_dlog(s, \"NSV AUDIO bit/sample != 16 (%d)!!!\\n\", bps);\n\n                }\n\n                if(channels)\n\n                    bps /= channels; // ???\n\n                else\n\n                    av_log(s, AV_LOG_WARNING, \"Channels is 0\\n\");\n\n                if (bps == 8)\n\n                    st[NSV_ST_AUDIO]->codec->codec_id = AV_CODEC_ID_PCM_U8;\n\n                samplerate /= 4;/* UGH ??? XXX */\n\n                channels = 1;\n\n                st[NSV_ST_AUDIO]->codec->channels = channels;\n\n                st[NSV_ST_AUDIO]->codec->sample_rate = samplerate;\n\n                av_dlog(s, \"NSV RAWAUDIO: bps %d, nchan %d, srate %d\\n\", bps, channels, samplerate);\n\n            }\n\n        }\n\n        av_get_packet(pb, pkt, asize);\n\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n\n            /* on a nsvs frame we have new information on a/v sync */\n\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n\n            av_dlog(s, \"NSV AUDIO: sync:%d, dts:%\"PRId64, nsv->avsync, pkt->dts);\n\n        }\n\n        nst->frame_offset++;\n\n    }\n\n\n\n    nsv->state = NSV_UNSYNC;\n\n    return 0;\n\n}\n", "idx": 15993, "_split": "valid", "_hash": "1ac384f97d38ee30198e9a07d2b8fd02"}
{"project": "FFmpeg", "commit_id": "ce19aec15b4291dc48e791d89a1f940babc22cdc", "target": 0, "func": "static int decode_slice(MpegEncContext *s){\n\n    const int part_mask= s->partitioned_frame ? (ER_AC_END|ER_AC_ERROR) : 0x7F;\n\n    const int mb_size= 16>>s->avctx->lowres;\n\n    int ret;\n\n\n\n    s->last_resync_gb= s->gb;\n\n    s->first_slice_line= 1;\n\n\n\n    s->resync_mb_x= s->mb_x;\n\n    s->resync_mb_y= s->mb_y;\n\n\n\n    ff_set_qscale(s, s->qscale);\n\n\n\n    if (s->avctx->hwaccel) {\n\n        const uint8_t *start= s->gb.buffer + get_bits_count(&s->gb)/8;\n\n        const uint8_t *end  = ff_h263_find_resync_marker(start + 1, s->gb.buffer_end);\n\n        skip_bits_long(&s->gb, 8*(end - start));\n\n        return s->avctx->hwaccel->decode_slice(s->avctx, start, end - start);\n\n    }\n\n\n\n    if(s->partitioned_frame){\n\n        const int qscale= s->qscale;\n\n\n\n        if(CONFIG_MPEG4_DECODER && s->codec_id==AV_CODEC_ID_MPEG4){\n\n            if ((ret = ff_mpeg4_decode_partitions(s)) < 0)\n\n                return ret;\n\n        }\n\n\n\n        /* restore variables which were modified */\n\n        s->first_slice_line=1;\n\n        s->mb_x= s->resync_mb_x;\n\n        s->mb_y= s->resync_mb_y;\n\n        ff_set_qscale(s, qscale);\n\n    }\n\n\n\n    for(; s->mb_y < s->mb_height; s->mb_y++) {\n\n        /* per-row end of slice checks */\n\n        if(s->msmpeg4_version){\n\n            if(s->resync_mb_y + s->slice_height == s->mb_y){\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, ER_MB_END);\n\n\n\n                return 0;\n\n            }\n\n        }\n\n\n\n        if(s->msmpeg4_version==1){\n\n            s->last_dc[0]=\n\n            s->last_dc[1]=\n\n            s->last_dc[2]= 128;\n\n        }\n\n\n\n        ff_init_block_index(s);\n\n        for(; s->mb_x < s->mb_width; s->mb_x++) {\n\n            int ret;\n\n\n\n            ff_update_block_index(s);\n\n\n\n            if(s->resync_mb_x == s->mb_x && s->resync_mb_y+1 == s->mb_y){\n\n                s->first_slice_line=0;\n\n            }\n\n\n\n            /* DCT & quantize */\n\n\n\n            s->mv_dir = MV_DIR_FORWARD;\n\n            s->mv_type = MV_TYPE_16X16;\n\n//            s->mb_skipped = 0;\n\n            av_dlog(s, \"%d %d %06X\\n\",\n\n                    ret, get_bits_count(&s->gb), show_bits(&s->gb, 24));\n\n            ret= s->decode_mb(s, s->block);\n\n\n\n            if (s->pict_type!=AV_PICTURE_TYPE_B)\n\n                ff_h263_update_motion_val(s);\n\n\n\n            if(ret<0){\n\n                const int xy= s->mb_x + s->mb_y*s->mb_stride;\n\n                if(ret==SLICE_END){\n\n                    ff_MPV_decode_mb(s, s->block);\n\n                    if(s->loop_filter)\n\n                        ff_h263_loop_filter(s);\n\n\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, ER_MB_END&part_mask);\n\n\n\n                    s->padding_bug_score--;\n\n\n\n                    if(++s->mb_x >= s->mb_width){\n\n                        s->mb_x=0;\n\n                        ff_draw_horiz_band(s, s->mb_y*mb_size, mb_size);\n\n                        ff_MPV_report_decode_progress(s);\n\n                        s->mb_y++;\n\n                    }\n\n                    return 0;\n\n                }else if(ret==SLICE_NOEND){\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"Slice mismatch at MB: %d\\n\", xy);\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x+1, s->mb_y, ER_MB_END&part_mask);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Error at MB: %d\\n\", xy);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, ER_MB_ERROR&part_mask);\n\n\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            ff_MPV_decode_mb(s, s->block);\n\n            if(s->loop_filter)\n\n                ff_h263_loop_filter(s);\n\n        }\n\n\n\n        ff_draw_horiz_band(s, s->mb_y*mb_size, mb_size);\n\n        ff_MPV_report_decode_progress(s);\n\n\n\n        s->mb_x= 0;\n\n    }\n\n\n\n    assert(s->mb_x==0 && s->mb_y==s->mb_height);\n\n\n\n    if(s->codec_id==AV_CODEC_ID_MPEG4\n\n       && (s->workaround_bugs&FF_BUG_AUTODETECT)\n\n       && get_bits_left(&s->gb) >= 48\n\n       && show_bits(&s->gb, 24)==0x4010\n\n       && !s->data_partitioning)\n\n        s->padding_bug_score+=32;\n\n\n\n    /* try to detect the padding bug */\n\n    if(      s->codec_id==AV_CODEC_ID_MPEG4\n\n       &&   (s->workaround_bugs&FF_BUG_AUTODETECT)\n\n       &&    get_bits_left(&s->gb) >=0\n\n       &&    get_bits_left(&s->gb) < 137\n\n//       &&   !s->resync_marker\n\n       &&   !s->data_partitioning){\n\n\n\n        const int bits_count= get_bits_count(&s->gb);\n\n        const int bits_left = s->gb.size_in_bits - bits_count;\n\n\n\n        if(bits_left==0){\n\n            s->padding_bug_score+=16;\n\n        } else if(bits_left != 1){\n\n            int v= show_bits(&s->gb, 8);\n\n            v|= 0x7F >> (7-(bits_count&7));\n\n\n\n            if(v==0x7F && bits_left<=8)\n\n                s->padding_bug_score--;\n\n            else if(v==0x7F && ((get_bits_count(&s->gb)+8)&8) && bits_left<=16)\n\n                s->padding_bug_score+= 4;\n\n            else\n\n                s->padding_bug_score++;\n\n        }\n\n    }\n\n\n\n    if(s->workaround_bugs&FF_BUG_AUTODETECT){\n\n        if(s->padding_bug_score > -2 && !s->data_partitioning /*&& (s->divx_version>=0 || !s->resync_marker)*/)\n\n            s->workaround_bugs |=  FF_BUG_NO_PADDING;\n\n        else\n\n            s->workaround_bugs &= ~FF_BUG_NO_PADDING;\n\n    }\n\n\n\n    // handle formats which don't have unique end markers\n\n    if(s->msmpeg4_version || (s->workaround_bugs&FF_BUG_NO_PADDING)){ //FIXME perhaps solve this more cleanly\n\n        int left= get_bits_left(&s->gb);\n\n        int max_extra=7;\n\n\n\n        /* no markers in M$ crap */\n\n        if(s->msmpeg4_version && s->pict_type==AV_PICTURE_TYPE_I)\n\n            max_extra+= 17;\n\n\n\n        /* buggy padding but the frame should still end approximately at the bitstream end */\n\n        if((s->workaround_bugs&FF_BUG_NO_PADDING) && (s->err_recognition&(AV_EF_BUFFER|AV_EF_AGGRESSIVE)))\n\n            max_extra+= 48;\n\n        else if((s->workaround_bugs&FF_BUG_NO_PADDING))\n\n            max_extra+= 256*256*256*64;\n\n\n\n        if(left>max_extra){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"discarding %d junk bits at end, next would be %X\\n\", left, show_bits(&s->gb, 24));\n\n        }\n\n        else if(left<0){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"overreading %d bits\\n\", -left);\n\n        }else\n\n            ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, ER_MB_END);\n\n\n\n        return 0;\n\n    }\n\n\n\n    av_log(s->avctx, AV_LOG_ERROR, \"slice end not reached but screenspace end (%d left %06X, score= %d)\\n\",\n\n            get_bits_left(&s->gb),\n\n            show_bits(&s->gb, 24), s->padding_bug_score);\n\n\n\n    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, ER_MB_END&part_mask);\n\n\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 16063, "_split": "valid", "_hash": "058c594c89e346ad41a47e44387efe05"}
{"project": "FFmpeg", "commit_id": "4328e1fc424b01488bab10d60d2ffc0102c054a1", "target": 0, "func": "static void get_fcb_param(FCBParam *optim, int16_t *impulse_resp,\n\n                          int16_t *buf, int pulse_cnt, int pitch_lag)\n\n{\n\n    FCBParam param;\n\n    int16_t impulse_r[SUBFRAME_LEN];\n\n    int16_t temp_corr[SUBFRAME_LEN];\n\n    int16_t impulse_corr[SUBFRAME_LEN];\n\n\n\n    int ccr1[SUBFRAME_LEN];\n\n    int ccr2[SUBFRAME_LEN];\n\n    int amp, err, max, max_amp_index, min, scale, i, j, k, l;\n\n\n\n    int64_t temp;\n\n\n\n    /* Update impulse response */\n\n    memcpy(impulse_r, impulse_resp, sizeof(int16_t) * SUBFRAME_LEN);\n\n    param.dirac_train = 0;\n\n    if (pitch_lag < SUBFRAME_LEN - 2) {\n\n        param.dirac_train = 1;\n\n        gen_dirac_train(impulse_r, pitch_lag);\n\n    }\n\n\n\n    for (i = 0; i < SUBFRAME_LEN; i++)\n\n        temp_corr[i] = impulse_r[i] >> 1;\n\n\n\n    /* Compute impulse response autocorrelation */\n\n    temp = dot_product(temp_corr, temp_corr, SUBFRAME_LEN);\n\n\n\n    scale = normalize_bits_int32(temp);\n\n    impulse_corr[0] = av_clipl_int32((temp << scale) + (1 << 15)) >> 16;\n\n\n\n    for (i = 1; i < SUBFRAME_LEN; i++) {\n\n        temp = dot_product(temp_corr + i, temp_corr, SUBFRAME_LEN - i);\n\n        impulse_corr[i] = av_clipl_int32((temp << scale) + (1 << 15)) >> 16;\n\n    }\n\n\n\n    /* Compute crosscorrelation of impulse response with residual signal */\n\n    scale -= 4;\n\n    for (i = 0; i < SUBFRAME_LEN; i++){\n\n        temp = dot_product(buf + i, impulse_r, SUBFRAME_LEN - i);\n\n        if (scale < 0)\n\n            ccr1[i] = temp >> -scale;\n\n        else\n\n            ccr1[i] = av_clipl_int32(temp << scale);\n\n    }\n\n\n\n    /* Search loop */\n\n    for (i = 0; i < GRID_SIZE; i++) {\n\n        /* Maximize the crosscorrelation */\n\n        max = 0;\n\n        for (j = i; j < SUBFRAME_LEN; j += GRID_SIZE) {\n\n            temp = FFABS(ccr1[j]);\n\n            if (temp >= max) {\n\n                max = temp;\n\n                param.pulse_pos[0] = j;\n\n            }\n\n        }\n\n\n\n        /* Quantize the gain (max crosscorrelation/impulse_corr[0]) */\n\n        amp = max;\n\n        min = 1 << 30;\n\n        max_amp_index = GAIN_LEVELS - 2;\n\n        for (j = max_amp_index; j >= 2; j--) {\n\n            temp = av_clipl_int32((int64_t)fixed_cb_gain[j] *\n\n                                  impulse_corr[0] << 1);\n\n            temp = FFABS(temp - amp);\n\n            if (temp < min) {\n\n                min = temp;\n\n                max_amp_index = j;\n\n            }\n\n        }\n\n\n\n        max_amp_index--;\n\n        /* Select additional gain values */\n\n        for (j = 1; j < 5; j++) {\n\n            for (k = i; k < SUBFRAME_LEN; k += GRID_SIZE) {\n\n                temp_corr[k] = 0;\n\n                ccr2[k]      = ccr1[k];\n\n            }\n\n            param.amp_index = max_amp_index + j - 2;\n\n            amp = fixed_cb_gain[param.amp_index];\n\n\n\n            param.pulse_sign[0] = (ccr2[param.pulse_pos[0]] < 0) ? -amp : amp;\n\n            temp_corr[param.pulse_pos[0]] = 1;\n\n\n\n            for (k = 1; k < pulse_cnt; k++) {\n\n                max = -1 << 30;\n\n                for (l = i; l < SUBFRAME_LEN; l += GRID_SIZE) {\n\n                    if (temp_corr[l])\n\n                        continue;\n\n                    temp = impulse_corr[FFABS(l - param.pulse_pos[k - 1])];\n\n                    temp = av_clipl_int32((int64_t)temp *\n\n                                          param.pulse_sign[k - 1] << 1);\n\n                    ccr2[l] -= temp;\n\n                    temp = FFABS(ccr2[l]);\n\n                    if (temp > max) {\n\n                        max = temp;\n\n                        param.pulse_pos[k] = l;\n\n                    }\n\n                }\n\n\n\n                param.pulse_sign[k] = (ccr2[param.pulse_pos[k]] < 0) ?\n\n                                      -amp : amp;\n\n                temp_corr[param.pulse_pos[k]] = 1;\n\n            }\n\n\n\n            /* Create the error vector */\n\n            memset(temp_corr, 0, sizeof(int16_t) * SUBFRAME_LEN);\n\n\n\n            for (k = 0; k < pulse_cnt; k++)\n\n                temp_corr[param.pulse_pos[k]] = param.pulse_sign[k];\n\n\n\n            for (k = SUBFRAME_LEN - 1; k >= 0; k--) {\n\n                temp = 0;\n\n                for (l = 0; l <= k; l++) {\n\n                    int prod = av_clipl_int32((int64_t)temp_corr[l] *\n\n                                              impulse_r[k - l] << 1);\n\n                    temp     = av_clipl_int32(temp + prod);\n\n                }\n\n                temp_corr[k] = temp << 2 >> 16;\n\n            }\n\n\n\n            /* Compute square of error */\n\n            err = 0;\n\n            for (k = 0; k < SUBFRAME_LEN; k++) {\n\n                int64_t prod;\n\n                prod = av_clipl_int32((int64_t)buf[k] * temp_corr[k] << 1);\n\n                err  = av_clipl_int32(err - prod);\n\n                prod = av_clipl_int32((int64_t)temp_corr[k] * temp_corr[k]);\n\n                err  = av_clipl_int32(err + prod);\n\n            }\n\n\n\n            /* Minimize */\n\n            if (err < optim->min_err) {\n\n                optim->min_err     = err;\n\n                optim->grid_index  = i;\n\n                optim->amp_index   = param.amp_index;\n\n                optim->dirac_train = param.dirac_train;\n\n\n\n                for (k = 0; k < pulse_cnt; k++) {\n\n                    optim->pulse_sign[k] = param.pulse_sign[k];\n\n                    optim->pulse_pos[k]  = param.pulse_pos[k];\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 16074, "_split": "valid", "_hash": "9579dc0ef2d6372ebd494dfce0aac3ad"}
{"project": "FFmpeg", "commit_id": "5b0fc078191138795e817244555741356f9d12e9", "target": 1, "func": "static int vp9_decode_update_thread_context(AVCodecContext *dst, const AVCodecContext *src)\n\n{\n\n    int i, res;\n\n    VP9Context *s = dst->priv_data, *ssrc = src->priv_data;\n\n\n\n    // FIXME scalability, size, etc.\n\n\n\n    for (i = 0; i < 2; i++) {\n\n        if (s->frames[i].tf.f->data[0])\n\n            vp9_unref_frame(dst, &s->frames[i]);\n\n        if (ssrc->frames[i].tf.f->data[0]) {\n\n            if ((res = vp9_ref_frame(dst, &s->frames[i], &ssrc->frames[i])) < 0)\n\n                return res;\n\n        }\n\n    }\n\n    for (i = 0; i < 8; i++) {\n\n        if (s->refs[i].f->data[0])\n\n            ff_thread_release_buffer(dst, &s->refs[i]);\n\n        if (ssrc->next_refs[i].f->data[0]) {\n\n            if ((res = ff_thread_ref_frame(&s->refs[i], &ssrc->next_refs[i])) < 0)\n\n                return res;\n\n        }\n\n    }\n\n\n\n    s->invisible = ssrc->invisible;\n\n    s->keyframe = ssrc->keyframe;\n\n    s->uses_2pass = ssrc->uses_2pass;\n\n    memcpy(&s->prob_ctx, &ssrc->prob_ctx, sizeof(s->prob_ctx));\n\n    memcpy(&s->lf_delta, &ssrc->lf_delta, sizeof(s->lf_delta));\n\n    if (ssrc->segmentation.enabled) {\n\n        memcpy(&s->segmentation.feat, &ssrc->segmentation.feat,\n\n               sizeof(s->segmentation.feat));\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 16122, "_split": "valid", "_hash": "04aefbde25af47ac47c752831ced998f"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static inline int h263_mv4_search(MpegEncContext *s, int mx, int my, int shift)\n\n{\n\n    MotionEstContext * const c= &s->me;\n\n    const int size= 1;\n\n    const int h=8;\n\n    int block;\n\n    int P[10][2];\n\n    int dmin_sum=0, mx4_sum=0, my4_sum=0;\n\n    int same=1;\n\n    const int stride= c->stride;\n\n    uint8_t *mv_penalty= c->current_mv_penalty;\n\n\n\n    init_mv4_ref(c);\n\n\n\n    for(block=0; block<4; block++){\n\n        int mx4, my4;\n\n        int pred_x4, pred_y4;\n\n        int dmin4;\n\n        static const int off[4]= {2, 1, 1, -1};\n\n        const int mot_stride = s->b8_stride;\n\n        const int mot_xy = s->block_index[block];\n\n\n\n        P_LEFT[0] = s->current_picture.motion_val[0][mot_xy - 1][0];\n\n        P_LEFT[1] = s->current_picture.motion_val[0][mot_xy - 1][1];\n\n\n\n        if(P_LEFT[0]       > (c->xmax<<shift)) P_LEFT[0]       = (c->xmax<<shift);\n\n\n\n        /* special case for first line */\n\n        if (s->first_slice_line && block<2) {\n\n            c->pred_x= pred_x4= P_LEFT[0];\n\n            c->pred_y= pred_y4= P_LEFT[1];\n\n        } else {\n\n            P_TOP[0]      = s->current_picture.motion_val[0][mot_xy - mot_stride             ][0];\n\n            P_TOP[1]      = s->current_picture.motion_val[0][mot_xy - mot_stride             ][1];\n\n            P_TOPRIGHT[0] = s->current_picture.motion_val[0][mot_xy - mot_stride + off[block]][0];\n\n            P_TOPRIGHT[1] = s->current_picture.motion_val[0][mot_xy - mot_stride + off[block]][1];\n\n            if(P_TOP[1]      > (c->ymax<<shift)) P_TOP[1]     = (c->ymax<<shift);\n\n            if(P_TOPRIGHT[0] < (c->xmin<<shift)) P_TOPRIGHT[0]= (c->xmin<<shift);\n\n            if(P_TOPRIGHT[0] > (c->xmax<<shift)) P_TOPRIGHT[0]= (c->xmax<<shift);\n\n            if(P_TOPRIGHT[1] > (c->ymax<<shift)) P_TOPRIGHT[1]= (c->ymax<<shift);\n\n\n\n            P_MEDIAN[0]= mid_pred(P_LEFT[0], P_TOP[0], P_TOPRIGHT[0]);\n\n            P_MEDIAN[1]= mid_pred(P_LEFT[1], P_TOP[1], P_TOPRIGHT[1]);\n\n\n\n            c->pred_x= pred_x4 = P_MEDIAN[0];\n\n            c->pred_y= pred_y4 = P_MEDIAN[1];\n\n        }\n\n        P_MV1[0]= mx;\n\n        P_MV1[1]= my;\n\n\n\n        dmin4 = epzs_motion_search4(s, &mx4, &my4, P, block, block, s->p_mv_table, (1<<16)>>shift);\n\n\n\n        dmin4= c->sub_motion_search(s, &mx4, &my4, dmin4, block, block, size, h);\n\n\n\n        if(s->dsp.me_sub_cmp[0] != s->dsp.mb_cmp[0]){\n\n            int dxy;\n\n            const int offset= ((block&1) + (block>>1)*stride)*8;\n\n            uint8_t *dest_y = c->scratchpad + offset;\n\n            if(s->quarter_sample){\n\n                uint8_t *ref= c->ref[block][0] + (mx4>>2) + (my4>>2)*stride;\n\n                dxy = ((my4 & 3) << 2) | (mx4 & 3);\n\n\n\n                if(s->no_rounding)\n\n                    s->dsp.put_no_rnd_qpel_pixels_tab[1][dxy](dest_y   , ref    , stride);\n\n                else\n\n                    s->dsp.put_qpel_pixels_tab       [1][dxy](dest_y   , ref    , stride);\n\n            }else{\n\n                uint8_t *ref= c->ref[block][0] + (mx4>>1) + (my4>>1)*stride;\n\n                dxy = ((my4 & 1) << 1) | (mx4 & 1);\n\n\n\n                if(s->no_rounding)\n\n                    s->hdsp.put_no_rnd_pixels_tab[1][dxy](dest_y    , ref    , stride, h);\n\n                else\n\n                    s->hdsp.put_pixels_tab       [1][dxy](dest_y    , ref    , stride, h);\n\n            }\n\n            dmin_sum+= (mv_penalty[mx4-pred_x4] + mv_penalty[my4-pred_y4])*c->mb_penalty_factor;\n\n        }else\n\n            dmin_sum+= dmin4;\n\n\n\n        if(s->quarter_sample){\n\n            mx4_sum+= mx4/2;\n\n            my4_sum+= my4/2;\n\n        }else{\n\n            mx4_sum+= mx4;\n\n            my4_sum+= my4;\n\n        }\n\n\n\n        s->current_picture.motion_val[0][s->block_index[block]][0] = mx4;\n\n        s->current_picture.motion_val[0][s->block_index[block]][1] = my4;\n\n\n\n        if(mx4 != mx || my4 != my) same=0;\n\n    }\n\n\n\n    if(same)\n\n        return INT_MAX;\n\n\n\n    if(s->dsp.me_sub_cmp[0] != s->dsp.mb_cmp[0]){\n\n        dmin_sum += s->dsp.mb_cmp[0](s, s->new_picture.f.data[0] + s->mb_x*16 + s->mb_y*16*stride, c->scratchpad, stride, 16);\n\n    }\n\n\n\n    if(c->avctx->mb_cmp&FF_CMP_CHROMA){\n\n        int dxy;\n\n        int mx, my;\n\n        int offset;\n\n\n\n        mx= ff_h263_round_chroma(mx4_sum);\n\n        my= ff_h263_round_chroma(my4_sum);\n\n        dxy = ((my & 1) << 1) | (mx & 1);\n\n\n\n        offset= (s->mb_x*8 + (mx>>1)) + (s->mb_y*8 + (my>>1))*s->uvlinesize;\n\n\n\n        if(s->no_rounding){\n\n            s->hdsp.put_no_rnd_pixels_tab[1][dxy](c->scratchpad    , s->last_picture.f.data[1] + offset, s->uvlinesize, 8);\n\n            s->hdsp.put_no_rnd_pixels_tab[1][dxy](c->scratchpad + 8, s->last_picture.f.data[2] + offset, s->uvlinesize, 8);\n\n        }else{\n\n            s->hdsp.put_pixels_tab       [1][dxy](c->scratchpad    , s->last_picture.f.data[1] + offset, s->uvlinesize, 8);\n\n            s->hdsp.put_pixels_tab       [1][dxy](c->scratchpad + 8, s->last_picture.f.data[2] + offset, s->uvlinesize, 8);\n\n        }\n\n\n\n        dmin_sum += s->dsp.mb_cmp[1](s, s->new_picture.f.data[1] + s->mb_x*8 + s->mb_y*8*s->uvlinesize, c->scratchpad  , s->uvlinesize, 8);\n\n        dmin_sum += s->dsp.mb_cmp[1](s, s->new_picture.f.data[2] + s->mb_x*8 + s->mb_y*8*s->uvlinesize, c->scratchpad+8, s->uvlinesize, 8);\n\n    }\n\n\n\n    c->pred_x= mx;\n\n    c->pred_y= my;\n\n\n\n    switch(c->avctx->mb_cmp&0xFF){\n\n    /*case FF_CMP_SSE:\n\n        return dmin_sum+ 32*s->qscale*s->qscale;*/\n\n    case FF_CMP_RD:\n\n        return dmin_sum;\n\n    default:\n\n        return dmin_sum+ 11*c->mb_penalty_factor;\n\n    }\n\n}\n", "idx": 16132, "_split": "valid", "_hash": "d2c853b13e8424374ff4bac25a1dbe53"}
{"project": "FFmpeg", "commit_id": "2758cdedfb7ac61f8b5e4861f99218b6fd43491d", "target": 0, "func": "static int url_alloc_for_protocol(URLContext **puc, struct URLProtocol *up,\n\n                                  const char *filename, int flags,\n\n                                  const AVIOInterruptCB *int_cb)\n\n{\n\n    URLContext *uc;\n\n    int err;\n\n\n\n#if CONFIG_NETWORK\n\n    if (up->flags & URL_PROTOCOL_FLAG_NETWORK && !ff_network_init())\n\n        return AVERROR(EIO);\n\n#endif\n\n    uc = av_mallocz(sizeof(URLContext) + strlen(filename) + 1);\n\n    if (!uc) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    uc->av_class = &ffurl_context_class;\n\n    uc->filename = (char *)&uc[1];\n\n    strcpy(uc->filename, filename);\n\n    uc->prot            = up;\n\n    uc->flags           = flags;\n\n    uc->is_streamed     = 0; /* default = not streamed */\n\n    uc->max_packet_size = 0; /* default: stream file */\n\n    if (up->priv_data_size) {\n\n        uc->priv_data = av_mallocz(up->priv_data_size);\n\n        if (!uc->priv_data) {\n\n            err = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        if (up->priv_data_class) {\n\n            *(const AVClass **)uc->priv_data = up->priv_data_class;\n\n            av_opt_set_defaults(uc->priv_data);\n\n        }\n\n    }\n\n    if (int_cb)\n\n        uc->interrupt_callback = *int_cb;\n\n\n\n    *puc = uc;\n\n    return 0;\n\nfail:\n\n    *puc = NULL;\n\n    if (uc)\n\n        av_freep(&uc->priv_data);\n\n    av_freep(&uc);\n\n#if CONFIG_NETWORK\n\n    if (up->flags & URL_PROTOCOL_FLAG_NETWORK)\n\n        ff_network_close();\n\n#endif\n\n    return err;\n\n}\n", "idx": 16184, "_split": "valid", "_hash": "6d8612d631373c64d0245ee0e61b7a89"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int rv10_decode_packet(AVCodecContext *avctx, const uint8_t *buf,\n\n                              int buf_size, int buf_size2)\n\n{\n\n    RVDecContext *rv = avctx->priv_data;\n\n    MpegEncContext *s = &rv->m;\n\n    int mb_count, mb_pos, left, start_mb_x, active_bits_size, ret;\n\n\n\n    active_bits_size = buf_size * 8;\n\n    init_get_bits(&s->gb, buf, FFMAX(buf_size, buf_size2) * 8);\n\n    if (s->codec_id == AV_CODEC_ID_RV10)\n\n        mb_count = rv10_decode_picture_header(s);\n\n    else\n\n        mb_count = rv20_decode_picture_header(rv);\n\n    if (mb_count < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"HEADER ERROR\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->mb_x >= s->mb_width ||\n\n        s->mb_y >= s->mb_height) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"POS ERROR %d %d\\n\", s->mb_x, s->mb_y);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    mb_pos = s->mb_y * s->mb_width + s->mb_x;\n\n    left   = s->mb_width * s->mb_height - mb_pos;\n\n    if (mb_count > left) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"COUNT ERROR\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((s->mb_x == 0 && s->mb_y == 0) || s->current_picture_ptr == NULL) {\n\n        // FIXME write parser so we always have complete frames?\n\n        if (s->current_picture_ptr) {\n\n            ff_er_frame_end(&s->er);\n\n            ff_mpv_frame_end(s);\n\n            s->mb_x = s->mb_y = s->resync_mb_x = s->resync_mb_y = 0;\n\n        }\n\n        if ((ret = ff_mpv_frame_start(s, avctx)) < 0)\n\n            return ret;\n\n        ff_mpeg_er_frame_start(s);\n\n    } else {\n\n        if (s->current_picture_ptr->f->pict_type != s->pict_type) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Slice type mismatch\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    av_dlog(avctx, \"qscale=%d\\n\", s->qscale);\n\n\n\n    /* default quantization values */\n\n    if (s->codec_id == AV_CODEC_ID_RV10) {\n\n        if (s->mb_y == 0)\n\n            s->first_slice_line = 1;\n\n    } else {\n\n        s->first_slice_line = 1;\n\n        s->resync_mb_x      = s->mb_x;\n\n    }\n\n    start_mb_x     = s->mb_x;\n\n    s->resync_mb_y = s->mb_y;\n\n    if (s->h263_aic) {\n\n        s->y_dc_scale_table =\n\n        s->c_dc_scale_table = ff_aic_dc_scale_table;\n\n    } else {\n\n        s->y_dc_scale_table =\n\n        s->c_dc_scale_table = ff_mpeg1_dc_scale_table;\n\n    }\n\n\n\n    if (s->modified_quant)\n\n        s->chroma_qscale_table = ff_h263_chroma_qscale_table;\n\n\n\n    ff_set_qscale(s, s->qscale);\n\n\n\n    s->rv10_first_dc_coded[0] = 0;\n\n    s->rv10_first_dc_coded[1] = 0;\n\n    s->rv10_first_dc_coded[2] = 0;\n\n    s->block_wrap[0] =\n\n    s->block_wrap[1] =\n\n    s->block_wrap[2] =\n\n    s->block_wrap[3] = s->b8_stride;\n\n    s->block_wrap[4] =\n\n    s->block_wrap[5] = s->mb_stride;\n\n    ff_init_block_index(s);\n\n\n\n    /* decode each macroblock */\n\n    for (s->mb_num_left = mb_count; s->mb_num_left > 0; s->mb_num_left--) {\n\n        int ret;\n\n        ff_update_block_index(s);\n\n        av_dlog(avctx, \"**mb x=%d y=%d\\n\", s->mb_x, s->mb_y);\n\n\n\n        s->mv_dir  = MV_DIR_FORWARD;\n\n        s->mv_type = MV_TYPE_16X16;\n\n        ret = ff_h263_decode_mb(s, s->block);\n\n\n\n        // Repeat the slice end check from ff_h263_decode_mb with our active\n\n        // bitstream size\n\n        if (ret != SLICE_ERROR) {\n\n            int v = show_bits(&s->gb, 16);\n\n\n\n            if (get_bits_count(&s->gb) + 16 > active_bits_size)\n\n                v >>= get_bits_count(&s->gb) + 16 - active_bits_size;\n\n\n\n            if (!v)\n\n                ret = SLICE_END;\n\n        }\n\n        if (ret != SLICE_ERROR && active_bits_size < get_bits_count(&s->gb) &&\n\n            8 * buf_size2 >= get_bits_count(&s->gb)) {\n\n            active_bits_size = buf_size2 * 8;\n\n            av_log(avctx, AV_LOG_DEBUG, \"update size from %d to %d\\n\",\n\n                   8 * buf_size, active_bits_size);\n\n            ret = SLICE_OK;\n\n        }\n\n\n\n        if (ret == SLICE_ERROR || active_bits_size < get_bits_count(&s->gb)) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"ERROR at MB %d %d\\n\", s->mb_x,\n\n                   s->mb_y);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n\n            ff_h263_update_motion_val(s);\n\n        ff_mpv_decode_mb(s, s->block);\n\n        if (s->loop_filter)\n\n            ff_h263_loop_filter(s);\n\n\n\n        if (++s->mb_x == s->mb_width) {\n\n            s->mb_x = 0;\n\n            s->mb_y++;\n\n            ff_init_block_index(s);\n\n        }\n\n        if (s->mb_x == s->resync_mb_x)\n\n            s->first_slice_line = 0;\n\n        if (ret == SLICE_END)\n\n            break;\n\n    }\n\n\n\n    ff_er_add_slice(&s->er, start_mb_x, s->resync_mb_y, s->mb_x - 1, s->mb_y,\n\n                    ER_MB_END);\n\n\n\n    return active_bits_size;\n\n}\n", "idx": 16185, "_split": "valid", "_hash": "493763da9357c5bc378a204b2750741f"}
{"project": "FFmpeg", "commit_id": "6eb2505855fa832ba7d0a1c2fb9f92c41c5446e3", "target": 0, "func": "static int parse_pixel_format(AVCodecContext *avctx)\n\n{\n\n    DDSContext *ctx = avctx->priv_data;\n\n    GetByteContext *gbc = &ctx->gbc;\n\n    char buf[32];\n\n    uint32_t flags, fourcc, gimp_tag;\n\n    enum DDSDXGIFormat dxgi;\n\n    int size, bpp, r, g, b, a;\n\n    int alpha_exponent, ycocg_classic, ycocg_scaled, normal_map, array;\n\n\n\n    /* Alternative DDS implementations use reserved1 as custom header. */\n\n    bytestream2_skip(gbc, 4 * 3);\n\n    gimp_tag = bytestream2_get_le32(gbc);\n\n    alpha_exponent = gimp_tag == MKTAG('A', 'E', 'X', 'P');\n\n    ycocg_classic  = gimp_tag == MKTAG('Y', 'C', 'G', '1');\n\n    ycocg_scaled   = gimp_tag == MKTAG('Y', 'C', 'G', '2');\n\n    bytestream2_skip(gbc, 4 * 7);\n\n\n\n    /* Now the real DDPF starts. */\n\n    size = bytestream2_get_le32(gbc);\n\n    if (size != 32) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid pixel format header %d.\\n\", size);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    flags = bytestream2_get_le32(gbc);\n\n    ctx->compressed = flags & DDPF_FOURCC;\n\n    ctx->paletted   = flags & DDPF_PALETTE;\n\n    normal_map      = flags & DDPF_NORMALMAP;\n\n    fourcc = bytestream2_get_le32(gbc);\n\n\n\n    if (ctx->compressed && ctx->paletted) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Disabling invalid palette flag for compressed dds.\\n\");\n\n        ctx->paletted = 0;\n\n    }\n\n\n\n    bpp = bytestream2_get_le32(gbc); // rgbbitcount\n\n    r   = bytestream2_get_le32(gbc); // rbitmask\n\n    g   = bytestream2_get_le32(gbc); // gbitmask\n\n    b   = bytestream2_get_le32(gbc); // bbitmask\n\n    a   = bytestream2_get_le32(gbc); // abitmask\n\n\n\n    bytestream2_skip(gbc, 4); // caps\n\n    bytestream2_skip(gbc, 4); // caps2\n\n    bytestream2_skip(gbc, 4); // caps3\n\n    bytestream2_skip(gbc, 4); // caps4\n\n    bytestream2_skip(gbc, 4); // reserved2\n\n\n\n    av_get_codec_tag_string(buf, sizeof(buf), fourcc);\n\n    av_log(avctx, AV_LOG_VERBOSE, \"fourcc %s bpp %d \"\n\n           \"r 0x%x g 0x%x b 0x%x a 0x%x\\n\", buf, bpp, r, g, b, a);\n\n    if (gimp_tag) {\n\n        av_get_codec_tag_string(buf, sizeof(buf), gimp_tag);\n\n        av_log(avctx, AV_LOG_VERBOSE, \"and GIMP-DDS tag %s\\n\", buf);\n\n    }\n\n\n\n    if (ctx->compressed)\n\n        avctx->pix_fmt = AV_PIX_FMT_RGBA;\n\n\n\n    if (ctx->compressed) {\n\n        switch (fourcc) {\n\n        case MKTAG('D', 'X', 'T', '1'):\n\n            ctx->tex_ratio = 8;\n\n            ctx->tex_funct = ctx->texdsp.dxt1a_block;\n\n            break;\n\n        case MKTAG('D', 'X', 'T', '2'):\n\n            ctx->tex_ratio = 16;\n\n            ctx->tex_funct = ctx->texdsp.dxt2_block;\n\n            break;\n\n        case MKTAG('D', 'X', 'T', '3'):\n\n            ctx->tex_ratio = 16;\n\n            ctx->tex_funct = ctx->texdsp.dxt3_block;\n\n            break;\n\n        case MKTAG('D', 'X', 'T', '4'):\n\n            ctx->tex_ratio = 16;\n\n            ctx->tex_funct = ctx->texdsp.dxt4_block;\n\n            break;\n\n        case MKTAG('D', 'X', 'T', '5'):\n\n            ctx->tex_ratio = 16;\n\n            if (ycocg_scaled)\n\n                ctx->tex_funct = ctx->texdsp.dxt5ys_block;\n\n            else if (ycocg_classic)\n\n                ctx->tex_funct = ctx->texdsp.dxt5y_block;\n\n            else\n\n                ctx->tex_funct = ctx->texdsp.dxt5_block;\n\n            break;\n\n        case MKTAG('R', 'X', 'G', 'B'):\n\n            ctx->tex_ratio = 16;\n\n            ctx->tex_funct = ctx->texdsp.dxt5_block;\n\n            /* This format may be considered as a normal map,\n\n             * but it is handled differently in a separate postproc. */\n\n            ctx->postproc = DDS_SWIZZLE_RXGB;\n\n            normal_map = 0;\n\n            break;\n\n        case MKTAG('A', 'T', 'I', '1'):\n\n        case MKTAG('B', 'C', '4', 'U'):\n\n            ctx->tex_ratio = 8;\n\n            ctx->tex_funct = ctx->texdsp.rgtc1u_block;\n\n            break;\n\n        case MKTAG('B', 'C', '4', 'S'):\n\n            ctx->tex_ratio = 8;\n\n            ctx->tex_funct = ctx->texdsp.rgtc1s_block;\n\n            break;\n\n        case MKTAG('A', 'T', 'I', '2'):\n\n            /* RGT2 variant with swapped R and G (3Dc)*/\n\n            ctx->tex_ratio = 16;\n\n            ctx->tex_funct = ctx->texdsp.dxn3dc_block;\n\n            break;\n\n        case MKTAG('B', 'C', '5', 'U'):\n\n            ctx->tex_ratio = 16;\n\n            ctx->tex_funct = ctx->texdsp.rgtc2u_block;\n\n            break;\n\n        case MKTAG('B', 'C', '5', 'S'):\n\n            ctx->tex_ratio = 16;\n\n            ctx->tex_funct = ctx->texdsp.rgtc2s_block;\n\n            break;\n\n        case MKTAG('U', 'Y', 'V', 'Y'):\n\n            ctx->compressed = 0;\n\n            avctx->pix_fmt = AV_PIX_FMT_UYVY422;\n\n            break;\n\n        case MKTAG('Y', 'U', 'Y', '2'):\n\n            ctx->compressed = 0;\n\n            avctx->pix_fmt = AV_PIX_FMT_YUYV422;\n\n            break;\n\n        case MKTAG('P', '8', ' ', ' '):\n\n            /* ATI Palette8, same as normal palette */\n\n            ctx->compressed = 0;\n\n            ctx->paletted   = 1;\n\n            avctx->pix_fmt  = AV_PIX_FMT_PAL8;\n\n            break;\n\n        case MKTAG('D', 'X', '1', '0'):\n\n            /* DirectX 10 extra header */\n\n            dxgi = bytestream2_get_le32(gbc);\n\n            bytestream2_skip(gbc, 4); // resourceDimension\n\n            bytestream2_skip(gbc, 4); // miscFlag\n\n            array = bytestream2_get_le32(gbc);\n\n            bytestream2_skip(gbc, 4); // miscFlag2\n\n\n\n            if (array != 0)\n\n                av_log(avctx, AV_LOG_VERBOSE,\n\n                       \"Found array of size %d (ignored).\\n\", array);\n\n\n\n            /* Only BC[1-5] are actually compressed. */\n\n            ctx->compressed = (dxgi >= 70) && (dxgi <= 84);\n\n\n\n            av_log(avctx, AV_LOG_VERBOSE, \"DXGI format %d.\\n\", dxgi);\n\n            switch (dxgi) {\n\n            /* RGB types. */\n\n            case DXGI_FORMAT_R16G16B16A16_TYPELESS:\n\n            case DXGI_FORMAT_R16G16B16A16_FLOAT:\n\n            case DXGI_FORMAT_R16G16B16A16_UNORM:\n\n            case DXGI_FORMAT_R16G16B16A16_UINT:\n\n            case DXGI_FORMAT_R16G16B16A16_SNORM:\n\n            case DXGI_FORMAT_R16G16B16A16_SINT:\n\n                avctx->pix_fmt = AV_PIX_FMT_BGRA64;\n\n                break;\n\n            case DXGI_FORMAT_R8G8B8A8_UNORM_SRGB:\n\n                avctx->colorspace = AVCOL_SPC_RGB;\n\n            case DXGI_FORMAT_R8G8B8A8_TYPELESS:\n\n            case DXGI_FORMAT_R8G8B8A8_UNORM:\n\n            case DXGI_FORMAT_R8G8B8A8_UINT:\n\n            case DXGI_FORMAT_R8G8B8A8_SNORM:\n\n            case DXGI_FORMAT_R8G8B8A8_SINT:\n\n                avctx->pix_fmt = AV_PIX_FMT_BGRA;\n\n                break;\n\n            case DXGI_FORMAT_B8G8R8A8_UNORM_SRGB:\n\n                avctx->colorspace = AVCOL_SPC_RGB;\n\n            case DXGI_FORMAT_B8G8R8A8_TYPELESS:\n\n            case DXGI_FORMAT_B8G8R8A8_UNORM:\n\n                avctx->pix_fmt = AV_PIX_FMT_RGBA;\n\n                break;\n\n            case DXGI_FORMAT_B8G8R8X8_UNORM_SRGB:\n\n                avctx->colorspace = AVCOL_SPC_RGB;\n\n            case DXGI_FORMAT_B8G8R8X8_TYPELESS:\n\n            case DXGI_FORMAT_B8G8R8X8_UNORM:\n\n                avctx->pix_fmt = AV_PIX_FMT_RGBA; // opaque\n\n                break;\n\n            case DXGI_FORMAT_B5G6R5_UNORM:\n\n                avctx->pix_fmt = AV_PIX_FMT_RGB565LE;\n\n                break;\n\n            /* Texture types. */\n\n            case DXGI_FORMAT_BC1_UNORM_SRGB:\n\n                avctx->colorspace = AVCOL_SPC_RGB;\n\n            case DXGI_FORMAT_BC1_TYPELESS:\n\n            case DXGI_FORMAT_BC1_UNORM:\n\n                ctx->tex_ratio = 8;\n\n                ctx->tex_funct = ctx->texdsp.dxt1a_block;\n\n                break;\n\n            case DXGI_FORMAT_BC2_UNORM_SRGB:\n\n                avctx->colorspace = AVCOL_SPC_RGB;\n\n            case DXGI_FORMAT_BC2_TYPELESS:\n\n            case DXGI_FORMAT_BC2_UNORM:\n\n                ctx->tex_ratio = 16;\n\n                ctx->tex_funct = ctx->texdsp.dxt3_block;\n\n                break;\n\n            case DXGI_FORMAT_BC3_UNORM_SRGB:\n\n                avctx->colorspace = AVCOL_SPC_RGB;\n\n            case DXGI_FORMAT_BC3_TYPELESS:\n\n            case DXGI_FORMAT_BC3_UNORM:\n\n                ctx->tex_ratio = 16;\n\n                ctx->tex_funct = ctx->texdsp.dxt5_block;\n\n                break;\n\n            case DXGI_FORMAT_BC4_TYPELESS:\n\n            case DXGI_FORMAT_BC4_UNORM:\n\n                ctx->tex_ratio = 8;\n\n                ctx->tex_funct = ctx->texdsp.rgtc1u_block;\n\n                break;\n\n            case DXGI_FORMAT_BC4_SNORM:\n\n                ctx->tex_ratio = 8;\n\n                ctx->tex_funct = ctx->texdsp.rgtc1s_block;\n\n                break;\n\n            case DXGI_FORMAT_BC5_TYPELESS:\n\n            case DXGI_FORMAT_BC5_UNORM:\n\n                ctx->tex_ratio = 16;\n\n                ctx->tex_funct = ctx->texdsp.rgtc2u_block;\n\n                break;\n\n            case DXGI_FORMAT_BC5_SNORM:\n\n                ctx->tex_ratio = 16;\n\n                ctx->tex_funct = ctx->texdsp.rgtc2s_block;\n\n                break;\n\n            default:\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"Unsupported DXGI format %d.\\n\", dxgi);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported %s fourcc.\\n\", buf);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else if (ctx->paletted) {\n\n        if (bpp == 8) {\n\n            avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n        } else {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported palette bpp %d.\\n\", bpp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else {\n\n        /*  8 bpp */\n\n        if (bpp == 8 && r == 0xff && g == 0 && b == 0 && a == 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n\n        else if (bpp == 8 && r == 0 && g == 0 && b == 0 && a == 0xff)\n\n            avctx->pix_fmt = AV_PIX_FMT_GRAY8;\n\n        /* 16 bpp */\n\n        else if (bpp == 16 && r == 0xff && g == 0 && b == 0 && a == 0xff00)\n\n            avctx->pix_fmt = AV_PIX_FMT_YA8;\n\n        else if (bpp == 16 && r == 0xffff && g == 0 && b == 0 && a == 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_GRAY16LE;\n\n        else if (bpp == 16 && r == 0x7c00 && g == 0x3e0 && b == 0x1f && a == 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_RGB555LE;\n\n        else if (bpp == 16 && r == 0x7c00 && g == 0x3e0 && b == 0x1f && a == 0x8000)\n\n            avctx->pix_fmt = AV_PIX_FMT_RGB555LE; // alpha ignored\n\n        else if (bpp == 16 && r == 0xf800 && g == 0x7e0 && b == 0x1f && a == 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_RGB565LE;\n\n        /* 24 bpp */\n\n        else if (bpp == 24 && r == 0xff0000 && g == 0xff00 && b == 0xff && a == 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_BGR24;\n\n        /* 32 bpp */\n\n        else if (bpp == 32 && r == 0xff0000 && g == 0xff00 && b == 0xff && a == 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_BGRA; // opaque\n\n        else if (bpp == 32 && r == 0xff && g == 0xff00 && b == 0xff0000 && a == 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_RGBA; // opaque\n\n        else if (bpp == 32 && r == 0xff0000 && g == 0xff00 && b == 0xff && a == 0xff000000)\n\n            avctx->pix_fmt = AV_PIX_FMT_BGRA;\n\n        else if (bpp == 32 && r == 0xff && g == 0xff00 && b == 0xff0000 && a == 0xff000000)\n\n            avctx->pix_fmt = AV_PIX_FMT_RGBA;\n\n        /* give up */\n\n        else {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unknown pixel format \"\n\n                   \"[bpp %d r 0x%x g 0x%x b 0x%x a 0x%x].\\n\", bpp, r, g, b, a);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* Set any remaining post-proc that should happen before frame is ready. */\n\n    if (alpha_exponent)\n\n        ctx->postproc = DDS_ALPHA_EXP;\n\n    else if (normal_map)\n\n        ctx->postproc = DDS_NORMAL_MAP;\n\n    else if (ycocg_classic && !ctx->compressed)\n\n        ctx->postproc = DDS_RAW_YCOCG;\n\n    else if (avctx->pix_fmt == AV_PIX_FMT_YA8)\n\n        ctx->postproc = DDS_SWAP_ALPHA;\n\n\n\n    /* ATI/NVidia variants sometimes add swizzling in bpp. */\n\n    switch (bpp) {\n\n    case MKTAG('A', '2', 'X', 'Y'):\n\n        ctx->postproc = DDS_SWIZZLE_A2XY;\n\n        break;\n\n    case MKTAG('x', 'G', 'B', 'R'):\n\n        ctx->postproc = DDS_SWIZZLE_XGBR;\n\n        break;\n\n    case MKTAG('x', 'R', 'B', 'G'):\n\n        ctx->postproc = DDS_SWIZZLE_XRBG;\n\n        break;\n\n    case MKTAG('R', 'B', 'x', 'G'):\n\n        ctx->postproc = DDS_SWIZZLE_RBXG;\n\n        break;\n\n    case MKTAG('R', 'G', 'x', 'B'):\n\n        ctx->postproc = DDS_SWIZZLE_RGXB;\n\n        break;\n\n    case MKTAG('R', 'x', 'B', 'G'):\n\n        ctx->postproc = DDS_SWIZZLE_RXBG;\n\n        break;\n\n    case MKTAG('x', 'G', 'x', 'R'):\n\n        ctx->postproc = DDS_SWIZZLE_XGXR;\n\n        break;\n\n    case MKTAG('A', '2', 'D', '5'):\n\n        ctx->postproc = DDS_NORMAL_MAP;\n\n        break;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 16254, "_split": "valid", "_hash": "198fbabb38ac0efbe11b4ce3ece9395b"}
{"project": "FFmpeg", "commit_id": "93dfc4f174d89ad4c9a76fb542ddfed138e4f01b", "target": 0, "func": "static int svc_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    SVCContext *s = avctx->priv_data;\n\n    SBufferInfo info = { 0 };\n\n    uint8_t* ptrs[3];\n\n    int linesize[3];\n\n    AVFrame *avframe = data;\n\n    DECODING_STATE state;\n\n\n\n    state = (*s->decoder)->DecodeFrame2(s->decoder, avpkt->data, avpkt->size, ptrs, &info);\n\n    if (state != dsErrorFree) {\n\n        av_log(avctx, AV_LOG_ERROR, \"DecodeFrame2 failed\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n    if (info.iBufferStatus != 1) {\n\n        av_log(avctx, AV_LOG_DEBUG, \"No frame produced\\n\");\n\n        return avpkt->size;\n\n    }\n\n\n\n    ff_set_dimensions(avctx, info.UsrData.sSystemBuffer.iWidth, info.UsrData.sSystemBuffer.iHeight);\n\n    // The decoder doesn't (currently) support decoding into a user\n\n    // provided buffer, so do a copy instead.\n\n    if (ff_get_buffer(avctx, avframe, 0) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to allocate buffer\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    linesize[0] = info.UsrData.sSystemBuffer.iStride[0];\n\n    linesize[1] = linesize[2] = info.UsrData.sSystemBuffer.iStride[1];\n\n    av_image_copy(avframe->data, avframe->linesize, (const uint8_t **) ptrs, linesize, avctx->pix_fmt, avctx->width, avctx->height);\n\n\n\n    avframe->pts     = avpkt->pts;\n\n    avframe->pkt_dts = avpkt->dts;\n\n#if FF_API_PKT_PTS\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    avframe->pkt_pts = avpkt->pts;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    *got_frame = 1;\n\n    return avpkt->size;\n\n}\n", "idx": 16257, "_split": "valid", "_hash": "572d3a364a8e8f0514bc442a727ba74a"}
{"project": "FFmpeg", "commit_id": "ef8740d8e58dc45950887305307206d27ad413fb", "target": 1, "func": "static av_always_inline void iadst4_1d(const dctcoef *in, ptrdiff_t stride,\n\n                                       dctcoef *out, int pass)\n\n{\n\n    int t0, t1, t2, t3;\n\n\n\n    t0 =  5283 * IN(0) + 15212 * IN(2) +  9929 * IN(3);\n\n    t1 =  9929 * IN(0) -  5283 * IN(2) - 15212 * IN(3);\n\n    t2 = 13377 * (IN(0) - IN(2) + IN(3));\n\n    t3 = 13377 * IN(1);\n\n\n\n    out[0] = (t0 + t3      + (1 << 13)) >> 14;\n\n    out[1] = (t1 + t3      + (1 << 13)) >> 14;\n\n    out[2] = (t2           + (1 << 13)) >> 14;\n\n    out[3] = (t0 + t1 - t3 + (1 << 13)) >> 14;\n\n}\n", "idx": 16290, "_split": "valid", "_hash": "add22790797284705f1b510dd9bdc430"}
{"project": "FFmpeg", "commit_id": "bfa0f96586fe2c257cfa574ffb991da493a54da1", "target": 1, "func": "static void vp8_decode_flush(AVCodecContext *avctx)\n\n{\n\n    vp8_decode_flush_impl(avctx, 0, 0);\n\n}\n", "idx": 16358, "_split": "valid", "_hash": "9a1d34e31e577a4544ca5ec382783490"}
{"project": "FFmpeg", "commit_id": "66875798eb88be2f9e49c7d1d1b92aadac1623f6", "target": 1, "func": "static int ipvideo_decode_block_opcode_0x9(IpvideoContext *s, AVFrame *frame)\n{\n    int x, y;\n    unsigned char P[4];\n    /* 4-color encoding */\n    bytestream2_get_buffer(&s->stream_ptr, P, 4);\n    if (P[0] <= P[1]) {\n        if (P[2] <= P[3]) {\n            /* 1 of 4 colors for each pixel, need 16 more bytes */\n            for (y = 0; y < 8; y++) {\n                /* get the next set of 8 2-bit flags */\n                int flags = bytestream2_get_le16(&s->stream_ptr);\n                for (x = 0; x < 8; x++, flags >>= 2)\n                    *s->pixel_ptr++ = P[flags & 0x03];\n                s->pixel_ptr += s->line_inc;\n        } else {\n            uint32_t flags;\n            /* 1 of 4 colors for each 2x2 block, need 4 more bytes */\n            flags = bytestream2_get_le32(&s->stream_ptr);\n            for (y = 0; y < 8; y += 2) {\n                for (x = 0; x < 8; x += 2, flags >>= 2) {\n                    s->pixel_ptr[x                ] =\n                    s->pixel_ptr[x + 1            ] =\n                    s->pixel_ptr[x +     s->stride] =\n                    s->pixel_ptr[x + 1 + s->stride] = P[flags & 0x03];\n                s->pixel_ptr += s->stride * 2;\n    } else {\n        uint64_t flags;\n        /* 1 of 4 colors for each 2x1 or 1x2 block, need 8 more bytes */\n        flags = bytestream2_get_le64(&s->stream_ptr);\n        if (P[2] <= P[3]) {\n            for (y = 0; y < 8; y++) {\n                for (x = 0; x < 8; x += 2, flags >>= 2) {\n                    s->pixel_ptr[x    ] =\n                    s->pixel_ptr[x + 1] = P[flags & 0x03];\n                s->pixel_ptr += s->stride;\n        } else {\n            for (y = 0; y < 8; y += 2) {\n                for (x = 0; x < 8; x++, flags >>= 2) {\n                    s->pixel_ptr[x            ] =\n                    s->pixel_ptr[x + s->stride] = P[flags & 0x03];\n                s->pixel_ptr += s->stride * 2;\n    /* report success */\n    return 0;", "idx": 16361, "_split": "valid", "_hash": "b084eea68065c9215636c23490d6b5de"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int select_input_picture(MpegEncContext *s)\n\n{\n\n    int i, ret;\n\n\n\n    for (i = 1; i < MAX_PICTURE_COUNT; i++)\n\n        s->reordered_input_picture[i - 1] = s->reordered_input_picture[i];\n\n    s->reordered_input_picture[MAX_PICTURE_COUNT - 1] = NULL;\n\n\n\n    /* set next picture type & ordering */\n\n    if (s->reordered_input_picture[0] == NULL && s->input_picture[0]) {\n\n        if (/*s->picture_in_gop_number >= s->gop_size ||*/\n\n            s->next_picture_ptr == NULL || s->intra_only) {\n\n            s->reordered_input_picture[0] = s->input_picture[0];\n\n            s->reordered_input_picture[0]->f.pict_type = AV_PICTURE_TYPE_I;\n\n            s->reordered_input_picture[0]->f.coded_picture_number =\n\n                s->coded_picture_number++;\n\n        } else {\n\n            int b_frames;\n\n\n\n            if (s->avctx->frame_skip_threshold || s->avctx->frame_skip_factor) {\n\n                if (s->picture_in_gop_number < s->gop_size &&\n\n                    skip_check(s, s->input_picture[0], s->next_picture_ptr)) {\n\n                    // FIXME check that te gop check above is +-1 correct\n\n                    av_frame_unref(&s->input_picture[0]->f);\n\n\n\n                    emms_c();\n\n                    ff_vbv_update(s, 0);\n\n\n\n                    goto no_output_pic;\n\n                }\n\n            }\n\n\n\n            if (s->flags & CODEC_FLAG_PASS2) {\n\n                for (i = 0; i < s->max_b_frames + 1; i++) {\n\n                    int pict_num = s->input_picture[0]->f.display_picture_number + i;\n\n\n\n                    if (pict_num >= s->rc_context.num_entries)\n\n                        break;\n\n                    if (!s->input_picture[i]) {\n\n                        s->rc_context.entry[pict_num - 1].new_pict_type = AV_PICTURE_TYPE_P;\n\n                        break;\n\n                    }\n\n\n\n                    s->input_picture[i]->f.pict_type =\n\n                        s->rc_context.entry[pict_num].new_pict_type;\n\n                }\n\n            }\n\n\n\n            if (s->avctx->b_frame_strategy == 0) {\n\n                b_frames = s->max_b_frames;\n\n                while (b_frames && !s->input_picture[b_frames])\n\n                    b_frames--;\n\n            } else if (s->avctx->b_frame_strategy == 1) {\n\n                for (i = 1; i < s->max_b_frames + 1; i++) {\n\n                    if (s->input_picture[i] &&\n\n                        s->input_picture[i]->b_frame_score == 0) {\n\n                        s->input_picture[i]->b_frame_score =\n\n                            get_intra_count(s,\n\n                                            s->input_picture[i    ]->f.data[0],\n\n                                            s->input_picture[i - 1]->f.data[0],\n\n                                            s->linesize) + 1;\n\n                    }\n\n                }\n\n                for (i = 0; i < s->max_b_frames + 1; i++) {\n\n                    if (s->input_picture[i] == NULL ||\n\n                        s->input_picture[i]->b_frame_score - 1 >\n\n                            s->mb_num / s->avctx->b_sensitivity)\n\n                        break;\n\n                }\n\n\n\n                b_frames = FFMAX(0, i - 1);\n\n\n\n                /* reset scores */\n\n                for (i = 0; i < b_frames + 1; i++) {\n\n                    s->input_picture[i]->b_frame_score = 0;\n\n                }\n\n            } else if (s->avctx->b_frame_strategy == 2) {\n\n                b_frames = estimate_best_b_count(s);\n\n            } else {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"illegal b frame strategy\\n\");\n\n                b_frames = 0;\n\n            }\n\n\n\n            emms_c();\n\n\n\n            for (i = b_frames - 1; i >= 0; i--) {\n\n                int type = s->input_picture[i]->f.pict_type;\n\n                if (type && type != AV_PICTURE_TYPE_B)\n\n                    b_frames = i;\n\n            }\n\n            if (s->input_picture[b_frames]->f.pict_type == AV_PICTURE_TYPE_B &&\n\n                b_frames == s->max_b_frames) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"warning, too many b frames in a row\\n\");\n\n            }\n\n\n\n            if (s->picture_in_gop_number + b_frames >= s->gop_size) {\n\n                if ((s->mpv_flags & FF_MPV_FLAG_STRICT_GOP) &&\n\n                    s->gop_size > s->picture_in_gop_number) {\n\n                    b_frames = s->gop_size - s->picture_in_gop_number - 1;\n\n                } else {\n\n                    if (s->flags & CODEC_FLAG_CLOSED_GOP)\n\n                        b_frames = 0;\n\n                    s->input_picture[b_frames]->f.pict_type = AV_PICTURE_TYPE_I;\n\n                }\n\n            }\n\n\n\n            if ((s->flags & CODEC_FLAG_CLOSED_GOP) && b_frames &&\n\n                s->input_picture[b_frames]->f.pict_type == AV_PICTURE_TYPE_I)\n\n                b_frames--;\n\n\n\n            s->reordered_input_picture[0] = s->input_picture[b_frames];\n\n            if (s->reordered_input_picture[0]->f.pict_type != AV_PICTURE_TYPE_I)\n\n                s->reordered_input_picture[0]->f.pict_type = AV_PICTURE_TYPE_P;\n\n            s->reordered_input_picture[0]->f.coded_picture_number =\n\n                s->coded_picture_number++;\n\n            for (i = 0; i < b_frames; i++) {\n\n                s->reordered_input_picture[i + 1] = s->input_picture[i];\n\n                s->reordered_input_picture[i + 1]->f.pict_type =\n\n                    AV_PICTURE_TYPE_B;\n\n                s->reordered_input_picture[i + 1]->f.coded_picture_number =\n\n                    s->coded_picture_number++;\n\n            }\n\n        }\n\n    }\n\nno_output_pic:\n\n    if (s->reordered_input_picture[0]) {\n\n        s->reordered_input_picture[0]->reference =\n\n           s->reordered_input_picture[0]->f.pict_type !=\n\n               AV_PICTURE_TYPE_B ? 3 : 0;\n\n\n\n        ff_mpeg_unref_picture(s, &s->new_picture);\n\n        if ((ret = ff_mpeg_ref_picture(s, &s->new_picture, s->reordered_input_picture[0])))\n\n            return ret;\n\n\n\n        if (s->reordered_input_picture[0]->shared || s->avctx->rc_buffer_size) {\n\n            // input is a shared pix, so we can't modifiy it -> alloc a new\n\n            // one & ensure that the shared one is reuseable\n\n\n\n            Picture *pic;\n\n            int i = ff_find_unused_picture(s, 0);\n\n            if (i < 0)\n\n                return i;\n\n            pic = &s->picture[i];\n\n\n\n            pic->reference = s->reordered_input_picture[0]->reference;\n\n            if (ff_alloc_picture(s, pic, 0) < 0) {\n\n                return -1;\n\n            }\n\n\n\n            ret = av_frame_copy_props(&pic->f, &s->reordered_input_picture[0]->f);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            /* mark us unused / free shared pic */\n\n            av_frame_unref(&s->reordered_input_picture[0]->f);\n\n            s->reordered_input_picture[0]->shared = 0;\n\n\n\n            s->current_picture_ptr = pic;\n\n        } else {\n\n            // input is not a shared pix -> reuse buffer for current_pix\n\n            s->current_picture_ptr = s->reordered_input_picture[0];\n\n            for (i = 0; i < 4; i++) {\n\n                s->new_picture.f.data[i] += INPLACE_OFFSET;\n\n            }\n\n        }\n\n        ff_mpeg_unref_picture(s, &s->current_picture);\n\n        if ((ret = ff_mpeg_ref_picture(s, &s->current_picture,\n\n                                       s->current_picture_ptr)) < 0)\n\n            return ret;\n\n\n\n        s->picture_number = s->new_picture.f.display_picture_number;\n\n    } else {\n\n        ff_mpeg_unref_picture(s, &s->new_picture);\n\n    }\n\n    return 0;\n\n}\n", "idx": 16435, "_split": "valid", "_hash": "e4785d7885d06bfda2418c236d7195e6"}
{"project": "FFmpeg", "commit_id": "87bddba43b725d43767f2a387cdea0936ac1b549", "target": 1, "func": "float ff_amr_set_fixed_gain(float fixed_gain_factor, float fixed_mean_energy,\n\n                            float *prediction_error, float energy_mean,\n\n                            const float *pred_table)\n\n{\n\n    // Equations 66-69:\n\n    // ^g_c = ^gamma_gc * 100.05 (predicted dB + mean dB - dB of fixed vector)\n\n    // Note 10^(0.05 * -10log(average x2)) = 1/sqrt((average x2)).\n\n    float val = fixed_gain_factor *\n\n        ff_exp10(0.05 *\n\n              (avpriv_scalarproduct_float_c(pred_table, prediction_error, 4) +\n\n               energy_mean)) /\n\n        sqrtf(fixed_mean_energy);\n\n\n\n    // update quantified prediction error energy history\n\n    memmove(&prediction_error[0], &prediction_error[1],\n\n            3 * sizeof(prediction_error[0]));\n\n    prediction_error[3] = 20.0 * log10f(fixed_gain_factor);\n\n\n\n    return val;\n\n}\n", "idx": 16464, "_split": "valid", "_hash": "098be84df3a9c4204bf31c2764bf9d7e"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int decode_chunks(AVCodecContext *avctx, AVFrame *picture,\n\n                         int *got_output, const uint8_t *buf, int buf_size)\n\n{\n\n    Mpeg1Context *s = avctx->priv_data;\n\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n\n    const uint8_t *buf_ptr = buf;\n\n    const uint8_t *buf_end = buf + buf_size;\n\n    int ret, input_size;\n\n    int last_code = 0, skip_frame = 0;\n\n\n\n    for (;;) {\n\n        /* find next start code */\n\n        uint32_t start_code = -1;\n\n        buf_ptr = avpriv_find_start_code(buf_ptr, buf_end, &start_code);\n\n        if (start_code > 0x1ff) {\n\n            if (!skip_frame) {\n\n                if (HAVE_THREADS &&\n\n                    (avctx->active_thread_type & FF_THREAD_SLICE) &&\n\n                    !avctx->hwaccel) {\n\n                    int i;\n\n\n\n                    avctx->execute(avctx, slice_decode_thread,\n\n                                   &s2->thread_context[0], NULL,\n\n                                   s->slice_count, sizeof(void *));\n\n                    for (i = 0; i < s->slice_count; i++)\n\n                        s2->er.error_count += s2->thread_context[i]->er.error_count;\n\n                }\n\n\n\n                ret = slice_end(avctx, picture);\n\n                if (ret < 0)\n\n                    return ret;\n\n                else if (ret) {\n\n                    // FIXME: merge with the stuff in mpeg_decode_slice\n\n                    if (s2->last_picture_ptr || s2->low_delay)\n\n                        *got_output = 1;\n\n                }\n\n            }\n\n            s2->pict_type = 0;\n\n            return FFMAX(0, buf_ptr - buf - s2->parse_context.last_index);\n\n        }\n\n\n\n        input_size = buf_end - buf_ptr;\n\n\n\n        if (avctx->debug & FF_DEBUG_STARTCODE)\n\n            av_log(avctx, AV_LOG_DEBUG, \"%3\"PRIX32\" at %td left %d\\n\",\n\n                   start_code, buf_ptr - buf, input_size);\n\n\n\n        /* prepare data for next start code */\n\n        switch (start_code) {\n\n        case SEQ_START_CODE:\n\n            if (last_code == 0) {\n\n                mpeg1_decode_sequence(avctx, buf_ptr, input_size);\n\n                s->sync = 1;\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"ignoring SEQ_START_CODE after %X\\n\", last_code);\n\n                if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n            break;\n\n\n\n        case PICTURE_START_CODE:\n\n            if (s2->width <= 0 || s2->height <= 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid frame dimensions %dx%d.\\n\",\n\n                       s2->width, s2->height);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if (HAVE_THREADS && (avctx->active_thread_type & FF_THREAD_SLICE) &&\n\n                !avctx->hwaccel && s->slice_count) {\n\n                int i;\n\n\n\n                avctx->execute(avctx, slice_decode_thread,\n\n                               s2->thread_context, NULL,\n\n                               s->slice_count, sizeof(void *));\n\n                for (i = 0; i < s->slice_count; i++)\n\n                    s2->er.error_count += s2->thread_context[i]->er.error_count;\n\n                s->slice_count = 0;\n\n            }\n\n            if (last_code == 0 || last_code == SLICE_MIN_START_CODE) {\n\n                ret = mpeg_decode_postinit(avctx);\n\n                if (ret < 0) {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"mpeg_decode_postinit() failure\\n\");\n\n                    return ret;\n\n                }\n\n\n\n                /* We have a complete image: we try to decompress it. */\n\n                if (mpeg1_decode_picture(avctx, buf_ptr, input_size) < 0)\n\n                    s2->pict_type = 0;\n\n                s->first_slice = 1;\n\n                last_code      = PICTURE_START_CODE;\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"ignoring pic after %X\\n\", last_code);\n\n                if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n            break;\n\n        case EXT_START_CODE:\n\n            init_get_bits(&s2->gb, buf_ptr, input_size * 8);\n\n\n\n            switch (get_bits(&s2->gb, 4)) {\n\n            case 0x1:\n\n                if (last_code == 0) {\n\n                    mpeg_decode_sequence_extension(s);\n\n                } else {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"ignoring seq ext after %X\\n\", last_code);\n\n                    if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                        return AVERROR_INVALIDDATA;\n\n                }\n\n                break;\n\n            case 0x2:\n\n                mpeg_decode_sequence_display_extension(s);\n\n                break;\n\n            case 0x3:\n\n                mpeg_decode_quant_matrix_extension(s2);\n\n                break;\n\n            case 0x7:\n\n                mpeg_decode_picture_display_extension(s);\n\n                break;\n\n            case 0x8:\n\n                if (last_code == PICTURE_START_CODE) {\n\n                    mpeg_decode_picture_coding_extension(s);\n\n                } else {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"ignoring pic cod ext after %X\\n\", last_code);\n\n                    if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                        return AVERROR_INVALIDDATA;\n\n                }\n\n                break;\n\n            }\n\n            break;\n\n        case USER_START_CODE:\n\n            mpeg_decode_user_data(avctx, buf_ptr, input_size);\n\n            break;\n\n        case GOP_START_CODE:\n\n            if (last_code == 0) {\n\n                s2->first_field = 0;\n\n                mpeg_decode_gop(avctx, buf_ptr, input_size);\n\n                s->sync = 1;\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"ignoring GOP_START_CODE after %X\\n\", last_code);\n\n                if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n            break;\n\n        default:\n\n            if (start_code >= SLICE_MIN_START_CODE &&\n\n                start_code <= SLICE_MAX_START_CODE && last_code != 0) {\n\n                const int field_pic = s2->picture_structure != PICT_FRAME;\n\n                int mb_y = (start_code - SLICE_MIN_START_CODE) << field_pic;\n\n                last_code = SLICE_MIN_START_CODE;\n\n\n\n                if (s2->picture_structure == PICT_BOTTOM_FIELD)\n\n                    mb_y++;\n\n\n\n                if (mb_y >= s2->mb_height) {\n\n                    av_log(s2->avctx, AV_LOG_ERROR,\n\n                           \"slice below image (%d >= %d)\\n\", mb_y, s2->mb_height);\n\n                    return -1;\n\n                }\n\n\n\n                if (s2->last_picture_ptr == NULL) {\n\n                    /* Skip B-frames if we do not have reference frames and\n\n                     * GOP is not closed. */\n\n                    if (s2->pict_type == AV_PICTURE_TYPE_B) {\n\n                        if (!s->closed_gop) {\n\n                            skip_frame = 1;\n\n                            break;\n\n                        }\n\n                    }\n\n                }\n\n                if (s2->pict_type == AV_PICTURE_TYPE_I)\n\n                    s->sync = 1;\n\n                if (s2->next_picture_ptr == NULL) {\n\n                    /* Skip P-frames if we do not have a reference frame or\n\n                     * we have an invalid header. */\n\n                    if (s2->pict_type == AV_PICTURE_TYPE_P && !s->sync) {\n\n                        skip_frame = 1;\n\n                        break;\n\n                    }\n\n                }\n\n                if ((avctx->skip_frame >= AVDISCARD_NONREF &&\n\n                     s2->pict_type == AV_PICTURE_TYPE_B) ||\n\n                    (avctx->skip_frame >= AVDISCARD_NONKEY &&\n\n                     s2->pict_type != AV_PICTURE_TYPE_I) ||\n\n                    avctx->skip_frame >= AVDISCARD_ALL) {\n\n                    skip_frame = 1;\n\n                    break;\n\n                }\n\n\n\n                if (!s->mpeg_enc_ctx_allocated)\n\n                    break;\n\n\n\n                if (s2->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n                    if (mb_y < avctx->skip_top ||\n\n                        mb_y >= s2->mb_height - avctx->skip_bottom)\n\n                        break;\n\n                }\n\n\n\n                if (!s2->pict_type) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Missing picture start code\\n\");\n\n                    if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                        return AVERROR_INVALIDDATA;\n\n                    break;\n\n                }\n\n\n\n                if (s->first_slice) {\n\n                    skip_frame     = 0;\n\n                    s->first_slice = 0;\n\n                    if (mpeg_field_start(s2, buf, buf_size) < 0)\n\n                        return -1;\n\n                }\n\n                if (!s2->current_picture_ptr) {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"current_picture not initialized\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                if (HAVE_THREADS &&\n\n                    (avctx->active_thread_type & FF_THREAD_SLICE) &&\n\n                    !avctx->hwaccel) {\n\n                    int threshold = (s2->mb_height * s->slice_count +\n\n                                     s2->slice_context_count / 2) /\n\n                                    s2->slice_context_count;\n\n                    if (threshold <= mb_y) {\n\n                        MpegEncContext *thread_context = s2->thread_context[s->slice_count];\n\n\n\n                        thread_context->start_mb_y = mb_y;\n\n                        thread_context->end_mb_y   = s2->mb_height;\n\n                        if (s->slice_count) {\n\n                            s2->thread_context[s->slice_count - 1]->end_mb_y = mb_y;\n\n                            ret = ff_update_duplicate_context(thread_context, s2);\n\n                            if (ret < 0)\n\n                                return ret;\n\n                        }\n\n                        init_get_bits(&thread_context->gb, buf_ptr, input_size * 8);\n\n                        s->slice_count++;\n\n                    }\n\n                    buf_ptr += 2; // FIXME add minimum number of bytes per slice\n\n                } else {\n\n                    ret = mpeg_decode_slice(s2, mb_y, &buf_ptr, input_size);\n\n                    emms_c();\n\n\n\n                    if (ret < 0) {\n\n                        if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                            return ret;\n\n                        if (s2->resync_mb_x >= 0 && s2->resync_mb_y >= 0)\n\n                            ff_er_add_slice(&s2->er, s2->resync_mb_x,\n\n                                            s2->resync_mb_y, s2->mb_x, s2->mb_y,\n\n                                            ER_AC_ERROR | ER_DC_ERROR | ER_MV_ERROR);\n\n                    } else {\n\n                        ff_er_add_slice(&s2->er, s2->resync_mb_x,\n\n                                        s2->resync_mb_y, s2->mb_x - 1, s2->mb_y,\n\n                                        ER_AC_END | ER_DC_END | ER_MV_END);\n\n                    }\n\n                }\n\n            }\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 16503, "_split": "valid", "_hash": "f94f1dc48663424d5e4ee1d51371807e"}
{"project": "FFmpeg", "commit_id": "b0cd14fb1dab4b044f7fe6b53ac635409849de77", "target": 0, "func": "int hw_device_setup_for_decode(InputStream *ist)\n\n{\n\n    enum AVHWDeviceType type;\n\n    HWDevice *dev;\n\n    int err;\n\n\n\n    if (ist->hwaccel_device) {\n\n        dev = hw_device_get_by_name(ist->hwaccel_device);\n\n        if (!dev) {\n\n            char *tmp;\n\n            type = hw_device_match_type_by_hwaccel(ist->hwaccel_id);\n\n            if (type == AV_HWDEVICE_TYPE_NONE) {\n\n                // No match - this isn't necessarily invalid, though,\n\n                // because an explicit device might not be needed or\n\n                // the hwaccel setup could be handled elsewhere.\n\n                return 0;\n\n            }\n\n            tmp = av_asprintf(\"%s:%s\", av_hwdevice_get_type_name(type),\n\n                              ist->hwaccel_device);\n\n            if (!tmp)\n\n                return AVERROR(ENOMEM);\n\n            err = hw_device_init_from_string(tmp, &dev);\n\n            av_free(tmp);\n\n            if (err < 0)\n\n                return err;\n\n        }\n\n    } else {\n\n        if (ist->hwaccel_id != HWACCEL_NONE)\n\n            type = hw_device_match_type_by_hwaccel(ist->hwaccel_id);\n\n        else\n\n            type = hw_device_match_type_in_name(ist->dec->name);\n\n        if (type != AV_HWDEVICE_TYPE_NONE) {\n\n            dev = hw_device_get_by_type(type);\n\n            if (!dev) {\n\n                hw_device_init_from_string(av_hwdevice_get_type_name(type),\n\n                                           &dev);\n\n            }\n\n        } else {\n\n            // No device required.\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    if (!dev) {\n\n        av_log(ist->dec_ctx, AV_LOG_WARNING, \"No device available \"\n\n               \"for decoder (device type %s for codec %s).\\n\",\n\n               av_hwdevice_get_type_name(type), ist->dec->name);\n\n        return 0;\n\n    }\n\n\n\n    ist->dec_ctx->hw_device_ctx = av_buffer_ref(dev->device_ref);\n\n    if (!ist->dec_ctx->hw_device_ctx)\n\n        return AVERROR(ENOMEM);\n\n\n\n    return 0;\n\n}\n", "idx": 16577, "_split": "valid", "_hash": "7f1f8825cc6feb34e92866bdf3b8e7f7"}
{"project": "FFmpeg", "commit_id": "1255eed533b4069db7f205601953ca54c0dc42c9", "target": 1, "func": "static void tgq_decode_mb(TgqContext *s, int mb_y, int mb_x, const uint8_t **bs, const uint8_t *buf_end){\n\n    int mode;\n\n    int i;\n\n    int8_t dc[6];\n\n\n\n    mode = bytestream_get_byte(bs);\n\n    if (mode>buf_end-*bs) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"truncated macroblock\\n\");\n\n        return;\n\n    }\n\n\n\n    if (mode>12) {\n\n        GetBitContext gb;\n\n        init_get_bits(&gb, *bs, mode*8);\n\n        for(i=0; i<6; i++)\n\n            tgq_decode_block(s, s->block[i], &gb);\n\n        tgq_idct_put_mb(s, s->block, mb_x, mb_y);\n\n    }else{\n\n        if (mode==3) {\n\n            memset(dc, (*bs)[0], 4);\n\n            dc[4] = (*bs)[1];\n\n            dc[5] = (*bs)[2];\n\n        }else if (mode==6) {\n\n            memcpy(dc, *bs, 6);\n\n        }else if (mode==12) {\n\n            for(i=0; i<6; i++)\n\n                dc[i] = (*bs)[i*2];\n\n        }else{\n\n            av_log(s->avctx, AV_LOG_ERROR, \"unsupported mb mode %i\\n\", mode);\n\n        }\n\n        tgq_idct_put_mb_dconly(s, mb_x, mb_y, dc);\n\n    }\n\n    *bs += mode;\n\n}\n", "idx": 16659, "_split": "valid", "_hash": "4d6f45b15b7891750ab32d94ad62cd7c"}
{"project": "FFmpeg", "commit_id": "f78cd0c243b9149c7f604ecf1006d78e344aa6ca", "target": 1, "func": "void ff_prores_idct(DCTELEM *block, const int16_t *qmat)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 64; i++)\n\n        block[i] *= qmat[i];\n\n\n\n    for (i = 0; i < 8; i++)\n\n        idctRowCondDC_10(block + i*8);\n\n\n\n    for (i = 0; i < 64; i++)\n\n        block[i] >>= 2;\n\n\n\n    for (i = 0; i < 8; i++)\n\n        idctSparseCol_10(block + i);\n\n}\n", "idx": 16660, "_split": "valid", "_hash": "341548b6ae06ee81628741e6cf6c19b7"}
{"project": "FFmpeg", "commit_id": "426d18b85be393a94adf4e4528702d8cf9d66a35", "target": 1, "func": "static inline void idct_col (int16_t * col, int offset)\n\n{\n\n#define T1 13036\n\n#define T2 27146\n\n#define T3 43790\n\n#define C4 23170\n\n\n\n    static const short _T1[] ATTR_ALIGN(8) = {T1,T1,T1,T1};\n\n    static const short _T2[] ATTR_ALIGN(8) = {T2,T2,T2,T2};\n\n    static const short _T3[] ATTR_ALIGN(8) = {T3,T3,T3,T3};\n\n    static const short _C4[] ATTR_ALIGN(8) = {C4,C4,C4,C4};\n\n\n\n    /* column code adapted from Peter Gubanov */\n\n    /* http://www.elecard.com/peter/idct.shtml */\n\n\n\n    movq_m2r (*_T1, mm0);               // mm0 = T1\n\n\n\n    movq_m2r (*(col+offset+1*8), mm1);  // mm1 = x1\n\n    movq_r2r (mm0, mm2);                // mm2 = T1\n\n\n\n    movq_m2r (*(col+offset+7*8), mm4);  // mm4 = x7\n\n    pmulhw_r2r (mm1, mm0);              // mm0 = T1*x1\n\n\n\n    movq_m2r (*_T3, mm5);               // mm5 = T3\n\n    pmulhw_r2r (mm4, mm2);              // mm2 = T1*x7\n\n\n\n    movq_m2r (*(col+offset+5*8), mm6);  // mm6 = x5\n\n    movq_r2r (mm5, mm7);                // mm7 = T3-1\n\n\n\n    movq_m2r (*(col+offset+3*8), mm3);  // mm3 = x3\n\n    psubsw_r2r (mm4, mm0);              // mm0 = v17\n\n\n\n    movq_m2r (*_T2, mm4);               // mm4 = T2\n\n    pmulhw_r2r (mm3, mm5);              // mm5 = (T3-1)*x3\n\n\n\n    paddsw_r2r (mm2, mm1);              // mm1 = u17\n\n    pmulhw_r2r (mm6, mm7);              // mm7 = (T3-1)*x5\n\n\n\n    /* slot */\n\n\n\n    movq_r2r (mm4, mm2);                // mm2 = T2\n\n    paddsw_r2r (mm3, mm5);              // mm5 = T3*x3\n\n\n\n    pmulhw_m2r (*(col+offset+2*8), mm4);// mm4 = T2*x2\n\n    paddsw_r2r (mm6, mm7);              // mm7 = T3*x5\n\n\n\n    psubsw_r2r (mm6, mm5);              // mm5 = v35\n\n    paddsw_r2r (mm3, mm7);              // mm7 = u35\n\n\n\n    movq_m2r (*(col+offset+6*8), mm3);  // mm3 = x6\n\n    movq_r2r (mm0, mm6);                // mm6 = v17\n\n\n\n    pmulhw_r2r (mm3, mm2);              // mm2 = T2*x6\n\n    psubsw_r2r (mm5, mm0);              // mm0 = b3\n\n\n\n    psubsw_r2r (mm3, mm4);              // mm4 = v26\n\n    paddsw_r2r (mm6, mm5);              // mm5 = v12\n\n\n\n    movq_r2m (mm0, *(col+offset+3*8));  // save b3 in scratch0\n\n    movq_r2r (mm1, mm6);                // mm6 = u17\n\n\n\n    paddsw_m2r (*(col+offset+2*8), mm2);// mm2 = u26\n\n    paddsw_r2r (mm7, mm6);              // mm6 = b0\n\n\n\n    psubsw_r2r (mm7, mm1);              // mm1 = u12\n\n    movq_r2r (mm1, mm7);                // mm7 = u12\n\n\n\n    movq_m2r (*(col+offset+0*8), mm3);  // mm3 = x0\n\n    paddsw_r2r (mm5, mm1);              // mm1 = u12+v12\n\n\n\n    movq_m2r (*_C4, mm0);               // mm0 = C4/2\n\n    psubsw_r2r (mm5, mm7);              // mm7 = u12-v12\n\n\n\n    movq_r2m (mm6, *(col+offset+5*8));  // save b0 in scratch1\n\n    pmulhw_r2r (mm0, mm1);              // mm1 = b1/2\n\n\n\n    movq_r2r (mm4, mm6);                // mm6 = v26\n\n    pmulhw_r2r (mm0, mm7);              // mm7 = b2/2\n\n\n\n    movq_m2r (*(col+offset+4*8), mm5);  // mm5 = x4\n\n    movq_r2r (mm3, mm0);                // mm0 = x0\n\n\n\n    psubsw_r2r (mm5, mm3);              // mm3 = v04\n\n    paddsw_r2r (mm5, mm0);              // mm0 = u04\n\n\n\n    paddsw_r2r (mm3, mm4);              // mm4 = a1\n\n    movq_r2r (mm0, mm5);                // mm5 = u04\n\n\n\n    psubsw_r2r (mm6, mm3);              // mm3 = a2\n\n    paddsw_r2r (mm2, mm5);              // mm5 = a0\n\n\n\n    paddsw_r2r (mm1, mm1);              // mm1 = b1\n\n    psubsw_r2r (mm2, mm0);              // mm0 = a3\n\n\n\n    paddsw_r2r (mm7, mm7);              // mm7 = b2\n\n    movq_r2r (mm3, mm2);                // mm2 = a2\n\n\n\n    movq_r2r (mm4, mm6);                // mm6 = a1\n\n    paddsw_r2r (mm7, mm3);              // mm3 = a2+b2\n\n\n\n    psraw_i2r (COL_SHIFT, mm3);         // mm3 = y2\n\n    paddsw_r2r (mm1, mm4);              // mm4 = a1+b1\n\n\n\n    psraw_i2r (COL_SHIFT, mm4);         // mm4 = y1\n\n    psubsw_r2r (mm1, mm6);              // mm6 = a1-b1\n\n\n\n    movq_m2r (*(col+offset+5*8), mm1);  // mm1 = b0\n\n    psubsw_r2r (mm7, mm2);              // mm2 = a2-b2\n\n\n\n    psraw_i2r (COL_SHIFT, mm6);         // mm6 = y6\n\n    movq_r2r (mm5, mm7);                // mm7 = a0\n\n\n\n    movq_r2m (mm4, *(col+offset+1*8));  // save y1\n\n    psraw_i2r (COL_SHIFT, mm2);         // mm2 = y5\n\n\n\n    movq_r2m (mm3, *(col+offset+2*8));  // save y2\n\n    paddsw_r2r (mm1, mm5);              // mm5 = a0+b0\n\n\n\n    movq_m2r (*(col+offset+3*8), mm4);  // mm4 = b3\n\n    psubsw_r2r (mm1, mm7);              // mm7 = a0-b0\n\n\n\n    psraw_i2r (COL_SHIFT, mm5);         // mm5 = y0\n\n    movq_r2r (mm0, mm3);                // mm3 = a3\n\n\n\n    movq_r2m (mm2, *(col+offset+5*8));  // save y5\n\n    psubsw_r2r (mm4, mm3);              // mm3 = a3-b3\n\n\n\n    psraw_i2r (COL_SHIFT, mm7);         // mm7 = y7\n\n    paddsw_r2r (mm0, mm4);              // mm4 = a3+b3\n\n\n\n    movq_r2m (mm5, *(col+offset+0*8));  // save y0\n\n    psraw_i2r (COL_SHIFT, mm3);         // mm3 = y4\n\n\n\n    movq_r2m (mm6, *(col+offset+6*8));  // save y6\n\n    psraw_i2r (COL_SHIFT, mm4);         // mm4 = y3\n\n\n\n    movq_r2m (mm7, *(col+offset+7*8));  // save y7\n\n\n\n    movq_r2m (mm3, *(col+offset+4*8));  // save y4\n\n\n\n    movq_r2m (mm4, *(col+offset+3*8));  // save y3\n\n\n\n#undef T1\n\n#undef T2\n\n#undef T3\n\n#undef C4\n\n}\n", "idx": 16704, "_split": "valid", "_hash": "19b53dac5b115122a47006a56795e9b3"}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "static av_always_inline void encode_mb_internal(MpegEncContext *s,\n\n                                                int motion_x, int motion_y,\n\n                                                int mb_block_height,\n\n                                                int mb_block_width,\n\n                                                int mb_block_count)\n\n{\n\n    int16_t weight[12][64];\n\n    int16_t orig[12][64];\n\n    const int mb_x = s->mb_x;\n\n    const int mb_y = s->mb_y;\n\n    int i;\n\n    int skip_dct[12];\n\n    int dct_offset = s->linesize * 8; // default for progressive frames\n\n    int uv_dct_offset = s->uvlinesize * 8;\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int wrap_y, wrap_c;\n\n\n\n    for (i = 0; i < mb_block_count; i++)\n\n        skip_dct[i] = s->skipdct;\n\n\n\n    if (s->adaptive_quant) {\n\n        const int last_qp = s->qscale;\n\n        const int mb_xy = mb_x + mb_y * s->mb_stride;\n\n\n\n        s->lambda = s->lambda_table[mb_xy];\n\n        update_qscale(s);\n\n\n\n        if (!(s->mpv_flags & FF_MPV_FLAG_QP_RD)) {\n\n            s->qscale = s->current_picture_ptr->qscale_table[mb_xy];\n\n            s->dquant = s->qscale - last_qp;\n\n\n\n            if (s->out_format == FMT_H263) {\n\n                s->dquant = av_clip(s->dquant, -2, 2);\n\n\n\n                if (s->codec_id == AV_CODEC_ID_MPEG4) {\n\n                    if (!s->mb_intra) {\n\n                        if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n                            if (s->dquant & 1 || s->mv_dir & MV_DIRECT)\n\n                                s->dquant = 0;\n\n                        }\n\n                        if (s->mv_type == MV_TYPE_8X8)\n\n                            s->dquant = 0;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        ff_set_qscale(s, last_qp + s->dquant);\n\n    } else if (s->mpv_flags & FF_MPV_FLAG_QP_RD)\n\n        ff_set_qscale(s, s->qscale + s->dquant);\n\n\n\n    wrap_y = s->linesize;\n\n    wrap_c = s->uvlinesize;\n\n    ptr_y  = s->new_picture.f.data[0] +\n\n             (mb_y * 16 * wrap_y)              + mb_x * 16;\n\n    ptr_cb = s->new_picture.f.data[1] +\n\n             (mb_y * mb_block_height * wrap_c) + mb_x * mb_block_width;\n\n    ptr_cr = s->new_picture.f.data[2] +\n\n             (mb_y * mb_block_height * wrap_c) + mb_x * mb_block_width;\n\n\n\n    if((mb_x*16+16 > s->width || mb_y*16+16 > s->height) && s->codec_id != AV_CODEC_ID_AMV){\n\n        uint8_t *ebuf = s->edge_emu_buffer + 32;\n\n        int cw = (s->width  + s->chroma_x_shift) >> s->chroma_x_shift;\n\n        int ch = (s->height + s->chroma_y_shift) >> s->chroma_y_shift;\n\n        s->vdsp.emulated_edge_mc(ebuf, ptr_y, wrap_y, 16, 16, mb_x * 16,\n\n                                 mb_y * 16, s->width, s->height);\n\n        ptr_y = ebuf;\n\n        s->vdsp.emulated_edge_mc(ebuf + 18 * wrap_y, ptr_cb, wrap_c, mb_block_width,\n\n                                 mb_block_height, mb_x * mb_block_width, mb_y * mb_block_height,\n\n                                 cw, ch);\n\n        ptr_cb = ebuf + 18 * wrap_y;\n\n        s->vdsp.emulated_edge_mc(ebuf + 18 * wrap_y + 16, ptr_cr, wrap_c, mb_block_width,\n\n                                 mb_block_height, mb_x * mb_block_width, mb_y * mb_block_height,\n\n                                 cw, ch);\n\n        ptr_cr = ebuf + 18 * wrap_y + 16;\n\n    }\n\n\n\n    if (s->mb_intra) {\n\n        if (s->flags & CODEC_FLAG_INTERLACED_DCT) {\n\n            int progressive_score, interlaced_score;\n\n\n\n            s->interlaced_dct = 0;\n\n            progressive_score = s->dsp.ildct_cmp[4](s, ptr_y,\n\n                                                    NULL, wrap_y, 8) +\n\n                                s->dsp.ildct_cmp[4](s, ptr_y + wrap_y * 8,\n\n                                                    NULL, wrap_y, 8) - 400;\n\n\n\n            if (progressive_score > 0) {\n\n                interlaced_score = s->dsp.ildct_cmp[4](s, ptr_y,\n\n                                                       NULL, wrap_y * 2, 8) +\n\n                                   s->dsp.ildct_cmp[4](s, ptr_y + wrap_y,\n\n                                                       NULL, wrap_y * 2, 8);\n\n                if (progressive_score > interlaced_score) {\n\n                    s->interlaced_dct = 1;\n\n\n\n                    dct_offset = wrap_y;\n\n                    uv_dct_offset = wrap_c;\n\n                    wrap_y <<= 1;\n\n                    if (s->chroma_format == CHROMA_422 ||\n\n                        s->chroma_format == CHROMA_444)\n\n                        wrap_c <<= 1;\n\n                }\n\n            }\n\n        }\n\n\n\n        s->dsp.get_pixels(s->block[0], ptr_y                  , wrap_y);\n\n        s->dsp.get_pixels(s->block[1], ptr_y              + 8 , wrap_y);\n\n        s->dsp.get_pixels(s->block[2], ptr_y + dct_offset     , wrap_y);\n\n        s->dsp.get_pixels(s->block[3], ptr_y + dct_offset + 8 , wrap_y);\n\n\n\n        if (s->flags & CODEC_FLAG_GRAY) {\n\n            skip_dct[4] = 1;\n\n            skip_dct[5] = 1;\n\n        } else {\n\n            s->dsp.get_pixels(s->block[4], ptr_cb, wrap_c);\n\n            s->dsp.get_pixels(s->block[5], ptr_cr, wrap_c);\n\n            if (!s->chroma_y_shift && s->chroma_x_shift) { /* 422 */\n\n                s->dsp.get_pixels(s->block[6], ptr_cb + uv_dct_offset, wrap_c);\n\n                s->dsp.get_pixels(s->block[7], ptr_cr + uv_dct_offset, wrap_c);\n\n            } else if (!s->chroma_y_shift && !s->chroma_x_shift) { /* 444 */\n\n                s->dsp.get_pixels(s->block[6], ptr_cb + 8, wrap_c);\n\n                s->dsp.get_pixels(s->block[7], ptr_cr + 8, wrap_c);\n\n                s->dsp.get_pixels(s->block[8], ptr_cb + uv_dct_offset, wrap_c);\n\n                s->dsp.get_pixels(s->block[9], ptr_cr + uv_dct_offset, wrap_c);\n\n                s->dsp.get_pixels(s->block[10], ptr_cb + uv_dct_offset + 8, wrap_c);\n\n                s->dsp.get_pixels(s->block[11], ptr_cr + uv_dct_offset + 8, wrap_c);\n\n            }\n\n        }\n\n    } else {\n\n        op_pixels_func (*op_pix)[4];\n\n        qpel_mc_func (*op_qpix)[16];\n\n        uint8_t *dest_y, *dest_cb, *dest_cr;\n\n\n\n        dest_y  = s->dest[0];\n\n        dest_cb = s->dest[1];\n\n        dest_cr = s->dest[2];\n\n\n\n        if ((!s->no_rounding) || s->pict_type == AV_PICTURE_TYPE_B) {\n\n            op_pix  = s->hdsp.put_pixels_tab;\n\n            op_qpix = s->dsp.put_qpel_pixels_tab;\n\n        } else {\n\n            op_pix  = s->hdsp.put_no_rnd_pixels_tab;\n\n            op_qpix = s->dsp.put_no_rnd_qpel_pixels_tab;\n\n        }\n\n\n\n        if (s->mv_dir & MV_DIR_FORWARD) {\n\n            ff_MPV_motion(s, dest_y, dest_cb, dest_cr, 0,\n\n                          s->last_picture.f.data,\n\n                          op_pix, op_qpix);\n\n            op_pix  = s->hdsp.avg_pixels_tab;\n\n            op_qpix = s->dsp.avg_qpel_pixels_tab;\n\n        }\n\n        if (s->mv_dir & MV_DIR_BACKWARD) {\n\n            ff_MPV_motion(s, dest_y, dest_cb, dest_cr, 1,\n\n                          s->next_picture.f.data,\n\n                          op_pix, op_qpix);\n\n        }\n\n\n\n        if (s->flags & CODEC_FLAG_INTERLACED_DCT) {\n\n            int progressive_score, interlaced_score;\n\n\n\n            s->interlaced_dct = 0;\n\n            progressive_score = s->dsp.ildct_cmp[0](s, dest_y,\n\n                                                    ptr_y,              wrap_y,\n\n                                                    8) +\n\n                                s->dsp.ildct_cmp[0](s, dest_y + wrap_y * 8,\n\n                                                    ptr_y + wrap_y * 8, wrap_y,\n\n                                                    8) - 400;\n\n\n\n            if (s->avctx->ildct_cmp == FF_CMP_VSSE)\n\n                progressive_score -= 400;\n\n\n\n            if (progressive_score > 0) {\n\n                interlaced_score = s->dsp.ildct_cmp[0](s, dest_y,\n\n                                                       ptr_y,\n\n                                                       wrap_y * 2, 8) +\n\n                                   s->dsp.ildct_cmp[0](s, dest_y + wrap_y,\n\n                                                       ptr_y + wrap_y,\n\n                                                       wrap_y * 2, 8);\n\n\n\n                if (progressive_score > interlaced_score) {\n\n                    s->interlaced_dct = 1;\n\n\n\n                    dct_offset = wrap_y;\n\n                    uv_dct_offset = wrap_c;\n\n                    wrap_y <<= 1;\n\n                    if (s->chroma_format == CHROMA_422)\n\n                        wrap_c <<= 1;\n\n                }\n\n            }\n\n        }\n\n\n\n        s->dsp.diff_pixels(s->block[0], ptr_y, dest_y, wrap_y);\n\n        s->dsp.diff_pixels(s->block[1], ptr_y + 8, dest_y + 8, wrap_y);\n\n        s->dsp.diff_pixels(s->block[2], ptr_y + dct_offset,\n\n                           dest_y + dct_offset, wrap_y);\n\n        s->dsp.diff_pixels(s->block[3], ptr_y + dct_offset + 8,\n\n                           dest_y + dct_offset + 8, wrap_y);\n\n\n\n        if (s->flags & CODEC_FLAG_GRAY) {\n\n            skip_dct[4] = 1;\n\n            skip_dct[5] = 1;\n\n        } else {\n\n            s->dsp.diff_pixels(s->block[4], ptr_cb, dest_cb, wrap_c);\n\n            s->dsp.diff_pixels(s->block[5], ptr_cr, dest_cr, wrap_c);\n\n            if (!s->chroma_y_shift) { /* 422 */\n\n                s->dsp.diff_pixels(s->block[6], ptr_cb + uv_dct_offset,\n\n                                   dest_cb + uv_dct_offset, wrap_c);\n\n                s->dsp.diff_pixels(s->block[7], ptr_cr + uv_dct_offset,\n\n                                   dest_cr + uv_dct_offset, wrap_c);\n\n            }\n\n        }\n\n        /* pre quantization */\n\n        if (s->current_picture.mc_mb_var[s->mb_stride * mb_y + mb_x] <\n\n                2 * s->qscale * s->qscale) {\n\n            // FIXME optimize\n\n            if (s->dsp.sad[1](NULL, ptr_y , dest_y,\n\n                              wrap_y, 8) < 20 * s->qscale)\n\n                skip_dct[0] = 1;\n\n            if (s->dsp.sad[1](NULL, ptr_y + 8,\n\n                              dest_y + 8, wrap_y, 8) < 20 * s->qscale)\n\n                skip_dct[1] = 1;\n\n            if (s->dsp.sad[1](NULL, ptr_y + dct_offset,\n\n                              dest_y + dct_offset, wrap_y, 8) < 20 * s->qscale)\n\n                skip_dct[2] = 1;\n\n            if (s->dsp.sad[1](NULL, ptr_y + dct_offset + 8,\n\n                              dest_y + dct_offset + 8,\n\n                              wrap_y, 8) < 20 * s->qscale)\n\n                skip_dct[3] = 1;\n\n            if (s->dsp.sad[1](NULL, ptr_cb, dest_cb,\n\n                              wrap_c, 8) < 20 * s->qscale)\n\n                skip_dct[4] = 1;\n\n            if (s->dsp.sad[1](NULL, ptr_cr, dest_cr,\n\n                              wrap_c, 8) < 20 * s->qscale)\n\n                skip_dct[5] = 1;\n\n            if (!s->chroma_y_shift) { /* 422 */\n\n                if (s->dsp.sad[1](NULL, ptr_cb + uv_dct_offset,\n\n                                  dest_cb + uv_dct_offset,\n\n                                  wrap_c, 8) < 20 * s->qscale)\n\n                    skip_dct[6] = 1;\n\n                if (s->dsp.sad[1](NULL, ptr_cr + uv_dct_offset,\n\n                                  dest_cr + uv_dct_offset,\n\n                                  wrap_c, 8) < 20 * s->qscale)\n\n                    skip_dct[7] = 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->quantizer_noise_shaping) {\n\n        if (!skip_dct[0])\n\n            get_visual_weight(weight[0], ptr_y                 , wrap_y);\n\n        if (!skip_dct[1])\n\n            get_visual_weight(weight[1], ptr_y              + 8, wrap_y);\n\n        if (!skip_dct[2])\n\n            get_visual_weight(weight[2], ptr_y + dct_offset    , wrap_y);\n\n        if (!skip_dct[3])\n\n            get_visual_weight(weight[3], ptr_y + dct_offset + 8, wrap_y);\n\n        if (!skip_dct[4])\n\n            get_visual_weight(weight[4], ptr_cb                , wrap_c);\n\n        if (!skip_dct[5])\n\n            get_visual_weight(weight[5], ptr_cr                , wrap_c);\n\n        if (!s->chroma_y_shift) { /* 422 */\n\n            if (!skip_dct[6])\n\n                get_visual_weight(weight[6], ptr_cb + uv_dct_offset,\n\n                                  wrap_c);\n\n            if (!skip_dct[7])\n\n                get_visual_weight(weight[7], ptr_cr + uv_dct_offset,\n\n                                  wrap_c);\n\n        }\n\n        memcpy(orig[0], s->block[0], sizeof(int16_t) * 64 * mb_block_count);\n\n    }\n\n\n\n    /* DCT & quantize */\n\n    av_assert2(s->out_format != FMT_MJPEG || s->qscale == 8);\n\n    {\n\n        for (i = 0; i < mb_block_count; i++) {\n\n            if (!skip_dct[i]) {\n\n                int overflow;\n\n                s->block_last_index[i] = s->dct_quantize(s, s->block[i], i, s->qscale, &overflow);\n\n                // FIXME we could decide to change to quantizer instead of\n\n                // clipping\n\n                // JS: I don't think that would be a good idea it could lower\n\n                //     quality instead of improve it. Just INTRADC clipping\n\n                //     deserves changes in quantizer\n\n                if (overflow)\n\n                    clip_coeffs(s, s->block[i], s->block_last_index[i]);\n\n            } else\n\n                s->block_last_index[i] = -1;\n\n        }\n\n        if (s->quantizer_noise_shaping) {\n\n            for (i = 0; i < mb_block_count; i++) {\n\n                if (!skip_dct[i]) {\n\n                    s->block_last_index[i] =\n\n                        dct_quantize_refine(s, s->block[i], weight[i],\n\n                                            orig[i], i, s->qscale);\n\n                }\n\n            }\n\n        }\n\n\n\n        if (s->luma_elim_threshold && !s->mb_intra)\n\n            for (i = 0; i < 4; i++)\n\n                dct_single_coeff_elimination(s, i, s->luma_elim_threshold);\n\n        if (s->chroma_elim_threshold && !s->mb_intra)\n\n            for (i = 4; i < mb_block_count; i++)\n\n                dct_single_coeff_elimination(s, i, s->chroma_elim_threshold);\n\n\n\n        if (s->mpv_flags & FF_MPV_FLAG_CBP_RD) {\n\n            for (i = 0; i < mb_block_count; i++) {\n\n                if (s->block_last_index[i] == -1)\n\n                    s->coded_score[i] = INT_MAX / 256;\n\n            }\n\n        }\n\n    }\n\n\n\n    if ((s->flags & CODEC_FLAG_GRAY) && s->mb_intra) {\n\n        s->block_last_index[4] =\n\n        s->block_last_index[5] = 0;\n\n        s->block[4][0] =\n\n        s->block[5][0] = (1024 + s->c_dc_scale / 2) / s->c_dc_scale;\n\n        if (!s->chroma_y_shift) { /* 422 / 444 */\n\n            for (i=6; i<12; i++) {\n\n                s->block_last_index[i] = 0;\n\n                s->block[i][0] = s->block[4][0];\n\n            }\n\n        }\n\n    }\n\n\n\n    // non c quantize code returns incorrect block_last_index FIXME\n\n    if (s->alternate_scan && s->dct_quantize != ff_dct_quantize_c) {\n\n        for (i = 0; i < mb_block_count; i++) {\n\n            int j;\n\n            if (s->block_last_index[i] > 0) {\n\n                for (j = 63; j > 0; j--) {\n\n                    if (s->block[i][s->intra_scantable.permutated[j]])\n\n                        break;\n\n                }\n\n                s->block_last_index[i] = j;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* huffman encode */\n\n    switch(s->codec_id){ //FIXME funct ptr could be slightly faster\n\n    case AV_CODEC_ID_MPEG1VIDEO:\n\n    case AV_CODEC_ID_MPEG2VIDEO:\n\n        if (CONFIG_MPEG1VIDEO_ENCODER || CONFIG_MPEG2VIDEO_ENCODER)\n\n            ff_mpeg1_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case AV_CODEC_ID_MPEG4:\n\n        if (CONFIG_MPEG4_ENCODER)\n\n            ff_mpeg4_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case AV_CODEC_ID_MSMPEG4V2:\n\n    case AV_CODEC_ID_MSMPEG4V3:\n\n    case AV_CODEC_ID_WMV1:\n\n        if (CONFIG_MSMPEG4_ENCODER)\n\n            ff_msmpeg4_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case AV_CODEC_ID_WMV2:\n\n        if (CONFIG_WMV2_ENCODER)\n\n            ff_wmv2_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case AV_CODEC_ID_H261:\n\n        if (CONFIG_H261_ENCODER)\n\n            ff_h261_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case AV_CODEC_ID_H263:\n\n    case AV_CODEC_ID_H263P:\n\n    case AV_CODEC_ID_FLV1:\n\n    case AV_CODEC_ID_RV10:\n\n    case AV_CODEC_ID_RV20:\n\n        if (CONFIG_H263_ENCODER)\n\n            ff_h263_encode_mb(s, s->block, motion_x, motion_y);\n\n        break;\n\n    case AV_CODEC_ID_MJPEG:\n\n    case AV_CODEC_ID_AMV:\n\n        if (CONFIG_MJPEG_ENCODER)\n\n            ff_mjpeg_encode_mb(s, s->block);\n\n        break;\n\n    default:\n\n        av_assert1(0);\n\n    }\n\n}\n", "idx": 16709, "_split": "valid", "_hash": "a2d53855a5f094d8e0bdec9f5888558f"}
{"project": "FFmpeg", "commit_id": "1109ed7973c7fd1e7001898adc4976590d862122", "target": 1, "func": "static void rtcp_send_sr(AVFormatContext *s1, int64_t ntp_time, int bye)\n\n{\n\n    RTPMuxContext *s = s1->priv_data;\n\n    uint32_t rtp_ts;\n\n\n\n    av_log(s1, AV_LOG_TRACE, \"RTCP: %02x %\"PRIx64\" %x\\n\", s->payload_type, ntp_time, s->timestamp);\n\n\n\n    s->last_rtcp_ntp_time = ntp_time;\n\n    rtp_ts = av_rescale_q(ntp_time - s->first_rtcp_ntp_time, (AVRational){1, 1000000},\n\n                          s1->streams[0]->time_base) + s->base_timestamp;\n\n    avio_w8(s1->pb, RTP_VERSION << 6);\n\n    avio_w8(s1->pb, RTCP_SR);\n\n    avio_wb16(s1->pb, 6); /* length in words - 1 */\n\n    avio_wb32(s1->pb, s->ssrc);\n\n    avio_wb64(s1->pb, NTP_TO_RTP_FORMAT(ntp_time));\n\n    avio_wb32(s1->pb, rtp_ts);\n\n    avio_wb32(s1->pb, s->packet_count);\n\n    avio_wb32(s1->pb, s->octet_count);\n\n\n\n    if (s->cname) {\n\n        int len = FFMIN(strlen(s->cname), 255);\n\n        avio_w8(s1->pb, (RTP_VERSION << 6) + 1);\n\n        avio_w8(s1->pb, RTCP_SDES);\n\n        avio_wb16(s1->pb, (7 + len + 3) / 4); /* length in words - 1 */\n\n\n\n        avio_wb32(s1->pb, s->ssrc);\n\n        avio_w8(s1->pb, 0x01); /* CNAME */\n\n        avio_w8(s1->pb, len);\n\n        avio_write(s1->pb, s->cname, len);\n\n        avio_w8(s1->pb, 0); /* END */\n\n        for (len = (7 + len) % 4; len % 4; len++)\n\n            avio_w8(s1->pb, 0);\n\n    }\n\n\n\n    if (bye) {\n\n        avio_w8(s1->pb, (RTP_VERSION << 6) | 1);\n\n        avio_w8(s1->pb, RTCP_BYE);\n\n        avio_wb16(s1->pb, 1); /* length in words - 1 */\n\n        avio_wb32(s1->pb, s->ssrc);\n\n    }\n\n\n\n    avio_flush(s1->pb);\n\n}\n", "idx": 16765, "_split": "valid", "_hash": "d0c9838ecb79d75601c2b179579587bf"}
{"project": "FFmpeg", "commit_id": "f7e1367f58263593e6cee3c282f7277d7ee9d553", "target": 0, "func": "static int msrle_decode_pal4(AVCodecContext *avctx, AVPicture *pic,\n\n                             GetByteContext *gb)\n\n{\n\n    unsigned char rle_code;\n\n    unsigned char extra_byte, odd_pixel;\n\n    unsigned char stream_byte;\n\n    unsigned int pixel_ptr = 0;\n\n    int row_dec = pic->linesize[0];\n\n    int row_ptr = (avctx->height - 1) * row_dec;\n\n    int frame_size = row_dec * avctx->height;\n\n    int i;\n\n\n\n    while (row_ptr >= 0) {\n\n        if (bytestream2_get_bytes_left(gb) <= 0) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"MS RLE: bytestream overrun, %d rows left\\n\",\n\n                   row_ptr);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        rle_code = stream_byte = bytestream2_get_byteu(gb);\n\n        if (rle_code == 0) {\n\n            /* fetch the next byte to see how to handle escape code */\n\n            stream_byte = bytestream2_get_byte(gb);\n\n            if (stream_byte == 0) {\n\n                /* line is done, goto the next one */\n\n                row_ptr -= row_dec;\n\n                pixel_ptr = 0;\n\n            } else if (stream_byte == 1) {\n\n                /* decode is done */\n\n                return 0;\n\n            } else if (stream_byte == 2) {\n\n                /* reposition frame decode coordinates */\n\n                stream_byte = bytestream2_get_byte(gb);\n\n                pixel_ptr += stream_byte;\n\n                stream_byte = bytestream2_get_byte(gb);\n\n                row_ptr -= stream_byte * row_dec;\n\n            } else {\n\n                // copy pixels from encoded stream\n\n                odd_pixel =  stream_byte & 1;\n\n                rle_code = (stream_byte + 1) / 2;\n\n                extra_byte = rle_code & 0x01;\n\n                if (row_ptr + pixel_ptr + stream_byte > frame_size ||\n\n                    bytestream2_get_bytes_left(gb) < rle_code) {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"MS RLE: frame/stream ptr just went out of bounds (copy)\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                for (i = 0; i < rle_code; i++) {\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    stream_byte = bytestream2_get_byteu(gb);\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte >> 4;\n\n                    pixel_ptr++;\n\n                    if (i + 1 == rle_code && odd_pixel)\n\n                        break;\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F;\n\n                    pixel_ptr++;\n\n                }\n\n\n\n                // if the RLE code is odd, skip a byte in the stream\n\n                if (extra_byte)\n\n                    bytestream2_skip(gb, 1);\n\n            }\n\n        } else {\n\n            // decode a run of data\n\n            if (row_ptr + pixel_ptr + stream_byte > frame_size) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"MS RLE: frame ptr just went out of bounds (run)\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            stream_byte = bytestream2_get_byte(gb);\n\n            for (i = 0; i < rle_code; i++) {\n\n                if (pixel_ptr >= avctx->width)\n\n                    break;\n\n                if ((i & 1) == 0)\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte >> 4;\n\n                else\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F;\n\n                pixel_ptr++;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* one last sanity check on the way out */\n\n    if (bytestream2_get_bytes_left(gb)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"MS RLE: ended frame decode with %d bytes left over\\n\",\n\n               bytestream2_get_bytes_left(gb));\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 16856, "_split": "valid", "_hash": "71719eef559c9618eea456253fcbe362"}
{"project": "FFmpeg", "commit_id": "b3f9f7a33337e9b64e6044b0010e2722fa0b2f9c", "target": 0, "func": "static AVStream *new_pes_av_stream(PESContext *pes, uint32_t prog_reg_desc, uint32_t code)\n\n{\n\n    AVStream *st = av_new_stream(pes->stream, pes->pid);\n\n\n\n    if (!st)\n\n        return NULL;\n\n\n\n    av_set_pts_info(st, 33, 1, 90000);\n\n    st->priv_data = pes;\n\n    st->codec->codec_type = CODEC_TYPE_DATA;\n\n    st->codec->codec_id   = CODEC_ID_NONE;\n\n    st->need_parsing = AVSTREAM_PARSE_FULL;\n\n    pes->st = st;\n\n\n\n    dprintf(pes->stream, \"stream_type=%x pid=%x prog_reg_desc=%.4s\\n\",\n\n            pes->stream_type, pes->pid, (char*)&prog_reg_desc);\n\n\n\n    st->codec->codec_tag = pes->stream_type;\n\n\n\n    mpegts_find_stream_type(st, pes->stream_type, ISO_types);\n\n    if (prog_reg_desc == AV_RL32(\"HDMV\") &&\n\n        st->codec->codec_id == CODEC_ID_NONE) {\n\n        mpegts_find_stream_type(st, pes->stream_type, HDMV_types);\n\n        if (pes->stream_type == 0x83) {\n\n            // HDMV TrueHD streams also contain an AC3 coded version of the\n\n            // audio track - add a second stream for this\n\n            AVStream *sub_st;\n\n            // priv_data cannot be shared between streams\n\n            PESContext *sub_pes = av_malloc(sizeof(*sub_pes));\n\n            if (!sub_pes)\n\n                return NULL;\n\n            memcpy(sub_pes, pes, sizeof(*sub_pes));\n\n\n\n            sub_st = av_new_stream(pes->stream, pes->pid);\n\n            if (!sub_st) {\n\n                av_free(sub_pes);\n\n                return NULL;\n\n            }\n\n\n\n            av_set_pts_info(sub_st, 33, 1, 90000);\n\n            sub_st->priv_data = sub_pes;\n\n            sub_st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n            sub_st->codec->codec_id   = CODEC_ID_AC3;\n\n            sub_st->need_parsing = AVSTREAM_PARSE_FULL;\n\n            sub_pes->sub_st = pes->sub_st = sub_st;\n\n        }\n\n    }\n\n    if (st->codec->codec_id == CODEC_ID_NONE)\n\n        mpegts_find_stream_type(st, pes->stream_type, MISC_types);\n\n\n\n    /* stream was not present in PMT, guess based on PES start code */\n\n    if (st->codec->codec_id == CODEC_ID_NONE) {\n\n        if (code >= 0x1c0 && code <= 0x1df) {\n\n            st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n            st->codec->codec_id = CODEC_ID_MP2;\n\n        } else if (code == 0x1bd) {\n\n            st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n            st->codec->codec_id = CODEC_ID_AC3;\n\n        }\n\n    }\n\n\n\n    return st;\n\n}\n", "idx": 16897, "_split": "valid", "_hash": "8676600155ce7d40648f71a2c8eb11d0"}
{"project": "FFmpeg", "commit_id": "fd1ef13bb4ac13f330178b4c2d67a62d3aaf46d9", "target": 1, "func": "void ff_er_frame_end(MpegEncContext *s){\n\n    int i, mb_x, mb_y, error, error_type, dc_error, mv_error, ac_error;\n\n    int distance;\n\n    int threshold_part[4]= {100,100,100};\n\n    int threshold= 50;\n\n    int is_intra_likely;\n\n    int size = s->b8_stride * 2 * s->mb_height;\n\n    Picture *pic= s->current_picture_ptr;\n\n\n\n    if(!s->error_recognition || s->error_count==0 || s->avctx->lowres ||\n\n       s->avctx->hwaccel ||\n\n       s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU ||\n\n\n       s->error_count==3*s->mb_width*(s->avctx->skip_top + s->avctx->skip_bottom)) return;\n\n\n\n    if(s->current_picture.motion_val[0] == NULL){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Warning MVs not available\\n\");\n\n\n\n        for(i=0; i<2; i++){\n\n            pic->ref_index[i]= av_mallocz(size * sizeof(uint8_t));\n\n            pic->motion_val_base[i]= av_mallocz((size+4) * 2 * sizeof(uint16_t));\n\n            pic->motion_val[i]= pic->motion_val_base[i]+4;\n\n        }\n\n        pic->motion_subsample_log2= 3;\n\n        s->current_picture= *s->current_picture_ptr;\n\n    }\n\n\n\n    for(i=0; i<2; i++){\n\n        if(pic->ref_index[i])\n\n            memset(pic->ref_index[i], 0, size * sizeof(uint8_t));\n\n    }\n\n\n\n    if(s->avctx->debug&FF_DEBUG_ER){\n\n        for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n            for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n                int status= s->error_status_table[mb_x + mb_y*s->mb_stride];\n\n\n\n                av_log(s->avctx, AV_LOG_DEBUG, \"%2X \", status);\n\n            }\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"\\n\");\n\n        }\n\n    }\n\n\n\n#if 1\n\n    /* handle overlapping slices */\n\n    for(error_type=1; error_type<=3; error_type++){\n\n        int end_ok=0;\n\n\n\n        for(i=s->mb_num-1; i>=0; i--){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error= s->error_status_table[mb_xy];\n\n\n\n            if(error&(1<<error_type))\n\n                end_ok=1;\n\n            if(error&(8<<error_type))\n\n                end_ok=1;\n\n\n\n            if(!end_ok)\n\n                s->error_status_table[mb_xy]|= 1<<error_type;\n\n\n\n            if(error&VP_START)\n\n                end_ok=0;\n\n        }\n\n    }\n\n#endif\n\n#if 1\n\n    /* handle slices with partitions of different length */\n\n    if(s->partitioned_frame){\n\n        int end_ok=0;\n\n\n\n        for(i=s->mb_num-1; i>=0; i--){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error= s->error_status_table[mb_xy];\n\n\n\n            if(error&AC_END)\n\n                end_ok=0;\n\n            if((error&MV_END) || (error&DC_END) || (error&AC_ERROR))\n\n                end_ok=1;\n\n\n\n            if(!end_ok)\n\n                s->error_status_table[mb_xy]|= AC_ERROR;\n\n\n\n            if(error&VP_START)\n\n                end_ok=0;\n\n        }\n\n    }\n\n#endif\n\n    /* handle missing slices */\n\n    if(s->error_recognition>=4){\n\n        int end_ok=1;\n\n\n\n        for(i=s->mb_num-2; i>=s->mb_width+100; i--){ //FIXME +100 hack\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error1= s->error_status_table[mb_xy  ];\n\n            int error2= s->error_status_table[s->mb_index2xy[i+1]];\n\n\n\n            if(error1&VP_START)\n\n                end_ok=1;\n\n\n\n            if(   error2==(VP_START|DC_ERROR|AC_ERROR|MV_ERROR|AC_END|DC_END|MV_END)\n\n               && error1!=(VP_START|DC_ERROR|AC_ERROR|MV_ERROR|AC_END|DC_END|MV_END)\n\n               && ((error1&AC_END) || (error1&DC_END) || (error1&MV_END))){ //end & uninit\n\n                end_ok=0;\n\n            }\n\n\n\n            if(!end_ok)\n\n                s->error_status_table[mb_xy]|= DC_ERROR|AC_ERROR|MV_ERROR;\n\n        }\n\n    }\n\n\n\n#if 1\n\n    /* backward mark errors */\n\n    distance=9999999;\n\n    for(error_type=1; error_type<=3; error_type++){\n\n        for(i=s->mb_num-1; i>=0; i--){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error= s->error_status_table[mb_xy];\n\n\n\n            if(!s->mbskip_table[mb_xy]) //FIXME partition specific\n\n                distance++;\n\n            if(error&(1<<error_type))\n\n                distance= 0;\n\n\n\n            if(s->partitioned_frame){\n\n                if(distance < threshold_part[error_type-1])\n\n                    s->error_status_table[mb_xy]|= 1<<error_type;\n\n            }else{\n\n                if(distance < threshold)\n\n                    s->error_status_table[mb_xy]|= 1<<error_type;\n\n            }\n\n\n\n            if(error&VP_START)\n\n                distance= 9999999;\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* forward mark errors */\n\n    error=0;\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        int old_error= s->error_status_table[mb_xy];\n\n\n\n        if(old_error&VP_START)\n\n            error= old_error& (DC_ERROR|AC_ERROR|MV_ERROR);\n\n        else{\n\n            error|= old_error& (DC_ERROR|AC_ERROR|MV_ERROR);\n\n            s->error_status_table[mb_xy]|= error;\n\n        }\n\n    }\n\n#if 1\n\n    /* handle not partitioned case */\n\n    if(!s->partitioned_frame){\n\n        for(i=0; i<s->mb_num; i++){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            error= s->error_status_table[mb_xy];\n\n            if(error&(AC_ERROR|DC_ERROR|MV_ERROR))\n\n                error|= AC_ERROR|DC_ERROR|MV_ERROR;\n\n            s->error_status_table[mb_xy]= error;\n\n        }\n\n    }\n\n#endif\n\n\n\n    dc_error= ac_error= mv_error=0;\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        error= s->error_status_table[mb_xy];\n\n        if(error&DC_ERROR) dc_error ++;\n\n        if(error&AC_ERROR) ac_error ++;\n\n        if(error&MV_ERROR) mv_error ++;\n\n    }\n\n    av_log(s->avctx, AV_LOG_INFO, \"concealing %d DC, %d AC, %d MV errors\\n\", dc_error, ac_error, mv_error);\n\n\n\n    is_intra_likely= is_intra_more_likely(s);\n\n\n\n    /* set unknown mb-type to most likely */\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        error= s->error_status_table[mb_xy];\n\n        if(!((error&DC_ERROR) && (error&MV_ERROR)))\n\n            continue;\n\n\n\n        if(is_intra_likely)\n\n            s->current_picture.mb_type[mb_xy]= MB_TYPE_INTRA4x4;\n\n        else\n\n            s->current_picture.mb_type[mb_xy]= MB_TYPE_16x16 | MB_TYPE_L0;\n\n    }\n\n\n\n    // change inter to intra blocks if no reference frames are available\n\n    if (!s->last_picture.data[0] && !s->next_picture.data[0])\n\n        for(i=0; i<s->mb_num; i++){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            if(!IS_INTRA(s->current_picture.mb_type[mb_xy]))\n\n                s->current_picture.mb_type[mb_xy]= MB_TYPE_INTRA4x4;\n\n        }\n\n\n\n    /* handle inter blocks with damaged AC */\n\n    for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n        for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n            const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n            const int mb_type= s->current_picture.mb_type[mb_xy];\n\n            int dir = !s->last_picture.data[0];\n\n            error= s->error_status_table[mb_xy];\n\n\n\n            if(IS_INTRA(mb_type)) continue; //intra\n\n            if(error&MV_ERROR) continue;              //inter with damaged MV\n\n            if(!(error&AC_ERROR)) continue;           //undamaged inter\n\n\n\n            s->mv_dir = dir ? MV_DIR_BACKWARD : MV_DIR_FORWARD;\n\n            s->mb_intra=0;\n\n            s->mb_skipped=0;\n\n            if(IS_8X8(mb_type)){\n\n                int mb_index= mb_x*2 + mb_y*2*s->b8_stride;\n\n                int j;\n\n                s->mv_type = MV_TYPE_8X8;\n\n                for(j=0; j<4; j++){\n\n                    s->mv[0][j][0] = s->current_picture.motion_val[dir][ mb_index + (j&1) + (j>>1)*s->b8_stride ][0];\n\n                    s->mv[0][j][1] = s->current_picture.motion_val[dir][ mb_index + (j&1) + (j>>1)*s->b8_stride ][1];\n\n                }\n\n            }else{\n\n                s->mv_type = MV_TYPE_16X16;\n\n                s->mv[0][0][0] = s->current_picture.motion_val[dir][ mb_x*2 + mb_y*2*s->b8_stride ][0];\n\n                s->mv[0][0][1] = s->current_picture.motion_val[dir][ mb_x*2 + mb_y*2*s->b8_stride ][1];\n\n            }\n\n\n\n            s->dsp.clear_blocks(s->block[0]);\n\n\n\n            s->mb_x= mb_x;\n\n            s->mb_y= mb_y;\n\n            decode_mb(s);\n\n        }\n\n    }\n\n\n\n    /* guess MVs */\n\n    if(s->pict_type==FF_B_TYPE){\n\n        for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n            for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n                int xy= mb_x*2 + mb_y*2*s->b8_stride;\n\n                const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n                const int mb_type= s->current_picture.mb_type[mb_xy];\n\n                error= s->error_status_table[mb_xy];\n\n\n\n                if(IS_INTRA(mb_type)) continue;\n\n                if(!(error&MV_ERROR)) continue;           //inter with undamaged MV\n\n                if(!(error&AC_ERROR)) continue;           //undamaged inter\n\n\n\n                s->mv_dir = MV_DIR_FORWARD|MV_DIR_BACKWARD;\n\n                if(!s->last_picture.data[0]) s->mv_dir &= ~MV_DIR_FORWARD;\n\n                if(!s->next_picture.data[0]) s->mv_dir &= ~MV_DIR_BACKWARD;\n\n                s->mb_intra=0;\n\n                s->mv_type = MV_TYPE_16X16;\n\n                s->mb_skipped=0;\n\n\n\n                if(s->pp_time){\n\n                    int time_pp= s->pp_time;\n\n                    int time_pb= s->pb_time;\n\n\n\n                    s->mv[0][0][0] = s->next_picture.motion_val[0][xy][0]*time_pb/time_pp;\n\n                    s->mv[0][0][1] = s->next_picture.motion_val[0][xy][1]*time_pb/time_pp;\n\n                    s->mv[1][0][0] = s->next_picture.motion_val[0][xy][0]*(time_pb - time_pp)/time_pp;\n\n                    s->mv[1][0][1] = s->next_picture.motion_val[0][xy][1]*(time_pb - time_pp)/time_pp;\n\n                }else{\n\n                    s->mv[0][0][0]= 0;\n\n                    s->mv[0][0][1]= 0;\n\n                    s->mv[1][0][0]= 0;\n\n                    s->mv[1][0][1]= 0;\n\n                }\n\n\n\n                s->dsp.clear_blocks(s->block[0]);\n\n                s->mb_x= mb_x;\n\n                s->mb_y= mb_y;\n\n                decode_mb(s);\n\n            }\n\n        }\n\n    }else\n\n        guess_mv(s);\n\n\n\n    /* the filters below are not XvMC compatible, skip them */\n\n    if(CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration)\n\n        goto ec_clean;\n\n    /* fill DC for inter blocks */\n\n    for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n        for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n            int dc, dcu, dcv, y, n;\n\n            int16_t *dc_ptr;\n\n            uint8_t *dest_y, *dest_cb, *dest_cr;\n\n            const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n            const int mb_type= s->current_picture.mb_type[mb_xy];\n\n\n\n            error= s->error_status_table[mb_xy];\n\n\n\n            if(IS_INTRA(mb_type) && s->partitioned_frame) continue;\n\n//            if(error&MV_ERROR) continue; //inter data damaged FIXME is this good?\n\n\n\n            dest_y = s->current_picture.data[0] + mb_x*16 + mb_y*16*s->linesize;\n\n            dest_cb= s->current_picture.data[1] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n            dest_cr= s->current_picture.data[2] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n\n\n            dc_ptr= &s->dc_val[0][mb_x*2 + mb_y*2*s->b8_stride];\n\n            for(n=0; n<4; n++){\n\n                dc=0;\n\n                for(y=0; y<8; y++){\n\n                    int x;\n\n                    for(x=0; x<8; x++){\n\n                       dc+= dest_y[x + (n&1)*8 + (y + (n>>1)*8)*s->linesize];\n\n                    }\n\n                }\n\n                dc_ptr[(n&1) + (n>>1)*s->b8_stride]= (dc+4)>>3;\n\n            }\n\n\n\n            dcu=dcv=0;\n\n            for(y=0; y<8; y++){\n\n                int x;\n\n                for(x=0; x<8; x++){\n\n                    dcu+=dest_cb[x + y*(s->uvlinesize)];\n\n                    dcv+=dest_cr[x + y*(s->uvlinesize)];\n\n                }\n\n            }\n\n            s->dc_val[1][mb_x + mb_y*s->mb_stride]= (dcu+4)>>3;\n\n            s->dc_val[2][mb_x + mb_y*s->mb_stride]= (dcv+4)>>3;\n\n        }\n\n    }\n\n#if 1\n\n    /* guess DC for damaged blocks */\n\n    guess_dc(s, s->dc_val[0], s->mb_width*2, s->mb_height*2, s->b8_stride, 1);\n\n    guess_dc(s, s->dc_val[1], s->mb_width  , s->mb_height  , s->mb_stride, 0);\n\n    guess_dc(s, s->dc_val[2], s->mb_width  , s->mb_height  , s->mb_stride, 0);\n\n#endif\n\n    /* filter luma DC */\n\n    filter181(s->dc_val[0], s->mb_width*2, s->mb_height*2, s->b8_stride);\n\n\n\n#if 1\n\n    /* render DC only intra */\n\n    for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n        for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n            uint8_t *dest_y, *dest_cb, *dest_cr;\n\n            const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n            const int mb_type= s->current_picture.mb_type[mb_xy];\n\n\n\n            error= s->error_status_table[mb_xy];\n\n\n\n            if(IS_INTER(mb_type)) continue;\n\n            if(!(error&AC_ERROR)) continue;              //undamaged\n\n\n\n            dest_y = s->current_picture.data[0] + mb_x*16 + mb_y*16*s->linesize;\n\n            dest_cb= s->current_picture.data[1] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n            dest_cr= s->current_picture.data[2] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n\n\n            put_dc(s, dest_y, dest_cb, dest_cr, mb_x, mb_y);\n\n        }\n\n    }\n\n#endif\n\n\n\n    if(s->avctx->error_concealment&FF_EC_DEBLOCK){\n\n        /* filter horizontal block boundaries */\n\n        h_block_filter(s, s->current_picture.data[0], s->mb_width*2, s->mb_height*2, s->linesize  , 1);\n\n        h_block_filter(s, s->current_picture.data[1], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n        h_block_filter(s, s->current_picture.data[2], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n\n\n        /* filter vertical block boundaries */\n\n        v_block_filter(s, s->current_picture.data[0], s->mb_width*2, s->mb_height*2, s->linesize  , 1);\n\n        v_block_filter(s, s->current_picture.data[1], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n        v_block_filter(s, s->current_picture.data[2], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n    }\n\n\n\nec_clean:\n\n    /* clean a few tables */\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        int error= s->error_status_table[mb_xy];\n\n\n\n        if(s->pict_type!=FF_B_TYPE && (error&(DC_ERROR|MV_ERROR|AC_ERROR))){\n\n            s->mbskip_table[mb_xy]=0;\n\n        }\n\n        s->mbintra_table[mb_xy]=1;\n\n    }\n\n}", "idx": 16921, "_split": "valid", "_hash": "8bbe3c329eadafdd064e27aa8a7205c8"}
{"project": "FFmpeg", "commit_id": "956c901c68eff78288f40e3c8f41ee2fa081d4a8", "target": 1, "func": "static int matroska_deliver_packet(MatroskaDemuxContext *matroska,\n\n                                   AVPacket *pkt)\n\n{\n\n    if (matroska->num_packets > 0) {\n\n        memcpy(pkt, matroska->packets[0], sizeof(AVPacket));\n\n        av_free(matroska->packets[0]);\n\n        if (matroska->num_packets > 1) {\n\n            memmove(&matroska->packets[0], &matroska->packets[1],\n\n                    (matroska->num_packets - 1) * sizeof(AVPacket *));\n\n            matroska->packets =\n\n                av_realloc(matroska->packets, (matroska->num_packets - 1) *\n\n                           sizeof(AVPacket *));\n\n        } else {\n\n            av_freep(&matroska->packets);\n\n        }\n\n        matroska->num_packets--;\n\n        return 0;\n\n    }\n\n\n\n    return -1;\n\n}\n", "idx": 16932, "_split": "valid", "_hash": "bce6d2be35ba0dd05970a1e324764ad7"}
{"project": "FFmpeg", "commit_id": "c742ab4e81bb9dcabfdab006d6b8b09a5808c4ce", "target": 0, "func": "static int vc1_parse_init(AVCodecParserContext *s)\n\n{\n\n    VC1ParseContext *vpc = s->priv_data;\n\n    vpc->v.s.slice_context_count = 1;\n\n    return 0;\n\n}\n", "idx": 16942, "_split": "valid", "_hash": "4bccc47d36a8d8390fae2fad91db94ca"}
{"project": "FFmpeg", "commit_id": "b3570f03893cc6f29472f418a144252fe7a5e207", "target": 0, "func": "static int decode_simple_internal(AVCodecContext *avctx, AVFrame *frame)\n\n{\n\n    AVCodecInternal   *avci = avctx->internal;\n\n    DecodeSimpleContext *ds = &avci->ds;\n\n    AVPacket           *pkt = ds->in_pkt;\n\n    // copy to ensure we do not change pkt\n\n    AVPacket tmp;\n\n    int got_frame, actual_got_frame, did_split;\n\n    int ret;\n\n\n\n    if (!pkt->data && !avci->draining) {\n\n        av_packet_unref(pkt);\n\n        ret = ff_decode_get_packet(avctx, pkt);\n\n        if (ret < 0 && ret != AVERROR_EOF)\n\n            return ret;\n\n    }\n\n\n\n    // Some codecs (at least wma lossless) will crash when feeding drain packets\n\n    // after EOF was signaled.\n\n    if (avci->draining_done)\n\n        return AVERROR_EOF;\n\n\n\n    if (!pkt->data &&\n\n        !(avctx->codec->capabilities & AV_CODEC_CAP_DELAY ||\n\n          avctx->active_thread_type & FF_THREAD_FRAME))\n\n        return AVERROR_EOF;\n\n\n\n    tmp = *pkt;\n\n#if FF_API_MERGE_SD\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    did_split = av_packet_split_side_data(&tmp);\n\n\n\n    if (did_split) {\n\n        ret = extract_packet_props(avctx->internal, &tmp);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = apply_param_change(avctx, &tmp);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    got_frame = 0;\n\n\n\n    if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME) {\n\n        ret = ff_thread_decode_frame(avctx, frame, &got_frame, &tmp);\n\n    } else {\n\n        ret = avctx->codec->decode(avctx, frame, &got_frame, &tmp);\n\n\n\n        if (avctx->codec->type == AVMEDIA_TYPE_VIDEO) {\n\n            if (!(avctx->codec->caps_internal & FF_CODEC_CAP_SETS_PKT_DTS))\n\n                frame->pkt_dts = pkt->dts;\n\n            if(!avctx->has_b_frames)\n\n                frame->pkt_pos = pkt->pos;\n\n            //FIXME these should be under if(!avctx->has_b_frames)\n\n            /* get_buffer is supposed to set frame parameters */\n\n            if (!(avctx->codec->capabilities & AV_CODEC_CAP_DR1)) {\n\n                if (!frame->sample_aspect_ratio.num)  frame->sample_aspect_ratio = avctx->sample_aspect_ratio;\n\n                if (!frame->width)                    frame->width               = avctx->width;\n\n                if (!frame->height)                   frame->height              = avctx->height;\n\n                if (frame->format == AV_PIX_FMT_NONE) frame->format              = avctx->pix_fmt;\n\n            }\n\n        } else if (avctx->codec->type == AVMEDIA_TYPE_AUDIO) {\n\n            frame->pkt_dts = pkt->dts;\n\n        }\n\n    }\n\n    emms_c();\n\n    actual_got_frame = got_frame;\n\n\n\n    if (avctx->codec->type == AVMEDIA_TYPE_VIDEO) {\n\n        if (frame->flags & AV_FRAME_FLAG_DISCARD)\n\n            got_frame = 0;\n\n        if (got_frame)\n\n            frame->best_effort_timestamp = guess_correct_pts(avctx,\n\n                                                             frame->pts,\n\n                                                             frame->pkt_dts);\n\n    } else if (avctx->codec->type == AVMEDIA_TYPE_AUDIO) {\n\n        uint8_t *side;\n\n        int side_size;\n\n        uint32_t discard_padding = 0;\n\n        uint8_t skip_reason = 0;\n\n        uint8_t discard_reason = 0;\n\n\n\n        if (ret >= 0 && got_frame) {\n\n            frame->best_effort_timestamp = guess_correct_pts(avctx,\n\n                                                             frame->pts,\n\n                                                             frame->pkt_dts);\n\n            if (frame->format == AV_SAMPLE_FMT_NONE)\n\n                frame->format = avctx->sample_fmt;\n\n            if (!frame->channel_layout)\n\n                frame->channel_layout = avctx->channel_layout;\n\n            if (!frame->channels)\n\n                frame->channels = avctx->channels;\n\n            if (!frame->sample_rate)\n\n                frame->sample_rate = avctx->sample_rate;\n\n        }\n\n\n\n        side= av_packet_get_side_data(pkt, AV_PKT_DATA_SKIP_SAMPLES, &side_size);\n\n        if(side && side_size>=10) {\n\n            avctx->internal->skip_samples = AV_RL32(side) * avctx->internal->skip_samples_multiplier;\n\n            discard_padding = AV_RL32(side + 4);\n\n            av_log(avctx, AV_LOG_DEBUG, \"skip %d / discard %d samples due to side data\\n\",\n\n                   avctx->internal->skip_samples, (int)discard_padding);\n\n            skip_reason = AV_RL8(side + 8);\n\n            discard_reason = AV_RL8(side + 9);\n\n        }\n\n\n\n        if ((frame->flags & AV_FRAME_FLAG_DISCARD) && got_frame &&\n\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n\n            avctx->internal->skip_samples = FFMAX(0, avctx->internal->skip_samples - frame->nb_samples);\n\n            got_frame = 0;\n\n        }\n\n\n\n        if (avctx->internal->skip_samples > 0 && got_frame &&\n\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n\n            if(frame->nb_samples <= avctx->internal->skip_samples){\n\n                got_frame = 0;\n\n                avctx->internal->skip_samples -= frame->nb_samples;\n\n                av_log(avctx, AV_LOG_DEBUG, \"skip whole frame, skip left: %d\\n\",\n\n                       avctx->internal->skip_samples);\n\n            } else {\n\n                av_samples_copy(frame->extended_data, frame->extended_data, 0, avctx->internal->skip_samples,\n\n                                frame->nb_samples - avctx->internal->skip_samples, avctx->channels, frame->format);\n\n                if(avctx->pkt_timebase.num && avctx->sample_rate) {\n\n                    int64_t diff_ts = av_rescale_q(avctx->internal->skip_samples,\n\n                                                   (AVRational){1, avctx->sample_rate},\n\n                                                   avctx->pkt_timebase);\n\n                    if(frame->pts!=AV_NOPTS_VALUE)\n\n                        frame->pts += diff_ts;\n\n#if FF_API_PKT_PTS\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n                    if(frame->pkt_pts!=AV_NOPTS_VALUE)\n\n                        frame->pkt_pts += diff_ts;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n                    if(frame->pkt_dts!=AV_NOPTS_VALUE)\n\n                        frame->pkt_dts += diff_ts;\n\n                    if (frame->pkt_duration >= diff_ts)\n\n                        frame->pkt_duration -= diff_ts;\n\n                } else {\n\n                    av_log(avctx, AV_LOG_WARNING, \"Could not update timestamps for skipped samples.\\n\");\n\n                }\n\n                av_log(avctx, AV_LOG_DEBUG, \"skip %d/%d samples\\n\",\n\n                       avctx->internal->skip_samples, frame->nb_samples);\n\n                frame->nb_samples -= avctx->internal->skip_samples;\n\n                avctx->internal->skip_samples = 0;\n\n            }\n\n        }\n\n\n\n        if (discard_padding > 0 && discard_padding <= frame->nb_samples && got_frame &&\n\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n\n            if (discard_padding == frame->nb_samples) {\n\n                got_frame = 0;\n\n            } else {\n\n                if(avctx->pkt_timebase.num && avctx->sample_rate) {\n\n                    int64_t diff_ts = av_rescale_q(frame->nb_samples - discard_padding,\n\n                                                   (AVRational){1, avctx->sample_rate},\n\n                                                   avctx->pkt_timebase);\n\n                    frame->pkt_duration = diff_ts;\n\n                } else {\n\n                    av_log(avctx, AV_LOG_WARNING, \"Could not update timestamps for discarded samples.\\n\");\n\n                }\n\n                av_log(avctx, AV_LOG_DEBUG, \"discard %d/%d samples\\n\",\n\n                       (int)discard_padding, frame->nb_samples);\n\n                frame->nb_samples -= discard_padding;\n\n            }\n\n        }\n\n\n\n        if ((avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL) && got_frame) {\n\n            AVFrameSideData *fside = av_frame_new_side_data(frame, AV_FRAME_DATA_SKIP_SAMPLES, 10);\n\n            if (fside) {\n\n                AV_WL32(fside->data, avctx->internal->skip_samples);\n\n                AV_WL32(fside->data + 4, discard_padding);\n\n                AV_WL8(fside->data + 8, skip_reason);\n\n                AV_WL8(fside->data + 9, discard_reason);\n\n                avctx->internal->skip_samples = 0;\n\n            }\n\n        }\n\n    }\n\n#if FF_API_MERGE_SD\n\n    if (did_split) {\n\n        av_packet_free_side_data(&tmp);\n\n        if(ret == tmp.size)\n\n            ret = pkt->size;\n\n    }\n\n#endif\n\n\n\n    if (avctx->codec->type == AVMEDIA_TYPE_AUDIO &&\n\n        !avci->showed_multi_packet_warning &&\n\n        ret >= 0 && ret != pkt->size && !(avctx->codec->capabilities & AV_CODEC_CAP_SUBFRAMES)) {\n\n        av_log(avctx, AV_LOG_WARNING, \"Multiple frames in a packet.\\n\");\n\n        avci->showed_multi_packet_warning = 1;\n\n    }\n\n\n\n    if (!got_frame)\n\n        av_frame_unref(frame);\n\n\n\n    if (ret >= 0 && avctx->codec->type == AVMEDIA_TYPE_VIDEO && !(avctx->flags & AV_CODEC_FLAG_TRUNCATED))\n\n        ret = pkt->size;\n\n\n\n#if FF_API_AVCTX_TIMEBASE\n\n    if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n\n        avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n\n#endif\n\n\n\n    /* do not stop draining when actual_got_frame != 0 or ret < 0 */\n\n    /* got_frame == 0 but actual_got_frame != 0 when frame is discarded */\n\n    if (avctx->internal->draining && !actual_got_frame) {\n\n        if (ret < 0) {\n\n            /* prevent infinite loop if a decoder wrongly always return error on draining */\n\n            /* reasonable nb_errors_max = maximum b frames + thread count */\n\n            int nb_errors_max = 20 + (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME ?\n\n                                avctx->thread_count : 1);\n\n\n\n            if (avci->nb_draining_errors++ >= nb_errors_max) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Too many errors when draining, this is a bug. \"\n\n                       \"Stop draining and force EOF.\\n\");\n\n                avci->draining_done = 1;\n\n                ret = AVERROR_BUG;\n\n            }\n\n        } else {\n\n            avci->draining_done = 1;\n\n        }\n\n    }\n\n\n\n    avci->compat_decode_consumed += ret;\n\n\n\n    if (ret >= pkt->size || ret < 0) {\n\n        av_packet_unref(pkt);\n\n    } else {\n\n        int consumed = ret;\n\n\n\n        pkt->data                += consumed;\n\n        pkt->size                -= consumed;\n\n        avci->last_pkt_props->size -= consumed; // See extract_packet_props() comment.\n\n        pkt->pts                  = AV_NOPTS_VALUE;\n\n        pkt->dts                  = AV_NOPTS_VALUE;\n\n        avci->last_pkt_props->pts = AV_NOPTS_VALUE;\n\n        avci->last_pkt_props->dts = AV_NOPTS_VALUE;\n\n    }\n\n\n\n    if (got_frame)\n\n        av_assert0(frame->buf[0]);\n\n\n\n    return ret < 0 ? ret : 0;\n\n}\n", "idx": 16943, "_split": "valid", "_hash": "8c02a1f6e329a02fa468839e4f5d6de7"}
{"project": "FFmpeg", "commit_id": "2f3b028c7117e03267ea7f88d0d612e70f1afc06", "target": 1, "func": "static void json_print_chapter_header(WriterContext *wctx, const char *chapter)\n\n{\n\n    JSONContext *json = wctx->priv;\n\n    char *chapter_esc;\n\n\n\n    if (wctx->nb_chapter)\n\n        printf(\",\");\n\n    json->multiple_entries = !strcmp(chapter, \"packets\") || !strcmp(chapter, \"streams\");\n\n    chapter_esc = json_escape_str(chapter);\n\n    printf(\"\\n  \\\"%s\\\":%s\", chapter_esc ? chapter_esc : \"\",\n\n           json->multiple_entries ? \" [\" : \" \");\n\n    av_free(chapter_esc);\n\n}\n", "idx": 16969, "_split": "valid", "_hash": "3beddef1b945a845e5d321917793dd8b"}
{"project": "FFmpeg", "commit_id": "dc0bc0f84ec3ecc475182c5c2934ca8ef5a45de2", "target": 0, "func": "static int compute_bit_allocation(AC3EncodeContext *s,\n\n                                  uint8_t bap[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS][AC3_MAX_COEFS],\n\n                                  uint8_t encoded_exp[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS][AC3_MAX_COEFS],\n\n                                  uint8_t exp_strategy[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS],\n\n                                  int frame_bits)\n\n{\n\n    int blk, ch;\n\n    int coarse_snr_offset, fine_snr_offset;\n\n    uint8_t bap1[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS][AC3_MAX_COEFS];\n\n    int16_t psd[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS][AC3_MAX_COEFS];\n\n    int16_t mask[AC3_MAX_BLOCKS][AC3_MAX_CHANNELS][AC3_CRITICAL_BANDS];\n\n    static const int frame_bits_inc[8] = { 0, 0, 2, 2, 2, 4, 2, 4 };\n\n\n\n    /* init default parameters */\n\n    s->slow_decay_code = 2;\n\n    s->fast_decay_code = 1;\n\n    s->slow_gain_code  = 1;\n\n    s->db_per_bit_code = 2;\n\n    s->floor_code      = 4;\n\n    for (ch = 0; ch < s->channels; ch++)\n\n        s->fast_gain_code[ch] = 4;\n\n\n\n    /* compute real values */\n\n    s->bit_alloc.slow_decay = ff_ac3_slow_decay_tab[s->slow_decay_code] >> s->bit_alloc.sr_shift;\n\n    s->bit_alloc.fast_decay = ff_ac3_fast_decay_tab[s->fast_decay_code] >> s->bit_alloc.sr_shift;\n\n    s->bit_alloc.slow_gain  = ff_ac3_slow_gain_tab[s->slow_gain_code];\n\n    s->bit_alloc.db_per_bit = ff_ac3_db_per_bit_tab[s->db_per_bit_code];\n\n    s->bit_alloc.floor      = ff_ac3_floor_tab[s->floor_code];\n\n\n\n    /* header size */\n\n    frame_bits += 65;\n\n    // if (s->channel_mode == 2)\n\n    //    frame_bits += 2;\n\n    frame_bits += frame_bits_inc[s->channel_mode];\n\n\n\n    /* audio blocks */\n\n    for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n        frame_bits += s->fbw_channels * 2 + 2; /* blksw * c, dithflag * c, dynrnge, cplstre */\n\n        if (s->channel_mode == AC3_CHMODE_STEREO) {\n\n            frame_bits++; /* rematstr */\n\n            if (!blk)\n\n                frame_bits += 4;\n\n        }\n\n        frame_bits += 2 * s->fbw_channels; /* chexpstr[2] * c */\n\n        if (s->lfe_on)\n\n            frame_bits++; /* lfeexpstr */\n\n        for (ch = 0; ch < s->fbw_channels; ch++) {\n\n            if (exp_strategy[blk][ch] != EXP_REUSE)\n\n                frame_bits += 6 + 2; /* chbwcod[6], gainrng[2] */\n\n        }\n\n        frame_bits++; /* baie */\n\n        frame_bits++; /* snr */\n\n        frame_bits += 2; /* delta / skip */\n\n    }\n\n    frame_bits++; /* cplinu for block 0 */\n\n    /* bit alloc info */\n\n    /* sdcycod[2], fdcycod[2], sgaincod[2], dbpbcod[2], floorcod[3] */\n\n    /* csnroffset[6] */\n\n    /* (fsnoffset[4] + fgaincod[4]) * c */\n\n    frame_bits += 2*4 + 3 + 6 + s->channels * (4 + 3);\n\n\n\n    /* auxdatae, crcrsv */\n\n    frame_bits += 2;\n\n\n\n    /* CRC */\n\n    frame_bits += 16;\n\n\n\n    /* calculate psd and masking curve before doing bit allocation */\n\n    bit_alloc_masking(s, encoded_exp, exp_strategy, psd, mask);\n\n\n\n    /* now the big work begins : do the bit allocation. Modify the snr\n\n       offset until we can pack everything in the requested frame size */\n\n\n\n    coarse_snr_offset = s->coarse_snr_offset;\n\n    while (coarse_snr_offset >= 0 &&\n\n           bit_alloc(s, mask, psd, bap, frame_bits, coarse_snr_offset, 0) < 0)\n\n        coarse_snr_offset -= SNR_INC1;\n\n    if (coarse_snr_offset < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Bit allocation failed. Try increasing the bitrate.\\n\");\n\n        return -1;\n\n    }\n\n    while (coarse_snr_offset + SNR_INC1 <= 63 &&\n\n           bit_alloc(s, mask, psd, bap1, frame_bits,\n\n                     coarse_snr_offset + SNR_INC1, 0) >= 0) {\n\n        coarse_snr_offset += SNR_INC1;\n\n        memcpy(bap, bap1, sizeof(bap1));\n\n    }\n\n    while (coarse_snr_offset + 1 <= 63 &&\n\n           bit_alloc(s, mask, psd, bap1, frame_bits, coarse_snr_offset + 1, 0) >= 0) {\n\n        coarse_snr_offset++;\n\n        memcpy(bap, bap1, sizeof(bap1));\n\n    }\n\n\n\n    fine_snr_offset = 0;\n\n    while (fine_snr_offset + SNR_INC1 <= 15 &&\n\n           bit_alloc(s, mask, psd, bap1, frame_bits,\n\n                     coarse_snr_offset, fine_snr_offset + SNR_INC1) >= 0) {\n\n        fine_snr_offset += SNR_INC1;\n\n        memcpy(bap, bap1, sizeof(bap1));\n\n    }\n\n    while (fine_snr_offset + 1 <= 15 &&\n\n           bit_alloc(s, mask, psd, bap1, frame_bits,\n\n                     coarse_snr_offset, fine_snr_offset + 1) >= 0) {\n\n        fine_snr_offset++;\n\n        memcpy(bap, bap1, sizeof(bap1));\n\n    }\n\n\n\n    s->coarse_snr_offset = coarse_snr_offset;\n\n    for (ch = 0; ch < s->channels; ch++)\n\n        s->fine_snr_offset[ch] = fine_snr_offset;\n\n\n\n    return 0;\n\n}\n", "idx": 16981, "_split": "valid", "_hash": "e23d3bfdf9dabbfa9d83005b7d0ecba0"}
{"project": "FFmpeg", "commit_id": "c8dcff0cdb17d0aa03ac729eba12d1a20f1f59c8", "target": 0, "func": "static int h264_frame_start(H264Context *h)\n\n{\n\n    H264Picture *pic;\n\n    int i, ret;\n\n    const int pixel_shift = h->pixel_shift;\n\n\n\n    ret = initialize_cur_frame(h);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    pic = h->cur_pic_ptr;\n\n    pic->reference              = h->droppable ? 0 : h->picture_structure;\n\n    pic->f->coded_picture_number = h->coded_picture_number++;\n\n    pic->field_picture          = h->picture_structure != PICT_FRAME;\n\n    pic->frame_num               = h->frame_num;\n\n    /*\n\n     * Zero key_frame here; IDR markings per slice in frame or fields are ORed\n\n     * in later.\n\n     * See decode_nal_units().\n\n     */\n\n    pic->f->key_frame = 0;\n\n    pic->mmco_reset  = 0;\n\n    pic->recovered   = 0;\n\n\n\n    if (CONFIG_ERROR_RESILIENCE && h->enable_er)\n\n        ff_er_frame_start(&h->slice_ctx[0].er);\n\n\n\n    for (i = 0; i < 16; i++) {\n\n        h->block_offset[i]           = (4 * ((scan8[i] - scan8[0]) & 7) << pixel_shift) + 4 * pic->f->linesize[0] * ((scan8[i] - scan8[0]) >> 3);\n\n        h->block_offset[48 + i]      = (4 * ((scan8[i] - scan8[0]) & 7) << pixel_shift) + 8 * pic->f->linesize[0] * ((scan8[i] - scan8[0]) >> 3);\n\n    }\n\n    for (i = 0; i < 16; i++) {\n\n        h->block_offset[16 + i]      =\n\n        h->block_offset[32 + i]      = (4 * ((scan8[i] - scan8[0]) & 7) << pixel_shift) + 4 * pic->f->linesize[1] * ((scan8[i] - scan8[0]) >> 3);\n\n        h->block_offset[48 + 16 + i] =\n\n        h->block_offset[48 + 32 + i] = (4 * ((scan8[i] - scan8[0]) & 7) << pixel_shift) + 8 * pic->f->linesize[1] * ((scan8[i] - scan8[0]) >> 3);\n\n    }\n\n\n\n    /* Some macroblocks can be accessed before they're available in case\n\n     * of lost slices, MBAFF or threading. */\n\n    memset(h->slice_table, -1,\n\n           (h->mb_height * h->mb_stride - 1) * sizeof(*h->slice_table));\n\n\n\n    /* We mark the current picture as non-reference after allocating it, so\n\n     * that if we break out due to an error it can be released automatically\n\n     * in the next ff_mpv_frame_start().\n\n     */\n\n    h->cur_pic_ptr->reference = 0;\n\n\n\n    h->cur_pic_ptr->field_poc[0] = h->cur_pic_ptr->field_poc[1] = INT_MAX;\n\n\n\n    h->next_output_pic = NULL;\n\n\n\n    assert(h->cur_pic_ptr->long_ref == 0);\n\n\n\n    return 0;\n\n}\n", "idx": 16988, "_split": "valid", "_hash": "c3f7bf8198e1f32fbd1282b6ca89b0f0"}
{"project": "FFmpeg", "commit_id": "e0c6cce44729d94e2a5507a4b6d031f23e8bd7b6", "target": 0, "func": "DECLARE_WEIGHT(sse2)\n\nDECLARE_WEIGHT(ssse3)\n\n\n\n/** @{ */\n\n/**\n\n * Define one qpel function.\n\n * LOOPSIZE must be already set to the number of pixels processed per\n\n * iteration in the inner loop of the called functions.\n\n * COFF(x) must be already defined so as to provide the offset into any\n\n * array of coeffs used by the called function for the qpel position x.\n\n */\n\n#define QPEL_FUNC_DECL(OP, SIZE, PH, PV, OPT)                           \\\n\nstatic void OP ## rv40_qpel ##SIZE ##_mc ##PH ##PV ##OPT(uint8_t *dst,  \\\n\n                                                         uint8_t *src,  \\\n\n                                                         int stride)    \\\n\n{                                                                       \\\n\n    int i;                                                              \\\n\n    if (PH && PV) {                                                     \\\n\n        DECLARE_ALIGNED(16, uint8_t, tmp)[SIZE * (SIZE + 5)];           \\\n\n        uint8_t *tmpptr = tmp + SIZE * 2;                               \\\n\n        src -= stride * 2;                                              \\\n\n                                                                        \\\n\n        for (i = 0; i < SIZE; i += LOOPSIZE)                            \\\n\n            ff_put_rv40_qpel_h ##OPT(tmp + i, SIZE, src + i, stride,    \\\n\n                                     SIZE + 5, HCOFF(PH));              \\\n\n        for (i = 0; i < SIZE; i += LOOPSIZE)                            \\\n\n            ff_ ##OP ##rv40_qpel_v ##OPT(dst + i, stride, tmpptr + i,   \\\n\n                                         SIZE, SIZE, VCOFF(PV));        \\\n\n    } else if (PV) {                                                    \\\n\n        for (i = 0; i < SIZE; i += LOOPSIZE)                            \\\n\n            ff_ ##OP ##rv40_qpel_v ## OPT(dst + i, stride, src + i,     \\\n\n                                          stride, SIZE, VCOFF(PV));     \\\n\n    } else {                                                            \\\n\n        for (i = 0; i < SIZE; i += LOOPSIZE)                            \\\n\n            ff_ ##OP ##rv40_qpel_h ## OPT(dst + i, stride, src + i,     \\\n\n                                          stride, SIZE, HCOFF(PH));     \\\n\n    }                                                                   \\\n\n};\n\n\n\n/** Declare functions for sizes 8 and 16 and given operations\n\n *  and qpel position. */\n\n#define QPEL_FUNCS_DECL(OP, PH, PV, OPT) \\\n\n    QPEL_FUNC_DECL(OP,  8, PH, PV, OPT)  \\\n\n    QPEL_FUNC_DECL(OP, 16, PH, PV, OPT)\n\n\n\n/** Declare all functions for all sizes and qpel positions */\n\n#define QPEL_MC_DECL(OP, OPT)                                           \\\n\nvoid ff_ ##OP ##rv40_qpel_h ##OPT(uint8_t *dst, ptrdiff_t dstStride,    \\\n\n                                  const uint8_t *src,                   \\\n\n                                  ptrdiff_t srcStride,                  \\\n\n                                  int len, int m);                      \\\n\nvoid ff_ ##OP ##rv40_qpel_v ##OPT(uint8_t *dst, ptrdiff_t dstStride,    \\\n\n                                  const uint8_t *src,                   \\\n\n                                  ptrdiff_t srcStride,                  \\\n\n                                  int len, int m);                      \\\n\nQPEL_FUNCS_DECL(OP, 0, 1, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 0, 3, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 1, 0, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 1, 1, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 1, 2, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 1, 3, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 2, 1, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 2, 2, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 2, 3, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 3, 0, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 3, 1, OPT)                                          \\\n\nQPEL_FUNCS_DECL(OP, 3, 2, OPT)\n\n/** @} */\n\n\n\n#define LOOPSIZE  8\n\n#define HCOFF(x)  (32 * (x - 1))\n\n#define VCOFF(x)  (32 * (x - 1))\n\nQPEL_MC_DECL(put_, _ssse3)\n\nQPEL_MC_DECL(avg_, _ssse3)\n\n\n\n#undef LOOPSIZE\n\n#undef HCOFF\n\n#undef VCOFF\n\n#define LOOPSIZE  8\n\n#define HCOFF(x)  (64 * (x - 1))\n\n#define VCOFF(x)  (64 * (x - 1))\n\nQPEL_MC_DECL(put_, _sse2)\n\nQPEL_MC_DECL(avg_, _sse2)\n\n\n\n#if ARCH_X86_32\n\n#undef LOOPSIZE\n\n#undef HCOFF\n\n#undef VCOFF\n\n#define LOOPSIZE  4\n\n#define HCOFF(x)  (64 * (x - 1))\n\n#define VCOFF(x)  (64 * (x - 1))\n\n\n\nQPEL_MC_DECL(put_, _mmx)\n\n\n\n#define ff_put_rv40_qpel_h_mmx2  ff_put_rv40_qpel_h_mmx\n\n#define ff_put_rv40_qpel_v_mmx2  ff_put_rv40_qpel_v_mmx\n\nQPEL_MC_DECL(avg_, _mmx2)\n\n\n\n#define ff_put_rv40_qpel_h_3dnow  ff_put_rv40_qpel_h_mmx\n\n#define ff_put_rv40_qpel_v_3dnow  ff_put_rv40_qpel_v_mmx\n\nQPEL_MC_DECL(avg_, _3dnow)\n\n#endif\n\n\n\n/** @{ */\n\n/** Set one function */\n\n#define QPEL_FUNC_SET(OP, SIZE, PH, PV, OPT)                            \\\n\n    c-> OP ## pixels_tab[2 - SIZE / 8][4 * PV + PH] = OP ## rv40_qpel ##SIZE ## _mc ##PH ##PV ##OPT;\n\n\n\n/** Set functions put and avg for sizes 8 and 16 and a given qpel position */\n\n#define QPEL_FUNCS_SET(OP, PH, PV, OPT)         \\\n\n    QPEL_FUNC_SET(OP,  8, PH, PV, OPT)          \\\n\n    QPEL_FUNC_SET(OP, 16, PH, PV, OPT)\n\n\n\n/** Set all functions for all sizes and qpel positions */\n\n#define QPEL_MC_SET(OP, OPT)   \\\n\nQPEL_FUNCS_SET (OP, 0, 1, OPT) \\\n\nQPEL_FUNCS_SET (OP, 0, 3, OPT) \\\n\nQPEL_FUNCS_SET (OP, 1, 0, OPT) \\\n\nQPEL_FUNCS_SET (OP, 1, 1, OPT) \\\n\nQPEL_FUNCS_SET (OP, 1, 2, OPT) \\\n\nQPEL_FUNCS_SET (OP, 1, 3, OPT) \\\n\nQPEL_FUNCS_SET (OP, 2, 1, OPT) \\\n\nQPEL_FUNCS_SET (OP, 2, 2, OPT) \\\n\nQPEL_FUNCS_SET (OP, 2, 3, OPT) \\\n\nQPEL_FUNCS_SET (OP, 3, 0, OPT) \\\n\nQPEL_FUNCS_SET (OP, 3, 1, OPT) \\\n\nQPEL_FUNCS_SET (OP, 3, 2, OPT)\n\n/** @} */\n\n\n\n#endif /* HAVE_YASM */\n\n\n\nvoid ff_rv40dsp_init_x86(RV34DSPContext *c, DSPContext *dsp)\n\n{\n\n#if HAVE_YASM\n\n    int mm_flags = av_get_cpu_flags();\n\n\n\n    if (mm_flags & AV_CPU_FLAG_MMX) {\n\n        c->put_chroma_pixels_tab[0] = ff_put_rv40_chroma_mc8_mmx;\n\n        c->put_chroma_pixels_tab[1] = ff_put_rv40_chroma_mc4_mmx;\n\n#if HAVE_INLINE_ASM\n\n        c->put_pixels_tab[0][15] = ff_put_rv40_qpel16_mc33_mmx;\n\n        c->put_pixels_tab[1][15] = ff_put_rv40_qpel8_mc33_mmx;\n\n        c->avg_pixels_tab[0][15] = ff_avg_rv40_qpel16_mc33_mmx;\n\n        c->avg_pixels_tab[1][15] = ff_avg_rv40_qpel8_mc33_mmx;\n\n#endif /* HAVE_INLINE_ASM */\n\n#if ARCH_X86_32\n\n        QPEL_MC_SET(put_, _mmx)\n\n#endif\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_MMXEXT) {\n\n        c->avg_chroma_pixels_tab[0] = ff_avg_rv40_chroma_mc8_mmx2;\n\n        c->avg_chroma_pixels_tab[1] = ff_avg_rv40_chroma_mc4_mmx2;\n\n        c->rv40_weight_pixels_tab[0][0] = ff_rv40_weight_func_rnd_16_mmx2;\n\n        c->rv40_weight_pixels_tab[0][1] = ff_rv40_weight_func_rnd_8_mmx2;\n\n        c->rv40_weight_pixels_tab[1][0] = ff_rv40_weight_func_nornd_16_mmx2;\n\n        c->rv40_weight_pixels_tab[1][1] = ff_rv40_weight_func_nornd_8_mmx2;\n\n#if ARCH_X86_32\n\n        QPEL_MC_SET(avg_, _mmx2)\n\n#endif\n\n    } else if (mm_flags & AV_CPU_FLAG_3DNOW) {\n\n        c->avg_chroma_pixels_tab[0] = ff_avg_rv40_chroma_mc8_3dnow;\n\n        c->avg_chroma_pixels_tab[1] = ff_avg_rv40_chroma_mc4_3dnow;\n\n#if ARCH_X86_32\n\n        QPEL_MC_SET(avg_, _3dnow)\n\n#endif\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_SSE2) {\n\n        c->rv40_weight_pixels_tab[0][0] = ff_rv40_weight_func_rnd_16_sse2;\n\n        c->rv40_weight_pixels_tab[0][1] = ff_rv40_weight_func_rnd_8_sse2;\n\n        c->rv40_weight_pixels_tab[1][0] = ff_rv40_weight_func_nornd_16_sse2;\n\n        c->rv40_weight_pixels_tab[1][1] = ff_rv40_weight_func_nornd_8_sse2;\n\n        QPEL_MC_SET(put_, _sse2)\n\n        QPEL_MC_SET(avg_, _sse2)\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_SSSE3) {\n\n        c->rv40_weight_pixels_tab[0][0] = ff_rv40_weight_func_rnd_16_ssse3;\n\n        c->rv40_weight_pixels_tab[0][1] = ff_rv40_weight_func_rnd_8_ssse3;\n\n        c->rv40_weight_pixels_tab[1][0] = ff_rv40_weight_func_nornd_16_ssse3;\n\n        c->rv40_weight_pixels_tab[1][1] = ff_rv40_weight_func_nornd_8_ssse3;\n\n        QPEL_MC_SET(put_, _ssse3)\n\n        QPEL_MC_SET(avg_, _ssse3)\n\n    }\n\n#endif /* HAVE_YASM */\n\n}\n", "idx": 17020, "_split": "valid", "_hash": "c48b646999e8fb223b3e119a213d9b05"}
{"project": "FFmpeg", "commit_id": "6a287b739f3a8660d5e4405be1302da8b3e51e88", "target": 1, "func": "static inline int range_get_symbol(APEContext * ctx,\n\n                                   const uint32_t counts[],\n\n                                   const uint16_t counts_diff[])\n\n{\n\n    int symbol, cf;\n\n\n\n    cf = range_decode_culshift(ctx, 16);\n\n\n\n\n\n\n\n\n\n\n    /* figure out the symbol inefficiently; a binary search would be much better */\n\n    for (symbol = 0; counts[symbol + 1] <= cf; symbol++);\n\n\n\n    range_decode_update(ctx, counts_diff[symbol], counts[symbol]);\n\n\n\n", "idx": 17056, "_split": "valid", "_hash": "04c1b86010c618011f25bed113abed0a"}
{"project": "FFmpeg", "commit_id": "bddcf758d3a68ac0bcc3bc4fc4aa7156e05245d4", "target": 0, "func": "static void check_loopfilter()\n\n{\n\n    LOCAL_ALIGNED_32(uint8_t, base0, [32 + 16 * 16 * 2]);\n\n    LOCAL_ALIGNED_32(uint8_t, base1, [32 + 16 * 16 * 2]);\n\n    VP9DSPContext dsp;\n\n    int dir, wd, wd2, bit_depth;\n\n    static const char *const dir_name[2] = { \"h\", \"v\" };\n\n    int E[2] = { 20, 28 }, I[2] = { 10, 16 }, H[2] = { 7, 11 }, F[2] = { 1, 1 };\n\n    declare_func(void, uint8_t *dst, ptrdiff_t stride, int E, int I, int H);\n\n\n\n    for (bit_depth = 8; bit_depth <= 12; bit_depth += 2) {\n\n        ff_vp9dsp_init(&dsp, bit_depth, 0);\n\n\n\n        for (dir = 0; dir < 2; dir++) {\n\n            uint8_t *buf0, *buf1;\n\n            int midoff = (dir ? 8 * 8 : 8) * SIZEOF_PIXEL;\n\n            int midoff_aligned = (dir ? 8 * 8 : 16) * SIZEOF_PIXEL;\n\n\n\n            buf0 = base0 + midoff_aligned;\n\n            buf1 = base1 + midoff_aligned;\n\n\n\n            for (wd = 0; wd < 3; wd++) {\n\n                // 4/8/16wd_8px\n\n                if (check_func(dsp.loop_filter_8[wd][dir],\n\n                               \"vp9_loop_filter_%s_%d_8_%dbpp\",\n\n                               dir_name[dir], 4 << wd, bit_depth)) {\n\n                    randomize_buffers(0, 0, 8);\n\n                    memcpy(buf1 - midoff, buf0 - midoff,\n\n                           16 * 8 * SIZEOF_PIXEL);\n\n                    call_ref(buf0, 16 * SIZEOF_PIXEL >> dir, E[0], I[0], H[0]);\n\n                    call_new(buf1, 16 * SIZEOF_PIXEL >> dir, E[0], I[0], H[0]);\n\n                    if (memcmp(buf0 - midoff, buf1 - midoff, 16 * 8 * SIZEOF_PIXEL))\n\n                        fail();\n\n                    bench_new(buf1, 16 * SIZEOF_PIXEL >> dir, E[0], I[0], H[0]);\n\n                }\n\n            }\n\n\n\n            midoff = (dir ? 16 * 8 : 8) * SIZEOF_PIXEL;\n\n            midoff_aligned = (dir ? 16 * 8 : 16) * SIZEOF_PIXEL;\n\n\n\n            // 16wd_16px loopfilter\n\n            if (check_func(dsp.loop_filter_16[dir],\n\n                           \"vp9_loop_filter_%s_16_16_%dbpp\",\n\n                           dir_name[dir], bit_depth)) {\n\n                randomize_buffers(0, 0, 16);\n\n                randomize_buffers(0, 8, 16);\n\n                memcpy(buf1 - midoff, buf0 - midoff, 16 * 16 * SIZEOF_PIXEL);\n\n                call_ref(buf0, 16 * SIZEOF_PIXEL, E[0], I[0], H[0]);\n\n                call_new(buf1, 16 * SIZEOF_PIXEL, E[0], I[0], H[0]);\n\n                if (memcmp(buf0 - midoff, buf1 - midoff, 16 * 16 * SIZEOF_PIXEL))\n\n                    fail();\n\n                bench_new(buf1, 16 * SIZEOF_PIXEL, E[0], I[0], H[0]);\n\n            }\n\n\n\n            for (wd = 0; wd < 2; wd++) {\n\n                for (wd2 = 0; wd2 < 2; wd2++) {\n\n                    // mix2 loopfilter\n\n                    if (check_func(dsp.loop_filter_mix2[wd][wd2][dir],\n\n                                   \"vp9_loop_filter_mix2_%s_%d%d_16_%dbpp\",\n\n                                   dir_name[dir], 4 << wd, 4 << wd2, bit_depth)) {\n\n                        randomize_buffers(0, 0, 16);\n\n                        randomize_buffers(1, 8, 16);\n\n                        memcpy(buf1 - midoff, buf0 - midoff, 16 * 16 * SIZEOF_PIXEL);\n\n#define M(a) ((a[1] << 8) | a[0])\n\n                        call_ref(buf0, 16 * SIZEOF_PIXEL, M(E), M(I), M(H));\n\n                        call_new(buf1, 16 * SIZEOF_PIXEL, M(E), M(I), M(H));\n\n                        if (memcmp(buf0 - midoff, buf1 - midoff, 16 * 16 * SIZEOF_PIXEL))\n\n                            fail();\n\n                        bench_new(buf1, 16 * SIZEOF_PIXEL, M(E), M(I), M(H));\n\n#undef M\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n    report(\"loopfilter\");\n\n}\n", "idx": 17183, "_split": "valid", "_hash": "5314d32d8ca25de629c9bca8f5efe2b1"}
{"project": "FFmpeg", "commit_id": "d206fd996bdaa501e341d9397cff8529b38a9ad9", "target": 1, "func": "static int url_alloc_for_protocol (URLContext **puc, struct URLProtocol *up,\n\n                                   const char *filename, int flags,\n\n                                   const AVIOInterruptCB *int_cb)\n\n{\n\n    URLContext *uc;\n\n    int err;\n\n\n\n#if CONFIG_NETWORK\n\n    if (up->flags & URL_PROTOCOL_FLAG_NETWORK && !ff_network_init())\n\n        return AVERROR(EIO);\n\n#endif\n\n    if ((flags & AVIO_FLAG_READ) && !up->url_read) {\n\n        av_log(NULL, AV_LOG_ERROR,\n\n               \"Impossible to open the '%s' protocol for reading\\n\", up->name);\n\n        return AVERROR(EIO);\n\n\n    if ((flags & AVIO_FLAG_WRITE) && !up->url_write) {\n\n        av_log(NULL, AV_LOG_ERROR,\n\n               \"Impossible to open the '%s' protocol for writing\\n\", up->name);\n\n        return AVERROR(EIO);\n\n\n    uc = av_mallocz(sizeof(URLContext) + strlen(filename) + 1);\n\n    if (!uc) {\n\n\n\n\n    uc->av_class = &ffurl_context_class;\n\n    uc->filename = (char *) &uc[1];\n\n    strcpy(uc->filename, filename);\n\n    uc->prot = up;\n\n    uc->flags = flags;\n\n    uc->is_streamed = 0; /* default = not streamed */\n\n    uc->max_packet_size = 0; /* default: stream file */\n\n    if (up->priv_data_size) {\n\n        uc->priv_data = av_mallocz(up->priv_data_size);\n\n\n\n\n\n        if (up->priv_data_class) {\n\n            int proto_len= strlen(up->name);\n\n            char *start = strchr(uc->filename, ',');\n\n            *(const AVClass**)uc->priv_data = up->priv_data_class;\n\n            av_opt_set_defaults(uc->priv_data);\n\n            if(!strncmp(up->name, uc->filename, proto_len) && uc->filename + proto_len == start){\n\n                int ret= 0;\n\n                char *p= start;\n\n                char sep= *++p;\n\n                char *key, *val;\n\n                p++;\n\n                while(ret >= 0 && (key= strchr(p, sep)) && p<key && (val = strchr(key+1, sep))){\n\n                    *val= *key= 0;\n\n                    ret= av_opt_set(uc->priv_data, p, key+1, 0);\n\n                    if (ret == AVERROR_OPTION_NOT_FOUND)\n\n                        av_log(uc, AV_LOG_ERROR, \"Key '%s' not found.\\n\", p);\n\n                    *val= *key= sep;\n\n                    p= val+1;\n\n\n                if(ret<0 || p!=key){\n\n                    av_log(uc, AV_LOG_ERROR, \"Error parsing options string %s\\n\", start);\n\n                    av_freep(&uc->priv_data);\n\n                    av_freep(&uc);\n\n                    err = AVERROR(EINVAL);\n\n\n\n                memmove(start, key+1, strlen(key));\n\n\n\n\n    if (int_cb)\n\n        uc->interrupt_callback = *int_cb;\n\n\n\n    *puc = uc;\n\n    return 0;\n\n fail:\n\n    *puc = NULL;\n\n    if (uc)\n\n        av_freep(&uc->priv_data);\n\n    av_freep(&uc);\n\n#if CONFIG_NETWORK\n\n    if (up->flags & URL_PROTOCOL_FLAG_NETWORK)\n\n        ff_network_close();\n\n#endif\n\n    return err;\n", "idx": 17191, "_split": "valid", "_hash": "41b1e4a62c1600860aa5aa085157b174"}
{"project": "FFmpeg", "commit_id": "b8fb21e902f83d8bd8dc340a52cadfd64e685774", "target": 1, "func": "static int flashsv_decode_frame(AVCodecContext *avctx,\n\n                                    void *data, int *data_size,\n\n                                    AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    FlashSVContext *s = avctx->priv_data;\n\n    int h_blocks, v_blocks, h_part, v_part, i, j;\n\n    GetBitContext gb;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0)\n\n        return 0;\n\n\n\n\n\n    init_get_bits(&gb, buf, buf_size * 8);\n\n\n\n    /* start to parse the bitstream */\n\n    s->block_width = 16* (get_bits(&gb, 4)+1);\n\n    s->image_width =     get_bits(&gb,12);\n\n    s->block_height= 16* (get_bits(&gb, 4)+1);\n\n    s->image_height=     get_bits(&gb,12);\n\n\n\n    /* calculate amount of blocks and the size of the border blocks */\n\n    h_blocks = s->image_width / s->block_width;\n\n    h_part = s->image_width % s->block_width;\n\n    v_blocks = s->image_height / s->block_height;\n\n    v_part = s->image_height % s->block_height;\n\n\n\n    /* the block size could change between frames, make sure the buffer\n\n     * is large enough, if not, get a larger one */\n\n    if(s->block_size < s->block_width*s->block_height) {\n\n        if (s->tmpblock != NULL)\n\n            av_free(s->tmpblock);\n\n        if ((s->tmpblock = av_malloc(3*s->block_width*s->block_height)) == NULL) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Can't allocate decompression buffer.\\n\");\n\n\n        }\n\n    }\n\n    s->block_size = s->block_width*s->block_height;\n\n\n\n    /* init the image size once */\n\n    if((avctx->width==0) && (avctx->height==0)){\n\n        avctx->width = s->image_width;\n\n        avctx->height = s->image_height;\n\n    }\n\n\n\n    /* check for changes of image width and image height */\n\n    if ((avctx->width != s->image_width) || (avctx->height != s->image_height)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Frame width or height differs from first frames!\\n\");\n\n        av_log(avctx, AV_LOG_ERROR, \"fh = %d, fv %d  vs  ch = %d, cv = %d\\n\",avctx->height,\n\n        avctx->width,s->image_height,s->image_width);\n\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"image: %dx%d block: %dx%d num: %dx%d part: %dx%d\\n\",\n\n        s->image_width, s->image_height, s->block_width, s->block_height,\n\n        h_blocks, v_blocks, h_part, v_part);\n\n\n\n    s->frame.reference = 1;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if(avctx->reget_buffer(avctx, &s->frame) < 0){\n\n      av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n\n    }\n\n\n\n    /* loop over all block columns */\n\n    for (j = 0; j < v_blocks + (v_part?1:0); j++)\n\n    {\n\n\n\n        int hp = j*s->block_height; // horiz position in frame\n\n        int hs = (j<v_blocks)?s->block_height:v_part; // size of block\n\n\n\n\n\n        /* loop over all block rows */\n\n        for (i = 0; i < h_blocks + (h_part?1:0); i++)\n\n        {\n\n            int wp = i*s->block_width; // vert position in frame\n\n            int ws = (i<h_blocks)?s->block_width:h_part; // size of block\n\n\n\n            /* get the size of the compressed zlib chunk */\n\n            int size = get_bits(&gb, 16);\n\n            if (8 * size > get_bits_left(&gb)) {\n\n                avctx->release_buffer(avctx, &s->frame);\n\n                s->frame.data[0] = NULL;\n\n\n            }\n\n\n\n            if (size == 0) {\n\n                /* no change, don't do anything */\n\n            } else {\n\n                /* decompress block */\n\n                int ret = inflateReset(&(s->zstream));\n\n                if (ret != Z_OK)\n\n                {\n\n                    av_log(avctx, AV_LOG_ERROR, \"error in decompression (reset) of block %dx%d\\n\", i, j);\n\n                    /* return -1; */\n\n                }\n\n                s->zstream.next_in = buf+(get_bits_count(&gb)/8);\n\n                s->zstream.avail_in = size;\n\n                s->zstream.next_out = s->tmpblock;\n\n                s->zstream.avail_out = s->block_size*3;\n\n                ret = inflate(&(s->zstream), Z_FINISH);\n\n                if (ret == Z_DATA_ERROR)\n\n                {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Zlib resync occurred\\n\");\n\n                    inflateSync(&(s->zstream));\n\n                    ret = inflate(&(s->zstream), Z_FINISH);\n\n                }\n\n\n\n                if ((ret != Z_OK) && (ret != Z_STREAM_END))\n\n                {\n\n                    av_log(avctx, AV_LOG_ERROR, \"error in decompression of block %dx%d: %d\\n\", i, j, ret);\n\n                    /* return -1; */\n\n                }\n\n                copy_region(s->tmpblock, s->frame.data[0], s->image_height-(hp+hs+1), wp, hs, ws, s->frame.linesize[0]);\n\n                skip_bits_long(&gb, 8*size);   /* skip the consumed bits */\n\n            }\n\n        }\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    if ((get_bits_count(&gb)/8) != buf_size)\n\n        av_log(avctx, AV_LOG_ERROR, \"buffer not fully consumed (%d != %d)\\n\",\n\n            buf_size, (get_bits_count(&gb)/8));\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}", "idx": 17193, "_split": "valid", "_hash": "469f7bce99d0188bdf0f16eaa06664c8"}
{"project": "FFmpeg", "commit_id": "bd0a9f603d0c1d0f3be782865f72ac29ab89bc5b", "target": 1, "func": "static int find_video_stream_info(AVFormatContext *fmt_ctx, int decode)\n{\n    int ret = 0;\n    int i, done = 0;\n    AVPacket pkt;\n    av_init_packet(&pkt);\n    while (!done) {\n        AVCodecContext *codec_ctx = NULL;\n        AVStream *st;\n        if ((ret = av_read_frame(fmt_ctx, &pkt)) < 0) {\n            av_log(fmt_ctx, AV_LOG_ERROR, \"Failed to read frame\\n\");\n            goto end;\n        st = fmt_ctx->streams[pkt.stream_index];\n        codec_ctx = st->codec;\n        /* Writing to AVStream.codec_info_nb_frames must not be done by\n         * user applications. It is done here for testing purposing as\n         * find_video_stream_info tries to mimic avformat_find_stream_info\n         * which writes to this field.\n         * */\n        if (codec_ctx->codec_type != AVMEDIA_TYPE_VIDEO ||\n            st->codec_info_nb_frames++ > 0) {\n            av_packet_unref(&pkt);\n            continue;\n        ret = try_decode_video_frame(codec_ctx, &pkt, decode);\n        if (ret < 0) {\n            av_log(fmt_ctx, AV_LOG_ERROR, \"Failed to decode video frame\\n\");\n            goto end;\n        av_packet_unref(&pkt);\n        /* check if all video streams have demuxed a packet */\n        done = 1;\n            st = fmt_ctx->streams[i];\n            codec_ctx = st->codec;\n            if (codec_ctx->codec_type != AVMEDIA_TYPE_VIDEO)\n                continue;\n            done &= st->codec_info_nb_frames > 0;\nend:\n    av_packet_unref(&pkt);\n    return ret < 0;", "idx": 17224, "_split": "valid", "_hash": "007af15fe68ae4453824ba8b227bf57d"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int vdpau_mpeg4_start_frame(AVCodecContext *avctx,\n\n                                   const uint8_t *buffer, uint32_t size)\n\n{\n\n    Mpeg4DecContext *ctx = avctx->priv_data;\n\n    MpegEncContext * const s = &ctx->m;\n\n    Picture *pic             = s->current_picture_ptr;\n\n    struct vdpau_picture_context *pic_ctx = pic->hwaccel_picture_private;\n\n    VdpPictureInfoMPEG4Part2 *info = &pic_ctx->info.mpeg4;\n\n    VdpVideoSurface ref;\n\n    int i;\n\n\n\n    /* fill VdpPictureInfoMPEG4Part2 struct */\n\n    info->forward_reference  = VDP_INVALID_HANDLE;\n\n    info->backward_reference = VDP_INVALID_HANDLE;\n\n    info->vop_coding_type    = 0;\n\n\n\n    switch (s->pict_type) {\n\n    case AV_PICTURE_TYPE_B:\n\n        ref = ff_vdpau_get_surface_id(&s->next_picture.f);\n\n        assert(ref != VDP_INVALID_HANDLE);\n\n        info->backward_reference = ref;\n\n        info->vop_coding_type    = 2;\n\n        /* fall-through */\n\n    case AV_PICTURE_TYPE_P:\n\n        ref = ff_vdpau_get_surface_id(&s->last_picture.f);\n\n        assert(ref != VDP_INVALID_HANDLE);\n\n        info->forward_reference  = ref;\n\n    }\n\n\n\n    info->trd[0]                            = s->pp_time;\n\n    info->trb[0]                            = s->pb_time;\n\n    info->trd[1]                            = s->pp_field_time >> 1;\n\n    info->trb[1]                            = s->pb_field_time >> 1;\n\n    info->vop_time_increment_resolution     = s->avctx->time_base.den;\n\n    info->vop_fcode_forward                 = s->f_code;\n\n    info->vop_fcode_backward                = s->b_code;\n\n    info->resync_marker_disable             = !ctx->resync_marker;\n\n    info->interlaced                        = !s->progressive_sequence;\n\n    info->quant_type                        = s->mpeg_quant;\n\n    info->quarter_sample                    = s->quarter_sample;\n\n    info->short_video_header                = avctx->codec->id == AV_CODEC_ID_H263;\n\n    info->rounding_control                  = s->no_rounding;\n\n    info->alternate_vertical_scan_flag      = s->alternate_scan;\n\n    info->top_field_first                   = s->top_field_first;\n\n    for (i = 0; i < 64; ++i) {\n\n        info->intra_quantizer_matrix[i]     = s->intra_matrix[i];\n\n        info->non_intra_quantizer_matrix[i] = s->inter_matrix[i];\n\n    }\n\n\n\n    ff_vdpau_common_start_frame(pic_ctx, buffer, size);\n\n    return ff_vdpau_add_buffer(pic_ctx, buffer, size);\n\n}\n", "idx": 17227, "_split": "valid", "_hash": "0c08e3ff8ad300f10174fc80a1465b6b"}
{"project": "FFmpeg", "commit_id": "dd561441b1e849df7d8681c6f32af82d4088dafd", "target": 0, "func": "static void h264_v_loop_filter_chroma_c(uint8_t *pix, int stride, int alpha, int beta, int8_t *tc0)\n\n{\n\n    h264_loop_filter_chroma_c(pix, stride, 1, alpha, beta, tc0);\n\n}\n", "idx": 17248, "_split": "valid", "_hash": "af23319bbd8f3066abada38989f100d6"}
{"project": "FFmpeg", "commit_id": "4c7b023d56e09a78a587d036db1b64bf7c493b3d", "target": 0, "func": "static int nvdec_vp9_end_frame(AVCodecContext *avctx)\n\n{\n\n    NVDECContext *ctx = avctx->internal->hwaccel_priv_data;\n\n    int ret = ff_nvdec_end_frame(avctx);\n\n    ctx->bitstream = NULL;\n\n    return ret;\n\n}\n", "idx": 17259, "_split": "valid", "_hash": "6494db4755b9f4d72db265cc7570710d"}
{"project": "FFmpeg", "commit_id": "fe573d1a9b742652f44cdc15b24fdd401eefc5e7", "target": 0, "func": "SwsVector *sws_allocVec(int length)\n\n{\n\n    SwsVector *vec = av_malloc(sizeof(SwsVector));\n\n    if (!vec)\n\n        return NULL;\n\n    vec->length = length;\n\n    vec->coeff  = av_malloc(sizeof(double) * length);\n\n    if (!vec->coeff)\n\n        av_freep(&vec);\n\n    return vec;\n\n}\n", "idx": 17289, "_split": "valid", "_hash": "adc2819b57811e57df225fe82b8b880c"}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "void ff_af_queue_log_state(AudioFrameQueue *afq)\n\n{\n\n    AudioFrame *f;\n\n    av_log(afq->avctx, AV_LOG_DEBUG, \"remaining delay   = %d\\n\",\n\n           afq->remaining_delay);\n\n    av_log(afq->avctx, AV_LOG_DEBUG, \"remaining samples = %d\\n\",\n\n           afq->remaining_samples);\n\n    av_log(afq->avctx, AV_LOG_DEBUG, \"frames:\\n\");\n\n    f = afq->frame_queue;\n\n    while (f) {\n\n        av_log(afq->avctx, AV_LOG_DEBUG, \"  [ pts=%9\"PRId64\" duration=%d ]\\n\",\n\n               f->pts, f->duration);\n\n        f = f->next;\n\n    }\n\n}\n", "idx": 17336, "_split": "valid", "_hash": "a58ea4d1fd0a928cc2d2380c56602532"}
{"project": "FFmpeg", "commit_id": "0c22311b56e66115675c4a96e4c78547886a4171", "target": 0, "func": "static void opt_frame_pad_bottom(const char *arg)\n\n{\n\n    frame_padbottom = atoi(arg);\n\n    if (frame_padbottom < 0) {\n\n        fprintf(stderr, \"Incorrect bottom pad size\\n\");\n\n        av_exit(1);\n\n    }\n\n}\n", "idx": 17358, "_split": "valid", "_hash": "f6f13ffb47b48efe7b34ddd6969265b1"}
{"project": "FFmpeg", "commit_id": "bd6ece4609b49eb40f880252452b809bff8f13ec", "target": 1, "func": "static int query_codec(enum CodecID id, int std_compliance)\n\n{\n\n    CodecMime *cm= ff_id3v2_mime_tags;\n\n    while(cm->id != CODEC_ID_NONE) {\n\n        if(id == cm->id)\n\n            return MKTAG('A', 'P', 'I', 'C');\n\n        cm++;\n\n    }\n\n    return -1;\n\n}\n", "idx": 17388, "_split": "valid", "_hash": "cc2dd88a78a4318b7245d0eef0a7ff64"}
{"project": "FFmpeg", "commit_id": "6341838f3ca69c7850aa11b067165ef544cead95", "target": 0, "func": "DECLARE_LOOP_FILTER(mmxext)\n\nDECLARE_LOOP_FILTER(sse2)\n\nDECLARE_LOOP_FILTER(ssse3)\n\nDECLARE_LOOP_FILTER(sse4)\n\n\n\n#endif\n\n\n\n#define VP8_LUMA_MC_FUNC(IDX, SIZE, OPT) \\\n\n    c->put_vp8_epel_pixels_tab[IDX][0][2] = ff_put_vp8_epel ## SIZE ## _h6_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][2][0] = ff_put_vp8_epel ## SIZE ## _v6_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][2][2] = ff_put_vp8_epel ## SIZE ## _h6v6_ ## OPT\n\n\n\n#define VP8_MC_FUNC(IDX, SIZE, OPT) \\\n\n    c->put_vp8_epel_pixels_tab[IDX][0][1] = ff_put_vp8_epel ## SIZE ## _h4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][1][0] = ff_put_vp8_epel ## SIZE ## _v4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][1][1] = ff_put_vp8_epel ## SIZE ## _h4v4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][1][2] = ff_put_vp8_epel ## SIZE ## _h6v4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][2][1] = ff_put_vp8_epel ## SIZE ## _h4v6_ ## OPT; \\\n\n    VP8_LUMA_MC_FUNC(IDX, SIZE, OPT)\n\n\n\n#define VP8_BILINEAR_MC_FUNC(IDX, SIZE, OPT) \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][0][1] = ff_put_vp8_bilinear ## SIZE ## _h_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][0][2] = ff_put_vp8_bilinear ## SIZE ## _h_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][1][0] = ff_put_vp8_bilinear ## SIZE ## _v_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][1][1] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][1][2] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][2][0] = ff_put_vp8_bilinear ## SIZE ## _v_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][2][1] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][2][2] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT\n\n\n\n\n\nav_cold void ff_vp8dsp_init_x86(VP8DSPContext* c)\n\n{\n\n    mm_flags = mm_support();\n\n\n\n#if HAVE_YASM\n\n    if (mm_flags & FF_MM_MMX) {\n\n        c->vp8_idct_dc_add    = ff_vp8_idct_dc_add_mmx;\n\n        c->vp8_idct_dc_add4y  = ff_vp8_idct_dc_add4y_mmx;\n\n        c->vp8_idct_dc_add4uv = ff_vp8_idct_dc_add4uv_mmx;\n\n        c->vp8_idct_add       = ff_vp8_idct_add_mmx;\n\n        c->vp8_luma_dc_wht    = ff_vp8_luma_dc_wht_mmx;\n\n        c->put_vp8_epel_pixels_tab[0][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_mmx;\n\n        c->put_vp8_epel_pixels_tab[1][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[1][0][0] = ff_put_vp8_pixels8_mmx;\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_mmx;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_mmx;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmx;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmx;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmx;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmx;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_mmx;\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_mmx;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_mmx;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_mmx;\n\n    }\n\n\n\n    /* note that 4-tap width=16 functions are missing because w=16\n\n     * is only used for luma, and luma is always a copy or sixtap. */\n\n    if (mm_flags & FF_MM_MMX2) {\n\n        VP8_LUMA_MC_FUNC(0, 16, mmxext);\n\n        VP8_MC_FUNC(1, 8, mmxext);\n\n        VP8_MC_FUNC(2, 4, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(2, 4, mmxext);\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_mmxext;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_mmxext;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmxext;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmxext;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmxext;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmxext;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_mmxext;\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_mmxext;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_mmxext;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_mmxext;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE) {\n\n        c->vp8_idct_add                         = ff_vp8_idct_add_sse;\n\n        c->put_vp8_epel_pixels_tab[0][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_sse;\n\n    }\n\n\n\n    if (mm_flags & (FF_MM_SSE2|FF_MM_SSE2SLOW)) {\n\n        VP8_LUMA_MC_FUNC(0, 16, sse2);\n\n        VP8_MC_FUNC(1, 8, sse2);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, sse2);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, sse2);\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_sse2;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_sse2;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_sse2;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_sse2;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_sse2;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_sse2;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE2) {\n\n        c->vp8_idct_dc_add4y          = ff_vp8_idct_dc_add4y_sse2;\n\n\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_sse2;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_sse2;\n\n\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_sse2;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_sse2;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSSE3) {\n\n        VP8_LUMA_MC_FUNC(0, 16, ssse3);\n\n        VP8_MC_FUNC(1, 8, ssse3);\n\n        VP8_MC_FUNC(2, 4, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(2, 4, ssse3);\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_ssse3;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_ssse3;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_ssse3;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_ssse3;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_ssse3;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_ssse3;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_ssse3;\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_ssse3;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_ssse3;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_ssse3;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE4) {\n\n        c->vp8_idct_dc_add                  = ff_vp8_idct_dc_add_sse4;\n\n\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_sse4;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_sse4;\n\n    }\n\n#endif\n\n}\n", "idx": 17398, "_split": "valid", "_hash": "cc600a299f67065e6308acdb77cdb5ed"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static unsigned int celt_decode_band(CeltContext *s, OpusRangeCoder *rc,\n\n                                     const int band, float *X, float *Y,\n\n                                     int N, int b, unsigned int blocks,\n\n                                     float *lowband, int duration,\n\n                                     float *lowband_out, int level,\n\n                                     float gain, float *lowband_scratch,\n\n                                     int fill)\n\n{\n\n    const uint8_t *cache;\n\n    int dualstereo, split;\n\n    int imid = 0, iside = 0;\n\n    unsigned int N0 = N;\n\n    int N_B;\n\n    int N_B0;\n\n    int B0 = blocks;\n\n    int time_divide = 0;\n\n    int recombine = 0;\n\n    int inv = 0;\n\n    float mid = 0, side = 0;\n\n    int longblocks = (B0 == 1);\n\n    unsigned int cm = 0;\n\n\n\n    N_B0 = N_B = N / blocks;\n\n    split = dualstereo = (Y != NULL);\n\n\n\n    if (N == 1) {\n\n        /* special case for one sample */\n\n        int i;\n\n        float *x = X;\n\n        for (i = 0; i <= dualstereo; i++) {\n\n            int sign = 0;\n\n            if (s->remaining2 >= 1<<3) {\n\n                sign           = opus_getrawbits(rc, 1);\n\n                s->remaining2 -= 1 << 3;\n\n                b             -= 1 << 3;\n\n            }\n\n            x[0] = sign ? -1.0f : 1.0f;\n\n            x = Y;\n\n        }\n\n        if (lowband_out)\n\n            lowband_out[0] = X[0];\n\n        return 1;\n\n    }\n\n\n\n    if (!dualstereo && level == 0) {\n\n        int tf_change = s->tf_change[band];\n\n        int k;\n\n        if (tf_change > 0)\n\n            recombine = tf_change;\n\n        /* Band recombining to increase frequency resolution */\n\n\n\n        if (lowband &&\n\n            (recombine || ((N_B & 1) == 0 && tf_change < 0) || B0 > 1)) {\n\n            int j;\n\n            for (j = 0; j < N; j++)\n\n                lowband_scratch[j] = lowband[j];\n\n            lowband = lowband_scratch;\n\n        }\n\n\n\n        for (k = 0; k < recombine; k++) {\n\n            if (lowband)\n\n                celt_haar1(lowband, N >> k, 1 << k);\n\n            fill = celt_bit_interleave[fill & 0xF] | celt_bit_interleave[fill >> 4] << 2;\n\n        }\n\n        blocks >>= recombine;\n\n        N_B <<= recombine;\n\n\n\n        /* Increasing the time resolution */\n\n        while ((N_B & 1) == 0 && tf_change < 0) {\n\n            if (lowband)\n\n                celt_haar1(lowband, N_B, blocks);\n\n            fill |= fill << blocks;\n\n            blocks <<= 1;\n\n            N_B >>= 1;\n\n            time_divide++;\n\n            tf_change++;\n\n        }\n\n        B0 = blocks;\n\n        N_B0 = N_B;\n\n\n\n        /* Reorganize the samples in time order instead of frequency order */\n\n        if (B0 > 1 && lowband)\n\n            celt_deinterleave_hadamard(s->scratch, lowband, N_B >> recombine,\n\n                                       B0 << recombine, longblocks);\n\n    }\n\n\n\n    /* If we need 1.5 more bit than we can produce, split the band in two. */\n\n    cache = celt_cache_bits +\n\n            celt_cache_index[(duration + 1) * CELT_MAX_BANDS + band];\n\n    if (!dualstereo && duration >= 0 && b > cache[cache[0]] + 12 && N > 2) {\n\n        N >>= 1;\n\n        Y = X + N;\n\n        split = 1;\n\n        duration -= 1;\n\n        if (blocks == 1)\n\n            fill = (fill & 1) | (fill << 1);\n\n        blocks = (blocks + 1) >> 1;\n\n    }\n\n\n\n    if (split) {\n\n        int qn;\n\n        int itheta = 0;\n\n        int mbits, sbits, delta;\n\n        int qalloc;\n\n        int pulse_cap;\n\n        int offset;\n\n        int orig_fill;\n\n        int tell;\n\n\n\n        /* Decide on the resolution to give to the split parameter theta */\n\n        pulse_cap = celt_log_freq_range[band] + duration * 8;\n\n        offset = (pulse_cap >> 1) - (dualstereo && N == 2 ? CELT_QTHETA_OFFSET_TWOPHASE :\n\n                                                          CELT_QTHETA_OFFSET);\n\n        qn = (dualstereo && band >= s->intensitystereo) ? 1 :\n\n             celt_compute_qn(N, b, offset, pulse_cap, dualstereo);\n\n        tell = opus_rc_tell_frac(rc);\n\n        if (qn != 1) {\n\n            /* Entropy coding of the angle. We use a uniform pdf for the\n\n            time split, a step for stereo, and a triangular one for the rest. */\n\n            if (dualstereo && N > 2)\n\n                itheta = opus_rc_stepmodel(rc, qn/2);\n\n            else if (dualstereo || B0 > 1)\n\n                itheta = opus_rc_unimodel(rc, qn+1);\n\n            else\n\n                itheta = opus_rc_trimodel(rc, qn);\n\n            itheta = itheta * 16384 / qn;\n\n            /* NOTE: Renormalising X and Y *may* help fixed-point a bit at very high rate.\n\n            Let's do that at higher complexity */\n\n        } else if (dualstereo) {\n\n            inv = (b > 2 << 3 && s->remaining2 > 2 << 3) ? opus_rc_p2model(rc, 2) : 0;\n\n            itheta = 0;\n\n        }\n\n        qalloc = opus_rc_tell_frac(rc) - tell;\n\n        b -= qalloc;\n\n\n\n        orig_fill = fill;\n\n        if (itheta == 0) {\n\n            imid = 32767;\n\n            iside = 0;\n\n            fill &= (1 << blocks) - 1;\n\n            delta = -16384;\n\n        } else if (itheta == 16384) {\n\n            imid = 0;\n\n            iside = 32767;\n\n            fill &= ((1 << blocks) - 1) << blocks;\n\n            delta = 16384;\n\n        } else {\n\n            imid = celt_cos(itheta);\n\n            iside = celt_cos(16384-itheta);\n\n            /* This is the mid vs side allocation that minimizes squared error\n\n            in that band. */\n\n            delta = ROUND_MUL16((N - 1) << 7, celt_log2tan(iside, imid));\n\n        }\n\n\n\n        mid  = imid  / 32768.0f;\n\n        side = iside / 32768.0f;\n\n\n\n        /* This is a special case for N=2 that only works for stereo and takes\n\n        advantage of the fact that mid and side are orthogonal to encode\n\n        the side with just one bit. */\n\n        if (N == 2 && dualstereo) {\n\n            int c;\n\n            int sign = 0;\n\n            float tmp;\n\n            float *x2, *y2;\n\n            mbits = b;\n\n            /* Only need one bit for the side */\n\n            sbits = (itheta != 0 && itheta != 16384) ? 1 << 3 : 0;\n\n            mbits -= sbits;\n\n            c = (itheta > 8192);\n\n            s->remaining2 -= qalloc+sbits;\n\n\n\n            x2 = c ? Y : X;\n\n            y2 = c ? X : Y;\n\n            if (sbits)\n\n                sign = opus_getrawbits(rc, 1);\n\n            sign = 1 - 2 * sign;\n\n            /* We use orig_fill here because we want to fold the side, but if\n\n            itheta==16384, we'll have cleared the low bits of fill. */\n\n            cm = celt_decode_band(s, rc, band, x2, NULL, N, mbits, blocks,\n\n                                  lowband, duration, lowband_out, level, gain,\n\n                                  lowband_scratch, orig_fill);\n\n            /* We don't split N=2 bands, so cm is either 1 or 0 (for a fold-collapse),\n\n            and there's no need to worry about mixing with the other channel. */\n\n            y2[0] = -sign * x2[1];\n\n            y2[1] =  sign * x2[0];\n\n            X[0] *= mid;\n\n            X[1] *= mid;\n\n            Y[0] *= side;\n\n            Y[1] *= side;\n\n            tmp = X[0];\n\n            X[0] = tmp - Y[0];\n\n            Y[0] = tmp + Y[0];\n\n            tmp = X[1];\n\n            X[1] = tmp - Y[1];\n\n            Y[1] = tmp + Y[1];\n\n        } else {\n\n            /* \"Normal\" split code */\n\n            float *next_lowband2     = NULL;\n\n            float *next_lowband_out1 = NULL;\n\n            int next_level = 0;\n\n            int rebalance;\n\n\n\n            /* Give more bits to low-energy MDCTs than they would\n\n             * otherwise deserve */\n\n            if (B0 > 1 && !dualstereo && (itheta & 0x3fff)) {\n\n                if (itheta > 8192)\n\n                    /* Rough approximation for pre-echo masking */\n\n                    delta -= delta >> (4 - duration);\n\n                else\n\n                    /* Corresponds to a forward-masking slope of\n\n                     * 1.5 dB per 10 ms */\n\n                    delta = FFMIN(0, delta + (N << 3 >> (5 - duration)));\n\n            }\n\n            mbits = av_clip((b - delta) / 2, 0, b);\n\n            sbits = b - mbits;\n\n            s->remaining2 -= qalloc;\n\n\n\n            if (lowband && !dualstereo)\n\n                next_lowband2 = lowband + N; /* >32-bit split case */\n\n\n\n            /* Only stereo needs to pass on lowband_out.\n\n             * Otherwise, it's handled at the end */\n\n            if (dualstereo)\n\n                next_lowband_out1 = lowband_out;\n\n            else\n\n                next_level = level + 1;\n\n\n\n            rebalance = s->remaining2;\n\n            if (mbits >= sbits) {\n\n                /* In stereo mode, we do not apply a scaling to the mid\n\n                 * because we need the normalized mid for folding later */\n\n                cm = celt_decode_band(s, rc, band, X, NULL, N, mbits, blocks,\n\n                                      lowband, duration, next_lowband_out1,\n\n                                      next_level, dualstereo ? 1.0f : (gain * mid),\n\n                                      lowband_scratch, fill);\n\n\n\n                rebalance = mbits - (rebalance - s->remaining2);\n\n                if (rebalance > 3 << 3 && itheta != 0)\n\n                    sbits += rebalance - (3 << 3);\n\n\n\n                /* For a stereo split, the high bits of fill are always zero,\n\n                 * so no folding will be done to the side. */\n\n                cm |= celt_decode_band(s, rc, band, Y, NULL, N, sbits, blocks,\n\n                                       next_lowband2, duration, NULL,\n\n                                       next_level, gain * side, NULL,\n\n                                       fill >> blocks) << ((B0 >> 1) & (dualstereo - 1));\n\n            } else {\n\n                /* For a stereo split, the high bits of fill are always zero,\n\n                 * so no folding will be done to the side. */\n\n                cm = celt_decode_band(s, rc, band, Y, NULL, N, sbits, blocks,\n\n                                      next_lowband2, duration, NULL,\n\n                                      next_level, gain * side, NULL,\n\n                                      fill >> blocks) << ((B0 >> 1) & (dualstereo - 1));\n\n\n\n                rebalance = sbits - (rebalance - s->remaining2);\n\n                if (rebalance > 3 << 3 && itheta != 16384)\n\n                    mbits += rebalance - (3 << 3);\n\n\n\n                /* In stereo mode, we do not apply a scaling to the mid because\n\n                 * we need the normalized mid for folding later */\n\n                cm |= celt_decode_band(s, rc, band, X, NULL, N, mbits, blocks,\n\n                                       lowband, duration, next_lowband_out1,\n\n                                       next_level, dualstereo ? 1.0f : (gain * mid),\n\n                                       lowband_scratch, fill);\n\n            }\n\n        }\n\n    } else {\n\n        /* This is the basic no-split case */\n\n        unsigned int q         = celt_bits2pulses(cache, b);\n\n        unsigned int curr_bits = celt_pulses2bits(cache, q);\n\n        s->remaining2 -= curr_bits;\n\n\n\n        /* Ensures we can never bust the budget */\n\n        while (s->remaining2 < 0 && q > 0) {\n\n            s->remaining2 += curr_bits;\n\n            curr_bits      = celt_pulses2bits(cache, --q);\n\n            s->remaining2 -= curr_bits;\n\n        }\n\n\n\n        if (q != 0) {\n\n            /* Finally do the actual quantization */\n\n            cm = celt_alg_unquant(rc, X, N, (q < 8) ? q : (8 + (q & 7)) << ((q >> 3) - 1),\n\n                                  s->spread, blocks, gain);\n\n        } else {\n\n            /* If there's no pulse, fill the band anyway */\n\n            int j;\n\n            unsigned int cm_mask = (1 << blocks) - 1;\n\n            fill &= cm_mask;\n\n            if (!fill) {\n\n                for (j = 0; j < N; j++)\n\n                    X[j] = 0.0f;\n\n            } else {\n\n                if (lowband == NULL) {\n\n                    /* Noise */\n\n                    for (j = 0; j < N; j++)\n\n                        X[j] = (((int32_t)celt_rng(s)) >> 20);\n\n                    cm = cm_mask;\n\n                } else {\n\n                    /* Folded spectrum */\n\n                    for (j = 0; j < N; j++) {\n\n                        /* About 48 dB below the \"normal\" folding level */\n\n                        X[j] = lowband[j] + (((celt_rng(s)) & 0x8000) ? 1.0f / 256 : -1.0f / 256);\n\n                    }\n\n                    cm = fill;\n\n                }\n\n                celt_renormalize_vector(X, N, gain);\n\n            }\n\n        }\n\n    }\n\n\n\n    /* This code is used by the decoder and by the resynthesis-enabled encoder */\n\n    if (dualstereo) {\n\n        int j;\n\n        if (N != 2)\n\n            celt_stereo_merge(X, Y, mid, N);\n\n        if (inv) {\n\n            for (j = 0; j < N; j++)\n\n                Y[j] *= -1;\n\n        }\n\n    } else if (level == 0) {\n\n        int k;\n\n\n\n        /* Undo the sample reorganization going from time order to frequency order */\n\n        if (B0 > 1)\n\n            celt_interleave_hadamard(s->scratch, X, N_B>>recombine,\n\n                                     B0<<recombine, longblocks);\n\n\n\n        /* Undo time-freq changes that we did earlier */\n\n        N_B = N_B0;\n\n        blocks = B0;\n\n        for (k = 0; k < time_divide; k++) {\n\n            blocks >>= 1;\n\n            N_B <<= 1;\n\n            cm |= cm >> blocks;\n\n            celt_haar1(X, N_B, blocks);\n\n        }\n\n\n\n        for (k = 0; k < recombine; k++) {\n\n            cm = celt_bit_deinterleave[cm];\n\n            celt_haar1(X, N0>>k, 1<<k);\n\n        }\n\n        blocks <<= recombine;\n\n\n\n        /* Scale output for later folding */\n\n        if (lowband_out) {\n\n            int j;\n\n            float n = sqrtf(N0);\n\n            for (j = 0; j < N0; j++)\n\n                lowband_out[j] = n * X[j];\n\n        }\n\n        cm &= (1 << blocks) - 1;\n\n    }\n\n    return cm;\n\n}\n", "idx": 17454, "_split": "valid", "_hash": "601508f8379b1c964dccbdb2a5f9a749"}
{"project": "FFmpeg", "commit_id": "ab1e4312887d8e560d027803871b55b883910714", "target": 1, "func": "static int tiff_unpack_strip(TiffContext *s, AVFrame *p, uint8_t *dst, int stride,\n\n                             const uint8_t *src, int size, int strip_start, int lines)\n\n{\n\n    PutByteContext pb;\n\n    int c, line, pixels, code, ret;\n\n    const uint8_t *ssrc = src;\n\n    int width = ((s->width * s->bpp) + 7) >> 3;\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(p->format);\n\n    int is_yuv = !(desc->flags & AV_PIX_FMT_FLAG_RGB) && desc->nb_components >= 2;\n\n\n\n    if (s->planar)\n\n        width /= s->bppcount;\n\n\n\n    if (size <= 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (is_yuv) {\n\n        int bytes_per_row = (((s->width - 1) / s->subsampling[0] + 1) * s->bpp *\n\n                            s->subsampling[0] * s->subsampling[1] + 7) >> 3;\n\n        av_fast_padded_malloc(&s->yuv_line, &s->yuv_line_size, bytes_per_row);\n\n        if (s->yuv_line == NULL) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Not enough memory\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        dst = s->yuv_line;\n\n        stride = 0;\n\n        width = s->width * s->subsampling[1] + 2*(s->width / s->subsampling[0]);\n\n        av_assert0(width <= bytes_per_row);\n\n        av_assert0(s->bpp == 24);\n\n    }\n\n\n\n    if (s->compr == TIFF_DEFLATE || s->compr == TIFF_ADOBE_DEFLATE) {\n\n#if CONFIG_ZLIB\n\n        return tiff_unpack_zlib(s, p, dst, stride, src, size, width, lines,\n\n                                strip_start, is_yuv);\n\n#else\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"zlib support not enabled, \"\n\n               \"deflate compression not supported\\n\");\n\n        return AVERROR(ENOSYS);\n\n#endif\n\n    }\n\n    if (s->compr == TIFF_LZMA) {\n\n#if CONFIG_LZMA\n\n        return tiff_unpack_lzma(s, p, dst, stride, src, size, width, lines,\n\n                                strip_start, is_yuv);\n\n#else\n\n        av_log(s->avctx, AV_LOG_ERROR,\n\n               \"LZMA support not enabled\\n\");\n\n        return AVERROR(ENOSYS);\n\n#endif\n\n    }\n\n    if (s->compr == TIFF_LZW) {\n\n        if (s->fill_order) {\n\n            if ((ret = deinvert_buffer(s, src, size)) < 0)\n\n                return ret;\n\n            ssrc = src = s->deinvert_buf;\n\n        }\n\n        if (size > 1 && !src[0] && (src[1]&1)) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Old style LZW is unsupported\\n\");\n\n        }\n\n        if ((ret = ff_lzw_decode_init(s->lzw, 8, src, size, FF_LZW_TIFF)) < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error initializing LZW decoder\\n\");\n\n            return ret;\n\n        }\n\n        for (line = 0; line < lines; line++) {\n\n            pixels = ff_lzw_decode(s->lzw, dst, width);\n\n            if (pixels < width) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"Decoded only %i bytes of %i\\n\",\n\n                       pixels, width);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (s->bpp < 8 && s->avctx->pix_fmt == AV_PIX_FMT_PAL8)\n\n                horizontal_fill(s->bpp, dst, 1, dst, 0, width, 0);\n\n            if (is_yuv) {\n\n                unpack_yuv(s, p, dst, strip_start + line);\n\n                line += s->subsampling[1] - 1;\n\n            }\n\n            dst += stride;\n\n        }\n\n        return 0;\n\n    }\n\n    if (s->compr == TIFF_CCITT_RLE ||\n\n        s->compr == TIFF_G3        ||\n\n        s->compr == TIFF_G4) {\n\n        if (is_yuv)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        return tiff_unpack_fax(s, dst, stride, src, size, width, lines);\n\n    }\n\n\n\n    bytestream2_init(&s->gb, src, size);\n\n    bytestream2_init_writer(&pb, dst, is_yuv ? s->yuv_line_size : (stride * lines));\n\n\n\n    for (line = 0; line < lines; line++) {\n\n        if (src - ssrc > size) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Source data overread\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (bytestream2_get_bytes_left(&s->gb) == 0 || bytestream2_get_eof(&pb))\n\n            break;\n\n        bytestream2_seek_p(&pb, stride * line, SEEK_SET);\n\n        switch (s->compr) {\n\n        case TIFF_RAW:\n\n            if (ssrc + size - src < width)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            if (!s->fill_order) {\n\n                horizontal_fill(s->bpp * (s->avctx->pix_fmt == AV_PIX_FMT_PAL8),\n\n                                dst, 1, src, 0, width, 0);\n\n            } else {\n\n                int i;\n\n                for (i = 0; i < width; i++)\n\n                    dst[i] = ff_reverse[src[i]];\n\n            }\n\n            src += width;\n\n            break;\n\n        case TIFF_PACKBITS:\n\n            for (pixels = 0; pixels < width;) {\n\n                if (ssrc + size - src < 2) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"Read went out of bounds\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                code = s->fill_order ? (int8_t) ff_reverse[*src++]: (int8_t) *src++;\n\n                if (code >= 0) {\n\n                    code++;\n\n                    if (pixels + code > width ||\n\n                        ssrc + size - src < code) {\n\n                        av_log(s->avctx, AV_LOG_ERROR,\n\n                               \"Copy went out of bounds\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    horizontal_fill(s->bpp * (s->avctx->pix_fmt == AV_PIX_FMT_PAL8),\n\n                                    dst, 1, src, 0, code, pixels);\n\n                    src    += code;\n\n                    pixels += code;\n\n                } else if (code != -128) { // -127..-1\n\n                    code = (-code) + 1;\n\n                    if (pixels + code > width) {\n\n                        av_log(s->avctx, AV_LOG_ERROR,\n\n                               \"Run went out of bounds\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    c = *src++;\n\n                    horizontal_fill(s->bpp * (s->avctx->pix_fmt == AV_PIX_FMT_PAL8),\n\n                                    dst, 0, NULL, c, code, pixels);\n\n                    pixels += code;\n\n                }\n\n            }\n\n            if (s->fill_order) {\n\n                int i;\n\n                for (i = 0; i < width; i++)\n\n                    dst[i] = ff_reverse[dst[i]];\n\n            }\n\n            break;\n\n        }\n\n        if (is_yuv) {\n\n            unpack_yuv(s, p, dst, strip_start + line);\n\n            line += s->subsampling[1] - 1;\n\n        }\n\n        dst += stride;\n\n    }\n\n    return 0;\n\n}\n", "idx": 17457, "_split": "valid", "_hash": "9bdc0daae6be4c35d55f9b77312e2822"}
{"project": "FFmpeg", "commit_id": "e4a1d87ef88d57cca21ec425120c6a370fdb0210", "target": 1, "func": "static void mkv_free(MatroskaMuxContext *mkv) {\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n    if (mkv->main_seekhead) {\n\n        av_freep(&mkv->main_seekhead->entries);\n\n        av_freep(&mkv->main_seekhead);\n\n\n    if (mkv->cues) {\n\n        av_freep(&mkv->cues->entries);\n\n        av_freep(&mkv->cues);\n\n\n    if (mkv->attachments) {\n\n        av_freep(&mkv->attachments->entries);\n\n        av_freep(&mkv->attachments);\n\n\n    av_freep(&mkv->tracks);\n\n    av_freep(&mkv->stream_durations);\n\n    av_freep(&mkv->stream_duration_offsets);\n", "idx": 17458, "_split": "valid", "_hash": "1cf363aaa027a614f47316627900e955"}
{"project": "FFmpeg", "commit_id": "fa2a34cd40d124161c748bb0f430dc63c94dd0da", "target": 0, "func": "int show_filters(void *optctx, const char *opt, const char *arg)\n\n{\n\n    AVFilter av_unused(**filter) = NULL;\n\n\n\n    printf(\"Filters:\\n\");\n\n#if CONFIG_AVFILTER\n\n    while ((filter = av_filter_next(filter)) && *filter)\n\n        printf(\"%-16s %s\\n\", (*filter)->name, (*filter)->description);\n\n#endif\n\n    return 0;\n\n}\n", "idx": 17492, "_split": "valid", "_hash": "3d473eecfa835b2b6ec529bd006b79ea"}
{"project": "FFmpeg", "commit_id": "d934de5c5d9ff1d228d0113e31e182efe2a853aa", "target": 0, "func": "static int cavs_find_frame_end(ParseContext *pc, const uint8_t *buf,\n\n                               int buf_size) {\n\n    int pic_found, i;\n\n    uint32_t state;\n\n\n\n    pic_found= pc->frame_start_found;\n\n    state= pc->state;\n\n\n\n    i=0;\n\n    if(!pic_found){\n\n        for(i=0; i<buf_size; i++){\n\n            state= (state<<8) | buf[i];\n\n            if(state == PIC_I_START_CODE || state == PIC_PB_START_CODE){\n\n                i++;\n\n                pic_found=1;\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if(pic_found){\n\n        /* EOF considered as end of frame */\n\n        if (buf_size == 0)\n\n            return 0;\n\n        for(; i<buf_size; i++){\n\n            state= (state<<8) | buf[i];\n\n            if((state&0xFFFFFF00) == 0x100){\n\n                if(state < SLICE_MIN_START_CODE || state > SLICE_MAX_START_CODE){\n\n                    pc->frame_start_found=0;\n\n                    pc->state=-1;\n\n                    return i-3;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    pc->frame_start_found= pic_found;\n\n    pc->state= state;\n\n    return END_NOT_FOUND;\n\n}\n", "idx": 17505, "_split": "valid", "_hash": "f454edd58b5250abde3870099ecf02bd"}
{"project": "FFmpeg", "commit_id": "004564c930ef60d2f9e8798e820ed7b2a37ba0bd", "target": 0, "func": "static void bwf_write_bext_chunk(AVFormatContext *s)\n\n{\n\n    AVDictionaryEntry *tmp_tag;\n\n    uint64_t time_reference = 0;\n\n    int64_t bext = ff_start_tag(s->pb, \"bext\");\n\n\n\n    bwf_write_bext_string(s, \"description\", 256);\n\n    bwf_write_bext_string(s, \"originator\", 32);\n\n    bwf_write_bext_string(s, \"originator_reference\", 32);\n\n    bwf_write_bext_string(s, \"origination_date\", 10);\n\n    bwf_write_bext_string(s, \"origination_time\", 8);\n\n\n\n    if (tmp_tag = av_dict_get(s->metadata, \"time_reference\", NULL, 0))\n\n        time_reference = strtoll(tmp_tag->value, NULL, 10);\n\n    avio_wl64(s->pb, time_reference);\n\n    avio_wl16(s->pb, 1);  // set version to 1\n\n\n\n    if (tmp_tag = av_dict_get(s->metadata, \"umid\", NULL, 0)) {\n\n        unsigned char umidpart_str[17] = {0};\n\n        int64_t i;\n\n        uint64_t umidpart;\n\n        size_t len = strlen(tmp_tag->value+2);\n\n\n\n        for (i = 0; i < len/16; i++) {\n\n            memcpy(umidpart_str, tmp_tag->value + 2 + (i*16), 16);\n\n            umidpart = strtoll(umidpart_str, NULL, 16);\n\n            avio_wb64(s->pb, umidpart);\n\n        }\n\n        ffio_fill(s->pb, 0, 64 - i*8);\n\n    } else\n\n        ffio_fill(s->pb, 0, 64); // zero UMID\n\n\n\n    ffio_fill(s->pb, 0, 190); // Reserved\n\n\n\n    if (tmp_tag = av_dict_get(s->metadata, \"coding_history\", NULL, 0))\n\n        avio_put_str(s->pb, tmp_tag->value);\n\n\n\n    ff_end_tag(s->pb, bext);\n\n}\n", "idx": 17539, "_split": "valid", "_hash": "1a346ca974ef19168359f178f0296d0b"}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "static void free_schro_frame(SchroFrame *frame, void *priv)\n\n{\n\n    AVFrame *p_pic = priv;\n\n    av_frame_free(&p_pic);\n\n}\n", "idx": 17544, "_split": "valid", "_hash": "5ab6949cbde3e0186ab9fd7e89fdd995"}
{"project": "FFmpeg", "commit_id": "2a37ac042f1247470ebeedeb0cc07059e4ae499f", "target": 1, "func": "static av_cold int flashsv2_encode_init(AVCodecContext * avctx)\n\n{\n\n    FlashSV2Context *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n\n\n    s->comp = avctx->compression_level;\n\n    if (s->comp == -1)\n\n        s->comp = 9;\n\n    if (s->comp < 0 || s->comp > 9) {\n\n\n               \"Compression level should be 0-9, not %d\\n\", s->comp);\n\n\n\n\n\n\n\n    if ((avctx->width > 4095) || (avctx->height > 4095)) {\n\n\n               \"Input dimensions too large, input must be max 4096x4096 !\\n\");\n\n\n\n\n\n\n\n\n\n\n    if (av_image_check_size(avctx->width, avctx->height, 0, avctx) < 0)\n\n\n\n\n\n\n    s->last_key_frame = 0;\n\n\n\n    s->image_width  = avctx->width;\n\n    s->image_height = avctx->height;\n\n\n\n    s->block_width  = (s->image_width /  12) & ~15;\n\n    s->block_height = (s->image_height / 12) & ~15;\n\n\n\n    if(!s->block_width)\n\n        s->block_width = 1;\n\n    if(!s->block_height)\n\n        s->block_height = 1;\n\n\n\n    s->rows = (s->image_height + s->block_height - 1) / s->block_height;\n\n    s->cols = (s->image_width +  s->block_width -  1) / s->block_width;\n\n\n\n    s->frame_size  = s->image_width * s->image_height * 3;\n\n    s->blocks_size = s->rows * s->cols * sizeof(Block);\n\n\n\n    s->encbuffer     = av_mallocz(s->frame_size);\n\n    s->keybuffer     = av_mallocz(s->frame_size);\n\n    s->databuffer    = av_mallocz(s->frame_size * 6);\n\n    s->current_frame = av_mallocz(s->frame_size);\n\n    s->key_frame     = av_mallocz(s->frame_size);\n\n    s->frame_blocks  = av_mallocz(s->blocks_size);\n\n    s->key_blocks    = av_mallocz(s->blocks_size);\n\n\n\n    init_blocks(s, s->frame_blocks, s->encbuffer, s->databuffer);\n\n    init_blocks(s, s->key_blocks,   s->keybuffer, 0);\n\n    reset_stats(s);\n\n#ifndef FLASHSV2_DUMB\n\n    s->total_bits = 1;\n\n#endif\n\n\n\n    s->use_custom_palette =  0;\n\n    s->palette_type       = -1;        // so that the palette will be generated in reconfigure_at_keyframe\n\n\n\n    if (!s->encbuffer || !s->keybuffer || !s->databuffer\n\n        || !s->current_frame || !s->key_frame || !s->key_blocks\n\n        || !s->frame_blocks) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Memory allocation failed.\\n\");\n\n        cleanup(s);\n\n\n\n\n\n    return 0;\n", "idx": 17562, "_split": "valid", "_hash": "51491a0fc9c28a93681b467faf46b66d"}
{"project": "FFmpeg", "commit_id": "aac0eda40754c010ab5156dcd5d0d1554937e9a7", "target": 0, "func": "static void decode_pulses(Pulse * pulse, GetBitContext * gb, const uint16_t * swb_offset) {\n\n    int i;\n\n    pulse->num_pulse = get_bits(gb, 2) + 1;\n\n    pulse->pos[0]    = swb_offset[get_bits(gb, 6)];\n\n    pulse->pos[0]   += get_bits(gb, 5);\n\n    pulse->amp[0]    = get_bits(gb, 4);\n\n    for (i = 1; i < pulse->num_pulse; i++) {\n\n        pulse->pos[i] = get_bits(gb, 5) + pulse->pos[i-1];\n\n        pulse->amp[i] = get_bits(gb, 4);\n\n    }\n\n}\n", "idx": 17585, "_split": "valid", "_hash": "58f6d28811648b5a4274a50f6681a012"}
{"project": "FFmpeg", "commit_id": "5d2b8850746b4513a43938f60930b060cad36ee5", "target": 0, "func": "int ff_start_frame(AVFilterLink *link, AVFilterBufferRef *picref)\n\n{\n\n    int (*start_frame)(AVFilterLink *, AVFilterBufferRef *);\n\n    AVFilterPad *src = link->srcpad;\n\n    AVFilterPad *dst = link->dstpad;\n\n    int ret, perms;\n\n    AVFilterCommand *cmd= link->dst->command_queue;\n\n    int64_t pts;\n\n\n\n    FF_TPRINTF_START(NULL, start_frame); ff_tlog_link(NULL, link, 0); ff_tlog(NULL, \" \"); ff_tlog_ref(NULL, picref, 1);\n\n\n\n    av_assert1(picref->format                     == link->format);\n\n    av_assert1(picref->video->w                   == link->w);\n\n    av_assert1(picref->video->h                   == link->h);\n\n\n\n    if (link->closed) {\n\n        avfilter_unref_buffer(picref);\n\n        return AVERROR_EOF;\n\n    }\n\n\n\n    if (!(start_frame = dst->start_frame))\n\n        start_frame = default_start_frame;\n\n\n\n    av_assert1((picref->perms & src->min_perms) == src->min_perms);\n\n    picref->perms &= ~ src->rej_perms;\n\n    perms = picref->perms;\n\n\n\n    if (picref->linesize[0] < 0)\n\n        perms |= AV_PERM_NEG_LINESIZES;\n\n    /* prepare to copy the picture if it has insufficient permissions */\n\n    if ((dst->min_perms & perms) != dst->min_perms || dst->rej_perms & perms) {\n\n        av_log(link->dst, AV_LOG_DEBUG,\n\n                \"frame copy needed (have perms %x, need %x, reject %x)\\n\",\n\n                picref->perms,\n\n                link->dstpad->min_perms, link->dstpad->rej_perms);\n\n\n\n        link->cur_buf = ff_get_video_buffer(link, dst->min_perms, link->w, link->h);\n\n        if (!link->cur_buf) {\n\n            avfilter_unref_bufferp(&picref);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        link->src_buf = picref;\n\n        avfilter_copy_buffer_ref_props(link->cur_buf, link->src_buf);\n\n\n\n        /* copy palette if required */\n\n        if (av_pix_fmt_descriptors[link->format].flags & PIX_FMT_PAL)\n\n            memcpy(link->cur_buf->data[1], link->src_buf-> data[1], AVPALETTE_SIZE);\n\n    }\n\n    else\n\n        link->cur_buf = picref;\n\n\n\n    link->cur_buf_copy = link->cur_buf;\n\n\n\n    while(cmd && cmd->time <= picref->pts * av_q2d(link->time_base)){\n\n        av_log(link->dst, AV_LOG_DEBUG,\n\n               \"Processing command time:%f command:%s arg:%s\\n\",\n\n               cmd->time, cmd->command, cmd->arg);\n\n        avfilter_process_command(link->dst, cmd->command, cmd->arg, 0, 0, cmd->flags);\n\n        ff_command_queue_pop(link->dst);\n\n        cmd= link->dst->command_queue;\n\n    }\n\n    pts = link->cur_buf->pts;\n\n    ret = start_frame(link, link->cur_buf);\n\n    ff_update_link_current_pts(link, pts);\n\n    if (ret < 0)\n\n        clear_link(link);\n\n    else\n\n        /* incoming buffers must not be freed in start frame,\n\n           because they can still be in use by the automatic copy mechanism */\n\n        av_assert1(link->cur_buf_copy->buf->refcount > 0);\n\n\n\n    return ret;\n\n}\n", "idx": 17621, "_split": "valid", "_hash": "4d4508c9ed3c71c1bca67457ce12bf38"}
{"project": "FFmpeg", "commit_id": "5e9a56a0350c518cd4b38845aff49d41a9c952ae", "target": 0, "func": "static int decode_wave_header(AVCodecContext *avctx, const uint8_t *header,\n\n                              int header_size)\n\n{\n\n    int len;\n\n    short wave_format;\n\n\n\n\n\n    if (bytestream_get_le32(&header) != MKTAG('R','I','F','F')) {\n\n        av_log(avctx, AV_LOG_ERROR, \"missing RIFF tag\\n\");\n\n        return -1;\n\n    }\n\n\n\n    header += 4; /* chunk size */;\n\n\n\n    if (bytestream_get_le32(&header) != MKTAG('W','A','V','E')) {\n\n        av_log(avctx, AV_LOG_ERROR, \"missing WAVE tag\\n\");\n\n        return -1;\n\n    }\n\n\n\n    while (bytestream_get_le32(&header) != MKTAG('f','m','t',' ')) {\n\n        len = bytestream_get_le32(&header);\n\n        header += len;\n\n    }\n\n    len = bytestream_get_le32(&header);\n\n\n\n    if (len < 16) {\n\n        av_log(avctx, AV_LOG_ERROR, \"fmt chunk was too short\\n\");\n\n        return -1;\n\n    }\n\n\n\n    wave_format = bytestream_get_le16(&header);\n\n\n\n    switch (wave_format) {\n\n        case WAVE_FORMAT_PCM:\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"unsupported wave format\\n\");\n\n            return -1;\n\n    }\n\n\n\n    header += 2;        // skip channels    (already got from shorten header)\n\n    avctx->sample_rate = bytestream_get_le32(&header);\n\n    header += 4;        // skip bit rate    (represents original uncompressed bit rate)\n\n    header += 2;        // skip block align (not needed)\n\n    avctx->bits_per_coded_sample = bytestream_get_le16(&header);\n\n\n\n    if (avctx->bits_per_coded_sample != 16) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported number of bits per sample\\n\");\n\n        return -1;\n\n    }\n\n\n\n    len -= 16;\n\n    if (len > 0)\n\n        av_log(avctx, AV_LOG_INFO, \"%d header bytes unparsed\\n\", len);\n\n\n\n    return 0;\n\n}\n", "idx": 17622, "_split": "valid", "_hash": "8a1de66039ee70177f2e4d0c0edfcff4"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int svq1_encode_init(AVCodecContext *avctx)\n\n{\n\n    SVQ1EncContext *const s = avctx->priv_data;\n\n    int ret;\n\n\n\n    ff_hpeldsp_init(&s->hdsp, avctx->flags);\n\n    ff_me_cmp_init(&s->mecc, avctx);\n\n    ff_mpegvideoencdsp_init(&s->m.mpvencdsp, avctx);\n\n\n\n    avctx->coded_frame = av_frame_alloc();\n\n    s->current_picture = av_frame_alloc();\n\n    s->last_picture    = av_frame_alloc();\n\n    if (!avctx->coded_frame || !s->current_picture || !s->last_picture) {\n\n        svq1_encode_end(avctx);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    s->frame_width  = avctx->width;\n\n    s->frame_height = avctx->height;\n\n\n\n    s->y_block_width  = (s->frame_width  + 15) / 16;\n\n    s->y_block_height = (s->frame_height + 15) / 16;\n\n\n\n    s->c_block_width  = (s->frame_width  / 4 + 15) / 16;\n\n    s->c_block_height = (s->frame_height / 4 + 15) / 16;\n\n\n\n    s->avctx               = avctx;\n\n    s->m.avctx             = avctx;\n\n\n\n    if ((ret = ff_mpv_common_init(&s->m)) < 0) {\n\n        svq1_encode_end(avctx);\n\n        return ret;\n\n    }\n\n\n\n    s->m.picture_structure = PICT_FRAME;\n\n    s->m.me.temp           =\n\n    s->m.me.scratchpad     = av_mallocz((avctx->width + 64) *\n\n                                        2 * 16 * 2 * sizeof(uint8_t));\n\n    s->m.me.map            = av_mallocz(ME_MAP_SIZE * sizeof(uint32_t));\n\n    s->m.me.score_map      = av_mallocz(ME_MAP_SIZE * sizeof(uint32_t));\n\n    s->mb_type             = av_mallocz((s->y_block_width + 1) *\n\n                                        s->y_block_height * sizeof(int16_t));\n\n    s->dummy               = av_mallocz((s->y_block_width + 1) *\n\n                                        s->y_block_height * sizeof(int32_t));\n\n    s->ssd_int8_vs_int16   = ssd_int8_vs_int16_c;\n\n\n\n    if (!s->m.me.temp || !s->m.me.scratchpad || !s->m.me.map ||\n\n        !s->m.me.score_map || !s->mb_type || !s->dummy) {\n\n        svq1_encode_end(avctx);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    if (ARCH_PPC)\n\n        ff_svq1enc_init_ppc(s);\n\n    if (ARCH_X86)\n\n        ff_svq1enc_init_x86(s);\n\n\n\n    ff_h263_encode_init(&s->m); // mv_penalty\n\n\n\n    return 0;\n\n}\n", "idx": 17677, "_split": "valid", "_hash": "bf9142ddd8f5babfc5883a9efd437eb3"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int asf_probe(AVProbeData *pd)\n\n{\n\n    /* check file header */\n\n    if (pd->buf_size <= 32)\n\n        return 0;\n\n\n\n    if (!memcmp(pd->buf, &asf_header, sizeof(GUID)))\n\n        return AVPROBE_SCORE_MAX;\n\n    else\n\n        return 0;\n\n}\n", "idx": 17734, "_split": "valid", "_hash": "1d4f18b44d763372387e5e314cf3b970"}
{"project": "FFmpeg", "commit_id": "30ba28fe8e5757ab4ee61b9c0e8a418bd7d54b50", "target": 1, "func": "static int write_adaptation_set(AVFormatContext *s, int as_index)\n\n{\n\n    WebMDashMuxContext *w = s->priv_data;\n\n    AdaptationSet *as = &w->as[as_index];\n\n    AVCodecContext *codec = s->streams[as->streams[0]]->codec;\n\n    AVDictionaryEntry *lang;\n\n    int i;\n\n    static const char boolean[2][6] = { \"false\", \"true\" };\n\n    int subsegmentStartsWithSAP = 1;\n\n\n\n    // Width, Height and Sample Rate will go in the AdaptationSet tag if they\n\n    // are the same for all contained Representations. otherwise, they will go\n\n    // on their respective Representation tag. For live streams, they always go\n\n    // in the Representation tag.\n\n    int width_in_as = 1, height_in_as = 1, sample_rate_in_as = 1;\n\n    if (codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n      width_in_as = !w->is_live && check_matching_width(s, as);\n\n      height_in_as = !w->is_live && check_matching_height(s, as);\n\n    } else {\n\n      sample_rate_in_as = !w->is_live && check_matching_sample_rate(s, as);\n\n    }\n\n\n\n    avio_printf(s->pb, \"<AdaptationSet id=\\\"%s\\\"\", as->id);\n\n    avio_printf(s->pb, \" mimeType=\\\"%s/webm\\\"\",\n\n                codec->codec_type == AVMEDIA_TYPE_VIDEO ? \"video\" : \"audio\");\n\n    avio_printf(s->pb, \" codecs=\\\"%s\\\"\", get_codec_name(codec->codec_id));\n\n\n\n    lang = av_dict_get(s->streams[as->streams[0]]->metadata, \"language\", NULL, 0);\n\n    if (lang) avio_printf(s->pb, \" lang=\\\"%s\\\"\", lang->value);\n\n\n\n    if (codec->codec_type == AVMEDIA_TYPE_VIDEO && width_in_as)\n\n        avio_printf(s->pb, \" width=\\\"%d\\\"\", codec->width);\n\n    if (codec->codec_type == AVMEDIA_TYPE_VIDEO && height_in_as)\n\n        avio_printf(s->pb, \" height=\\\"%d\\\"\", codec->height);\n\n    if (codec->codec_type == AVMEDIA_TYPE_AUDIO && sample_rate_in_as)\n\n        avio_printf(s->pb, \" audioSamplingRate=\\\"%d\\\"\", codec->sample_rate);\n\n\n\n    avio_printf(s->pb, \" bitstreamSwitching=\\\"%s\\\"\",\n\n                boolean[bitstream_switching(s, as)]);\n\n    avio_printf(s->pb, \" subsegmentAlignment=\\\"%s\\\"\",\n\n                boolean[w->is_live || subsegment_alignment(s, as)]);\n\n\n\n    for (i = 0; i < as->nb_streams; i++) {\n\n        AVDictionaryEntry *kf = av_dict_get(s->streams[as->streams[i]]->metadata,\n\n                                            CLUSTER_KEYFRAME, NULL, 0);\n\n        if (!w->is_live && (!kf || !strncmp(kf->value, \"0\", 1))) subsegmentStartsWithSAP = 0;\n\n    }\n\n    avio_printf(s->pb, \" subsegmentStartsWithSAP=\\\"%d\\\"\", subsegmentStartsWithSAP);\n\n    avio_printf(s->pb, \">\\n\");\n\n\n\n    if (w->is_live) {\n\n        AVDictionaryEntry *filename =\n\n            av_dict_get(s->streams[as->streams[0]]->metadata, FILENAME, NULL, 0);\n\n        char *initialization_pattern = NULL;\n\n        char *media_pattern = NULL;\n\n        int ret = parse_filename(filename->value, NULL, &initialization_pattern,\n\n                                 &media_pattern);\n\n        if (ret) return ret;\n\n        avio_printf(s->pb, \"<ContentComponent id=\\\"1\\\" type=\\\"%s\\\"/>\\n\",\n\n                    codec->codec_type == AVMEDIA_TYPE_VIDEO ? \"video\" : \"audio\");\n\n        avio_printf(s->pb, \"<SegmentTemplate\");\n\n        avio_printf(s->pb, \" timescale=\\\"1000\\\"\");\n\n        avio_printf(s->pb, \" duration=\\\"%d\\\"\", w->chunk_duration);\n\n        avio_printf(s->pb, \" media=\\\"%s\\\"\", media_pattern);\n\n        avio_printf(s->pb, \" startNumber=\\\"%d\\\"\", w->chunk_start_index);\n\n        avio_printf(s->pb, \" initialization=\\\"%s\\\"\", initialization_pattern);\n\n        avio_printf(s->pb, \"/>\\n\");\n\n        av_free(initialization_pattern);\n\n        av_free(media_pattern);\n\n    }\n\n\n\n    for (i = 0; i < as->nb_streams; i++) {\n\n        char *representation_id = NULL;\n\n        int ret;\n\n        if (w->is_live) {\n\n            AVDictionaryEntry *filename =\n\n                av_dict_get(s->streams[as->streams[i]]->metadata, FILENAME, NULL, 0);\n\n            if (!filename ||\n\n                (ret = parse_filename(filename->value, &representation_id, NULL, NULL))) {\n\n                return ret;\n\n            }\n\n        } else {\n\n            representation_id = av_asprintf(\"%d\", w->representation_id++);\n\n            if (!representation_id) return AVERROR(ENOMEM);\n\n        }\n\n        ret = write_representation(s, s->streams[as->streams[i]],\n\n                                   representation_id, !width_in_as,\n\n                                   !height_in_as, !sample_rate_in_as);\n\n        if (ret) return ret;\n\n        av_free(representation_id);\n\n    }\n\n    avio_printf(s->pb, \"</AdaptationSet>\\n\");\n\n    return 0;\n\n}\n", "idx": 17749, "_split": "valid", "_hash": "f07f70008b1b7aa026bb48638220c4ef"}
{"project": "FFmpeg", "commit_id": "9b211c43dc5f2e618f204c4a7fd184eb2ea51f02", "target": 1, "func": "static AVStream *add_stream(AVFormatContext *oc, AVCodec **codec,\n\n                            enum AVCodecID codec_id)\n\n{\n\n    AVCodecContext *c;\n\n    AVStream *st;\n\n\n\n    /* find the encoder */\n\n    *codec = avcodec_find_encoder(codec_id);\n\n    if (!(*codec)) {\n\n        fprintf(stderr, \"Could not find encoder for '%s'\\n\",\n\n                avcodec_get_name(codec_id));\n\n        exit(1);\n\n    }\n\n\n\n    st = avformat_new_stream(oc, *codec);\n\n    if (!st) {\n\n        fprintf(stderr, \"Could not allocate stream\\n\");\n\n        exit(1);\n\n    }\n\n    st->id = oc->nb_streams-1;\n\n    c = st->codec;\n\n\n\n    switch ((*codec)->type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        st->id = 1;\n\n        c->sample_fmt  = AV_SAMPLE_FMT_S16;\n\n        c->bit_rate    = 64000;\n\n        c->sample_rate = 44100;\n\n        c->channels    = 2;\n\n        break;\n\n\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        avcodec_get_context_defaults3(c, *codec);\n\n        c->codec_id = codec_id;\n\n\n\n        c->bit_rate = 400000;\n\n        /* Resolution must be a multiple of two. */\n\n        c->width    = 352;\n\n        c->height   = 288;\n\n        /* timebase: This is the fundamental unit of time (in seconds) in terms\n\n         * of which frame timestamps are represented. For fixed-fps content,\n\n         * timebase should be 1/framerate and timestamp increments should be\n\n         * identical to 1. */\n\n        c->time_base.den = STREAM_FRAME_RATE;\n\n        c->time_base.num = 1;\n\n        c->gop_size      = 12; /* emit one intra frame every twelve frames at most */\n\n        c->pix_fmt       = STREAM_PIX_FMT;\n\n        if (c->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n            /* just for testing, we also add B frames */\n\n            c->max_b_frames = 2;\n\n        }\n\n        if (c->codec_id == AV_CODEC_ID_MPEG1VIDEO) {\n\n            /* Needed to avoid using macroblocks in which some coeffs overflow.\n\n             * This does not happen with normal video, it just happens here as\n\n             * the motion of the chroma plane does not match the luma plane. */\n\n            c->mb_decision = 2;\n\n        }\n\n    break;\n\n\n\n    default:\n\n        break;\n\n    }\n\n\n\n    /* Some formats want stream headers to be separate. */\n\n    if (oc->oformat->flags & AVFMT_GLOBALHEADER)\n\n        c->flags |= CODEC_FLAG_GLOBAL_HEADER;\n\n\n\n    return st;\n\n}\n", "idx": 17768, "_split": "valid", "_hash": "028cf85a1caec4fb33c121f7510f9b28"}
{"project": "FFmpeg", "commit_id": "5e53486545726987ab4482321d4dcf7e23e7652f", "target": 0, "func": "static int vc1_decode_init(AVCodecContext *avctx)\n\n{\n\n    VC1Context *v = avctx->priv_data;\n\n    MpegEncContext *s = &v->s;\n\n    GetBitContext gb;\n\n\n\n    if (!avctx->extradata_size || !avctx->extradata) return -1;\n\n    if (!(avctx->flags & CODEC_FLAG_GRAY))\n\n        avctx->pix_fmt = PIX_FMT_YUV420P;\n\n    else\n\n        avctx->pix_fmt = PIX_FMT_GRAY8;\n\n    v->s.avctx = avctx;\n\n    avctx->flags |= CODEC_FLAG_EMU_EDGE;\n\n    v->s.flags |= CODEC_FLAG_EMU_EDGE;\n\n\n\n    if(avctx->idct_algo==FF_IDCT_AUTO){\n\n        avctx->idct_algo=FF_IDCT_WMV2;\n\n    }\n\n\n\n    if(ff_h263_decode_init(avctx) < 0)\n\n        return -1;\n\n    if (vc1_init_common(v) < 0) return -1;\n\n\n\n    avctx->coded_width = avctx->width;\n\n    avctx->coded_height = avctx->height;\n\n    if (avctx->codec_id == CODEC_ID_WMV3)\n\n    {\n\n        int count = 0;\n\n\n\n        // looks like WMV3 has a sequence header stored in the extradata\n\n        // advanced sequence header may be before the first frame\n\n        // the last byte of the extradata is a version number, 1 for the\n\n        // samples we can decode\n\n\n\n        init_get_bits(&gb, avctx->extradata, avctx->extradata_size*8);\n\n\n\n        if (decode_sequence_header(avctx, &gb) < 0)\n\n          return -1;\n\n\n\n        count = avctx->extradata_size*8 - get_bits_count(&gb);\n\n        if (count>0)\n\n        {\n\n            av_log(avctx, AV_LOG_INFO, \"Extra data: %i bits left, value: %X\\n\",\n\n                   count, get_bits(&gb, count));\n\n        }\n\n        else if (count < 0)\n\n        {\n\n            av_log(avctx, AV_LOG_INFO, \"Read %i bits in overflow\\n\", -count);\n\n        }\n\n    } else { // VC1/WVC1\n\n        const uint8_t *start = avctx->extradata;\n\n        uint8_t *end = avctx->extradata + avctx->extradata_size;\n\n        const uint8_t *next;\n\n        int size, buf2_size;\n\n        uint8_t *buf2 = NULL;\n\n        int seq_inited = 0, ep_inited = 0;\n\n\n\n        if(avctx->extradata_size < 16) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Extradata size too small: %i\\n\", avctx->extradata_size);\n\n            return -1;\n\n        }\n\n\n\n        buf2 = av_mallocz(avctx->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if(start[0]) start++; // in WVC1 extradata first byte is its size\n\n        next = start;\n\n        for(; next < end; start = next){\n\n            next = find_next_marker(start + 4, end);\n\n            size = next - start - 4;\n\n            if(size <= 0) continue;\n\n            buf2_size = vc1_unescape_buffer(start + 4, size, buf2);\n\n            init_get_bits(&gb, buf2, buf2_size * 8);\n\n            switch(AV_RB32(start)){\n\n            case VC1_CODE_SEQHDR:\n\n                if(decode_sequence_header(avctx, &gb) < 0){\n\n                    av_free(buf2);\n\n                    return -1;\n\n                }\n\n                seq_inited = 1;\n\n                break;\n\n            case VC1_CODE_ENTRYPOINT:\n\n                if(decode_entry_point(avctx, &gb) < 0){\n\n                    av_free(buf2);\n\n                    return -1;\n\n                }\n\n                ep_inited = 1;\n\n                break;\n\n            }\n\n        }\n\n        av_free(buf2);\n\n        if(!seq_inited || !ep_inited){\n\n            av_log(avctx, AV_LOG_ERROR, \"Incomplete extradata\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n    avctx->has_b_frames= !!(avctx->max_b_frames);\n\n    s->low_delay = !avctx->has_b_frames;\n\n\n\n    s->mb_width = (avctx->coded_width+15)>>4;\n\n    s->mb_height = (avctx->coded_height+15)>>4;\n\n\n\n    /* Allocate mb bitplanes */\n\n    v->mv_type_mb_plane = av_malloc(s->mb_stride * s->mb_height);\n\n    v->direct_mb_plane = av_malloc(s->mb_stride * s->mb_height);\n\n    v->acpred_plane = av_malloc(s->mb_stride * s->mb_height);\n\n    v->over_flags_plane = av_malloc(s->mb_stride * s->mb_height);\n\n\n\n    /* allocate block type info in that way so it could be used with s->block_index[] */\n\n    v->mb_type_base = av_malloc(s->b8_stride * (s->mb_height * 2 + 1) + s->mb_stride * (s->mb_height + 1) * 2);\n\n    v->mb_type[0] = v->mb_type_base + s->b8_stride + 1;\n\n    v->mb_type[1] = v->mb_type_base + s->b8_stride * (s->mb_height * 2 + 1) + s->mb_stride + 1;\n\n    v->mb_type[2] = v->mb_type[1] + s->mb_stride * (s->mb_height + 1);\n\n\n\n    /* Init coded blocks info */\n\n    if (v->profile == PROFILE_ADVANCED)\n\n    {\n\n//        if (alloc_bitplane(&v->over_flags_plane, s->mb_width, s->mb_height) < 0)\n\n//            return -1;\n\n//        if (alloc_bitplane(&v->ac_pred_plane, s->mb_width, s->mb_height) < 0)\n\n//            return -1;\n\n    }\n\n\n\n    ff_intrax8_common_init(&v->x8,s);\n\n    return 0;\n\n}\n", "idx": 17795, "_split": "valid", "_hash": "dda0a7a55d07cf5ca5f06ba9ba6e5981"}
{"project": "FFmpeg", "commit_id": "ffbd1d2b0002576ef0d976a41ff959c635373fdc", "target": 1, "func": "av_cold void ff_vp9dsp_init(VP9DSPContext *dsp)\n\n{\n\n    vp9dsp_intrapred_init(dsp);\n\n    vp9dsp_itxfm_init(dsp);\n\n    vp9dsp_loopfilter_init(dsp);\n\n    vp9dsp_mc_init(dsp);\n\n\n\n\n\n    if (ARCH_X86)\n\n        ff_vp9dsp_init_x86(dsp);\n\n}", "idx": 17825, "_split": "valid", "_hash": "41c0fdfdc551b406e4e31d9803058ba0"}
{"project": "FFmpeg", "commit_id": "4ee247a2bdf2fbe81026a428d4affc46c81f28db", "target": 0, "func": "static int flv_write_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    FLVContext *flv = s->priv_data;\n\n    AVCodecContext *audio_enc = NULL, *video_enc = NULL;\n\n    int i, metadata_count = 0;\n\n    double framerate = 0.0;\n\n    int64_t metadata_size_pos, data_size, metadata_count_pos;\n\n    AVDictionaryEntry *tag = NULL;\n\n\n\n    for(i=0; i<s->nb_streams; i++){\n\n        AVCodecContext *enc = s->streams[i]->codec;\n\n        if (enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            if (s->streams[i]->r_frame_rate.den && s->streams[i]->r_frame_rate.num) {\n\n                framerate = av_q2d(s->streams[i]->r_frame_rate);\n\n            } else {\n\n                framerate = 1/av_q2d(s->streams[i]->codec->time_base);\n\n            }\n\n            video_enc = enc;\n\n            if(enc->codec_tag == 0) {\n\n                av_log(enc, AV_LOG_ERROR, \"video codec not compatible with flv\\n\");\n\n                return -1;\n\n            }\n\n        } else {\n\n            audio_enc = enc;\n\n            if(get_audio_flags(enc)<0)\n\n                return -1;\n\n        }\n\n        av_set_pts_info(s->streams[i], 32, 1, 1000); /* 32 bit pts in ms */\n\n    }\n\n    avio_write(pb, \"FLV\", 3);\n\n    avio_w8(pb,1);\n\n    avio_w8(pb,   FLV_HEADER_FLAG_HASAUDIO * !!audio_enc\n\n                 + FLV_HEADER_FLAG_HASVIDEO * !!video_enc);\n\n    avio_wb32(pb,9);\n\n    avio_wb32(pb,0);\n\n\n\n    for(i=0; i<s->nb_streams; i++){\n\n        if(s->streams[i]->codec->codec_tag == 5){\n\n            avio_w8(pb,8); // message type\n\n            avio_wb24(pb,0); // include flags\n\n            avio_wb24(pb,0); // time stamp\n\n            avio_wb32(pb,0); // reserved\n\n            avio_wb32(pb,11); // size\n\n            flv->reserved=5;\n\n        }\n\n    }\n\n\n\n    flv->last_video_ts = -1;\n\n\n\n    /* write meta_tag */\n\n    avio_w8(pb, 18);         // tag type META\n\n    metadata_size_pos= avio_tell(pb);\n\n    avio_wb24(pb, 0);          // size of data part (sum of all parts below)\n\n    avio_wb24(pb, 0);          // time stamp\n\n    avio_wb32(pb, 0);          // reserved\n\n\n\n    /* now data of data_size size */\n\n\n\n    /* first event name as a string */\n\n    avio_w8(pb, AMF_DATA_TYPE_STRING);\n\n    put_amf_string(pb, \"onMetaData\"); // 12 bytes\n\n\n\n    /* mixed array (hash) with size and string/type/data tuples */\n\n    avio_w8(pb, AMF_DATA_TYPE_MIXEDARRAY);\n\n    metadata_count_pos = avio_tell(pb);\n\n    metadata_count = 5*!!video_enc + 5*!!audio_enc + 2; // +2 for duration and file size\n\n    avio_wb32(pb, metadata_count);\n\n\n\n    put_amf_string(pb, \"duration\");\n\n    flv->duration_offset= avio_tell(pb);\n\n    put_amf_double(pb, s->duration / AV_TIME_BASE); // fill in the guessed duration, it'll be corrected later if incorrect\n\n\n\n    if(video_enc){\n\n        put_amf_string(pb, \"width\");\n\n        put_amf_double(pb, video_enc->width);\n\n\n\n        put_amf_string(pb, \"height\");\n\n        put_amf_double(pb, video_enc->height);\n\n\n\n        put_amf_string(pb, \"videodatarate\");\n\n        put_amf_double(pb, video_enc->bit_rate / 1024.0);\n\n\n\n        put_amf_string(pb, \"framerate\");\n\n        put_amf_double(pb, framerate);\n\n\n\n        put_amf_string(pb, \"videocodecid\");\n\n        put_amf_double(pb, video_enc->codec_tag);\n\n    }\n\n\n\n    if(audio_enc){\n\n        put_amf_string(pb, \"audiodatarate\");\n\n        put_amf_double(pb, audio_enc->bit_rate / 1024.0);\n\n\n\n        put_amf_string(pb, \"audiosamplerate\");\n\n        put_amf_double(pb, audio_enc->sample_rate);\n\n\n\n        put_amf_string(pb, \"audiosamplesize\");\n\n        put_amf_double(pb, audio_enc->codec_id == CODEC_ID_PCM_U8 ? 8 : 16);\n\n\n\n        put_amf_string(pb, \"stereo\");\n\n        put_amf_bool(pb, audio_enc->channels == 2);\n\n\n\n        put_amf_string(pb, \"audiocodecid\");\n\n        put_amf_double(pb, audio_enc->codec_tag);\n\n    }\n\n\n\n    while ((tag = av_dict_get(s->metadata, \"\", tag, AV_DICT_IGNORE_SUFFIX))) {\n\n        put_amf_string(pb, tag->key);\n\n        avio_w8(pb, AMF_DATA_TYPE_STRING);\n\n        put_amf_string(pb, tag->value);\n\n        metadata_count++;\n\n    }\n\n\n\n    put_amf_string(pb, \"filesize\");\n\n    flv->filesize_offset= avio_tell(pb);\n\n    put_amf_double(pb, 0); // delayed write\n\n\n\n    put_amf_string(pb, \"\");\n\n    avio_w8(pb, AMF_END_OF_OBJECT);\n\n\n\n    /* write total size of tag */\n\n    data_size= avio_tell(pb) - metadata_size_pos - 10;\n\n\n\n    avio_seek(pb, metadata_count_pos, SEEK_SET);\n\n    avio_wb32(pb, metadata_count);\n\n\n\n    avio_seek(pb, metadata_size_pos, SEEK_SET);\n\n    avio_wb24(pb, data_size);\n\n    avio_skip(pb, data_size + 10 - 3);\n\n    avio_wb32(pb, data_size + 11);\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVCodecContext *enc = s->streams[i]->codec;\n\n        if (enc->codec_id == CODEC_ID_AAC || enc->codec_id == CODEC_ID_H264) {\n\n            int64_t pos;\n\n            avio_w8(pb, enc->codec_type == AVMEDIA_TYPE_VIDEO ?\n\n                     FLV_TAG_TYPE_VIDEO : FLV_TAG_TYPE_AUDIO);\n\n            avio_wb24(pb, 0); // size patched later\n\n            avio_wb24(pb, 0); // ts\n\n            avio_w8(pb, 0); // ts ext\n\n            avio_wb24(pb, 0); // streamid\n\n            pos = avio_tell(pb);\n\n            if (enc->codec_id == CODEC_ID_AAC) {\n\n                avio_w8(pb, get_audio_flags(enc));\n\n                avio_w8(pb, 0); // AAC sequence header\n\n                avio_write(pb, enc->extradata, enc->extradata_size);\n\n            } else {\n\n                avio_w8(pb, enc->codec_tag | FLV_FRAME_KEY); // flags\n\n                avio_w8(pb, 0); // AVC sequence header\n\n                avio_wb24(pb, 0); // composition time\n\n                ff_isom_write_avcc(pb, enc->extradata, enc->extradata_size);\n\n            }\n\n            data_size = avio_tell(pb) - pos;\n\n            avio_seek(pb, -data_size - 10, SEEK_CUR);\n\n            avio_wb24(pb, data_size);\n\n            avio_skip(pb, data_size + 10 - 3);\n\n            avio_wb32(pb, data_size + 11); // previous tag size\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 17835, "_split": "valid", "_hash": "c6679bb4c7aafde7ef024f197d6326be"}
{"project": "FFmpeg", "commit_id": "221f902f1dc167bdc0bfdff6b6af3214ae3cc1f4", "target": 1, "func": "static void filter_edges(void *dst1, void *prev1, void *cur1, void *next1,\n\n                         int w, int prefs, int mrefs, int parity, int mode)\n\n{\n\n    uint8_t *dst  = dst1;\n\n    uint8_t *prev = prev1;\n\n    uint8_t *cur  = cur1;\n\n    uint8_t *next = next1;\n\n    int x;\n\n    uint8_t *prev2 = parity ? prev : cur ;\n\n    uint8_t *next2 = parity ? cur  : next;\n\n\n\n    /* Only edge pixels need to be processed here.  A constant value of false\n\n     * for is_not_edge should let the compiler ignore the whole branch. */\n\n    FILTER(0, 3, 0)\n\n\n\n    dst  = (uint8_t*)dst1  + w - 3;\n\n    prev = (uint8_t*)prev1 + w - 3;\n\n    cur  = (uint8_t*)cur1  + w - 3;\n\n    next = (uint8_t*)next1 + w - 3;\n\n    prev2 = (uint8_t*)(parity ? prev : cur);\n\n    next2 = (uint8_t*)(parity ? cur  : next);\n\n\n\n    FILTER(w - 3, w, 0)\n\n}\n", "idx": 17866, "_split": "valid", "_hash": "b93deefb24fb5dcef4f0f6dc9b703887"}
{"project": "FFmpeg", "commit_id": "53509d20cac1f9c4bb7e746f36e25d6fc66ae31b", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                        AVPacket *avpkt)\n\n{\n\n    V210DecContext *s = avctx->priv_data;\n\n\n\n    int h, w, stride, aligned_input;\n\n    AVFrame *pic = avctx->coded_frame;\n\n    const uint8_t *psrc = avpkt->data;\n\n    uint16_t *y, *u, *v;\n\n\n\n    if (s->custom_stride )\n\n        stride = s->custom_stride;\n\n    else {\n\n        int aligned_width = ((avctx->width + 47) / 48) * 48;\n\n        stride = aligned_width * 8 / 3;\n\n    }\n\n\n\n    aligned_input = !((uintptr_t)psrc & 0xf) && !(stride & 0xf);\n\n    if (aligned_input != s->aligned_input) {\n\n        s->aligned_input = aligned_input;\n\n        if (HAVE_MMX)\n\n            v210_x86_init(s);\n\n    }\n\n\n\n    if (pic->data[0])\n\n        avctx->release_buffer(avctx, pic);\n\n\n\n    if (avpkt->size < stride * avctx->height) {\n\n        av_log(avctx, AV_LOG_ERROR, \"packet too small\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pic->reference = 0;\n\n    if (avctx->get_buffer(avctx, pic) < 0)\n\n        return -1;\n\n\n\n    y = (uint16_t*)pic->data[0];\n\n    u = (uint16_t*)pic->data[1];\n\n    v = (uint16_t*)pic->data[2];\n\n    pic->pict_type = AV_PICTURE_TYPE_I;\n\n    pic->key_frame = 1;\n\n\n\n    for (h = 0; h < avctx->height; h++) {\n\n        const uint32_t *src = (const uint32_t*)psrc;\n\n        uint32_t val;\n\n\n\n        w = (avctx->width / 6) * 6;\n\n        s->unpack_frame(src, y, u, v, w);\n\n\n\n        y += w;\n\n        u += w >> 1;\n\n        v += w >> 1;\n\n        src += (w << 1) / 3;\n\n\n\n        if (w < avctx->width - 1) {\n\n            READ_PIXELS(u, y, v);\n\n\n\n            val  = av_le2ne32(*src++);\n\n            *y++ =  val & 0x3FF;\n\n        }\n\n        if (w < avctx->width - 3) {\n\n            *u++ = (val >> 10) & 0x3FF;\n\n            *y++ = (val >> 20) & 0x3FF;\n\n\n\n            val  = av_le2ne32(*src++);\n\n            *v++ =  val & 0x3FF;\n\n            *y++ = (val >> 10) & 0x3FF;\n\n        }\n\n\n\n        psrc += stride;\n\n        y += pic->linesize[0] / 2 - avctx->width;\n\n        u += pic->linesize[1] / 2 - avctx->width / 2;\n\n        v += pic->linesize[2] / 2 - avctx->width / 2;\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = *avctx->coded_frame;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 17878, "_split": "valid", "_hash": "f5687b963010e0dcaa79fd98ee25452d"}
{"project": "FFmpeg", "commit_id": "184c13f64aa5dda7af648cfd8302df3ef8afacc7", "target": 1, "func": "static int read_shape_from_file(int *cols, int *rows, int **values, const char *filename,\n\n                                void *log_ctx)\n\n{\n\n    uint8_t *buf, *p, *pend;\n\n    size_t size;\n\n    int ret, i, j, w;\n\n\n\n    if ((ret = av_file_map(filename, &buf, &size, 0, log_ctx)) < 0)\n\n        return ret;\n\n\n\n    /* prescan file to get the number of lines and the maximum width */\n\n    w = 0;\n\n    for (i = 0; i < size; i++) {\n\n        if (buf[i] == '\\n') {\n\n            if (*rows == INT_MAX) {\n\n                av_log(log_ctx, AV_LOG_ERROR, \"Overflow on the number of rows in the file\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            ++(*rows);\n\n            *cols = FFMAX(*cols, w);\n\n            w = 0;\n\n        } else if (w == INT_MAX) {\n\n            av_log(log_ctx, AV_LOG_ERROR, \"Overflow on the number of columns in the file\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        w++;\n\n    }\n\n    if (*rows > (SIZE_MAX / sizeof(int) / *cols)) {\n\n        av_log(log_ctx, AV_LOG_ERROR, \"File with size %dx%d is too big\\n\",\n\n               *rows, *cols);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!(*values = av_mallocz_array(sizeof(int) * *rows, *cols)))\n\n        return AVERROR(ENOMEM);\n\n\n\n    /* fill *values */\n\n    p    = buf;\n\n    pend = buf + size-1;\n\n    for (i = 0; i < *rows; i++) {\n\n        for (j = 0;; j++) {\n\n            if (p > pend || *p == '\\n') {\n\n                p++;\n\n                break;\n\n            } else\n\n                (*values)[*cols*i + j] = !!av_isgraph(*(p++));\n\n        }\n\n    }\n\n    av_file_unmap(buf, size);\n\n\n\n#ifdef DEBUG\n\n    {\n\n        char *line;\n\n        if (!(line = av_malloc(*cols + 1)))\n\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < *rows; i++) {\n\n            for (j = 0; j < *cols; j++)\n\n                line[j] = (*values)[i * *cols + j] ? '@' : ' ';\n\n            line[j] = 0;\n\n            av_log(log_ctx, AV_LOG_DEBUG, \"%3d: %s\\n\", i, line);\n\n        }\n\n        av_free(line);\n\n    }\n\n#endif\n\n\n\n    return 0;\n\n}\n", "idx": 17892, "_split": "valid", "_hash": "e58be318d18855b7104dac1192ee986d"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(rgb16to32)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tconst uint16_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint16_t *mm_end;\n\n#endif\n\n\tuint8_t *d = (uint8_t *)dst;\n\n\tconst uint16_t *s = (uint16_t *)src;\n\n\tend = s + src_size/2;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*s):\"memory\");\n\n\t__asm __volatile(\"pxor\t%%mm7,%%mm7\\n\\t\":::\"memory\");\n\n\tmm_end = end - 3;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\t\"movq\t%1, %%mm1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm2\\n\\t\"\n\n\t\t\"pand\t%2, %%mm0\\n\\t\"\n\n\t\t\"pand\t%3, %%mm1\\n\\t\"\n\n\t\t\"pand\t%4, %%mm2\\n\\t\"\n\n\t\t\"psllq\t$3, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm1, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm2, %%mm5\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm0\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm1\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm2\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm3\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm4\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm5\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm1\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm2\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm4\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm3, 8%0\\n\\t\"\n\n\t\t:\"=m\"(*d)\n\n\t\t:\"m\"(*s),\"m\"(mask16b),\"m\"(mask16g),\"m\"(mask16r)\n\n\t\t:\"memory\");\n\n\t\td += 16;\n\n\t\ts += 4;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tregister uint16_t bgr;\n\n\t\tbgr = *s++;\n\n#ifdef WORDS_BIGENDIAN\n\n\t\t*d++ = 0;\n\n\t\t*d++ = (bgr&0xF800)>>8;\n\n\t\t*d++ = (bgr&0x7E0)>>3;\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n#else\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n\t\t*d++ = (bgr&0x7E0)>>3;\n\n\t\t*d++ = (bgr&0xF800)>>8;\n\n\t\t*d++ = 0;\n\n#endif\n\n\t}\n\n}\n", "idx": 17894, "_split": "valid", "_hash": "415b22975bcabc5ed28e1311bffc2ee1"}
{"project": "FFmpeg", "commit_id": "07339a45a04e5fa0848937090511d69a39a04740", "target": 1, "func": "int ff_packet_split_and_drop_side_data(AVPacket *pkt){\n\n    if (!pkt->side_data_elems && pkt->size >12 && AV_RB64(pkt->data + pkt->size - 8) == FF_MERGE_MARKER){\n\n        int i;\n\n        unsigned int size;\n\n        uint8_t *p;\n\n\n\n        p = pkt->data + pkt->size - 8 - 5;\n\n        for (i=1; ; i++){\n\n            size = AV_RB32(p);\n\n            if (size>INT_MAX - 5 || p - pkt->data < size)\n\n\n            if (p[4]&128)\n\n                break;\n\n            if (p - pkt->data < size + 5)\n\n\n            p-= size+5;\n\n\n\n        }\n\n        pkt->size = p - pkt->data - size;\n\n        av_assert0(pkt->size >= 0);\n\n        return 1;\n\n    }\n\n\n}", "idx": 17925, "_split": "valid", "_hash": "15e03ff647cba8c462efd6aa9da506f7"}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static float get_band_cost_SPAIR_mips(struct AACEncContext *s,\n\n                                      PutBitContext *pb, const float *in,\n\n                                      const float *scaled, int size, int scale_idx,\n\n                                      int cb, const float lambda, const float uplim,\n\n                                      int *bits)\n\n{\n\n    const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    int i;\n\n    float cost = 0;\n\n    int qc1, qc2, qc3, qc4;\n\n    int curbits = 0;\n\n\n\n    uint8_t *p_bits  = (uint8_t *)ff_aac_spectral_bits[cb-1];\n\n    float   *p_codes = (float   *)ff_aac_codebook_vectors[cb-1];\n\n\n\n    for (i = 0; i < size; i += 4) {\n\n        const float *vec, *vec2;\n\n        int curidx, curidx2;\n\n        int   *in_int = (int   *)&in[i];\n\n        float *in_pos = (float *)&in[i];\n\n        float di0, di1, di2, di3;\n\n        int t0, t1, t2, t3, t4, t5, t6, t7;\n\n\n\n        qc1 = scaled[i  ] * Q34 + ROUND_STANDARD;\n\n        qc2 = scaled[i+1] * Q34 + ROUND_STANDARD;\n\n        qc3 = scaled[i+2] * Q34 + ROUND_STANDARD;\n\n        qc4 = scaled[i+3] * Q34 + ROUND_STANDARD;\n\n\n\n        __asm__ volatile (\n\n            \".set push                                  \\n\\t\"\n\n            \".set noreorder                             \\n\\t\"\n\n\n\n            \"ori        %[t4],  $zero,  4               \\n\\t\"\n\n            \"slt        %[t0],  %[t4],  %[qc1]          \\n\\t\"\n\n            \"slt        %[t1],  %[t4],  %[qc2]          \\n\\t\"\n\n            \"slt        %[t2],  %[t4],  %[qc3]          \\n\\t\"\n\n            \"slt        %[t3],  %[t4],  %[qc4]          \\n\\t\"\n\n            \"movn       %[qc1], %[t4],  %[t0]           \\n\\t\"\n\n            \"movn       %[qc2], %[t4],  %[t1]           \\n\\t\"\n\n            \"movn       %[qc3], %[t4],  %[t2]           \\n\\t\"\n\n            \"movn       %[qc4], %[t4],  %[t3]           \\n\\t\"\n\n            \"lw         %[t0],  0(%[in_int])            \\n\\t\"\n\n            \"lw         %[t1],  4(%[in_int])            \\n\\t\"\n\n            \"lw         %[t2],  8(%[in_int])            \\n\\t\"\n\n            \"lw         %[t3],  12(%[in_int])           \\n\\t\"\n\n            \"srl        %[t0],  %[t0],  31              \\n\\t\"\n\n            \"srl        %[t1],  %[t1],  31              \\n\\t\"\n\n            \"srl        %[t2],  %[t2],  31              \\n\\t\"\n\n            \"srl        %[t3],  %[t3],  31              \\n\\t\"\n\n            \"subu       %[t4],  $zero,  %[qc1]          \\n\\t\"\n\n            \"subu       %[t5],  $zero,  %[qc2]          \\n\\t\"\n\n            \"subu       %[t6],  $zero,  %[qc3]          \\n\\t\"\n\n            \"subu       %[t7],  $zero,  %[qc4]          \\n\\t\"\n\n            \"movn       %[qc1], %[t4],  %[t0]           \\n\\t\"\n\n            \"movn       %[qc2], %[t5],  %[t1]           \\n\\t\"\n\n            \"movn       %[qc3], %[t6],  %[t2]           \\n\\t\"\n\n            \"movn       %[qc4], %[t7],  %[t3]           \\n\\t\"\n\n\n\n            \".set pop                                   \\n\\t\"\n\n\n\n            : [qc1]\"+r\"(qc1), [qc2]\"+r\"(qc2),\n\n              [qc3]\"+r\"(qc3), [qc4]\"+r\"(qc4),\n\n              [t0]\"=&r\"(t0), [t1]\"=&r\"(t1), [t2]\"=&r\"(t2), [t3]\"=&r\"(t3),\n\n              [t4]\"=&r\"(t4), [t5]\"=&r\"(t5), [t6]\"=&r\"(t6), [t7]\"=&r\"(t7)\n\n            : [in_int]\"r\"(in_int)\n\n            : \"memory\"\n\n        );\n\n\n\n        curidx = 9 * qc1;\n\n        curidx += qc2 + 40;\n\n\n\n        curidx2 = 9 * qc3;\n\n        curidx2 += qc4 + 40;\n\n\n\n        curbits += p_bits[curidx];\n\n        curbits += p_bits[curidx2];\n\n\n\n        vec     = &p_codes[curidx*2];\n\n        vec2    = &p_codes[curidx2*2];\n\n\n\n        __asm__ volatile (\n\n            \".set push                                  \\n\\t\"\n\n            \".set noreorder                             \\n\\t\"\n\n\n\n            \"lwc1       $f0,    0(%[in_pos])            \\n\\t\"\n\n            \"lwc1       $f1,    0(%[vec])               \\n\\t\"\n\n            \"lwc1       $f2,    4(%[in_pos])            \\n\\t\"\n\n            \"lwc1       $f3,    4(%[vec])               \\n\\t\"\n\n            \"lwc1       $f4,    8(%[in_pos])            \\n\\t\"\n\n            \"lwc1       $f5,    0(%[vec2])              \\n\\t\"\n\n            \"lwc1       $f6,    12(%[in_pos])           \\n\\t\"\n\n            \"lwc1       $f7,    4(%[vec2])              \\n\\t\"\n\n            \"nmsub.s    %[di0], $f0,    $f1,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di1], $f2,    $f3,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di2], $f4,    $f5,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di3], $f6,    $f7,    %[IQ]   \\n\\t\"\n\n\n\n            \".set pop                                   \\n\\t\"\n\n\n\n            : [di0]\"=&f\"(di0), [di1]\"=&f\"(di1),\n\n              [di2]\"=&f\"(di2), [di3]\"=&f\"(di3)\n\n            : [in_pos]\"r\"(in_pos), [vec]\"r\"(vec),\n\n              [vec2]\"r\"(vec2), [IQ]\"f\"(IQ)\n\n            : \"$f0\", \"$f1\", \"$f2\", \"$f3\",\n\n              \"$f4\", \"$f5\", \"$f6\", \"$f7\",\n\n              \"memory\"\n\n        );\n\n\n\n        cost += di0 * di0 + di1 * di1\n\n                + di2 * di2 + di3 * di3;\n\n    }\n\n\n\n    if (bits)\n\n        *bits = curbits;\n\n    return cost * lambda + curbits;\n\n}\n", "idx": 17943, "_split": "valid", "_hash": "358a0d056f187c36383ef3c405c83301"}
{"project": "FFmpeg", "commit_id": "7d204e67e8f991bfdfb6a6e91b6855b6c5a782c0", "target": 1, "func": "void ff_rm_free_rmstream (RMStream *rms)\n\n{\n\n    av_free(rms->videobuf);\n\n    av_free(rms->audiobuf);\n\n}\n", "idx": 17984, "_split": "valid", "_hash": "ebdd72320d9716d684f44d6674a1859e"}
{"project": "FFmpeg", "commit_id": "1f94c31f69e6eb7eee80d0a3b42875261a18dcbe", "target": 0, "func": "int ff_raw_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    AVStream *st;\n\n    enum CodecID id;\n\n\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n        id = s->iformat->value;\n\n        if (id == CODEC_ID_RAWVIDEO) {\n\n            st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        } else {\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        }\n\n        st->codec->codec_id = id;\n\n\n\n        switch(st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO: {\n\n            RawAudioDemuxerContext *s1 = s->priv_data;\n\n\n\n#if FF_API_FORMAT_PARAMETERS\n\n            if (ap->sample_rate)\n\n                st->codec->sample_rate = ap->sample_rate;\n\n            if (ap->channels)\n\n                st->codec->channels    = ap->channels;\n\n            else st->codec->channels   = 1;\n\n#endif\n\n\n\n            if (s1->sample_rate)\n\n                st->codec->sample_rate = s1->sample_rate;\n\n            if (s1->channels)\n\n                st->codec->channels    = s1->channels;\n\n\n\n            st->codec->bits_per_coded_sample = av_get_bits_per_sample(st->codec->codec_id);\n\n            assert(st->codec->bits_per_coded_sample > 0);\n\n            st->codec->block_align = st->codec->bits_per_coded_sample*st->codec->channels/8;\n\n            av_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n            break;\n\n            }\n\n        case AVMEDIA_TYPE_VIDEO: {\n\n            FFRawVideoDemuxerContext *s1 = s->priv_data;\n\n            int width = 0, height = 0, ret;\n\n            enum PixelFormat pix_fmt;\n\n\n\n            if(ap->time_base.num)\n\n                av_set_pts_info(st, 64, ap->time_base.num, ap->time_base.den);\n\n            else\n\n                av_set_pts_info(st, 64, 1, 25);\n\n            if (s1->video_size && (ret = av_parse_video_size(&width, &height, s1->video_size)) < 0) {\n\n                av_log(s, AV_LOG_ERROR, \"Couldn't parse video size.\\n\");\n\n                goto fail;\n\n            }\n\n            if ((pix_fmt = av_get_pix_fmt(s1->pixel_format)) == PIX_FMT_NONE) {\n\n                av_log(s, AV_LOG_ERROR, \"No such pixel format: %s.\\n\", s1->pixel_format);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n#if FF_API_FORMAT_PARAMETERS\n\n            if (ap->width > 0)\n\n                width = ap->width;\n\n            if (ap->height > 0)\n\n                height = ap->height;\n\n            if (ap->pix_fmt)\n\n                pix_fmt = ap->pix_fmt;\n\n#endif\n\n            st->codec->width  = width;\n\n            st->codec->height = height;\n\n            st->codec->pix_fmt = pix_fmt;\n\nfail:\n\n            av_freep(&s1->video_size);\n\n            av_freep(&s1->pixel_format);\n\n            return ret;\n\n            }\n\n        default:\n\n            return -1;\n\n        }\n\n    return 0;\n\n}\n", "idx": 17998, "_split": "valid", "_hash": "0b1e7e2ec4755bc8b4fc98070eba837f"}
{"project": "FFmpeg", "commit_id": "0b882b4009c9fbe24020c2fe83b21ee43d0784ea", "target": 1, "func": "static int read_access_unit(AVCodecContext *avctx, void* data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MLPDecodeContext *m = avctx->priv_data;\n\n    GetBitContext gb;\n\n    unsigned int length, substr;\n\n    unsigned int substream_start;\n\n    unsigned int header_size = 4;\n\n    unsigned int substr_header_size = 0;\n\n    uint8_t substream_parity_present[MAX_SUBSTREAMS];\n\n    uint16_t substream_data_len[MAX_SUBSTREAMS];\n\n    uint8_t parity_bits;\n\n\n\n    if (buf_size < 4)\n\n        return 0;\n\n\n\n    length = (AV_RB16(buf) & 0xfff) * 2;\n\n\n\n    if (length > buf_size)\n\n        return -1;\n\n\n\n    init_get_bits(&gb, (buf + 4), (length - 4) * 8);\n\n\n\n    m->is_major_sync_unit = 0;\n\n    if (show_bits_long(&gb, 31) == (0xf8726fba >> 1)) {\n\n        if (read_major_sync(m, &gb) < 0)\n\n            goto error;\n\n        m->is_major_sync_unit = 1;\n\n        header_size += 28;\n\n    }\n\n\n\n    if (!m->params_valid) {\n\n        av_log(m->avctx, AV_LOG_WARNING,\n\n               \"Stream parameters not seen; skipping frame.\\n\");\n\n        *data_size = 0;\n\n        return length;\n\n    }\n\n\n\n    substream_start = 0;\n\n\n\n    for (substr = 0; substr < m->num_substreams; substr++) {\n\n        int extraword_present, checkdata_present, end, nonrestart_substr;\n\n\n\n        extraword_present = get_bits1(&gb);\n\n        nonrestart_substr = get_bits1(&gb);\n\n        checkdata_present = get_bits1(&gb);\n\n        skip_bits1(&gb);\n\n\n\n        end = get_bits(&gb, 12) * 2;\n\n\n\n        substr_header_size += 2;\n\n\n\n        if (extraword_present) {\n\n            if (m->avctx->codec_id == CODEC_ID_MLP) {\n\n                av_log(m->avctx, AV_LOG_ERROR, \"There must be no extraword for MLP.\\n\");\n\n                goto error;\n\n            }\n\n            skip_bits(&gb, 16);\n\n            substr_header_size += 2;\n\n        }\n\n\n\n        if (!(nonrestart_substr ^ m->is_major_sync_unit)) {\n\n            av_log(m->avctx, AV_LOG_ERROR, \"Invalid nonrestart_substr.\\n\");\n\n            goto error;\n\n        }\n\n\n\n        if (end + header_size + substr_header_size > length) {\n\n            av_log(m->avctx, AV_LOG_ERROR,\n\n                   \"Indicated length of substream %d data goes off end of \"\n\n                   \"packet.\\n\", substr);\n\n            end = length - header_size - substr_header_size;\n\n        }\n\n\n\n        if (end < substream_start) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Indicated end offset of substream %d data \"\n\n                   \"is smaller than calculated start offset.\\n\",\n\n                   substr);\n\n            goto error;\n\n        }\n\n\n\n        if (substr > m->max_decoded_substream)\n\n            continue;\n\n\n\n        substream_parity_present[substr] = checkdata_present;\n\n        substream_data_len[substr] = end - substream_start;\n\n        substream_start = end;\n\n    }\n\n\n\n    parity_bits  = ff_mlp_calculate_parity(buf, 4);\n\n    parity_bits ^= ff_mlp_calculate_parity(buf + header_size, substr_header_size);\n\n\n\n    if ((((parity_bits >> 4) ^ parity_bits) & 0xF) != 0xF) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Parity check failed.\\n\");\n\n        goto error;\n\n    }\n\n\n\n    buf += header_size + substr_header_size;\n\n\n\n    for (substr = 0; substr <= m->max_decoded_substream; substr++) {\n\n        SubStream *s = &m->substream[substr];\n\n        init_get_bits(&gb, buf, substream_data_len[substr] * 8);\n\n\n\n        m->matrix_changed = 0;\n\n        memset(m->filter_changed, 0, sizeof(m->filter_changed));\n\n\n\n        s->blockpos = 0;\n\n        do {\n\n            if (get_bits1(&gb)) {\n\n                if (get_bits1(&gb)) {\n\n                    /* A restart header should be present. */\n\n                    if (read_restart_header(m, &gb, buf, substr) < 0)\n\n                        goto next_substr;\n\n                    s->restart_seen = 1;\n\n                }\n\n\n\n                if (!s->restart_seen)\n\n                    goto next_substr;\n\n                if (read_decoding_params(m, &gb, substr) < 0)\n\n                    goto next_substr;\n\n            }\n\n\n\n            if (!s->restart_seen)\n\n                goto next_substr;\n\n\n\n            if (read_block_data(m, &gb, substr) < 0)\n\n                return -1;\n\n\n\n            if (get_bits_count(&gb) >= substream_data_len[substr] * 8)\n\n                goto substream_length_mismatch;\n\n\n\n        } while (!get_bits1(&gb));\n\n\n\n        skip_bits(&gb, (-get_bits_count(&gb)) & 15);\n\n\n\n        if (substream_data_len[substr] * 8 - get_bits_count(&gb) >= 32) {\n\n            int shorten_by;\n\n\n\n            if (get_bits(&gb, 16) != 0xD234)\n\n                return -1;\n\n\n\n            shorten_by = get_bits(&gb, 16);\n\n            if      (m->avctx->codec_id == CODEC_ID_TRUEHD && shorten_by  & 0x2000)\n\n                s->blockpos -= FFMIN(shorten_by & 0x1FFF, s->blockpos);\n\n            else if (m->avctx->codec_id == CODEC_ID_MLP    && shorten_by != 0xD234)\n\n                return -1;\n\n\n\n            if (substr == m->max_decoded_substream)\n\n                av_log(m->avctx, AV_LOG_INFO, \"End of stream indicated.\\n\");\n\n        }\n\n\n\n        if (substream_parity_present[substr]) {\n\n            uint8_t parity, checksum;\n\n\n\n            if (substream_data_len[substr] * 8 - get_bits_count(&gb) != 16)\n\n                goto substream_length_mismatch;\n\n\n\n            parity   = ff_mlp_calculate_parity(buf, substream_data_len[substr] - 2);\n\n            checksum = ff_mlp_checksum8       (buf, substream_data_len[substr] - 2);\n\n\n\n            if ((get_bits(&gb, 8) ^ parity) != 0xa9    )\n\n                av_log(m->avctx, AV_LOG_ERROR, \"Substream %d parity check failed.\\n\", substr);\n\n            if ( get_bits(&gb, 8)           != checksum)\n\n                av_log(m->avctx, AV_LOG_ERROR, \"Substream %d checksum failed.\\n\"    , substr);\n\n        }\n\n\n\n        if (substream_data_len[substr] * 8 != get_bits_count(&gb))\n\n            goto substream_length_mismatch;\n\n\n\nnext_substr:\n\n        if (!s->restart_seen)\n\n            av_log(m->avctx, AV_LOG_ERROR,\n\n                   \"No restart header present in substream %d.\\n\", substr);\n\n\n\n        buf += substream_data_len[substr];\n\n    }\n\n\n\n    rematrix_channels(m, m->max_decoded_substream);\n\n\n\n    if (output_data(m, m->max_decoded_substream, data, data_size) < 0)\n\n        return -1;\n\n\n\n    return length;\n\n\n\nsubstream_length_mismatch:\n\n    av_log(m->avctx, AV_LOG_ERROR, \"substream %d length mismatch\\n\", substr);\n\n    return -1;\n\n\n\nerror:\n\n    m->params_valid = 0;\n\n    return -1;\n\n}\n", "idx": 18032, "_split": "valid", "_hash": "0b3938a052c98e70bb08a5e86a0e97e7"}
{"project": "FFmpeg", "commit_id": "cc965300cb504ce452df1d37041b81c6ee6a5964", "target": 0, "func": "static void sunrast_image_write_image(AVCodecContext *avctx,\n\n                                      const uint8_t *pixels,\n\n                                      const uint32_t *palette_data,\n\n                                      int linesize)\n\n{\n\n    SUNRASTContext *s = avctx->priv_data;\n\n    const uint8_t *ptr;\n\n    int len, alen, x;\n\n\n\n    if (s->maplength) {     // palettized\n\n        PutByteContext pb_r, pb_g;\n\n        int len = s->maplength / 3;\n\n\n\n        pb_r = s->p;\n\n        bytestream2_skip_p(&s->p, len);\n\n        pb_g = s->p;\n\n        bytestream2_skip_p(&s->p, len);\n\n\n\n        for (x = 0; x < len; x++) {\n\n            uint32_t pixel = palette_data[x];\n\n\n\n            bytestream2_put_byteu(&pb_r, (pixel >> 16) & 0xFF);\n\n            bytestream2_put_byteu(&pb_g, (pixel >> 8)  & 0xFF);\n\n            bytestream2_put_byteu(&s->p,  pixel        & 0xFF);\n\n        }\n\n    }\n\n\n\n    len  = (s->depth * avctx->width + 7) >> 3;\n\n    alen = len + (len & 1);\n\n    ptr  = pixels;\n\n\n\n     if (s->type == RT_BYTE_ENCODED) {\n\n        uint8_t value, value2;\n\n        int run;\n\n        const uint8_t *end = pixels + avctx->height * linesize;\n\n\n\n        ptr = pixels;\n\n\n\n#define GET_VALUE ptr >= end ? 0 : x >= len ? ptr[len-1] : ptr[x]\n\n\n\n        x = 0;\n\n        value2 = GET_VALUE;\n\n        while (ptr < end) {\n\n            run = 1;\n\n            value = value2;\n\n            x++;\n\n            if (x >= alen) {\n\n                x = 0;\n\n                ptr += linesize;\n\n            }\n\n\n\n            value2 = GET_VALUE;\n\n            while (value2 == value && run < 256 && ptr < end) {\n\n                x++;\n\n                run++;\n\n                if (x >= alen) {\n\n                    x = 0;\n\n                    ptr += linesize;\n\n                }\n\n                value2 = GET_VALUE;\n\n            }\n\n\n\n            if (run > 2 || value == RLE_TRIGGER) {\n\n                bytestream2_put_byteu(&s->p, RLE_TRIGGER);\n\n                bytestream2_put_byteu(&s->p, run - 1);\n\n                if (run > 1)\n\n                    bytestream2_put_byteu(&s->p, value);\n\n            } else if (run == 1) {\n\n                bytestream2_put_byteu(&s->p, value);\n\n            } else\n\n                bytestream2_put_be16u(&s->p, (value << 8) | value);\n\n        }\n\n\n\n        // update data length for header\n\n        s->length = bytestream2_tell_p(&s->p) - 32 - s->maplength;\n\n    } else {\n\n        int y;\n\n        for (y = 0; y < avctx->height; y++) {\n\n            bytestream2_put_buffer(&s->p, ptr, len);\n\n            if (len < alen)\n\n                bytestream2_put_byteu(&s->p, 0);\n\n            ptr += linesize;\n\n        }\n\n    }\n\n}\n", "idx": 18034, "_split": "valid", "_hash": "aaedb6558ea4b7fc79ef8635fe723a1e"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int sol_probe(AVProbeData *p)\n\n{\n\n    /* check file header */\n\n    uint16_t magic;\n\n    if (p->buf_size <= 14)\n\n        return 0;\n\n    magic=le2me_16(*((uint16_t*)p->buf));\n\n    if ((magic == 0x0B8D || magic == 0x0C0D || magic == 0x0C8D) &&\n\n        p->buf[2] == 'S' && p->buf[3] == 'O' &&\n\n        p->buf[4] == 'L' && p->buf[5] == 0)\n\n        return AVPROBE_SCORE_MAX;\n\n    else\n\n        return 0;\n\n}\n", "idx": 18064, "_split": "valid", "_hash": "c4c7ad4a437aef6f818efcb7207f7a2f"}
{"project": "FFmpeg", "commit_id": "b4466c9c1a82ce72011ed72e1221a30b15f73adb", "target": 1, "func": "static int daala_header(AVFormatContext *s, int idx)\n\n{\n\n    int i, err;\n\n    uint8_t *cdp;\n\n    GetByteContext gb;\n\n    AVRational timebase;\n\n    struct ogg *ogg        = s->priv_data;\n\n    struct ogg_stream *os  = ogg->streams + idx;\n\n    AVStream *st           = s->streams[idx];\n\n    int cds                = st->codec->extradata_size + os->psize + 2;\n\n    DaalaInfoHeader *hdr   = os->private;\n\n\n\n    if (!(os->buf[os->pstart] & 0x80))\n\n        return 0;\n\n\n\n    if (!hdr) {\n\n        hdr = av_mallocz(sizeof(*hdr));\n\n        if (!hdr)\n\n            return AVERROR(ENOMEM);\n\n        os->private = hdr;\n\n\n\n\n    switch (os->buf[os->pstart]) {\n\n    case 0x80:\n\n        bytestream2_init(&gb, os->buf + os->pstart, os->psize);\n\n        bytestream2_skip(&gb, ff_daala_codec.magicsize);\n\n\n\n        hdr->version_maj = bytestream2_get_byte(&gb);\n\n        hdr->version_min = bytestream2_get_byte(&gb);\n\n        hdr->version_sub = bytestream2_get_byte(&gb);\n\n\n\n        st->codec->width  = bytestream2_get_ne32(&gb);\n\n        st->codec->height = bytestream2_get_ne32(&gb);\n\n\n\n        st->sample_aspect_ratio.num = bytestream2_get_ne32(&gb);\n\n        st->sample_aspect_ratio.den = bytestream2_get_ne32(&gb);\n\n\n\n        timebase.num = bytestream2_get_ne32(&gb);\n\n        timebase.den = bytestream2_get_ne32(&gb);\n\n        if (timebase.num < 0 && timebase.den < 0) {\n\n            av_log(s, AV_LOG_WARNING, \"Invalid timebase, assuming 30 FPS\\n\");\n\n            timebase.num = 1;\n\n            timebase.den = 30;\n\n\n        avpriv_set_pts_info(st, 64, timebase.den, timebase.num);\n\n\n\n        hdr->frame_duration = bytestream2_get_ne32(&gb);\n\n        hdr->gpshift = bytestream2_get_byte(&gb);\n\n        hdr->gpmask  = (1 << hdr->gpshift) - 1;\n\n\n\n        hdr->format.depth  = 8 + 2*(bytestream2_get_byte(&gb)-1);\n\n\n\n        hdr->fpr = bytestream2_get_byte(&gb);\n\n\n\n        hdr->format.planes = bytestream2_get_byte(&gb);\n\n\n\n\n\n\n\n        for (i = 0; i < hdr->format.planes; i++) {\n\n            hdr->format.xdec[i] = bytestream2_get_byte(&gb);\n\n            hdr->format.ydec[i] = bytestream2_get_byte(&gb);\n\n\n\n\n        if ((st->codec->pix_fmt = daala_match_pix_fmt(&hdr->format)) < 0)\n\n            av_log(s, AV_LOG_ERROR, \"Unsupported pixel format - %i %i\\n\",\n\n                   hdr->format.depth, hdr->format.planes);\n\n\n\n        st->codec->codec_id   = AV_CODEC_ID_DAALA;\n\n        st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        st->need_parsing      = AVSTREAM_PARSE_HEADERS;\n\n\n\n        hdr->init_d = 1;\n\n        break;\n\n    case 0x81:\n\n        if (!hdr->init_d)\n\n\n        ff_vorbis_stream_comment(s, st,\n\n                                 os->buf + os->pstart + ff_daala_codec.magicsize,\n\n                                 os->psize - ff_daala_codec.magicsize);\n\n        break;\n\n    case 0x82:\n\n        if (!hdr->init_d)\n\n\n        break;\n\n    default:\n\n        av_log(s, AV_LOG_ERROR, \"Unknown header type %X\\n\", os->buf[os->pstart]);\n\n\n        break;\n\n\n\n\n    if ((err = av_reallocp(&st->codec->extradata,\n\n                           cds + AV_INPUT_BUFFER_PADDING_SIZE)) < 0) {\n\n        st->codec->extradata_size = 0;\n\n        return err;\n\n\n\n\n    memset(st->codec->extradata + cds, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n\n    cdp    = st->codec->extradata + st->codec->extradata_size;\n\n    *cdp++ = os->psize >> 8;\n\n    *cdp++ = os->psize & 0xff;\n\n    memcpy(cdp, os->buf + os->pstart, os->psize);\n\n    st->codec->extradata_size = cds;\n\n\n\n    return 1;\n", "idx": 18072, "_split": "valid", "_hash": "9d27b89667f66d7b6bdf23636032140a"}
{"project": "FFmpeg", "commit_id": "d70fa8f131699fa1889cf65cc88563d000c4e1ef", "target": 1, "func": "static int vorbis_parse_setup_hdr_mappings(vorbis_context *vc) {\n\n    GetBitContext *gb=&vc->gb;\n\n    uint_fast8_t i, j;\n\n\n\n    vc->mapping_count=get_bits(gb, 6)+1;\n\n    vc->mappings=av_mallocz(vc->mapping_count * sizeof(vorbis_mapping));\n\n\n\n    AV_DEBUG(\" There are %d mappings. \\n\", vc->mapping_count);\n\n\n\n    for(i=0;i<vc->mapping_count;++i) {\n\n        vorbis_mapping *mapping_setup=&vc->mappings[i];\n\n\n\n        if (get_bits(gb, 16)) {\n\n            av_log(vc->avccontext, AV_LOG_ERROR, \"Other mappings than type 0 are not compliant with the Vorbis I specification. \\n\");\n\n            return 1;\n\n        }\n\n        if (get_bits1(gb)) {\n\n            mapping_setup->submaps=get_bits(gb, 4)+1;\n\n        } else {\n\n            mapping_setup->submaps=1;\n\n        }\n\n\n\n        if (get_bits1(gb)) {\n\n            mapping_setup->coupling_steps=get_bits(gb, 8)+1;\n\n            mapping_setup->magnitude=av_mallocz(mapping_setup->coupling_steps * sizeof(uint_fast8_t));\n\n            mapping_setup->angle    =av_mallocz(mapping_setup->coupling_steps * sizeof(uint_fast8_t));\n\n            for(j=0;j<mapping_setup->coupling_steps;++j) {\n\n                mapping_setup->magnitude[j]=get_bits(gb, ilog(vc->audio_channels-1));\n\n                mapping_setup->angle[j]=get_bits(gb, ilog(vc->audio_channels-1));\n\n                // FIXME: sanity checks\n\n            }\n\n        } else {\n\n            mapping_setup->coupling_steps=0;\n\n        }\n\n\n\n        AV_DEBUG(\"   %d mapping coupling steps: %d \\n\", i, mapping_setup->coupling_steps);\n\n\n\n        if(get_bits(gb, 2)) {\n\n            av_log(vc->avccontext, AV_LOG_ERROR, \"%d. mapping setup data invalid. \\n\", i);\n\n            return 1; // following spec.\n\n        }\n\n\n\n        if (mapping_setup->submaps>1) {\n\n            mapping_setup->mux=av_mallocz(vc->audio_channels * sizeof(uint_fast8_t));\n\n            for(j=0;j<vc->audio_channels;++j) {\n\n                mapping_setup->mux[j]=get_bits(gb, 4);\n\n            }\n\n        }\n\n\n\n        for(j=0;j<mapping_setup->submaps;++j) {\n\n            skip_bits(gb, 8); // FIXME check?\n\n            mapping_setup->submap_floor[j]=get_bits(gb, 8);\n\n            mapping_setup->submap_residue[j]=get_bits(gb, 8);\n\n\n\n            AV_DEBUG(\"   %d mapping %d submap : floor %d, residue %d \\n\", i, j, mapping_setup->submap_floor[j], mapping_setup->submap_residue[j]);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 18074, "_split": "valid", "_hash": "f7204752c28672b10f0cbff9ffbd7d7d"}
{"project": "FFmpeg", "commit_id": "ac0057f3a6dd6a06e6b47d95371f7e271f0cc9ae", "target": 0, "func": "static void residue_encode(venc_context_t * venc, residue_t * rc, PutBitContext * pb, float * coeffs, int samples, int real_ch) {\n\n    int pass, i, j, p, k;\n\n    int psize = rc->partition_size;\n\n    int partitions = (rc->end - rc->begin) / psize;\n\n    int channels = (rc->type == 2) ? 1 : real_ch;\n\n    int classes[channels][partitions];\n\n    int classwords = venc->codebooks[rc->classbook].ndimentions;\n\n\n\n    assert(rc->type == 2);\n\n    assert(real_ch == 2);\n\n    for (p = 0; p < partitions; p++) {\n\n        float max1 = 0., max2 = 0.;\n\n        int s = rc->begin + p * psize;\n\n        for (k = s; k < s + psize; k += 2) {\n\n            max1 = FFMAX(max1, fabs(coeffs[          k / real_ch]));\n\n            max2 = FFMAX(max2, fabs(coeffs[samples + k / real_ch]));\n\n        }\n\n\n\n        for (i = 0; i < rc->classifications - 1; i++) {\n\n            if (max1 < rc->maxes[i][0] && max2 < rc->maxes[i][1]) break;\n\n        }\n\n        classes[0][p] = i;\n\n    }\n\n\n\n    for (pass = 0; pass < 8; pass++) {\n\n        p = 0;\n\n        while (p < partitions) {\n\n            if (pass == 0) for (j = 0; j < channels; j++) {\n\n                codebook_t * book = &venc->codebooks[rc->classbook];\n\n                int entry = 0;\n\n                for (i = 0; i < classwords; i++) {\n\n                    entry *= rc->classifications;\n\n                    entry += classes[j][p + i];\n\n                }\n\n                put_codeword(pb, book, entry);\n\n            }\n\n            for (i = 0; i < classwords && p < partitions; i++, p++) {\n\n                for (j = 0; j < channels; j++) {\n\n                    int nbook = rc->books[classes[j][p]][pass];\n\n                    codebook_t * book = &venc->codebooks[nbook];\n\n                    float * buf = coeffs + samples*j + rc->begin + p*psize;\n\n                    if (nbook == -1) continue;\n\n\n\n                    assert(rc->type == 0 || rc->type == 2);\n\n                    assert(!(psize % book->ndimentions));\n\n\n\n                    if (rc->type == 0) {\n\n                        for (k = 0; k < psize; k += book->ndimentions) {\n\n                            float * a = put_vector(book, pb, &buf[k]);\n\n                            int l;\n\n                            for (l = 0; l < book->ndimentions; l++) buf[k + l] -= a[l];\n\n                        }\n\n                    } else {\n\n                        for (k = 0; k < psize; k += book->ndimentions) {\n\n                            int dim = book->ndimentions, s = rc->begin + p * psize + k, l;\n\n                            float vec[dim], * a = vec;\n\n                            for (l = s; l < s + dim; l++)\n\n                                *a++ = coeffs[(l % real_ch) * samples + l / real_ch];\n\n                            a = put_vector(book, pb, vec);\n\n                            for (l = s; l < s + dim; l++)\n\n                                coeffs[(l % real_ch) * samples + l / real_ch] -= *a++;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 18154, "_split": "valid", "_hash": "6ec25544f03e5433084b9b8e6b066394"}
{"project": "FFmpeg", "commit_id": "97cfa55eea39cef30abe14682c56c1e4e7f6f10d", "target": 1, "func": "static void ff_compute_band_indexes(MPADecodeContext *s, GranuleDef *g)\n\n{\n\n    if (g->block_type == 2) {\n\n        if (g->switch_point) {\n\n            /* if switched mode, we handle the 36 first samples as\n\n                long blocks.  For 8000Hz, we handle the 72 first\n\n                exponents as long blocks */\n\n            if (s->sample_rate_index <= 2)\n\n                g->long_end = 8;\n\n            else\n\n                g->long_end = 6;\n\n\n\n            g->short_start = 2 + (s->sample_rate_index != 8);\n\n        } else {\n\n            g->long_end    = 0;\n\n            g->short_start = 0;\n\n        }\n\n    } else {\n\n        g->short_start = 13;\n\n        g->long_end    = 22;\n\n    }\n\n}\n", "idx": 18217, "_split": "valid", "_hash": "ac50b9e3d6937685847d12f80676167f"}
{"project": "FFmpeg", "commit_id": "80a5d05108cb218e8cd2e25c6621a3bfef0a832e", "target": 0, "func": "static av_cold int vaapi_encode_h264_init_fixed_qp(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext      *ctx = avctx->priv_data;\n\n    VAAPIEncodeH264Context *priv = ctx->priv_data;\n\n    VAAPIEncodeH264Options  *opt = ctx->codec_options;\n\n\n\n    priv->fixed_qp_p = opt->qp;\n\n    if (avctx->i_quant_factor > 0.0)\n\n        priv->fixed_qp_idr = (int)((priv->fixed_qp_p * avctx->i_quant_factor +\n\n                                    avctx->i_quant_offset) + 0.5);\n\n    else\n\n        priv->fixed_qp_idr = priv->fixed_qp_p;\n\n    if (avctx->b_quant_factor > 0.0)\n\n        priv->fixed_qp_b = (int)((priv->fixed_qp_p * avctx->b_quant_factor +\n\n                                  avctx->b_quant_offset) + 0.5);\n\n    else\n\n        priv->fixed_qp_b = priv->fixed_qp_p;\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Using fixed QP = \"\n\n           \"%d / %d / %d for IDR- / P- / B-frames.\\n\",\n\n           priv->fixed_qp_idr, priv->fixed_qp_p, priv->fixed_qp_b);\n\n    return 0;\n\n}\n", "idx": 18234, "_split": "valid", "_hash": "9fc8f37bf35fb7448578bd3add92c47c"}
{"project": "FFmpeg", "commit_id": "d7cabb3c7e843c2028b398cb19a40db84d40c790", "target": 0, "func": "int ff_bgmc_init(AVCodecContext *avctx, uint8_t **cf_lut, int **cf_lut_status)\n\n{\n\n    *cf_lut        = av_malloc(sizeof(**cf_lut)        * LUT_BUFF * 16 * LUT_SIZE);\n\n    *cf_lut_status = av_malloc(sizeof(**cf_lut_status) * LUT_BUFF);\n\n\n\n    if (!cf_lut || !cf_lut_status) {\n\n        ff_bgmc_end(cf_lut, cf_lut_status);\n\n        av_log(avctx, AV_LOG_ERROR, \"Allocating buffer memory failed.\\n\");\n\n        return AVERROR(ENOMEM);\n\n    } else {\n\n        // initialize lut_status buffer to a value never used to compare against\n\n        memset(*cf_lut_status, -1, sizeof(**cf_lut_status) * LUT_BUFF);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 18257, "_split": "valid", "_hash": "f4f0ef4079a114af255b5c667744e66d"}
{"project": "FFmpeg", "commit_id": "6df2c94130b026930d1f7148699925dcaa08759c", "target": 0, "func": "static void yuv_from_cqt(ColorFloat *c, const FFTComplex *v, float gamma, int len)\n\n{\n\n    int x;\n\n    for (x = 0; x < len; x++) {\n\n        float r, g, b;\n\n        r = calculate_gamma(FFMIN(1.0f, v[x].re), gamma);\n\n        g = calculate_gamma(FFMIN(1.0f, 0.5f * (v[x].re + v[x].im)), gamma);\n\n        b = calculate_gamma(FFMIN(1.0f, v[x].im), gamma);\n\n        c[x].yuv.y = 16.0f + 65.481f * r + 128.553f * g + 24.966f * b;\n\n        c[x].yuv.u = 128.0f - 37.797f * r - 74.203f * g + 112.0f * b;\n\n        c[x].yuv.v = 128.0f + 112.0f * r - 93.786f * g - 18.214 * b;\n\n    }\n\n}\n", "idx": 18366, "_split": "valid", "_hash": "98a1ec130ecb23929640765c8d5c0c33"}
{"project": "FFmpeg", "commit_id": "8b9457deab98959ece4ab5b68c89b7557e2b872a", "target": 1, "func": "static int rtsp_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    int ret;\n\n    RTSPMessageHeader reply1, *reply = &reply1;\n\n    char cmd[1024];\n\n\n\n    if (rt->server_type == RTSP_SERVER_REAL) {\n\n        int i;\n\n        enum AVDiscard cache[MAX_STREAMS];\n\n\n\n        for (i = 0; i < s->nb_streams; i++)\n\n            cache[i] = s->streams[i]->discard;\n\n\n\n        if (!rt->need_subscription) {\n\n            if (memcmp (cache, rt->real_setup_cache,\n\n                        sizeof(enum AVDiscard) * s->nb_streams)) {\n\n                av_strlcatf(cmd, sizeof(cmd),\n\n                            \"SET_PARAMETER %s RTSP/1.0\\r\\n\"\n\n                            \"Unsubscribe: %s\\r\\n\",\n\n                            s->filename, rt->last_subscription);\n\n                rtsp_send_cmd(s, cmd, reply, NULL);\n\n                if (reply->status_code != RTSP_STATUS_OK)\n\n                    return AVERROR_INVALIDDATA;\n\n                rt->need_subscription = 1;\n\n            }\n\n        }\n\n\n\n        if (rt->need_subscription) {\n\n            int r, rule_nr, first = 1;\n\n\n\n            memcpy(rt->real_setup_cache, cache,\n\n                   sizeof(enum AVDiscard) * s->nb_streams);\n\n            rt->last_subscription[0] = 0;\n\n\n\n            snprintf(cmd, sizeof(cmd),\n\n                     \"SET_PARAMETER %s RTSP/1.0\\r\\n\"\n\n                     \"Subscribe: \",\n\n                     s->filename);\n\n            for (i = 0; i < rt->nb_rtsp_streams; i++) {\n\n                rule_nr = 0;\n\n                for (r = 0; r < s->nb_streams; r++) {\n\n                    if (s->streams[r]->priv_data == rt->rtsp_streams[i]) {\n\n                        if (s->streams[r]->discard != AVDISCARD_ALL) {\n\n                            if (!first)\n\n                                av_strlcat(rt->last_subscription, \",\",\n\n                                           sizeof(rt->last_subscription));\n\n                            ff_rdt_subscribe_rule(\n\n                                rt->last_subscription,\n\n                                sizeof(rt->last_subscription), i, rule_nr);\n\n                            first = 0;\n\n                        }\n\n                        rule_nr++;\n\n                    }\n\n                }\n\n            }\n\n            av_strlcatf(cmd, sizeof(cmd), \"%s\\r\\n\", rt->last_subscription);\n\n            rtsp_send_cmd(s, cmd, reply, NULL);\n\n            if (reply->status_code != RTSP_STATUS_OK)\n\n                return AVERROR_INVALIDDATA;\n\n            rt->need_subscription = 0;\n\n\n\n            if (rt->state == RTSP_STATE_PLAYING)\n\n                rtsp_read_play (s);\n\n        }\n\n    }\n\n\n\n    ret = rtsp_fetch_packet(s, pkt);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* send dummy request to keep TCP connection alive */\n\n    if ((rt->server_type == RTSP_SERVER_WMS ||\n\n         rt->server_type == RTSP_SERVER_REAL) &&\n\n        (av_gettime() - rt->last_cmd_time) / 1000000 >= rt->timeout / 2) {\n\n        if (rt->server_type == RTSP_SERVER_WMS) {\n\n            snprintf(cmd, sizeof(cmd) - 1,\n\n                     \"GET_PARAMETER %s RTSP/1.0\\r\\n\",\n\n                     s->filename);\n\n            rtsp_send_cmd_async(s, cmd, reply, NULL);\n\n        } else {\n\n            rtsp_send_cmd_async(s, \"OPTIONS * RTSP/1.0\\r\\n\",\n\n                                reply, NULL);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 18405, "_split": "valid", "_hash": "537af00789829e71a17f40b73d0dba23"}
{"project": "FFmpeg", "commit_id": "d4f7d8386693beb987382ece8bb7499955620388", "target": 0, "func": "static int split_field_half_ref_list(Picture *dest, int dest_len,\n\n                                     Picture *src,  int src_len,  int parity){\n\n    int same_parity   = 1;\n\n    int same_i        = 0;\n\n    int opp_i         = 0;\n\n    int out_i;\n\n    int field_output;\n\n\n\n    for (out_i = 0; out_i < dest_len; out_i += field_output) {\n\n        if (same_parity && same_i < src_len) {\n\n            field_output = split_field_copy(dest + out_i, src + same_i,\n\n                                            parity, 1);\n\n            same_parity = !field_output;\n\n            same_i++;\n\n\n\n        } else if (opp_i < src_len) {\n\n            field_output = split_field_copy(dest + out_i, src + opp_i,\n\n                                            PICT_FRAME - parity, 0);\n\n            same_parity = field_output;\n\n            opp_i++;\n\n\n\n        } else {\n\n            break;\n\n        }\n\n    }\n\n\n\n    return out_i;\n\n}\n", "idx": 18419, "_split": "valid", "_hash": "b4fe4910916450fc59e7cb038dc6100e"}
{"project": "FFmpeg", "commit_id": "f92f4935acd7d974adfd1deebdf1bb06cbe107ca", "target": 1, "func": "static void count_usage(uint8_t *src, int width,\n\n                        int height, uint32_t *counts)\n\n{\n\n    int i, j;\n\n\n\n    for (j = 0; j < height; j++) {\n\n        for (i = 0; i < width; i++) {\n\n            counts[src[i]]++;\n\n        }\n\n        src += width;\n\n    }\n\n}\n", "idx": 18427, "_split": "valid", "_hash": "7435eb787b98980e2e06756b137cf770"}
{"project": "FFmpeg", "commit_id": "c82bf15dca00f67a701d126e47ea9075fc9459cb", "target": 1, "func": "void ff_rtp_send_hevc(AVFormatContext *ctx, const uint8_t *frame_buf, int frame_size)\n\n{\n\n    const uint8_t *next_NAL_unit;\n\n    const uint8_t *buf_ptr, *buf_end = frame_buf + frame_size;\n\n    RTPMuxContext *rtp_ctx = ctx->priv_data;\n\n\n\n    /* use the default 90 KHz time stamp */\n\n    rtp_ctx->timestamp = rtp_ctx->cur_timestamp;\n\n    rtp_ctx->buf_ptr   = rtp_ctx->buf;\n\n\n\n    if (rtp_ctx->nal_length_size)\n\n        buf_ptr = ff_avc_mp4_find_startcode(frame_buf, buf_end, rtp_ctx->nal_length_size) ? frame_buf : buf_end;\n\n    else\n\n        buf_ptr = ff_avc_find_startcode(frame_buf, buf_end);\n\n\n\n    /* find all NAL units and send them as separate packets */\n\n    while (buf_ptr < buf_end) {\n\n        if (rtp_ctx->nal_length_size) {\n\n            next_NAL_unit = ff_avc_mp4_find_startcode(buf_ptr, buf_end, rtp_ctx->nal_length_size);\n\n            if (!next_NAL_unit)\n\n                next_NAL_unit = buf_end;\n\n\n\n            buf_ptr += rtp_ctx->nal_length_size;\n\n        } else {\n\n            while (!*(buf_ptr++))\n\n                ;\n\n            next_NAL_unit = ff_avc_find_startcode(buf_ptr, buf_end);\n\n        }\n\n        /* send the next NAL unit */\n\n        nal_send(ctx, buf_ptr, next_NAL_unit - buf_ptr, next_NAL_unit == buf_end);\n\n\n\n        /* jump to the next NAL unit */\n\n        buf_ptr = next_NAL_unit;\n\n    }\n\n    flush_buffered(ctx, 1);\n\n}\n", "idx": 18451, "_split": "valid", "_hash": "5faaafee67d82a40e84247ef76c72bef"}
{"project": "FFmpeg", "commit_id": "41b68dce4d148b6a227d001b32deb275c01aa550", "target": 0, "func": "static inline int dc1394_read_common(AVFormatContext *c, AVFormatParameters *ap,\n\n                                     struct dc1394_frame_format **select_fmt, struct dc1394_frame_rate **select_fps)\n\n{\n\n    dc1394_data* dc1394 = c->priv_data;\n\n    AVStream* vst;\n\n    struct dc1394_frame_format *fmt;\n\n    struct dc1394_frame_rate *fps;\n\n    enum PixelFormat pix_fmt;\n\n    int width, height;\n\n    AVRational framerate;\n\n    int ret = 0;\n\n\n\n    if ((pix_fmt = av_get_pix_fmt(dc1394->pixel_format)) == PIX_FMT_NONE) {\n\n        av_log(c, AV_LOG_ERROR, \"No such pixel format: %s.\\n\", dc1394->pixel_format);\n\n        ret = AVERROR(EINVAL);\n\n        goto out;\n\n    }\n\n\n\n    if ((ret = av_parse_video_size(&width, &height, dc1394->video_size)) < 0) {\n\n        av_log(c, AV_LOG_ERROR, \"Couldn't parse video size.\\n\");\n\n        goto out;\n\n    }\n\n    if ((ret = av_parse_video_rate(&framerate, dc1394->framerate)) < 0) {\n\n        av_log(c, AV_LOG_ERROR, \"Couldn't parse framerate.\\n\");\n\n        goto out;\n\n    }\n\n#if FF_API_FORMAT_PARAMETERS\n\n    if (ap->width > 0)\n\n        width = ap->width;\n\n    if (ap->height > 0)\n\n        height = ap->height;\n\n    if (ap->pix_fmt)\n\n        pix_fmt = ap->pix_fmt;\n\n    if (ap->time_base.num)\n\n        framerate = (AVRational){ap->time_base.den, ap->time_base.num};\n\n#endif\n\n    dc1394->frame_rate = av_rescale(1000, framerate.num, framerate.den);\n\n\n\n    for (fmt = dc1394_frame_formats; fmt->width; fmt++)\n\n         if (fmt->pix_fmt == pix_fmt && fmt->width == width && fmt->height == height)\n\n             break;\n\n\n\n    for (fps = dc1394_frame_rates; fps->frame_rate; fps++)\n\n         if (fps->frame_rate == dc1394->frame_rate)\n\n             break;\n\n\n\n    if (!fps->frame_rate || !fmt->width) {\n\n        av_log(c, AV_LOG_ERROR, \"Can't find matching camera format for %s, %dx%d@%d:1000fps\\n\", av_get_pix_fmt_name(pix_fmt),\n\n                                                                                                width, height, dc1394->frame_rate);\n\n        ret = AVERROR(EINVAL);\n\n        goto out;\n\n    }\n\n\n\n    /* create a video stream */\n\n    vst = av_new_stream(c, 0);\n\n    if (!vst) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto out;\n\n    }\n\n    av_set_pts_info(vst, 64, 1, 1000);\n\n    vst->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    vst->codec->codec_id = CODEC_ID_RAWVIDEO;\n\n    vst->codec->time_base.den = framerate.num;\n\n    vst->codec->time_base.num = framerate.den;\n\n    vst->codec->width = fmt->width;\n\n    vst->codec->height = fmt->height;\n\n    vst->codec->pix_fmt = fmt->pix_fmt;\n\n\n\n    /* packet init */\n\n    av_init_packet(&dc1394->packet);\n\n    dc1394->packet.size = avpicture_get_size(fmt->pix_fmt, fmt->width, fmt->height);\n\n    dc1394->packet.stream_index = vst->index;\n\n    dc1394->packet.flags |= AV_PKT_FLAG_KEY;\n\n\n\n    dc1394->current_frame = 0;\n\n\n\n    vst->codec->bit_rate = av_rescale(dc1394->packet.size * 8, fps->frame_rate, 1000);\n\n    *select_fps = fps;\n\n    *select_fmt = fmt;\n\nout:\n\n    return ret;\n\n}\n", "idx": 18464, "_split": "valid", "_hash": "549ff8fdacdf1f834d1aa3434dea6b12"}
{"project": "FFmpeg", "commit_id": "c9454cb643f5404ca8f4f02e1384c863136f7a9e", "target": 1, "func": "int av_tempfile(const char *prefix, char **filename, int log_offset, void *log_ctx) {\n\n    FileLogContext file_log_ctx = { &file_log_ctx_class, log_offset, log_ctx };\n\n    int fd=-1;\n\n#if !HAVE_MKSTEMP\n\n    void *ptr= tempnam(NULL, prefix);\n\n    if(!ptr)\n\n        ptr= tempnam(\".\", prefix);\n\n    *filename = av_strdup(ptr);\n\n#undef free\n\n    free(ptr);\n\n#else\n\n    size_t len = strlen(prefix) + 12; /* room for \"/tmp/\" and \"XXXXXX\\0\" */\n\n    *filename = av_malloc(len);\n\n#endif\n\n    /* -----common section-----*/\n\n    if (*filename == NULL) {\n\n        av_log(&file_log_ctx, AV_LOG_ERROR, \"ff_tempfile: Cannot allocate file name\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n#if !HAVE_MKSTEMP\n\n#   ifndef O_BINARY\n\n#       define O_BINARY 0\n\n#   endif\n\n#   ifndef O_EXCL\n\n#       define O_EXCL 0\n\n#   endif\n\n    fd = open(*filename, O_RDWR | O_BINARY | O_CREAT | O_EXCL, 0600);\n\n#else\n\n    snprintf(*filename, len, \"/tmp/%sXXXXXX\", prefix);\n\n    fd = mkstemp(*filename);\n\n#ifdef _WIN32\n\n    if (fd < 0) {\n\n        snprintf(*filename, len, \"./%sXXXXXX\", prefix);\n\n        fd = mkstemp(*filename);\n\n    }\n\n#endif\n\n#endif\n\n    /* -----common section-----*/\n\n    if (fd < 0) {\n\n        int err = AVERROR(errno);\n\n        av_log(&file_log_ctx, AV_LOG_ERROR, \"ff_tempfile: Cannot open temporary file %s\\n\", *filename);\n\n\n        return err;\n\n    }\n\n    return fd; /* success */\n\n}", "idx": 18472, "_split": "valid", "_hash": "ffc3aecad633fd06c416f2c4d041c0f0"}
{"project": "FFmpeg", "commit_id": "06599638dd678c9939df0fd83ff693c43b25971d", "target": 0, "func": "static int decode_frame_header(NUTContext *nut, int *flags_ret, int64_t *pts, int *stream_id, int frame_code){\n\n    AVFormatContext *s= nut->avf;\n\n    ByteIOContext *bc = &s->pb;\n\n    StreamContext *stc;\n\n    int size, flags, size_mul, pts_delta, i, reserved_count;\n\n    uint64_t tmp;\n\n\n\n    if(url_ftell(bc) > nut->last_syncpoint_pos + nut->max_distance){\n\n        av_log(s, AV_LOG_ERROR, \"last frame must have been damaged %Ld > %Ld + %d\\n\", url_ftell(bc), nut->last_syncpoint_pos, nut->max_distance);\n\n        return -1;\n\n    }\n\n\n\n    flags          = nut->frame_code[frame_code].flags;\n\n    size_mul       = nut->frame_code[frame_code].size_mul;\n\n    size           = nut->frame_code[frame_code].size_lsb;\n\n    *stream_id     = nut->frame_code[frame_code].stream_id;\n\n    pts_delta      = nut->frame_code[frame_code].pts_delta;\n\n    reserved_count = nut->frame_code[frame_code].reserved_count;\n\n\n\n    if(flags & FLAG_INVALID)\n\n        return -1;\n\n    if(flags & FLAG_CODED)\n\n        flags ^= get_v(bc);\n\n    if(flags & FLAG_STREAM_ID){\n\n        GET_V(*stream_id, tmp < s->nb_streams)\n\n    }\n\n    stc= &nut->stream[*stream_id];\n\n    if(flags&FLAG_CODED_PTS){\n\n        int coded_pts= get_v(bc);\n\n//FIXME check last_pts validity?\n\n        if(coded_pts < (1<<stc->msb_pts_shift)){\n\n            *pts=lsb2full(stc, coded_pts);\n\n        }else\n\n            *pts=coded_pts - (1<<stc->msb_pts_shift);\n\n    }else\n\n        *pts= stc->last_pts + pts_delta;\n\n    if(flags&FLAG_SIZE_MSB){\n\n        size += size_mul*get_v(bc);\n\n    }\n\n    if(flags&FLAG_RESERVED)\n\n        reserved_count= get_v(bc);\n\n    for(i=0; i<reserved_count; i++)\n\n        get_v(bc);\n\n    if(flags&FLAG_CHECKSUM){\n\n        get_be32(bc); //FIXME check this\n\n    }else if(size > 2*nut->max_distance){\n\n        av_log(s, AV_LOG_ERROR, \"frame size > 2max_distance and no checksum\\n\");\n\n        return -1;\n\n    }\n\n    *flags_ret= flags;\n\n\n\n    stc->last_pts= *pts;\n\n    stc->last_key_frame= flags&FLAG_KEY; //FIXME change to last flags\n\n\n\n    return size;\n\n}\n", "idx": 18501, "_split": "valid", "_hash": "b7b19543655f908c02f8603bba13f7b0"}
{"project": "FFmpeg", "commit_id": "358078d9bb89d6266e274720eba8582ec7b1c6b7", "target": 0, "func": "static av_cold int alac_encode_init(AVCodecContext *avctx)\n\n{\n\n    AlacEncodeContext *s = avctx->priv_data;\n\n    int ret;\n\n    uint8_t *alac_extradata;\n\n\n\n    avctx->frame_size = s->frame_size = DEFAULT_FRAME_SIZE;\n\n\n\n    if (avctx->sample_fmt != AV_SAMPLE_FMT_S16) {\n\n        av_log(avctx, AV_LOG_ERROR, \"only pcm_s16 input samples are supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* TODO: Correctly implement multi-channel ALAC.\n\n             It is similar to multi-channel AAC, in that it has a series of\n\n             single-channel (SCE), channel-pair (CPE), and LFE elements. */\n\n    if (avctx->channels > 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"only mono or stereo input is currently supported\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    // Set default compression level\n\n    if (avctx->compression_level == FF_COMPRESSION_DEFAULT)\n\n        s->compression_level = 2;\n\n    else\n\n        s->compression_level = av_clip(avctx->compression_level, 0, 2);\n\n\n\n    // Initialize default Rice parameters\n\n    s->rc.history_mult    = 40;\n\n    s->rc.initial_history = 10;\n\n    s->rc.k_modifier      = 14;\n\n    s->rc.rice_modifier   = 4;\n\n\n\n    s->max_coded_frame_size = get_max_frame_size(avctx->frame_size,\n\n                                                 avctx->channels,\n\n                                                 DEFAULT_SAMPLE_SIZE);\n\n\n\n    // FIXME: consider wasted_bytes\n\n    s->write_sample_size  = DEFAULT_SAMPLE_SIZE + avctx->channels - 1;\n\n\n\n    avctx->extradata = av_mallocz(ALAC_EXTRADATA_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!avctx->extradata) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto error;\n\n    }\n\n    avctx->extradata_size = ALAC_EXTRADATA_SIZE;\n\n\n\n    alac_extradata = avctx->extradata;\n\n    AV_WB32(alac_extradata,    ALAC_EXTRADATA_SIZE);\n\n    AV_WB32(alac_extradata+4,  MKBETAG('a','l','a','c'));\n\n    AV_WB32(alac_extradata+12, avctx->frame_size);\n\n    AV_WB8 (alac_extradata+17, DEFAULT_SAMPLE_SIZE);\n\n    AV_WB8 (alac_extradata+21, avctx->channels);\n\n    AV_WB32(alac_extradata+24, s->max_coded_frame_size);\n\n    AV_WB32(alac_extradata+28,\n\n            avctx->sample_rate * avctx->channels * DEFAULT_SAMPLE_SIZE); // average bitrate\n\n    AV_WB32(alac_extradata+32, avctx->sample_rate);\n\n\n\n    // Set relevant extradata fields\n\n    if (s->compression_level > 0) {\n\n        AV_WB8(alac_extradata+18, s->rc.history_mult);\n\n        AV_WB8(alac_extradata+19, s->rc.initial_history);\n\n        AV_WB8(alac_extradata+20, s->rc.k_modifier);\n\n    }\n\n\n\n    s->min_prediction_order = DEFAULT_MIN_PRED_ORDER;\n\n    if (avctx->min_prediction_order >= 0) {\n\n        if (avctx->min_prediction_order < MIN_LPC_ORDER ||\n\n           avctx->min_prediction_order > ALAC_MAX_LPC_ORDER) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid min prediction order: %d\\n\",\n\n                   avctx->min_prediction_order);\n\n            ret = AVERROR(EINVAL);\n\n            goto error;\n\n        }\n\n\n\n        s->min_prediction_order = avctx->min_prediction_order;\n\n    }\n\n\n\n    s->max_prediction_order = DEFAULT_MAX_PRED_ORDER;\n\n    if (avctx->max_prediction_order >= 0) {\n\n        if (avctx->max_prediction_order < MIN_LPC_ORDER ||\n\n            avctx->max_prediction_order > ALAC_MAX_LPC_ORDER) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid max prediction order: %d\\n\",\n\n                   avctx->max_prediction_order);\n\n            ret = AVERROR(EINVAL);\n\n            goto error;\n\n        }\n\n\n\n        s->max_prediction_order = avctx->max_prediction_order;\n\n    }\n\n\n\n    if (s->max_prediction_order < s->min_prediction_order) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"invalid prediction orders: min=%d max=%d\\n\",\n\n               s->min_prediction_order, s->max_prediction_order);\n\n        ret = AVERROR(EINVAL);\n\n        goto error;\n\n    }\n\n\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n    if (!avctx->coded_frame) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto error;\n\n    }\n\n\n\n    s->avctx = avctx;\n\n\n\n    if ((ret = ff_lpc_init(&s->lpc_ctx, avctx->frame_size,\n\n                           s->max_prediction_order,\n\n                           FF_LPC_TYPE_LEVINSON)) < 0) {\n\n        goto error;\n\n    }\n\n\n\n    return 0;\n\nerror:\n\n    alac_encode_close(avctx);\n\n    return ret;\n\n}\n", "idx": 18503, "_split": "valid", "_hash": "86d6cc40990e1d598534347c741365c5"}
{"project": "FFmpeg", "commit_id": "24f6559bd2417b30c848d27523c88949d537a83c", "target": 1, "func": "static int rv34_decode_mv(RV34DecContext *r, int block_type)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int i, j, k, l;\n\n    int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride;\n\n    int next_bt;\n\n\n\n    memset(r->dmv, 0, sizeof(r->dmv));\n\n    for(i = 0; i < num_mvs[block_type]; i++){\n\n        r->dmv[i][0] = get_interleaved_se_golomb(gb);\n\n        r->dmv[i][1] = get_interleaved_se_golomb(gb);\n\n\n\n\n\n\n\n    switch(block_type){\n\n    case RV34_MB_TYPE_INTRA:\n\n    case RV34_MB_TYPE_INTRA16x16:\n\n        ZERO8x2(s->current_picture_ptr->motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n        return 0;\n\n    case RV34_MB_SKIP:\n\n        if(s->pict_type == AV_PICTURE_TYPE_P){\n\n            ZERO8x2(s->current_picture_ptr->motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n            rv34_mc_1mv (r, block_type, 0, 0, 0, 2, 2, 0);\n\n            break;\n\n\n    case RV34_MB_B_DIRECT:\n\n        //surprisingly, it uses motion scheme from next reference frame\n\n        /* wait for the current mb row to be finished */\n\n        if (HAVE_THREADS && (s->avctx->active_thread_type & FF_THREAD_FRAME))\n\n            ff_thread_await_progress(&s->next_picture_ptr->tf, FFMAX(0, s->mb_y-1), 0);\n\n\n\n        next_bt = s->next_picture_ptr->mb_type[s->mb_x + s->mb_y * s->mb_stride];\n\n        if(IS_INTRA(next_bt) || IS_SKIP(next_bt)){\n\n            ZERO8x2(s->current_picture_ptr->motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n            ZERO8x2(s->current_picture_ptr->motion_val[1][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n        }else\n\n            for(j = 0; j < 2; j++)\n\n                for(i = 0; i < 2; i++)\n\n                    for(k = 0; k < 2; k++)\n\n                        for(l = 0; l < 2; l++)\n\n                            s->current_picture_ptr->motion_val[l][mv_pos + i + j*s->b8_stride][k] = calc_add_mv(r, l, s->next_picture_ptr->motion_val[0][mv_pos + i + j*s->b8_stride][k]);\n\n        if(!(IS_16X8(next_bt) || IS_8X16(next_bt) || IS_8X8(next_bt))) //we can use whole macroblock MC\n\n            rv34_mc_2mv(r, block_type);\n\n        else\n\n            rv34_mc_2mv_skip(r);\n\n        ZERO8x2(s->current_picture_ptr->motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n        break;\n\n    case RV34_MB_P_16x16:\n\n    case RV34_MB_P_MIX16x16:\n\n        rv34_pred_mv(r, block_type, 0, 0);\n\n        rv34_mc_1mv (r, block_type, 0, 0, 0, 2, 2, 0);\n\n        break;\n\n    case RV34_MB_B_FORWARD:\n\n    case RV34_MB_B_BACKWARD:\n\n        r->dmv[1][0] = r->dmv[0][0];\n\n        r->dmv[1][1] = r->dmv[0][1];\n\n        if(r->rv30)\n\n            rv34_pred_mv_rv3(r, block_type, block_type == RV34_MB_B_BACKWARD);\n\n        else\n\n            rv34_pred_mv_b  (r, block_type, block_type == RV34_MB_B_BACKWARD);\n\n        rv34_mc_1mv     (r, block_type, 0, 0, 0, 2, 2, block_type == RV34_MB_B_BACKWARD);\n\n        break;\n\n    case RV34_MB_P_16x8:\n\n    case RV34_MB_P_8x16:\n\n        rv34_pred_mv(r, block_type, 0, 0);\n\n        rv34_pred_mv(r, block_type, 1 + (block_type == RV34_MB_P_16x8), 1);\n\n        if(block_type == RV34_MB_P_16x8){\n\n            rv34_mc_1mv(r, block_type, 0, 0, 0,            2, 1, 0);\n\n            rv34_mc_1mv(r, block_type, 0, 8, s->b8_stride, 2, 1, 0);\n\n\n        if(block_type == RV34_MB_P_8x16){\n\n            rv34_mc_1mv(r, block_type, 0, 0, 0, 1, 2, 0);\n\n            rv34_mc_1mv(r, block_type, 8, 0, 1, 1, 2, 0);\n\n\n        break;\n\n    case RV34_MB_B_BIDIR:\n\n        rv34_pred_mv_b  (r, block_type, 0);\n\n        rv34_pred_mv_b  (r, block_type, 1);\n\n        rv34_mc_2mv     (r, block_type);\n\n        break;\n\n    case RV34_MB_P_8x8:\n\n        for(i=0;i< 4;i++){\n\n            rv34_pred_mv(r, block_type, i, i);\n\n            rv34_mc_1mv (r, block_type, (i&1)<<3, (i&2)<<2, (i&1)+(i>>1)*s->b8_stride, 1, 1, 0);\n\n\n        break;\n\n\n\n\n    return 0;\n", "idx": 18524, "_split": "valid", "_hash": "0a6ddeee41447493193a4ff82c7ccf8c"}
{"project": "FFmpeg", "commit_id": "3a8c95f730732b9f1ffacdbfbf79a01b202a67af", "target": 0, "func": "static void print_format_entry(const char *tag,\n\n                               const char *val)\n\n{\n\n    if (!fmt_entries_to_show) {\n\n        if (tag) {\n\n            printf(\"%s=%s\\n\", tag, val);\n\n        } else {\n\n            printf(\"%s\\n\", val);\n\n        }\n\n    } else if (tag && av_dict_get(fmt_entries_to_show, tag, NULL, 0)) {\n\n        if (nb_fmt_entries_to_show > 1)\n\n            printf(\"%s=\", tag);\n\n        printf(\"%s\\n\", val);\n\n    }\n\n}\n", "idx": 18541, "_split": "valid", "_hash": "59820a136fb1f501223a8d57c23b80a4"}
{"project": "FFmpeg", "commit_id": "6f1ccca4ae3b93b6a2a820a7a0e72081ab35767c", "target": 0, "func": "static int dnxhd_decode_dct_block_8(const DNXHDContext *ctx,\n\n                                    RowContext *row, int n)\n\n{\n\n    return dnxhd_decode_dct_block(ctx, row, n, 4, 32, 6);\n\n}\n", "idx": 18543, "_split": "valid", "_hash": "3a80c77c176ff7deb018b86e9ec5883b"}
{"project": "FFmpeg", "commit_id": "d7b542ae294aaf818f2a00c5606e009cf931e77c", "target": 1, "func": "static int ogg_packet(AVFormatContext *s, int *str, int *dstart, int *dsize,\n\n                      int64_t *fpos)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    int idx, i, ret;\n\n    struct ogg_stream *os;\n\n    int complete = 0;\n\n    int segp = 0, psize = 0;\n\n\n\n    av_dlog(s, \"ogg_packet: curidx=%i\\n\", ogg->curidx);\n\n\n\n    do{\n\n        idx = ogg->curidx;\n\n\n\n        while (idx < 0){\n\n            ret = ogg_read_page(s, &idx);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n\n\n        os = ogg->streams + idx;\n\n\n\n        av_dlog(s, \"ogg_packet: idx=%d pstart=%d psize=%d segp=%d nsegs=%d\\n\",\n\n                idx, os->pstart, os->psize, os->segp, os->nsegs);\n\n\n\n        if (!os->codec){\n\n            if (os->header < 0){\n\n                os->codec = ogg_find_codec (os->buf, os->bufpos);\n\n                if (!os->codec){\n\n                    av_log(s, AV_LOG_WARNING, \"Codec not found\\n\");\n\n                    os->header = 0;\n\n                    return 0;\n\n                }\n\n            }else{\n\n                return 0;\n\n            }\n\n        }\n\n\n\n        segp = os->segp;\n\n        psize = os->psize;\n\n\n\n        while (os->segp < os->nsegs){\n\n            int ss = os->segments[os->segp++];\n\n            os->psize += ss;\n\n            if (ss < 255){\n\n                complete = 1;\n\n                break;\n\n            }\n\n        }\n\n\n\n        if (!complete && os->segp == os->nsegs){\n\n            ogg->curidx = -1;\n\n            os->incomplete = 1;\n\n        }\n\n    }while (!complete);\n\n\n\n\n\n    if (os->granule == -1)\n\n        av_log(s, AV_LOG_WARNING, \"Page at %\"PRId64\" is missing granule\\n\", os->page_pos);\n\n\n\n    ogg->curidx = idx;\n\n    os->incomplete = 0;\n\n\n\n    if (os->header) {\n\n        os->header = os->codec->header (s, idx);\n\n        if (!os->header){\n\n            os->segp = segp;\n\n            os->psize = psize;\n\n\n\n            // We have reached the first non-header packet in this stream.\n\n            // Unfortunately more header packets may still follow for others,\n\n            // but if we continue with header parsing we may lose data packets.\n\n            ogg->headers = 1;\n\n\n\n            // Update the header state for all streams and\n\n            // compute the data_offset.\n\n            if (!s->data_offset)\n\n                s->data_offset = os->sync_pos;\n\n            for (i = 0; i < ogg->nstreams; i++) {\n\n                struct ogg_stream *cur_os = ogg->streams + i;\n\n\n\n                // if we have a partial non-header packet, its start is\n\n                // obviously at or after the data start\n\n                if (cur_os->incomplete)\n\n                    s->data_offset = FFMIN(s->data_offset, cur_os->sync_pos);\n\n            }\n\n        }else{\n\n            os->pstart += os->psize;\n\n            os->psize = 0;\n\n        }\n\n    } else {\n\n        os->pflags = 0;\n\n        os->pduration = 0;\n\n        if (os->codec && os->codec->packet)\n\n            os->codec->packet (s, idx);\n\n        if (str)\n\n            *str = idx;\n\n        if (dstart)\n\n            *dstart = os->pstart;\n\n        if (dsize)\n\n            *dsize = os->psize;\n\n        if (fpos)\n\n            *fpos = os->sync_pos;\n\n        os->pstart += os->psize;\n\n        os->psize = 0;\n\n        if(os->pstart == os->bufpos)\n\n            os->bufpos = os->pstart = 0;\n\n        os->sync_pos = os->page_pos;\n\n    }\n\n\n\n    // determine whether there are more complete packets in this page\n\n    // if not, the page's granule will apply to this packet\n\n    os->page_end = 1;\n\n    for (i = os->segp; i < os->nsegs; i++)\n\n        if (os->segments[i] < 255) {\n\n            os->page_end = 0;\n\n            break;\n\n        }\n\n\n\n    if (os->segp == os->nsegs)\n\n        ogg->curidx = -1;\n\n\n\n    return 0;\n\n}\n", "idx": 18560, "_split": "valid", "_hash": "7b74e428f24fb6636668c9c19e48da4e"}
{"project": "FFmpeg", "commit_id": "8d9c9775b248b0a0f43bd96a242b5311fcc28b72", "target": 0, "func": "void av_log_default_callback(void* ptr, int level, const char* fmt, va_list vl)\n\n{\n\n    static int print_prefix = 1;\n\n    static int count;\n\n    static char prev[LINE_SZ];\n\n    AVBPrint part[4];\n\n    char line[LINE_SZ];\n\n    static int is_atty;\n\n    int type[2];\n\n    unsigned tint = 0;\n\n\n\n    if (level >= 0) {\n\n        tint = level & 0xff00;\n\n        level &= 0xff;\n\n    }\n\n\n\n    if (level > av_log_level)\n\n        return;\n\n#if HAVE_PTHREADS\n\n    pthread_mutex_lock(&mutex);\n\n#endif\n\n\n\n    format_line(ptr, level, fmt, vl, part, &print_prefix, type);\n\n    snprintf(line, sizeof(line), \"%s%s%s%s\", part[0].str, part[1].str, part[2].str, part[3].str);\n\n\n\n#if HAVE_ISATTY\n\n    if (!is_atty)\n\n        is_atty = isatty(2) ? 1 : -1;\n\n#endif\n\n\n\n    if (print_prefix && (flags & AV_LOG_SKIP_REPEATED) && !strcmp(line, prev) &&\n\n        *line && line[strlen(line) - 1] != '\\r'){\n\n        count++;\n\n        if (is_atty == 1)\n\n            fprintf(stderr, \"    Last message repeated %d times\\r\", count);\n\n        goto end;\n\n    }\n\n    if (count > 0) {\n\n        fprintf(stderr, \"    Last message repeated %d times\\n\", count);\n\n        count = 0;\n\n    }\n\n    strcpy(prev, line);\n\n    sanitize(part[0].str);\n\n    colored_fputs(type[0], 0, part[0].str);\n\n    sanitize(part[1].str);\n\n    colored_fputs(type[1], 0, part[1].str);\n\n    sanitize(part[2].str);\n\n    colored_fputs(av_clip(level >> 3, 0, NB_LEVELS - 1), tint >> 8, part[2].str);\n\n    sanitize(part[3].str);\n\n    colored_fputs(av_clip(level >> 3, 0, NB_LEVELS - 1), tint >> 8, part[3].str);\n\n\n\n#if CONFIG_VALGRIND_BACKTRACE\n\n    if (level <= BACKTRACE_LOGLEVEL)\n\n        VALGRIND_PRINTF_BACKTRACE(\"%s\", \"\");\n\n#endif\n\nend:\n\n    av_bprint_finalize(part+3, NULL);\n\n#if HAVE_PTHREADS\n\n    pthread_mutex_unlock(&mutex);\n\n#endif\n\n}\n", "idx": 18580, "_split": "valid", "_hash": "368f643416e8baf9c1d5f61ab02e0ed0"}
{"project": "FFmpeg", "commit_id": "8b263331c5ebbb10b6ea521e9fd56751ba94254b", "target": 0, "func": "int ff_parse_mpeg2_descriptor(AVFormatContext *fc, AVStream *st, int stream_type,\n\n                              const uint8_t **pp, const uint8_t *desc_list_end,\n\n                              Mp4Descr *mp4_descr, int mp4_descr_count, int pid,\n\n                              MpegTSContext *ts)\n\n{\n\n    const uint8_t *desc_end;\n\n    int desc_len, desc_tag, desc_es_id;\n\n    char language[252];\n\n    int i;\n\n\n\n    desc_tag = get8(pp, desc_list_end);\n\n    if (desc_tag < 0)\n\n        return AVERROR_INVALIDDATA;\n\n    desc_len = get8(pp, desc_list_end);\n\n    if (desc_len < 0)\n\n        return AVERROR_INVALIDDATA;\n\n    desc_end = *pp + desc_len;\n\n    if (desc_end > desc_list_end)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    av_dlog(fc, \"tag: 0x%02x len=%d\\n\", desc_tag, desc_len);\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_NONE &&\n\n        stream_type == STREAM_TYPE_PRIVATE_DATA)\n\n        mpegts_find_stream_type(st, desc_tag, DESC_types);\n\n\n\n    switch (desc_tag) {\n\n    case 0x1E: /* SL descriptor */\n\n        desc_es_id = get16(pp, desc_end);\n\n        if (ts && ts->pids[pid])\n\n            ts->pids[pid]->es_id = desc_es_id;\n\n        for (i = 0; i < mp4_descr_count; i++)\n\n            if (mp4_descr[i].dec_config_descr_len &&\n\n                mp4_descr[i].es_id == desc_es_id) {\n\n                AVIOContext pb;\n\n                ffio_init_context(&pb, mp4_descr[i].dec_config_descr,\n\n                                  mp4_descr[i].dec_config_descr_len, 0,\n\n                                  NULL, NULL, NULL, NULL);\n\n                ff_mp4_read_dec_config_descr(fc, st, &pb);\n\n                if (st->codec->codec_id == AV_CODEC_ID_AAC &&\n\n                    st->codec->extradata_size > 0)\n\n                    st->need_parsing = 0;\n\n                if (st->codec->codec_id == AV_CODEC_ID_MPEG4SYSTEMS)\n\n                    mpegts_open_section_filter(ts, pid, m4sl_cb, ts, 1);\n\n            }\n\n        break;\n\n    case 0x1F: /* FMC descriptor */\n\n        get16(pp, desc_end);\n\n        if (mp4_descr_count > 0 &&\n\n            st->codec->codec_id == AV_CODEC_ID_AAC_LATM &&\n\n            mp4_descr->dec_config_descr_len && mp4_descr->es_id == pid) {\n\n            AVIOContext pb;\n\n            ffio_init_context(&pb, mp4_descr->dec_config_descr,\n\n                              mp4_descr->dec_config_descr_len, 0,\n\n                              NULL, NULL, NULL, NULL);\n\n            ff_mp4_read_dec_config_descr(fc, st, &pb);\n\n            if (st->codec->codec_id == AV_CODEC_ID_AAC &&\n\n                st->codec->extradata_size > 0)\n\n                st->need_parsing = 0;\n\n        }\n\n        break;\n\n    case 0x56: /* DVB teletext descriptor */\n\n        language[0] = get8(pp, desc_end);\n\n        language[1] = get8(pp, desc_end);\n\n        language[2] = get8(pp, desc_end);\n\n        language[3] = 0;\n\n        av_dict_set(&st->metadata, \"language\", language, 0);\n\n        break;\n\n    case 0x59: /* subtitling descriptor */\n\n        language[0] = get8(pp, desc_end);\n\n        language[1] = get8(pp, desc_end);\n\n        language[2] = get8(pp, desc_end);\n\n        language[3] = 0;\n\n        /* hearing impaired subtitles detection */\n\n        switch (get8(pp, desc_end)) {\n\n        case 0x20: /* DVB subtitles (for the hard of hearing) with no monitor aspect ratio criticality */\n\n        case 0x21: /* DVB subtitles (for the hard of hearing) for display on 4:3 aspect ratio monitor */\n\n        case 0x22: /* DVB subtitles (for the hard of hearing) for display on 16:9 aspect ratio monitor */\n\n        case 0x23: /* DVB subtitles (for the hard of hearing) for display on 2.21:1 aspect ratio monitor */\n\n        case 0x24: /* DVB subtitles (for the hard of hearing) for display on a high definition monitor */\n\n        case 0x25: /* DVB subtitles (for the hard of hearing) with plano-stereoscopic disparity for display on a high definition monitor */\n\n            st->disposition |= AV_DISPOSITION_HEARING_IMPAIRED;\n\n            break;\n\n        }\n\n        if (st->codec->extradata) {\n\n            if (st->codec->extradata_size == 4 &&\n\n                memcmp(st->codec->extradata, *pp, 4))\n\n                avpriv_request_sample(fc, \"DVB sub with multiple IDs\");\n\n        } else {\n\n            st->codec->extradata = av_malloc(4 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (st->codec->extradata) {\n\n                st->codec->extradata_size = 4;\n\n                memcpy(st->codec->extradata, *pp, 4);\n\n            }\n\n        }\n\n        *pp += 4;\n\n        av_dict_set(&st->metadata, \"language\", language, 0);\n\n        break;\n\n    case 0x0a: /* ISO 639 language descriptor */\n\n        for (i = 0; i + 4 <= desc_len; i += 4) {\n\n            language[i + 0] = get8(pp, desc_end);\n\n            language[i + 1] = get8(pp, desc_end);\n\n            language[i + 2] = get8(pp, desc_end);\n\n            language[i + 3] = ',';\n\n            switch (get8(pp, desc_end)) {\n\n            case 0x01:\n\n                st->disposition |= AV_DISPOSITION_CLEAN_EFFECTS;\n\n                break;\n\n            case 0x02:\n\n                st->disposition |= AV_DISPOSITION_HEARING_IMPAIRED;\n\n                break;\n\n            case 0x03:\n\n                st->disposition |= AV_DISPOSITION_VISUAL_IMPAIRED;\n\n                break;\n\n            }\n\n        }\n\n        if (i && language[0]) {\n\n            language[i - 1] = 0;\n\n            av_dict_set(&st->metadata, \"language\", language, 0);\n\n        }\n\n        break;\n\n    case 0x05: /* registration descriptor */\n\n        st->codec->codec_tag = bytestream_get_le32(pp);\n\n        av_dlog(fc, \"reg_desc=%.4s\\n\", (char *)&st->codec->codec_tag);\n\n        if (st->codec->codec_id == AV_CODEC_ID_NONE)\n\n            mpegts_find_stream_type(st, st->codec->codec_tag, REGD_types);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n    *pp = desc_end;\n\n    return 0;\n\n}\n", "idx": 18615, "_split": "valid", "_hash": "cc93b8870d15f2fd961af50f705786d1"}
{"project": "FFmpeg", "commit_id": "4cc896ea5f06f8b1ebcde6d876d9c5b59ef9a016", "target": 1, "func": "void av_register_output_format(AVOutputFormat *format)\n\n{\n\n    AVOutputFormat **p = last_oformat;\n\n\n\n    format->next = NULL;\n\n    while(*p || avpriv_atomic_ptr_cas((void * volatile *)p, NULL, format))\n\n        p = &(*p)->next;\n\n    last_oformat = &format->next;\n\n}\n", "idx": 18643, "_split": "valid", "_hash": "e37ad6e685ed112958556d536d9234aa"}
{"project": "FFmpeg", "commit_id": "a75a3ca429e0c0f34a60c3fbd4653f6cd3ab94d7", "target": 0, "func": "static void select_input_picture(MpegEncContext *s){\n\n    int i;\n\n\n\n    for(i=1; i<MAX_PICTURE_COUNT; i++)\n\n        s->reordered_input_picture[i-1]= s->reordered_input_picture[i];\n\n    s->reordered_input_picture[MAX_PICTURE_COUNT-1]= NULL;\n\n\n\n    /* set next picture type & ordering */\n\n    if(s->reordered_input_picture[0]==NULL && s->input_picture[0]){\n\n        if(/*s->picture_in_gop_number >= s->gop_size ||*/ s->next_picture_ptr==NULL || s->intra_only){\n\n            s->reordered_input_picture[0]= s->input_picture[0];\n\n            s->reordered_input_picture[0]->pict_type= I_TYPE;\n\n            s->reordered_input_picture[0]->coded_picture_number= s->coded_picture_number++;\n\n        }else{\n\n            int b_frames;\n\n\n\n            if(s->avctx->frame_skip_threshold || s->avctx->frame_skip_factor){\n\n                if(skip_check(s, s->input_picture[0], s->next_picture_ptr)){\n\n//av_log(NULL, AV_LOG_DEBUG, \"skip %p %Ld\\n\", s->input_picture[0]->data[0], s->input_picture[0]->pts);\n\n                \n\n                    if(s->input_picture[0]->type == FF_BUFFER_TYPE_SHARED){\n\n                        for(i=0; i<4; i++)\n\n                            s->input_picture[0]->data[i]= NULL;\n\n                        s->input_picture[0]->type= 0;            \n\n                    }else{\n\n                        assert(   s->input_picture[0]->type==FF_BUFFER_TYPE_USER \n\n                               || s->input_picture[0]->type==FF_BUFFER_TYPE_INTERNAL);\n\n            \n\n                        s->avctx->release_buffer(s->avctx, (AVFrame*)s->input_picture[0]);\n\n                    }\n\n\n\n                    goto no_output_pic;\n\n                }\n\n            }\n\n\n\n            if(s->flags&CODEC_FLAG_PASS2){\n\n                for(i=0; i<s->max_b_frames+1; i++){\n\n                    int pict_num= s->input_picture[0]->display_picture_number + i;\n\n\n\n                    if(pict_num >= s->rc_context.num_entries) \n\n                        break;\n\n                    if(!s->input_picture[i]){\n\n                        s->rc_context.entry[pict_num-1].new_pict_type = P_TYPE;\n\n                        break;\n\n                    }\n\n\n\n                    s->input_picture[i]->pict_type= \n\n                        s->rc_context.entry[pict_num].new_pict_type;\n\n                }\n\n            }\n\n\n\n            if(s->avctx->b_frame_strategy==0){\n\n                b_frames= s->max_b_frames;\n\n                while(b_frames && !s->input_picture[b_frames]) b_frames--;\n\n            }else if(s->avctx->b_frame_strategy==1){\n\n                for(i=1; i<s->max_b_frames+1; i++){\n\n                    if(s->input_picture[i] && s->input_picture[i]->b_frame_score==0){\n\n                        s->input_picture[i]->b_frame_score= \n\n                            get_intra_count(s, s->input_picture[i  ]->data[0], \n\n                                               s->input_picture[i-1]->data[0], s->linesize) + 1;\n\n                    }\n\n                }\n\n                for(i=0; i<s->max_b_frames+1; i++){\n\n                    if(s->input_picture[i]==NULL || s->input_picture[i]->b_frame_score - 1 > s->mb_num/40) break;\n\n                }\n\n                                \n\n                b_frames= FFMAX(0, i-1);\n\n                \n\n                /* reset scores */\n\n                for(i=0; i<b_frames+1; i++){\n\n                    s->input_picture[i]->b_frame_score=0;\n\n                }\n\n            }else{\n\n                av_log(s->avctx, AV_LOG_ERROR, \"illegal b frame strategy\\n\");\n\n                b_frames=0;\n\n            }\n\n\n\n            emms_c();\n\n//static int b_count=0;\n\n//b_count+= b_frames;\n\n//av_log(s->avctx, AV_LOG_DEBUG, \"b_frames: %d\\n\", b_count);\n\n\n\n            for(i= b_frames - 1; i>=0; i--){\n\n                int type= s->input_picture[i]->pict_type;\n\n                if(type && type != B_TYPE)\n\n                    b_frames= i;\n\n            }\n\n            if(s->input_picture[b_frames]->pict_type == B_TYPE && b_frames == s->max_b_frames){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"warning, too many b frames in a row\\n\");\n\n            }\n\n\n\n            if(s->picture_in_gop_number + b_frames >= s->gop_size){\n\n              if((s->flags2 & CODEC_FLAG2_STRICT_GOP) && s->gop_size > s->picture_in_gop_number){\n\n                    b_frames= s->gop_size - s->picture_in_gop_number - 1;\n\n              }else{\n\n                if(s->flags & CODEC_FLAG_CLOSED_GOP)\n\n                    b_frames=0;\n\n                s->input_picture[b_frames]->pict_type= I_TYPE;\n\n              }\n\n            }\n\n            \n\n            if(   (s->flags & CODEC_FLAG_CLOSED_GOP)\n\n               && b_frames\n\n               && s->input_picture[b_frames]->pict_type== I_TYPE)\n\n                b_frames--;\n\n\n\n            s->reordered_input_picture[0]= s->input_picture[b_frames];\n\n            if(s->reordered_input_picture[0]->pict_type != I_TYPE)\n\n                s->reordered_input_picture[0]->pict_type= P_TYPE;\n\n            s->reordered_input_picture[0]->coded_picture_number= s->coded_picture_number++;\n\n            for(i=0; i<b_frames; i++){\n\n                s->reordered_input_picture[i+1]= s->input_picture[i];\n\n                s->reordered_input_picture[i+1]->pict_type= B_TYPE;\n\n                s->reordered_input_picture[i+1]->coded_picture_number= s->coded_picture_number++;\n\n            }\n\n        }\n\n    }\n\nno_output_pic:\n\n    if(s->reordered_input_picture[0]){\n\n        s->reordered_input_picture[0]->reference= s->reordered_input_picture[0]->pict_type!=B_TYPE ? 3 : 0;\n\n\n\n        copy_picture(&s->new_picture, s->reordered_input_picture[0]);\n\n\n\n        if(s->reordered_input_picture[0]->type == FF_BUFFER_TYPE_SHARED){\n\n            // input is a shared pix, so we can't modifiy it -> alloc a new one & ensure that the shared one is reuseable\n\n        \n\n            int i= ff_find_unused_picture(s, 0);\n\n            Picture *pic= &s->picture[i];\n\n\n\n            /* mark us unused / free shared pic */\n\n            for(i=0; i<4; i++)\n\n                s->reordered_input_picture[0]->data[i]= NULL;\n\n            s->reordered_input_picture[0]->type= 0;\n\n            \n\n            pic->reference              = s->reordered_input_picture[0]->reference;\n\n            \n\n            alloc_picture(s, pic, 0);\n\n\n\n            copy_picture_attributes(s, (AVFrame*)pic, (AVFrame*)s->reordered_input_picture[0]);\n\n\n\n            s->current_picture_ptr= pic;\n\n        }else{\n\n            // input is not a shared pix -> reuse buffer for current_pix\n\n\n\n            assert(   s->reordered_input_picture[0]->type==FF_BUFFER_TYPE_USER \n\n                   || s->reordered_input_picture[0]->type==FF_BUFFER_TYPE_INTERNAL);\n\n            \n\n            s->current_picture_ptr= s->reordered_input_picture[0];\n\n            for(i=0; i<4; i++){\n\n                s->new_picture.data[i]+=16;\n\n            }\n\n        }\n\n        copy_picture(&s->current_picture, s->current_picture_ptr);\n\n    \n\n        s->picture_number= s->new_picture.display_picture_number;\n\n//printf(\"dpn:%d\\n\", s->picture_number);\n\n    }else{\n\n       memset(&s->new_picture, 0, sizeof(Picture));\n\n    }\n\n}\n", "idx": 18723, "_split": "valid", "_hash": "d07da17870178865715f009567a43eb2"}
{"project": "FFmpeg", "commit_id": "c988f97566cdf536ba0dcbc0d77d885456852060", "target": 0, "func": "static inline void xchg_mb_border(H264Context *h, uint8_t *src_y, uint8_t *src_cb, uint8_t *src_cr, int linesize, int uvlinesize, int xchg, int simple){\n\n    MpegEncContext * const s = &h->s;\n\n    int temp8, i;\n\n    uint64_t temp64;\n\n    int deblock_left;\n\n    int deblock_top;\n\n    int mb_xy;\n\n    int step    = 1;\n\n    int offset  = 1;\n\n    int uvoffset= 1;\n\n    int top_idx = 1;\n\n\n\n    if(!simple && FRAME_MBAFF){\n\n        if(s->mb_y&1){\n\n            offset  = MB_MBAFF ? 1 : 17;\n\n            uvoffset= MB_MBAFF ? 1 : 9;\n\n        }else{\n\n            offset  =\n\n            uvoffset=\n\n            top_idx = MB_MBAFF ? 0 : 1;\n\n        }\n\n        step= MB_MBAFF ? 2 : 1;\n\n    }\n\n\n\n    if(h->deblocking_filter == 2) {\n\n        mb_xy = h->mb_xy;\n\n        deblock_left = h->slice_table[mb_xy] == h->slice_table[mb_xy - 1];\n\n        deblock_top  = h->slice_table[mb_xy] == h->slice_table[h->top_mb_xy];\n\n    } else {\n\n        deblock_left = (s->mb_x > 0);\n\n        deblock_top =  (s->mb_y > !!MB_FIELD);\n\n    }\n\n\n\n    src_y  -=   linesize + 1;\n\n    src_cb -= uvlinesize + 1;\n\n    src_cr -= uvlinesize + 1;\n\n\n\n#define XCHG(a,b,t,xchg)\\\n\nt= a;\\\n\nif(xchg)\\\n\n    a= b;\\\n\nb= t;\n\n\n\n    if(deblock_left){\n\n        for(i = !deblock_top; i<16; i++){\n\n            XCHG(h->left_border[offset+i*step], src_y [i*  linesize], temp8, xchg);\n\n        }\n\n        XCHG(h->left_border[offset+i*step], src_y [i*  linesize], temp8, 1);\n\n    }\n\n\n\n    if(deblock_top){\n\n        XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+0), *(uint64_t*)(src_y +1), temp64, xchg);\n\n        XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+8), *(uint64_t*)(src_y +9), temp64, 1);\n\n        if(s->mb_x+1 < s->mb_width){\n\n            XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x+1]), *(uint64_t*)(src_y +17), temp64, 1);\n\n        }\n\n    }\n\n\n\n    if(simple || !CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n        if(deblock_left){\n\n            for(i = !deblock_top; i<8; i++){\n\n                XCHG(h->left_border[uvoffset+34   +i*step], src_cb[i*uvlinesize], temp8, xchg);\n\n                XCHG(h->left_border[uvoffset+34+18+i*step], src_cr[i*uvlinesize], temp8, xchg);\n\n            }\n\n            XCHG(h->left_border[uvoffset+34   +i*step], src_cb[i*uvlinesize], temp8, 1);\n\n            XCHG(h->left_border[uvoffset+34+18+i*step], src_cr[i*uvlinesize], temp8, 1);\n\n        }\n\n        if(deblock_top){\n\n            XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+16), *(uint64_t*)(src_cb+1), temp64, 1);\n\n            XCHG(*(uint64_t*)(h->top_borders[top_idx][s->mb_x]+24), *(uint64_t*)(src_cr+1), temp64, 1);\n\n        }\n\n    }\n\n}\n", "idx": 18749, "_split": "valid", "_hash": "a5923f6efa6739d849c4bc1108b2860c"}
{"project": "FFmpeg", "commit_id": "171ec812235a5d22fa421242351ee2da5a96c3ba", "target": 1, "func": "static void rv34_pred_4x4_block(RV34DecContext *r, uint8_t *dst, int stride, int itype, int up, int left, int down, int right)\n\n{\n\n    uint8_t *prev = dst - stride + 4;\n\n    uint32_t topleft;\n\n\n\n    if(!up && !left)\n\n        itype = DC_128_PRED;\n\n    else if(!up){\n\n        if(itype == VERT_PRED) itype = HOR_PRED;\n\n        if(itype == DC_PRED)   itype = LEFT_DC_PRED;\n\n    }else if(!left){\n\n        if(itype == HOR_PRED)  itype = VERT_PRED;\n\n        if(itype == DC_PRED)   itype = TOP_DC_PRED;\n\n        if(itype == DIAG_DOWN_LEFT_PRED) itype = DIAG_DOWN_LEFT_PRED_RV40_NODOWN;\n\n    }\n\n    if(!down){\n\n        if(itype == DIAG_DOWN_LEFT_PRED) itype = DIAG_DOWN_LEFT_PRED_RV40_NODOWN;\n\n        if(itype == HOR_UP_PRED) itype = HOR_UP_PRED_RV40_NODOWN;\n\n        if(itype == VERT_LEFT_PRED) itype = VERT_LEFT_PRED_RV40_NODOWN;\n\n    }\n\n    if(!right && up){\n\n        topleft = dst[-stride + 3] * 0x01010101;\n\n        prev = (uint8_t*)&topleft;\n\n    }\n\n    r->h.pred4x4[itype](dst, prev, stride);\n\n}\n", "idx": 18753, "_split": "valid", "_hash": "8a680b0373c5ee20da6eeb686817fd35"}
{"project": "FFmpeg", "commit_id": "22fa406f384eb9d825b1d691332e1f928750d55b", "target": 1, "func": "static av_cold int MP3lame_encode_init(AVCodecContext *avctx)\n\n{\n\n    Mp3AudioContext *s = avctx->priv_data;\n\n\n\n    if (avctx->channels > 2)\n\n        return -1;\n\n\n\n    s->stereo = avctx->channels > 1 ? 1 : 0;\n\n\n\n    if ((s->gfp = lame_init()) == NULL)\n\n        goto err;\n\n    lame_set_in_samplerate(s->gfp, avctx->sample_rate);\n\n    lame_set_out_samplerate(s->gfp, avctx->sample_rate);\n\n    lame_set_num_channels(s->gfp, avctx->channels);\n\n    if(avctx->compression_level == FF_COMPRESSION_DEFAULT) {\n\n        lame_set_quality(s->gfp, 5);\n\n    } else {\n\n        lame_set_quality(s->gfp, avctx->compression_level);\n\n    }\n\n    lame_set_mode(s->gfp, s->stereo ? JOINT_STEREO : MONO);\n\n    lame_set_brate(s->gfp, avctx->bit_rate/1000);\n\n    if(avctx->flags & CODEC_FLAG_QSCALE) {\n\n        lame_set_brate(s->gfp, 0);\n\n        lame_set_VBR(s->gfp, vbr_default);\n\n        lame_set_VBR_quality(s->gfp, avctx->global_quality/(float)FF_QP2LAMBDA);\n\n    }\n\n    lame_set_bWriteVbrTag(s->gfp,0);\n\n    lame_set_disable_reservoir(s->gfp, avctx->flags2 & CODEC_FLAG2_BIT_RESERVOIR ? 0 : 1);\n\n    if (lame_init_params(s->gfp) < 0)\n\n        goto err_close;\n\n\n\n    avctx->frame_size = lame_get_framesize(s->gfp);\n\n\n\n    avctx->coded_frame= avcodec_alloc_frame();\n\n    avctx->coded_frame->key_frame= 1;\n\n\n\n    return 0;\n\n\n\nerr_close:\n\n    lame_close(s->gfp);\n\nerr:\n\n    return -1;\n\n}\n", "idx": 18756, "_split": "valid", "_hash": "cff23dd736e22210e2c1c5555d7d5c16"}
{"project": "FFmpeg", "commit_id": "e2959f455850143272f3455a936dfd4d89ae9e03", "target": 0, "func": "int av_strerror(int errnum, char *errbuf, size_t errbuf_size)\n\n{\n\n    int ret = 0;\n\n    const char *errstr = NULL;\n\n\n\n    switch (errnum) {\n\n    case AVERROR_EOF:               errstr = \"End of file\"; break;\n\n    case AVERROR_INVALIDDATA:       errstr = \"Invalid data found when processing input\"; break;\n\n    case AVERROR_NUMEXPECTED:       errstr = \"Number syntax expected in filename\"; break;\n\n    case AVERROR_PATCHWELCOME:      errstr = \"Not yet implemented in FFmpeg, patches welcome\"; break;\n\n    }\n\n\n\n    if (errstr) {\n\n        av_strlcpy(errbuf, errstr, errbuf_size);\n\n    } else {\n\n#if HAVE_STRERROR_R\n\n        ret = strerror_r(AVUNERROR(errnum), errbuf, errbuf_size);\n\n#endif\n\n        if (!HAVE_STRERROR_R || ret < 0)\n\n            snprintf(errbuf, errbuf_size, \"Error number %d occurred\", errnum);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 18766, "_split": "valid", "_hash": "3282e81d8c97c6acbb3b91dd90761982"}
{"project": "FFmpeg", "commit_id": "fbdaebb29861d32acc93fa55fd13554a2ae32eb4", "target": 0, "func": "static int h263_decode_gob_header(MpegEncContext *s)\n\n{\n\n    unsigned int val, gob_number;\n\n    int left;\n\n\n\n    /* Check for GOB Start Code */\n\n    val = show_bits(&s->gb, 16);\n\n    if(val)\n\n        return -1;\n\n\n\n        /* We have a GBSC probably with GSTUFF */\n\n    skip_bits(&s->gb, 16); /* Drop the zeros */\n\n    left= get_bits_left(&s->gb);\n\n    //MN: we must check the bits left or we might end in a infinite loop (or segfault)\n\n    for(;left>13; left--){\n\n        if(get_bits1(&s->gb)) break; /* Seek the '1' bit */\n\n    }\n\n    if(left<=13)\n\n        return -1;\n\n\n\n    if(s->h263_slice_structured){\n\n        if(get_bits1(&s->gb)==0)\n\n            return -1;\n\n\n\n        ff_h263_decode_mba(s);\n\n\n\n        if(s->mb_num > 1583)\n\n            if(get_bits1(&s->gb)==0)\n\n                return -1;\n\n\n\n        s->qscale = get_bits(&s->gb, 5); /* SQUANT */\n\n        if(get_bits1(&s->gb)==0)\n\n            return -1;\n\n        skip_bits(&s->gb, 2); /* GFID */\n\n    }else{\n\n        gob_number = get_bits(&s->gb, 5); /* GN */\n\n        s->mb_x= 0;\n\n        s->mb_y= s->gob_index* gob_number;\n\n        skip_bits(&s->gb, 2); /* GFID */\n\n        s->qscale = get_bits(&s->gb, 5); /* GQUANT */\n\n    }\n\n\n\n    if(s->mb_y >= s->mb_height)\n\n        return -1;\n\n\n\n    if(s->qscale==0)\n\n        return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 18806, "_split": "valid", "_hash": "8cea2fa546dee5c3264674000f9eae0e"}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred4x4_dc)(uint8_t *_src, const uint8_t *topright, int _stride){\n\n    pixel *src = (pixel*)_src;\n\n    int stride = _stride/sizeof(pixel);\n\n    const int dc= (  src[-stride] + src[1-stride] + src[2-stride] + src[3-stride]\n\n                   + src[-1+0*stride] + src[-1+1*stride] + src[-1+2*stride] + src[-1+3*stride] + 4) >>3;\n\n\n\n    ((pixel4*)(src+0*stride))[0]=\n\n    ((pixel4*)(src+1*stride))[0]=\n\n    ((pixel4*)(src+2*stride))[0]=\n\n    ((pixel4*)(src+3*stride))[0]= PIXEL_SPLAT_X4(dc);\n\n}\n", "idx": 18828, "_split": "valid", "_hash": "3aca21203825d8ab9cd944a26c16b6f5"}
{"project": "FFmpeg", "commit_id": "892fc83e88a20f9543c6c5be3626712be7a2e6f2", "target": 0, "func": "static void unpack_dct_coeffs(Vp3DecodeContext *s, GetBitContext *gb)\n\n{\n\n    int i;\n\n    int dc_y_table;\n\n    int dc_c_table;\n\n    int ac_y_table;\n\n    int ac_c_table;\n\n    int residual_eob_run = 0;\n\n\n\n    /* fetch the DC table indices */\n\n    dc_y_table = get_bits(gb, 4);\n\n    dc_c_table = get_bits(gb, 4);\n\n\n\n    /* unpack the Y plane DC coefficients */\n\n    debug_vp3(\"  vp3: unpacking Y plane DC coefficients using table %d\\n\",\n\n        dc_y_table);\n\n    residual_eob_run = unpack_vlcs(s, gb, &s->dc_vlc[dc_y_table], 0, \n\n        s->first_coded_y_fragment, s->last_coded_y_fragment, residual_eob_run);\n\n\n\n    /* unpack the C plane DC coefficients */\n\n    debug_vp3(\"  vp3: unpacking C plane DC coefficients using table %d\\n\",\n\n        dc_c_table);\n\n    residual_eob_run = unpack_vlcs(s, gb, &s->dc_vlc[dc_c_table], 0,\n\n        s->first_coded_c_fragment, s->last_coded_c_fragment, residual_eob_run);\n\n\n\n    /* fetch the AC table indices */\n\n    ac_y_table = get_bits(gb, 4);\n\n    ac_c_table = get_bits(gb, 4);\n\n\n\n    /* unpack the group 1 AC coefficients (coeffs 1-5) */\n\n    for (i = 1; i <= 5; i++) {\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d Y plane AC coefficients using table %d\\n\",\n\n            i, ac_y_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_1[ac_y_table], i, \n\n            s->first_coded_y_fragment, s->last_coded_y_fragment, residual_eob_run);\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d C plane AC coefficients using table %d\\n\",\n\n            i, ac_c_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_1[ac_c_table], i, \n\n            s->first_coded_c_fragment, s->last_coded_c_fragment, residual_eob_run);\n\n    }\n\n\n\n    /* unpack the group 2 AC coefficients (coeffs 6-14) */\n\n    for (i = 6; i <= 14; i++) {\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d Y plane AC coefficients using table %d\\n\",\n\n            i, ac_y_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_2[ac_y_table], i, \n\n            s->first_coded_y_fragment, s->last_coded_y_fragment, residual_eob_run);\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d C plane AC coefficients using table %d\\n\",\n\n            i, ac_c_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_2[ac_c_table], i, \n\n            s->first_coded_c_fragment, s->last_coded_c_fragment, residual_eob_run);\n\n    }\n\n\n\n    /* unpack the group 3 AC coefficients (coeffs 15-27) */\n\n    for (i = 15; i <= 27; i++) {\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d Y plane AC coefficients using table %d\\n\",\n\n            i, ac_y_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_3[ac_y_table], i, \n\n            s->first_coded_y_fragment, s->last_coded_y_fragment, residual_eob_run);\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d C plane AC coefficients using table %d\\n\",\n\n            i, ac_c_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_3[ac_c_table], i, \n\n            s->first_coded_c_fragment, s->last_coded_c_fragment, residual_eob_run);\n\n    }\n\n\n\n    /* unpack the group 4 AC coefficients (coeffs 28-63) */\n\n    for (i = 28; i <= 63; i++) {\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d Y plane AC coefficients using table %d\\n\",\n\n            i, ac_y_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_4[ac_y_table], i, \n\n            s->first_coded_y_fragment, s->last_coded_y_fragment, residual_eob_run);\n\n\n\n        debug_vp3(\"  vp3: unpacking level %d C plane AC coefficients using table %d\\n\",\n\n            i, ac_c_table);\n\n        residual_eob_run = unpack_vlcs(s, gb, &s->ac_vlc_4[ac_c_table], i, \n\n            s->first_coded_c_fragment, s->last_coded_c_fragment, residual_eob_run);\n\n    }\n\n}\n", "idx": 18852, "_split": "valid", "_hash": "1334d04d689740f21f03ffe2f1d1f365"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "void ff_fix_long_mvs(MpegEncContext * s, uint8_t *field_select_table, int field_select,\n\n                     int16_t (*mv_table)[2], int f_code, int type, int truncate)\n\n{\n\n    MotionEstContext * const c= &s->me;\n\n    int y, h_range, v_range;\n\n\n\n    // RAL: 8 in MPEG-1, 16 in MPEG-4\n\n    int range = (((s->out_format == FMT_MPEG1 || s->msmpeg4_version) ? 8 : 16) << f_code);\n\n\n\n    if(c->avctx->me_range && range > c->avctx->me_range) range= c->avctx->me_range;\n\n\n\n    h_range= range;\n\n    v_range= field_select_table ? range>>1 : range;\n\n\n\n    /* clip / convert to intra 16x16 type MVs */\n\n    for(y=0; y<s->mb_height; y++){\n\n        int x;\n\n        int xy= y*s->mb_stride;\n\n        for(x=0; x<s->mb_width; x++){\n\n            if (s->mb_type[xy] & type){    // RAL: \"type\" test added...\n\n                if(field_select_table==NULL || field_select_table[xy] == field_select){\n\n                    if(   mv_table[xy][0] >=h_range || mv_table[xy][0] <-h_range\n\n                       || mv_table[xy][1] >=v_range || mv_table[xy][1] <-v_range){\n\n\n\n                        if(truncate){\n\n                            if     (mv_table[xy][0] > h_range-1) mv_table[xy][0]=  h_range-1;\n\n                            else if(mv_table[xy][0] < -h_range ) mv_table[xy][0]= -h_range;\n\n                            if     (mv_table[xy][1] > v_range-1) mv_table[xy][1]=  v_range-1;\n\n                            else if(mv_table[xy][1] < -v_range ) mv_table[xy][1]= -v_range;\n\n                        }else{\n\n                            s->mb_type[xy] &= ~type;\n\n                            s->mb_type[xy] |= CANDIDATE_MB_TYPE_INTRA;\n\n                            mv_table[xy][0]=\n\n                            mv_table[xy][1]= 0;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n            xy++;\n\n        }\n\n    }\n\n}\n", "idx": 18883, "_split": "valid", "_hash": "eecd22cdfee7652fd537ba8f22ed099e"}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int ftp_write(URLContext *h, const unsigned char *buf, int size)\n\n{\n\n    int err;\n\n    FTPContext *s = h->priv_data;\n\n    int written;\n\n\n\n    av_dlog(h, \"ftp protocol write %d bytes\\n\", size);\n\n\n\n    if (s->state == DISCONNECTED) {\n\n        if ((err = ftp_connect_data_connection(h)) < 0)\n\n            return err;\n\n    }\n\n    if (s->state == READY) {\n\n        if ((err = ftp_store(s)) < 0)\n\n            return err;\n\n    }\n\n    if (s->conn_data && s->state == UPLOADING) {\n\n        written = ffurl_write(s->conn_data, buf, size);\n\n        if (written > 0) {\n\n            s->position += written;\n\n            s->filesize = FFMAX(s->filesize, s->position);\n\n        }\n\n        return written;\n\n    }\n\n\n\n    av_log(h, AV_LOG_ERROR, \"FTP write failed\\n\");\n\n    return AVERROR(EIO);\n\n}\n", "idx": 18898, "_split": "valid", "_hash": "a78a668f1de601a914e6debe483424e5"}
{"project": "FFmpeg", "commit_id": "9b7a8bddac52bd05dddb28afd4dff92739946d3b", "target": 1, "func": "static int udp_write(URLContext *h, const uint8_t *buf, int size)\n\n{\n\n    UDPContext *s = h->priv_data;\n\n    int ret;\n\n\n\n#if HAVE_PTHREAD_CANCEL\n\n    if (s->fifo) {\n\n        uint8_t tmp[4];\n\n\n\n        pthread_mutex_lock(&s->mutex);\n\n\n\n        /*\n\n          Return error if last tx failed.\n\n          Here we can't know on which packet error was, but it needs to know that error exists.\n\n        */\n\n        if (s->circular_buffer_error<0) {\n\n            int err=s->circular_buffer_error;\n\n            s->circular_buffer_error=0;\n\n            pthread_mutex_unlock(&s->mutex);\n\n            return err;\n\n        }\n\n\n\n        if(av_fifo_space(s->fifo) < size + 4) {\n\n            /* What about a partial packet tx ? */\n\n            pthread_mutex_unlock(&s->mutex);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        AV_WL32(tmp, size);\n\n        av_fifo_generic_write(s->fifo, tmp, 4, NULL); /* size of packet */\n\n        av_fifo_generic_write(s->fifo, (uint8_t *)buf, size, NULL); /* the data */\n\n        pthread_cond_signal(&s->cond);\n\n        pthread_mutex_unlock(&s->mutex);\n\n        return size;\n\n    }\n\n#endif\n\n    if (!(h->flags & AVIO_FLAG_NONBLOCK)) {\n\n        ret = ff_network_wait_fd(s->udp_fd, 1);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    if (!s->is_connected) {\n\n        ret = sendto (s->udp_fd, buf, size, 0,\n\n                      (struct sockaddr *) &s->dest_addr,\n\n                      s->dest_addr_len);\n\n    } else\n\n        ret = send(s->udp_fd, buf, size, 0);\n\n\n\n    return ret < 0 ? ff_neterrno() : ret;\n\n}\n", "idx": 18959, "_split": "valid", "_hash": "200b2284ad689bd8c8138f1864f0236d"}
{"project": "FFmpeg", "commit_id": "aba232cfa9b193604ed98f3fa505378d006b1b3b", "target": 1, "func": "static void compute_frame_duration(int *pnum, int *pden, AVStream *st,\n\n                                   AVCodecParserContext *pc, AVPacket *pkt)\n\n{\n\n    int frame_size;\n\n\n\n    *pnum = 0;\n\n    *pden = 0;\n\n    switch(st->codec->codec_type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        if (st->r_frame_rate.num) {\n\n            *pnum = st->r_frame_rate.den;\n\n            *pden = st->r_frame_rate.num;\n\n        } else if(st->time_base.num*1000LL > st->time_base.den) {\n\n            *pnum = st->time_base.num;\n\n            *pden = st->time_base.den;\n\n        }else if(st->codec->time_base.num*1000LL > st->codec->time_base.den){\n\n            *pnum = st->codec->time_base.num;\n\n            *pden = st->codec->time_base.den;\n\n            if (pc && pc->repeat_pict) {\n\n                *pnum = (*pnum) * (1 + pc->repeat_pict);\n\n            }\n\n            //If this codec can be interlaced or progressive then we need a parser to compute duration of a packet\n\n            //Thus if we have no parser in such case leave duration undefined.\n\n            if(st->codec->ticks_per_frame>1 && !pc){\n\n                *pnum = *pden = 0;\n\n            }\n\n        }\n\n        break;\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        frame_size = get_audio_frame_size(st->codec, pkt->size, 0);\n\n        if (frame_size <= 0 || st->codec->sample_rate <= 0)\n\n            break;\n\n        *pnum = frame_size;\n\n        *pden = st->codec->sample_rate;\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n}\n", "idx": 18965, "_split": "valid", "_hash": "106c63c57730aa30f53152b20849e06a"}
{"project": "FFmpeg", "commit_id": "afa612901615cca6c0160b5e6c18ffcacf0add46", "target": 0, "func": "static int zerocodec_decode_frame(AVCodecContext *avctx, void *data,\n\n                                  int *data_size, AVPacket *avpkt)\n\n{\n\n    ZeroCodecContext *zc = avctx->priv_data;\n\n    AVFrame *pic         = avctx->coded_frame;\n\n    AVFrame *prev_pic    = &zc->previous_frame;\n\n    z_stream *zstream    = &zc->zstream;\n\n    uint8_t *prev, *dst;\n\n    int i, j, zret;\n\n\n\n    pic->reference = 3;\n\n\n\n    if (avctx->get_buffer(avctx, pic) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not allocate buffer.\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    zret = inflateReset(zstream);\n\n\n\n    if (zret != Z_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not reset inflate: %d\\n\", zret);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    zstream->next_in  = avpkt->data;\n\n    zstream->avail_in = avpkt->size;\n\n\n\n    prev = prev_pic->data[0];\n\n    dst  = pic->data[0];\n\n\n\n    /**\n\n     * ZeroCodec has very simple interframe compression. If a value\n\n     * is the same as the previous frame, set it to 0.\n\n     */\n\n\n\n    if (avpkt->flags & AV_PKT_FLAG_KEY) {\n\n\n\n        pic->key_frame = 1;\n\n        pic->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n        for (i = 0; i < avctx->height; i++) {\n\n\n\n            zstream->next_out  = dst;\n\n            zstream->avail_out = avctx->width << 1;\n\n\n\n            zret = inflate(zstream, Z_SYNC_FLUSH);\n\n\n\n            if (zret != Z_OK && zret != Z_STREAM_END) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"Inflate failed with return code: %d\\n\", zret);\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            dst += pic->linesize[0];\n\n        }\n\n    } else {\n\n\n\n        pic->key_frame = 0;\n\n        pic->pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        for (i = 0; i < avctx->height; i++) {\n\n\n\n            zstream->next_out  = dst;\n\n            zstream->avail_out = avctx->width << 1;\n\n\n\n            zret = inflate(zstream, Z_SYNC_FLUSH);\n\n\n\n            if (zret != Z_OK && zret != Z_STREAM_END) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"Inflate failed with return code: %d\\n\", zret);\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            for (j = 0; j < avctx->width << 1; j++)\n\n                dst[j] += prev[j] & -!dst[j];\n\n\n\n            prev += prev_pic->linesize[0];\n\n            dst  += pic->linesize[0];\n\n        }\n\n    }\n\n\n\n    /* Release the previous buffer if need be */\n\n    if (prev_pic->data[0])\n\n        avctx->release_buffer(avctx, prev_pic);\n\n\n\n    /* Store the previouse frame for use later */\n\n    *prev_pic = *pic;\n\n\n\n    *data_size       = sizeof(AVFrame);\n\n    *(AVFrame *)data = *pic;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 18994, "_split": "valid", "_hash": "0729ac2dec1f2c4e5dc2ad9c24d33289"}
{"project": "FFmpeg", "commit_id": "dabea74d0e82ea80cd344f630497cafcb3ef872c", "target": 1, "func": "int update_dimensions(VP8Context *s, int width, int height, int is_vp7)\n\n{\n\n    AVCodecContext *avctx = s->avctx;\n\n    int i, ret;\n\n\n\n    if (width  != s->avctx->width || ((width+15)/16 != s->mb_width || (height+15)/16 != s->mb_height) && s->macroblocks_base ||\n\n        height != s->avctx->height) {\n\n        vp8_decode_flush_impl(s->avctx, 1);\n\n\n\n        ret = ff_set_dimensions(s->avctx, width, height);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    s->mb_width  = (s->avctx->coded_width  + 15) / 16;\n\n    s->mb_height = (s->avctx->coded_height + 15) / 16;\n\n\n\n    s->mb_layout = is_vp7 || avctx->active_thread_type == FF_THREAD_SLICE &&\n\n                   FFMIN(s->num_coeff_partitions, avctx->thread_count) > 1;\n\n    if (!s->mb_layout) { // Frame threading and one thread\n\n        s->macroblocks_base       = av_mallocz((s->mb_width + s->mb_height * 2 + 1) *\n\n                                               sizeof(*s->macroblocks));\n\n        s->intra4x4_pred_mode_top = av_mallocz(s->mb_width * 4);\n\n    } else // Sliced threading\n\n        s->macroblocks_base = av_mallocz((s->mb_width + 2) * (s->mb_height + 2) *\n\n                                         sizeof(*s->macroblocks));\n\n    s->top_nnz     = av_mallocz(s->mb_width * sizeof(*s->top_nnz));\n\n    s->top_border  = av_mallocz((s->mb_width + 1) * sizeof(*s->top_border));\n\n    s->thread_data = av_mallocz(MAX_THREADS * sizeof(VP8ThreadData));\n\n\n\n    if (!s->macroblocks_base || !s->top_nnz || !s->top_border ||\n\n        !s->thread_data || (!s->intra4x4_pred_mode_top && !s->mb_layout)) {\n\n        free_buffers(s);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    for (i = 0; i < MAX_THREADS; i++) {\n\n        s->thread_data[i].filter_strength =\n\n            av_mallocz(s->mb_width * sizeof(*s->thread_data[0].filter_strength));\n\n        if (!s->thread_data[i].filter_strength) {\n\n            free_buffers(s);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n#if HAVE_THREADS\n\n        pthread_mutex_init(&s->thread_data[i].lock, NULL);\n\n        pthread_cond_init(&s->thread_data[i].cond, NULL);\n\n#endif\n\n    }\n\n\n\n    s->macroblocks = s->macroblocks_base + 1;\n\n\n\n    return 0;\n\n}\n", "idx": 19009, "_split": "valid", "_hash": "1726316094e0d9ce00cf38fa419fa46c"}
{"project": "FFmpeg", "commit_id": "b8a9dfb7f6706d56bc0e71bd5348e676ac96d14d", "target": 0, "func": "static int mpeg_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    Mpeg1Context *s = avctx->priv_data;\n\n    const uint8_t *buf_end;\n\n    const uint8_t *buf_ptr;\n\n    uint32_t start_code;\n\n    int ret, input_size;\n\n    AVFrame *picture = data;\n\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n\n    dprintf(avctx, \"fill_buffer\\n\");\n\n\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == SEQ_END_CODE)) {\n\n        /* special case for last picture */\n\n        if (s2->low_delay==0 && s2->next_picture_ptr) {\n\n            *picture= *(AVFrame*)s2->next_picture_ptr;\n\n            s2->next_picture_ptr= NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    if(s2->flags&CODEC_FLAG_TRUNCATED){\n\n        int next= ff_mpeg1_find_frame_end(&s2->parse_context, buf, buf_size);\n\n\n\n        if( ff_combine_frame(&s2->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0 )\n\n            return buf_size;\n\n    }\n\n\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n\n\n#if 0\n\n    if (s->repeat_field % 2 == 1) {\n\n        s->repeat_field++;\n\n        //fprintf(stderr,\"\\nRepeating last frame: %d -> %d! pict: %d %d\", avctx->frame_number-1, avctx->frame_number,\n\n        //        s2->picture_number, s->repeat_field);\n\n        if (avctx->flags & CODEC_FLAG_REPEAT_FIELD) {\n\n            *data_size = sizeof(AVPicture);\n\n            goto the_end;\n\n        }\n\n    }\n\n#endif\n\n\n\n    if(s->mpeg_enc_ctx_allocated==0 && avctx->codec_tag == ff_get_fourcc(\"VCR2\"))\n\n        vcr2_init_sequence(avctx);\n\n\n\n    s->slice_count= 0;\n\n\n\n    for(;;) {\n\n        /* find start next code */\n\n        start_code = -1;\n\n        buf_ptr = ff_find_start_code(buf_ptr,buf_end, &start_code);\n\n        if (start_code > 0x1ff){\n\n            if(s2->pict_type != B_TYPE || avctx->skip_frame <= AVDISCARD_DEFAULT){\n\n                if(avctx->thread_count > 1){\n\n                    int i;\n\n\n\n                    avctx->execute(avctx, slice_decode_thread,  (void**)&(s2->thread_context[0]), NULL, s->slice_count);\n\n                    for(i=0; i<s->slice_count; i++)\n\n                        s2->error_count += s2->thread_context[i]->error_count;\n\n                }\n\n                if (slice_end(avctx, picture)) {\n\n                    if(s2->last_picture_ptr || s2->low_delay) //FIXME merge with the stuff in mpeg_decode_slice\n\n                        *data_size = sizeof(AVPicture);\n\n                }\n\n            }\n\n            return FFMAX(0, buf_ptr - buf - s2->parse_context.last_index);\n\n        }\n\n\n\n        input_size = buf_end - buf_ptr;\n\n\n\n        if(avctx->debug & FF_DEBUG_STARTCODE){\n\n            av_log(avctx, AV_LOG_DEBUG, \"%3X at %zd left %d\\n\", start_code, buf_ptr-buf, input_size);\n\n        }\n\n\n\n        /* prepare data for next start code */\n\n        switch(start_code) {\n\n        case SEQ_START_CODE:\n\n            mpeg1_decode_sequence(avctx, buf_ptr,\n\n                                    input_size);\n\n            break;\n\n\n\n        case PICTURE_START_CODE:\n\n            /* we have a complete image : we try to decompress it */\n\n            mpeg1_decode_picture(avctx,\n\n                                    buf_ptr, input_size);\n\n            break;\n\n        case EXT_START_CODE:\n\n            mpeg_decode_extension(avctx,\n\n                                    buf_ptr, input_size);\n\n            break;\n\n        case USER_START_CODE:\n\n            mpeg_decode_user_data(avctx,\n\n                                    buf_ptr, input_size);\n\n            break;\n\n        case GOP_START_CODE:\n\n            s2->first_field=0;\n\n            mpeg_decode_gop(avctx,\n\n                                    buf_ptr, input_size);\n\n            break;\n\n        default:\n\n            if (start_code >= SLICE_MIN_START_CODE &&\n\n                start_code <= SLICE_MAX_START_CODE) {\n\n                int mb_y= start_code - SLICE_MIN_START_CODE;\n\n\n\n                if(s2->last_picture_ptr==NULL){\n\n                /* Skip B-frames if we do not have reference frames. */\n\n                    if(s2->pict_type==B_TYPE) break;\n\n                /* Skip P-frames if we do not have reference frame no valid header. */\n\n//                    if(s2->pict_type==P_TYPE && s2->first_field && !s2->first_slice) break;\n\n                }\n\n                /* Skip B-frames if we are in a hurry. */\n\n                if(avctx->hurry_up && s2->pict_type==B_TYPE) break;\n\n                if(  (avctx->skip_frame >= AVDISCARD_NONREF && s2->pict_type==B_TYPE)\n\n                    ||(avctx->skip_frame >= AVDISCARD_NONKEY && s2->pict_type!=I_TYPE)\n\n                    || avctx->skip_frame >= AVDISCARD_ALL)\n\n                    break;\n\n                /* Skip everything if we are in a hurry>=5. */\n\n                if(avctx->hurry_up>=5) break;\n\n\n\n                if (!s->mpeg_enc_ctx_allocated) break;\n\n\n\n                if(s2->codec_id == CODEC_ID_MPEG2VIDEO){\n\n                    if(mb_y < avctx->skip_top || mb_y >= s2->mb_height - avctx->skip_bottom)\n\n                        break;\n\n                }\n\n\n\n                if(s2->first_slice){\n\n                    s2->first_slice=0;\n\n                            if(mpeg_field_start(s2) < 0)\n\n                        return -1;\n\n                    }\n\n                if(!s2->current_picture_ptr){\n\n                    av_log(avctx, AV_LOG_ERROR, \"current_picture not initialized\\n\");\n\n                    return -1;\n\n                }\n\n\n\n                if(avctx->thread_count > 1){\n\n                    int threshold= (s2->mb_height*s->slice_count + avctx->thread_count/2) / avctx->thread_count;\n\n                    if(threshold <= mb_y){\n\n                        MpegEncContext *thread_context= s2->thread_context[s->slice_count];\n\n\n\n                        thread_context->start_mb_y= mb_y;\n\n                        thread_context->end_mb_y  = s2->mb_height;\n\n                        if(s->slice_count){\n\n                            s2->thread_context[s->slice_count-1]->end_mb_y= mb_y;\n\n                            ff_update_duplicate_context(thread_context, s2);\n\n                        }\n\n                        init_get_bits(&thread_context->gb, buf_ptr, input_size*8);\n\n                        s->slice_count++;\n\n                    }\n\n                    buf_ptr += 2; //FIXME add minimum num of bytes per slice\n\n                }else{\n\n                    ret = mpeg_decode_slice(s, mb_y, &buf_ptr, input_size);\n\n                    emms_c();\n\n\n\n                    if(ret < 0){\n\n                        if(s2->resync_mb_x>=0 && s2->resync_mb_y>=0)\n\n                            ff_er_add_slice(s2, s2->resync_mb_x, s2->resync_mb_y, s2->mb_x, s2->mb_y, AC_ERROR|DC_ERROR|MV_ERROR);\n\n                    }else{\n\n                        ff_er_add_slice(s2, s2->resync_mb_x, s2->resync_mb_y, s2->mb_x-1, s2->mb_y, AC_END|DC_END|MV_END);\n\n                    }\n\n                }\n\n            }\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 19012, "_split": "valid", "_hash": "02401d48ad84106078427aa4f9c134c0"}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static void seg_free_context(SegmentContext *seg)\n\n{\n\n    avio_closep(&seg->pb);\n\n    avformat_free_context(seg->avf);\n\n    seg->avf = NULL;\n\n}\n", "idx": 19031, "_split": "valid", "_hash": "c3624e0fc664548e4bb513bcb8f28158"}
{"project": "FFmpeg", "commit_id": "b69b43e2c471c4febbffaf313875396256b6a51e", "target": 1, "func": "static int transcode_subtitles(InputStream *ist, AVPacket *pkt, int *got_output)\n\n{\n\n    AVSubtitle subtitle;\n\n    int i, ret = avcodec_decode_subtitle2(ist->dec_ctx,\n\n                                          &subtitle, got_output, pkt);\n\n\n\n    check_decode_result(got_output, ret);\n\n\n\n    if (ret < 0 || !*got_output) {\n\n        if (!pkt->size)\n\n            sub2video_flush(ist);\n\n        return ret;\n\n    }\n\n\n\n    if (ist->fix_sub_duration) {\n\n        int end = 1;\n\n        if (ist->prev_sub.got_output) {\n\n            end = av_rescale(subtitle.pts - ist->prev_sub.subtitle.pts,\n\n                             1000, AV_TIME_BASE);\n\n            if (end < ist->prev_sub.subtitle.end_display_time) {\n\n                av_log(ist->dec_ctx, AV_LOG_DEBUG,\n\n                       \"Subtitle duration reduced from %d to %d%s\\n\",\n\n                       ist->prev_sub.subtitle.end_display_time, end,\n\n                       end <= 0 ? \", dropping it\" : \"\");\n\n                ist->prev_sub.subtitle.end_display_time = end;\n\n            }\n\n        }\n\n        FFSWAP(int,        *got_output, ist->prev_sub.got_output);\n\n        FFSWAP(int,        ret,         ist->prev_sub.ret);\n\n        FFSWAP(AVSubtitle, subtitle,    ist->prev_sub.subtitle);\n\n        if (end <= 0)\n\n            goto out;\n\n    }\n\n\n\n    if (!*got_output)\n\n        return ret;\n\n\n\n    sub2video_update(ist, &subtitle);\n\n\n\n    if (!subtitle.num_rects)\n\n        goto out;\n\n\n\n    ist->frames_decoded++;\n\n\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        OutputStream *ost = output_streams[i];\n\n\n\n        if (!check_output_constraints(ist, ost) || !ost->encoding_needed\n\n            || ost->enc->type != AVMEDIA_TYPE_SUBTITLE)\n\n            continue;\n\n\n\n        do_subtitle_out(output_files[ost->file_index]->ctx, ost, ist, &subtitle);\n\n    }\n\n\n\nout:\n\n    avsubtitle_free(&subtitle);\n\n    return ret;\n\n}\n", "idx": 19051, "_split": "valid", "_hash": "4e7d145d1f08497becbef9c2d2fc9b00"}
{"project": "FFmpeg", "commit_id": "7f8ffc4efddf796aa3aa8174fb008007cb8f8c1c", "target": 0, "func": "static int yuv4_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    char header[MAX_YUV4_HEADER+10];  // Include headroom for the longest option\n\n    char *tokstart,*tokend,*header_end;\n\n    int i;\n\n    ByteIOContext *pb = s->pb;\n\n    int width=-1, height=-1, raten=0, rated=0, aspectn=0, aspectd=0;\n\n    enum PixelFormat pix_fmt=PIX_FMT_NONE,alt_pix_fmt=PIX_FMT_NONE;\n\n    enum AVChromaLocation chroma_sample_location = AVCHROMA_LOC_UNSPECIFIED;\n\n    AVStream *st;\n\n    struct frame_attributes *s1 = s->priv_data;\n\n\n\n    for (i=0; i<MAX_YUV4_HEADER; i++) {\n\n        header[i] = get_byte(pb);\n\n        if (header[i] == '\\n') {\n\n            header[i+1] = 0x20;  // Add a space after last option. Makes parsing \"444\" vs \"444alpha\" easier.\n\n            header[i+2] = 0;\n\n            break;\n\n        }\n\n    }\n\n    if (i == MAX_YUV4_HEADER) return -1;\n\n    if (strncmp(header, Y4M_MAGIC, strlen(Y4M_MAGIC))) return -1;\n\n\n\n    s1->interlaced_frame = 0;\n\n    s1->top_field_first = 0;\n\n    header_end = &header[i+1]; // Include space\n\n    for(tokstart = &header[strlen(Y4M_MAGIC) + 1]; tokstart < header_end; tokstart++) {\n\n        if (*tokstart==0x20) continue;\n\n        switch (*tokstart++) {\n\n        case 'W': // Width. Required.\n\n            width = strtol(tokstart, &tokend, 10);\n\n            tokstart=tokend;\n\n            break;\n\n        case 'H': // Height. Required.\n\n            height = strtol(tokstart, &tokend, 10);\n\n            tokstart=tokend;\n\n            break;\n\n        case 'C': // Color space\n\n            if (strncmp(\"420jpeg\",tokstart,7)==0) {\n\n                pix_fmt = PIX_FMT_YUV420P;\n\n                chroma_sample_location = AVCHROMA_LOC_CENTER;\n\n            } else if (strncmp(\"420mpeg2\",tokstart,8)==0) {\n\n                pix_fmt = PIX_FMT_YUV420P;\n\n                chroma_sample_location = AVCHROMA_LOC_LEFT;\n\n            } else if (strncmp(\"420paldv\", tokstart, 8)==0) {\n\n                pix_fmt = PIX_FMT_YUV420P;\n\n                chroma_sample_location = AVCHROMA_LOC_TOPLEFT;\n\n            } else if (strncmp(\"411\", tokstart, 3)==0)\n\n                pix_fmt = PIX_FMT_YUV411P;\n\n            else if (strncmp(\"422\", tokstart, 3)==0)\n\n                pix_fmt = PIX_FMT_YUV422P;\n\n            else if (strncmp(\"444alpha\", tokstart, 8)==0) {\n\n                av_log(s, AV_LOG_ERROR, \"Cannot handle 4:4:4:4 YUV4MPEG stream.\\n\");\n\n                return -1;\n\n            } else if (strncmp(\"444\", tokstart, 3)==0)\n\n                pix_fmt = PIX_FMT_YUV444P;\n\n            else if (strncmp(\"mono\",tokstart, 4)==0) {\n\n                pix_fmt = PIX_FMT_GRAY8;\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"YUV4MPEG stream contains an unknown pixel format.\\n\");\n\n                return -1;\n\n            }\n\n            while(tokstart<header_end&&*tokstart!=0x20) tokstart++;\n\n            break;\n\n        case 'I': // Interlace type\n\n            switch (*tokstart++){\n\n            case '?':\n\n                break;\n\n            case 'p':\n\n                s1->interlaced_frame=0;\n\n                break;\n\n            case 't':\n\n                s1->interlaced_frame=1;\n\n                s1->top_field_first=1;\n\n                break;\n\n            case 'b':\n\n                s1->interlaced_frame=1;\n\n                s1->top_field_first=0;\n\n                break;\n\n            case 'm':\n\n                av_log(s, AV_LOG_ERROR, \"YUV4MPEG stream contains mixed interlaced and non-interlaced frames.\\n\");\n\n                return -1;\n\n            default:\n\n                av_log(s, AV_LOG_ERROR, \"YUV4MPEG has invalid header.\\n\");\n\n                return -1;\n\n            }\n\n            break;\n\n        case 'F': // Frame rate\n\n            sscanf(tokstart,\"%d:%d\",&raten,&rated); // 0:0 if unknown\n\n            while(tokstart<header_end&&*tokstart!=0x20) tokstart++;\n\n            break;\n\n        case 'A': // Pixel aspect\n\n            sscanf(tokstart,\"%d:%d\",&aspectn,&aspectd); // 0:0 if unknown\n\n            while(tokstart<header_end&&*tokstart!=0x20) tokstart++;\n\n            break;\n\n        case 'X': // Vendor extensions\n\n            if (strncmp(\"YSCSS=\",tokstart,6)==0) {\n\n                // Older nonstandard pixel format representation\n\n                tokstart+=6;\n\n                if (strncmp(\"420JPEG\",tokstart,7)==0)\n\n                    alt_pix_fmt=PIX_FMT_YUV420P;\n\n                else if (strncmp(\"420MPEG2\",tokstart,8)==0)\n\n                    alt_pix_fmt=PIX_FMT_YUV420P;\n\n                else if (strncmp(\"420PALDV\",tokstart,8)==0)\n\n                    alt_pix_fmt=PIX_FMT_YUV420P;\n\n                else if (strncmp(\"411\",tokstart,3)==0)\n\n                    alt_pix_fmt=PIX_FMT_YUV411P;\n\n                else if (strncmp(\"422\",tokstart,3)==0)\n\n                    alt_pix_fmt=PIX_FMT_YUV422P;\n\n                else if (strncmp(\"444\",tokstart,3)==0)\n\n                    alt_pix_fmt=PIX_FMT_YUV444P;\n\n            }\n\n            while(tokstart<header_end&&*tokstart!=0x20) tokstart++;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if ((width == -1) || (height == -1)) {\n\n        av_log(s, AV_LOG_ERROR, \"YUV4MPEG has invalid header.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (pix_fmt == PIX_FMT_NONE) {\n\n        if (alt_pix_fmt == PIX_FMT_NONE)\n\n            pix_fmt = PIX_FMT_YUV420P;\n\n        else\n\n            pix_fmt = alt_pix_fmt;\n\n    }\n\n\n\n    if (raten == 0 && rated == 0) {\n\n        // Frame rate unknown\n\n        raten = 25;\n\n        rated = 1;\n\n    }\n\n\n\n    if (aspectn == 0 && aspectd == 0) {\n\n        // Pixel aspect unknown\n\n        aspectd = 1;\n\n    }\n\n\n\n    st = av_new_stream(s, 0);\n\n    if(!st)\n\n        return AVERROR(ENOMEM);\n\n    st->codec->width = width;\n\n    st->codec->height = height;\n\n    av_reduce(&raten, &rated, raten, rated, (1UL<<31)-1);\n\n    av_set_pts_info(st, 64, rated, raten);\n\n    st->codec->pix_fmt = pix_fmt;\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = CODEC_ID_RAWVIDEO;\n\n    st->sample_aspect_ratio= (AVRational){aspectn, aspectd};\n\n    st->codec->chroma_sample_location = chroma_sample_location;\n\n\n\n    return 0;\n\n}\n", "idx": 19087, "_split": "valid", "_hash": "112a4060fc535abda5e2dd9178adf60f"}
{"project": "FFmpeg", "commit_id": "1a3598aae768465a8efc8475b6df5a8261bc62fc", "target": 1, "func": "static int get_coc(Jpeg2000DecoderContext *s, Jpeg2000CodingStyle *c,\n\n                   uint8_t *properties)\n\n{\n\n    int compno;\n\n\n\n    if (s->buf_end - s->buf < 2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    compno = bytestream_get_byte(&s->buf);\n\n\n\n    c      += compno;\n\n    c->csty = bytestream_get_byte(&s->buf);\n\n    get_cox(s, c);\n\n\n\n    properties[compno] |= HAD_COC;\n\n    return 0;\n\n}\n", "idx": 19156, "_split": "valid", "_hash": "cfc7343f0622f6b676cc74f7472b8c2b"}
{"project": "FFmpeg", "commit_id": "c51c08e0e70c186971385bdbb225f69edd4e3375", "target": 0, "func": "static int decode_frame_packing_arrangement(H264Context *h)\n\n{\n\n    h->sei_fpa.frame_packing_arrangement_id          = get_ue_golomb(&h->gb);\n\n    h->sei_fpa.frame_packing_arrangement_cancel_flag = get_bits1(&h->gb);\n\n    h->sei_frame_packing_present = !h->sei_fpa.frame_packing_arrangement_cancel_flag;\n\n\n\n    if (h->sei_frame_packing_present) {\n\n        h->sei_fpa.frame_packing_arrangement_type =\n\n        h->frame_packing_arrangement_type = get_bits(&h->gb, 7);\n\n        h->sei_fpa.quincunx_sampling_flag         =\n\n        h->quincunx_subsampling           = get_bits1(&h->gb);\n\n        h->sei_fpa.content_interpretation_type    =\n\n        h->content_interpretation_type    = get_bits(&h->gb, 6);\n\n\n\n        // the following skips: spatial_flipping_flag, frame0_flipped_flag,\n\n        // field_views_flag, current_frame_is_frame0_flag,\n\n        // frame0_self_contained_flag, frame1_self_contained_flag\n\n        skip_bits(&h->gb, 6);\n\n\n\n        if (!h->quincunx_subsampling && h->frame_packing_arrangement_type != 5)\n\n            skip_bits(&h->gb, 16);      // frame[01]_grid_position_[xy]\n\n        skip_bits(&h->gb, 8);           // frame_packing_arrangement_reserved_byte\n\n        h->sei_fpa.frame_packing_arrangement_repetition_period = get_ue_golomb(&h->gb) /* frame_packing_arrangement_repetition_period */;\n\n    }\n\n    skip_bits1(&h->gb);                 // frame_packing_arrangement_extension_flag\n\n\n\n    if (h->avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_log(h->avctx, AV_LOG_DEBUG, \"SEI FPA %d %d %d %d %d %d\\n\",\n\n                                       h->sei_fpa.frame_packing_arrangement_id,\n\n                                       h->sei_fpa.frame_packing_arrangement_cancel_flag,\n\n                                       h->sei_fpa.frame_packing_arrangement_type,\n\n                                       h->sei_fpa.quincunx_sampling_flag,\n\n                                       h->sei_fpa.content_interpretation_type,\n\n                                       h->sei_fpa.frame_packing_arrangement_repetition_period);\n\n\n\n    return 0;\n\n}\n", "idx": 19201, "_split": "valid", "_hash": "365e17d6fcd6b5b4a446c8452f68336b"}
{"project": "FFmpeg", "commit_id": "66e959682c49e0686667cd3cbde87d725bb3c7e3", "target": 0, "func": "av_cold int ff_MPV_encode_init(AVCodecContext *avctx)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i, ret;\n\n\n\n    MPV_encode_defaults(s);\n\n\n\n    switch (avctx->codec_id) {\n\n    case AV_CODEC_ID_MPEG2VIDEO:\n\n        if (avctx->pix_fmt != AV_PIX_FMT_YUV420P &&\n\n            avctx->pix_fmt != AV_PIX_FMT_YUV422P) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"only YUV420 and YUV422 are supported\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_MJPEG:\n\n    case AV_CODEC_ID_AMV:\n\n        if (avctx->pix_fmt != AV_PIX_FMT_YUVJ420P &&\n\n            avctx->pix_fmt != AV_PIX_FMT_YUVJ422P &&\n\n            avctx->pix_fmt != AV_PIX_FMT_YUVJ444P &&\n\n            ((avctx->pix_fmt != AV_PIX_FMT_YUV420P &&\n\n              avctx->pix_fmt != AV_PIX_FMT_YUV422P &&\n\n              avctx->pix_fmt != AV_PIX_FMT_YUV444P) ||\n\n             avctx->strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"colorspace not supported in jpeg\\n\");\n\n            return -1;\n\n        }\n\n        break;\n\n    default:\n\n        if (avctx->pix_fmt != AV_PIX_FMT_YUV420P) {\n\n            av_log(avctx, AV_LOG_ERROR, \"only YUV420 is supported\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_YUVJ444P:\n\n    case AV_PIX_FMT_YUV444P:\n\n        s->chroma_format = CHROMA_444;\n\n        break;\n\n    case AV_PIX_FMT_YUVJ422P:\n\n    case AV_PIX_FMT_YUV422P:\n\n        s->chroma_format = CHROMA_422;\n\n        break;\n\n    case AV_PIX_FMT_YUVJ420P:\n\n    case AV_PIX_FMT_YUV420P:\n\n    default:\n\n        s->chroma_format = CHROMA_420;\n\n        break;\n\n    }\n\n\n\n    s->bit_rate = avctx->bit_rate;\n\n    s->width    = avctx->width;\n\n    s->height   = avctx->height;\n\n    if (avctx->gop_size > 600 &&\n\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"keyframe interval too large!, reducing it from %d to %d\\n\",\n\n               avctx->gop_size, 600);\n\n        avctx->gop_size = 600;\n\n    }\n\n    s->gop_size     = avctx->gop_size;\n\n    s->avctx        = avctx;\n\n    s->flags        = avctx->flags;\n\n    s->flags2       = avctx->flags2;\n\n    if (avctx->max_b_frames > MAX_B_FRAMES) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Too many B-frames requested, maximum \"\n\n               \"is %d.\\n\", MAX_B_FRAMES);\n\n        avctx->max_b_frames = MAX_B_FRAMES;\n\n    }\n\n    s->max_b_frames = avctx->max_b_frames;\n\n    s->codec_id     = avctx->codec->id;\n\n    s->strict_std_compliance = avctx->strict_std_compliance;\n\n    s->quarter_sample     = (avctx->flags & CODEC_FLAG_QPEL) != 0;\n\n    s->mpeg_quant         = avctx->mpeg_quant;\n\n    s->rtp_mode           = !!avctx->rtp_payload_size;\n\n    s->intra_dc_precision = avctx->intra_dc_precision;\n\n    s->user_specified_pts = AV_NOPTS_VALUE;\n\n\n\n    if (s->gop_size <= 1) {\n\n        s->intra_only = 1;\n\n        s->gop_size   = 12;\n\n    } else {\n\n        s->intra_only = 0;\n\n    }\n\n\n\n    s->me_method = avctx->me_method;\n\n\n\n    /* Fixed QSCALE */\n\n    s->fixed_qscale = !!(avctx->flags & CODEC_FLAG_QSCALE);\n\n\n\n    s->adaptive_quant = (s->avctx->lumi_masking ||\n\n                         s->avctx->dark_masking ||\n\n                         s->avctx->temporal_cplx_masking ||\n\n                         s->avctx->spatial_cplx_masking  ||\n\n                         s->avctx->p_masking      ||\n\n                         s->avctx->border_masking ||\n\n                         (s->mpv_flags & FF_MPV_FLAG_QP_RD)) &&\n\n                        !s->fixed_qscale;\n\n\n\n    s->loop_filter      = !!(s->flags & CODEC_FLAG_LOOP_FILTER);\n\n\n\n    if (avctx->rc_max_rate && !avctx->rc_buffer_size) {\n\n        switch(avctx->codec_id) {\n\n        case AV_CODEC_ID_MPEG1VIDEO:\n\n        case AV_CODEC_ID_MPEG2VIDEO:\n\n            avctx->rc_buffer_size = FFMAX(avctx->rc_max_rate, 15000000) * 112L / 15000000 * 16384;\n\n            break;\n\n        case AV_CODEC_ID_MPEG4:\n\n        case AV_CODEC_ID_MSMPEG4V1:\n\n        case AV_CODEC_ID_MSMPEG4V2:\n\n        case AV_CODEC_ID_MSMPEG4V3:\n\n            if       (avctx->rc_max_rate >= 15000000) {\n\n                avctx->rc_buffer_size = 320 + (avctx->rc_max_rate - 15000000L) * (760-320) / (38400000 - 15000000);\n\n            } else if(avctx->rc_max_rate >=  2000000) {\n\n                avctx->rc_buffer_size =  80 + (avctx->rc_max_rate -  2000000L) * (320- 80) / (15000000 -  2000000);\n\n            } else if(avctx->rc_max_rate >=   384000) {\n\n                avctx->rc_buffer_size =  40 + (avctx->rc_max_rate -   384000L) * ( 80- 40) / ( 2000000 -   384000);\n\n            } else\n\n                avctx->rc_buffer_size = 40;\n\n            avctx->rc_buffer_size *= 16384;\n\n            break;\n\n        }\n\n        if (avctx->rc_buffer_size) {\n\n            av_log(avctx, AV_LOG_INFO, \"Automatically choosing VBV buffer size of %d kbyte\\n\", avctx->rc_buffer_size/8192);\n\n        }\n\n    }\n\n\n\n    if ((!avctx->rc_max_rate) != (!avctx->rc_buffer_size)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Either both buffer size and max rate or neither must be specified\\n\");\n\n        if (avctx->rc_max_rate && !avctx->rc_buffer_size)\n\n            return -1;\n\n    }\n\n\n\n    if (avctx->rc_min_rate && avctx->rc_max_rate != avctx->rc_min_rate) {\n\n        av_log(avctx, AV_LOG_INFO,\n\n               \"Warning min_rate > 0 but min_rate != max_rate isn't recommended!\\n\");\n\n    }\n\n\n\n    if (avctx->rc_min_rate && avctx->rc_min_rate > avctx->bit_rate) {\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate below min bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (avctx->rc_max_rate && avctx->rc_max_rate < avctx->bit_rate) {\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate above max bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (avctx->rc_max_rate &&\n\n        avctx->rc_max_rate == avctx->bit_rate &&\n\n        avctx->rc_max_rate != avctx->rc_min_rate) {\n\n        av_log(avctx, AV_LOG_INFO,\n\n               \"impossible bitrate constraints, this will fail\\n\");\n\n    }\n\n\n\n    if (avctx->rc_buffer_size &&\n\n        avctx->bit_rate * (int64_t)avctx->time_base.num >\n\n            avctx->rc_buffer_size * (int64_t)avctx->time_base.den) {\n\n        av_log(avctx, AV_LOG_ERROR, \"VBV buffer too small for bitrate\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (!s->fixed_qscale &&\n\n        avctx->bit_rate * av_q2d(avctx->time_base) >\n\n            avctx->bit_rate_tolerance) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"bitrate tolerance %d too small for bitrate %d\\n\", avctx->bit_rate_tolerance, avctx->bit_rate);\n\n        return -1;\n\n    }\n\n\n\n    if (s->avctx->rc_max_rate &&\n\n        s->avctx->rc_min_rate == s->avctx->rc_max_rate &&\n\n        (s->codec_id == AV_CODEC_ID_MPEG1VIDEO ||\n\n         s->codec_id == AV_CODEC_ID_MPEG2VIDEO) &&\n\n        90000LL * (avctx->rc_buffer_size - 1) >\n\n            s->avctx->rc_max_rate * 0xFFFFLL) {\n\n        av_log(avctx, AV_LOG_INFO,\n\n               \"Warning vbv_delay will be set to 0xFFFF (=VBR) as the \"\n\n               \"specified vbv buffer is too large for the given bitrate!\\n\");\n\n    }\n\n\n\n    if ((s->flags & CODEC_FLAG_4MV)  && s->codec_id != AV_CODEC_ID_MPEG4 &&\n\n        s->codec_id != AV_CODEC_ID_H263 && s->codec_id != AV_CODEC_ID_H263P &&\n\n        s->codec_id != AV_CODEC_ID_FLV1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"4MV not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->obmc && s->avctx->mb_decision != FF_MB_DECISION_SIMPLE) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"OBMC is only supported with simple mb decision\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->quarter_sample && s->codec_id != AV_CODEC_ID_MPEG4) {\n\n        av_log(avctx, AV_LOG_ERROR, \"qpel not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->max_b_frames                    &&\n\n        s->codec_id != AV_CODEC_ID_MPEG4      &&\n\n        s->codec_id != AV_CODEC_ID_MPEG1VIDEO &&\n\n        s->codec_id != AV_CODEC_ID_MPEG2VIDEO) {\n\n        av_log(avctx, AV_LOG_ERROR, \"b frames not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n    if (s->max_b_frames < 0) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"max b frames must be 0 or positive for mpegvideo based encoders\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((s->codec_id == AV_CODEC_ID_MPEG4 ||\n\n         s->codec_id == AV_CODEC_ID_H263  ||\n\n         s->codec_id == AV_CODEC_ID_H263P) &&\n\n        (avctx->sample_aspect_ratio.num > 255 ||\n\n         avctx->sample_aspect_ratio.den > 255)) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Invalid pixel aspect ratio %i/%i, limit is 255/255 reducing\\n\",\n\n               avctx->sample_aspect_ratio.num, avctx->sample_aspect_ratio.den);\n\n        av_reduce(&avctx->sample_aspect_ratio.num, &avctx->sample_aspect_ratio.den,\n\n                   avctx->sample_aspect_ratio.num,  avctx->sample_aspect_ratio.den, 255);\n\n    }\n\n\n\n    if ((s->codec_id == AV_CODEC_ID_H263  ||\n\n         s->codec_id == AV_CODEC_ID_H263P) &&\n\n        (avctx->width  > 2048 ||\n\n         avctx->height > 1152 )) {\n\n        av_log(avctx, AV_LOG_ERROR, \"H.263 does not support resolutions above 2048x1152\\n\");\n\n        return -1;\n\n    }\n\n    if ((s->codec_id == AV_CODEC_ID_H263  ||\n\n         s->codec_id == AV_CODEC_ID_H263P) &&\n\n        ((avctx->width &3) ||\n\n         (avctx->height&3) )) {\n\n        av_log(avctx, AV_LOG_ERROR, \"w/h must be a multiple of 4\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO &&\n\n        (avctx->width  > 4095 ||\n\n         avctx->height > 4095 )) {\n\n        av_log(avctx, AV_LOG_ERROR, \"MPEG-1 does not support resolutions above 4095x4095\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO &&\n\n        (avctx->width  > 16383 ||\n\n         avctx->height > 16383 )) {\n\n        av_log(avctx, AV_LOG_ERROR, \"MPEG-2 does not support resolutions above 16383x16383\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->codec_id == AV_CODEC_ID_RV10 &&\n\n        (avctx->width &15 ||\n\n         avctx->height&15 )) {\n\n        av_log(avctx, AV_LOG_ERROR, \"width and height must be a multiple of 16\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (s->codec_id == AV_CODEC_ID_RV20 &&\n\n        (avctx->width &3 ||\n\n         avctx->height&3 )) {\n\n        av_log(avctx, AV_LOG_ERROR, \"width and height must be a multiple of 4\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if ((s->codec_id == AV_CODEC_ID_WMV1 ||\n\n         s->codec_id == AV_CODEC_ID_WMV2) &&\n\n         avctx->width & 1) {\n\n         av_log(avctx, AV_LOG_ERROR, \"width must be multiple of 2\\n\");\n\n         return -1;\n\n    }\n\n\n\n    if ((s->flags & (CODEC_FLAG_INTERLACED_DCT | CODEC_FLAG_INTERLACED_ME)) &&\n\n        s->codec_id != AV_CODEC_ID_MPEG4 && s->codec_id != AV_CODEC_ID_MPEG2VIDEO) {\n\n        av_log(avctx, AV_LOG_ERROR, \"interlacing not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    // FIXME mpeg2 uses that too\n\n    if (s->mpeg_quant && (   s->codec_id != AV_CODEC_ID_MPEG4\n\n                          && s->codec_id != AV_CODEC_ID_MPEG2VIDEO)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"mpeg2 style quantization not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((s->mpv_flags & FF_MPV_FLAG_CBP_RD) && !avctx->trellis) {\n\n        av_log(avctx, AV_LOG_ERROR, \"CBP RD needs trellis quant\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((s->mpv_flags & FF_MPV_FLAG_QP_RD) &&\n\n        s->avctx->mb_decision != FF_MB_DECISION_RD) {\n\n        av_log(avctx, AV_LOG_ERROR, \"QP RD needs mbd=2\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->avctx->scenechange_threshold < 1000000000 &&\n\n        (s->flags & CODEC_FLAG_CLOSED_GOP)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"closed gop with scene change detection are not supported yet, \"\n\n               \"set threshold to 1000000000\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->flags & CODEC_FLAG_LOW_DELAY) {\n\n        if (s->codec_id != AV_CODEC_ID_MPEG2VIDEO) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                  \"low delay forcing is only available for mpeg2\\n\");\n\n            return -1;\n\n        }\n\n        if (s->max_b_frames != 0) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"b frames cannot be used with low delay\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (s->q_scale_type == 1) {\n\n        if (avctx->qmax > 12) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"non linear quant only supports qmax <= 12 currently\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (s->avctx->thread_count > 1         &&\n\n        s->codec_id != AV_CODEC_ID_MPEG4      &&\n\n        s->codec_id != AV_CODEC_ID_MPEG1VIDEO &&\n\n        s->codec_id != AV_CODEC_ID_MPEG2VIDEO &&\n\n        s->codec_id != AV_CODEC_ID_MJPEG      &&\n\n        (s->codec_id != AV_CODEC_ID_H263P)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"multi threaded encoding not supported by codec\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->avctx->thread_count < 1) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"automatic thread number detection not supported by codec, \"\n\n               \"patch welcome\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (s->avctx->slices > 1 || s->avctx->thread_count > 1)\n\n        s->rtp_mode = 1;\n\n\n\n    if (s->avctx->thread_count > 1 && s->codec_id == AV_CODEC_ID_H263P)\n\n        s->h263_slice_structured = 1;\n\n\n\n    if (!avctx->time_base.den || !avctx->time_base.num) {\n\n        av_log(avctx, AV_LOG_ERROR, \"framerate not set\\n\");\n\n        return -1;\n\n    }\n\n\n\n    i = (INT_MAX / 2 + 128) >> 8;\n\n    if (avctx->mb_threshold >= i) {\n\n        av_log(avctx, AV_LOG_ERROR, \"mb_threshold too large, max is %d\\n\",\n\n               i - 1);\n\n        return -1;\n\n    }\n\n\n\n    if (avctx->b_frame_strategy && (avctx->flags & CODEC_FLAG_PASS2)) {\n\n        av_log(avctx, AV_LOG_INFO,\n\n               \"notice: b_frame_strategy only affects the first pass\\n\");\n\n        avctx->b_frame_strategy = 0;\n\n    }\n\n\n\n    i = av_gcd(avctx->time_base.den, avctx->time_base.num);\n\n    if (i > 1) {\n\n        av_log(avctx, AV_LOG_INFO, \"removing common factors from framerate\\n\");\n\n        avctx->time_base.den /= i;\n\n        avctx->time_base.num /= i;\n\n        //return -1;\n\n    }\n\n\n\n    if (s->mpeg_quant || s->codec_id == AV_CODEC_ID_MPEG1VIDEO || s->codec_id == AV_CODEC_ID_MPEG2VIDEO || s->codec_id == AV_CODEC_ID_MJPEG || s->codec_id==AV_CODEC_ID_AMV) {\n\n        // (a + x * 3 / 8) / x\n\n        s->intra_quant_bias = 3 << (QUANT_BIAS_SHIFT - 3);\n\n        s->inter_quant_bias = 0;\n\n    } else {\n\n        s->intra_quant_bias = 0;\n\n        // (a - x / 4) / x\n\n        s->inter_quant_bias = -(1 << (QUANT_BIAS_SHIFT - 2));\n\n    }\n\n\n\n    if (avctx->qmin > avctx->qmax || avctx->qmin <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"qmin and or qmax are invalid, they must be 0 < min <= max\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (avctx->intra_quant_bias != FF_DEFAULT_QUANT_BIAS)\n\n        s->intra_quant_bias = avctx->intra_quant_bias;\n\n    if (avctx->inter_quant_bias != FF_DEFAULT_QUANT_BIAS)\n\n        s->inter_quant_bias = avctx->inter_quant_bias;\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"intra_quant_bias = %d inter_quant_bias = %d\\n\",s->intra_quant_bias,s->inter_quant_bias);\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_MPEG4 &&\n\n        s->avctx->time_base.den > (1 << 16) - 1) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"timebase %d/%d not supported by MPEG 4 standard, \"\n\n               \"the maximum admitted value for the timebase denominator \"\n\n               \"is %d\\n\", s->avctx->time_base.num, s->avctx->time_base.den,\n\n               (1 << 16) - 1);\n\n        return -1;\n\n    }\n\n    s->time_increment_bits = av_log2(s->avctx->time_base.den - 1) + 1;\n\n\n\n    switch (avctx->codec->id) {\n\n    case AV_CODEC_ID_MPEG1VIDEO:\n\n        s->out_format = FMT_MPEG1;\n\n        s->low_delay  = !!(s->flags & CODEC_FLAG_LOW_DELAY);\n\n        avctx->delay  = s->low_delay ? 0 : (s->max_b_frames + 1);\n\n        break;\n\n    case AV_CODEC_ID_MPEG2VIDEO:\n\n        s->out_format = FMT_MPEG1;\n\n        s->low_delay  = !!(s->flags & CODEC_FLAG_LOW_DELAY);\n\n        avctx->delay  = s->low_delay ? 0 : (s->max_b_frames + 1);\n\n        s->rtp_mode   = 1;\n\n        break;\n\n    case AV_CODEC_ID_MJPEG:\n\n    case AV_CODEC_ID_AMV:\n\n        s->out_format = FMT_MJPEG;\n\n        s->intra_only = 1; /* force intra only for jpeg */\n\n        if (!CONFIG_MJPEG_ENCODER ||\n\n            ff_mjpeg_encode_init(s) < 0)\n\n            return -1;\n\n        avctx->delay = 0;\n\n        s->low_delay = 1;\n\n        break;\n\n    case AV_CODEC_ID_H261:\n\n        if (!CONFIG_H261_ENCODER)\n\n            return -1;\n\n        if (ff_h261_get_picture_format(s->width, s->height) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"The specified picture size of %dx%d is not valid for the \"\n\n                   \"H.261 codec.\\nValid sizes are 176x144, 352x288\\n\",\n\n                    s->width, s->height);\n\n            return -1;\n\n        }\n\n        s->out_format = FMT_H261;\n\n        avctx->delay  = 0;\n\n        s->low_delay  = 1;\n\n        break;\n\n    case AV_CODEC_ID_H263:\n\n        if (!CONFIG_H263_ENCODER)\n\n            return -1;\n\n        if (ff_match_2uint16(ff_h263_format, FF_ARRAY_ELEMS(ff_h263_format),\n\n                             s->width, s->height) == 8) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"The specified picture size of %dx%d is not valid for \"\n\n                   \"the H.263 codec.\\nValid sizes are 128x96, 176x144, \"\n\n                   \"352x288, 704x576, and 1408x1152. \"\n\n                   \"Try H.263+.\\n\", s->width, s->height);\n\n            return -1;\n\n        }\n\n        s->out_format = FMT_H263;\n\n        avctx->delay  = 0;\n\n        s->low_delay  = 1;\n\n        break;\n\n    case AV_CODEC_ID_H263P:\n\n        s->out_format = FMT_H263;\n\n        s->h263_plus  = 1;\n\n        /* Fx */\n\n        s->h263_aic        = (avctx->flags & CODEC_FLAG_AC_PRED) ? 1 : 0;\n\n        s->modified_quant  = s->h263_aic;\n\n        s->loop_filter     = (avctx->flags & CODEC_FLAG_LOOP_FILTER) ? 1 : 0;\n\n        s->unrestricted_mv = s->obmc || s->loop_filter || s->umvplus;\n\n\n\n        /* /Fx */\n\n        /* These are just to be sure */\n\n        avctx->delay = 0;\n\n        s->low_delay = 1;\n\n        break;\n\n    case AV_CODEC_ID_FLV1:\n\n        s->out_format      = FMT_H263;\n\n        s->h263_flv        = 2; /* format = 1; 11-bit codes */\n\n        s->unrestricted_mv = 1;\n\n        s->rtp_mode  = 0; /* don't allow GOB */\n\n        avctx->delay = 0;\n\n        s->low_delay = 1;\n\n        break;\n\n    case AV_CODEC_ID_RV10:\n\n        s->out_format = FMT_H263;\n\n        avctx->delay  = 0;\n\n        s->low_delay  = 1;\n\n        break;\n\n    case AV_CODEC_ID_RV20:\n\n        s->out_format      = FMT_H263;\n\n        avctx->delay       = 0;\n\n        s->low_delay       = 1;\n\n        s->modified_quant  = 1;\n\n        s->h263_aic        = 1;\n\n        s->h263_plus       = 1;\n\n        s->loop_filter     = 1;\n\n        s->unrestricted_mv = 0;\n\n        break;\n\n    case AV_CODEC_ID_MPEG4:\n\n        s->out_format      = FMT_H263;\n\n        s->h263_pred       = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->low_delay       = s->max_b_frames ? 0 : 1;\n\n        avctx->delay       = s->low_delay ? 0 : (s->max_b_frames + 1);\n\n        break;\n\n    case AV_CODEC_ID_MSMPEG4V2:\n\n        s->out_format      = FMT_H263;\n\n        s->h263_pred       = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version = 2;\n\n        avctx->delay       = 0;\n\n        s->low_delay       = 1;\n\n        break;\n\n    case AV_CODEC_ID_MSMPEG4V3:\n\n        s->out_format        = FMT_H263;\n\n        s->h263_pred         = 1;\n\n        s->unrestricted_mv   = 1;\n\n        s->msmpeg4_version   = 3;\n\n        s->flipflop_rounding = 1;\n\n        avctx->delay         = 0;\n\n        s->low_delay         = 1;\n\n        break;\n\n    case AV_CODEC_ID_WMV1:\n\n        s->out_format        = FMT_H263;\n\n        s->h263_pred         = 1;\n\n        s->unrestricted_mv   = 1;\n\n        s->msmpeg4_version   = 4;\n\n        s->flipflop_rounding = 1;\n\n        avctx->delay         = 0;\n\n        s->low_delay         = 1;\n\n        break;\n\n    case AV_CODEC_ID_WMV2:\n\n        s->out_format        = FMT_H263;\n\n        s->h263_pred         = 1;\n\n        s->unrestricted_mv   = 1;\n\n        s->msmpeg4_version   = 5;\n\n        s->flipflop_rounding = 1;\n\n        avctx->delay         = 0;\n\n        s->low_delay         = 1;\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    avctx->has_b_frames = !s->low_delay;\n\n\n\n    s->encoding = 1;\n\n\n\n    s->progressive_frame    =\n\n    s->progressive_sequence = !(avctx->flags & (CODEC_FLAG_INTERLACED_DCT |\n\n                                                CODEC_FLAG_INTERLACED_ME) ||\n\n                                s->alternate_scan);\n\n\n\n    /* init */\n\n    if (ff_MPV_common_init(s) < 0)\n\n        return -1;\n\n\n\n    s->avctx->coded_frame = s->current_picture.f;\n\n\n\n    if (s->msmpeg4_version) {\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->ac_stats,\n\n                          2 * 2 * (MAX_LEVEL + 1) *\n\n                          (MAX_RUN + 1) * 2 * sizeof(int), fail);\n\n    }\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->avctx->stats_out, 256, fail);\n\n\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->q_intra_matrix,   64 * 32 * sizeof(int), fail);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->q_chroma_intra_matrix, 64 * 32 * sizeof(int), fail);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->q_inter_matrix,   64 * 32 * sizeof(int), fail);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->q_intra_matrix16, 64 * 32 * 2 * sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->q_chroma_intra_matrix16, 64 * 32 * 2 * sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->q_inter_matrix16, 64 * 32 * 2 * sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->input_picture,\n\n                      MAX_PICTURE_COUNT * sizeof(Picture *), fail);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->reordered_input_picture,\n\n                      MAX_PICTURE_COUNT * sizeof(Picture *), fail);\n\n\n\n    if (s->avctx->noise_reduction) {\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->dct_offset,\n\n                          2 * 64 * sizeof(uint16_t), fail);\n\n    }\n\n\n\n    ff_dct_encode_init(s);\n\n\n\n    if ((CONFIG_H263P_ENCODER || CONFIG_RV20_ENCODER) && s->modified_quant)\n\n        s->chroma_qscale_table = ff_h263_chroma_qscale_table;\n\n\n\n    s->quant_precision = 5;\n\n\n\n    ff_set_cmp(&s->dsp, s->dsp.ildct_cmp, s->avctx->ildct_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.frame_skip_cmp, s->avctx->frame_skip_cmp);\n\n\n\n    if (CONFIG_H261_ENCODER && s->out_format == FMT_H261)\n\n        ff_h261_encode_init(s);\n\n    if (CONFIG_H263_ENCODER && s->out_format == FMT_H263)\n\n        ff_h263_encode_init(s);\n\n    if (CONFIG_MSMPEG4_ENCODER && s->msmpeg4_version)\n\n        ff_msmpeg4_encode_init(s);\n\n    if ((CONFIG_MPEG1VIDEO_ENCODER || CONFIG_MPEG2VIDEO_ENCODER)\n\n        && s->out_format == FMT_MPEG1)\n\n        ff_mpeg1_encode_init(s);\n\n\n\n    /* init q matrix */\n\n    for (i = 0; i < 64; i++) {\n\n        int j = s->dsp.idct_permutation[i];\n\n        if (CONFIG_MPEG4_ENCODER && s->codec_id == AV_CODEC_ID_MPEG4 &&\n\n            s->mpeg_quant) {\n\n            s->intra_matrix[j] = ff_mpeg4_default_intra_matrix[i];\n\n            s->inter_matrix[j] = ff_mpeg4_default_non_intra_matrix[i];\n\n        } else if (s->out_format == FMT_H263 || s->out_format == FMT_H261) {\n\n            s->intra_matrix[j] =\n\n            s->inter_matrix[j] = ff_mpeg1_default_non_intra_matrix[i];\n\n        } else {\n\n            /* mpeg1/2 */\n\n            s->intra_matrix[j] = ff_mpeg1_default_intra_matrix[i];\n\n            s->inter_matrix[j] = ff_mpeg1_default_non_intra_matrix[i];\n\n        }\n\n        if (s->avctx->intra_matrix)\n\n            s->intra_matrix[j] = s->avctx->intra_matrix[i];\n\n        if (s->avctx->inter_matrix)\n\n            s->inter_matrix[j] = s->avctx->inter_matrix[i];\n\n    }\n\n\n\n    /* precompute matrix */\n\n    /* for mjpeg, we do include qscale in the matrix */\n\n    if (s->out_format != FMT_MJPEG) {\n\n        ff_convert_matrix(&s->dsp, s->q_intra_matrix, s->q_intra_matrix16,\n\n                          s->intra_matrix, s->intra_quant_bias, avctx->qmin,\n\n                          31, 1);\n\n        ff_convert_matrix(&s->dsp, s->q_inter_matrix, s->q_inter_matrix16,\n\n                          s->inter_matrix, s->inter_quant_bias, avctx->qmin,\n\n                          31, 0);\n\n    }\n\n\n\n    if (ff_rate_control_init(s) < 0)\n\n        return -1;\n\n\n\n#if FF_API_ERROR_RATE\n\n    FF_DISABLE_DEPRECATION_WARNINGS\n\n    if (avctx->error_rate)\n\n        s->error_rate = avctx->error_rate;\n\n    FF_ENABLE_DEPRECATION_WARNINGS;\n\n#endif\n\n\n\n    if (avctx->b_frame_strategy == 2) {\n\n        for (i = 0; i < s->max_b_frames + 2; i++) {\n\n            s->tmp_frames[i] = av_frame_alloc();\n\n            if (!s->tmp_frames[i])\n\n                return AVERROR(ENOMEM);\n\n\n\n            s->tmp_frames[i]->format = AV_PIX_FMT_YUV420P;\n\n            s->tmp_frames[i]->width  = s->width  >> avctx->brd_scale;\n\n            s->tmp_frames[i]->height = s->height >> avctx->brd_scale;\n\n\n\n            ret = av_frame_get_buffer(s->tmp_frames[i], 32);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n    }\n\n\n\n    return 0;\n\nfail:\n\n    ff_MPV_encode_end(avctx);\n\n    return AVERROR_UNKNOWN;\n\n}\n", "idx": 19250, "_split": "valid", "_hash": "28e4a63e41c0f6d57170806847bcc12d"}
{"project": "FFmpeg", "commit_id": "83548fe894cdb455cc127f754d09905b6d23c173", "target": 0, "func": "static int au_write_trailer(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    int64_t file_size;\n\n\n\n    if (s->pb->seekable) {\n\n        /* update file size */\n\n        file_size = avio_tell(pb);\n\n        avio_seek(pb, 8, SEEK_SET);\n\n        avio_wb32(pb, (uint32_t)(file_size - 24));\n\n        avio_seek(pb, file_size, SEEK_SET);\n\n        avio_flush(pb);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 19282, "_split": "valid", "_hash": "8f0c13aebc5d43510248adcd6a7f1b68"}
{"project": "FFmpeg", "commit_id": "cdfc38f43b94e8ec3a9be10de2767778946d6eb5", "target": 1, "func": "static int xa_read_packet(AVFormatContext *s,\n\n                          AVPacket *pkt)\n\n{\n\n    MaxisXADemuxContext *xa = s->priv_data;\n\n    AVStream *st = s->streams[0];\n\n    ByteIOContext *pb = s->pb;\n\n    unsigned int packet_size;\n\n    int ret;\n\n\n\n    if(xa->sent_bytes > xa->out_size)\n\n        return AVERROR(EIO);\n\n    /* 1 byte header and 14 bytes worth of samples * number channels per block */\n\n    packet_size = 15*st->codec->channels;\n\n\n\n    ret = av_get_packet(pb, pkt, packet_size);\n\n    if(ret != packet_size)\n\n        return AVERROR(EIO);\n\n\n\n    pkt->stream_index = st->index;\n\n    xa->sent_bytes += packet_size;\n\n    pkt->pts = xa->audio_frame_counter;\n\n    /* 14 bytes Samples per channel with 2 samples per byte */\n\n    xa->audio_frame_counter += 28 * st->codec->channels;\n\n\n\n    return ret;\n\n}\n", "idx": 19361, "_split": "valid", "_hash": "30b3a6db7e972d8e1a6fd7e4e54dafc5"}
{"project": "FFmpeg", "commit_id": "dc4a621e9ceb81c4c019aa7656c2bfbec2df18d5", "target": 0, "func": "static int unpack_superblocks(Vp3DecodeContext *s, GetBitContext *gb)\n\n{\n\n    int superblock_starts[3] = {\n\n        0, s->u_superblock_start, s->v_superblock_start\n\n    };\n\n    int bit = 0;\n\n    int current_superblock = 0;\n\n    int current_run = 0;\n\n    int num_partial_superblocks = 0;\n\n\n\n    int i, j;\n\n    int current_fragment;\n\n    int plane;\n\n\n\n    if (s->keyframe) {\n\n        memset(s->superblock_coding, SB_FULLY_CODED, s->superblock_count);\n\n    } else {\n\n        /* unpack the list of partially-coded superblocks */\n\n        bit         = get_bits1(gb) ^ 1;\n\n        current_run = 0;\n\n\n\n        while (current_superblock < s->superblock_count && get_bits_left(gb) > 0) {\n\n            if (s->theora && current_run == MAXIMUM_LONG_BIT_RUN)\n\n                bit = get_bits1(gb);\n\n            else\n\n                bit ^= 1;\n\n\n\n            current_run = get_vlc2(gb, s->superblock_run_length_vlc.table,\n\n                                   6, 2) + 1;\n\n            if (current_run == 34)\n\n                current_run += get_bits(gb, 12);\n\n\n\n            if (current_superblock + current_run > s->superblock_count) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"Invalid partially coded superblock run length\\n\");\n\n                return -1;\n\n            }\n\n\n\n            memset(s->superblock_coding + current_superblock, bit, current_run);\n\n\n\n            current_superblock += current_run;\n\n            if (bit)\n\n                num_partial_superblocks += current_run;\n\n        }\n\n\n\n        /* unpack the list of fully coded superblocks if any of the blocks were\n\n         * not marked as partially coded in the previous step */\n\n        if (num_partial_superblocks < s->superblock_count) {\n\n            int superblocks_decoded = 0;\n\n\n\n            current_superblock = 0;\n\n            bit                = get_bits1(gb) ^ 1;\n\n            current_run        = 0;\n\n\n\n            while (superblocks_decoded < s->superblock_count - num_partial_superblocks &&\n\n                   get_bits_left(gb) > 0) {\n\n                if (s->theora && current_run == MAXIMUM_LONG_BIT_RUN)\n\n                    bit = get_bits1(gb);\n\n                else\n\n                    bit ^= 1;\n\n\n\n                current_run = get_vlc2(gb, s->superblock_run_length_vlc.table,\n\n                                       6, 2) + 1;\n\n                if (current_run == 34)\n\n                    current_run += get_bits(gb, 12);\n\n\n\n                for (j = 0; j < current_run; current_superblock++) {\n\n                    if (current_superblock >= s->superblock_count) {\n\n                        av_log(s->avctx, AV_LOG_ERROR,\n\n                               \"Invalid fully coded superblock run length\\n\");\n\n                        return -1;\n\n                    }\n\n\n\n                    /* skip any superblocks already marked as partially coded */\n\n                    if (s->superblock_coding[current_superblock] == SB_NOT_CODED) {\n\n                        s->superblock_coding[current_superblock] = 2 * bit;\n\n                        j++;\n\n                    }\n\n                }\n\n                superblocks_decoded += current_run;\n\n            }\n\n        }\n\n\n\n        /* if there were partial blocks, initialize bitstream for\n\n         * unpacking fragment codings */\n\n        if (num_partial_superblocks) {\n\n            current_run = 0;\n\n            bit         = get_bits1(gb);\n\n            /* toggle the bit because as soon as the first run length is\n\n             * fetched the bit will be toggled again */\n\n            bit ^= 1;\n\n        }\n\n    }\n\n\n\n    /* figure out which fragments are coded; iterate through each\n\n     * superblock (all planes) */\n\n    s->total_num_coded_frags = 0;\n\n    memset(s->macroblock_coding, MODE_COPY, s->macroblock_count);\n\n\n\n    for (plane = 0; plane < 3; plane++) {\n\n        int sb_start = superblock_starts[plane];\n\n        int sb_end   = sb_start + (plane ? s->c_superblock_count\n\n                                         : s->y_superblock_count);\n\n        int num_coded_frags = 0;\n\n\n\n        for (i = sb_start; i < sb_end && get_bits_left(gb) > 0; i++) {\n\n            /* iterate through all 16 fragments in a superblock */\n\n            for (j = 0; j < 16; j++) {\n\n                /* if the fragment is in bounds, check its coding status */\n\n                current_fragment = s->superblock_fragments[i * 16 + j];\n\n                if (current_fragment != -1) {\n\n                    int coded = s->superblock_coding[i];\n\n\n\n                    if (s->superblock_coding[i] == SB_PARTIALLY_CODED) {\n\n                        /* fragment may or may not be coded; this is the case\n\n                         * that cares about the fragment coding runs */\n\n                        if (current_run-- == 0) {\n\n                            bit        ^= 1;\n\n                            current_run = get_vlc2(gb, s->fragment_run_length_vlc.table, 5, 2);\n\n                        }\n\n                        coded = bit;\n\n                    }\n\n\n\n                    if (coded) {\n\n                        /* default mode; actual mode will be decoded in\n\n                         * the next phase */\n\n                        s->all_fragments[current_fragment].coding_method =\n\n                            MODE_INTER_NO_MV;\n\n                        s->coded_fragment_list[plane][num_coded_frags++] =\n\n                            current_fragment;\n\n                    } else {\n\n                        /* not coded; copy this fragment from the prior frame */\n\n                        s->all_fragments[current_fragment].coding_method =\n\n                            MODE_COPY;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        s->total_num_coded_frags += num_coded_frags;\n\n        for (i = 0; i < 64; i++)\n\n            s->num_coded_frags[plane][i] = num_coded_frags;\n\n        if (plane < 2)\n\n            s->coded_fragment_list[plane + 1] = s->coded_fragment_list[plane] +\n\n                                                num_coded_frags;\n\n    }\n\n    return 0;\n\n}\n", "idx": 19371, "_split": "valid", "_hash": "4a711487bf094e31eaf72053bde2d4d2"}
{"project": "FFmpeg", "commit_id": "0e6c8532215790bbe560a9eea4f3cc82bb55cf92", "target": 0, "func": "static int init_video_param(AVCodecContext *avctx, QSVEncContext *q)\n\n{\n\n    float quant;\n\n    int ret;\n\n\n\n    ret = ff_qsv_codec_id_to_mfx(avctx->codec_id);\n\n    if (ret < 0)\n\n        return AVERROR_BUG;\n\n    q->param.mfx.CodecId = ret;\n\n\n\n    q->width_align = avctx->codec_id == AV_CODEC_ID_HEVC ? 32 : 16;\n\n\n\n    if (avctx->level > 0)\n\n        q->param.mfx.CodecLevel = avctx->level;\n\n\n\n    q->param.mfx.CodecProfile       = q->profile;\n\n    q->param.mfx.TargetUsage        = q->preset;\n\n    q->param.mfx.GopPicSize         = FFMAX(0, avctx->gop_size);\n\n    q->param.mfx.GopRefDist         = FFMAX(-1, avctx->max_b_frames) + 1;\n\n    q->param.mfx.GopOptFlag         = avctx->flags & AV_CODEC_FLAG_CLOSED_GOP ?\n\n                                      MFX_GOP_CLOSED : 0;\n\n    q->param.mfx.IdrInterval        = q->idr_interval;\n\n    q->param.mfx.NumSlice           = avctx->slices;\n\n    q->param.mfx.NumRefFrame        = FFMAX(0, avctx->refs);\n\n    q->param.mfx.EncodedOrder       = 0;\n\n    q->param.mfx.BufferSizeInKB     = 0;\n\n\n\n    q->param.mfx.FrameInfo.FourCC         = MFX_FOURCC_NV12;\n\n    q->param.mfx.FrameInfo.Width          = FFALIGN(avctx->width, q->width_align);\n\n    q->param.mfx.FrameInfo.Height         = FFALIGN(avctx->height, 32);\n\n    q->param.mfx.FrameInfo.CropX          = 0;\n\n    q->param.mfx.FrameInfo.CropY          = 0;\n\n    q->param.mfx.FrameInfo.CropW          = avctx->width;\n\n    q->param.mfx.FrameInfo.CropH          = avctx->height;\n\n    q->param.mfx.FrameInfo.AspectRatioW   = avctx->sample_aspect_ratio.num;\n\n    q->param.mfx.FrameInfo.AspectRatioH   = avctx->sample_aspect_ratio.den;\n\n    q->param.mfx.FrameInfo.PicStruct      = MFX_PICSTRUCT_PROGRESSIVE;\n\n    q->param.mfx.FrameInfo.ChromaFormat   = MFX_CHROMAFORMAT_YUV420;\n\n    q->param.mfx.FrameInfo.BitDepthLuma   = 8;\n\n    q->param.mfx.FrameInfo.BitDepthChroma = 8;\n\n\n\n    if (avctx->framerate.den > 0 && avctx->framerate.num > 0) {\n\n        q->param.mfx.FrameInfo.FrameRateExtN = avctx->framerate.num;\n\n        q->param.mfx.FrameInfo.FrameRateExtD = avctx->framerate.den;\n\n    } else {\n\n        q->param.mfx.FrameInfo.FrameRateExtN  = avctx->time_base.den;\n\n        q->param.mfx.FrameInfo.FrameRateExtD  = avctx->time_base.num;\n\n    }\n\n\n\n    ret = select_rc_mode(avctx, q);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    switch (q->param.mfx.RateControlMethod) {\n\n    case MFX_RATECONTROL_CBR:\n\n    case MFX_RATECONTROL_VBR:\n\n#if QSV_HAVE_VCM\n\n    case MFX_RATECONTROL_VCM:\n\n#endif\n\n        q->param.mfx.InitialDelayInKB = avctx->rc_initial_buffer_occupancy / 1000;\n\n        q->param.mfx.TargetKbps       = avctx->bit_rate / 1000;\n\n        q->param.mfx.MaxKbps          = avctx->rc_max_rate / 1000;\n\n        break;\n\n    case MFX_RATECONTROL_CQP:\n\n        quant = avctx->global_quality / FF_QP2LAMBDA;\n\n\n\n        q->param.mfx.QPI = av_clip(quant * fabs(avctx->i_quant_factor) + avctx->i_quant_offset, 0, 51);\n\n        q->param.mfx.QPP = av_clip(quant, 0, 51);\n\n        q->param.mfx.QPB = av_clip(quant * fabs(avctx->b_quant_factor) + avctx->b_quant_offset, 0, 51);\n\n\n\n        break;\n\n    case MFX_RATECONTROL_AVBR:\n\n        q->param.mfx.TargetKbps  = avctx->bit_rate / 1000;\n\n        q->param.mfx.Convergence = q->avbr_convergence;\n\n        q->param.mfx.Accuracy    = q->avbr_accuracy;\n\n        break;\n\n#if QSV_HAVE_LA\n\n    case MFX_RATECONTROL_LA:\n\n        q->param.mfx.TargetKbps  = avctx->bit_rate / 1000;\n\n        q->extco2.LookAheadDepth = q->la_depth;\n\n        break;\n\n#if QSV_HAVE_ICQ\n\n    case MFX_RATECONTROL_LA_ICQ:\n\n        q->extco2.LookAheadDepth = q->la_depth;\n\n    case MFX_RATECONTROL_ICQ:\n\n        q->param.mfx.ICQQuality  = avctx->global_quality;\n\n        break;\n\n#endif\n\n#endif\n\n    }\n\n\n\n    // the HEVC encoder plugin currently fails if coding options\n\n    // are provided\n\n    if (avctx->codec_id != AV_CODEC_ID_HEVC) {\n\n        q->extco.Header.BufferId      = MFX_EXTBUFF_CODING_OPTION;\n\n        q->extco.Header.BufferSz      = sizeof(q->extco);\n\n        q->extco.CAVLC                = avctx->coder_type == FF_CODER_TYPE_VLC ?\n\n                                        MFX_CODINGOPTION_ON : MFX_CODINGOPTION_UNKNOWN;\n\n\n\n        if (q->rdo >= 0)\n\n            q->extco.RateDistortionOpt = q->rdo > 0 ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n\n\n        if (avctx->codec_id == AV_CODEC_ID_H264) {\n\n            if (avctx->strict_std_compliance != FF_COMPLIANCE_NORMAL)\n\n                q->extco.NalHrdConformance = avctx->strict_std_compliance > FF_COMPLIANCE_NORMAL ?\n\n                                             MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n\n\n            if (q->single_sei_nal_unit >= 0)\n\n                q->extco.SingleSeiNalUnit = q->single_sei_nal_unit ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n            if (q->recovery_point_sei >= 0)\n\n                q->extco.RecoveryPointSEI = q->recovery_point_sei ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n            q->extco.MaxDecFrameBuffering = q->max_dec_frame_buffering;\n\n        }\n\n\n\n        q->extparam_internal[q->nb_extparam_internal++] = (mfxExtBuffer *)&q->extco;\n\n\n\n#if QSV_HAVE_CO2\n\n        if (avctx->codec_id == AV_CODEC_ID_H264) {\n\n            q->extco2.Header.BufferId     = MFX_EXTBUFF_CODING_OPTION2;\n\n            q->extco2.Header.BufferSz     = sizeof(q->extco2);\n\n\n\n            if (q->int_ref_type >= 0)\n\n                q->extco2.IntRefType = q->int_ref_type;\n\n            if (q->int_ref_cycle_size >= 0)\n\n                q->extco2.IntRefCycleSize = q->int_ref_cycle_size;\n\n            if (q->int_ref_qp_delta != INT16_MIN)\n\n                q->extco2.IntRefQPDelta = q->int_ref_qp_delta;\n\n\n\n            if (q->bitrate_limit >= 0)\n\n                q->extco2.BitrateLimit = q->bitrate_limit ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n            if (q->mbbrc >= 0)\n\n                q->extco2.MBBRC = q->mbbrc ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n            if (q->extbrc >= 0)\n\n                q->extco2.ExtBRC = q->extbrc ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n\n\n            if (q->max_frame_size >= 0)\n\n                q->extco2.MaxFrameSize = q->max_frame_size;\n\n#if QSV_HAVE_MAX_SLICE_SIZE\n\n            if (q->max_slice_size >= 0)\n\n                q->extco2.MaxSliceSize = q->max_slice_size;\n\n#endif\n\n\n\n#if QSV_HAVE_TRELLIS\n\n            q->extco2.Trellis = q->trellis;\n\n#endif\n\n\n\n#if QSV_HAVE_BREF_TYPE\n\n            if (avctx->b_frame_strategy >= 0)\n\n                q->extco2.BRefType = avctx->b_frame_strategy ? MFX_B_REF_PYRAMID : MFX_B_REF_OFF;\n\n            if (q->adaptive_i >= 0)\n\n                q->extco2.AdaptiveI = q->adaptive_i ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n            if (q->adaptive_b >= 0)\n\n                q->extco2.AdaptiveB = q->adaptive_b ? MFX_CODINGOPTION_ON : MFX_CODINGOPTION_OFF;\n\n#endif\n\n\n\n            q->extparam_internal[q->nb_extparam_internal++] = (mfxExtBuffer *)&q->extco2;\n\n        }\n\n#endif\n\n    }\n\n\n\n    if (!rc_supported(q)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Selected ratecontrol mode is not supported by the QSV \"\n\n               \"runtime. Choose a different mode.\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 19406, "_split": "valid", "_hash": "1f40654c625a1ff9a71c20958f82d50d"}
{"project": "FFmpeg", "commit_id": "0a82f5275f719e6e369a807720a2c3603aa0ddd9", "target": 1, "func": "static void lag_pred_line(LagarithContext *l, uint8_t *buf,\n\n                          int width, int stride, int line)\n\n{\n\n    int L, TL;\n\n\n\n    /* Left pixel is actually prev_row[width] */\n\n    L = buf[width - stride - 1];\n\n    if (!line) {\n\n        /* Left prediction only for first line */\n\n        L = l->dsp.add_hfyu_left_prediction(buf + 1, buf + 1,\n\n                                            width - 1, buf[0]);\n\n        return;\n\n    } else if (line == 1) {\n\n        /* Second line, left predict first pixel, the rest of the line is median predicted\n\n         * NOTE: In the case of RGB this pixel is top predicted */\n\n        TL = l->avctx->pix_fmt == PIX_FMT_YUV420P ? buf[-stride] : L;\n\n    } else {\n\n        /* Top left is 2 rows back, last pixel */\n\n        TL = buf[width - (2 * stride) - 1];\n\n    }\n\n\n\n    add_lag_median_prediction(buf, buf - stride, buf,\n\n                              width, &L, &TL);\n\n}\n", "idx": 19414, "_split": "valid", "_hash": "3addf33e5286d9490da088004dd539a8"}
{"project": "FFmpeg", "commit_id": "b9de1303a6414174ab2f3bccefa801bfabcf0f88", "target": 1, "func": "static void ff_acelp_interpolatef_mips(float *out, const float *in,\n\n                           const float *filter_coeffs, int precision,\n\n                           int frac_pos, int filter_length, int length)\n\n{\n\n    int n, i;\n\n    int prec = precision * 4;\n\n    int fc_offset = precision - frac_pos;\n\n    float in_val_p, in_val_m, fc_val_p, fc_val_m;\n\n\n\n    for (n = 0; n < length; n++) {\n\n        /**\n\n        * four pointers are defined in order to minimize number of\n\n        * computations done in inner loop\n\n        */\n\n        const float *p_in_p = &in[n];\n\n        const float *p_in_m = &in[n-1];\n\n        const float *p_filter_coeffs_p = &filter_coeffs[frac_pos];\n\n        const float *p_filter_coeffs_m = filter_coeffs + fc_offset;\n\n        float v = 0;\n\n\n\n        for (i = 0; i < filter_length;i++) {\n\n            __asm__ volatile (\n\n                \"lwc1   %[in_val_p],           0(%[p_in_p])                    \\n\\t\"\n\n                \"lwc1   %[fc_val_p],           0(%[p_filter_coeffs_p])         \\n\\t\"\n\n                \"lwc1   %[in_val_m],           0(%[p_in_m])                    \\n\\t\"\n\n                \"lwc1   %[fc_val_m],           0(%[p_filter_coeffs_m])         \\n\\t\"\n\n                \"addiu  %[p_in_p],             %[p_in_p],              4       \\n\\t\"\n\n                \"madd.s %[v],%[v],             %[in_val_p],%[fc_val_p]         \\n\\t\"\n\n                \"addiu  %[p_in_m],             %[p_in_m],              -4      \\n\\t\"\n\n                \"addu   %[p_filter_coeffs_p],  %[p_filter_coeffs_p],   %[prec] \\n\\t\"\n\n                \"addu   %[p_filter_coeffs_m],  %[p_filter_coeffs_m],   %[prec] \\n\\t\"\n\n                \"madd.s %[v],%[v],%[in_val_m], %[fc_val_m]                     \\n\\t\"\n\n\n\n                : [v] \"=&f\" (v),[p_in_p] \"+r\" (p_in_p), [p_in_m] \"+r\" (p_in_m),\n\n                  [p_filter_coeffs_p] \"+r\" (p_filter_coeffs_p),\n\n                  [in_val_p] \"=&f\" (in_val_p), [in_val_m] \"=&f\" (in_val_m),\n\n                  [fc_val_p] \"=&f\" (fc_val_p), [fc_val_m] \"=&f\" (fc_val_m),\n\n                  [p_filter_coeffs_m] \"+r\" (p_filter_coeffs_m)\n\n                : [prec] \"r\" (prec)\n\n                : \"memory\"\n\n            );\n\n        }\n\n        out[n] = v;\n\n    }\n\n}\n", "idx": 19435, "_split": "valid", "_hash": "33b3e201c80610be1e51f70d52cadebc"}
{"project": "FFmpeg", "commit_id": "5081514269a17809f8a8ff71e6b26e4b761e8266", "target": 1, "func": "static int mpegts_push_data(MpegTSFilter *filter,\n\n                            const uint8_t *buf, int buf_size, int is_start,\n\n                            int64_t pos)\n\n{\n\n    PESContext *pes = filter->u.pes_filter.opaque;\n\n    MpegTSContext *ts = pes->ts;\n\n    const uint8_t *p;\n\n    int len, code;\n\n\n\n    if(!ts->pkt)\n\n        return 0;\n\n\n\n    if (is_start) {\n\n        if (pes->state == MPEGTS_PAYLOAD && pes->data_index > 0) {\n\n            new_pes_packet(pes, ts->pkt);\n\n            ts->stop_parse = 1;\n\n        }\n\n        pes->state = MPEGTS_HEADER;\n\n        pes->data_index = 0;\n\n        pes->ts_packet_pos = pos;\n\n    }\n\n    p = buf;\n\n    while (buf_size > 0) {\n\n        switch(pes->state) {\n\n        case MPEGTS_HEADER:\n\n            len = PES_START_SIZE - pes->data_index;\n\n            if (len > buf_size)\n\n                len = buf_size;\n\n            memcpy(pes->header + pes->data_index, p, len);\n\n            pes->data_index += len;\n\n            p += len;\n\n            buf_size -= len;\n\n            if (pes->data_index == PES_START_SIZE) {\n\n                /* we got all the PES or section header. We can now\n\n                   decide */\n\n                if (pes->header[0] == 0x00 && pes->header[1] == 0x00 &&\n\n                    pes->header[2] == 0x01) {\n\n                    /* it must be an mpeg2 PES stream */\n\n                    code = pes->header[3] | 0x100;\n\n                    av_dlog(pes->stream, \"pid=%x pes_code=%#x\\n\", pes->pid, code);\n\n\n\n                    if ((pes->st && pes->st->discard == AVDISCARD_ALL) ||\n\n                        code == 0x1be) /* padding_stream */\n\n                        goto skip;\n\n\n\n                    /* stream not present in PMT */\n\n                    if (!pes->st) {\n\n                        pes->st = av_new_stream(ts->stream, pes->pid);\n\n                        if (!pes->st)\n\n                            return AVERROR(ENOMEM);\n\n                        mpegts_set_stream_info(pes->st, pes, 0, 0);\n\n                    }\n\n\n\n                    pes->total_size = AV_RB16(pes->header + 4);\n\n                    /* NOTE: a zero total size means the PES size is\n\n                       unbounded */\n\n                    if (!pes->total_size)\n\n                        pes->total_size = MAX_PES_PAYLOAD;\n\n\n\n                    /* allocate pes buffer */\n\n                    pes->buffer = av_malloc(pes->total_size+FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!pes->buffer)\n\n                        return AVERROR(ENOMEM);\n\n\n\n                    if (code != 0x1bc && code != 0x1bf && /* program_stream_map, private_stream_2 */\n\n                        code != 0x1f0 && code != 0x1f1 && /* ECM, EMM */\n\n                        code != 0x1ff && code != 0x1f2 && /* program_stream_directory, DSMCC_stream */\n\n                        code != 0x1f8) {                  /* ITU-T Rec. H.222.1 type E stream */\n\n                        pes->state = MPEGTS_PESHEADER;\n\n                        if (pes->st->codec->codec_id == CODEC_ID_NONE) {\n\n                            av_dlog(pes->stream, \"pid=%x stream_type=%x probing\\n\",\n\n                                    pes->pid, pes->stream_type);\n\n                            pes->st->codec->codec_id = CODEC_ID_PROBE;\n\n                        }\n\n                    } else {\n\n                        pes->state = MPEGTS_PAYLOAD;\n\n                        pes->data_index = 0;\n\n                    }\n\n                } else {\n\n                    /* otherwise, it should be a table */\n\n                    /* skip packet */\n\n                skip:\n\n                    pes->state = MPEGTS_SKIP;\n\n                    continue;\n\n                }\n\n            }\n\n            break;\n\n            /**********************************************/\n\n            /* PES packing parsing */\n\n        case MPEGTS_PESHEADER:\n\n            len = PES_HEADER_SIZE - pes->data_index;\n\n            if (len < 0)\n\n                return -1;\n\n            if (len > buf_size)\n\n                len = buf_size;\n\n            memcpy(pes->header + pes->data_index, p, len);\n\n            pes->data_index += len;\n\n            p += len;\n\n            buf_size -= len;\n\n            if (pes->data_index == PES_HEADER_SIZE) {\n\n                pes->pes_header_size = pes->header[8] + 9;\n\n                pes->state = MPEGTS_PESHEADER_FILL;\n\n            }\n\n            break;\n\n        case MPEGTS_PESHEADER_FILL:\n\n            len = pes->pes_header_size - pes->data_index;\n\n            if (len < 0)\n\n                return -1;\n\n            if (len > buf_size)\n\n                len = buf_size;\n\n            memcpy(pes->header + pes->data_index, p, len);\n\n            pes->data_index += len;\n\n            p += len;\n\n            buf_size -= len;\n\n            if (pes->data_index == pes->pes_header_size) {\n\n                const uint8_t *r;\n\n                unsigned int flags, pes_ext, skip;\n\n\n\n                flags = pes->header[7];\n\n                r = pes->header + 9;\n\n                pes->pts = AV_NOPTS_VALUE;\n\n                pes->dts = AV_NOPTS_VALUE;\n\n                if ((flags & 0xc0) == 0x80) {\n\n                    pes->dts = pes->pts = ff_parse_pes_pts(r);\n\n                    r += 5;\n\n                } else if ((flags & 0xc0) == 0xc0) {\n\n                    pes->pts = ff_parse_pes_pts(r);\n\n                    r += 5;\n\n                    pes->dts = ff_parse_pes_pts(r);\n\n                    r += 5;\n\n                }\n\n                pes->extended_stream_id = -1;\n\n                if (flags & 0x01) { /* PES extension */\n\n                    pes_ext = *r++;\n\n                    /* Skip PES private data, program packet sequence counter and P-STD buffer */\n\n                    skip = (pes_ext >> 4) & 0xb;\n\n                    skip += skip & 0x9;\n\n                    r += skip;\n\n                    if ((pes_ext & 0x41) == 0x01 &&\n\n                        (r + 2) <= (pes->header + pes->pes_header_size)) {\n\n                        /* PES extension 2 */\n\n                        if ((r[0] & 0x7f) > 0 && (r[1] & 0x80) == 0)\n\n                            pes->extended_stream_id = r[1];\n\n                    }\n\n                }\n\n\n\n                /* we got the full header. We parse it and get the payload */\n\n                pes->state = MPEGTS_PAYLOAD;\n\n                pes->data_index = 0;\n\n            }\n\n            break;\n\n        case MPEGTS_PAYLOAD:\n\n            if (buf_size > 0 && pes->buffer) {\n\n                if (pes->data_index > 0 && pes->data_index+buf_size > pes->total_size) {\n\n                    new_pes_packet(pes, ts->pkt);\n\n                    pes->total_size = MAX_PES_PAYLOAD;\n\n                    pes->buffer = av_malloc(pes->total_size+FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!pes->buffer)\n\n                        return AVERROR(ENOMEM);\n\n                    ts->stop_parse = 1;\n\n                } else if (pes->data_index == 0 && buf_size > pes->total_size) {\n\n                    // pes packet size is < ts size packet and pes data is padded with 0xff\n\n                    // not sure if this is legal in ts but see issue #2392\n\n                    buf_size = pes->total_size;\n\n                    pes->flags |= AV_PKT_FLAG_CORRUPT;\n\n                }\n\n                memcpy(pes->buffer+pes->data_index, p, buf_size);\n\n                pes->data_index += buf_size;\n\n            }\n\n            buf_size = 0;\n\n            /* emit complete packets with known packet size\n\n             * decreases demuxer delay for infrequent packets like subtitles from\n\n             * a couple of seconds to milliseconds for properly muxed files.\n\n             * total_size is the number of bytes following pes_packet_length\n\n             * in the pes header, i.e. not counting the first 6 bytes */\n\n            if (!ts->stop_parse && pes->total_size < MAX_PES_PAYLOAD &&\n\n                pes->pes_header_size + pes->data_index == pes->total_size + 6) {\n\n                ts->stop_parse = 1;\n\n                new_pes_packet(pes, ts->pkt);\n\n            }\n\n            break;\n\n        case MPEGTS_SKIP:\n\n            buf_size = 0;\n\n            break;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 19462, "_split": "valid", "_hash": "0f3d162cfb6a73372d4d2e8f193e300c"}
{"project": "FFmpeg", "commit_id": "eb96505b761eb02b6a3efc76d854afa6a41941ff", "target": 0, "func": "static void mov_build_index(MOVContext *mov, AVStream *st)\n\n{\n\n    MOVStreamContext *sc = st->priv_data;\n\n    int64_t current_offset;\n\n    int64_t current_dts = 0;\n\n    unsigned int stts_index = 0;\n\n    unsigned int stsc_index = 0;\n\n    unsigned int stss_index = 0;\n\n    unsigned int stps_index = 0;\n\n    unsigned int i, j;\n\n    uint64_t stream_size = 0;\n\n\n\n    /* adjust first dts according to edit list */\n\n    if (sc->time_offset && mov->time_scale > 0) {\n\n        if (sc->time_offset < 0)\n\n            sc->time_offset = av_rescale(sc->time_offset, sc->time_scale, mov->time_scale);\n\n        current_dts = -sc->time_offset;\n\n        if (sc->ctts_data && sc->stts_data && sc->stts_data[0].duration &&\n\n            sc->ctts_data[0].duration / sc->stts_data[0].duration > 16) {\n\n            /* more than 16 frames delay, dts are likely wrong\n\n               this happens with files created by iMovie */\n\n            sc->wrong_dts = 1;\n\n            st->internal->avctx->has_b_frames = 1;\n\n        }\n\n    }\n\n\n\n    /* only use old uncompressed audio chunk demuxing when stts specifies it */\n\n    if (!(st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n          sc->stts_count == 1 && sc->stts_data[0].duration == 1)) {\n\n        unsigned int current_sample = 0;\n\n        unsigned int stts_sample = 0;\n\n        unsigned int sample_size;\n\n        unsigned int distance = 0;\n\n        unsigned int rap_group_index = 0;\n\n        unsigned int rap_group_sample = 0;\n\n        int rap_group_present = sc->rap_group_count && sc->rap_group;\n\n        int key_off = (sc->keyframes && sc->keyframes[0] > 0) || (sc->stps_data && sc->stps_data[0] > 0);\n\n\n\n        current_dts -= sc->dts_shift;\n\n\n\n        if (!sc->sample_count)\n\n            return;\n\n        if (sc->sample_count >= UINT_MAX / sizeof(*st->index_entries) - st->nb_index_entries)\n\n            return;\n\n        if (av_reallocp_array(&st->index_entries,\n\n                              st->nb_index_entries + sc->sample_count,\n\n                              sizeof(*st->index_entries)) < 0) {\n\n            st->nb_index_entries = 0;\n\n            return;\n\n        }\n\n        st->index_entries_allocated_size = (st->nb_index_entries + sc->sample_count) * sizeof(*st->index_entries);\n\n\n\n        for (i = 0; i < sc->chunk_count; i++) {\n\n            current_offset = sc->chunk_offsets[i];\n\n            while (mov_stsc_index_valid(stsc_index, sc->stsc_count) &&\n\n                i + 1 == sc->stsc_data[stsc_index + 1].first)\n\n                stsc_index++;\n\n            for (j = 0; j < sc->stsc_data[stsc_index].count; j++) {\n\n                int keyframe = 0;\n\n                if (current_sample >= sc->sample_count) {\n\n                    av_log(mov->fc, AV_LOG_ERROR, \"wrong sample count\\n\");\n\n                    return;\n\n                }\n\n\n\n                if (!sc->keyframe_absent && (!sc->keyframe_count || current_sample+key_off == sc->keyframes[stss_index])) {\n\n                    keyframe = 1;\n\n                    if (stss_index + 1 < sc->keyframe_count)\n\n                        stss_index++;\n\n                } else if (sc->stps_count && current_sample+key_off == sc->stps_data[stps_index]) {\n\n                    keyframe = 1;\n\n                    if (stps_index + 1 < sc->stps_count)\n\n                        stps_index++;\n\n                }\n\n                if (rap_group_present && rap_group_index < sc->rap_group_count) {\n\n                    if (sc->rap_group[rap_group_index].index > 0)\n\n                        keyframe = 1;\n\n                    if (++rap_group_sample == sc->rap_group[rap_group_index].count) {\n\n                        rap_group_sample = 0;\n\n                        rap_group_index++;\n\n                    }\n\n                }\n\n                if (keyframe)\n\n                    distance = 0;\n\n                sample_size = sc->sample_size > 0 ? sc->sample_size : sc->sample_sizes[current_sample];\n\n                if (sc->pseudo_stream_id == -1 ||\n\n                   sc->stsc_data[stsc_index].id - 1 == sc->pseudo_stream_id) {\n\n                    AVIndexEntry *e = &st->index_entries[st->nb_index_entries++];\n\n                    e->pos = current_offset;\n\n                    e->timestamp = current_dts;\n\n                    e->size = sample_size;\n\n                    e->min_distance = distance;\n\n                    e->flags = keyframe ? AVINDEX_KEYFRAME : 0;\n\n                    av_log(mov->fc, AV_LOG_TRACE, \"AVIndex stream %d, sample %d, offset %\"PRIx64\", dts %\"PRId64\", \"\n\n                            \"size %d, distance %d, keyframe %d\\n\", st->index, current_sample,\n\n                            current_offset, current_dts, sample_size, distance, keyframe);\n\n                }\n\n\n\n                current_offset += sample_size;\n\n                stream_size += sample_size;\n\n                current_dts += sc->stts_data[stts_index].duration;\n\n                distance++;\n\n                stts_sample++;\n\n                current_sample++;\n\n                if (stts_index + 1 < sc->stts_count && stts_sample == sc->stts_data[stts_index].count) {\n\n                    stts_sample = 0;\n\n                    stts_index++;\n\n                }\n\n            }\n\n        }\n\n        if (st->duration > 0)\n\n            st->codecpar->bit_rate = stream_size*8*sc->time_scale/st->duration;\n\n    } else {\n\n        unsigned chunk_samples, total = 0;\n\n\n\n        // compute total chunk count\n\n        for (i = 0; i < sc->stsc_count; i++) {\n\n            unsigned count, chunk_count;\n\n\n\n            chunk_samples = sc->stsc_data[i].count;\n\n            if (i != sc->stsc_count - 1 &&\n\n                sc->samples_per_frame && chunk_samples % sc->samples_per_frame) {\n\n                av_log(mov->fc, AV_LOG_ERROR, \"error unaligned chunk\\n\");\n\n                return;\n\n            }\n\n\n\n            if (sc->samples_per_frame >= 160) { // gsm\n\n                count = chunk_samples / sc->samples_per_frame;\n\n            } else if (sc->samples_per_frame > 1) {\n\n                unsigned samples = (1024/sc->samples_per_frame)*sc->samples_per_frame;\n\n                count = (chunk_samples+samples-1) / samples;\n\n            } else {\n\n                count = (chunk_samples+1023) / 1024;\n\n            }\n\n\n\n            if (mov_stsc_index_valid(i, sc->stsc_count))\n\n                chunk_count = sc->stsc_data[i+1].first - sc->stsc_data[i].first;\n\n            else\n\n                chunk_count = sc->chunk_count - (sc->stsc_data[i].first - 1);\n\n            total += chunk_count * count;\n\n        }\n\n\n\n        av_log(mov->fc, AV_LOG_TRACE, \"chunk count %d\\n\", total);\n\n        if (total >= UINT_MAX / sizeof(*st->index_entries) - st->nb_index_entries)\n\n            return;\n\n        if (av_reallocp_array(&st->index_entries,\n\n                              st->nb_index_entries + total,\n\n                              sizeof(*st->index_entries)) < 0) {\n\n            st->nb_index_entries = 0;\n\n            return;\n\n        }\n\n        st->index_entries_allocated_size = (st->nb_index_entries + total) * sizeof(*st->index_entries);\n\n\n\n        // populate index\n\n        for (i = 0; i < sc->chunk_count; i++) {\n\n            current_offset = sc->chunk_offsets[i];\n\n            if (mov_stsc_index_valid(stsc_index, sc->stsc_count) &&\n\n                i + 1 == sc->stsc_data[stsc_index + 1].first)\n\n                stsc_index++;\n\n            chunk_samples = sc->stsc_data[stsc_index].count;\n\n\n\n            while (chunk_samples > 0) {\n\n                AVIndexEntry *e;\n\n                unsigned size, samples;\n\n\n\n                if (sc->samples_per_frame > 1 && !sc->bytes_per_frame) {\n\n                    avpriv_request_sample(mov->fc,\n\n                           \"Zero bytes per frame, but %d samples per frame\",\n\n                           sc->samples_per_frame);\n\n                    return;\n\n                }\n\n\n\n                if (sc->samples_per_frame >= 160) { // gsm\n\n                    samples = sc->samples_per_frame;\n\n                    size = sc->bytes_per_frame;\n\n                } else {\n\n                    if (sc->samples_per_frame > 1) {\n\n                        samples = FFMIN((1024 / sc->samples_per_frame)*\n\n                                        sc->samples_per_frame, chunk_samples);\n\n                        size = (samples / sc->samples_per_frame) * sc->bytes_per_frame;\n\n                    } else {\n\n                        samples = FFMIN(1024, chunk_samples);\n\n                        size = samples * sc->sample_size;\n\n                    }\n\n                }\n\n\n\n                if (st->nb_index_entries >= total) {\n\n                    av_log(mov->fc, AV_LOG_ERROR, \"wrong chunk count %d\\n\", total);\n\n                    return;\n\n                }\n\n                e = &st->index_entries[st->nb_index_entries++];\n\n                e->pos = current_offset;\n\n                e->timestamp = current_dts;\n\n                e->size = size;\n\n                e->min_distance = 0;\n\n                e->flags = AVINDEX_KEYFRAME;\n\n                av_log(mov->fc, AV_LOG_TRACE, \"AVIndex stream %d, chunk %d, offset %\"PRIx64\", dts %\"PRId64\", \"\n\n                        \"size %d, duration %d\\n\", st->index, i, current_offset, current_dts,\n\n                        size, samples);\n\n\n\n                current_offset += size;\n\n                current_dts += samples;\n\n                chunk_samples -= samples;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 19472, "_split": "valid", "_hash": "2f995ed12161cf3bca6f7ea8597f0736"}
{"project": "FFmpeg", "commit_id": "f1ffb01ee9fd3a15c395c3cf6ff362ac5cd668d0", "target": 0, "func": "static void video_audio_display(VideoState *s)\n\n{\n\n    int i, i_start, x, y1, y, ys, delay, n, nb_display_channels;\n\n    int ch, channels, h, h2, bgcolor, fgcolor;\n\n    int16_t time_diff;\n\n    int rdft_bits, nb_freq;\n\n\n\n    for (rdft_bits = 1; (1 << rdft_bits) < 2 * s->height; rdft_bits++)\n\n        ;\n\n    nb_freq = 1 << (rdft_bits - 1);\n\n\n\n    /* compute display index : center on currently output samples */\n\n    channels = s->audio_st->codec->channels;\n\n    nb_display_channels = channels;\n\n    if (!s->paused) {\n\n        int data_used = s->show_audio == 1 ? s->width : (2 * nb_freq);\n\n        n = 2 * channels;\n\n        delay = audio_write_get_buf_size(s);\n\n        delay /= n;\n\n\n\n        /* to be more precise, we take into account the time spent since\n\n           the last buffer computation */\n\n        if (audio_callback_time) {\n\n            time_diff = av_gettime() - audio_callback_time;\n\n            delay -= (time_diff * s->audio_st->codec->sample_rate) / 1000000;\n\n        }\n\n\n\n        delay += 2 * data_used;\n\n        if (delay < data_used)\n\n            delay = data_used;\n\n\n\n        i_start= x = compute_mod(s->sample_array_index - delay * channels, SAMPLE_ARRAY_SIZE);\n\n        if (s->show_audio == 1) {\n\n            h = INT_MIN;\n\n            for (i = 0; i < 1000; i += channels) {\n\n                int idx = (SAMPLE_ARRAY_SIZE + x - i) % SAMPLE_ARRAY_SIZE;\n\n                int a = s->sample_array[idx];\n\n                int b = s->sample_array[(idx + 4 * channels) % SAMPLE_ARRAY_SIZE];\n\n                int c = s->sample_array[(idx + 5 * channels) % SAMPLE_ARRAY_SIZE];\n\n                int d = s->sample_array[(idx + 9 * channels) % SAMPLE_ARRAY_SIZE];\n\n                int score = a - d;\n\n                if (h < score && (b ^ c) < 0) {\n\n                    h = score;\n\n                    i_start = idx;\n\n                }\n\n            }\n\n        }\n\n\n\n        s->last_i_start = i_start;\n\n    } else {\n\n        i_start = s->last_i_start;\n\n    }\n\n\n\n    bgcolor = SDL_MapRGB(screen->format, 0x00, 0x00, 0x00);\n\n    if (s->show_audio == 1) {\n\n        fill_rectangle(screen,\n\n                       s->xleft, s->ytop, s->width, s->height,\n\n                       bgcolor);\n\n\n\n        fgcolor = SDL_MapRGB(screen->format, 0xff, 0xff, 0xff);\n\n\n\n        /* total height for one channel */\n\n        h = s->height / nb_display_channels;\n\n        /* graph height / 2 */\n\n        h2 = (h * 9) / 20;\n\n        for (ch = 0; ch < nb_display_channels; ch++) {\n\n            i = i_start + ch;\n\n            y1 = s->ytop + ch * h + (h / 2); /* position of center line */\n\n            for (x = 0; x < s->width; x++) {\n\n                y = (s->sample_array[i] * h2) >> 15;\n\n                if (y < 0) {\n\n                    y = -y;\n\n                    ys = y1 - y;\n\n                } else {\n\n                    ys = y1;\n\n                }\n\n                fill_rectangle(screen,\n\n                               s->xleft + x, ys, 1, y,\n\n                               fgcolor);\n\n                i += channels;\n\n                if (i >= SAMPLE_ARRAY_SIZE)\n\n                    i -= SAMPLE_ARRAY_SIZE;\n\n            }\n\n        }\n\n\n\n        fgcolor = SDL_MapRGB(screen->format, 0x00, 0x00, 0xff);\n\n\n\n        for (ch = 1; ch < nb_display_channels; ch++) {\n\n            y = s->ytop + ch * h;\n\n            fill_rectangle(screen,\n\n                           s->xleft, y, s->width, 1,\n\n                           fgcolor);\n\n        }\n\n        SDL_UpdateRect(screen, s->xleft, s->ytop, s->width, s->height);\n\n    } else {\n\n        nb_display_channels= FFMIN(nb_display_channels, 2);\n\n        if (rdft_bits != s->rdft_bits) {\n\n            av_rdft_end(s->rdft);\n\n            av_free(s->rdft_data);\n\n            s->rdft = av_rdft_init(rdft_bits, DFT_R2C);\n\n            s->rdft_bits = rdft_bits;\n\n            s->rdft_data = av_malloc(4 * nb_freq * sizeof(*s->rdft_data));\n\n        }\n\n        {\n\n            FFTSample *data[2];\n\n            for (ch = 0; ch < nb_display_channels; ch++) {\n\n                data[ch] = s->rdft_data + 2 * nb_freq * ch;\n\n                i = i_start + ch;\n\n                for (x = 0; x < 2 * nb_freq; x++) {\n\n                    double w = (x-nb_freq) * (1.0 / nb_freq);\n\n                    data[ch][x] = s->sample_array[i] * (1.0 - w * w);\n\n                    i += channels;\n\n                    if (i >= SAMPLE_ARRAY_SIZE)\n\n                        i -= SAMPLE_ARRAY_SIZE;\n\n                }\n\n                av_rdft_calc(s->rdft, data[ch]);\n\n            }\n\n            // least efficient way to do this, we should of course directly access it but its more than fast enough\n\n            for (y = 0; y < s->height; y++) {\n\n                double w = 1 / sqrt(nb_freq);\n\n                int a = sqrt(w * sqrt(data[0][2 * y + 0] * data[0][2 * y + 0] + data[0][2 * y + 1] * data[0][2 * y + 1]));\n\n                int b = (nb_display_channels == 2 ) ? sqrt(w * sqrt(data[1][2 * y + 0] * data[1][2 * y + 0]\n\n                       + data[1][2 * y + 1] * data[1][2 * y + 1])) : a;\n\n                a = FFMIN(a, 255);\n\n                b = FFMIN(b, 255);\n\n                fgcolor = SDL_MapRGB(screen->format, a, b, (a + b) / 2);\n\n\n\n                fill_rectangle(screen,\n\n                            s->xpos, s->height-y, 1, 1,\n\n                            fgcolor);\n\n            }\n\n        }\n\n        SDL_UpdateRect(screen, s->xpos, s->ytop, 1, s->height);\n\n        s->xpos++;\n\n        if (s->xpos >= s->width)\n\n            s->xpos= s->xleft;\n\n    }\n\n}\n", "idx": 19525, "_split": "valid", "_hash": "ac4b3cb5dea2ef1bf1f7930deda19723"}
{"project": "FFmpeg", "commit_id": "e2710e790c09e49e86baa58c6063af0097cc8cb0", "target": 1, "func": "int ff_get_cpu_flags_arm(void)\n{\n    int flags = CORE_CPU_FLAGS;\n    uint32_t hwcap;\n    if (get_hwcap(&hwcap) < 0)\n        if (get_cpuinfo(&hwcap) < 0)\n            return flags;\n#define check_cap(cap, flag) do {               \\\n        if (hwcap & HWCAP_ ## cap)              \\\n            flags |= AV_CPU_FLAG_ ## flag;      \\\n    } while (0)\n    /* No flags explicitly indicate v6 or v6T2 so check others which\n       imply support. */\n    check_cap(EDSP,    ARMV5TE);\n    check_cap(TLS,     ARMV6);\n    check_cap(THUMBEE, ARMV6T2);\n    check_cap(VFP,     VFP);\n    check_cap(VFPv3,   VFPV3);\n    check_cap(NEON,    NEON);\n    /* The v6 checks above are not reliable so let higher flags\n       trickle down. */\n    if (flags & (AV_CPU_FLAG_VFPV3 | AV_CPU_FLAG_NEON))\n        flags |= AV_CPU_FLAG_ARMV6T2;\n    if (flags & AV_CPU_FLAG_ARMV6T2)\n        flags |= AV_CPU_FLAG_ARMV6;\n    return flags;\n}", "idx": 19547, "_split": "valid", "_hash": "1cc2ad8871c7ef86523c181620fc9699"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "static void avc_luma_vt_4w_msa(const uint8_t *src, int32_t src_stride,\n\n                               uint8_t *dst, int32_t dst_stride,\n\n                               int32_t height)\n\n{\n\n    int32_t loop_cnt;\n\n    int16_t filt_const0 = 0xfb01;\n\n    int16_t filt_const1 = 0x1414;\n\n    int16_t filt_const2 = 0x1fb;\n\n    v16i8 src0, src1, src2, src3, src4, src5, src6, src7, src8;\n\n    v16i8 src10_r, src32_r, src54_r, src76_r, src21_r, src43_r, src65_r;\n\n    v16i8 src87_r, src2110, src4332, src6554, src8776;\n\n    v16i8 filt0, filt1, filt2;\n\n    v8i16 out10, out32;\n\n    v16u8 out;\n\n\n\n    filt0 = (v16i8) __msa_fill_h(filt_const0);\n\n    filt1 = (v16i8) __msa_fill_h(filt_const1);\n\n    filt2 = (v16i8) __msa_fill_h(filt_const2);\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    ILVR_B4_SB(src1, src0, src2, src1, src3, src2, src4, src3,\n\n               src10_r, src21_r, src32_r, src43_r);\n\n    ILVR_D2_SB(src21_r, src10_r, src43_r, src32_r, src2110, src4332);\n\n    XORI_B2_128_SB(src2110, src4332);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src, src_stride, src5, src6, src7, src8);\n\n        src += (4 * src_stride);\n\n\n\n        ILVR_B4_SB(src5, src4, src6, src5, src7, src6, src8, src7,\n\n                   src54_r, src65_r, src76_r, src87_r);\n\n        ILVR_D2_SB(src65_r, src54_r, src87_r, src76_r, src6554, src8776);\n\n        XORI_B2_128_SB(src6554, src8776);\n\n        out10 = DPADD_SH3_SH(src2110, src4332, src6554, filt0, filt1, filt2);\n\n        out32 = DPADD_SH3_SH(src4332, src6554, src8776, filt0, filt1, filt2);\n\n        SRARI_H2_SH(out10, out32, 5);\n\n        SAT_SH2_SH(out10, out32, 7);\n\n        out = PCKEV_XORI128_UB(out10, out32);\n\n        ST4x4_UB(out, out, 0, 1, 2, 3, dst, dst_stride);\n\n\n\n        dst += (4 * dst_stride);\n\n        src2110 = src6554;\n\n        src4332 = src8776;\n\n        src4 = src8;\n\n    }\n\n}\n", "idx": 19549, "_split": "valid", "_hash": "a7599b3b329b2250c5ba5af682edd37c"}
{"project": "FFmpeg", "commit_id": "a084884b628fd9cbfe965b7ac37e59202d708c26", "target": 1, "func": "static int flashsv_decode_frame(AVCodecContext *avctx, void *data,\n\n                                int *got_frame, AVPacket *avpkt)\n\n{\n\n    int buf_size       = avpkt->size;\n\n    FlashSVContext *s  = avctx->priv_data;\n\n    int h_blocks, v_blocks, h_part, v_part, i, j;\n\n    GetBitContext gb;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0)\n\n        return 0;\n\n    if (buf_size < 4)\n\n        return -1;\n\n\n\n    init_get_bits(&gb, avpkt->data, buf_size * 8);\n\n\n\n    /* start to parse the bitstream */\n\n    s->block_width  = 16 * (get_bits(&gb,  4) + 1);\n\n    s->image_width  =       get_bits(&gb, 12);\n\n    s->block_height = 16 * (get_bits(&gb,  4) + 1);\n\n    s->image_height =       get_bits(&gb, 12);\n\n\n\n    if (s->ver == 2) {\n\n        skip_bits(&gb, 6);\n\n        if (get_bits1(&gb)) {\n\n            av_log_missing_feature(avctx, \"iframe\", 1);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        if (get_bits1(&gb)) {\n\n            av_log_missing_feature(avctx, \"Custom palette\", 1);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n    }\n\n\n\n    /* calculate number of blocks and size of border (partial) blocks */\n\n    h_blocks = s->image_width  / s->block_width;\n\n    h_part   = s->image_width  % s->block_width;\n\n    v_blocks = s->image_height / s->block_height;\n\n    v_part   = s->image_height % s->block_height;\n\n\n\n    /* the block size could change between frames, make sure the buffer\n\n     * is large enough, if not, get a larger one */\n\n    if (s->block_size < s->block_width * s->block_height) {\n\n        int tmpblock_size = 3 * s->block_width * s->block_height;\n\n\n\n        s->tmpblock = av_realloc(s->tmpblock, tmpblock_size);\n\n        if (!s->tmpblock) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Can't allocate decompression buffer.\\n\");\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        if (s->ver == 2) {\n\n            s->deflate_block_size = calc_deflate_block_size(tmpblock_size);\n\n            if (s->deflate_block_size <= 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Can't determine deflate buffer size.\\n\");\n\n                return -1;\n\n            }\n\n            s->deflate_block = av_realloc(s->deflate_block, s->deflate_block_size);\n\n            if (!s->deflate_block) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Can't allocate deflate buffer.\\n\");\n\n                return AVERROR(ENOMEM);\n\n            }\n\n        }\n\n    }\n\n    s->block_size = s->block_width * s->block_height;\n\n\n\n    /* initialize the image size once */\n\n    if (avctx->width == 0 && avctx->height == 0) {\n\n        avcodec_set_dimensions(avctx, s->image_width, s->image_height);\n\n    }\n\n\n\n    /* check for changes of image width and image height */\n\n    if (avctx->width != s->image_width || avctx->height != s->image_height) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Frame width or height differs from first frame!\\n\");\n\n        av_log(avctx, AV_LOG_ERROR, \"fh = %d, fv %d  vs  ch = %d, cv = %d\\n\",\n\n               avctx->height, avctx->width, s->image_height, s->image_width);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* we care for keyframes only in Screen Video v2 */\n\n    s->is_keyframe = (avpkt->flags & AV_PKT_FLAG_KEY) && (s->ver == 2);\n\n    if (s->is_keyframe) {\n\n        s->keyframedata = av_realloc(s->keyframedata, avpkt->size);\n\n        memcpy(s->keyframedata, avpkt->data, avpkt->size);\n\n    }\n\n    if(s->ver == 2)\n\n        s->blocks = av_realloc(s->blocks,\n\n                                (v_blocks + !!v_part) * (h_blocks + !!h_part)\n\n                                * sizeof(s->blocks[0]));\n\n\n\n    av_dlog(avctx, \"image: %dx%d block: %dx%d num: %dx%d part: %dx%d\\n\",\n\n            s->image_width, s->image_height, s->block_width, s->block_height,\n\n            h_blocks, v_blocks, h_part, v_part);\n\n\n\n    s->frame.reference    = 3;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID    |\n\n                            FF_BUFFER_HINTS_PRESERVE |\n\n                            FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* loop over all block columns */\n\n    for (j = 0; j < v_blocks + (v_part ? 1 : 0); j++) {\n\n\n\n        int y_pos  = j * s->block_height; // vertical position in frame\n\n        int cur_blk_height = (j < v_blocks) ? s->block_height : v_part;\n\n\n\n        /* loop over all block rows */\n\n        for (i = 0; i < h_blocks + (h_part ? 1 : 0); i++) {\n\n            int x_pos = i * s->block_width; // horizontal position in frame\n\n            int cur_blk_width = (i < h_blocks) ? s->block_width : h_part;\n\n            int has_diff = 0;\n\n\n\n            /* get the size of the compressed zlib chunk */\n\n            int size = get_bits(&gb, 16);\n\n\n\n            s->color_depth    = 0;\n\n            s->zlibprime_curr = 0;\n\n            s->zlibprime_prev = 0;\n\n            s->diff_start     = 0;\n\n            s->diff_height    = cur_blk_height;\n\n\n\n            if (8 * size > get_bits_left(&gb)) {\n\n                avctx->release_buffer(avctx, &s->frame);\n\n                s->frame.data[0] = NULL;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if (s->ver == 2 && size) {\n\n                skip_bits(&gb, 3);\n\n                s->color_depth    = get_bits(&gb, 2);\n\n                has_diff          = get_bits1(&gb);\n\n                s->zlibprime_curr = get_bits1(&gb);\n\n                s->zlibprime_prev = get_bits1(&gb);\n\n\n\n                if (s->color_depth != 0 && s->color_depth != 2) {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"%dx%d invalid color depth %d\\n\", i, j, s->color_depth);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                if (has_diff) {\n\n                    if (!s->keyframe) {\n\n                        av_log(avctx, AV_LOG_ERROR,\n\n                               \"inter frame without keyframe\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    s->diff_start  = get_bits(&gb, 8);\n\n                    s->diff_height = get_bits(&gb, 8);\n\n                    av_log(avctx, AV_LOG_DEBUG,\n\n                           \"%dx%d diff start %d height %d\\n\",\n\n                           i, j, s->diff_start, s->diff_height);\n\n                    size -= 2;\n\n                }\n\n\n\n                if (s->zlibprime_prev)\n\n                    av_log(avctx, AV_LOG_DEBUG, \"%dx%d zlibprime_prev\\n\", i, j);\n\n\n\n                if (s->zlibprime_curr) {\n\n                    int col = get_bits(&gb, 8);\n\n                    int row = get_bits(&gb, 8);\n\n                    av_log(avctx, AV_LOG_DEBUG, \"%dx%d zlibprime_curr %dx%d\\n\", i, j, col, row);\n\n                    size -= 2;\n\n                    av_log_missing_feature(avctx, \"zlibprime_curr\", 1);\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n                if (!s->blocks && (s->zlibprime_curr || s->zlibprime_prev)) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"no data available for zlib \"\n\n                           \"priming\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                size--; // account for flags byte\n\n            }\n\n\n\n            if (has_diff) {\n\n                int k;\n\n                int off = (s->image_height - y_pos - 1) * s->frame.linesize[0];\n\n\n\n                for (k = 0; k < cur_blk_height; k++)\n\n                    memcpy(s->frame.data[0] + off - k*s->frame.linesize[0] + x_pos*3,\n\n                           s->keyframe + off - k*s->frame.linesize[0] + x_pos*3,\n\n                           cur_blk_width * 3);\n\n            }\n\n\n\n            /* skip unchanged blocks, which have size 0 */\n\n            if (size) {\n\n                if (flashsv_decode_block(avctx, avpkt, &gb, size,\n\n                                         cur_blk_width, cur_blk_height,\n\n                                         x_pos, y_pos,\n\n                                         i + j * (h_blocks + !!h_part)))\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"error in decompression of block %dx%d\\n\", i, j);\n\n            }\n\n        }\n\n    }\n\n    if (s->is_keyframe && s->ver == 2) {\n\n        if (!s->keyframe) {\n\n            s->keyframe = av_malloc(s->frame.linesize[0] * avctx->height);\n\n            if (!s->keyframe) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Cannot allocate image data\\n\");\n\n                return AVERROR(ENOMEM);\n\n            }\n\n        }\n\n        memcpy(s->keyframe, s->frame.data[0], s->frame.linesize[0] * avctx->height);\n\n    }\n\n\n\n    *got_frame = 1;\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    if ((get_bits_count(&gb) / 8) != buf_size)\n\n        av_log(avctx, AV_LOG_ERROR, \"buffer not fully consumed (%d != %d)\\n\",\n\n               buf_size, (get_bits_count(&gb) / 8));\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 19620, "_split": "valid", "_hash": "21116da0403c80eb859be2792e8b94c9"}
{"project": "FFmpeg", "commit_id": "09d89d940635e34b0f61266d66fbb9802b18564c", "target": 0, "func": "static void decode_subband(DiracContext *s, GetBitContext *gb, int quant,\n\n                           int slice_x, int slice_y, int bits_end,\n\n                           SubBand *b1, SubBand *b2)\n\n{\n\n    int left   = b1->width  * slice_x    / s->num_x;\n\n    int right  = b1->width  *(slice_x+1) / s->num_x;\n\n    int top    = b1->height * slice_y    / s->num_y;\n\n    int bottom = b1->height *(slice_y+1) / s->num_y;\n\n\n\n    int qfactor, qoffset;\n\n\n\n    uint8_t *buf1 =      b1->ibuf + top * b1->stride;\n\n    uint8_t *buf2 = b2 ? b2->ibuf + top * b2->stride: NULL;\n\n    int x, y;\n\n\n\n    if (quant > 115) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Unsupported quant %d\\n\", quant);\n\n        return;\n\n    }\n\n    qfactor = ff_dirac_qscale_tab[quant & 0x7f];\n\n    qoffset = ff_dirac_qoffset_intra_tab[quant & 0x7f] + 2;\n\n    /* we have to constantly check for overread since the spec explicitly\n\n       requires this, with the meaning that all remaining coeffs are set to 0 */\n\n    if (get_bits_count(gb) >= bits_end)\n\n        return;\n\n\n\n    if (s->pshift) {\n\n        for (y = top; y < bottom; y++) {\n\n            for (x = left; x < right; x++) {\n\n                PARSE_VALUES(int32_t, x, gb, bits_end, buf1, buf2);\n\n            }\n\n            buf1 += b1->stride;\n\n            if (buf2)\n\n                buf2 += b2->stride;\n\n        }\n\n    }\n\n    else {\n\n        for (y = top; y < bottom; y++) {\n\n            for (x = left; x < right; x++) {\n\n                PARSE_VALUES(int16_t, x, gb, bits_end, buf1, buf2);\n\n            }\n\n            buf1 += b1->stride;\n\n            if (buf2)\n\n                buf2 += b2->stride;\n\n        }\n\n    }\n\n}\n", "idx": 19625, "_split": "valid", "_hash": "04fcf3088514a2e5984b22d5d9d17175"}
{"project": "FFmpeg", "commit_id": "fbd0dacc8d61ab418b3fa8e7be22017558323e56", "target": 1, "func": "static int decode_p_block(FourXContext *f, uint16_t *dst, uint16_t *src,\n\n                          int log2w, int log2h, int stride)\n\n{\n\n    const int index = size2index[log2h][log2w];\n\n    const int h     = 1 << log2h;\n\n    int code        = get_vlc2(&f->gb,\n\n                               block_type_vlc[1 - (f->version > 1)][index].table,\n\n                               BLOCK_TYPE_VLC_BITS, 1);\n\n    uint16_t *start = (uint16_t *)f->last_picture->data[0];\n\n    uint16_t *end   = start + stride * (f->avctx->height - h + 1) - (1 << log2w);\n\n    int ret;\n\n\n\n    if (code < 0 || code > 6 || log2w < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (code == 0) {\n\n        src += f->mv[bytestream2_get_byte(&f->g)];\n\n        if (start > src || src > end) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"mv out of pic\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        mcdc(dst, src, log2w, h, stride, 1, 0);\n\n    } else if (code == 1) {\n\n        log2h--;\n\n        if ((ret = decode_p_block(f, dst, src, log2w, log2h, stride)) < 0)\n\n            return ret;\n\n        if ((ret = decode_p_block(f, dst + (stride << log2h),\n\n                                  src + (stride << log2h),\n\n                                  log2w, log2h, stride)) < 0)\n\n            return ret;\n\n    } else if (code == 2) {\n\n        log2w--;\n\n        if ((ret = decode_p_block(f, dst , src, log2w, log2h, stride)) < 0)\n\n            return ret;\n\n        if ((ret = decode_p_block(f, dst + (1 << log2w),\n\n                                  src + (1 << log2w),\n\n                                  log2w, log2h, stride)) < 0)\n\n            return ret;\n\n    } else if (code == 3 && f->version < 2) {\n\n        if (start > src || src > end) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"mv out of pic\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        mcdc(dst, src, log2w, h, stride, 1, 0);\n\n    } else if (code == 4) {\n\n        src += f->mv[bytestream2_get_byte(&f->g)];\n\n        if (start > src || src > end) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"mv out of pic\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        mcdc(dst, src, log2w, h, stride, 1, bytestream2_get_le16(&f->g2));\n\n    } else if (code == 5) {\n\n        if (start > src || src > end) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"mv out of pic\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        mcdc(dst, src, log2w, h, stride, 0, bytestream2_get_le16(&f->g2));\n\n    } else if (code == 6) {\n\n        if (log2w) {\n\n            dst[0]      = bytestream2_get_le16(&f->g2);\n\n            dst[1]      = bytestream2_get_le16(&f->g2);\n\n        } else {\n\n            dst[0]      = bytestream2_get_le16(&f->g2);\n\n            dst[stride] = bytestream2_get_le16(&f->g2);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 19662, "_split": "valid", "_hash": "8372adc20dfccbc7f588e08bc2bdaa59"}
{"project": "FFmpeg", "commit_id": "55354b7de21e7bb4bbeb1c12ff55ea17f807c70c", "target": 1, "func": "static inline int wv_unpack_mono(WavpackFrameContext *s, GetBitContext *gb, void *dst, const int type)\n\n{\n\n    int i, j, count = 0;\n\n    int last, t;\n\n    int A, S, T;\n\n    int pos = s->pos;\n\n    uint32_t crc = s->sc.crc;\n\n    uint32_t crc_extra_bits = s->extra_sc.crc;\n\n    int16_t *dst16 = dst;\n\n    int32_t *dst32 = dst;\n\n    float   *dstfl = dst;\n\n    const int channel_stride = s->avctx->channels;\n\n\n\n    if(s->samples_left == s->samples)\n\n        s->one = s->zero = s->zeroes = 0;\n\n    do{\n\n        T = wv_get_value(s, gb, 0, &last);\n\n        S = 0;\n\n        if(last) break;\n\n        for(i = 0; i < s->terms; i++){\n\n            t = s->decorr[i].value;\n\n            if(t > 8){\n\n                if(t & 1)\n\n                    A = 2 * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1];\n\n                else\n\n                    A = (3 * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1]) >> 1;\n\n                s->decorr[i].samplesA[1] = s->decorr[i].samplesA[0];\n\n                j = 0;\n\n            }else{\n\n                A = s->decorr[i].samplesA[pos];\n\n                j = (pos + t) & 7;\n\n            }\n\n            if(type != AV_SAMPLE_FMT_S16)\n\n                S = T + ((s->decorr[i].weightA * (int64_t)A + 512) >> 10);\n\n            else\n\n                S = T + ((s->decorr[i].weightA * A + 512) >> 10);\n\n            if(A && T) s->decorr[i].weightA -= ((((T ^ A) >> 30) & 2) - 1) * s->decorr[i].delta;\n\n            s->decorr[i].samplesA[j] = T = S;\n\n        }\n\n        pos = (pos + 1) & 7;\n\n        crc = crc * 3 + S;\n\n\n\n        if(type == AV_SAMPLE_FMT_FLT){\n\n            *dstfl = wv_get_value_float(s, &crc_extra_bits, S);\n\n            dstfl += channel_stride;\n\n        }else if(type == AV_SAMPLE_FMT_S32){\n\n            *dst32 = wv_get_value_integer(s, &crc_extra_bits, S);\n\n            dst32 += channel_stride;\n\n        }else{\n\n            *dst16 = wv_get_value_integer(s, &crc_extra_bits, S);\n\n            dst16 += channel_stride;\n\n        }\n\n        count++;\n\n    }while(!last && count < s->max_samples);\n\n\n\n    s->samples_left -= count;\n\n    if(!s->samples_left){\n\n        wv_reset_saved_context(s);\n\n        if(crc != s->CRC){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"CRC error\\n\");\n\n            return -1;\n\n        }\n\n        if(s->got_extra_bits && crc_extra_bits != s->crc_extra_bits){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Extra bits CRC error\\n\");\n\n            return -1;\n\n        }\n\n    }else{\n\n        s->pos = pos;\n\n        s->sc.crc = crc;\n\n        s->sc.bits_used = get_bits_count(&s->gb);\n\n        if(s->got_extra_bits){\n\n            s->extra_sc.crc = crc_extra_bits;\n\n            s->extra_sc.bits_used = get_bits_count(&s->gb_extra_bits);\n\n        }\n\n    }\n\n    return count;\n\n}\n", "idx": 19682, "_split": "valid", "_hash": "465d0151fabc41ea6e9e5d14634eb72a"}
{"project": "FFmpeg", "commit_id": "73bb8f61d48dbf7237df2e9cacd037f12b84b00a", "target": 0, "func": "static void FUNC(hevc_loop_filter_luma)(uint8_t *_pix,\n\n                                        ptrdiff_t _xstride, ptrdiff_t _ystride,\n\n                                        int *_beta, int *_tc,\n\n                                        uint8_t *_no_p, uint8_t *_no_q)\n\n{\n\n    int d, j;\n\n    pixel *pix        = (pixel *)_pix;\n\n    ptrdiff_t xstride = _xstride / sizeof(pixel);\n\n    ptrdiff_t ystride = _ystride / sizeof(pixel);\n\n\n\n    for (j = 0; j < 2; j++) {\n\n        const int dp0  = abs(P2  - 2 * P1  + P0);\n\n        const int dq0  = abs(Q2  - 2 * Q1  + Q0);\n\n        const int dp3  = abs(TP2 - 2 * TP1 + TP0);\n\n        const int dq3  = abs(TQ2 - 2 * TQ1 + TQ0);\n\n        const int d0   = dp0 + dq0;\n\n        const int d3   = dp3 + dq3;\n\n        const int beta = _beta[j] << (BIT_DEPTH - 8);\n\n        const int tc   = _tc[j]   << (BIT_DEPTH - 8);\n\n        const int no_p = _no_p[j];\n\n        const int no_q = _no_q[j];\n\n\n\n        if (d0 + d3 >= beta) {\n\n            pix += 4 * ystride;\n\n            continue;\n\n        } else {\n\n            const int beta_3 = beta >> 3;\n\n            const int beta_2 = beta >> 2;\n\n            const int tc25   = ((tc * 5 + 1) >> 1);\n\n\n\n            if (abs(P3  -  P0) + abs(Q3  -  Q0) < beta_3 && abs(P0  -  Q0) < tc25 &&\n\n                abs(TP3 - TP0) + abs(TQ3 - TQ0) < beta_3 && abs(TP0 - TQ0) < tc25 &&\n\n                                      (d0 << 1) < beta_2 &&      (d3 << 1) < beta_2) {\n\n                // strong filtering\n\n                const int tc2 = tc << 1;\n\n                for (d = 0; d < 4; d++) {\n\n                    const int p3 = P3;\n\n                    const int p2 = P2;\n\n                    const int p1 = P1;\n\n                    const int p0 = P0;\n\n                    const int q0 = Q0;\n\n                    const int q1 = Q1;\n\n                    const int q2 = Q2;\n\n                    const int q3 = Q3;\n\n                    if (!no_p) {\n\n                        P0 = p0 + av_clip(((p2 + 2 * p1 + 2 * p0 + 2 * q0 + q1 + 4) >> 3) - p0, -tc2, tc2);\n\n                        P1 = p1 + av_clip(((p2 + p1 + p0 + q0 + 2) >> 2) - p1, -tc2, tc2);\n\n                        P2 = p2 + av_clip(((2 * p3 + 3 * p2 + p1 + p0 + q0 + 4) >> 3) - p2, -tc2, tc2);\n\n                    }\n\n                    if (!no_q) {\n\n                        Q0 = q0 + av_clip(((p1 + 2 * p0 + 2 * q0 + 2 * q1 + q2 + 4) >> 3) - q0, -tc2, tc2);\n\n                        Q1 = q1 + av_clip(((p0 + q0 + q1 + q2 + 2) >> 2) - q1, -tc2, tc2);\n\n                        Q2 = q2 + av_clip(((2 * q3 + 3 * q2 + q1 + q0 + p0 + 4) >> 3) - q2, -tc2, tc2);\n\n                    }\n\n                    pix += ystride;\n\n                }\n\n            } else { // normal filtering\n\n                int nd_p = 1;\n\n                int nd_q = 1;\n\n                const int tc_2 = tc >> 1;\n\n                if (dp0 + dp3 < ((beta + (beta >> 1)) >> 3))\n\n                    nd_p = 2;\n\n                if (dq0 + dq3 < ((beta + (beta >> 1)) >> 3))\n\n                    nd_q = 2;\n\n\n\n                for (d = 0; d < 4; d++) {\n\n                    const int p2 = P2;\n\n                    const int p1 = P1;\n\n                    const int p0 = P0;\n\n                    const int q0 = Q0;\n\n                    const int q1 = Q1;\n\n                    const int q2 = Q2;\n\n                    int delta0   = (9 * (q0 - p0) - 3 * (q1 - p1) + 8) >> 4;\n\n                    if (abs(delta0) < 10 * tc) {\n\n                        delta0 = av_clip(delta0, -tc, tc);\n\n                        if (!no_p)\n\n                            P0 = av_clip_pixel(p0 + delta0);\n\n                        if (!no_q)\n\n                            Q0 = av_clip_pixel(q0 - delta0);\n\n                        if (!no_p && nd_p > 1) {\n\n                            const int deltap1 = av_clip((((p2 + p0 + 1) >> 1) - p1 + delta0) >> 1, -tc_2, tc_2);\n\n                            P1 = av_clip_pixel(p1 + deltap1);\n\n                        }\n\n                        if (!no_q && nd_q > 1) {\n\n                            const int deltaq1 = av_clip((((q2 + q0 + 1) >> 1) - q1 - delta0) >> 1, -tc_2, tc_2);\n\n                            Q1 = av_clip_pixel(q1 + deltaq1);\n\n                        }\n\n                    }\n\n                    pix += ystride;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 19725, "_split": "valid", "_hash": "5bc755fc8931e3c61f3b8987d8d31e87"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(rgb24to16)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tconst uint8_t *s = src;\n\n\tconst uint8_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint8_t *mm_end;\n\n#endif\n\n\tuint16_t *d = (uint16_t *)dst;\n\n\tend = s + src_size;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*src):\"memory\");\n\n\t__asm __volatile(\n\n\t    \"movq\t%0, %%mm7\\n\\t\"\n\n\t    \"movq\t%1, %%mm6\\n\\t\"\n\n\t    ::\"m\"(red_16mask),\"m\"(green_16mask));\n\n\tmm_end = end - 11;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movd\t%1, %%mm0\\n\\t\"\n\n\t\t\"movd\t3%1, %%mm3\\n\\t\"\n\n\t\t\"punpckldq 6%1, %%mm0\\n\\t\"\n\n\t\t\"punpckldq 9%1, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm3, %%mm5\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm3\\n\\t\"\n\n\t\t\"pand\t%2, %%mm0\\n\\t\"\n\n\t\t\"pand\t%2, %%mm3\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$5, %%mm4\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm6, %%mm4\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm2\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm5\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm2\\n\\t\"\n\n\t\t\"pand\t%%mm7, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\t:\"=m\"(*d):\"m\"(*s),\"m\"(blue_16mask):\"memory\");\n\n\t\td += 4;\n\n\t\ts += 12;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tconst int b= *s++;\n\n\t\tconst int g= *s++;\n\n\t\tconst int r= *s++;\n\n\t\t*d++ = (b>>3) | ((g&0xFC)<<3) | ((r&0xF8)<<8);\n\n\t}\n\n}\n", "idx": 19751, "_split": "valid", "_hash": "1d9b02f22e189e1287557f1006f233cb"}
{"project": "FFmpeg", "commit_id": "c96bd21227e594856f8fd0610fd213b002056383", "target": 0, "func": "static int mp3_read_probe(AVProbeData *p)\n\n{\n\n    int max_frames, first_frames = 0;\n\n    int fsize, frames, sample_rate;\n\n    uint32_t header;\n\n    uint8_t *buf, *buf2, *end;\n\n    AVCodecContext avctx;\n\n\n\n    if(id3v2_match(p->buf))\n\n        return AVPROBE_SCORE_MAX/2+1; // this must be less than mpeg-ps because some retards put id3v2 tags before mpeg-ps files\n\n\n\n    max_frames = 0;\n\n    buf = p->buf;\n\n    end = buf + p->buf_size - sizeof(uint32_t);\n\n\n\n    for(; buf < end; buf= buf2+1) {\n\n        buf2 = buf;\n\n\n\n        for(frames = 0; buf2 < end; frames++) {\n\n            header = AV_RB32(buf2);\n\n            fsize = ff_mpa_decode_header(&avctx, header, &sample_rate);\n\n            if(fsize < 0)\n\n                break;\n\n            buf2 += fsize;\n\n        }\n\n        max_frames = FFMAX(max_frames, frames);\n\n        if(buf == p->buf)\n\n            first_frames= frames;\n\n    }\n\n    if   (first_frames>=3) return AVPROBE_SCORE_MAX/2+1;\n\n    else if(max_frames>500)return AVPROBE_SCORE_MAX/2;\n\n    else if(max_frames>=3) return AVPROBE_SCORE_MAX/4;\n\n    else if(max_frames>=1) return 1;\n\n    else                   return 0;\n\n}\n", "idx": 19752, "_split": "valid", "_hash": "db3e2180c37ec428b5cd1017ad07dfea"}
{"project": "FFmpeg", "commit_id": "2862b63783b5556f7f3fb2d097629bc6879f833a", "target": 0, "func": "static int ljpeg_encode_yuv(AVCodecContext *avctx, PutBitContext *pb,\n\n                            const AVFrame *frame)\n\n{\n\n    const int predictor = avctx->prediction_method + 1;\n\n    LJpegEncContext *s  = avctx->priv_data;\n\n    const int mb_width  = (avctx->width  + s->hsample[0] - 1) / s->hsample[0];\n\n    const int mb_height = (avctx->height + s->vsample[0] - 1) / s->vsample[0];\n\n    int mb_x, mb_y;\n\n\n\n    for (mb_y = 0; mb_y < mb_height; mb_y++) {\n\n        if (pb->buf_end - pb->buf - (put_bits_count(pb) >> 3) <\n\n            mb_width * 4 * 3 * s->hsample[0] * s->vsample[0]) {\n\n            av_log(avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n            return -1;\n\n        }\n\n\n\n        for (mb_x = 0; mb_x < mb_width; mb_x++)\n\n            ljpeg_encode_yuv_mb(s, pb, frame, predictor, mb_x, mb_y);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 19758, "_split": "valid", "_hash": "c38c7642ecb427b9cd143e6e0d938063"}
{"project": "FFmpeg", "commit_id": "c3390fd56cf55259ea7665ecea6c8aeddf56e2fc", "target": 1, "func": "static av_cold int ra144_decode_init(AVCodecContext * avctx)\n{\n    RA144Context *ractx = avctx->priv_data;\n    ractx->avctx = avctx;\n    ractx->lpc_coef[0] = ractx->lpc_tables[0];\n    ractx->lpc_coef[1] = ractx->lpc_tables[1];\n    avctx->channels       = 1;\n    avctx->channel_layout = AV_CH_LAYOUT_MONO;\n    avctx->sample_fmt     = AV_SAMPLE_FMT_S16;\n    return 0;\n}", "idx": 19788, "_split": "valid", "_hash": "027c46ea0af758911a292c73b36f1892"}
{"project": "FFmpeg", "commit_id": "cb077b7aa319caf4a11e811df93b1c2b86fff954", "target": 1, "func": "static int alloc_tables(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    const int big_mb_num= s->mb_stride * (s->mb_height+1);\n\n    int x,y;\n\n\n\n    CHECKED_ALLOCZ(h->intra4x4_pred_mode, big_mb_num * 8  * sizeof(uint8_t))\n\n\n\n    CHECKED_ALLOCZ(h->non_zero_count    , big_mb_num * 16 * sizeof(uint8_t))\n\n    CHECKED_ALLOCZ(h->slice_table_base  , (big_mb_num+s->mb_stride) * sizeof(uint8_t))\n\n    CHECKED_ALLOCZ(h->cbp_table, big_mb_num * sizeof(uint16_t))\n\n\n\n    if( h->pps.cabac ) {\n\n        CHECKED_ALLOCZ(h->chroma_pred_mode_table, big_mb_num * sizeof(uint8_t))\n\n        CHECKED_ALLOCZ(h->mvd_table[0], 32*big_mb_num * sizeof(uint16_t));\n\n        CHECKED_ALLOCZ(h->mvd_table[1], 32*big_mb_num * sizeof(uint16_t));\n\n        CHECKED_ALLOCZ(h->direct_table, 32*big_mb_num * sizeof(uint8_t));\n\n    }\n\n\n\n    memset(h->slice_table_base, -1, (big_mb_num+s->mb_stride)  * sizeof(uint8_t));\n\n    h->slice_table= h->slice_table_base + s->mb_stride*2 + 1;\n\n\n\n    CHECKED_ALLOCZ(h->mb2b_xy  , big_mb_num * sizeof(uint32_t));\n\n    CHECKED_ALLOCZ(h->mb2b8_xy , big_mb_num * sizeof(uint32_t));\n\n    for(y=0; y<s->mb_height; y++){\n\n        for(x=0; x<s->mb_width; x++){\n\n            const int mb_xy= x + y*s->mb_stride;\n\n            const int b_xy = 4*x + 4*y*h->b_stride;\n\n            const int b8_xy= 2*x + 2*y*h->b8_stride;\n\n\n\n            h->mb2b_xy [mb_xy]= b_xy;\n\n            h->mb2b8_xy[mb_xy]= b8_xy;\n\n        }\n\n    }\n\n\n\n    s->obmc_scratchpad = NULL;\n\n\n\n    if(!h->dequant4_coeff[0])\n\n        init_dequant_tables(h);\n\n\n\n    return 0;\n\nfail:\n\n    free_tables(h);\n\n    return -1;\n\n}\n", "idx": 19845, "_split": "valid", "_hash": "98c1e856ff45eb89348fdf9745c10480"}
{"project": "FFmpeg", "commit_id": "b7dc6f662868fbdad779c61c233b1d19d8b89d3c", "target": 1, "func": "static void RENAME(swScale)(SwsContext *c, uint8_t* srcParam[], int srcStrideParam[], int srcSliceY,\n\n             int srcSliceH, uint8_t* dstParam[], int dstStrideParam[]){\n\n\n\n\t/* load a few things into local vars to make the code more readable? and faster */\n\n\tconst int srcW= c->srcW;\n\n\tconst int dstW= c->dstW;\n\n\tconst int dstH= c->dstH;\n\n\tconst int chrDstW= c->chrDstW;\n\n\tconst int lumXInc= c->lumXInc;\n\n\tconst int chrXInc= c->chrXInc;\n\n\tconst int dstFormat= c->dstFormat;\n\n\tconst int flags= c->flags;\n\n\tconst int canMMX2BeUsed= c->canMMX2BeUsed;\n\n\tint16_t *vLumFilterPos= c->vLumFilterPos;\n\n\tint16_t *vChrFilterPos= c->vChrFilterPos;\n\n\tint16_t *hLumFilterPos= c->hLumFilterPos;\n\n\tint16_t *hChrFilterPos= c->hChrFilterPos;\n\n\tint16_t *vLumFilter= c->vLumFilter;\n\n\tint16_t *vChrFilter= c->vChrFilter;\n\n\tint16_t *hLumFilter= c->hLumFilter;\n\n\tint16_t *hChrFilter= c->hChrFilter;\n\n\tint16_t *lumMmxFilter= c->lumMmxFilter;\n\n\tint16_t *chrMmxFilter= c->chrMmxFilter;\n\n\tconst int vLumFilterSize= c->vLumFilterSize;\n\n\tconst int vChrFilterSize= c->vChrFilterSize;\n\n\tconst int hLumFilterSize= c->hLumFilterSize;\n\n\tconst int hChrFilterSize= c->hChrFilterSize;\n\n\tint16_t **lumPixBuf= c->lumPixBuf;\n\n\tint16_t **chrPixBuf= c->chrPixBuf;\n\n\tconst int vLumBufSize= c->vLumBufSize;\n\n\tconst int vChrBufSize= c->vChrBufSize;\n\n\tuint8_t *funnyYCode= c->funnyYCode;\n\n\tuint8_t *funnyUVCode= c->funnyUVCode;\n\n\tuint8_t *formatConvBuffer= c->formatConvBuffer;\n\n\n\n\t/* vars whch will change and which we need to storw back in the context */\n\n\tint dstY= c->dstY;\n\n\tint lumBufIndex= c->lumBufIndex;\n\n\tint chrBufIndex= c->chrBufIndex;\n\n\tint lastInLumBuf= c->lastInLumBuf;\n\n\tint lastInChrBuf= c->lastInChrBuf;\n\n\tint srcStride[3];\n\n\tint dstStride[3];\n\n\tuint8_t *src[3];\n\n\tuint8_t *dst[3];\n\n\t\n\n\tif(c->srcFormat == IMGFMT_I420){\n\n\t\tsrc[0]= srcParam[0];\n\n\t\tsrc[1]= srcParam[2];\n\n\t\tsrc[2]= srcParam[1];\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]= srcStrideParam[2];\n\n\t\tsrcStride[2]= srcStrideParam[1];\n\n\t}\n\n\telse if(c->srcFormat==IMGFMT_YV12){\n\n\t\tsrc[0]= srcParam[0];\n\n\t\tsrc[1]= srcParam[1];\n\n\t\tsrc[2]= srcParam[2];\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]= srcStrideParam[1];\n\n\t\tsrcStride[2]= srcStrideParam[2];\n\n\t}\n\n\telse if(isPacked(c->srcFormat)){\n\n\t\tsrc[0]=\n\n\t\tsrc[1]=\n\n\t\tsrc[2]= srcParam[0];\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]=\n\n\t\tsrcStride[2]= srcStrideParam[0]<<1;\n\n\t}\n\n\telse if(isGray(c->srcFormat)){\n\n\t\tsrc[0]= srcParam[0];\n\n\t\tsrc[1]=\n\n\t\tsrc[2]= NULL;\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]=\n\n\t\tsrcStride[2]= 0;\n\n\t}\n\n\n\n\tif(dstFormat == IMGFMT_I420){\n\n\t\tdst[0]= dstParam[0];\n\n\t\tdst[1]= dstParam[2];\n\n\t\tdst[2]= dstParam[1];\n\n\t\tdstStride[0]= dstStrideParam[0];\n\n\t\tdstStride[1]= dstStrideParam[2];\n\n\t\tdstStride[2]= dstStrideParam[1];\n\n\t}else{\n\n\t\tdst[0]= dstParam[0];\n\n\t\tdst[1]= dstParam[1];\n\n\t\tdst[2]= dstParam[2];\n\n\t\tdstStride[0]= dstStrideParam[0];\n\n\t\tdstStride[1]= dstStrideParam[1];\n\n\t\tdstStride[2]= dstStrideParam[2];\n\n\t}\n\n\n\n//printf(\"sws Strides:%d %d %d -> %d %d %d\\n\", srcStride[0],srcStride[1],srcStride[2],\n\n//dstStride[0],dstStride[1],dstStride[2]);\n\n\n\n\tif(dstStride[0]%8 !=0 || dstStride[1]%8 !=0 || dstStride[2]%8 !=0)\n\n\t{\n\n\t\tstatic int firstTime=1; //FIXME move this into the context perhaps\n\n\t\tif(flags & SWS_PRINT_INFO && firstTime)\n\n\t\t{\n\n\t\t\tfprintf(stderr, \"SwScaler: Warning: dstStride is not aligned!\\n\"\n\n\t\t\t\t\t\"SwScaler:          ->cannot do aligned memory acesses anymore\\n\");\n\n\t\t\tfirstTime=0;\n\n\t\t}\n\n\t}\n\n\n\n\t/* Note the user might start scaling the picture in the middle so this will not get executed\n\n\t   this is not really intended but works currently, so ppl might do it */\n\n\tif(srcSliceY ==0){\n\n\t\tlumBufIndex=0;\n\n\t\tchrBufIndex=0;\n\n\t\tdstY=0;\t\n\n\t\tlastInLumBuf= -1;\n\n\t\tlastInChrBuf= -1;\n\n\t}\n\n\n\n\tfor(;dstY < dstH; dstY++){\n\n\t\tunsigned char *dest =dst[0]+dstStride[0]*dstY;\n\n\t\tunsigned char *uDest=dst[1]+dstStride[1]*(dstY>>1);\n\n\t\tunsigned char *vDest=dst[2]+dstStride[2]*(dstY>>1);\n\n\t\tconst int chrDstY= isHalfChrV(dstFormat) ? (dstY>>1) : dstY;\n\n\n\n\t\tconst int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n\t\tconst int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n\t\tconst int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n\t\tconst int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n\n\n\t\t//handle holes (FAST_BILINEAR & weird filters)\n\n\t\tif(firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n\t\tif(firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n//printf(\"%d %d %d\\n\", firstChrSrcY, lastInChrBuf, vChrBufSize);\n\n\t\tASSERT(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1)\n\n\t\tASSERT(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1)\n\n\n\n\t\t// Do we have enough lines in this slice to output the dstY line\n\n\t\tif(lastLumSrcY < srcSliceY + srcSliceH && lastChrSrcY < ((srcSliceY + srcSliceH + 1)>>1))\n\n\t\t{\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf < lastLumSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *s= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n\t\t\t\tlumBufIndex++;\n\n//\t\t\t\tprintf(\"%d %d %d %d\\n\", lumBufIndex, vLumBufSize, lastInLumBuf,  lastLumSrcY);\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n//\t\t\t\tprintf(\"%d %d\\n\", lumBufIndex, vLumBufSize);\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, s, srcW, lumXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n\t\t\t\t\t\tfunnyYCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf < lastChrSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= src[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[1];\n\n\t\t\t\tuint8_t *src2= src[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < ((srcSliceH+1)>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\t//FIXME replace parameters through context struct (some at least)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, (srcW+1)>>1, chrXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hChrFilter, hChrFilterPos, hChrFilterSize,\n\n\t\t\t\t\t\tfunnyUVCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t}\n\n\t\telse // not enough lines left in this slice -> load the rest in the buffer\n\n\t\t{\n\n/*\t\tprintf(\"%d %d Last:%d %d LastInBuf:%d %d Index:%d %d Y:%d FSize: %d %d BSize: %d %d\\n\",\n\n\t\t\tfirstChrSrcY,firstLumSrcY,lastChrSrcY,lastLumSrcY,\n\n\t\t\tlastInChrBuf,lastInLumBuf,chrBufIndex,lumBufIndex,dstY,vChrFilterSize,vLumFilterSize,\n\n\t\t\tvChrBufSize, vLumBufSize);\n\n*/\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf+1 < srcSliceY + srcSliceH)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *s= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n\t\t\t\tlumBufIndex++;\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, s, srcW, lumXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n\t\t\t\t\t\tfunnyYCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf+1 < ((srcSliceY + srcSliceH)>>1))\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= src[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[1];\n\n\t\t\t\tuint8_t *src2= src[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < ((srcSliceH+1)>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, (srcW+1)>>1, chrXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hChrFilter, hChrFilterPos, hChrFilterSize,\n\n\t\t\t\t\t\tfunnyUVCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t\tbreak; //we cant output a dstY line so lets try with the next slice\n\n\t\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t\tb5Dither= dither8[dstY&1];\n\n\t\tg6Dither= dither4[dstY&1];\n\n\t\tg5Dither= dither8[dstY&1];\n\n\t\tr5Dither= dither8[(dstY+1)&1];\n\n#endif\n\n\t    if(dstY < dstH-2)\n\n\t    {\n\n\t\tif(isPlanarYUV(dstFormat)) //YV12 like\n\n\t\t{\n\n\t\t\tif(dstY&1) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 1) // Unscaled YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t *lumBuf = lumPixBuf[0];\n\n\t\t\t\tint16_t *chrBuf= chrPixBuf[0];\n\n\t\t\t\tRENAME(yuv2yuv1)(lumBuf, chrBuf, dest, uDest, vDest, dstW);\n\n\t\t\t}\n\n\t\t\telse //General YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\t\t\t\tRENAME(yuv2yuvX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize     , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+(dstY>>1)*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, uDest, vDest, dstW,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+(dstY>>1)*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 2) //Unscaled RGB\n\n\t\t\t{\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb1)(*lumSrcPtr, *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, chrAlpha, dstFormat, flags);\n\n\t\t\t}\n\n\t\t\telse if(vLumFilterSize == 2 && vChrFilterSize == 2) //BiLinear Upscale RGB\n\n\t\t\t{\n\n\t\t\t\tint lumAlpha= vLumFilter[2*dstY+1];\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb2)(*lumSrcPtr, *(lumSrcPtr+1), *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, lumAlpha, chrAlpha, dstFormat, flags);\n\n\t\t\t}\n\n\t\t\telse //General RGB\n\n\t\t\t{\n\n\t\t\t\tRENAME(yuv2rgbX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, dstW, dstFormat,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+dstY*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n            }\n\n\t    else // hmm looks like we cant use MMX here without overwriting this arrays tail\n\n\t    {\n\n\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\t\tif(isPlanarYUV(dstFormat)) //YV12\n\n\t\t{\n\n\t\t\tif(dstY&1) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tyuv2yuvXinC(\n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize     , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+(dstY>>1)*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, uDest, vDest, dstW);\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tyuv2rgbXinC(\n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, dstW, dstFormat);\n\n\t\t}\n\n\t    }\n\n\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\t/* store changed local vars back in the context */\n\n\tc->dstY= dstY;\n\n\tc->lumBufIndex= lumBufIndex;\n\n\tc->chrBufIndex= chrBufIndex;\n\n\tc->lastInLumBuf= lastInLumBuf;\n\n\tc->lastInChrBuf= lastInChrBuf;\n\n}\n", "idx": 19864, "_split": "valid", "_hash": "6b31c2d89920c54b6eec0666151e6e8d"}
{"project": "FFmpeg", "commit_id": "23fe14bb20888038b91e62b16d50fe0b75043a10", "target": 1, "func": "static int vmdaudio_decode_init(AVCodecContext *avctx)\n\n{\n\n    VmdAudioContext *s = (VmdAudioContext *)avctx->priv_data;\n\n    int i;\n\n\n\n    s->channels = avctx->channels;\n\n    s->bits = avctx->bits_per_sample;\n\n    s->block_align = avctx->block_align;\n\n\n\nprintf (\"  %d channels, %d bits/sample, block align = %d\\n\",\n\n  s->channels, s->bits, s->block_align);\n\n\n\n    /* set up the steps8 and steps16 tables */\n\n    for (i = 0; i < 8; i++) {\n\n        if (i < 4)\n\n            s->steps8[i] = i;\n\n        else\n\n            s->steps8[i] = s->steps8[i - 1] + i - 1;\n\n\n\n        if (i == 0)\n\n            s->steps16[i] = 0;\n\n        else if (i == 1)\n\n            s->steps16[i] = 4;\n\n        else if (i == 2)\n\n            s->steps16[i] = 16;\n\n        else\n\n            s->steps16[i] = 1 << (i + 4);\n\n    }\n\n\n\n    /* set up the step128 table */\n\n    s->steps128[0] = 0;\n\n    s->steps128[1] = 8;\n\n    for (i = 0x02; i <= 0x20; i++)\n\n        s->steps128[i] = (i - 1) << 4;\n\n    for (i = 0x21; i <= 0x60; i++)\n\n        s->steps128[i] = (i + 0x1F) << 3;\n\n    for (i = 0x61; i <= 0x70; i++)\n\n        s->steps128[i] = (i - 0x51) << 6;\n\n    for (i = 0x71; i <= 0x78; i++)\n\n        s->steps128[i] = (i - 0x69) << 8;\n\n    for (i = 0x79; i <= 0x7D; i++)\n\n        s->steps128[i] = (i - 0x75) << 10;\n\n    s->steps128[0x7E] = 0x3000;\n\n    s->steps128[0x7F] = 0x4000;\n\n\n\n    /* set up the negative half of each table */\n\n    for (i = 0; i < 8; i++) {\n\n        s->steps8[i + 8] = -s->steps8[i];\n\n        s->steps16[i + 8] = -s->steps16[i];\n\n    }\n\n    for (i = 0; i < 128; i++)\n\n      s->steps128[i + 128] = -s->steps128[i];\n\n\n\n    return 0;\n\n}\n", "idx": 19893, "_split": "valid", "_hash": "a4a69a885594234d40b1185f5f89f6d2"}
{"project": "FFmpeg", "commit_id": "4c2d4e8700cd3db59bc11ab196c0002215cf601f", "target": 1, "func": "static int decode_slice(AVCodecContext *c, void *arg)\n\n{\n\n    FFV1Context *fs   = *(void **)arg;\n\n    FFV1Context *f    = fs->avctx->priv_data;\n\n    int width, height, x, y, ret;\n\n    const int ps      = av_pix_fmt_desc_get(c->pix_fmt)->comp[0].step;\n\n    AVFrame * const p = f->cur;\n\n    int i, si;\n\n\n\n    for( si=0; fs != f->slice_context[si]; si ++)\n\n        ;\n\n\n\n    if(f->fsrc && !p->key_frame)\n\n        ff_thread_await_progress(&f->last_picture, si, 0);\n\n\n\n    if(f->fsrc && !p->key_frame) {\n\n        FFV1Context *fssrc = f->fsrc->slice_context[si];\n\n        FFV1Context *fsdst = f->slice_context[si];\n\n        av_assert1(fsdst->plane_count == fssrc->plane_count);\n\n        av_assert1(fsdst == fs);\n\n\n\n        if (!p->key_frame)\n\n            fsdst->slice_damaged |= fssrc->slice_damaged;\n\n\n\n        for (i = 0; i < f->plane_count; i++) {\n\n            PlaneContext *psrc = &fssrc->plane[i];\n\n            PlaneContext *pdst = &fsdst->plane[i];\n\n\n\n            av_free(pdst->state);\n\n            av_free(pdst->vlc_state);\n\n            memcpy(pdst, psrc, sizeof(*pdst));\n\n            pdst->state = NULL;\n\n            pdst->vlc_state = NULL;\n\n\n\n            if (fssrc->ac) {\n\n                pdst->state = av_malloc_array(CONTEXT_SIZE,  psrc->context_count);\n\n                memcpy(pdst->state, psrc->state, CONTEXT_SIZE * psrc->context_count);\n\n            } else {\n\n                pdst->vlc_state = av_malloc_array(sizeof(*pdst->vlc_state), psrc->context_count);\n\n                memcpy(pdst->vlc_state, psrc->vlc_state, sizeof(*pdst->vlc_state) * psrc->context_count);\n\n            }\n\n        }\n\n    }\n\n\n\n    fs->slice_rct_by_coef = 1;\n\n    fs->slice_rct_ry_coef = 1;\n\n\n\n    if (f->version > 2) {\n\n        if (ff_ffv1_init_slice_state(f, fs) < 0)\n\n            return AVERROR(ENOMEM);\n\n        if (decode_slice_header(f, fs) < 0) {\n\n\n            fs->slice_damaged = 1;\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    if ((ret = ff_ffv1_init_slice_state(f, fs)) < 0)\n\n        return ret;\n\n    if (f->cur->key_frame || fs->slice_reset_contexts)\n\n        ff_ffv1_clear_slice_state(f, fs);\n\n\n\n    width  = fs->slice_width;\n\n    height = fs->slice_height;\n\n    x      = fs->slice_x;\n\n    y      = fs->slice_y;\n\n\n\n    if (!fs->ac) {\n\n        if (f->version == 3 && f->micro_version > 1 || f->version > 3)\n\n            get_rac(&fs->c, (uint8_t[]) { 129 });\n\n        fs->ac_byte_count = f->version > 2 || (!x && !y) ? fs->c.bytestream - fs->c.bytestream_start - 1 : 0;\n\n        init_get_bits(&fs->gb,\n\n                      fs->c.bytestream_start + fs->ac_byte_count,\n\n                      (fs->c.bytestream_end - fs->c.bytestream_start - fs->ac_byte_count) * 8);\n\n    }\n\n\n\n    av_assert1(width && height);\n\n    if (f->colorspace == 0) {\n\n        const int chroma_width  = FF_CEIL_RSHIFT(width,  f->chroma_h_shift);\n\n        const int chroma_height = FF_CEIL_RSHIFT(height, f->chroma_v_shift);\n\n        const int cx            = x >> f->chroma_h_shift;\n\n        const int cy            = y >> f->chroma_v_shift;\n\n        decode_plane(fs, p->data[0] + ps*x + y*p->linesize[0], width, height, p->linesize[0], 0);\n\n\n\n        if (f->chroma_planes) {\n\n            decode_plane(fs, p->data[1] + ps*cx+cy*p->linesize[1], chroma_width, chroma_height, p->linesize[1], 1);\n\n            decode_plane(fs, p->data[2] + ps*cx+cy*p->linesize[2], chroma_width, chroma_height, p->linesize[2], 1);\n\n        }\n\n        if (fs->transparency)\n\n            decode_plane(fs, p->data[3] + ps*x + y*p->linesize[3], width, height, p->linesize[3], (f->version >= 4 && !f->chroma_planes) ? 1 : 2);\n\n    } else {\n\n        uint8_t *planes[3] = { p->data[0] + ps * x + y * p->linesize[0],\n\n                               p->data[1] + ps * x + y * p->linesize[1],\n\n                               p->data[2] + ps * x + y * p->linesize[2] };\n\n        decode_rgb_frame(fs, planes, width, height, p->linesize);\n\n    }\n\n    if (fs->ac && f->version > 2) {\n\n        int v;\n\n        get_rac(&fs->c, (uint8_t[]) { 129 });\n\n        v = fs->c.bytestream_end - fs->c.bytestream - 2 - 5*f->ec;\n\n        if (v) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"bytestream end mismatching by %d\\n\", v);\n\n            fs->slice_damaged = 1;\n\n        }\n\n    }\n\n\n\n    emms_c();\n\n\n\n    ff_thread_report_progress(&f->picture, si, 0);\n\n\n\n    return 0;\n\n}", "idx": 19910, "_split": "valid", "_hash": "23ab29f8a4d6d96f7fb78488a1b472ee"}
{"project": "FFmpeg", "commit_id": "a3145d0335b04d143c26832c91dcc7242c758206", "target": 0, "func": "static av_cold int bmv_aud_decode_init(AVCodecContext *avctx)\n\n{\n\n    BMVAudioDecContext *c = avctx->priv_data;\n\n\n\n    if (avctx->channels != 2) {\n\n        av_log(avctx, AV_LOG_INFO, \"invalid number of channels\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n\n\n    avcodec_get_frame_defaults(&c->frame);\n\n    avctx->coded_frame = &c->frame;\n\n\n\n    return 0;\n\n}\n", "idx": 19919, "_split": "valid", "_hash": "67a99b8b4a142744c3e4ad3ca29cc4cf"}
{"project": "FFmpeg", "commit_id": "feeb3a92616310b5f79191b0ef3064712c40b7d3", "target": 1, "func": "static int build_filter(ResampleContext *c, void *filter, double factor, int tap_count, int alloc, int phase_count, int scale,\n\n                        int filter_type, double kaiser_beta){\n\n    int ph, i;\n\n    double x, y, w, t, s;\n\n    double *tab = av_malloc_array(tap_count+1,  sizeof(*tab));\n\n    double *sin_lut = av_malloc_array(phase_count / 2 + 1, sizeof(*sin_lut));\n\n    const int center= (tap_count-1)/2;\n\n\n\n    if (!tab || !sin_lut)\n\n        goto fail;\n\n\n\n    /* if upsampling, only need to interpolate, no filter */\n\n    if (factor > 1.0)\n\n        factor = 1.0;\n\n\n\n    av_assert0(phase_count == 1 || phase_count % 2 == 0);\n\n\n\n    if (factor == 1.0) {\n\n        for (ph = 0; ph <= phase_count / 2; ph++)\n\n            sin_lut[ph] = sin(M_PI * ph / phase_count);\n\n    }\n\n    for(ph = 0; ph <= phase_count / 2; ph++) {\n\n        double norm = 0;\n\n        s = sin_lut[ph];\n\n        for(i=0;i<=tap_count;i++) {\n\n            x = M_PI * ((double)(i - center) - (double)ph / phase_count) * factor;\n\n            if (x == 0) y = 1.0;\n\n            else if (factor == 1.0)\n\n                y = s / x;\n\n            else\n\n                y = sin(x) / x;\n\n            switch(filter_type){\n\n            case SWR_FILTER_TYPE_CUBIC:{\n\n                const float d= -0.5; //first order derivative = -0.5\n\n                x = fabs(((double)(i - center) - (double)ph / phase_count) * factor);\n\n                if(x<1.0) y= 1 - 3*x*x + 2*x*x*x + d*(            -x*x + x*x*x);\n\n                else      y=                       d*(-4 + 8*x - 5*x*x + x*x*x);\n\n                break;}\n\n            case SWR_FILTER_TYPE_BLACKMAN_NUTTALL:\n\n                w = 2.0*x / (factor*tap_count);\n\n                t = -cos(w);\n\n                y *= 0.3635819 - 0.4891775 * t + 0.1365995 * (2*t*t-1) - 0.0106411 * (4*t*t*t - 3*t);\n\n                break;\n\n            case SWR_FILTER_TYPE_KAISER:\n\n                w = 2.0*x / (factor*tap_count*M_PI);\n\n                y *= bessel(kaiser_beta*sqrt(FFMAX(1-w*w, 0)));\n\n                break;\n\n            default:\n\n                av_assert0(0);\n\n            }\n\n\n\n            tab[i] = y;\n\n            s = -s;\n\n            if (i < tap_count)\n\n                norm += y;\n\n        }\n\n\n\n        /* normalize so that an uniform color remains the same */\n\n        switch(c->format){\n\n        case AV_SAMPLE_FMT_S16P:\n\n            for(i=0;i<tap_count;i++)\n\n                ((int16_t*)filter)[ph * alloc + i] = av_clip_int16(lrintf(tab[i] * scale / norm));\n\n            if (tap_count % 2 == 0) {\n\n                for (i = 0; i < tap_count; i++)\n\n                    ((int16_t*)filter)[(phase_count-ph) * alloc + tap_count-1-i] = ((int16_t*)filter)[ph * alloc + i];\n\n            }\n\n            else {\n\n                for (i = 1; i <= tap_count; i++)\n\n                    ((int16_t*)filter)[(phase_count-ph) * alloc + tap_count-i] =\n\n                        av_clip_int16(lrintf(tab[i] * scale / (norm - tab[0] + tab[tap_count])));\n\n            }\n\n            break;\n\n        case AV_SAMPLE_FMT_S32P:\n\n            for(i=0;i<tap_count;i++)\n\n                ((int32_t*)filter)[ph * alloc + i] = av_clipl_int32(llrint(tab[i] * scale / norm));\n\n            if (tap_count % 2 == 0) {\n\n                for (i = 0; i < tap_count; i++)\n\n                    ((int32_t*)filter)[(phase_count-ph) * alloc + tap_count-1-i] = ((int32_t*)filter)[ph * alloc + i];\n\n            }\n\n            else {\n\n                for (i = 1; i <= tap_count; i++)\n\n                    ((int32_t*)filter)[(phase_count-ph) * alloc + tap_count-i] =\n\n                        av_clipl_int32(llrint(tab[i] * scale / (norm - tab[0] + tab[tap_count])));\n\n            }\n\n            break;\n\n        case AV_SAMPLE_FMT_FLTP:\n\n            for(i=0;i<tap_count;i++)\n\n                ((float*)filter)[ph * alloc + i] = tab[i] * scale / norm;\n\n            if (tap_count % 2 == 0) {\n\n                for (i = 0; i < tap_count; i++)\n\n                    ((float*)filter)[(phase_count-ph) * alloc + tap_count-1-i] = ((float*)filter)[ph * alloc + i];\n\n            }\n\n            else {\n\n                for (i = 1; i <= tap_count; i++)\n\n                    ((float*)filter)[(phase_count-ph) * alloc + tap_count-i] = tab[i] * scale / (norm - tab[0] + tab[tap_count]);\n\n            }\n\n            break;\n\n        case AV_SAMPLE_FMT_DBLP:\n\n            for(i=0;i<tap_count;i++)\n\n                ((double*)filter)[ph * alloc + i] = tab[i] * scale / norm;\n\n            if (tap_count % 2 == 0) {\n\n                for (i = 0; i < tap_count; i++)\n\n                    ((double*)filter)[(phase_count-ph) * alloc + tap_count-1-i] = ((double*)filter)[ph * alloc + i];\n\n            }\n\n            else {\n\n                for (i = 1; i <= tap_count; i++)\n\n                    ((double*)filter)[(phase_count-ph) * alloc + tap_count-i] = tab[i] * scale / (norm - tab[0] + tab[tap_count]);\n\n            }\n\n            break;\n\n        }\n\n    }\n\n#if 0\n\n    {\n\n#define LEN 1024\n\n        int j,k;\n\n        double sine[LEN + tap_count];\n\n        double filtered[LEN];\n\n        double maxff=-2, minff=2, maxsf=-2, minsf=2;\n\n        for(i=0; i<LEN; i++){\n\n            double ss=0, sf=0, ff=0;\n\n            for(j=0; j<LEN+tap_count; j++)\n\n                sine[j]= cos(i*j*M_PI/LEN);\n\n            for(j=0; j<LEN; j++){\n\n                double sum=0;\n\n                ph=0;\n\n                for(k=0; k<tap_count; k++)\n\n                    sum += filter[ph * tap_count + k] * sine[k+j];\n\n                filtered[j]= sum / (1<<FILTER_SHIFT);\n\n                ss+= sine[j + center] * sine[j + center];\n\n                ff+= filtered[j] * filtered[j];\n\n                sf+= sine[j + center] * filtered[j];\n\n            }\n\n            ss= sqrt(2*ss/LEN);\n\n            ff= sqrt(2*ff/LEN);\n\n            sf= 2*sf/LEN;\n\n            maxff= FFMAX(maxff, ff);\n\n            minff= FFMIN(minff, ff);\n\n            maxsf= FFMAX(maxsf, sf);\n\n            minsf= FFMIN(minsf, sf);\n\n            if(i%11==0){\n\n                av_log(NULL, AV_LOG_ERROR, \"i:%4d ss:%f ff:%13.6e-%13.6e sf:%13.6e-%13.6e\\n\", i, ss, maxff, minff, maxsf, minsf);\n\n                minff=minsf= 2;\n\n                maxff=maxsf= -2;\n\n            }\n\n        }\n\n    }\n\n#endif\n\n\n\nfail:\n\n    av_free(tab);\n\n    av_free(sin_lut);\n\n    return 0;\n\n}\n", "idx": 19996, "_split": "valid", "_hash": "63ee21bbdfbf015985fb57c084eafd5c"}
{"project": "FFmpeg", "commit_id": "29208e6dcf944bbea696d37a354a8bac9b552709", "target": 0, "func": "int av_image_fill_arrays(uint8_t *dst_data[4], int dst_linesize[4],\n\n                         const uint8_t *src,\n\n                         enum AVPixelFormat pix_fmt, int width, int height, int align)\n\n{\n\n    int ret, i;\n\n\n\n    if ((ret = av_image_check_size(width, height, 0, NULL)) < 0)\n\n        return ret;\n\n\n\n    if ((ret = av_image_fill_linesizes(dst_linesize, pix_fmt, width)) < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < 4; i++)\n\n        dst_linesize[i] = FFALIGN(dst_linesize[i], align);\n\n\n\n    if ((ret = av_image_fill_pointers(dst_data, pix_fmt, width, NULL, dst_linesize)) < 0)\n\n        return ret;\n\n\n\n    return av_image_fill_pointers(dst_data, pix_fmt, height, (uint8_t *)src, dst_linesize);\n\n}\n", "idx": 20017, "_split": "valid", "_hash": "ea3b12fbf642ef15c89c58a773d6954e"}
{"project": "FFmpeg", "commit_id": "271344377a3391c1a8ccc45e021721a56f237612", "target": 1, "func": "static int mov_read_extradata(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    uint64_t size= (uint64_t)st->codec->extradata_size + atom.size + 8 + FF_INPUT_BUFFER_PADDING_SIZE;\n\n    uint8_t *buf;\n\n    if(size > INT_MAX || (uint64_t)atom.size > INT_MAX)\n\n        return -1;\n\n    buf= av_realloc(st->codec->extradata, size);\n\n    if(!buf)\n\n        return -1;\n\n    st->codec->extradata= buf;\n\n    buf+= st->codec->extradata_size;\n\n    st->codec->extradata_size= size - FF_INPUT_BUFFER_PADDING_SIZE;\n\n    AV_WB32(       buf    , atom.size + 8);\n\n    AV_WL32(       buf + 4, atom.type);\n\n    get_buffer(pb, buf + 8, atom.size);\n\n    return 0;\n\n}\n", "idx": 20034, "_split": "valid", "_hash": "6d1098572f35a738d7a0bf24606e6db3"}
{"project": "FFmpeg", "commit_id": "9ecf7fada31aac294dee540abb9a8dcf8131d67d", "target": 1, "func": "static void av_estimate_timings(AVFormatContext *ic)\n\n{\n\n    int64_t file_size;\n\n\n\n    /* get the file size, if possible */\n\n    if (ic->iformat->flags & AVFMT_NOFILE) {\n\n        file_size = 0;\n\n    } else {\n\n        file_size = url_fsize(&ic->pb);\n\n        if (file_size < 0)\n\n            file_size = 0;\n\n    }\n\n    ic->file_size = file_size;\n\n\n\n    if ((!strcmp(ic->iformat->name, \"mpeg\") ||\n\n         !strcmp(ic->iformat->name, \"mpegts\")) &&\n\n        file_size && !ic->pb.is_streamed) {\n\n        /* get accurate estimate from the PTSes */\n\n        av_estimate_timings_from_pts(ic);\n\n    } else if (av_has_timings(ic)) {\n\n        /* at least one components has timings - we use them for all\n\n           the components */\n\n        fill_all_stream_timings(ic);\n\n    } else {\n\n        /* less precise: use bit rate info */\n\n        av_estimate_timings_from_bit_rate(ic);\n\n    }\n\n    av_update_stream_timings(ic);\n\n\n\n#if 0\n\n    {\n\n        int i;\n\n        AVStream *st;\n\n        for(i = 0;i < ic->nb_streams; i++) {\n\n            st = ic->streams[i];\n\n        printf(\"%d: start_time: %0.3f duration: %0.3f\\n\",\n\n               i, (double)st->start_time / AV_TIME_BASE,\n\n               (double)st->duration / AV_TIME_BASE);\n\n        }\n\n        printf(\"stream: start_time: %0.3f duration: %0.3f bitrate=%d kb/s\\n\",\n\n               (double)ic->start_time / AV_TIME_BASE,\n\n               (double)ic->duration / AV_TIME_BASE,\n\n               ic->bit_rate / 1000);\n\n    }\n\n#endif\n\n}\n", "idx": 20040, "_split": "valid", "_hash": "3e6df3f042e932e299a2d2a7e877aa5f"}
{"project": "FFmpeg", "commit_id": "8f60f70d44c14cead6033456c9e58ae7aa9e83cc", "target": 0, "func": "static av_cold int ac3_encode_init(AVCodecContext *avctx)\n\n{\n\n    int freq = avctx->sample_rate;\n\n    int bitrate = avctx->bit_rate;\n\n    AC3EncodeContext *s = avctx->priv_data;\n\n    int i, j, ch;\n\n    int bw_code;\n\n\n\n    avctx->frame_size = AC3_FRAME_SIZE;\n\n\n\n    ac3_common_init();\n\n\n\n    if (!avctx->channel_layout) {\n\n        av_log(avctx, AV_LOG_WARNING, \"No channel layout specified. The \"\n\n                                      \"encoder will guess the layout, but it \"\n\n                                      \"might be incorrect.\\n\");\n\n    }\n\n    if (set_channel_info(s, avctx->channels, &avctx->channel_layout)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid channel layout\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* frequency */\n\n    for (i = 0; i < 3; i++) {\n\n        for (j = 0; j < 3; j++)\n\n            if ((ff_ac3_sample_rate_tab[j] >> i) == freq)\n\n                goto found;\n\n    }\n\n    return -1;\n\n found:\n\n    s->sample_rate        = freq;\n\n    s->bit_alloc.sr_shift = i;\n\n    s->bit_alloc.sr_code  = j;\n\n    s->bitstream_id       = 8 + s->bit_alloc.sr_shift;\n\n    s->bitstream_mode     = 0; /* complete main audio service */\n\n\n\n    /* bitrate & frame size */\n\n    for (i = 0; i < 19; i++) {\n\n        if ((ff_ac3_bitrate_tab[i] >> s->bit_alloc.sr_shift)*1000 == bitrate)\n\n            break;\n\n    }\n\n    if (i == 19)\n\n        return -1;\n\n    s->bit_rate        = bitrate;\n\n    s->frame_size_code = i << 1;\n\n    s->frame_size_min  = 2 * ff_ac3_frame_size_tab[s->frame_size_code][s->bit_alloc.sr_code];\n\n    s->bits_written    = 0;\n\n    s->samples_written = 0;\n\n    s->frame_size      = s->frame_size_min;\n\n\n\n    /* set bandwidth */\n\n    if (avctx->cutoff) {\n\n        /* calculate bandwidth based on user-specified cutoff frequency */\n\n        int cutoff     = av_clip(avctx->cutoff, 1, s->sample_rate >> 1);\n\n        int fbw_coeffs = cutoff * 2 * AC3_MAX_COEFS / s->sample_rate;\n\n        bw_code        = av_clip((fbw_coeffs - 73) / 3, 0, 60);\n\n    } else {\n\n        /* use default bandwidth setting */\n\n        /* XXX: should compute the bandwidth according to the frame\n\n           size, so that we avoid annoying high frequency artifacts */\n\n        bw_code = 50;\n\n    }\n\n    for (ch = 0; ch < s->fbw_channels; ch++) {\n\n        /* bandwidth for each channel */\n\n        s->bandwidth_code[ch] = bw_code;\n\n        s->nb_coefs[ch]       = bw_code * 3 + 73;\n\n    }\n\n    if (s->lfe_on)\n\n        s->nb_coefs[s->lfe_channel] = 7; /* LFE channel always has 7 coefs */\n\n\n\n    /* initial snr offset */\n\n    s->coarse_snr_offset = 40;\n\n\n\n    mdct_init(9);\n\n\n\n    avctx->coded_frame= avcodec_alloc_frame();\n\n    avctx->coded_frame->key_frame= 1;\n\n\n\n    return 0;\n\n}\n", "idx": 20055, "_split": "valid", "_hash": "3ff3491ddd901be95da1542d3488e04b"}
{"project": "FFmpeg", "commit_id": "e64673e4f4f7acefe5f60f35fb3a196ccf5e9490", "target": 0, "func": "static void gen_connect(URLContext *s, RTMPContext *rt)\n\n{\n\n    RTMPPacket pkt;\n\n    uint8_t ver[64], *p;\n\n\n\n    ff_rtmp_packet_create(&pkt, RTMP_SYSTEM_CHANNEL, RTMP_PT_INVOKE, 0, 4096);\n\n    p = pkt.data;\n\n\n\n    ff_amf_write_string(&p, \"connect\");\n\n    ff_amf_write_number(&p, ++rt->nb_invokes);\n\n    ff_amf_write_object_start(&p);\n\n    ff_amf_write_field_name(&p, \"app\");\n\n    ff_amf_write_string(&p, rt->app);\n\n\n\n    if (rt->is_input) {\n\n        snprintf(ver, sizeof(ver), \"%s %d,%d,%d,%d\", RTMP_CLIENT_PLATFORM, RTMP_CLIENT_VER1,\n\n                 RTMP_CLIENT_VER2, RTMP_CLIENT_VER3, RTMP_CLIENT_VER4);\n\n    } else {\n\n        snprintf(ver, sizeof(ver), \"FMLE/3.0 (compatible; %s)\", LIBAVFORMAT_IDENT);\n\n        ff_amf_write_field_name(&p, \"type\");\n\n        ff_amf_write_string(&p, \"nonprivate\");\n\n    }\n\n    ff_amf_write_field_name(&p, \"flashVer\");\n\n    ff_amf_write_string(&p, ver);\n\n    ff_amf_write_field_name(&p, \"tcUrl\");\n\n    ff_amf_write_string(&p, rt->tcurl);\n\n    if (rt->is_input) {\n\n        ff_amf_write_field_name(&p, \"fpad\");\n\n        ff_amf_write_bool(&p, 0);\n\n        ff_amf_write_field_name(&p, \"capabilities\");\n\n        ff_amf_write_number(&p, 15.0);\n\n\n\n        /* Tell the server we support all the audio codecs except\n\n         * SUPPORT_SND_INTEL (0x0008) and SUPPORT_SND_UNUSED (0x0010)\n\n         * which are unused in the RTMP protocol implementation. */\n\n        ff_amf_write_field_name(&p, \"audioCodecs\");\n\n        ff_amf_write_number(&p, 4071.0);\n\n        ff_amf_write_field_name(&p, \"videoCodecs\");\n\n        ff_amf_write_number(&p, 252.0);\n\n        ff_amf_write_field_name(&p, \"videoFunction\");\n\n        ff_amf_write_number(&p, 1.0);\n\n    }\n\n    ff_amf_write_object_end(&p);\n\n\n\n    pkt.data_size = p - pkt.data;\n\n\n\n    ff_rtmp_packet_write(rt->stream, &pkt, rt->chunk_size, rt->prev_pkt[1]);\n\n    ff_rtmp_packet_destroy(&pkt);\n\n}\n", "idx": 20056, "_split": "valid", "_hash": "486c4a03c0febee4c8e960ef27a65626"}
{"project": "FFmpeg", "commit_id": "436f00b10c062b75c7aab276c4a7d64524bd0444", "target": 0, "func": "static int wrapped_avframe_encode(AVCodecContext *avctx, AVPacket *pkt,\n\n                     const AVFrame *frame, int *got_packet)\n\n{\n\n    AVFrame *wrapped = av_frame_clone(frame);\n\n\n\n    if (!wrapped)\n\n        return AVERROR(ENOMEM);\n\n\n\n    pkt->buf = av_buffer_create((uint8_t *)wrapped, sizeof(*wrapped),\n\n                                wrapped_avframe_release_buffer, NULL,\n\n                                AV_BUFFER_FLAG_READONLY);\n\n    if (!pkt->buf) {\n\n        av_frame_free(&wrapped);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    pkt->data = (uint8_t *)wrapped;\n\n    pkt->size = sizeof(*wrapped);\n\n\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n    return 0;\n\n}\n", "idx": 20067, "_split": "valid", "_hash": "46339f01702dbe0ebd82128dadf7b3dc"}
{"project": "FFmpeg", "commit_id": "7f2fe444a39bca733d390b6608801c5f002bfd31", "target": 0, "func": "int MPV_encode_init(AVCodecContext *avctx)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    avctx->pix_fmt = PIX_FMT_YUV420P;\n\n\n\n    s->bit_rate = avctx->bit_rate;\n\n    s->bit_rate_tolerance = avctx->bit_rate_tolerance;\n\n    s->frame_rate = avctx->frame_rate;\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n    s->gop_size = avctx->gop_size;\n\n    s->rtp_mode = avctx->rtp_mode;\n\n    s->rtp_payload_size = avctx->rtp_payload_size;\n\n    if (avctx->rtp_callback)\n\n        s->rtp_callback = avctx->rtp_callback;\n\n    s->qmin= avctx->qmin;\n\n    s->qmax= avctx->qmax;\n\n    s->max_qdiff= avctx->max_qdiff;\n\n    s->qcompress= avctx->qcompress;\n\n    s->qblur= avctx->qblur;\n\n    s->b_quant_factor= avctx->b_quant_factor;\n\n    s->avctx = avctx;\n\n    s->aspect_ratio_info= avctx->aspect_ratio_info;\n\n    s->flags= avctx->flags;\n\n    s->max_b_frames= avctx->max_b_frames;\n\n    s->rc_strategy= avctx->rc_strategy;\n\n    s->b_frame_strategy= avctx->b_frame_strategy;\n\n    s->codec_id= avctx->codec->id;\n\n\n\n    if (s->gop_size <= 1) {\n\n        s->intra_only = 1;\n\n        s->gop_size = 12;\n\n    } else {\n\n        s->intra_only = 0;\n\n    }\n\n    \n\n    /* ME algorithm */\n\n    if (avctx->me_method == 0)\n\n        /* For compatibility */\n\n        s->me_method = motion_estimation_method;\n\n    else\n\n        s->me_method = avctx->me_method;\n\n        \n\n    /* Fixed QSCALE */\n\n    s->fixed_qscale = (avctx->flags & CODEC_FLAG_QSCALE);\n\n    \n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_MPEG1VIDEO:\n\n        s->out_format = FMT_MPEG1;\n\n        avctx->delay=0; //FIXME not sure, should check the spec\n\n        break;\n\n    case CODEC_ID_MJPEG:\n\n        s->out_format = FMT_MJPEG;\n\n        s->intra_only = 1; /* force intra only for jpeg */\n\n        s->mjpeg_write_tables = 1; /* write all tables */\n\n\ts->mjpeg_data_only_frames = 0; /* write all the needed headers */\n\n        s->mjpeg_vsample[0] = 2; /* set up default sampling factors */\n\n        s->mjpeg_vsample[1] = 1; /* the only currently supported values */\n\n        s->mjpeg_vsample[2] = 1; \n\n        s->mjpeg_hsample[0] = 2;\n\n        s->mjpeg_hsample[1] = 1; \n\n        s->mjpeg_hsample[2] = 1; \n\n        if (mjpeg_init(s) < 0)\n\n            return -1;\n\n        avctx->delay=0;\n\n        break;\n\n    case CODEC_ID_H263:\n\n        if (h263_get_picture_format(s->width, s->height) == 7) {\n\n            printf(\"Input picture size isn't suitable for h263 codec! try h263+\\n\");\n\n            return -1;\n\n        }\n\n        s->out_format = FMT_H263;\n\n        avctx->delay=0;\n\n        break;\n\n    case CODEC_ID_H263P:\n\n        s->out_format = FMT_H263;\n\n        s->rtp_mode = 1;\n\n        s->rtp_payload_size = 1200; \n\n        s->h263_plus = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->h263_aic = 1;\n\n        \n\n        /* These are just to be sure */\n\n        s->umvplus = 0;\n\n        s->umvplus_dec = 0;\n\n        avctx->delay=0;\n\n        break;\n\n    case CODEC_ID_RV10:\n\n        s->out_format = FMT_H263;\n\n        s->h263_rv10 = 1;\n\n        avctx->delay=0;\n\n        break;\n\n    case CODEC_ID_MPEG4:\n\n        s->out_format = FMT_H263;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->has_b_frames= s->max_b_frames ? 1 : 0;\n\n        s->low_delay=0;\n\n        avctx->delay= s->low_delay ? 0 : (s->max_b_frames + 1); \n\n        break;\n\n    case CODEC_ID_MSMPEG4V1:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 1;\n\n        avctx->delay=0;\n\n        break;\n\n    case CODEC_ID_MSMPEG4V2:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 2;\n\n        avctx->delay=0;\n\n        break;\n\n    case CODEC_ID_MSMPEG4V3:\n\n        s->out_format = FMT_H263;\n\n        s->h263_msmpeg4 = 1;\n\n        s->h263_pred = 1;\n\n        s->unrestricted_mv = 1;\n\n        s->msmpeg4_version= 3;\n\n        avctx->delay=0;\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n    \n\n    if((s->flags&CODEC_FLAG_4MV) && !(s->flags&CODEC_FLAG_HQ)){\n\n        printf(\"4MV is currently only supported in HQ mode\\n\");\n\n        return -1;\n\n    }\n\n\n\n    { /* set up some save defaults, some codecs might override them later */\n\n        static int done=0;\n\n        if(!done){\n\n            int i;\n\n            done=1;\n\n            memset(default_mv_penalty, 0, sizeof(UINT16)*(MAX_FCODE+1)*(2*MAX_MV+1));\n\n            memset(default_fcode_tab , 0, sizeof(UINT8)*(2*MAX_MV+1));\n\n\n\n            for(i=-16; i<16; i++){\n\n                default_fcode_tab[i + MAX_MV]= 1;\n\n            }\n\n        }\n\n    }\n\n    s->mv_penalty= default_mv_penalty;\n\n    s->fcode_tab= default_fcode_tab;\n\n\n\n    if (s->out_format == FMT_H263)\n\n        h263_encode_init(s);\n\n    else if (s->out_format == FMT_MPEG1)\n\n        mpeg1_encode_init(s);\n\n\n\n    /* dont use mv_penalty table for crap MV as it would be confused */\n\n    if (s->me_method < ME_EPZS) s->mv_penalty = default_mv_penalty;\n\n\n\n    s->encoding = 1;\n\n\n\n    /* init */\n\n    if (MPV_common_init(s) < 0)\n\n        return -1;\n\n    \n\n    /* init default q matrix */\n\n    for(i=0;i<64;i++) {\n\n        if(s->out_format == FMT_H263)\n\n            s->intra_matrix[i] = default_non_intra_matrix[i];\n\n        else\n\n            s->intra_matrix[i] = default_intra_matrix[i];\n\n\n\n        s->inter_matrix[i] = default_non_intra_matrix[i];\n\n    }\n\n\n\n    /* precompute matrix */\n\n    /* for mjpeg, we do include qscale in the matrix */\n\n    if (s->out_format != FMT_MJPEG) {\n\n        convert_matrix(s->q_intra_matrix, s->q_intra_matrix16, s->q_intra_matrix16_bias, \n\n                       s->intra_matrix, s->intra_quant_bias);\n\n        convert_matrix(s->q_inter_matrix, s->q_inter_matrix16, s->q_inter_matrix16_bias, \n\n                       s->inter_matrix, s->inter_quant_bias);\n\n    }\n\n\n\n    if(ff_rate_control_init(s) < 0)\n\n        return -1;\n\n\n\n    s->picture_number = 0;\n\n    s->picture_in_gop_number = 0;\n\n    s->fake_picture_number = 0;\n\n    /* motion detector init */\n\n    s->f_code = 1;\n\n    s->b_code = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 20136, "_split": "valid", "_hash": "c96e2514a3540e89b1f0bbf17201e53c"}
{"project": "FFmpeg", "commit_id": "ca16618b01abfde44b4eaf92dc89b01aa1b4a91e", "target": 0, "func": "static void inline xan_wc3_output_pixel_run(XanContext *s, \n\n    unsigned char *pixel_buffer, int x, int y, int pixel_count)\n\n{\n\n    int stride;\n\n    int line_inc;\n\n    int index;\n\n    int current_x;\n\n    int width = s->avctx->width;\n\n    unsigned char pix;\n\n    unsigned char *palette_plane;\n\n    unsigned char *y_plane;\n\n    unsigned char *u_plane;\n\n    unsigned char *v_plane;\n\n    unsigned char *rgb_plane;\n\n    unsigned short *rgb16_plane;\n\n    unsigned short *palette16;\n\n    unsigned int *rgb32_plane;\n\n    unsigned int *palette32;\n\n\n\n    switch (s->avctx->pix_fmt) {\n\n\n\n    case PIX_FMT_PAL8:\n\n        palette_plane = s->current_frame.data[0];\n\n        stride = s->current_frame.linesize[0];\n\n        line_inc = stride - width;\n\n        index = y * stride + x;\n\n        current_x = x;\n\n        while(pixel_count--) {\n\n\n\n            /* don't do a memcpy() here; keyframes generally copy an entire\n\n             * frame of data and the stride needs to be accounted for */\n\n            palette_plane[index++] = *pixel_buffer++;\n\n\n\n            ADVANCE_CURRENT_X();\n\n        }\n\n        break;\n\n\n\n    case PIX_FMT_RGB555:\n\n    case PIX_FMT_RGB565:\n\n        rgb16_plane = (unsigned short *)s->current_frame.data[0];\n\n        palette16 = (unsigned short *)s->palette;\n\n        stride = s->current_frame.linesize[0] / 2;\n\n        line_inc = stride - width;\n\n        index = y * stride + x;\n\n        current_x = x;\n\n        while(pixel_count--) {\n\n\n\n            rgb16_plane[index++] = palette16[*pixel_buffer++];\n\n\n\n            ADVANCE_CURRENT_X();\n\n        }\n\n        break;\n\n\n\n    case PIX_FMT_RGB24:\n\n    case PIX_FMT_BGR24:\n\n        rgb_plane = s->current_frame.data[0];\n\n        stride = s->current_frame.linesize[0];\n\n        line_inc = stride - width * 3;\n\n        index = y * stride + x * 3;\n\n        current_x = x;\n\n        while(pixel_count--) {\n\n            pix = *pixel_buffer++;\n\n\n\n            rgb_plane[index++] = s->palette[pix * 4 + 0];\n\n            rgb_plane[index++] = s->palette[pix * 4 + 1];\n\n            rgb_plane[index++] = s->palette[pix * 4 + 2];\n\n\n\n            ADVANCE_CURRENT_X();\n\n        }\n\n        break;\n\n\n\n    case PIX_FMT_RGBA32:\n\n        rgb32_plane = (unsigned int *)s->current_frame.data[0];\n\n        palette32 = (unsigned int *)s->palette;\n\n        stride = s->current_frame.linesize[0] / 4;\n\n        line_inc = stride - width;\n\n        index = y * stride + x;\n\n        current_x = x;\n\n        while(pixel_count--) {\n\n\n\n            rgb32_plane[index++] = palette32[*pixel_buffer++];\n\n\n\n            ADVANCE_CURRENT_X();\n\n        }\n\n        break;\n\n\n\n    case PIX_FMT_YUV444P:\n\n        y_plane = s->current_frame.data[0];\n\n        u_plane = s->current_frame.data[1];\n\n        v_plane = s->current_frame.data[2];\n\n        stride = s->current_frame.linesize[0];\n\n        line_inc = stride - width;\n\n        index = y * stride + x;\n\n        current_x = x;\n\n        while(pixel_count--) {\n\n            pix = *pixel_buffer++;\n\n\n\n            y_plane[index] = s->palette[pix * 4 + 0];\n\n            u_plane[index] = s->palette[pix * 4 + 1];\n\n            v_plane[index] = s->palette[pix * 4 + 2];\n\n\n\n            index++;\n\n            ADVANCE_CURRENT_X();\n\n        }\n\n        break;\n\n\n\n    default:\n\n        av_log(s->avctx, AV_LOG_ERROR, \" Xan WC3: Unhandled colorspace\\n\");\n\n        break;\n\n    }\n\n}\n", "idx": 20138, "_split": "valid", "_hash": "1fcc542af46389e2e66a98bb59b6a742"}
{"project": "FFmpeg", "commit_id": "fefe43ff2c180928348d445abb9696cf2581d953", "target": 1, "func": "static int mov_read_hdlr(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    uint32_t type;\n\n    uint32_t ctype;\n\n\n\n    get_byte(pb); /* version */\n\n    get_be24(pb); /* flags */\n\n\n\n    /* component type */\n\n    ctype = get_le32(pb);\n\n    type = get_le32(pb); /* component subtype */\n\n\n\n    dprintf(c->fc, \"ctype= %c%c%c%c (0x%08x)\\n\", *((char *)&ctype), ((char *)&ctype)[1],\n\n            ((char *)&ctype)[2], ((char *)&ctype)[3], (int) ctype);\n\n    dprintf(c->fc, \"stype= %c%c%c%c\\n\",\n\n            *((char *)&type), ((char *)&type)[1], ((char *)&type)[2], ((char *)&type)[3]);\n\n    if(!ctype)\n\n        c->isom = 1;\n\n    if     (type == MKTAG('v','i','d','e'))\n\n        st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n    else if(type == MKTAG('s','o','u','n'))\n\n        st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n    else if(type == MKTAG('m','1','a',' '))\n\n        st->codec->codec_id = CODEC_ID_MP2;\n\n    else if(type == MKTAG('s','u','b','p')) {\n\n        st->codec->codec_type = CODEC_TYPE_SUBTITLE;\n\n    }\n\n    get_be32(pb); /* component  manufacture */\n\n    get_be32(pb); /* component flags */\n\n    get_be32(pb); /* component flags mask */\n\n\n\n    if(atom.size <= 24)\n\n        return 0; /* nothing left to read */\n\n\n\n    url_fskip(pb, atom.size - (url_ftell(pb) - atom.offset));\n\n    return 0;\n\n}\n", "idx": 20174, "_split": "valid", "_hash": "46b2240ec42fc720f010784d39abbb92"}
{"project": "FFmpeg", "commit_id": "39bb30f6640fe1faf4bbc779a79786028febc95d", "target": 1, "func": "static int mxf_read_cryptographic_context(MXFCryptoContext *cryptocontext, ByteIOContext *pb, int tag, int size, UID uid)\n\n{\n\n    if (size != 16)\n\n        return -1;\n\n    if (IS_KLV_KEY(uid, mxf_crypto_source_container_ul))\n\n        get_buffer(pb, cryptocontext->source_container_ul, 16);\n\n    return 0;\n\n}\n", "idx": 20181, "_split": "valid", "_hash": "70a46e0b8178871dedc1827ee46dfbe2"}
{"project": "FFmpeg", "commit_id": "2b17c7685fd3ff0bffaf3b45458d4a6283f3935f", "target": 1, "func": "static void assert_file_overwrite(const char *filename)\n\n{\n\n    if (file_overwrite && no_file_overwrite) {\n\n        fprintf(stderr, \"Error, both -y and -n supplied. Exiting.\\n\");\n\n        exit_program(1);\n\n    }\n\n\n\n    if (!file_overwrite &&\n\n        (strchr(filename, ':') == NULL || filename[1] == ':' ||\n\n         av_strstart(filename, \"file:\", NULL))) {\n\n        if (avio_check(filename, 0) == 0) {\n\n            if (stdin_interaction && !no_file_overwrite) {\n\n                fprintf(stderr,\"File '%s' already exists. Overwrite ? [y/N] \", filename);\n\n                fflush(stderr);\n\n                term_exit();\n\n                signal(SIGINT, SIG_DFL);\n\n                if (!read_yesno()) {\n\n                    av_log(NULL, AV_LOG_FATAL, \"Not overwriting - exiting\\n\");\n\n                    exit_program(1);\n\n                }\n\n                term_init();\n\n            }\n\n            else {\n\n                av_log(NULL, AV_LOG_FATAL, \"File '%s' already exists. Exiting.\\n\", filename);\n\n                exit_program(1);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 20184, "_split": "valid", "_hash": "6543ca91f544e4130225e4b852f15353"}
{"project": "FFmpeg", "commit_id": "182d4f1f3855460ee8634ea052f33332cf9d174e", "target": 0, "func": "static av_cold int oggvorbis_init_encoder(vorbis_info *vi,\n\n                                          AVCodecContext *avctx)\n\n{\n\n    OggVorbisContext *s = avctx->priv_data;\n\n    double cfreq;\n\n    int ret;\n\n\n\n    if (avctx->flags & CODEC_FLAG_QSCALE) {\n\n        /* variable bitrate\n\n         * NOTE: we use the oggenc range of -1 to 10 for global_quality for\n\n         *       user convenience, but libvorbis uses -0.1 to 1.0\n\n         */\n\n        float q = avctx->global_quality / (float)FF_QP2LAMBDA;\n\n        if ((ret = vorbis_encode_setup_vbr(vi, avctx->channels,\n\n                                           avctx->sample_rate,\n\n                                           q / 10.0)))\n\n            goto error;\n\n    } else {\n\n        int minrate = avctx->rc_min_rate > 0 ? avctx->rc_min_rate : -1;\n\n        int maxrate = avctx->rc_min_rate > 0 ? avctx->rc_max_rate : -1;\n\n\n\n        /* average bitrate */\n\n        if ((ret = vorbis_encode_setup_managed(vi, avctx->channels,\n\n                                               avctx->sample_rate, minrate,\n\n                                               avctx->bit_rate, maxrate)))\n\n            goto error;\n\n\n\n        /* variable bitrate by estimate, disable slow rate management */\n\n        if (minrate == -1 && maxrate == -1)\n\n            if ((ret = vorbis_encode_ctl(vi, OV_ECTL_RATEMANAGE2_SET, NULL)))\n\n                goto error;\n\n    }\n\n\n\n    /* cutoff frequency */\n\n    if (avctx->cutoff > 0) {\n\n        cfreq = avctx->cutoff / 1000.0;\n\n        if ((ret = vorbis_encode_ctl(vi, OV_ECTL_LOWPASS_SET, &cfreq)))\n\n            goto error;\n\n    }\n\n\n\n    /* impulse block bias */\n\n    if (s->iblock) {\n\n        if ((ret = vorbis_encode_ctl(vi, OV_ECTL_IBLOCK_SET, &s->iblock)))\n\n            goto error;\n\n    }\n\n\n\n    if ((ret = vorbis_encode_setup_init(vi)))\n\n        goto error;\n\n\n\n    return 0;\n\nerror:\n\n    return vorbis_error_to_averror(ret);\n\n}\n", "idx": 20243, "_split": "valid", "_hash": "a9a3134a17050d9ad5933d0044ebe916"}
{"project": "FFmpeg", "commit_id": "f121dbd9f76031d7f6d56261be2f14937a19d2dd", "target": 0, "func": "static int mpegts_write_header(AVFormatContext *s)\n\n{\n\n    MpegTSWrite *ts = s->priv_data;\n\n    MpegTSWriteStream *ts_st;\n\n    MpegTSService *service;\n\n    AVStream *st, *pcr_st = NULL;\n\n    AVDictionaryEntry *title, *provider;\n\n    int i, j;\n\n    const char *service_name;\n\n    const char *provider_name;\n\n    int *pids;\n\n    int ret;\n\n\n\n    if (s->max_delay < 0) /* Not set by the caller */\n\n        s->max_delay = 0;\n\n\n\n    // round up to a whole number of TS packets\n\n    ts->pes_payload_size = (ts->pes_payload_size + 14 + 183) / 184 * 184 - 14;\n\n\n\n    ts->tsid = ts->transport_stream_id;\n\n    ts->onid = ts->original_network_id;\n\n    /* allocate a single DVB service */\n\n    title = av_dict_get(s->metadata, \"service_name\", NULL, 0);\n\n    if (!title)\n\n        title = av_dict_get(s->metadata, \"title\", NULL, 0);\n\n    service_name = title ? title->value : DEFAULT_SERVICE_NAME;\n\n    provider = av_dict_get(s->metadata, \"service_provider\", NULL, 0);\n\n    provider_name = provider ? provider->value : DEFAULT_PROVIDER_NAME;\n\n    service = mpegts_add_service(ts, ts->service_id, provider_name, service_name);\n\n    service->pmt.write_packet = section_write_packet;\n\n    service->pmt.opaque = s;\n\n    service->pmt.cc = 15;\n\n\n\n    ts->pat.pid = PAT_PID;\n\n    ts->pat.cc = 15; // Initialize at 15 so that it wraps and be equal to 0 for the first packet we write\n\n    ts->pat.write_packet = section_write_packet;\n\n    ts->pat.opaque = s;\n\n\n\n    ts->sdt.pid = SDT_PID;\n\n    ts->sdt.cc = 15;\n\n    ts->sdt.write_packet = section_write_packet;\n\n    ts->sdt.opaque = s;\n\n\n\n    pids = av_malloc(s->nb_streams * sizeof(*pids));\n\n    if (!pids)\n\n        return AVERROR(ENOMEM);\n\n\n\n    /* assign pids to each stream */\n\n    for(i = 0;i < s->nb_streams; i++) {\n\n        st = s->streams[i];\n\n        avpriv_set_pts_info(st, 33, 1, 90000);\n\n        ts_st = av_mallocz(sizeof(MpegTSWriteStream));\n\n        if (!ts_st) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        st->priv_data = ts_st;\n\n        ts_st->payload = av_mallocz(ts->pes_payload_size);\n\n        if (!ts_st->payload) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        ts_st->service = service;\n\n        /* MPEG pid values < 16 are reserved. Applications which set st->id in\n\n         * this range are assigned a calculated pid. */\n\n        if (st->id < 16) {\n\n            ts_st->pid = ts->start_pid + i;\n\n        } else if (st->id < 0x1FFF) {\n\n            ts_st->pid = st->id;\n\n        } else {\n\n            av_log(s, AV_LOG_ERROR, \"Invalid stream id %d, must be less than 8191\\n\", st->id);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        if (ts_st->pid == service->pmt.pid) {\n\n            av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        for (j = 0; j < i; j++)\n\n            if (pids[j] == ts_st->pid) {\n\n                av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n        pids[i] = ts_st->pid;\n\n        ts_st->payload_pts = AV_NOPTS_VALUE;\n\n        ts_st->payload_dts = AV_NOPTS_VALUE;\n\n        ts_st->first_pts_check = 1;\n\n        ts_st->cc = 15;\n\n        /* update PCR pid by using the first video stream */\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n            service->pcr_pid == 0x1fff) {\n\n            service->pcr_pid = ts_st->pid;\n\n            pcr_st = st;\n\n        }\n\n        if (st->codec->codec_id == AV_CODEC_ID_AAC &&\n\n            st->codec->extradata_size > 0)\n\n        {\n\n            AVStream *ast;\n\n            ts_st->amux = avformat_alloc_context();\n\n            if (!ts_st->amux) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            ts_st->amux->oformat = av_guess_format((ts->flags & MPEGTS_FLAG_AAC_LATM) ? \"latm\" : \"adts\", NULL, NULL);\n\n            if (!ts_st->amux->oformat) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            ast = avformat_new_stream(ts_st->amux, NULL);\n\n            ret = avcodec_copy_context(ast->codec, st->codec);\n\n            if (ret != 0)\n\n                goto fail;\n\n            ret = avformat_write_header(ts_st->amux, NULL);\n\n            if (ret < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    av_free(pids);\n\n\n\n    /* if no video stream, use the first stream as PCR */\n\n    if (service->pcr_pid == 0x1fff && s->nb_streams > 0) {\n\n        pcr_st = s->streams[0];\n\n        ts_st = pcr_st->priv_data;\n\n        service->pcr_pid = ts_st->pid;\n\n    }\n\n\n\n    if (ts->mux_rate > 1) {\n\n        service->pcr_packet_period = (ts->mux_rate * PCR_RETRANS_TIME) /\n\n            (TS_PACKET_SIZE * 8 * 1000);\n\n        ts->sdt_packet_period      = (ts->mux_rate * SDT_RETRANS_TIME) /\n\n            (TS_PACKET_SIZE * 8 * 1000);\n\n        ts->pat_packet_period      = (ts->mux_rate * PAT_RETRANS_TIME) /\n\n            (TS_PACKET_SIZE * 8 * 1000);\n\n\n\n        ts->first_pcr = av_rescale(s->max_delay, PCR_TIME_BASE, AV_TIME_BASE);\n\n    } else {\n\n        /* Arbitrary values, PAT/PMT could be written on key frames */\n\n        ts->sdt_packet_period = 200;\n\n        ts->pat_packet_period = 40;\n\n        if (pcr_st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (!pcr_st->codec->frame_size) {\n\n                av_log(s, AV_LOG_WARNING, \"frame size not set\\n\");\n\n                service->pcr_packet_period =\n\n                    pcr_st->codec->sample_rate/(10*512);\n\n            } else {\n\n                service->pcr_packet_period =\n\n                    pcr_st->codec->sample_rate/(10*pcr_st->codec->frame_size);\n\n            }\n\n        } else {\n\n            // max delta PCR 0.1s\n\n            service->pcr_packet_period =\n\n                pcr_st->codec->time_base.den/(10*pcr_st->codec->time_base.num);\n\n        }\n\n    }\n\n\n\n    // output a PCR as soon as possible\n\n    service->pcr_packet_count = service->pcr_packet_period;\n\n    ts->pat_packet_count = ts->pat_packet_period-1;\n\n    ts->sdt_packet_count = ts->sdt_packet_period-1;\n\n\n\n    if (ts->mux_rate == 1)\n\n        av_log(s, AV_LOG_VERBOSE, \"muxrate VBR, \");\n\n    else\n\n        av_log(s, AV_LOG_VERBOSE, \"muxrate %d, \", ts->mux_rate);\n\n    av_log(s, AV_LOG_VERBOSE, \"pcr every %d pkts, \"\n\n           \"sdt every %d, pat/pmt every %d pkts\\n\",\n\n           service->pcr_packet_period,\n\n           ts->sdt_packet_period, ts->pat_packet_period);\n\n\n\n    avio_flush(s->pb);\n\n\n\n    return 0;\n\n\n\n fail:\n\n    av_free(pids);\n\n    for(i = 0;i < s->nb_streams; i++) {\n\n        MpegTSWriteStream *ts_st;\n\n        st = s->streams[i];\n\n        ts_st = st->priv_data;\n\n        if (ts_st) {\n\n            av_freep(&ts_st->payload);\n\n            if (ts_st->amux) {\n\n                avformat_free_context(ts_st->amux);\n\n                ts_st->amux = NULL;\n\n            }\n\n        }\n\n        av_freep(&st->priv_data);\n\n    }\n\n    return ret;\n\n}\n", "idx": 20321, "_split": "valid", "_hash": "c60621767c9391e219ea560252e88beb"}
{"project": "FFmpeg", "commit_id": "d1b284119bd5c6a52124443de2c45dbe569c25fc", "target": 0, "func": "static int read_ir(AVFilterLink *link, AVFrame *frame)\n\n{\n\n    AVFilterContext *ctx = link->dst;\n\n    AudioFIRContext *s = ctx->priv;\n\n    int nb_taps, max_nb_taps;\n\n\n\n    av_audio_fifo_write(s->fifo[1], (void **)frame->extended_data,\n\n                        frame->nb_samples);\n\n    av_frame_free(&frame);\n\n\n\n    nb_taps = av_audio_fifo_size(s->fifo[1]);\n\n    max_nb_taps = MAX_IR_DURATION * ctx->outputs[0]->sample_rate;\n\n    if (nb_taps > max_nb_taps) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Too big number of coefficients: %d > %d.\\n\", nb_taps, max_nb_taps);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 20385, "_split": "valid", "_hash": "b9e242ec0037c6608b6696d03f49d4a9"}
{"project": "FFmpeg", "commit_id": "3385989b98be7940044e4f0a6b431a0a00abf2fa", "target": 1, "func": "int ff_scale_eval_dimensions(void *log_ctx,\n\n    const char *w_expr, const char *h_expr,\n\n    AVFilterLink *inlink, AVFilterLink *outlink,\n\n    int *ret_w, int *ret_h)\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);\n\n    const AVPixFmtDescriptor *out_desc = av_pix_fmt_desc_get(outlink->format);\n\n    const char *expr;\n\n    int w, h;\n\n    int factor_w, factor_h;\n\n    int eval_w, eval_h;\n\n    int ret;\n\n    double var_values[VARS_NB], res;\n\n\n\n    var_values[VAR_PI]    = M_PI;\n\n    var_values[VAR_PHI]   = M_PHI;\n\n    var_values[VAR_E]     = M_E;\n\n    var_values[VAR_IN_W]  = var_values[VAR_IW] = inlink->w;\n\n    var_values[VAR_IN_H]  = var_values[VAR_IH] = inlink->h;\n\n    var_values[VAR_OUT_W] = var_values[VAR_OW] = NAN;\n\n    var_values[VAR_OUT_H] = var_values[VAR_OH] = NAN;\n\n    var_values[VAR_A]     = (double) inlink->w / inlink->h;\n\n    var_values[VAR_SAR]   = inlink->sample_aspect_ratio.num ?\n\n        (double) inlink->sample_aspect_ratio.num / inlink->sample_aspect_ratio.den : 1;\n\n    var_values[VAR_DAR]   = var_values[VAR_A] * var_values[VAR_SAR];\n\n    var_values[VAR_HSUB]  = 1 << desc->log2_chroma_w;\n\n    var_values[VAR_VSUB]  = 1 << desc->log2_chroma_h;\n\n    var_values[VAR_OHSUB] = 1 << out_desc->log2_chroma_w;\n\n    var_values[VAR_OVSUB] = 1 << out_desc->log2_chroma_h;\n\n\n\n    /* evaluate width and height */\n\n    av_expr_parse_and_eval(&res, (expr = w_expr),\n\n                           var_names, var_values,\n\n                           NULL, NULL, NULL, NULL, NULL, 0, log_ctx);\n\n    eval_w = var_values[VAR_OUT_W] = var_values[VAR_OW] = res;\n\n\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = h_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, log_ctx)) < 0)\n\n        goto fail;\n\n    eval_h = var_values[VAR_OUT_H] = var_values[VAR_OH] = res;\n\n    /* evaluate again the width, as it may depend on the output height */\n\n    if ((ret = av_expr_parse_and_eval(&res, (expr = w_expr),\n\n                                      var_names, var_values,\n\n                                      NULL, NULL, NULL, NULL, NULL, 0, log_ctx)) < 0)\n\n        goto fail;\n\n    eval_w = res;\n\n\n\n    w = eval_w;\n\n    h = eval_h;\n\n\n\n    /* Check if it is requested that the result has to be divisible by a some\n\n     * factor (w or h = -n with n being the factor). */\n\n    factor_w = 1;\n\n    factor_h = 1;\n\n    if (w < -1) {\n\n        factor_w = -w;\n\n    }\n\n    if (h < -1) {\n\n        factor_h = -h;\n\n    }\n\n\n\n    if (w < 0 && h < 0)\n\n        eval_w = eval_h = 0;\n\n\n\n    if (!(w = eval_w))\n\n        w = inlink->w;\n\n    if (!(h = eval_h))\n\n        h = inlink->h;\n\n\n\n    /* Make sure that the result is divisible by the factor we determined\n\n     * earlier. If no factor was set, it is nothing will happen as the default\n\n     * factor is 1 */\n\n    if (w < 0)\n\n        w = av_rescale(h, inlink->w, inlink->h * factor_w) * factor_w;\n\n    if (h < 0)\n\n        h = av_rescale(w, inlink->h, inlink->w * factor_h) * factor_h;\n\n\n\n    *ret_w = w;\n\n    *ret_h = h;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_log(log_ctx, AV_LOG_ERROR,\n\n           \"Error when evaluating the expression '%s'.\\n\"\n\n           \"Maybe the expression for out_w:'%s' or for out_h:'%s' is self-referencing.\\n\",\n\n           expr, w_expr, h_expr);\n\n    return ret;\n\n}\n", "idx": 20455, "_split": "valid", "_hash": "7857242407db77e3b2884898e3a8fa2a"}
{"project": "FFmpeg", "commit_id": "42d73f7f6bea0ee0f64a3ad4882860ce5b923a11", "target": 1, "func": "static int parse_strk(AVFormatContext *s,\n\n                      FourxmDemuxContext *fourxm, uint8_t *buf, int size)\n\n{\n\n    AVStream *st;\n\n    int track;\n\n    /* check that there is enough data */\n\n    if (size != strk_SIZE)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    track = AV_RL32(buf + 8);\n\n    if (track + 1 > fourxm->track_count) {\n\n        if (av_reallocp_array(&fourxm->tracks, track + 1, sizeof(AudioTrack)))\n\n            return AVERROR(ENOMEM);\n\n        memset(&fourxm->tracks[fourxm->track_count], 0,\n\n               sizeof(AudioTrack) * (track + 1 - fourxm->track_count));\n\n        fourxm->track_count = track + 1;\n\n    }\n\n    fourxm->tracks[track].adpcm       = AV_RL32(buf + 12);\n\n    fourxm->tracks[track].channels    = AV_RL32(buf + 36);\n\n    fourxm->tracks[track].sample_rate = AV_RL32(buf + 40);\n\n    fourxm->tracks[track].bits        = AV_RL32(buf + 44);\n\n    fourxm->tracks[track].audio_pts   = 0;\n\n\n\n    if (fourxm->tracks[track].channels    <= 0 ||\n\n        fourxm->tracks[track].sample_rate <= 0 ||\n\n        fourxm->tracks[track].bits        < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"audio header invalid\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    /* allocate a new AVStream */\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->id = track;\n\n    avpriv_set_pts_info(st, 60, 1, fourxm->tracks[track].sample_rate);\n\n\n\n    fourxm->tracks[track].stream_index = st->index;\n\n\n\n    st->codec->codec_type            = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_tag             = 0;\n\n    st->codec->channels              = fourxm->tracks[track].channels;\n\n    st->codec->sample_rate           = fourxm->tracks[track].sample_rate;\n\n    st->codec->bits_per_coded_sample = fourxm->tracks[track].bits;\n\n    st->codec->bit_rate              = st->codec->channels *\n\n                                       st->codec->sample_rate *\n\n                                       st->codec->bits_per_coded_sample;\n\n    st->codec->block_align           = st->codec->channels *\n\n                                       st->codec->bits_per_coded_sample;\n\n\n\n    if (fourxm->tracks[track].adpcm){\n\n        st->codec->codec_id = AV_CODEC_ID_ADPCM_4XM;\n\n    } else if (st->codec->bits_per_coded_sample == 8) {\n\n        st->codec->codec_id = AV_CODEC_ID_PCM_U8;\n\n    } else\n\n        st->codec->codec_id = AV_CODEC_ID_PCM_S16LE;\n\n\n\n    return 0;\n\n}\n", "idx": 20472, "_split": "valid", "_hash": "6c49b3cb9a2b27b8bfa308ea1e32bec4"}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline int blah (int32_t i)\n\n{\n\n    if (i > 0x43c07fff)\n\n        return 32767;\n\n    else if (i < 0x43bf8000)\n\n        return -32768;\n\n    else\n\n        return i - 0x43c00000;\n\n}\n", "idx": 20536, "_split": "valid", "_hash": "8dd2469e70ae48fa0efdaef405cfa050"}
{"project": "FFmpeg", "commit_id": "fbd91d7cad28915dd7e6061b869b22171ca84101", "target": 1, "func": "static int decode_tns(AACContext * ac, TemporalNoiseShaping * tns,\n\n        GetBitContext * gb, const IndividualChannelStream * ics) {\n\n    int w, filt, i, coef_len, coef_res, coef_compress;\n\n    const int is8 = ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE;\n\n    const int tns_max_order = is8 ? 7 : ac->m4ac.object_type == AOT_AAC_MAIN ? 20 : 12;\n\n    for (w = 0; w < ics->num_windows; w++) {\n\n        tns->n_filt[w] = get_bits(gb, 2 - is8);\n\n\n\n        if (tns->n_filt[w])\n\n            coef_res = get_bits1(gb);\n\n\n\n        for (filt = 0; filt < tns->n_filt[w]; filt++) {\n\n            int tmp2_idx;\n\n            tns->length[w][filt] = get_bits(gb, 6 - 2*is8);\n\n\n\n            if ((tns->order[w][filt] = get_bits(gb, 5 - 2*is8)) > tns_max_order) {\n\n                av_log(ac->avccontext, AV_LOG_ERROR, \"TNS filter order %d is greater than maximum %d.\",\n\n                       tns->order[w][filt], tns_max_order);\n\n                tns->order[w][filt] = 0;\n\n                return -1;\n\n            }\n\n            tns->direction[w][filt] = get_bits1(gb);\n\n            coef_compress = get_bits1(gb);\n\n            coef_len = coef_res + 3 - coef_compress;\n\n            tmp2_idx = 2*coef_compress + coef_res;\n\n\n\n            for (i = 0; i < tns->order[w][filt]; i++)\n\n                tns->coef[w][filt][i] = tns_tmp2_map[tmp2_idx][get_bits(gb, coef_len)];\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 20596, "_split": "valid", "_hash": "7eecdbe10cb30eeaa41ee05122c1c49f"}
{"project": "FFmpeg", "commit_id": "56cc024220886927350cfc26ee695062ca7ecaf4", "target": 1, "func": "static int mpc8_read_header(AVFormatContext *s)\n\n{\n\n    MPCContext *c = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    int tag = 0;\n\n    int64_t size, pos;\n\n\n\n    c->header_pos = avio_tell(pb);\n\n    if(avio_rl32(pb) != TAG_MPCK){\n\n        av_log(s, AV_LOG_ERROR, \"Not a Musepack8 file\\n\");\n\n\n\n\n\n    while(!avio_feof(pb)){\n\n        pos = avio_tell(pb);\n\n        mpc8_get_chunk_header(pb, &tag, &size);\n\n\n\n\n\n        if(tag == TAG_STREAMHDR)\n\n            break;\n\n        mpc8_handle_chunk(s, tag, pos, size);\n\n\n    if(tag != TAG_STREAMHDR){\n\n        av_log(s, AV_LOG_ERROR, \"Stream header not found\\n\");\n\n\n\n    pos = avio_tell(pb);\n\n    avio_skip(pb, 4); //CRC\n\n    c->ver = avio_r8(pb);\n\n    if(c->ver != 8){\n\n        av_log(s, AV_LOG_ERROR, \"Unknown stream version %d\\n\", c->ver);\n\n        return AVERROR_PATCHWELCOME;\n\n\n    c->samples = ffio_read_varlen(pb);\n\n    ffio_read_varlen(pb); //silence samples at the beginning\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_id = AV_CODEC_ID_MUSEPACK8;\n\n    st->codec->bits_per_coded_sample = 16;\n\n\n\n    if (ff_get_extradata(st->codec, pb, 2) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codec->channels = (st->codec->extradata[1] >> 4) + 1;\n\n    st->codec->sample_rate = mpc8_rate[st->codec->extradata[0] >> 5];\n\n    avpriv_set_pts_info(st, 32, 1152  << (st->codec->extradata[1]&3)*2, st->codec->sample_rate);\n\n    st->start_time = 0;\n\n    st->duration = c->samples / (1152 << (st->codec->extradata[1]&3)*2);\n\n    size -= avio_tell(pb) - pos;\n\n    if (size > 0)\n\n        avio_skip(pb, size);\n\n\n\n    if (pb->seekable) {\n\n        int64_t pos = avio_tell(s->pb);\n\n        c->apetag_start = ff_ape_parse_tag(s);\n\n        avio_seek(s->pb, pos, SEEK_SET);\n\n\n\n\n    return 0;\n", "idx": 20610, "_split": "valid", "_hash": "012449edbba0a8b990e186b6ee511b96"}
{"project": "FFmpeg", "commit_id": "79964745b3ed5a700f4f0dda56c7360497328c88", "target": 1, "func": "static int fourxm_read_header(AVFormatContext *s,\n\n                              AVFormatParameters *ap)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    unsigned int fourcc_tag;\n\n    unsigned int size;\n\n    int header_size;\n\n    FourxmDemuxContext *fourxm = s->priv_data;\n\n    unsigned char *header;\n\n    int i, ret;\n\n    AVStream *st;\n\n\n\n    fourxm->track_count = 0;\n\n    fourxm->tracks = NULL;\n\n    fourxm->fps = 1.0;\n\n\n\n    /* skip the first 3 32-bit numbers */\n\n    avio_skip(pb, 12);\n\n\n\n    /* check for LIST-HEAD */\n\n    GET_LIST_HEADER();\n\n    header_size = size - 4;\n\n    if (fourcc_tag != HEAD_TAG || header_size < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* allocate space for the header and load the whole thing */\n\n    header = av_malloc(header_size);\n\n    if (!header)\n\n        return AVERROR(ENOMEM);\n\n    if (avio_read(pb, header, header_size) != header_size){\n\n        av_free(header);\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    /* take the lazy approach and search for any and all vtrk and strk chunks */\n\n    for (i = 0; i < header_size - 8; i++) {\n\n        fourcc_tag = AV_RL32(&header[i]);\n\n        size = AV_RL32(&header[i + 4]);\n\n\n\n        if (fourcc_tag == std__TAG) {\n\n            fourxm->fps = av_int2flt(AV_RL32(&header[i + 12]));\n\n        } else if (fourcc_tag == vtrk_TAG) {\n\n            /* check that there is enough data */\n\n            if (size != vtrk_SIZE) {\n\n                ret= AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            fourxm->width  = AV_RL32(&header[i + 36]);\n\n            fourxm->height = AV_RL32(&header[i + 40]);\n\n\n\n            /* allocate a new AVStream */\n\n            st = av_new_stream(s, 0);\n\n            if (!st){\n\n                ret= AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            av_set_pts_info(st, 60, 1, fourxm->fps);\n\n\n\n            fourxm->video_stream_index = st->index;\n\n\n\n            st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n            st->codec->codec_id = CODEC_ID_4XM;\n\n            st->codec->extradata_size = 4;\n\n            st->codec->extradata = av_malloc(4);\n\n            AV_WL32(st->codec->extradata, AV_RL32(&header[i + 16]));\n\n            st->codec->width  = fourxm->width;\n\n            st->codec->height = fourxm->height;\n\n\n\n            i += 8 + size;\n\n        } else if (fourcc_tag == strk_TAG) {\n\n            int current_track;\n\n            /* check that there is enough data */\n\n            if (size != strk_SIZE) {\n\n                ret= AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            current_track = AV_RL32(&header[i + 8]);\n\n            if((unsigned)current_track >= UINT_MAX / sizeof(AudioTrack) - 1){\n\n                av_log(s, AV_LOG_ERROR, \"current_track too large\\n\");\n\n                ret= -1;\n\n                goto fail;\n\n            }\n\n            if (current_track + 1 > fourxm->track_count) {\n\n                fourxm->track_count = current_track + 1;\n\n                fourxm->tracks = av_realloc(fourxm->tracks,\n\n                    fourxm->track_count * sizeof(AudioTrack));\n\n                if (!fourxm->tracks) {\n\n                    ret=  AVERROR(ENOMEM);\n\n                    goto fail;\n\n                }\n\n            }\n\n            fourxm->tracks[current_track].adpcm       = AV_RL32(&header[i + 12]);\n\n            fourxm->tracks[current_track].channels    = AV_RL32(&header[i + 36]);\n\n            fourxm->tracks[current_track].sample_rate = AV_RL32(&header[i + 40]);\n\n            fourxm->tracks[current_track].bits        = AV_RL32(&header[i + 44]);\n\n            fourxm->tracks[current_track].audio_pts   = 0;\n\n            if(   fourxm->tracks[current_track].channels    <= 0\n\n               || fourxm->tracks[current_track].sample_rate <= 0\n\n               || fourxm->tracks[current_track].bits        <  0){\n\n                av_log(s, AV_LOG_ERROR, \"audio header invalid\\n\");\n\n                ret= -1;\n\n                goto fail;\n\n            }\n\n            i += 8 + size;\n\n\n\n            /* allocate a new AVStream */\n\n            st = av_new_stream(s, current_track);\n\n            if (!st){\n\n                ret= AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n\n\n            av_set_pts_info(st, 60, 1, fourxm->tracks[current_track].sample_rate);\n\n\n\n            fourxm->tracks[current_track].stream_index = st->index;\n\n\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n            st->codec->codec_tag = 0;\n\n            st->codec->channels              = fourxm->tracks[current_track].channels;\n\n            st->codec->sample_rate           = fourxm->tracks[current_track].sample_rate;\n\n            st->codec->bits_per_coded_sample = fourxm->tracks[current_track].bits;\n\n            st->codec->bit_rate              = st->codec->channels * st->codec->sample_rate *\n\n                st->codec->bits_per_coded_sample;\n\n            st->codec->block_align = st->codec->channels * st->codec->bits_per_coded_sample;\n\n            if (fourxm->tracks[current_track].adpcm){\n\n                st->codec->codec_id = CODEC_ID_ADPCM_4XM;\n\n            }else if (st->codec->bits_per_coded_sample == 8){\n\n                st->codec->codec_id = CODEC_ID_PCM_U8;\n\n            }else\n\n                st->codec->codec_id = CODEC_ID_PCM_S16LE;\n\n        }\n\n    }\n\n\n\n    /* skip over the LIST-MOVI chunk (which is where the stream should be */\n\n    GET_LIST_HEADER();\n\n    if (fourcc_tag != MOVI_TAG){\n\n        ret= AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n    av_free(header);\n\n    /* initialize context members */\n\n    fourxm->video_pts = -1;  /* first frame will push to 0 */\n\n\n\n    return 0;\n\nfail:\n\n    av_freep(&fourxm->tracks);\n\n    av_free(header);\n\n    return ret;\n\n}\n", "idx": 20638, "_split": "valid", "_hash": "10a98511c06f08016c677bbb1d4dab27"}
{"project": "FFmpeg", "commit_id": "5745cf799a4389bc5d14f2b4daf32fe4631c50bc", "target": 1, "func": "static int read_extra_header(FFV1Context *f)\n\n{\n\n    RangeCoder *const c = &f->c;\n\n    uint8_t state[CONTEXT_SIZE];\n\n    int i, j, k, ret;\n\n    uint8_t state2[32][CONTEXT_SIZE];\n\n    unsigned crc = 0;\n\n\n\n    memset(state2, 128, sizeof(state2));\n\n    memset(state, 128, sizeof(state));\n\n\n\n    ff_init_range_decoder(c, f->avctx->extradata, f->avctx->extradata_size);\n\n    ff_build_rac_states(c, 0.05 * (1LL << 32), 256 - 8);\n\n\n\n    f->version = get_symbol(c, state, 0);\n\n    if (f->version < 2) {\n\n        av_log(f->avctx, AV_LOG_ERROR, \"Invalid version in global header\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (f->version > 2) {\n\n        c->bytestream_end -= 4;\n\n        f->micro_version = get_symbol(c, state, 0);\n\n        if (f->micro_version < 0)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n    f->ac = f->avctx->coder_type = get_symbol(c, state, 0);\n\n    if (f->ac > 1) {\n\n        for (i = 1; i < 256; i++)\n\n            f->state_transition[i] = get_symbol(c, state, 1) + c->one_state[i];\n\n    }\n\n\n\n    f->colorspace                 = get_symbol(c, state, 0); //YUV cs type\n\n    f->avctx->bits_per_raw_sample = get_symbol(c, state, 0);\n\n    f->chroma_planes              = get_rac(c, state);\n\n    f->chroma_h_shift             = get_symbol(c, state, 0);\n\n    f->chroma_v_shift             = get_symbol(c, state, 0);\n\n    f->transparency               = get_rac(c, state);\n\n    f->plane_count                = 1 + (f->chroma_planes || f->version<4) + f->transparency;\n\n    f->num_h_slices               = 1 + get_symbol(c, state, 0);\n\n    f->num_v_slices               = 1 + get_symbol(c, state, 0);\n\n\n\n    if (f->chroma_h_shift > 4U || f->chroma_v_shift > 4U) {\n\n        av_log(f->avctx, AV_LOG_ERROR, \"chroma shift parameters %d %d are invalid\\n\",\n\n               f->chroma_h_shift, f->chroma_v_shift);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (f->num_h_slices > (unsigned)f->width  || !f->num_h_slices ||\n\n        f->num_v_slices > (unsigned)f->height || !f->num_v_slices\n\n       ) {\n\n        av_log(f->avctx, AV_LOG_ERROR, \"slice count invalid\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    f->quant_table_count = get_symbol(c, state, 0);\n\n    if (f->quant_table_count > (unsigned)MAX_QUANT_TABLES)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    for (i = 0; i < f->quant_table_count; i++) {\n\n        f->context_count[i] = read_quant_tables(c, f->quant_tables[i]);\n\n        if (f->context_count[i] < 0) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"read_quant_table error\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    if ((ret = ff_ffv1_allocate_initial_states(f)) < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < f->quant_table_count; i++)\n\n        if (get_rac(c, state)) {\n\n            for (j = 0; j < f->context_count[i]; j++)\n\n                for (k = 0; k < CONTEXT_SIZE; k++) {\n\n                    int pred = j ? f->initial_states[i][j - 1][k] : 128;\n\n                    f->initial_states[i][j][k] =\n\n                        (pred + get_symbol(c, state2[k], 1)) & 0xFF;\n\n                }\n\n        }\n\n\n\n    if (f->version > 2) {\n\n        f->ec = get_symbol(c, state, 0);\n\n        if (f->micro_version > 2)\n\n            f->intra = get_symbol(c, state, 0);\n\n    }\n\n\n\n    if (f->version > 2) {\n\n        unsigned v;\n\n        v = av_crc(av_crc_get_table(AV_CRC_32_IEEE), 0,\n\n                   f->avctx->extradata, f->avctx->extradata_size);\n\n        if (v || f->avctx->extradata_size < 4) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"CRC mismatch %X!\\n\", v);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        crc = AV_RB32(f->avctx->extradata + f->avctx->extradata_size - 4);\n\n    }\n\n\n\n    if (f->avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_log(f->avctx, AV_LOG_DEBUG,\n\n               \"global: ver:%d.%d, coder:%d, colorspace: %d bpr:%d chroma:%d(%d:%d), alpha:%d slices:%dx%d qtabs:%d ec:%d intra:%d CRC:0x%08X\\n\",\n\n               f->version, f->micro_version,\n\n               f->ac,\n\n               f->colorspace,\n\n               f->avctx->bits_per_raw_sample,\n\n               f->chroma_planes, f->chroma_h_shift, f->chroma_v_shift,\n\n               f->transparency,\n\n               f->num_h_slices, f->num_v_slices,\n\n               f->quant_table_count,\n\n               f->ec,\n\n               f->intra,\n\n               crc\n\n              );\n\n    return 0;\n\n}\n", "idx": 20642, "_split": "valid", "_hash": "660e84f214ac5293efa290cd2fef43d7"}
{"project": "FFmpeg", "commit_id": "ecf79c4d3e8baaf2f303278ef81db6f8407656bc", "target": 1, "func": "void ff_vorbis_ready_floor1_list(vorbis_floor1_entry * list, int values)\n\n{\n\n    int i;\n\n    list[0].sort = 0;\n\n    list[1].sort = 1;\n\n    for (i = 2; i < values; i++) {\n\n        int j;\n\n        list[i].low  = 0;\n\n        list[i].high = 1;\n\n        list[i].sort = i;\n\n        for (j = 2; j < i; j++) {\n\n            int tmp = list[j].x;\n\n            if (tmp < list[i].x) {\n\n                if (tmp > list[list[i].low].x)\n\n                    list[i].low  =  j;\n\n            } else {\n\n                if (tmp < list[list[i].high].x)\n\n                    list[i].high = j;\n\n            }\n\n        }\n\n    }\n\n    for (i = 0; i < values - 1; i++) {\n\n        int j;\n\n        for (j = i + 1; j < values; j++) {\n\n            if (list[list[i].sort].x > list[list[j].sort].x) {\n\n                int tmp = list[i].sort;\n\n                list[i].sort = list[j].sort;\n\n                list[j].sort = tmp;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 20670, "_split": "valid", "_hash": "986017a4e8039ce5800878599f6b83e3"}
{"project": "FFmpeg", "commit_id": "8babfc033ecb6332155c1f8879e54dee41d16952", "target": 1, "func": "static av_cold void init_cavlc_level_tab(void){\n\n    int suffix_length, mask;\n\n    unsigned int i;\n\n\n\n    for(suffix_length=0; suffix_length<7; suffix_length++){\n\n        for(i=0; i<(1<<LEVEL_TAB_BITS); i++){\n\n            int prefix= LEVEL_TAB_BITS - av_log2(2*i);\n\n            int level_code= (prefix<<suffix_length) + (i>>(LEVEL_TAB_BITS-prefix-1-suffix_length)) - (1<<suffix_length);\n\n\n\n            mask= -(level_code&1);\n\n            level_code= (((2+level_code)>>1) ^ mask) - mask;\n\n            if(prefix + 1 + suffix_length <= LEVEL_TAB_BITS){\n\n                cavlc_level_tab[suffix_length][i][0]= level_code;\n\n                cavlc_level_tab[suffix_length][i][1]= prefix + 1 + suffix_length;\n\n            }else if(prefix + 1 <= LEVEL_TAB_BITS){\n\n                cavlc_level_tab[suffix_length][i][0]= prefix+100;\n\n                cavlc_level_tab[suffix_length][i][1]= prefix + 1;\n\n            }else{\n\n                cavlc_level_tab[suffix_length][i][0]= LEVEL_TAB_BITS+100;\n\n                cavlc_level_tab[suffix_length][i][1]= LEVEL_TAB_BITS;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 20712, "_split": "valid", "_hash": "c856fd252061f44df9b2de9ba67aeba0"}
{"project": "FFmpeg", "commit_id": "ce7098b8f2b59c62b5abdb3d74819db75cf67698", "target": 1, "func": "static void yuv_a_to_rgba(const uint8_t *ycbcr, const uint8_t *alpha, uint32_t *rgba, int num_values)\n\n{\n\n    const uint8_t *cm = ff_crop_tab + MAX_NEG_CROP;\n\n    uint8_t r, g, b;\n\n    int i, y, cb, cr;\n\n    int r_add, g_add, b_add;\n\n\n\n    for (i = num_values; i > 0; i--) {\n\n        y = *ycbcr++;\n\n        cr = *ycbcr++;\n\n        cb = *ycbcr++;\n\n        YUV_TO_RGB1_CCIR(cb, cr);\n\n        YUV_TO_RGB2_CCIR(r, g, b, y);\n\n        *rgba++ = (*alpha++ << 24) | (r << 16) | (g << 8) | b;\n\n    }\n\n}\n", "idx": 20720, "_split": "valid", "_hash": "7853c1e49bfe89db3bff7311a4297b87"}
{"project": "FFmpeg", "commit_id": "75a13115cd6b961f4f6779423353c1cf25db4c0e", "target": 0, "func": "static int init_muxer(AVFormatContext *s, AVDictionary **options)\n\n{\n\n    int ret = 0, i;\n\n    AVStream *st;\n\n    AVDictionary *tmp = NULL;\n\n    AVCodecParameters *par = NULL;\n\n    AVOutputFormat *of = s->oformat;\n\n    const AVCodecDescriptor *desc;\n\n    AVDictionaryEntry *e;\n\n\n\n    if (options)\n\n        av_dict_copy(&tmp, *options, 0);\n\n\n\n    if ((ret = av_opt_set_dict(s, &tmp)) < 0)\n\n        goto fail;\n\n    if (s->priv_data && s->oformat->priv_class && *(const AVClass**)s->priv_data==s->oformat->priv_class &&\n\n        (ret = av_opt_set_dict2(s->priv_data, &tmp, AV_OPT_SEARCH_CHILDREN)) < 0)\n\n        goto fail;\n\n\n\n#if FF_API_LAVF_AVCTX\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    if (s->nb_streams && s->streams[0]->codec->flags & AV_CODEC_FLAG_BITEXACT) {\n\n        if (!(s->flags & AVFMT_FLAG_BITEXACT)) {\n\n#if FF_API_LAVF_BITEXACT\n\n            av_log(s, AV_LOG_WARNING,\n\n                   \"Setting the AVFormatContext to bitexact mode, because \"\n\n                   \"the AVCodecContext is in that mode. This behavior will \"\n\n                   \"change in the future. To keep the current behavior, set \"\n\n                   \"AVFormatContext.flags |= AVFMT_FLAG_BITEXACT.\\n\");\n\n            s->flags |= AVFMT_FLAG_BITEXACT;\n\n#else\n\n            av_log(s, AV_LOG_WARNING,\n\n                   \"The AVFormatContext is not in set to bitexact mode, only \"\n\n                   \"the AVCodecContext. If this is not intended, set \"\n\n                   \"AVFormatContext.flags |= AVFMT_FLAG_BITEXACT.\\n\");\n\n#endif\n\n        }\n\n    }\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    // some sanity checks\n\n    if (s->nb_streams == 0 && !(of->flags & AVFMT_NOSTREAMS)) {\n\n        av_log(s, AV_LOG_ERROR, \"No streams to mux were specified\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        st  = s->streams[i];\n\n        par = st->codecpar;\n\n\n\n#if FF_API_LAVF_CODEC_TB && FF_API_LAVF_AVCTX\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        if (!st->time_base.num && st->codec->time_base.num) {\n\n            av_log(s, AV_LOG_WARNING, \"Using AVStream.codec.time_base as a \"\n\n                   \"timebase hint to the muxer is deprecated. Set \"\n\n                   \"AVStream.time_base instead.\\n\");\n\n            avpriv_set_pts_info(st, 64, st->codec->time_base.num, st->codec->time_base.den);\n\n        }\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n#if FF_API_LAVF_AVCTX\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_UNKNOWN &&\n\n            st->codec->codec_type    != AVMEDIA_TYPE_UNKNOWN) {\n\n            av_log(s, AV_LOG_WARNING, \"Using AVStream.codec to pass codec \"\n\n                   \"parameters to muxers is deprecated, use AVStream.codecpar \"\n\n                   \"instead.\\n\");\n\n            ret = avcodec_parameters_from_context(st->codecpar, st->codec);\n\n            if (ret < 0)\n\n                goto fail;\n\n        }\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n        /* update internal context from codecpar, old bsf api needs this\n\n         * FIXME: remove when autobsf uses new bsf API */\n\n        ret = avcodec_parameters_to_context(st->internal->avctx, st->codecpar);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        if (!st->time_base.num) {\n\n            /* fall back on the default timebase values */\n\n            if (par->codec_type == AVMEDIA_TYPE_AUDIO && par->sample_rate)\n\n                avpriv_set_pts_info(st, 64, 1, par->sample_rate);\n\n            else\n\n                avpriv_set_pts_info(st, 33, 1, 90000);\n\n        }\n\n\n\n        switch (par->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            if (par->sample_rate <= 0) {\n\n                av_log(s, AV_LOG_ERROR, \"sample rate not set\\n\");\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            if (!par->block_align)\n\n                par->block_align = par->channels *\n\n                                   av_get_bits_per_sample(par->codec_id) >> 3;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if ((par->width <= 0 || par->height <= 0) &&\n\n                !(of->flags & AVFMT_NODIMENSIONS)) {\n\n                av_log(s, AV_LOG_ERROR, \"dimensions not set\\n\");\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            if (av_cmp_q(st->sample_aspect_ratio, par->sample_aspect_ratio)\n\n                && fabs(av_q2d(st->sample_aspect_ratio) - av_q2d(par->sample_aspect_ratio)) > 0.004*av_q2d(st->sample_aspect_ratio)\n\n            ) {\n\n                if (st->sample_aspect_ratio.num != 0 &&\n\n                    st->sample_aspect_ratio.den != 0 &&\n\n                    par->sample_aspect_ratio.num != 0 &&\n\n                    par->sample_aspect_ratio.den != 0) {\n\n                    av_log(s, AV_LOG_ERROR, \"Aspect ratio mismatch between muxer \"\n\n                           \"(%d/%d) and encoder layer (%d/%d)\\n\",\n\n                           st->sample_aspect_ratio.num, st->sample_aspect_ratio.den,\n\n                           par->sample_aspect_ratio.num,\n\n                           par->sample_aspect_ratio.den);\n\n                    ret = AVERROR(EINVAL);\n\n                    goto fail;\n\n                }\n\n            }\n\n            break;\n\n        }\n\n\n\n        desc = avcodec_descriptor_get(par->codec_id);\n\n        if (desc && desc->props & AV_CODEC_PROP_REORDER)\n\n            st->internal->reorder = 1;\n\n\n\n        if (of->codec_tag) {\n\n            if (   par->codec_tag\n\n                && par->codec_id == AV_CODEC_ID_RAWVIDEO\n\n                && (   av_codec_get_tag(of->codec_tag, par->codec_id) == 0\n\n                    || av_codec_get_tag(of->codec_tag, par->codec_id) == MKTAG('r', 'a', 'w', ' '))\n\n                && !validate_codec_tag(s, st)) {\n\n                // the current rawvideo encoding system ends up setting\n\n                // the wrong codec_tag for avi/mov, we override it here\n\n                par->codec_tag = 0;\n\n            }\n\n            if (par->codec_tag) {\n\n                if (!validate_codec_tag(s, st)) {\n\n                    char tagbuf[32], tagbuf2[32];\n\n                    av_get_codec_tag_string(tagbuf, sizeof(tagbuf), par->codec_tag);\n\n                    av_get_codec_tag_string(tagbuf2, sizeof(tagbuf2), av_codec_get_tag(s->oformat->codec_tag, par->codec_id));\n\n                    av_log(s, AV_LOG_ERROR,\n\n                           \"Tag %s/0x%08x incompatible with output codec id '%d' (%s)\\n\",\n\n                           tagbuf, par->codec_tag, par->codec_id, tagbuf2);\n\n                    ret = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n                }\n\n            } else\n\n                par->codec_tag = av_codec_get_tag(of->codec_tag, par->codec_id);\n\n        }\n\n\n\n        if (par->codec_type != AVMEDIA_TYPE_ATTACHMENT)\n\n            s->internal->nb_interleaved_streams++;\n\n    }\n\n\n\n    if (!s->priv_data && of->priv_data_size > 0) {\n\n        s->priv_data = av_mallocz(of->priv_data_size);\n\n        if (!s->priv_data) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        if (of->priv_class) {\n\n            *(const AVClass **)s->priv_data = of->priv_class;\n\n            av_opt_set_defaults(s->priv_data);\n\n            if ((ret = av_opt_set_dict2(s->priv_data, &tmp, AV_OPT_SEARCH_CHILDREN)) < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    /* set muxer identification string */\n\n    if (!(s->flags & AVFMT_FLAG_BITEXACT)) {\n\n        av_dict_set(&s->metadata, \"encoder\", LIBAVFORMAT_IDENT, 0);\n\n    } else {\n\n        av_dict_set(&s->metadata, \"encoder\", NULL, 0);\n\n    }\n\n\n\n    for (e = NULL; e = av_dict_get(s->metadata, \"encoder-\", e, AV_DICT_IGNORE_SUFFIX); ) {\n\n        av_dict_set(&s->metadata, e->key, NULL, 0);\n\n    }\n\n\n\n    if (options) {\n\n         av_dict_free(options);\n\n         *options = tmp;\n\n    }\n\n\n\n    if (s->oformat->init) {\n\n        if ((ret = s->oformat->init(s)) < 0) {\n\n            if (s->oformat->deinit)\n\n                s->oformat->deinit(s);\n\n            return ret;\n\n        }\n\n        return ret == 0;\n\n    }\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_dict_free(&tmp);\n\n    return ret;\n\n}\n", "idx": 20725, "_split": "valid", "_hash": "b5fb0cb12c58640e033476052c678dc1"}
{"project": "FFmpeg", "commit_id": "f7459bcfc5b54554f95616214696b2a9d189d7fa", "target": 0, "func": "int ff_frame_thread_encoder_init(AVCodecContext *avctx, AVDictionary *options){\n\n    int i=0;\n\n    ThreadContext *c;\n\n\n\n\n\n    if(   !(avctx->thread_type & FF_THREAD_FRAME)\n\n       || !(avctx->codec->capabilities & CODEC_CAP_INTRA_ONLY))\n\n        return 0;\n\n\n\n    if(   !avctx->thread_count\n\n       && avctx->codec_id == AV_CODEC_ID_MJPEG\n\n       && !(avctx->flags & CODEC_FLAG_QSCALE)) {\n\n        av_log(avctx, AV_LOG_DEBUG,\n\n               \"Forcing thread count to 1 for MJPEG encoding, use -thread_type slice \"\n\n               \"or a constant quantizer if you want to use multiple cpu cores\\n\");\n\n        avctx->thread_count = 1;\n\n    }\n\n    if(   avctx->thread_count > 1\n\n       && avctx->codec_id == AV_CODEC_ID_MJPEG\n\n       && !(avctx->flags & CODEC_FLAG_QSCALE))\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"MJPEG CBR encoding works badly with frame multi-threading, consider \"\n\n               \"using -threads 1, -thread_type slice or a constant quantizer.\\n\");\n\n    if(!avctx->thread_count) {\n\n        avctx->thread_count = av_cpu_count();\n\n        avctx->thread_count = FFMIN(avctx->thread_count, MAX_THREADS);\n\n    }\n\n\n\n    if(avctx->thread_count <= 1)\n\n        return 0;\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_HUFFYUV ||\n\n        avctx->codec_id == AV_CODEC_ID_FFVHUFF) {\n\n        // huffyuv doesnt support these with multiple frame threads currently\n\n        if (avctx->context_model > 0 || (avctx->flags & CODEC_FLAG_PASS1))\n\n            return 0;\n\n    }\n\n\n\n    if(avctx->thread_count > MAX_THREADS)\n\n        return AVERROR(EINVAL);\n\n\n\n    av_assert0(!avctx->internal->frame_thread_encoder);\n\n    c = avctx->internal->frame_thread_encoder = av_mallocz(sizeof(ThreadContext));\n\n    if(!c)\n\n        return AVERROR(ENOMEM);\n\n\n\n    c->parent_avctx = avctx;\n\n\n\n    c->task_fifo = av_fifo_alloc(sizeof(Task) * BUFFER_SIZE);\n\n    if(!c->task_fifo)\n\n        goto fail;\n\n\n\n    pthread_mutex_init(&c->task_fifo_mutex, NULL);\n\n    pthread_mutex_init(&c->finished_task_mutex, NULL);\n\n    pthread_mutex_init(&c->buffer_mutex, NULL);\n\n    pthread_cond_init(&c->task_fifo_cond, NULL);\n\n    pthread_cond_init(&c->finished_task_cond, NULL);\n\n\n\n    for(i=0; i<avctx->thread_count ; i++){\n\n        AVDictionary *tmp = NULL;\n\n        void *tmpv;\n\n        AVCodecContext *thread_avctx = avcodec_alloc_context3(avctx->codec);\n\n        if(!thread_avctx)\n\n            goto fail;\n\n        tmpv = thread_avctx->priv_data;\n\n        *thread_avctx = *avctx;\n\n        thread_avctx->priv_data = tmpv;\n\n        thread_avctx->internal = NULL;\n\n        memcpy(thread_avctx->priv_data, avctx->priv_data, avctx->codec->priv_data_size);\n\n        thread_avctx->thread_count = 1;\n\n        thread_avctx->active_thread_type &= ~FF_THREAD_FRAME;\n\n\n\n        av_dict_copy(&tmp, options, 0);\n\n        av_dict_set(&tmp, \"threads\", \"1\", 0);\n\n        if(avcodec_open2(thread_avctx, avctx->codec, &tmp) < 0) {\n\n            av_dict_free(&tmp);\n\n            goto fail;\n\n        }\n\n        av_dict_free(&tmp);\n\n        av_assert0(!thread_avctx->internal->frame_thread_encoder);\n\n        thread_avctx->internal->frame_thread_encoder = c;\n\n        if(pthread_create(&c->worker[i], NULL, worker, thread_avctx)) {\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n    avctx->active_thread_type = FF_THREAD_FRAME;\n\n\n\n    return 0;\n\nfail:\n\n    avctx->thread_count = i;\n\n    av_log(avctx, AV_LOG_ERROR, \"ff_frame_thread_encoder_init failed\\n\");\n\n    ff_frame_thread_encoder_free(avctx);\n\n    return -1;\n\n}\n", "idx": 20772, "_split": "valid", "_hash": "6d6140d35b9e3d43ff8231b22d2c8acf"}
{"project": "FFmpeg", "commit_id": "d6737539e77e78fca9a04914d51996cfd1ccc55c", "target": 0, "func": "static void intra_predict_mad_cow_dc_0l0_8x8_msa(uint8_t *src, int32_t stride)\n\n{\n\n    uint8_t lp_cnt;\n\n    uint32_t src0 = 0;\n\n    uint64_t out0, out1;\n\n\n\n    for (lp_cnt = 0; lp_cnt < 4; lp_cnt++) {\n\n        src0 += src[(4 + lp_cnt) * stride - 1];\n\n    }\n\n\n\n    src0 = (src0 + 2) >> 2;\n\n\n\n    out0 = 0x8080808080808080;\n\n    out1 = src0 * 0x0101010101010101;\n\n\n\n    for (lp_cnt = 4; lp_cnt--;) {\n\n        SD(out0, src);\n\n        SD(out1, src + stride * 4);\n\n        src += stride;\n\n    }\n\n}\n", "idx": 20773, "_split": "valid", "_hash": "61bba6fbecca0880786399802a22dd85"}
{"project": "FFmpeg", "commit_id": "7b94df232a4b76c44e243e618573f8d331a1eb1c", "target": 0, "func": "static void srt_to_ass(AVCodecContext *avctx, AVBPrint *dst,\n\n                       const char *in, int x1, int y1, int x2, int y2)\n\n{\n\n    if (x1 >= 0 && y1 >= 0) {\n\n        /* XXX: here we rescale coordinate assuming they are in DVD resolution\n\n         * (720x480) since we don't have anything better */\n\n\n\n        if (x2 >= 0 && y2 >= 0 && (x2 != x1 || y2 != y1) && x2 >= x1 && y2 >= y1) {\n\n            /* text rectangle defined, write the text at the center of the rectangle */\n\n            const int cx = x1 + (x2 - x1)/2;\n\n            const int cy = y1 + (y2 - y1)/2;\n\n            const int scaled_x = cx * (int64_t)ASS_DEFAULT_PLAYRESX / 720;\n\n            const int scaled_y = cy * (int64_t)ASS_DEFAULT_PLAYRESY / 480;\n\n            av_bprintf(dst, \"{\\\\an5}{\\\\pos(%d,%d)}\", scaled_x, scaled_y);\n\n        } else {\n\n            /* only the top left corner, assume the text starts in that corner */\n\n            const int scaled_x = x1 * (int64_t)ASS_DEFAULT_PLAYRESX / 720;\n\n            const int scaled_y = y1 * (int64_t)ASS_DEFAULT_PLAYRESY / 480;\n\n            av_bprintf(dst, \"{\\\\an1}{\\\\pos(%d,%d)}\", scaled_x, scaled_y);\n\n        }\n\n    }\n\n\n\n    ff_htmlmarkup_to_ass(avctx, dst, in);\n\n}\n", "idx": 20777, "_split": "valid", "_hash": "a7fde6a49e36eabfece81847d25d9071"}
{"project": "FFmpeg", "commit_id": "161ccdaa06d1d109e8f77d2535bda11ce02720f5", "target": 0, "func": "static int msvideo1_decode_frame(AVCodecContext *avctx,\n\n                                void *data, int *got_frame,\n\n                                AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    Msvideo1Context *s = avctx->priv_data;\n\n    int ret;\n\n\n\n    s->buf = buf;\n\n    s->size = buf_size;\n\n\n\n    if ((ret = ff_reget_buffer(avctx, s->frame)) < 0)\n\n        return ret;\n\n\n\n    if (s->mode_8bit) {\n\n        const uint8_t *pal = av_packet_get_side_data(avpkt, AV_PKT_DATA_PALETTE, NULL);\n\n\n\n        if (pal) {\n\n            memcpy(s->pal, pal, AVPALETTE_SIZE);\n\n            s->frame->palette_has_changed = 1;\n\n        }\n\n    }\n\n\n\n    if (s->mode_8bit)\n\n        msvideo1_decode_8bit(s);\n\n    else\n\n        msvideo1_decode_16bit(s);\n\n\n\n    if ((ret = av_frame_ref(data, s->frame)) < 0)\n\n        return ret;\n\n\n\n    *got_frame      = 1;\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 20779, "_split": "valid", "_hash": "b5d08868aa99a2264568930e2c195d3a"}
{"project": "FFmpeg", "commit_id": "e24c31b656254b2516befbde78aeaca0122a6010", "target": 1, "func": "int ff_dirac_golomb_read_32bit(DiracGolombLUT *lut_ctx, const uint8_t *buf,\n\n                               int bytes, uint8_t *_dst, int coeffs)\n\n{\n\n    int i, b, c_idx = 0;\n\n    int32_t *dst = (int32_t *)_dst;\n\n    DiracGolombLUT *future[4], *l = &lut_ctx[2*LUT_SIZE + buf[0]];\n\n    INIT_RESIDUE(res, 0, 0);\n\n\n\n#define APPEND_RESIDUE(N, M)         \\\n\n    N          |= M >> (N ## _bits); \\\n\n    N ## _bits +=      (M ## _bits)\n\n\n\n    for (b = 1; b <= bytes; b++) {\n\n        future[0] = &lut_ctx[buf[b]];\n\n        future[1] = future[0] + 1*LUT_SIZE;\n\n        future[2] = future[0] + 2*LUT_SIZE;\n\n        future[3] = future[0] + 3*LUT_SIZE;\n\n\n\n        if ((c_idx + 1) > coeffs)\n\n            return c_idx;\n\n\n\n        /* res_bits is a hint for better branch prediction */\n\n        if (res_bits && l->sign) {\n\n            int32_t coeff = 1;\n\n            APPEND_RESIDUE(res, l->preamble);\n\n            for (i = 0; i < (res_bits >> 1) - 1; i++) {\n\n                coeff <<= 1;\n\n                coeff |= (res >> (RSIZE_BITS - 2*i - 2)) & 1;\n\n            }\n\n            dst[c_idx++] = l->sign * (coeff - 1);\n\n            res_bits = res = 0;\n\n        }\n\n\n\n        memcpy(&dst[c_idx], l->ready, LUT_BITS*sizeof(int32_t));\n\n        c_idx += l->ready_num;\n\n\n\n        APPEND_RESIDUE(res, l->leftover);\n\n\n\n        l = future[l->need_s ? 3 : !res_bits ? 2 : res_bits & 1];\n\n    }\n\n\n\n    return c_idx;\n\n}\n", "idx": 20869, "_split": "valid", "_hash": "41aac1a2727a60a7ac9176212adcb152"}
{"project": "FFmpeg", "commit_id": "efe1ba7201b3bb609d3a41091e15e875137f3f32", "target": 1, "func": "static int dirac_unpack_idwt_params(DiracContext *s)\n{\n    GetBitContext *gb = &s->gb;\n    int i, level;\n    unsigned tmp;\n#define CHECKEDREAD(dst, cond, errmsg) \\\n    tmp = svq3_get_ue_golomb(gb); \\\n    if (cond) { \\\n        av_log(s->avctx, AV_LOG_ERROR, errmsg); \\\n        return -1; \\\n    }\\\n    dst = tmp;\n    align_get_bits(gb);\n    s->zero_res = s->num_refs ? get_bits1(gb) : 0;\n    if (s->zero_res)\n        return 0;\n    /*[DIRAC_STD] 11.3.1 Transform parameters. transform_parameters() */\n    CHECKEDREAD(s->wavelet_idx, tmp > 6, \"wavelet_idx is too big\\n\")\n    CHECKEDREAD(s->wavelet_depth, tmp > MAX_DWT_LEVELS || tmp < 1, \"invalid number of DWT decompositions\\n\")\n    if (!s->low_delay) {\n        /* Codeblock paramaters (core syntax only) */\n        if (get_bits1(gb)) {\n            for (i = 0; i <= s->wavelet_depth; i++) {\n                CHECKEDREAD(s->codeblock[i].width , tmp < 1, \"codeblock width invalid\\n\")\n                CHECKEDREAD(s->codeblock[i].height, tmp < 1, \"codeblock height invalid\\n\")\n            CHECKEDREAD(s->codeblock_mode, tmp > 1, \"unknown codeblock mode\\n\")\n        } else\n            for (i = 0; i <= s->wavelet_depth; i++)\n                s->codeblock[i].width = s->codeblock[i].height = 1;\n    } else {\n        /* Slice parameters + quantization matrix*/\n        /*[DIRAC_STD] 11.3.4 Slice coding Parameters (low delay syntax only). slice_parameters() */\n        s->lowdelay.num_x     = svq3_get_ue_golomb(gb);\n        s->lowdelay.num_y     = svq3_get_ue_golomb(gb);\n        s->lowdelay.bytes.num = svq3_get_ue_golomb(gb);\n        s->lowdelay.bytes.den = svq3_get_ue_golomb(gb);\n        /* [DIRAC_STD] 11.3.5 Quantisation matrices (low-delay syntax). quant_matrix() */\n        if (get_bits1(gb)) {\n            av_log(s->avctx,AV_LOG_DEBUG,\"Low Delay: Has Custom Quantization Matrix!\\n\");\n            /* custom quantization matrix */\n            s->lowdelay.quant[0][0] = svq3_get_ue_golomb(gb);\n            for (level = 0; level < s->wavelet_depth; level++) {\n                s->lowdelay.quant[level][1] = svq3_get_ue_golomb(gb);\n                s->lowdelay.quant[level][2] = svq3_get_ue_golomb(gb);\n                s->lowdelay.quant[level][3] = svq3_get_ue_golomb(gb);\n        } else {\n            /* default quantization matrix */\n            for (level = 0; level < s->wavelet_depth; level++)\n                for (i = 0; i < 4; i++) {\n                    s->lowdelay.quant[level][i] = default_qmat[s->wavelet_idx][level][i];\n                    /* haar with no shift differs for different depths */\n                    if (s->wavelet_idx == 3)\n                        s->lowdelay.quant[level][i] += 4*(s->wavelet_depth-1 - level);\n    return 0;", "idx": 20879, "_split": "valid", "_hash": "3b9b316aeb6fee296ceb74f6a7692325"}
{"project": "FFmpeg", "commit_id": "f6e1c96730ebbcebbd0341329d51d3d3a36b4fa1", "target": 1, "func": "static int ffm_read_data(AVFormatContext *s,\n\n                         uint8_t *buf, int size, int header)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int len, fill_size, size1, frame_offset;\n\n    uint32_t id;\n\n    int64_t last_pos = -1;\n\n\n\n    size1 = size;\n\n    while (size > 0) {\n\n    redo:\n\n        len = ffm->packet_end - ffm->packet_ptr;\n\n        if (len < 0)\n\n            return -1;\n\n        if (len > size)\n\n            len = size;\n\n        if (len == 0) {\n\n            if (avio_tell(pb) == ffm->file_size) {\n\n                if (ffm->server_attached) {\n\n                    avio_seek(pb, ffm->packet_size, SEEK_SET);\n\n                } else\n\n                    return AVERROR_EOF;\n\n            }\n\n    retry_read:\n\n            if (pb->buffer_size != ffm->packet_size) {\n\n                int64_t tell = avio_tell(pb);\n\n                int ret = ffio_set_buf_size(pb, ffm->packet_size);\n\n                if (ret < 0)\n\n                    return ret;\n\n                avio_seek(pb, tell, SEEK_SET);\n\n            }\n\n            id = avio_rb16(pb); /* PACKET_ID */\n\n            if (id != PACKET_ID) {\n\n                if (ffm_resync(s, id) < 0)\n\n                    return -1;\n\n                last_pos = avio_tell(pb);\n\n            }\n\n            fill_size = avio_rb16(pb);\n\n            ffm->dts = avio_rb64(pb);\n\n            frame_offset = avio_rb16(pb);\n\n            avio_read(pb, ffm->packet, ffm->packet_size - FFM_HEADER_SIZE);\n\n            if (ffm->packet_size < FFM_HEADER_SIZE + fill_size || frame_offset < 0) {\n\n                return -1;\n\n            }\n\n            ffm->packet_end = ffm->packet + (ffm->packet_size - FFM_HEADER_SIZE - fill_size);\n\n            /* if first packet or resynchronization packet, we must\n\n               handle it specifically */\n\n            if (ffm->first_packet || (frame_offset & 0x8000)) {\n\n                if (!frame_offset) {\n\n                    /* This packet has no frame headers in it */\n\n                    if (avio_tell(pb) >= ffm->packet_size * 3LL) {\n\n                        int64_t seekback = FFMIN(ffm->packet_size * 2LL, avio_tell(pb) - last_pos);\n\n                        seekback = FFMAX(seekback, 0);\n\n                        avio_seek(pb, -seekback, SEEK_CUR);\n\n                        goto retry_read;\n\n                    }\n\n                    /* This is bad, we cannot find a valid frame header */\n\n                    return 0;\n\n                }\n\n                ffm->first_packet = 0;\n\n                if ((frame_offset & 0x7fff) < FFM_HEADER_SIZE) {\n\n                    ffm->packet_end = ffm->packet_ptr;\n\n                    return -1;\n\n                }\n\n                ffm->packet_ptr = ffm->packet + (frame_offset & 0x7fff) - FFM_HEADER_SIZE;\n\n                if (!header)\n\n                    break;\n\n            } else {\n\n                ffm->packet_ptr = ffm->packet;\n\n            }\n\n            goto redo;\n\n        }\n\n        memcpy(buf, ffm->packet_ptr, len);\n\n        buf += len;\n\n        ffm->packet_ptr += len;\n\n        size -= len;\n\n        header = 0;\n\n    }\n\n    return size1 - size;\n\n}\n", "idx": 20883, "_split": "valid", "_hash": "50c00543acb324752d0809d14a28e2f5"}
{"project": "FFmpeg", "commit_id": "03931ecf71710452fc9e89d4f18354f0b5e05395", "target": 0, "func": "static void ssim_4x4x2_core(const uint8_t *main, int main_stride,\n\n                            const uint8_t *ref, int ref_stride,\n\n                            int sums[2][4])\n\n{\n\n    int x, y, z;\n\n\n\n    for (z = 0; z < 2; z++) {\n\n        uint32_t s1 = 0, s2 = 0, ss = 0, s12 = 0;\n\n\n\n        for (y = 0; y < 4; y++) {\n\n            for (x = 0; x < 4; x++) {\n\n                int a = main[x + y * main_stride];\n\n                int b = ref[x + y * ref_stride];\n\n\n\n                s1  += a;\n\n                s2  += b;\n\n                ss  += a*a;\n\n                ss  += b*b;\n\n                s12 += a*b;\n\n            }\n\n        }\n\n\n\n        sums[z][0] = s1;\n\n        sums[z][1] = s2;\n\n        sums[z][2] = ss;\n\n        sums[z][3] = s12;\n\n        main += 4;\n\n        ref += 4;\n\n    }\n\n}\n", "idx": 20992, "_split": "valid", "_hash": "0c3c2421f857789f48628442b437d10a"}
{"project": "FFmpeg", "commit_id": "71bd023da5e83e3f65e068d0b12bf5b45050d2d5", "target": 1, "func": "static int seq_parse_frame_data(SeqDemuxContext *seq, ByteIOContext *pb)\n\n{\n\n    unsigned int offset_table[4], buffer_num[4];\n\n    TiertexSeqFrameBuffer *seq_buffer;\n\n    int i, e;\n\n\n\n    seq->current_frame_offs += SEQ_FRAME_SIZE;\n\n    url_fseek(pb, seq->current_frame_offs, SEEK_SET);\n\n\n\n    /* sound data */\n\n    seq->current_audio_data_offs = get_le16(pb);\n\n    if (seq->current_audio_data_offs != 0) {\n\n        seq->current_audio_data_size = SEQ_AUDIO_BUFFER_SIZE * 2;\n\n    } else {\n\n        seq->current_audio_data_size = 0;\n\n    }\n\n\n\n    /* palette data */\n\n    seq->current_pal_data_offs = get_le16(pb);\n\n    if (seq->current_pal_data_offs != 0) {\n\n        seq->current_pal_data_size = 768;\n\n    } else {\n\n        seq->current_pal_data_size = 0;\n\n    }\n\n\n\n    /* video data */\n\n    for (i = 0; i < 4; i++)\n\n        buffer_num[i] = get_byte(pb);\n\n\n\n    for (i = 0; i < 4; i++)\n\n        offset_table[i] = get_le16(pb);\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        if (offset_table[i] != 0) {\n\n            for (e = i + 1; e < 4 && offset_table[e] == 0; e++);\n\n            seq_fill_buffer(seq, pb, buffer_num[1 + i],\n\n              offset_table[i],\n\n              offset_table[e] - offset_table[i]);\n\n        }\n\n    }\n\n\n\n    if (buffer_num[0] != 255) {\n\n        seq_buffer = &seq->frame_buffers[buffer_num[0]];\n\n        seq->current_video_data_size = seq_buffer->fill_size;\n\n        seq->current_video_data_ptr  = seq_buffer->data;\n\n        seq_buffer->fill_size = 0;\n\n    } else {\n\n        seq->current_video_data_size = 0;\n\n        seq->current_video_data_ptr  = 0;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 21006, "_split": "valid", "_hash": "834eb3e205a32e4c8762531921194753"}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "struct AACISError ff_aac_is_encoding_err(AACEncContext *s, ChannelElement *cpe,\n\n                                         int start, int w, int g, float ener0,\n\n                                         float ener1, float ener01,\n\n                                         int use_pcoeffs, int phase)\n\n{\n\n    int i, w2;\n\n    SingleChannelElement *sce0 = &cpe->ch[0];\n\n    SingleChannelElement *sce1 = &cpe->ch[1];\n\n    float *L = use_pcoeffs ? sce0->pcoeffs : sce0->coeffs;\n\n    float *R = use_pcoeffs ? sce1->pcoeffs : sce1->coeffs;\n\n    float *L34 = &s->scoefs[256*0], *R34 = &s->scoefs[256*1];\n\n    float *IS  = &s->scoefs[256*2], *I34 = &s->scoefs[256*3];\n\n    float dist1 = 0.0f, dist2 = 0.0f;\n\n    struct AACISError is_error = {0};\n\n\n\n    for (w2 = 0; w2 < sce0->ics.group_len[w]; w2++) {\n\n        FFPsyBand *band0 = &s->psy.ch[s->cur_channel+0].psy_bands[(w+w2)*16+g];\n\n        FFPsyBand *band1 = &s->psy.ch[s->cur_channel+1].psy_bands[(w+w2)*16+g];\n\n        int is_band_type, is_sf_idx = FFMAX(1, sce0->sf_idx[(w+w2)*16+g]-4);\n\n        float e01_34 = phase*pow(ener1/ener0, 3.0/4.0);\n\n        float maxval, dist_spec_err = 0.0f;\n\n        float minthr = FFMIN(band0->threshold, band1->threshold);\n\n        for (i = 0; i < sce0->ics.swb_sizes[g]; i++)\n\n            IS[i] = (L[start+(w+w2)*128+i] + phase*R[start+(w+w2)*128+i])*sqrt(ener0/ener01);\n\n        abs_pow34_v(L34, &L[start+(w+w2)*128], sce0->ics.swb_sizes[g]);\n\n        abs_pow34_v(R34, &R[start+(w+w2)*128], sce0->ics.swb_sizes[g]);\n\n        abs_pow34_v(I34, IS,                   sce0->ics.swb_sizes[g]);\n\n        maxval = find_max_val(1, sce0->ics.swb_sizes[g], I34);\n\n        is_band_type = find_min_book(maxval, is_sf_idx);\n\n        dist1 += quantize_band_cost(s, &L[start + (w+w2)*128], L34,\n\n                                    sce0->ics.swb_sizes[g],\n\n                                    sce0->sf_idx[(w+w2)*16+g],\n\n                                    sce0->band_type[(w+w2)*16+g],\n\n                                    s->lambda / band0->threshold, INFINITY, NULL, 0);\n\n        dist1 += quantize_band_cost(s, &R[start + (w+w2)*128], R34,\n\n                                    sce1->ics.swb_sizes[g],\n\n                                    sce1->sf_idx[(w+w2)*16+g],\n\n                                    sce1->band_type[(w+w2)*16+g],\n\n                                    s->lambda / band1->threshold, INFINITY, NULL, 0);\n\n        dist2 += quantize_band_cost(s, IS, I34, sce0->ics.swb_sizes[g],\n\n                                    is_sf_idx, is_band_type,\n\n                                    s->lambda / minthr, INFINITY, NULL, 0);\n\n        for (i = 0; i < sce0->ics.swb_sizes[g]; i++) {\n\n            dist_spec_err += (L34[i] - I34[i])*(L34[i] - I34[i]);\n\n            dist_spec_err += (R34[i] - I34[i]*e01_34)*(R34[i] - I34[i]*e01_34);\n\n        }\n\n        dist_spec_err *= s->lambda / minthr;\n\n        dist2 += dist_spec_err;\n\n    }\n\n\n\n    is_error.pass = dist2 <= dist1;\n\n    is_error.phase = phase;\n\n    is_error.error = fabsf(dist1 - dist2);\n\n    is_error.dist1 = dist1;\n\n    is_error.dist2 = dist2;\n\n\n\n    return is_error;\n\n}\n", "idx": 21045, "_split": "valid", "_hash": "78945b39ef548a5b285f9560782579ca"}
{"project": "FFmpeg", "commit_id": "088ed4d636e3065bf4fc67ef11bfe8592bcd8c0e", "target": 1, "func": "static Picture * remove_short(H264Context *h, int frame_num){\n\n    MpegEncContext * const s = &h->s;\n\n    int i;\n\n\n\n    if(s->avctx->debug&FF_DEBUG_MMCO)\n\n        av_log(h->s.avctx, AV_LOG_DEBUG, \"remove short %d count %d\\n\", frame_num, h->short_ref_count);\n\n\n\n    for(i=0; i<h->short_ref_count; i++){\n\n        Picture *pic= h->short_ref[i];\n\n        if(s->avctx->debug&FF_DEBUG_MMCO)\n\n            av_log(h->s.avctx, AV_LOG_DEBUG, \"%d %d %p\\n\", i, pic->frame_num, pic);\n\n        if(pic->frame_num == frame_num){\n\n            h->short_ref[i]= NULL;\n\n            memmove(&h->short_ref[i], &h->short_ref[i+1], (h->short_ref_count - i - 1)*sizeof(Picture*));\n\n            h->short_ref_count--;\n\n            return pic;\n\n        }\n\n    }\n\n    return NULL;\n\n}\n", "idx": 21059, "_split": "valid", "_hash": "adb5f914da19d8715dc2b4338970c113"}
{"project": "FFmpeg", "commit_id": "e34c6c9708336b9445574bb6ddb48416368af963", "target": 0, "func": "static int cook_decode_frame(AVCodecContext *avctx,\n\n            void *data, int *data_size,\n\n            AVPacket *avpkt) {\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    COOKContext *q = avctx->priv_data;\n\n    int i;\n\n    int offset = 0;\n\n    int chidx = 0;\n\n\n\n    if (buf_size < avctx->block_align)\n\n        return buf_size;\n\n\n\n    /* estimate subpacket sizes */\n\n    q->subpacket[0].size = avctx->block_align;\n\n\n\n    for(i=1;i<q->num_subpackets;i++){\n\n        q->subpacket[i].size = 2 * buf[avctx->block_align - q->num_subpackets + i];\n\n        q->subpacket[0].size -= q->subpacket[i].size + 1;\n\n        if (q->subpacket[0].size < 0) {\n\n            av_log(avctx,AV_LOG_DEBUG,\"frame subpacket size total > avctx->block_align!\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* decode supbackets */\n\n    for(i=0;i<q->num_subpackets;i++){\n\n        q->subpacket[i].bits_per_subpacket = (q->subpacket[i].size*8)>>q->subpacket[i].bits_per_subpdiv;\n\n        q->subpacket[i].ch_idx = chidx;\n\n        av_log(avctx,AV_LOG_DEBUG,\"subpacket[%i] size %i js %i %i block_align %i\\n\",i,q->subpacket[i].size,q->subpacket[i].joint_stereo,offset,avctx->block_align);\n\n        decode_subpacket(q, &q->subpacket[i], buf + offset, data);\n\n        offset += q->subpacket[i].size;\n\n        chidx += q->subpacket[i].num_channels;\n\n        av_log(avctx,AV_LOG_DEBUG,\"subpacket[%i] %i %i\\n\",i,q->subpacket[i].size * 8,get_bits_count(&q->gb));\n\n    }\n\n    *data_size = q->nb_channels * q->samples_per_channel *\n\n                 av_get_bytes_per_sample(avctx->sample_fmt);\n\n\n\n    /* Discard the first two frames: no valid audio. */\n\n    if (avctx->frame_number < 2) *data_size = 0;\n\n\n\n    return avctx->block_align;\n\n}\n", "idx": 21068, "_split": "valid", "_hash": "3491786073a1941f4a40082d39abf65d"}
{"project": "FFmpeg", "commit_id": "4ce75387cdcbcef8afbaadc5b66232c25178c0c6", "target": 1, "func": "static int read_thread(void *arg)\n\n{\n\n    VideoState *is = arg;\n\n    AVFormatContext *ic = NULL;\n\n    int err, i, ret;\n\n    int st_index[AVMEDIA_TYPE_NB];\n\n    AVPacket pkt1, *pkt = &pkt1;\n\n    int64_t stream_start_time;\n\n    int pkt_in_play_range = 0;\n\n    AVDictionaryEntry *t;\n\n    AVDictionary **opts;\n\n    int orig_nb_streams;\n\n    SDL_mutex *wait_mutex = SDL_CreateMutex();\n\n    int scan_all_pmts_set = 0;\n\n    int64_t pkt_ts;\n\n\n\n    if (!wait_mutex) {\n\n        av_log(NULL, AV_LOG_FATAL, \"SDL_CreateMutex(): %s\\n\", SDL_GetError());\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    memset(st_index, -1, sizeof(st_index));\n\n    is->last_video_stream = is->video_stream = -1;\n\n    is->last_audio_stream = is->audio_stream = -1;\n\n    is->last_subtitle_stream = is->subtitle_stream = -1;\n\n    is->eof = 0;\n\n\n\n    ic = avformat_alloc_context();\n\n    if (!ic) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Could not allocate context.\\n\");\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    ic->interrupt_callback.callback = decode_interrupt_cb;\n\n    ic->interrupt_callback.opaque = is;\n\n    if (!av_dict_get(format_opts, \"scan_all_pmts\", NULL, AV_DICT_MATCH_CASE)) {\n\n        av_dict_set(&format_opts, \"scan_all_pmts\", \"1\", AV_DICT_DONT_OVERWRITE);\n\n        scan_all_pmts_set = 1;\n\n    }\n\n    err = avformat_open_input(&ic, is->filename, is->iformat, &format_opts);\n\n    if (err < 0) {\n\n        print_error(is->filename, err);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n    if (scan_all_pmts_set)\n\n        av_dict_set(&format_opts, \"scan_all_pmts\", NULL, AV_DICT_MATCH_CASE);\n\n\n\n    if ((t = av_dict_get(format_opts, \"\", NULL, AV_DICT_IGNORE_SUFFIX))) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Option %s not found.\\n\", t->key);\n\n        ret = AVERROR_OPTION_NOT_FOUND;\n\n        goto fail;\n\n    }\n\n    is->ic = ic;\n\n\n\n    if (genpts)\n\n        ic->flags |= AVFMT_FLAG_GENPTS;\n\n\n\n    av_format_inject_global_side_data(ic);\n\n\n\n    opts = setup_find_stream_info_opts(ic, codec_opts);\n\n    orig_nb_streams = ic->nb_streams;\n\n\n\n    err = avformat_find_stream_info(ic, opts);\n\n\n\n    for (i = 0; i < orig_nb_streams; i++)\n\n        av_dict_free(&opts[i]);\n\n    av_freep(&opts);\n\n\n\n    if (err < 0) {\n\n        av_log(NULL, AV_LOG_WARNING,\n\n               \"%s: could not find codec parameters\\n\", is->filename);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n\n\n    if (ic->pb)\n\n        ic->pb->eof_reached = 0; // FIXME hack, ffplay maybe should not use avio_feof() to test for the end\n\n\n\n    if (seek_by_bytes < 0)\n\n        seek_by_bytes = !!(ic->iformat->flags & AVFMT_TS_DISCONT) && strcmp(\"ogg\", ic->iformat->name);\n\n\n\n    is->max_frame_duration = (ic->iformat->flags & AVFMT_TS_DISCONT) ? 10.0 : 3600.0;\n\n\n\n    if (!window_title && (t = av_dict_get(ic->metadata, \"title\", NULL, 0)))\n\n        window_title = av_asprintf(\"%s - %s\", t->value, input_filename);\n\n\n\n    /* if seeking requested, we execute it */\n\n    if (start_time != AV_NOPTS_VALUE) {\n\n        int64_t timestamp;\n\n\n\n        timestamp = start_time;\n\n        /* add the stream start time */\n\n        if (ic->start_time != AV_NOPTS_VALUE)\n\n            timestamp += ic->start_time;\n\n        ret = avformat_seek_file(ic, -1, INT64_MIN, timestamp, INT64_MAX, 0);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_WARNING, \"%s: could not seek to position %0.3f\\n\",\n\n                    is->filename, (double)timestamp / AV_TIME_BASE);\n\n        }\n\n    }\n\n\n\n    is->realtime = is_realtime(ic);\n\n\n\n    if (show_status)\n\n        av_dump_format(ic, 0, is->filename, 0);\n\n\n\n    for (i = 0; i < ic->nb_streams; i++) {\n\n        AVStream *st = ic->streams[i];\n\n        enum AVMediaType type = st->codec->codec_type;\n\n        st->discard = AVDISCARD_ALL;\n\n        if (wanted_stream_spec[type] && st_index[type] == -1)\n\n            if (avformat_match_stream_specifier(ic, st, wanted_stream_spec[type]) > 0)\n\n                st_index[type] = i;\n\n    }\n\n    for (i = 0; i < AVMEDIA_TYPE_NB; i++) {\n\n        if (wanted_stream_spec[i] && st_index[i] == -1) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Stream specifier %s does not match any %s stream\\n\", wanted_stream_spec[i], av_get_media_type_string(i));\n\n            st_index[i] = INT_MAX;\n\n        }\n\n    }\n\n\n\n    if (!video_disable)\n\n        st_index[AVMEDIA_TYPE_VIDEO] =\n\n            av_find_best_stream(ic, AVMEDIA_TYPE_VIDEO,\n\n                                st_index[AVMEDIA_TYPE_VIDEO], -1, NULL, 0);\n\n    if (!audio_disable)\n\n        st_index[AVMEDIA_TYPE_AUDIO] =\n\n            av_find_best_stream(ic, AVMEDIA_TYPE_AUDIO,\n\n                                st_index[AVMEDIA_TYPE_AUDIO],\n\n                                st_index[AVMEDIA_TYPE_VIDEO],\n\n                                NULL, 0);\n\n    if (!video_disable && !subtitle_disable)\n\n        st_index[AVMEDIA_TYPE_SUBTITLE] =\n\n            av_find_best_stream(ic, AVMEDIA_TYPE_SUBTITLE,\n\n                                st_index[AVMEDIA_TYPE_SUBTITLE],\n\n                                (st_index[AVMEDIA_TYPE_AUDIO] >= 0 ?\n\n                                 st_index[AVMEDIA_TYPE_AUDIO] :\n\n                                 st_index[AVMEDIA_TYPE_VIDEO]),\n\n                                NULL, 0);\n\n\n\n    is->show_mode = show_mode;\n\n    if (st_index[AVMEDIA_TYPE_VIDEO] >= 0) {\n\n        AVStream *st = ic->streams[st_index[AVMEDIA_TYPE_VIDEO]];\n\n        AVCodecContext *avctx = st->codec;\n\n        AVRational sar = av_guess_sample_aspect_ratio(ic, st, NULL);\n\n        if (avctx->width)\n\n            set_default_window_size(avctx->width, avctx->height, sar);\n\n    }\n\n\n\n    /* open the streams */\n\n    if (st_index[AVMEDIA_TYPE_AUDIO] >= 0) {\n\n        stream_component_open(is, st_index[AVMEDIA_TYPE_AUDIO]);\n\n    }\n\n\n\n    ret = -1;\n\n    if (st_index[AVMEDIA_TYPE_VIDEO] >= 0) {\n\n        ret = stream_component_open(is, st_index[AVMEDIA_TYPE_VIDEO]);\n\n    }\n\n    if (is->show_mode == SHOW_MODE_NONE)\n\n        is->show_mode = ret >= 0 ? SHOW_MODE_VIDEO : SHOW_MODE_RDFT;\n\n\n\n    if (st_index[AVMEDIA_TYPE_SUBTITLE] >= 0) {\n\n        stream_component_open(is, st_index[AVMEDIA_TYPE_SUBTITLE]);\n\n    }\n\n\n\n    if (is->video_stream < 0 && is->audio_stream < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Failed to open file '%s' or configure filtergraph\\n\",\n\n               is->filename);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n\n\n    if (infinite_buffer < 0 && is->realtime)\n\n        infinite_buffer = 1;\n\n\n\n    for (;;) {\n\n        if (is->abort_request)\n\n            break;\n\n        if (is->paused != is->last_paused) {\n\n            is->last_paused = is->paused;\n\n            if (is->paused)\n\n                is->read_pause_return = av_read_pause(ic);\n\n            else\n\n                av_read_play(ic);\n\n        }\n\n#if CONFIG_RTSP_DEMUXER || CONFIG_MMSH_PROTOCOL\n\n        if (is->paused &&\n\n                (!strcmp(ic->iformat->name, \"rtsp\") ||\n\n                 (ic->pb && !strncmp(input_filename, \"mmsh:\", 5)))) {\n\n            /* wait 10 ms to avoid trying to get another packet */\n\n            /* XXX: horrible */\n\n            SDL_Delay(10);\n\n            continue;\n\n        }\n\n#endif\n\n        if (is->seek_req) {\n\n            int64_t seek_target = is->seek_pos;\n\n            int64_t seek_min    = is->seek_rel > 0 ? seek_target - is->seek_rel + 2: INT64_MIN;\n\n            int64_t seek_max    = is->seek_rel < 0 ? seek_target - is->seek_rel - 2: INT64_MAX;\n\n// FIXME the +-2 is due to rounding being not done in the correct direction in generation\n\n//      of the seek_pos/seek_rel variables\n\n\n\n            ret = avformat_seek_file(is->ic, -1, seek_min, seek_target, seek_max, is->seek_flags);\n\n            if (ret < 0) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"%s: error while seeking\\n\", is->ic->filename);\n\n            } else {\n\n                if (is->audio_stream >= 0) {\n\n                    packet_queue_flush(&is->audioq);\n\n                    packet_queue_put(&is->audioq, &flush_pkt);\n\n                }\n\n                if (is->subtitle_stream >= 0) {\n\n                    packet_queue_flush(&is->subtitleq);\n\n                    packet_queue_put(&is->subtitleq, &flush_pkt);\n\n                }\n\n                if (is->video_stream >= 0) {\n\n                    packet_queue_flush(&is->videoq);\n\n                    packet_queue_put(&is->videoq, &flush_pkt);\n\n                }\n\n                if (is->seek_flags & AVSEEK_FLAG_BYTE) {\n\n                   set_clock(&is->extclk, NAN, 0);\n\n                } else {\n\n                   set_clock(&is->extclk, seek_target / (double)AV_TIME_BASE, 0);\n\n                }\n\n            }\n\n            is->seek_req = 0;\n\n            is->queue_attachments_req = 1;\n\n            is->eof = 0;\n\n            if (is->paused)\n\n                step_to_next_frame(is);\n\n        }\n\n        if (is->queue_attachments_req) {\n\n            if (is->video_st && is->video_st->disposition & AV_DISPOSITION_ATTACHED_PIC) {\n\n                AVPacket copy;\n\n                if ((ret = av_copy_packet(&copy, &is->video_st->attached_pic)) < 0)\n\n                    goto fail;\n\n                packet_queue_put(&is->videoq, &copy);\n\n                packet_queue_put_nullpacket(&is->videoq, is->video_stream);\n\n            }\n\n            is->queue_attachments_req = 0;\n\n        }\n\n\n\n        /* if the queue are full, no need to read more */\n\n        if (infinite_buffer<1 &&\n\n              (is->audioq.size + is->videoq.size + is->subtitleq.size > MAX_QUEUE_SIZE\n\n            || (   (is->audioq   .nb_packets > MIN_FRAMES || is->audio_stream < 0 || is->audioq.abort_request)\n\n                && (is->videoq   .nb_packets > MIN_FRAMES || is->video_stream < 0 || is->videoq.abort_request\n\n                    || (is->video_st->disposition & AV_DISPOSITION_ATTACHED_PIC))\n\n                && (is->subtitleq.nb_packets > MIN_FRAMES || is->subtitle_stream < 0 || is->subtitleq.abort_request)))) {\n\n            /* wait 10 ms */\n\n            SDL_LockMutex(wait_mutex);\n\n            SDL_CondWaitTimeout(is->continue_read_thread, wait_mutex, 10);\n\n            SDL_UnlockMutex(wait_mutex);\n\n            continue;\n\n        }\n\n        if (!is->paused &&\n\n            (!is->audio_st || (is->auddec.finished == is->audioq.serial && frame_queue_nb_remaining(&is->sampq) == 0)) &&\n\n            (!is->video_st || (is->viddec.finished == is->videoq.serial && frame_queue_nb_remaining(&is->pictq) == 0))) {\n\n            if (loop != 1 && (!loop || --loop)) {\n\n                stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0);\n\n            } else if (autoexit) {\n\n                ret = AVERROR_EOF;\n\n                goto fail;\n\n            }\n\n        }\n\n        ret = av_read_frame(ic, pkt);\n\n        if (ret < 0) {\n\n            if ((ret == AVERROR_EOF || avio_feof(ic->pb)) && !is->eof) {\n\n                if (is->video_stream >= 0)\n\n                    packet_queue_put_nullpacket(&is->videoq, is->video_stream);\n\n                if (is->audio_stream >= 0)\n\n                    packet_queue_put_nullpacket(&is->audioq, is->audio_stream);\n\n                if (is->subtitle_stream >= 0)\n\n                    packet_queue_put_nullpacket(&is->subtitleq, is->subtitle_stream);\n\n                is->eof = 1;\n\n            }\n\n            if (ic->pb && ic->pb->error)\n\n                break;\n\n            SDL_LockMutex(wait_mutex);\n\n            SDL_CondWaitTimeout(is->continue_read_thread, wait_mutex, 10);\n\n            SDL_UnlockMutex(wait_mutex);\n\n            continue;\n\n        } else {\n\n            is->eof = 0;\n\n        }\n\n        /* check if packet is in play range specified by user, then queue, otherwise discard */\n\n        stream_start_time = ic->streams[pkt->stream_index]->start_time;\n\n        pkt_ts = pkt->pts == AV_NOPTS_VALUE ? pkt->dts : pkt->pts;\n\n        pkt_in_play_range = duration == AV_NOPTS_VALUE ||\n\n                (pkt_ts - (stream_start_time != AV_NOPTS_VALUE ? stream_start_time : 0)) *\n\n                av_q2d(ic->streams[pkt->stream_index]->time_base) -\n\n                (double)(start_time != AV_NOPTS_VALUE ? start_time : 0) / 1000000\n\n                <= ((double)duration / 1000000);\n\n        if (pkt->stream_index == is->audio_stream && pkt_in_play_range) {\n\n            packet_queue_put(&is->audioq, pkt);\n\n        } else if (pkt->stream_index == is->video_stream && pkt_in_play_range\n\n                   && !(is->video_st->disposition & AV_DISPOSITION_ATTACHED_PIC)) {\n\n            packet_queue_put(&is->videoq, pkt);\n\n        } else if (pkt->stream_index == is->subtitle_stream && pkt_in_play_range) {\n\n            packet_queue_put(&is->subtitleq, pkt);\n\n        } else {\n\n            av_free_packet(pkt);\n\n        }\n\n    }\n\n    /* wait until the end */\n\n    while (!is->abort_request) {\n\n        SDL_Delay(100);\n\n    }\n\n\n\n    ret = 0;\n\n fail:\n\n    /* close each stream */\n\n    if (is->audio_stream >= 0)\n\n        stream_component_close(is, is->audio_stream);\n\n    if (is->video_stream >= 0)\n\n        stream_component_close(is, is->video_stream);\n\n    if (is->subtitle_stream >= 0)\n\n        stream_component_close(is, is->subtitle_stream);\n\n    if (ic) {\n\n        avformat_close_input(&ic);\n\n        is->ic = NULL;\n\n    }\n\n\n\n    if (ret != 0) {\n\n        SDL_Event event;\n\n\n\n        event.type = FF_QUIT_EVENT;\n\n        event.user.data1 = is;\n\n        SDL_PushEvent(&event);\n\n    }\n\n    SDL_DestroyMutex(wait_mutex);\n\n    return 0;\n\n}\n", "idx": 21141, "_split": "valid", "_hash": "2428703efd2e074ff857df83904383f4"}
{"project": "FFmpeg", "commit_id": "9bcbb250e23959075765edd3cb4c1fcb46736d7d", "target": 0, "func": "static inline void RENAME(yuv2yuv1_ar)(SwsContext *c, const int16_t *lumSrc,\n\n                                       const int16_t *chrUSrc, const int16_t *chrVSrc,\n\n                                       const int16_t *alpSrc,\n\n                                       uint8_t *dest, uint8_t *uDest, uint8_t *vDest,\n\n                                       uint8_t *aDest, int dstW, int chrDstW)\n\n{\n\n    int p= 4;\n\n    const uint8_t *src[4]= { alpSrc + dstW, lumSrc + dstW, chrUSrc + chrDstW, chrVSrc + chrDstW };\n\n    uint8_t *dst[4]= { aDest, dest, uDest, vDest };\n\n    x86_reg counter[4]= { dstW, dstW, chrDstW, chrDstW };\n\n\n\n    while (p--) {\n\n        if (dst[p]) {\n\n            __asm__ volatile(\n\n                \"mov %2, %%\"REG_a\"                    \\n\\t\"\n\n                \"pcmpeqw %%mm7, %%mm7                 \\n\\t\"\n\n                \"psrlw                 $15, %%mm7     \\n\\t\"\n\n                \"psllw                  $6, %%mm7     \\n\\t\"\n\n                \".p2align                4            \\n\\t\" /* FIXME Unroll? */\n\n                \"1:                                   \\n\\t\"\n\n                \"movq  (%0, %%\"REG_a\", 2), %%mm0      \\n\\t\"\n\n                \"movq 8(%0, %%\"REG_a\", 2), %%mm1      \\n\\t\"\n\n                \"paddsw             %%mm7, %%mm0      \\n\\t\"\n\n                \"paddsw             %%mm7, %%mm1      \\n\\t\"\n\n                \"psraw                 $7, %%mm0      \\n\\t\"\n\n                \"psraw                 $7, %%mm1      \\n\\t\"\n\n                \"packuswb           %%mm1, %%mm0      \\n\\t\"\n\n                MOVNTQ(%%mm0, (%1, %%REGa))\n\n                \"add                   $8, %%\"REG_a\"  \\n\\t\"\n\n                \"jnc                   1b             \\n\\t\"\n\n                :: \"r\" (src[p]), \"r\" (dst[p] + counter[p]),\n\n                   \"g\" (-counter[p])\n\n                : \"%\"REG_a\n\n            );\n\n        }\n\n    }\n\n}\n", "idx": 21148, "_split": "valid", "_hash": "e5a281cfeca82aa0a9b7ddc03493f742"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(rgb16to32)(const uint8_t *src, uint8_t *dst, unsigned src_size)\n\n{\n\n\tconst uint16_t *end;\n\n#ifdef HAVE_MMX\n\n\tconst uint16_t *mm_end;\n\n#endif\n\n\tuint8_t *d = (uint8_t *)dst;\n\n\tconst uint16_t *s = (uint16_t *)src;\n\n\tend = s + src_size/2;\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(PREFETCH\"\t%0\"::\"m\"(*s):\"memory\");\n\n\t__asm __volatile(\"pxor\t%%mm7,%%mm7\\n\\t\":::\"memory\");\n\n\tmm_end = end - 3;\n\n\twhile(s < mm_end)\n\n\t{\n\n\t    __asm __volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\t\"movq\t%1, %%mm1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm2\\n\\t\"\n\n\t\t\"pand\t%2, %%mm0\\n\\t\"\n\n\t\t\"pand\t%3, %%mm1\\n\\t\"\n\n\t\t\"pand\t%4, %%mm2\\n\\t\"\n\n\t\t\"psllq\t$3, %%mm0\\n\\t\"\n\n\t\t\"psrlq\t$3, %%mm1\\n\\t\"\n\n\t\t\"psrlq\t$8, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm3\\n\\t\"\n\n\t\t\"movq\t%%mm1, %%mm4\\n\\t\"\n\n\t\t\"movq\t%%mm2, %%mm5\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm0\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm1\\n\\t\"\n\n\t\t\"punpcklwd %%mm7, %%mm2\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm3\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm4\\n\\t\"\n\n\t\t\"punpckhwd %%mm7, %%mm5\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm1\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm2\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm2, %%mm0\\n\\t\"\n\n\t\t\"psllq\t$8, %%mm4\\n\\t\"\n\n\t\t\"psllq\t$16, %%mm5\\n\\t\"\n\n\t\t\"por\t%%mm4, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm5, %%mm3\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm3, 8%0\\n\\t\"\n\n\t\t:\"=m\"(*d)\n\n\t\t:\"m\"(*s),\"m\"(mask16b),\"m\"(mask16g),\"m\"(mask16r)\n\n\t\t:\"memory\");\n\n\t\td += 16;\n\n\t\ts += 4;\n\n\t}\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\twhile(s < end)\n\n\t{\n\n\t\tregister uint16_t bgr;\n\n\t\tbgr = *s++;\n\n#ifdef WORDS_BIGENDIAN\n\n\t\t*d++ = 0;\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n\t\t*d++ = (bgr&0x7E0)>>3;\n\n\t\t*d++ = (bgr&0xF800)>>8;\n\n#else\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n\t\t*d++ = (bgr&0x7E0)>>3;\n\n\t\t*d++ = (bgr&0xF800)>>8;\n\n\t\t*d++ = 0;\n\n#endif\n\n\t}\n\n}\n", "idx": 21173, "_split": "valid", "_hash": "2950a9bce8abe80da68b567b3cb58022"}
{"project": "FFmpeg", "commit_id": "f141b353e60f1081185927a1e74a9ab46cae8bef", "target": 1, "func": "static void celt_search_for_dual_stereo(OpusPsyContext *s, CeltFrame *f)\n{\n    float td1, td2;\n    f->dual_stereo = 0;\n    bands_dist(s, f, &td1);\n    f->dual_stereo = 1;\n    bands_dist(s, f, &td2);\n    f->dual_stereo = td2 < td1;\n    s->dual_stereo_used += td2 < td1;\n}", "idx": 21176, "_split": "valid", "_hash": "2178d11f567082812c62755f1425c850"}
{"project": "FFmpeg", "commit_id": "83344066d326e6bad20feb66825ace12708eb084", "target": 0, "func": "void ff_er_frame_end(MpegEncContext *s){\n\n    int i, mb_x, mb_y, error, error_type, dc_error, mv_error, ac_error;\n\n    int distance;\n\n    int threshold_part[4]= {100,100,100};\n\n    int threshold= 50;\n\n    int is_intra_likely;\n\n    int size = s->b8_stride * 2 * s->mb_height;\n\n    Picture *pic= s->current_picture_ptr;\n\n\n\n    if(!s->error_recognition || s->error_count==0 || s->avctx->lowres ||\n\n       s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU ||\n\n       s->error_count==3*s->mb_width*(s->avctx->skip_top + s->avctx->skip_bottom)) return;\n\n\n\n    if(s->current_picture.motion_val[0] == NULL){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Warning MVs not available\\n\");\n\n\n\n        for(i=0; i<2; i++){\n\n            pic->ref_index[i]= av_mallocz(size * sizeof(uint8_t));\n\n            pic->motion_val_base[i]= av_mallocz((size+4) * 2 * sizeof(uint16_t));\n\n            pic->motion_val[i]= pic->motion_val_base[i]+4;\n\n        }\n\n        pic->motion_subsample_log2= 3;\n\n        s->current_picture= *s->current_picture_ptr;\n\n    }\n\n\n\n    for(i=0; i<2; i++){\n\n        if(pic->ref_index[i])\n\n            memset(pic->ref_index[i], 0, size * sizeof(uint8_t));\n\n    }\n\n\n\n    if(s->avctx->debug&FF_DEBUG_ER){\n\n        for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n            for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n                int status= s->error_status_table[mb_x + mb_y*s->mb_stride];\n\n\n\n                av_log(s->avctx, AV_LOG_DEBUG, \"%2X \", status);\n\n            }\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"\\n\");\n\n        }\n\n    }\n\n\n\n#if 1\n\n    /* handle overlapping slices */\n\n    for(error_type=1; error_type<=3; error_type++){\n\n        int end_ok=0;\n\n\n\n        for(i=s->mb_num-1; i>=0; i--){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error= s->error_status_table[mb_xy];\n\n\n\n            if(error&(1<<error_type))\n\n                end_ok=1;\n\n            if(error&(8<<error_type))\n\n                end_ok=1;\n\n\n\n            if(!end_ok)\n\n                s->error_status_table[mb_xy]|= 1<<error_type;\n\n\n\n            if(error&VP_START)\n\n                end_ok=0;\n\n        }\n\n    }\n\n#endif\n\n#if 1\n\n    /* handle slices with partitions of different length */\n\n    if(s->partitioned_frame){\n\n        int end_ok=0;\n\n\n\n        for(i=s->mb_num-1; i>=0; i--){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error= s->error_status_table[mb_xy];\n\n\n\n            if(error&AC_END)\n\n                end_ok=0;\n\n            if((error&MV_END) || (error&DC_END) || (error&AC_ERROR))\n\n                end_ok=1;\n\n\n\n            if(!end_ok)\n\n                s->error_status_table[mb_xy]|= AC_ERROR;\n\n\n\n            if(error&VP_START)\n\n                end_ok=0;\n\n        }\n\n    }\n\n#endif\n\n    /* handle missing slices */\n\n    if(s->error_recognition>=4){\n\n        int end_ok=1;\n\n\n\n        for(i=s->mb_num-2; i>=s->mb_width+100; i--){ //FIXME +100 hack\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error1= s->error_status_table[mb_xy  ];\n\n            int error2= s->error_status_table[s->mb_index2xy[i+1]];\n\n\n\n            if(error1&VP_START)\n\n                end_ok=1;\n\n\n\n            if(   error2==(VP_START|DC_ERROR|AC_ERROR|MV_ERROR|AC_END|DC_END|MV_END)\n\n               && error1!=(VP_START|DC_ERROR|AC_ERROR|MV_ERROR|AC_END|DC_END|MV_END)\n\n               && ((error1&AC_END) || (error1&DC_END) || (error1&MV_END))){ //end & uninit\n\n                end_ok=0;\n\n            }\n\n\n\n            if(!end_ok)\n\n                s->error_status_table[mb_xy]|= DC_ERROR|AC_ERROR|MV_ERROR;\n\n        }\n\n    }\n\n\n\n#if 1\n\n    /* backward mark errors */\n\n    distance=9999999;\n\n    for(error_type=1; error_type<=3; error_type++){\n\n        for(i=s->mb_num-1; i>=0; i--){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            int error= s->error_status_table[mb_xy];\n\n\n\n            if(!s->mbskip_table[mb_xy]) //FIXME partition specific\n\n                distance++;\n\n            if(error&(1<<error_type))\n\n                distance= 0;\n\n\n\n            if(s->partitioned_frame){\n\n                if(distance < threshold_part[error_type-1])\n\n                    s->error_status_table[mb_xy]|= 1<<error_type;\n\n            }else{\n\n                if(distance < threshold)\n\n                    s->error_status_table[mb_xy]|= 1<<error_type;\n\n            }\n\n\n\n            if(error&VP_START)\n\n                distance= 9999999;\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* forward mark errors */\n\n    error=0;\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        int old_error= s->error_status_table[mb_xy];\n\n\n\n        if(old_error&VP_START)\n\n            error= old_error& (DC_ERROR|AC_ERROR|MV_ERROR);\n\n        else{\n\n            error|= old_error& (DC_ERROR|AC_ERROR|MV_ERROR);\n\n            s->error_status_table[mb_xy]|= error;\n\n        }\n\n    }\n\n#if 1\n\n    /* handle not partitioned case */\n\n    if(!s->partitioned_frame){\n\n        for(i=0; i<s->mb_num; i++){\n\n            const int mb_xy= s->mb_index2xy[i];\n\n            error= s->error_status_table[mb_xy];\n\n            if(error&(AC_ERROR|DC_ERROR|MV_ERROR))\n\n                error|= AC_ERROR|DC_ERROR|MV_ERROR;\n\n            s->error_status_table[mb_xy]= error;\n\n        }\n\n    }\n\n#endif\n\n\n\n    dc_error= ac_error= mv_error=0;\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        error= s->error_status_table[mb_xy];\n\n        if(error&DC_ERROR) dc_error ++;\n\n        if(error&AC_ERROR) ac_error ++;\n\n        if(error&MV_ERROR) mv_error ++;\n\n    }\n\n    av_log(s->avctx, AV_LOG_INFO, \"concealing %d DC, %d AC, %d MV errors\\n\", dc_error, ac_error, mv_error);\n\n\n\n    is_intra_likely= is_intra_more_likely(s);\n\n\n\n    /* set unknown mb-type to most likely */\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        error= s->error_status_table[mb_xy];\n\n        if(!((error&DC_ERROR) && (error&MV_ERROR)))\n\n            continue;\n\n\n\n        if(is_intra_likely)\n\n            s->current_picture.mb_type[mb_xy]= MB_TYPE_INTRA4x4;\n\n        else\n\n            s->current_picture.mb_type[mb_xy]= MB_TYPE_16x16 | MB_TYPE_L0;\n\n    }\n\n\n\n    /* handle inter blocks with damaged AC */\n\n    for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n        for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n            const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n            const int mb_type= s->current_picture.mb_type[mb_xy];\n\n            error= s->error_status_table[mb_xy];\n\n\n\n            if(IS_INTRA(mb_type)) continue; //intra\n\n            if(error&MV_ERROR) continue;              //inter with damaged MV\n\n            if(!(error&AC_ERROR)) continue;           //undamaged inter\n\n\n\n            s->mv_dir = MV_DIR_FORWARD;\n\n            s->mb_intra=0;\n\n            s->mb_skipped=0;\n\n            if(IS_8X8(mb_type)){\n\n                int mb_index= mb_x*2 + mb_y*2*s->b8_stride;\n\n                int j;\n\n                s->mv_type = MV_TYPE_8X8;\n\n                for(j=0; j<4; j++){\n\n                    s->mv[0][j][0] = s->current_picture.motion_val[0][ mb_index + (j&1) + (j>>1)*s->b8_stride ][0];\n\n                    s->mv[0][j][1] = s->current_picture.motion_val[0][ mb_index + (j&1) + (j>>1)*s->b8_stride ][1];\n\n                }\n\n            }else{\n\n                s->mv_type = MV_TYPE_16X16;\n\n                s->mv[0][0][0] = s->current_picture.motion_val[0][ mb_x*2 + mb_y*2*s->b8_stride ][0];\n\n                s->mv[0][0][1] = s->current_picture.motion_val[0][ mb_x*2 + mb_y*2*s->b8_stride ][1];\n\n            }\n\n\n\n            s->dsp.clear_blocks(s->block[0]);\n\n\n\n            s->mb_x= mb_x;\n\n            s->mb_y= mb_y;\n\n            decode_mb(s);\n\n        }\n\n    }\n\n\n\n    /* guess MVs */\n\n    if(s->pict_type==FF_B_TYPE){\n\n        for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n            for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n                int xy= mb_x*2 + mb_y*2*s->b8_stride;\n\n                const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n                const int mb_type= s->current_picture.mb_type[mb_xy];\n\n                error= s->error_status_table[mb_xy];\n\n\n\n                if(IS_INTRA(mb_type)) continue;\n\n                if(!(error&MV_ERROR)) continue;           //inter with undamaged MV\n\n                if(!(error&AC_ERROR)) continue;           //undamaged inter\n\n\n\n                s->mv_dir = MV_DIR_FORWARD|MV_DIR_BACKWARD;\n\n                s->mb_intra=0;\n\n                s->mv_type = MV_TYPE_16X16;\n\n                s->mb_skipped=0;\n\n\n\n                if(s->pp_time){\n\n                    int time_pp= s->pp_time;\n\n                    int time_pb= s->pb_time;\n\n\n\n                    s->mv[0][0][0] = s->next_picture.motion_val[0][xy][0]*time_pb/time_pp;\n\n                    s->mv[0][0][1] = s->next_picture.motion_val[0][xy][1]*time_pb/time_pp;\n\n                    s->mv[1][0][0] = s->next_picture.motion_val[0][xy][0]*(time_pb - time_pp)/time_pp;\n\n                    s->mv[1][0][1] = s->next_picture.motion_val[0][xy][1]*(time_pb - time_pp)/time_pp;\n\n                }else{\n\n                    s->mv[0][0][0]= 0;\n\n                    s->mv[0][0][1]= 0;\n\n                    s->mv[1][0][0]= 0;\n\n                    s->mv[1][0][1]= 0;\n\n                }\n\n\n\n                s->dsp.clear_blocks(s->block[0]);\n\n                s->mb_x= mb_x;\n\n                s->mb_y= mb_y;\n\n                decode_mb(s);\n\n            }\n\n        }\n\n    }else\n\n        guess_mv(s);\n\n\n\n#if CONFIG_MPEG_XVMC_DECODER\n\n    /* the filters below are not XvMC compatible, skip them */\n\n    if(s->avctx->xvmc_acceleration) goto ec_clean;\n\n#endif\n\n    /* fill DC for inter blocks */\n\n    for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n        for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n            int dc, dcu, dcv, y, n;\n\n            int16_t *dc_ptr;\n\n            uint8_t *dest_y, *dest_cb, *dest_cr;\n\n            const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n            const int mb_type= s->current_picture.mb_type[mb_xy];\n\n\n\n            error= s->error_status_table[mb_xy];\n\n\n\n            if(IS_INTRA(mb_type) && s->partitioned_frame) continue;\n\n//            if(error&MV_ERROR) continue; //inter data damaged FIXME is this good?\n\n\n\n            dest_y = s->current_picture.data[0] + mb_x*16 + mb_y*16*s->linesize;\n\n            dest_cb= s->current_picture.data[1] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n            dest_cr= s->current_picture.data[2] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n\n\n            dc_ptr= &s->dc_val[0][mb_x*2 + mb_y*2*s->b8_stride];\n\n            for(n=0; n<4; n++){\n\n                dc=0;\n\n                for(y=0; y<8; y++){\n\n                    int x;\n\n                    for(x=0; x<8; x++){\n\n                       dc+= dest_y[x + (n&1)*8 + (y + (n>>1)*8)*s->linesize];\n\n                    }\n\n                }\n\n                dc_ptr[(n&1) + (n>>1)*s->b8_stride]= (dc+4)>>3;\n\n            }\n\n\n\n            dcu=dcv=0;\n\n            for(y=0; y<8; y++){\n\n                int x;\n\n                for(x=0; x<8; x++){\n\n                    dcu+=dest_cb[x + y*(s->uvlinesize)];\n\n                    dcv+=dest_cr[x + y*(s->uvlinesize)];\n\n                }\n\n            }\n\n            s->dc_val[1][mb_x + mb_y*s->mb_stride]= (dcu+4)>>3;\n\n            s->dc_val[2][mb_x + mb_y*s->mb_stride]= (dcv+4)>>3;\n\n        }\n\n    }\n\n#if 1\n\n    /* guess DC for damaged blocks */\n\n    guess_dc(s, s->dc_val[0], s->mb_width*2, s->mb_height*2, s->b8_stride, 1);\n\n    guess_dc(s, s->dc_val[1], s->mb_width  , s->mb_height  , s->mb_stride, 0);\n\n    guess_dc(s, s->dc_val[2], s->mb_width  , s->mb_height  , s->mb_stride, 0);\n\n#endif\n\n    /* filter luma DC */\n\n    filter181(s->dc_val[0], s->mb_width*2, s->mb_height*2, s->b8_stride);\n\n\n\n#if 1\n\n    /* render DC only intra */\n\n    for(mb_y=0; mb_y<s->mb_height; mb_y++){\n\n        for(mb_x=0; mb_x<s->mb_width; mb_x++){\n\n            uint8_t *dest_y, *dest_cb, *dest_cr;\n\n            const int mb_xy= mb_x + mb_y * s->mb_stride;\n\n            const int mb_type= s->current_picture.mb_type[mb_xy];\n\n\n\n            error= s->error_status_table[mb_xy];\n\n\n\n            if(IS_INTER(mb_type)) continue;\n\n            if(!(error&AC_ERROR)) continue;              //undamaged\n\n\n\n            dest_y = s->current_picture.data[0] + mb_x*16 + mb_y*16*s->linesize;\n\n            dest_cb= s->current_picture.data[1] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n            dest_cr= s->current_picture.data[2] + mb_x*8  + mb_y*8 *s->uvlinesize;\n\n\n\n            put_dc(s, dest_y, dest_cb, dest_cr, mb_x, mb_y);\n\n        }\n\n    }\n\n#endif\n\n\n\n    if(s->avctx->error_concealment&FF_EC_DEBLOCK){\n\n        /* filter horizontal block boundaries */\n\n        h_block_filter(s, s->current_picture.data[0], s->mb_width*2, s->mb_height*2, s->linesize  , 1);\n\n        h_block_filter(s, s->current_picture.data[1], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n        h_block_filter(s, s->current_picture.data[2], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n\n\n        /* filter vertical block boundaries */\n\n        v_block_filter(s, s->current_picture.data[0], s->mb_width*2, s->mb_height*2, s->linesize  , 1);\n\n        v_block_filter(s, s->current_picture.data[1], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n        v_block_filter(s, s->current_picture.data[2], s->mb_width  , s->mb_height  , s->uvlinesize, 0);\n\n    }\n\n\n\n#if CONFIG_MPEG_XVMC_DECODER\n\nec_clean:\n\n#endif\n\n    /* clean a few tables */\n\n    for(i=0; i<s->mb_num; i++){\n\n        const int mb_xy= s->mb_index2xy[i];\n\n        int error= s->error_status_table[mb_xy];\n\n\n\n        if(s->pict_type!=FF_B_TYPE && (error&(DC_ERROR|MV_ERROR|AC_ERROR))){\n\n            s->mbskip_table[mb_xy]=0;\n\n        }\n\n        s->mbintra_table[mb_xy]=1;\n\n    }\n\n}\n", "idx": 21222, "_split": "valid", "_hash": "9fc6ab10bf70d481ada1813290e97974"}
{"project": "FFmpeg", "commit_id": "76e6b1eba1feb5fc9d2ee70962914faff0228db2", "target": 0, "func": "void ff_mspel_motion(MpegEncContext *s,\n\n                               uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                               uint8_t **ref_picture, op_pixels_func (*pix_op)[4],\n\n                               int motion_x, int motion_y, int h)\n\n{\n\n    Wmv2Context * const w= (Wmv2Context*)s;\n\n    uint8_t *ptr;\n\n    int dxy, offset, mx, my, src_x, src_y, v_edge_pos, linesize, uvlinesize;\n\n    int emu=0;\n\n\n\n    dxy = ((motion_y & 1) << 1) | (motion_x & 1);\n\n    dxy = 2*dxy + w->hshift;\n\n    src_x = s->mb_x * 16 + (motion_x >> 1);\n\n    src_y = s->mb_y * 16 + (motion_y >> 1);\n\n\n\n    /* WARNING: do no forget half pels */\n\n    v_edge_pos = s->v_edge_pos;\n\n    src_x = av_clip(src_x, -16, s->width);\n\n    src_y = av_clip(src_y, -16, s->height);\n\n\n\n    if(src_x<=-16 || src_x >= s->width)\n\n        dxy &= ~3;\n\n    if(src_y<=-16 || src_y >= s->height)\n\n        dxy &= ~4;\n\n\n\n    linesize   = s->linesize;\n\n    uvlinesize = s->uvlinesize;\n\n    ptr = ref_picture[0] + (src_y * linesize) + src_x;\n\n\n\n    if(s->flags&CODEC_FLAG_EMU_EDGE){\n\n        if(src_x<1 || src_y<1 || src_x + 17  >= s->h_edge_pos\n\n                              || src_y + h+1 >= v_edge_pos){\n\n            s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr - 1 - s->linesize, s->linesize, 19, 19,\n\n                             src_x-1, src_y-1, s->h_edge_pos, s->v_edge_pos);\n\n            ptr= s->edge_emu_buffer + 1 + s->linesize;\n\n            emu=1;\n\n        }\n\n    }\n\n\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y             , ptr             , linesize);\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y+8           , ptr+8           , linesize);\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y  +8*linesize, ptr  +8*linesize, linesize);\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y+8+8*linesize, ptr+8+8*linesize, linesize);\n\n\n\n    if(s->flags&CODEC_FLAG_GRAY) return;\n\n\n\n    if (s->out_format == FMT_H263) {\n\n        dxy = 0;\n\n        if ((motion_x & 3) != 0)\n\n            dxy |= 1;\n\n        if ((motion_y & 3) != 0)\n\n            dxy |= 2;\n\n        mx = motion_x >> 2;\n\n        my = motion_y >> 2;\n\n    } else {\n\n        mx = motion_x / 2;\n\n        my = motion_y / 2;\n\n        dxy = ((my & 1) << 1) | (mx & 1);\n\n        mx >>= 1;\n\n        my >>= 1;\n\n    }\n\n\n\n    src_x = s->mb_x * 8 + mx;\n\n    src_y = s->mb_y * 8 + my;\n\n    src_x = av_clip(src_x, -8, s->width >> 1);\n\n    if (src_x == (s->width >> 1))\n\n        dxy &= ~1;\n\n    src_y = av_clip(src_y, -8, s->height >> 1);\n\n    if (src_y == (s->height >> 1))\n\n        dxy &= ~2;\n\n    offset = (src_y * uvlinesize) + src_x;\n\n    ptr = ref_picture[1] + offset;\n\n    if(emu){\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr, s->uvlinesize, 9, 9,\n\n                         src_x, src_y, s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n        ptr= s->edge_emu_buffer;\n\n    }\n\n    pix_op[1][dxy](dest_cb, ptr, uvlinesize, h >> 1);\n\n\n\n    ptr = ref_picture[2] + offset;\n\n    if(emu){\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr, s->uvlinesize, 9, 9,\n\n                         src_x, src_y, s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n        ptr= s->edge_emu_buffer;\n\n    }\n\n    pix_op[1][dxy](dest_cr, ptr, uvlinesize, h >> 1);\n\n}\n", "idx": 21236, "_split": "valid", "_hash": "a74c884f5d75807571496f4d311c3924"}
{"project": "FFmpeg", "commit_id": "838740e6420538ad45982da6b1d3aa3ae91307f5", "target": 1, "func": "static int scaling_list_data(HEVCContext *s, ScalingList *sl)\n\n{\n\n    GetBitContext *gb = &s->HEVClc.gb;\n\n    uint8_t scaling_list_pred_mode_flag[4][6];\n\n    int32_t scaling_list_dc_coef[2][6];\n\n    int size_id, matrix_id, i, pos, delta;\n\n\n\n    for (size_id = 0; size_id < 4; size_id++)\n\n        for (matrix_id = 0; matrix_id < (size_id == 3 ? 2 : 6); matrix_id++) {\n\n            scaling_list_pred_mode_flag[size_id][matrix_id] = get_bits1(gb);\n\n            if (!scaling_list_pred_mode_flag[size_id][matrix_id]) {\n\n                delta = get_ue_golomb_long(gb);\n\n                /* Only need to handle non-zero delta. Zero means default,\n\n                 * which should already be in the arrays. */\n\n                if (delta) {\n\n                    // Copy from previous array.\n\n                    if (matrix_id - delta < 0) {\n\n                        av_log(s->avctx, AV_LOG_ERROR,\n\n                               \"Invalid delta in scaling list data: %d.\\n\", delta);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n\n\n                    memcpy(sl->sl[size_id][matrix_id],\n\n                           sl->sl[size_id][matrix_id - delta],\n\n                           size_id > 0 ? 64 : 16);\n\n                    if (size_id > 1)\n\n                        sl->sl_dc[size_id - 2][matrix_id] = sl->sl_dc[size_id - 2][matrix_id - delta];\n\n                }\n\n            } else {\n\n                int next_coef, coef_num;\n\n                int32_t scaling_list_delta_coef;\n\n\n\n                next_coef = 8;\n\n                coef_num  = FFMIN(64, 1 << (4 + (size_id << 1)));\n\n                if (size_id > 1) {\n\n                    scaling_list_dc_coef[size_id - 2][matrix_id] = get_se_golomb(gb) + 8;\n\n                    next_coef = scaling_list_dc_coef[size_id - 2][matrix_id];\n\n                    sl->sl_dc[size_id - 2][matrix_id] = next_coef;\n\n                }\n\n                for (i = 0; i < coef_num; i++) {\n\n                    if (size_id == 0)\n\n                        pos = 4 * ff_hevc_diag_scan4x4_y[i] +\n\n                                  ff_hevc_diag_scan4x4_x[i];\n\n                    else\n\n                        pos = 8 * ff_hevc_diag_scan8x8_y[i] +\n\n                                  ff_hevc_diag_scan8x8_x[i];\n\n\n\n                    scaling_list_delta_coef = get_se_golomb(gb);\n\n                    next_coef = (next_coef + scaling_list_delta_coef + 256) % 256;\n\n                    sl->sl[size_id][matrix_id][pos] = next_coef;\n\n                }\n\n            }\n\n        }\n\n\n\n    return 0;\n\n}\n", "idx": 21251, "_split": "valid", "_hash": "29c1d7d914bb0ab710eab4d520094296"}
{"project": "FFmpeg", "commit_id": "4c7b023d56e09a78a587d036db1b64bf7c493b3d", "target": 0, "func": "static int nvdec_mpeg12_start_frame(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n\n\n    NVDECContext      *ctx = avctx->internal->hwaccel_priv_data;\n\n    CUVIDPICPARAMS     *pp = &ctx->pic_params;\n\n    CUVIDMPEG2PICPARAMS *ppc = &pp->CodecSpecific.mpeg2;\n\n    FrameDecodeData *fdd;\n\n    NVDECFrame *cf;\n\n    AVFrame *cur_frame = s->current_picture.f;\n\n\n\n    int ret, i;\n\n\n\n    ret = ff_nvdec_start_frame(avctx, cur_frame);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    fdd = (FrameDecodeData*)cur_frame->private_ref->data;\n\n    cf  = (NVDECFrame*)fdd->hwaccel_priv;\n\n\n\n    *pp = (CUVIDPICPARAMS) {\n\n        .PicWidthInMbs     = (cur_frame->width  + 15) / 16,\n\n        .FrameHeightInMbs  = (cur_frame->height + 15) / 16,\n\n        .CurrPicIdx        = cf->idx,\n\n\n\n        .intra_pic_flag    = s->pict_type == AV_PICTURE_TYPE_I,\n\n        .ref_pic_flag      = s->pict_type == AV_PICTURE_TYPE_I ||\n\n                             s->pict_type == AV_PICTURE_TYPE_P,\n\n\n\n        .CodecSpecific.mpeg2 = {\n\n            .ForwardRefIdx     = get_ref_idx(s->last_picture.f),\n\n            .BackwardRefIdx    = get_ref_idx(s->next_picture.f),\n\n\n\n            .picture_coding_type        = s->pict_type,\n\n            .full_pel_forward_vector    = s->full_pel[0],\n\n            .full_pel_backward_vector   = s->full_pel[1],\n\n            .f_code                     = { { s->mpeg_f_code[0][0],\n\n                                              s->mpeg_f_code[0][1] },\n\n                                            { s->mpeg_f_code[1][0],\n\n                                              s->mpeg_f_code[1][1] } },\n\n            .intra_dc_precision         = s->intra_dc_precision,\n\n            .frame_pred_frame_dct       = s->frame_pred_frame_dct,\n\n            .concealment_motion_vectors = s->concealment_motion_vectors,\n\n            .q_scale_type               = s->q_scale_type,\n\n            .intra_vlc_format           = s->intra_vlc_format,\n\n            .alternate_scan             = s->alternate_scan,\n\n            .top_field_first            = s->top_field_first,\n\n        }\n\n    };\n\n\n\n    for (i = 0; i < 64; ++i) {\n\n        ppc->QuantMatrixIntra[i] = s->intra_matrix[i];\n\n        ppc->QuantMatrixInter[i] = s->inter_matrix[i];\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 21280, "_split": "valid", "_hash": "af872c2ff9e46f141be6e82256550477"}
{"project": "FFmpeg", "commit_id": "f7c67536fe56336b9c6dcbc87162394c7feb18a5", "target": 1, "func": "static int svq1_decode_frame(AVCodecContext *avctx,\n                             void *data, int *data_size,\n                             AVPacket *avpkt)\n{\n  const uint8_t *buf = avpkt->data;\n  int buf_size = avpkt->size;\n  MpegEncContext *s=avctx->priv_data;\n  uint8_t        *current, *previous;\n  int             result, i, x, y, width, height;\n  AVFrame *pict = data;\n  svq1_pmv *pmv;\n  /* initialize bit buffer */\n  init_get_bits(&s->gb,buf,buf_size*8);\n  /* decode frame header */\n  s->f_code = get_bits (&s->gb, 22);\n  if ((s->f_code & ~0x70) || !(s->f_code & 0x60))\n    return -1;\n  /* swap some header bytes (why?) */\n  if (s->f_code != 0x20) {\n    uint32_t *src = (uint32_t *) (buf + 4);\n    for (i=0; i < 4; i++) {\n      src[i] = ((src[i] << 16) | (src[i] >> 16)) ^ src[7 - i];\n    }\n  }\n  result = svq1_decode_frame_header (&s->gb, s);\n  if (result != 0)\n  {\n    av_dlog(s->avctx, \"Error in svq1_decode_frame_header %i\\n\",result);\n    return result;\n  }\n  avcodec_set_dimensions(avctx, s->width, s->height);\n  //FIXME this avoids some confusion for \"B frames\" without 2 references\n  //this should be removed after libavcodec can handle more flexible picture types & ordering\n  if(s->pict_type==AV_PICTURE_TYPE_B && s->last_picture_ptr==NULL) return buf_size;\n  if(  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type==AV_PICTURE_TYPE_B)\n     ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type!=AV_PICTURE_TYPE_I)\n     || avctx->skip_frame >= AVDISCARD_ALL)\n      return buf_size;\n  if(ff_MPV_frame_start(s, avctx) < 0)\n      return -1;\n  pmv = av_malloc((FFALIGN(s->width, 16)/8 + 3) * sizeof(*pmv));\n  if (!pmv)\n      return -1;\n  /* decode y, u and v components */\n  for (i=0; i < 3; i++) {\n    int linesize;\n    if (i == 0) {\n      width  = FFALIGN(s->width, 16);\n      height = FFALIGN(s->height, 16);\n      linesize= s->linesize;\n    } else {\n      if(s->flags&CODEC_FLAG_GRAY) break;\n      width  = FFALIGN(s->width/4, 16);\n      height = FFALIGN(s->height/4, 16);\n      linesize= s->uvlinesize;\n    }\n    current = s->current_picture.f.data[i];\n    if(s->pict_type==AV_PICTURE_TYPE_B){\n        previous = s->next_picture.f.data[i];\n    }else{\n        previous = s->last_picture.f.data[i];\n    }\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n      /* keyframe */\n      for (y=0; y < height; y+=16) {\n        for (x=0; x < width; x+=16) {\n          result = svq1_decode_block_intra (&s->gb, &current[x], linesize);\n          if (result != 0)\n          {\n            av_log(s->avctx, AV_LOG_ERROR, \"Error in svq1_decode_block %i (keyframe)\\n\",result);\n            goto err;\n          }\n        }\n        current += 16*linesize;\n      }\n    } else {\n      /* delta frame */\n      memset (pmv, 0, ((width / 8) + 3) * sizeof(svq1_pmv));\n      for (y=0; y < height; y+=16) {\n        for (x=0; x < width; x+=16) {\n          result = svq1_decode_delta_block (s, &s->gb, &current[x], previous,\n                                            linesize, pmv, x, y);\n          if (result != 0)\n          {\n            av_dlog(s->avctx, \"Error in svq1_decode_delta_block %i\\n\",result);\n            goto err;\n          }\n        }\n        pmv[0].x =\n        pmv[0].y = 0;\n        current += 16*linesize;\n      }\n    }\n  }\n  *pict = s->current_picture.f;\n  ff_MPV_frame_end(s);\n  *data_size=sizeof(AVFrame);\n  result = buf_size;\nerr:\n  av_free(pmv);\n  return result;\n}", "idx": 21288, "_split": "valid", "_hash": "268bbd086d7f255fff2a5849a30085dc"}
{"project": "FFmpeg", "commit_id": "505cb8e390f275830f5f387020207aaf267be800", "target": 1, "func": "static void ogg_free(AVFormatContext *s)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        OGGStreamContext *oggstream = st->priv_data;\n\n\n\n        if (st->codecpar->codec_id == AV_CODEC_ID_FLAC ||\n\n            st->codecpar->codec_id == AV_CODEC_ID_SPEEX ||\n\n            st->codecpar->codec_id == AV_CODEC_ID_OPUS ||\n\n            st->codecpar->codec_id == AV_CODEC_ID_VP8) {\n\n            av_freep(&oggstream->header[0]);\n\n        }\n\n        av_freep(&oggstream->header[1]);\n\n        av_freep(&st->priv_data);\n\n    }\n\n}", "idx": 21290, "_split": "valid", "_hash": "1098592c6c1c4b71375ee23888f4accb"}
{"project": "FFmpeg", "commit_id": "ae7a4a1594e3624f7c844dec44266d2dc74a6be2", "target": 1, "func": "static inline CopyRet receive_frame(AVCodecContext *avctx,\n\n                                    void *data, int *data_size,\n\n                                    uint8_t second_field)\n\n{\n\n    BC_STATUS ret;\n\n    BC_DTS_PROC_OUT output = {\n\n        .PicInfo.width  = avctx->width,\n\n        .PicInfo.height = avctx->height,\n\n    };\n\n    CHDContext *priv = avctx->priv_data;\n\n    HANDLE dev       = priv->dev;\n\n\n\n    *data_size = 0;\n\n\n\n    // Request decoded data from the driver\n\n    ret = DtsProcOutputNoCopy(dev, OUTPUT_PROC_TIMEOUT, &output);\n\n    if (ret == BC_STS_FMT_CHANGE) {\n\n        av_log(avctx, AV_LOG_VERBOSE, \"CrystalHD: Initial format change\\n\");\n\n        avctx->width  = output.PicInfo.width;\n\n        avctx->height = output.PicInfo.height;\n\n        return RET_COPY_AGAIN;\n\n    } else if (ret == BC_STS_SUCCESS) {\n\n        int copy_ret = -1;\n\n        if (output.PoutFlags & BC_POUT_FLAGS_PIB_VALID) {\n\n            if (priv->last_picture == -1) {\n\n                /*\n\n                 * Init to one less, so that the incrementing code doesn't\n\n                 * need to be special-cased.\n\n                 */\n\n                priv->last_picture = output.PicInfo.picture_number - 1;\n\n            }\n\n\n\n            if (avctx->codec->id == CODEC_ID_MPEG4 &&\n\n                output.PicInfo.timeStamp == 0) {\n\n                av_log(avctx, AV_LOG_VERBOSE,\n\n                       \"CrystalHD: Not returning packed frame twice.\\n\");\n\n                priv->last_picture++;\n\n                DtsReleaseOutputBuffs(dev, NULL, FALSE);\n\n                return RET_COPY_AGAIN;\n\n            }\n\n\n\n            print_frame_info(priv, &output);\n\n\n\n            if (priv->last_picture + 1 < output.PicInfo.picture_number) {\n\n                av_log(avctx, AV_LOG_WARNING,\n\n                       \"CrystalHD: Picture Number discontinuity\\n\");\n\n                /*\n\n                 * Have we lost frames? If so, we need to shrink the\n\n                 * pipeline length appropriately.\n\n                 *\n\n                 * XXX: I have no idea what the semantics of this situation\n\n                 * are so I don't even know if we've lost frames or which\n\n                 * ones.\n\n                 *\n\n                 * In any case, only warn the first time.\n\n                 */\n\n               priv->last_picture = output.PicInfo.picture_number - 1;\n\n            }\n\n\n\n            copy_ret = copy_frame(avctx, &output, data, data_size, second_field);\n\n            if (*data_size > 0) {\n\n                avctx->has_b_frames--;\n\n                priv->last_picture++;\n\n                av_log(avctx, AV_LOG_VERBOSE, \"CrystalHD: Pipeline length: %u\\n\",\n\n                       avctx->has_b_frames);\n\n            }\n\n        } else {\n\n            /*\n\n             * An invalid frame has been consumed.\n\n             */\n\n            av_log(avctx, AV_LOG_ERROR, \"CrystalHD: ProcOutput succeeded with \"\n\n                                        \"invalid PIB\\n\");\n\n            avctx->has_b_frames--;\n\n            copy_ret = RET_OK;\n\n        }\n\n        DtsReleaseOutputBuffs(dev, NULL, FALSE);\n\n\n\n        return copy_ret;\n\n    } else if (ret == BC_STS_BUSY) {\n\n        return RET_COPY_AGAIN;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"CrystalHD: ProcOutput failed %d\\n\", ret);\n\n        return RET_ERROR;\n\n    }\n\n}\n", "idx": 21390, "_split": "valid", "_hash": "4fbcdae317a88722a9647ef4401d9d17"}
{"project": "FFmpeg", "commit_id": "a1335149fd610b16459d9281b611282cac51c950", "target": 0, "func": "static int encode_frame(AVCodecContext *avctx, QSVEncContext *q,\n\n                        const AVFrame *frame)\n\n{\n\n    AVPacket new_pkt = { 0 };\n\n    mfxBitstream *bs;\n\n\n\n    mfxFrameSurface1 *surf = NULL;\n\n    mfxSyncPoint sync      = NULL;\n\n    int ret;\n\n\n\n    if (frame) {\n\n        ret = submit_frame(q, frame, &surf);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error submitting the frame for encoding.\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    ret = av_new_packet(&new_pkt, q->packet_size);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error allocating the output packet\\n\");\n\n        return ret;\n\n    }\n\n\n\n    bs = av_mallocz(sizeof(*bs));\n\n    if (!bs) {\n\n        av_packet_unref(&new_pkt);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    bs->Data      = new_pkt.data;\n\n    bs->MaxLength = new_pkt.size;\n\n\n\n    do {\n\n        ret = MFXVideoENCODE_EncodeFrameAsync(q->session, NULL, surf, bs, &sync);\n\n        if (ret == MFX_WRN_DEVICE_BUSY)\n\n            av_usleep(1);\n\n    } while (ret > 0);\n\n\n\n    if (ret < 0) {\n\n        av_packet_unref(&new_pkt);\n\n        av_freep(&bs);\n\n        return (ret == MFX_ERR_MORE_DATA) ? 0 : ff_qsv_error(ret);\n\n    }\n\n\n\n    if (ret == MFX_WRN_INCOMPATIBLE_VIDEO_PARAM && frame->interlaced_frame)\n\n        print_interlace_msg(avctx, q);\n\n\n\n    if (sync) {\n\n        av_fifo_generic_write(q->async_fifo, &new_pkt, sizeof(new_pkt), NULL);\n\n        av_fifo_generic_write(q->async_fifo, &sync,    sizeof(sync),    NULL);\n\n        av_fifo_generic_write(q->async_fifo, &bs,      sizeof(bs),    NULL);\n\n    } else {\n\n        av_packet_unref(&new_pkt);\n\n        av_freep(&bs);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 21399, "_split": "valid", "_hash": "1856f566c4930792ef90506cef1e22f7"}
{"project": "FFmpeg", "commit_id": "28bf81c90d36a55cf76e2be913c5215ebebf61f2", "target": 1, "func": "static inline void RENAME(initFilter)(int16_t *dstFilter, int16_t *filterPos, int *filterSize, int xInc,\n\n\t\t\t\t      int srcW, int dstW, int filterAlign, int one)\n\n{\n\n\tint i;\n\n\tdouble filter[8000];\n\n#ifdef HAVE_MMX\n\n\tasm volatile(\"emms\\n\\t\"::: \"memory\"); //FIXME this shouldnt be required but it IS (even for non mmx versions)\n\n#endif\n\n\n\n\tif(ABS(xInc - 0x10000) <10) // unscaled\n\n\t{\n\n\t\tint i;\n\n\t\t*filterSize= (1 +(filterAlign-1)) & (~(filterAlign-1)); // 1 or 4 normaly\n\n\t\tfor(i=0; i<dstW*(*filterSize); i++) filter[i]=0;\n\n\n\n\t\tfor(i=0; i<dstW; i++)\n\n\t\t{\n\n\t\t\tfilter[i*(*filterSize)]=1;\n\n\t\t\tfilterPos[i]=i;\n\n\t\t}\n\n\n\n\t}\n\n\telse if(xInc <= (1<<16) || sws_flags==SWS_FAST_BILINEAR) // upscale\n\n\t{\n\n\t\tint i;\n\n\t\tint xDstInSrc;\n\n\t\tif(sws_flags==SWS_BICUBIC) *filterSize= 4;\n\n\t\telse\t\t\t   *filterSize= 2;\n\n//\t\tprintf(\"%d %d %d\\n\", filterSize, srcW, dstW);\n\n\t\t*filterSize= (*filterSize +(filterAlign-1)) & (~(filterAlign-1));\n\n\n\n\t\txDstInSrc= xInc/2 - 0x8000;\n\n\t\tfor(i=0; i<dstW; i++)\n\n\t\t{\n\n\t\t\tint xx= (xDstInSrc>>16) - (*filterSize>>1) + 1;\n\n\t\t\tint j;\n\n\n\n\t\t\tfilterPos[i]= xx;\n\n\t\t\tif(sws_flags == SWS_BICUBIC)\n\n\t\t\t{\n\n\t\t\t\tdouble d= ABS(((xx+1)<<16) - xDstInSrc)/(double)(1<<16);\n\n\t\t\t\tdouble y1,y2,y3,y4;\n\n\t\t\t\tdouble A= -0.75;\n\n\t\t\t\t\t// Equation is from VirtualDub\n\n\t\t\t\ty1 = (        +     A*d -       2.0*A*d*d +       A*d*d*d);\n\n\t\t\t\ty2 = (+ 1.0             -     (A+3.0)*d*d + (A+2.0)*d*d*d);\n\n\t\t\t\ty3 = (        -     A*d + (2.0*A+3.0)*d*d - (A+2.0)*d*d*d);\n\n\t\t\t\ty4 = (                  +           A*d*d -       A*d*d*d);\n\n\n\n//\t\t\t\tprintf(\"%d %d %d \\n\", coeff, (int)d, xDstInSrc);\n\n\t\t\t\tfilter[i*(*filterSize) + 0]= y1;\n\n\t\t\t\tfilter[i*(*filterSize) + 1]= y2;\n\n\t\t\t\tfilter[i*(*filterSize) + 2]= y3;\n\n\t\t\t\tfilter[i*(*filterSize) + 3]= y4;\n\n//\t\t\t\tprintf(\"%1.3f %d, %d, %d, %d\\n\",d , y1, y2, y3, y4);\n\n\t\t\t}\n\n\t\t\telse\n\n\t\t\t{\n\n\t\t\t\tfor(j=0; j<*filterSize; j++)\n\n\t\t\t\t{\n\n\t\t\t\t\tdouble d= ABS((xx<<16) - xDstInSrc)/(double)(1<<16);\n\n\t\t\t\t\tdouble coeff= 1.0 - d;\n\n\t\t\t\t\tif(coeff<0) coeff=0;\n\n\t//\t\t\t\tprintf(\"%d %d %d \\n\", coeff, (int)d, xDstInSrc);\n\n\t\t\t\t\tfilter[i*(*filterSize) + j]= coeff;\n\n\t\t\t\t\txx++;\n\n\t\t\t\t}\n\n\t\t\t}\n\n\t\t\txDstInSrc+= xInc;\n\n\t\t}\n\n\t}\n\n\telse // downscale\n\n\t{\n\n\t\tint xDstInSrc;\n\n\t\tif(sws_flags==SWS_BICUBIC) *filterSize= (int)ceil(1 + 4.0*srcW / (double)dstW);\n\n\t\telse\t\t\t   *filterSize= (int)ceil(1 + 2.0*srcW / (double)dstW);\n\n//\t\tprintf(\"%d %d %d\\n\", *filterSize, srcW, dstW);\n\n\t\t*filterSize= (*filterSize +(filterAlign-1)) & (~(filterAlign-1));\n\n\n\n\t\txDstInSrc= xInc/2 - 0x8000;\n\n\t\tfor(i=0; i<dstW; i++)\n\n\t\t{\n\n\t\t\tint xx= (int)((double)xDstInSrc/(double)(1<<16) - ((*filterSize)-1)*0.5 + 0.5);\n\n\t\t\tint j;\n\n\n\n\t\t\tfilterPos[i]= xx;\n\n\t\t\tfor(j=0; j<*filterSize; j++)\n\n\t\t\t{\n\n\t\t\t\tdouble d= ABS((xx<<16) - xDstInSrc)/(double)xInc;\n\n\t\t\t\tdouble coeff;\n\n\t\t\t\tif(sws_flags == SWS_BICUBIC)\n\n\t\t\t\t{\n\n\t\t\t\t\tdouble A= -0.75;\n\n//\t\t\t\t\td*=2;\n\n\t\t\t\t\t// Equation is from VirtualDub\n\n\t\t\t\t\tif(d<1.0)\n\n\t\t\t\t\t\tcoeff = (1.0 - (A+3.0)*d*d + (A+2.0)*d*d*d);\n\n\t\t\t\t\telse if(d<2.0)\n\n\t\t\t\t\t\tcoeff = (-4.0*A + 8.0*A*d - 5.0*A*d*d + A*d*d*d);\n\n\t\t\t\t\telse\n\n\t\t\t\t\t\tcoeff=0.0;\n\n\t\t\t\t}\n\n\t\t\t\telse\n\n\t\t\t\t{\n\n\t\t\t\t\tcoeff= 1.0 - d;\n\n\t\t\t\t\tif(coeff<0) coeff=0;\n\n\t\t\t\t}\n\n//\t\t\t\tif(filterAlign==1) printf(\"%d %d %d \\n\", coeff, (int)d, xDstInSrc);\n\n\t\t\t\tfilter[i*(*filterSize) + j]= coeff;\n\n\t\t\t\txx++;\n\n\t\t\t}\n\n\t\t\txDstInSrc+= xInc;\n\n\t\t}\n\n\t}\n\n\n\n\t//fix borders\n\n\tfor(i=0; i<dstW; i++)\n\n\t{\n\n\t\tint j;\n\n\t\tif(filterPos[i] < 0)\n\n\t\t{\n\n\t\t\t// Move filter coeffs left to compensate for filterPos\n\n\t\t\tfor(j=1; j<*filterSize; j++)\n\n\t\t\t{\n\n\t\t\t\tint left= MAX(j + filterPos[i], 0);\n\n\t\t\t\tfilter[i*(*filterSize) + left] += filter[i*(*filterSize) + j];\n\n\t\t\t\tfilter[i*(*filterSize) + j]=0;\n\n\t\t\t}\n\n\t\t\tfilterPos[i]= 0;\n\n\t\t}\n\n\n\n\t\tif(filterPos[i] + (*filterSize) > srcW)\n\n\t\t{\n\n\t\t\tint shift= filterPos[i] + (*filterSize) - srcW;\n\n\t\t\t// Move filter coeffs right to compensate for filterPos\n\n\t\t\tfor(j=(*filterSize)-2; j>=0; j--)\n\n\t\t\t{\n\n\t\t\t\tint right= MIN(j + shift, (*filterSize)-1);\n\n\t\t\t\tfilter[i*(*filterSize) +right] += filter[i*(*filterSize) +j];\n\n\t\t\t\tfilter[i*(*filterSize) +j]=0;\n\n\t\t\t}\n\n\t\t\tfilterPos[i]= srcW - (*filterSize);\n\n\t\t}\n\n\t}\n\n\n\n\t//FIXME try to align filterpos if possible / try to shift filterpos to put zeros at the end\n\n\t// and skip these than later\n\n\n\n\t//Normalize\n\n\tfor(i=0; i<dstW; i++)\n\n\t{\n\n\t\tint j;\n\n\t\tdouble sum=0;\n\n\t\tdouble scale= one;\n\n\t\tfor(j=0; j<*filterSize; j++)\n\n\t\t{\n\n\t\t\tsum+= filter[i*(*filterSize) + j];\n\n\t\t}\n\n\t\tscale/= sum;\n\n\t\tfor(j=0; j<*filterSize; j++)\n\n\t\t{\n\n\t\t\tdstFilter[i*(*filterSize) + j]= (int)(filter[i*(*filterSize) + j]*scale);\n\n\t\t}\n\n\t}\n\n}\n", "idx": 21470, "_split": "valid", "_hash": "08e0468b831e42f5bacc7d5c260eea27"}
{"project": "FFmpeg", "commit_id": "0c22311b56e66115675c4a96e4c78547886a4171", "target": 0, "func": "static void opt_pad_color(const char *arg) {\n\n    /* Input is expected to be six hex digits similar to\n\n       how colors are expressed in html tags (but without the #) */\n\n    int rgb = strtol(arg, NULL, 16);\n\n    int r,g,b;\n\n\n\n    r = (rgb >> 16);\n\n    g = ((rgb >> 8) & 255);\n\n    b = (rgb & 255);\n\n\n\n    padcolor[0] = RGB_TO_Y(r,g,b);\n\n    padcolor[1] = RGB_TO_U(r,g,b,0);\n\n    padcolor[2] = RGB_TO_V(r,g,b,0);\n\n}\n", "idx": 21586, "_split": "valid", "_hash": "cecc4e8056bc339515c7c66a564c076d"}
{"project": "FFmpeg", "commit_id": "52c959a2376614e4c9089145b8ee69334b663257", "target": 1, "func": "static int read_channels(AVFilterContext *ctx, int channels, uint8_t *item_str, int *nb, double **c, double **cache)\n\n{\n\n    char *p, *arg, *old_str, *prev_arg = NULL, *saveptr = NULL;\n\n    int i, ret;\n\n\n\n    p = old_str = av_strdup(item_str);\n\n    if (!p)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < channels; i++) {\n\n        if (!(arg = av_strtok(p, \"|\", &saveptr)))\n\n            arg = prev_arg;\n\n\n\n        p = NULL;\n\n        count_coefficients(arg, &nb[i]);\n\n        cache[i] = av_calloc(nb[i], sizeof(cache[i]));\n\n        c[i] = av_calloc(nb[i], sizeof(c[i]));\n\n        if (!c[i] || !cache[i])\n\n            return AVERROR(ENOMEM);\n\n\n\n        ret = read_coefficients(ctx, arg, nb[i], c[i]);\n\n        if (ret < 0)\n\n            return ret;\n\n        prev_arg = arg;\n\n    }\n\n\n\n    av_freep(&old_str);\n\n\n\n    return 0;\n\n}\n", "idx": 21589, "_split": "valid", "_hash": "b4624c7f4cd4f0e50b03182a4986dcc2"}
{"project": "FFmpeg", "commit_id": "95a98ab3f0439df82a907233f80a7404b987e838", "target": 0, "func": "av_cold void ff_ac3dsp_init_x86(AC3DSPContext *c, int bit_exact)\n\n{\n\n#if HAVE_YASM\n\n    int mm_flags = av_get_cpu_flags();\n\n\n\n    if (mm_flags & AV_CPU_FLAG_MMX) {\n\n        c->ac3_exponent_min = ff_ac3_exponent_min_mmx;\n\n        c->ac3_max_msb_abs_int16 = ff_ac3_max_msb_abs_int16_mmx;\n\n        c->ac3_lshift_int16 = ff_ac3_lshift_int16_mmx;\n\n        c->ac3_rshift_int32 = ff_ac3_rshift_int32_mmx;\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_3DNOW && HAVE_AMD3DNOW) {\n\n        c->extract_exponents = ff_ac3_extract_exponents_3dnow;\n\n        if (!bit_exact) {\n\n            c->float_to_fixed24 = ff_float_to_fixed24_3dnow;\n\n        }\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_MMX2 && HAVE_MMX2) {\n\n        c->ac3_exponent_min = ff_ac3_exponent_min_mmxext;\n\n        c->ac3_max_msb_abs_int16 = ff_ac3_max_msb_abs_int16_mmxext;\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_SSE && HAVE_SSE) {\n\n        c->float_to_fixed24 = ff_float_to_fixed24_sse;\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_SSE2 && HAVE_SSE) {\n\n        c->ac3_exponent_min = ff_ac3_exponent_min_sse2;\n\n        c->ac3_max_msb_abs_int16 = ff_ac3_max_msb_abs_int16_sse2;\n\n        c->float_to_fixed24 = ff_float_to_fixed24_sse2;\n\n        c->compute_mantissa_size = ff_ac3_compute_mantissa_size_sse2;\n\n        c->extract_exponents = ff_ac3_extract_exponents_sse2;\n\n        if (!(mm_flags & AV_CPU_FLAG_SSE2SLOW)) {\n\n            c->ac3_lshift_int16 = ff_ac3_lshift_int16_sse2;\n\n            c->ac3_rshift_int32 = ff_ac3_rshift_int32_sse2;\n\n        }\n\n    }\n\n    if (mm_flags & AV_CPU_FLAG_SSSE3 && HAVE_SSSE3) {\n\n        c->ac3_max_msb_abs_int16 = ff_ac3_max_msb_abs_int16_ssse3;\n\n        if (!(mm_flags & AV_CPU_FLAG_ATOM)) {\n\n            c->extract_exponents = ff_ac3_extract_exponents_ssse3;\n\n        }\n\n    }\n\n#endif\n\n}\n", "idx": 21601, "_split": "valid", "_hash": "a95a47a833cb44c6583cd58e37baac72"}
{"project": "FFmpeg", "commit_id": "ca16618b01abfde44b4eaf92dc89b01aa1b4a91e", "target": 0, "func": "static int xan_decode_end(AVCodecContext *avctx)\n\n{\n\n    XanContext *s = avctx->priv_data;\n\n\n\n    /* release the last frame */\n\n    avctx->release_buffer(avctx, &s->last_frame);\n\n\n\n    av_free(s->buffer1);\n\n    av_free(s->buffer2);\n\n\n\n    return 0;\n\n}\n", "idx": 21607, "_split": "valid", "_hash": "2acf6df74d09a1a699fa121a562d41e6"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int apc_probe(AVProbeData *p)\n\n{\n\n    if (p->buf_size < 8)\n\n        return 0;\n\n\n\n    if (!strncmp(p->buf, \"CRYO_APC\", 8))\n\n        return AVPROBE_SCORE_MAX;\n\n\n\n    return 0;\n\n}\n", "idx": 21664, "_split": "valid", "_hash": "68f32ed421ccfbe51f45ba0d1a69f352"}
{"project": "FFmpeg", "commit_id": "ba992711f79ccfba4ff0b305215d7056faf0ed0d", "target": 1, "func": "static int hnm_decode_frame(AVCodecContext *avctx, void *data,\n                            int *got_frame, AVPacket *avpkt)\n{\n    AVFrame *frame = data;\n    Hnm4VideoContext *hnm = avctx->priv_data;\n    int ret;\n    uint16_t chunk_id;\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0)\n        return ret;\n    chunk_id = AV_RL16(avpkt->data + 4);\n    if (chunk_id == HNM4_CHUNK_ID_PL) {\n        hnm_update_palette(avctx, avpkt->data, avpkt->size);\n        frame->palette_has_changed = 1;\n    } else if (chunk_id == HNM4_CHUNK_ID_IZ) {\n        unpack_intraframe(avctx, avpkt->data + 12, avpkt->size - 12);\n        memcpy(hnm->previous, hnm->current, hnm->width * hnm->height);\n        if (hnm->version == 0x4a)\n            memcpy(hnm->processed, hnm->current, hnm->width * hnm->height);\n        else\n            postprocess_current_frame(avctx);\n        copy_processed_frame(avctx, frame);\n        frame->pict_type = AV_PICTURE_TYPE_I;\n        frame->key_frame = 1;\n        memcpy(frame->data[1], hnm->palette, 256 * 4);\n        *got_frame = 1;\n    } else if (chunk_id == HNM4_CHUNK_ID_IU) {\n        if (hnm->version == 0x4a) {\n            decode_interframe_v4a(avctx, avpkt->data + 8, avpkt->size - 8);\n            memcpy(hnm->processed, hnm->current, hnm->width * hnm->height);\n        } else {\n            decode_interframe_v4(avctx, avpkt->data + 8, avpkt->size - 8);\n            postprocess_current_frame(avctx);\n        copy_processed_frame(avctx, frame);\n        frame->pict_type = AV_PICTURE_TYPE_P;\n        frame->key_frame = 0;\n        memcpy(frame->data[1], hnm->palette, 256 * 4);\n        *got_frame = 1;\n        hnm_flip_buffers(hnm);\n    } else {\n        av_log(avctx, AV_LOG_ERROR, \"invalid chunk id: %d\\n\", chunk_id);\n    return avpkt->size;", "idx": 21683, "_split": "valid", "_hash": "7da74592bfe56cebb0a73b17a852141a"}
{"project": "FFmpeg", "commit_id": "57623cba1301ee7874687dd7e04c611051638e9d", "target": 0, "func": "int vp78_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n\n                      AVPacket *avpkt, int is_vp7)\n\n{\n\n    VP8Context *s = avctx->priv_data;\n\n    int ret, i, referenced, num_jobs;\n\n    enum AVDiscard skip_thresh;\n\n    VP8Frame *av_uninit(curframe), *prev_frame;\n\n\n\n    if (is_vp7)\n\n        ret = vp7_decode_frame_header(s, avpkt->data, avpkt->size);\n\n    else\n\n        ret = vp8_decode_frame_header(s, avpkt->data, avpkt->size);\n\n\n\n    if (ret < 0)\n\n        goto err;\n\n\n\n    if (!is_vp7 && s->pix_fmt == AV_PIX_FMT_NONE) {\n\n        enum AVPixelFormat pix_fmts[] = {\n\n#if CONFIG_VP8_VAAPI_HWACCEL\n\n            AV_PIX_FMT_VAAPI,\n\n#endif\n\n            AV_PIX_FMT_YUV420P,\n\n            AV_PIX_FMT_NONE,\n\n        };\n\n\n\n        s->pix_fmt = ff_get_format(s->avctx, pix_fmts);\n\n        if (s->pix_fmt < 0) {\n\n            ret = AVERROR(EINVAL);\n\n            goto err;\n\n        }\n\n        avctx->pix_fmt = s->pix_fmt;\n\n    }\n\n\n\n    prev_frame = s->framep[VP56_FRAME_CURRENT];\n\n\n\n    referenced = s->update_last || s->update_golden == VP56_FRAME_CURRENT ||\n\n                 s->update_altref == VP56_FRAME_CURRENT;\n\n\n\n    skip_thresh = !referenced ? AVDISCARD_NONREF\n\n                              : !s->keyframe ? AVDISCARD_NONKEY\n\n                                             : AVDISCARD_ALL;\n\n\n\n    if (avctx->skip_frame >= skip_thresh) {\n\n        s->invisible = 1;\n\n        memcpy(&s->next_framep[0], &s->framep[0], sizeof(s->framep[0]) * 4);\n\n        goto skip_decode;\n\n    }\n\n    s->deblock_filter = s->filter.level && avctx->skip_loop_filter < skip_thresh;\n\n\n\n    // release no longer referenced frames\n\n    for (i = 0; i < 5; i++)\n\n        if (s->frames[i].tf.f->data[0] &&\n\n            &s->frames[i] != prev_frame &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN]   &&\n\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2])\n\n            vp8_release_frame(s, &s->frames[i]);\n\n\n\n    curframe = s->framep[VP56_FRAME_CURRENT] = vp8_find_free_buffer(s);\n\n\n\n    if (!s->colorspace)\n\n        avctx->colorspace = AVCOL_SPC_BT470BG;\n\n    if (s->fullrange)\n\n        avctx->color_range = AVCOL_RANGE_JPEG;\n\n    else\n\n        avctx->color_range = AVCOL_RANGE_MPEG;\n\n\n\n    /* Given that arithmetic probabilities are updated every frame, it's quite\n\n     * likely that the values we have on a random interframe are complete\n\n     * junk if we didn't start decode on a keyframe. So just don't display\n\n     * anything rather than junk. */\n\n    if (!s->keyframe && (!s->framep[VP56_FRAME_PREVIOUS] ||\n\n                         !s->framep[VP56_FRAME_GOLDEN]   ||\n\n                         !s->framep[VP56_FRAME_GOLDEN2])) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Discarding interframe without a prior keyframe!\\n\");\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto err;\n\n    }\n\n\n\n    curframe->tf.f->key_frame = s->keyframe;\n\n    curframe->tf.f->pict_type = s->keyframe ? AV_PICTURE_TYPE_I\n\n                                            : AV_PICTURE_TYPE_P;\n\n    if ((ret = vp8_alloc_frame(s, curframe, referenced))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed!\\n\");\n\n        goto err;\n\n    }\n\n\n\n    // check if golden and altref are swapped\n\n    if (s->update_altref != VP56_FRAME_NONE)\n\n        s->next_framep[VP56_FRAME_GOLDEN2] = s->framep[s->update_altref];\n\n    else\n\n        s->next_framep[VP56_FRAME_GOLDEN2] = s->framep[VP56_FRAME_GOLDEN2];\n\n\n\n    if (s->update_golden != VP56_FRAME_NONE)\n\n        s->next_framep[VP56_FRAME_GOLDEN] = s->framep[s->update_golden];\n\n    else\n\n        s->next_framep[VP56_FRAME_GOLDEN] = s->framep[VP56_FRAME_GOLDEN];\n\n\n\n    if (s->update_last)\n\n        s->next_framep[VP56_FRAME_PREVIOUS] = curframe;\n\n    else\n\n        s->next_framep[VP56_FRAME_PREVIOUS] = s->framep[VP56_FRAME_PREVIOUS];\n\n\n\n    s->next_framep[VP56_FRAME_CURRENT] = curframe;\n\n\n\n    ff_thread_finish_setup(avctx);\n\n\n\n    if (avctx->hwaccel) {\n\n        ret = avctx->hwaccel->start_frame(avctx, avpkt->data, avpkt->size);\n\n        if (ret < 0)\n\n            goto err;\n\n\n\n        ret = avctx->hwaccel->decode_slice(avctx, avpkt->data, avpkt->size);\n\n        if (ret < 0)\n\n            goto err;\n\n\n\n        ret = avctx->hwaccel->end_frame(avctx);\n\n        if (ret < 0)\n\n            goto err;\n\n\n\n    } else {\n\n        s->linesize   = curframe->tf.f->linesize[0];\n\n        s->uvlinesize = curframe->tf.f->linesize[1];\n\n\n\n        memset(s->top_nnz, 0, s->mb_width * sizeof(*s->top_nnz));\n\n        /* Zero macroblock structures for top/top-left prediction\n\n         * from outside the frame. */\n\n        if (!s->mb_layout)\n\n            memset(s->macroblocks + s->mb_height * 2 - 1, 0,\n\n                   (s->mb_width + 1) * sizeof(*s->macroblocks));\n\n        if (!s->mb_layout && s->keyframe)\n\n            memset(s->intra4x4_pred_mode_top, DC_PRED, s->mb_width * 4);\n\n\n\n        memset(s->ref_count, 0, sizeof(s->ref_count));\n\n\n\n        if (s->mb_layout == 1) {\n\n            // Make sure the previous frame has read its segmentation map,\n\n            // if we re-use the same map.\n\n            if (prev_frame && s->segmentation.enabled &&\n\n                !s->segmentation.update_map)\n\n                ff_thread_await_progress(&prev_frame->tf, 1, 0);\n\n            if (is_vp7)\n\n                vp7_decode_mv_mb_modes(avctx, curframe, prev_frame);\n\n            else\n\n                vp8_decode_mv_mb_modes(avctx, curframe, prev_frame);\n\n        }\n\n\n\n        if (avctx->active_thread_type == FF_THREAD_FRAME)\n\n            num_jobs = 1;\n\n        else\n\n            num_jobs = FFMIN(s->num_coeff_partitions, avctx->thread_count);\n\n        s->num_jobs   = num_jobs;\n\n        s->curframe   = curframe;\n\n        s->prev_frame = prev_frame;\n\n        s->mv_min.y   = -MARGIN;\n\n        s->mv_max.y   = ((s->mb_height - 1) << 6) + MARGIN;\n\n        for (i = 0; i < MAX_THREADS; i++) {\n\n            s->thread_data[i].thread_mb_pos = 0;\n\n            s->thread_data[i].wait_mb_pos   = INT_MAX;\n\n        }\n\n\n\n        if (is_vp7)\n\n            avctx->execute2(avctx, vp7_decode_mb_row_sliced, s->thread_data, NULL,\n\n                            num_jobs);\n\n        else\n\n            avctx->execute2(avctx, vp8_decode_mb_row_sliced, s->thread_data, NULL,\n\n                            num_jobs);\n\n    }\n\n\n\n    ff_thread_report_progress(&curframe->tf, INT_MAX, 0);\n\n    memcpy(&s->framep[0], &s->next_framep[0], sizeof(s->framep[0]) * 4);\n\n\n\nskip_decode:\n\n    // if future frames don't use the updated probabilities,\n\n    // reset them to the values we saved\n\n    if (!s->update_probabilities)\n\n        s->prob[0] = s->prob[1];\n\n\n\n    if (!s->invisible) {\n\n        if ((ret = av_frame_ref(data, curframe->tf.f)) < 0)\n\n            return ret;\n\n        *got_frame = 1;\n\n    }\n\n\n\n    return avpkt->size;\n\nerr:\n\n    memcpy(&s->next_framep[0], &s->framep[0], sizeof(s->framep[0]) * 4);\n\n    return ret;\n\n}\n", "idx": 21685, "_split": "valid", "_hash": "e2daacdeb23f0b239dee1f7b172f9abe"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t *udst, uint8_t *vdst,\n\n                                      long width, long height,\n\n                                      long lumStride, long chromStride, long srcStride)\n\n{\n\n    long y;\n\n    const x86_reg chromWidth= width>>1;\n\n    for (y=0; y<height; y+=2) {\n\n#if COMPILE_TEMPLATE_MMX\n\n        __asm__ volatile(\n\n            \"xor                 %%\"REG_a\", %%\"REG_a\"   \\n\\t\"\n\n            \"pcmpeqw             %%mm7, %%mm7   \\n\\t\"\n\n            \"psrlw                  $8, %%mm7   \\n\\t\" // FF,00,FF,00...\n\n            \".p2align                4          \\n\\t\"\n\n            \"1:                                 \\n\\t\"\n\n            PREFETCH\" 64(%0, %%\"REG_a\", 4)          \\n\\t\"\n\n            \"movq       (%0, %%\"REG_a\", 4), %%mm0   \\n\\t\" // UYVY UYVY(0)\n\n            \"movq      8(%0, %%\"REG_a\", 4), %%mm1   \\n\\t\" // UYVY UYVY(4)\n\n            \"movq                %%mm0, %%mm2   \\n\\t\" // UYVY UYVY(0)\n\n            \"movq                %%mm1, %%mm3   \\n\\t\" // UYVY UYVY(4)\n\n            \"pand                %%mm7, %%mm0   \\n\\t\" // U0V0 U0V0(0)\n\n            \"pand                %%mm7, %%mm1   \\n\\t\" // U0V0 U0V0(4)\n\n            \"psrlw                  $8, %%mm2   \\n\\t\" // Y0Y0 Y0Y0(0)\n\n            \"psrlw                  $8, %%mm3   \\n\\t\" // Y0Y0 Y0Y0(4)\n\n            \"packuswb            %%mm1, %%mm0   \\n\\t\" // UVUV UVUV(0)\n\n            \"packuswb            %%mm3, %%mm2   \\n\\t\" // YYYY YYYY(0)\n\n\n\n            MOVNTQ\"              %%mm2,  (%1, %%\"REG_a\", 2) \\n\\t\"\n\n\n\n            \"movq     16(%0, %%\"REG_a\", 4), %%mm1   \\n\\t\" // UYVY UYVY(8)\n\n            \"movq     24(%0, %%\"REG_a\", 4), %%mm2   \\n\\t\" // UYVY UYVY(12)\n\n            \"movq                %%mm1, %%mm3   \\n\\t\" // UYVY UYVY(8)\n\n            \"movq                %%mm2, %%mm4   \\n\\t\" // UYVY UYVY(12)\n\n            \"pand                %%mm7, %%mm1   \\n\\t\" // U0V0 U0V0(8)\n\n            \"pand                %%mm7, %%mm2   \\n\\t\" // U0V0 U0V0(12)\n\n            \"psrlw                  $8, %%mm3   \\n\\t\" // Y0Y0 Y0Y0(8)\n\n            \"psrlw                  $8, %%mm4   \\n\\t\" // Y0Y0 Y0Y0(12)\n\n            \"packuswb            %%mm2, %%mm1   \\n\\t\" // UVUV UVUV(8)\n\n            \"packuswb            %%mm4, %%mm3   \\n\\t\" // YYYY YYYY(8)\n\n\n\n            MOVNTQ\"              %%mm3, 8(%1, %%\"REG_a\", 2) \\n\\t\"\n\n\n\n            \"movq                %%mm0, %%mm2   \\n\\t\" // UVUV UVUV(0)\n\n            \"movq                %%mm1, %%mm3   \\n\\t\" // UVUV UVUV(8)\n\n            \"psrlw                  $8, %%mm0   \\n\\t\" // V0V0 V0V0(0)\n\n            \"psrlw                  $8, %%mm1   \\n\\t\" // V0V0 V0V0(8)\n\n            \"pand                %%mm7, %%mm2   \\n\\t\" // U0U0 U0U0(0)\n\n            \"pand                %%mm7, %%mm3   \\n\\t\" // U0U0 U0U0(8)\n\n            \"packuswb            %%mm1, %%mm0   \\n\\t\" // VVVV VVVV(0)\n\n            \"packuswb            %%mm3, %%mm2   \\n\\t\" // UUUU UUUU(0)\n\n\n\n            MOVNTQ\"              %%mm0, (%3, %%\"REG_a\") \\n\\t\"\n\n            MOVNTQ\"              %%mm2, (%2, %%\"REG_a\") \\n\\t\"\n\n\n\n            \"add                    $8, %%\"REG_a\"   \\n\\t\"\n\n            \"cmp                    %4, %%\"REG_a\"   \\n\\t\"\n\n            \" jb                    1b          \\n\\t\"\n\n            ::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n            : \"memory\", \"%\"REG_a\n\n        );\n\n\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n\n\n        __asm__ volatile(\n\n            \"xor                 %%\"REG_a\", %%\"REG_a\"   \\n\\t\"\n\n            \".p2align                    4          \\n\\t\"\n\n            \"1:                                 \\n\\t\"\n\n            PREFETCH\" 64(%0, %%\"REG_a\", 4)          \\n\\t\"\n\n            \"movq       (%0, %%\"REG_a\", 4), %%mm0   \\n\\t\" // YUYV YUYV(0)\n\n            \"movq      8(%0, %%\"REG_a\", 4), %%mm1   \\n\\t\" // YUYV YUYV(4)\n\n            \"movq     16(%0, %%\"REG_a\", 4), %%mm2   \\n\\t\" // YUYV YUYV(8)\n\n            \"movq     24(%0, %%\"REG_a\", 4), %%mm3   \\n\\t\" // YUYV YUYV(12)\n\n            \"psrlw                  $8, %%mm0   \\n\\t\" // Y0Y0 Y0Y0(0)\n\n            \"psrlw                  $8, %%mm1   \\n\\t\" // Y0Y0 Y0Y0(4)\n\n            \"psrlw                  $8, %%mm2   \\n\\t\" // Y0Y0 Y0Y0(8)\n\n            \"psrlw                  $8, %%mm3   \\n\\t\" // Y0Y0 Y0Y0(12)\n\n            \"packuswb            %%mm1, %%mm0   \\n\\t\" // YYYY YYYY(0)\n\n            \"packuswb            %%mm3, %%mm2   \\n\\t\" // YYYY YYYY(8)\n\n\n\n            MOVNTQ\"              %%mm0,  (%1, %%\"REG_a\", 2) \\n\\t\"\n\n            MOVNTQ\"              %%mm2, 8(%1, %%\"REG_a\", 2) \\n\\t\"\n\n\n\n            \"add                    $8, %%\"REG_a\"   \\n\\t\"\n\n            \"cmp                    %4, %%\"REG_a\"   \\n\\t\"\n\n            \" jb                    1b          \\n\\t\"\n\n\n\n            ::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n            : \"memory\", \"%\"REG_a\n\n        );\n\n#else\n\n        long i;\n\n        for (i=0; i<chromWidth; i++) {\n\n            udst[i]     = src[4*i+0];\n\n            ydst[2*i+0] = src[4*i+1];\n\n            vdst[i]     = src[4*i+2];\n\n            ydst[2*i+1] = src[4*i+3];\n\n        }\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n\n\n        for (i=0; i<chromWidth; i++) {\n\n            ydst[2*i+0] = src[4*i+1];\n\n            ydst[2*i+1] = src[4*i+3];\n\n        }\n\n#endif\n\n        udst += chromStride;\n\n        vdst += chromStride;\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n    }\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(EMMS\"       \\n\\t\"\n\n                     SFENCE\"     \\n\\t\"\n\n                     :::\"memory\");\n\n#endif\n\n}\n", "idx": 21738, "_split": "valid", "_hash": "843b46d0398d86b54b0fc7e3368ab2fc"}
{"project": "FFmpeg", "commit_id": "cf1e0786ed64e69614760bfb4ecd7adbde8e6094", "target": 0, "func": "static int init_er(MpegEncContext *s)\n\n{\n\n    ERContext *er = &s->er;\n\n    int mb_array_size = s->mb_height * s->mb_stride;\n\n    int i;\n\n\n\n    er->avctx       = s->avctx;\n\n    er->mecc        = &s->mecc;\n\n\n\n    er->mb_index2xy = s->mb_index2xy;\n\n    er->mb_num      = s->mb_num;\n\n    er->mb_width    = s->mb_width;\n\n    er->mb_height   = s->mb_height;\n\n    er->mb_stride   = s->mb_stride;\n\n    er->b8_stride   = s->b8_stride;\n\n\n\n    er->er_temp_buffer     = av_malloc(s->mb_height * s->mb_stride);\n\n    er->error_status_table = av_mallocz(mb_array_size);\n\n    if (!er->er_temp_buffer || !er->error_status_table)\n\n        goto fail;\n\n\n\n    er->mbskip_table  = s->mbskip_table;\n\n    er->mbintra_table = s->mbintra_table;\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->dc_val); i++)\n\n        er->dc_val[i] = s->dc_val[i];\n\n\n\n    er->decode_mb = mpeg_er_decode_mb;\n\n    er->opaque    = s;\n\n\n\n    return 0;\n\nfail:\n\n    av_freep(&er->er_temp_buffer);\n\n    av_freep(&er->error_status_table);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 21760, "_split": "valid", "_hash": "ed6f7f06cbdda210e85dd033351df8ed"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int xbm_encode_close(AVCodecContext *avctx)\n\n{\n\n    av_frame_free(&avctx->coded_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 21765, "_split": "valid", "_hash": "9e8f2e1401a070a552e770998bdfe46a"}
{"project": "FFmpeg", "commit_id": "5f01beb54846de8764c15206aa63086238dde493", "target": 1, "func": "int ff_lzw_decode_init(LZWState *p, int csize, uint8_t *buf, int buf_size, int mode)\n\n{\n\n    struct LZWState *s = (struct LZWState *)p;\n\n\n\n    if(csize < 1 || csize > LZW_MAXBITS)\n\n        return -1;\n\n    /* read buffer */\n\n    s->eob_reached = 0;\n\n    s->pbuf = buf;\n\n    s->ebuf = s->pbuf + buf_size;\n\n    s->bbuf = 0;\n\n    s->bbits = 0;\n\n    s->bs = 0;\n\n\n\n    /* decoder */\n\n    s->codesize = csize;\n\n    s->cursize = s->codesize + 1;\n\n    s->curmask = mask[s->cursize];\n\n    s->top_slot = 1 << s->cursize;\n\n    s->clear_code = 1 << s->codesize;\n\n    s->end_code = s->clear_code + 1;\n\n    s->slot = s->newcodes = s->clear_code + 2;\n\n    s->oc = s->fc = 0;\n\n    s->sp = s->stack;\n\n\n\n    s->mode = mode;\n\n    switch(s->mode){\n\n    case FF_LZW_GIF:\n\n        s->extra_slot= 0;\n\n        break;\n\n    case FF_LZW_TIFF:\n\n        s->extra_slot= 1;\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 21815, "_split": "valid", "_hash": "9cfdba49e46cb954e9e5a4652bb8be9d"}
{"project": "FFmpeg", "commit_id": "7dd44cde2abb156710f26a08b6cd6c8dd9a9793d", "target": 0, "func": "static void sub2video_update(InputStream *ist, AVSubtitle *sub)\n\n{\n\n    AVFrame *frame = ist->sub2video.frame;\n\n    int8_t *dst;\n\n    int     dst_linesize;\n\n    int num_rects, i;\n\n    int64_t pts, end_pts;\n\n\n\n    if (!frame)\n\n        return;\n\n    if (sub) {\n\n        pts       = av_rescale_q(sub->pts + sub->start_display_time * 1000LL,\n\n                                 AV_TIME_BASE_Q, ist->st->time_base);\n\n        end_pts   = av_rescale_q(sub->pts + sub->end_display_time   * 1000LL,\n\n                                 AV_TIME_BASE_Q, ist->st->time_base);\n\n        num_rects = sub->num_rects;\n\n    } else {\n\n        pts       = ist->sub2video.end_pts;\n\n        end_pts   = INT64_MAX;\n\n        num_rects = 0;\n\n    }\n\n    if (sub2video_get_blank_frame(ist) < 0) {\n\n        av_log(ist->dec_ctx, AV_LOG_ERROR,\n\n               \"Impossible to get a blank canvas.\\n\");\n\n        return;\n\n    }\n\n    dst          = frame->data    [0];\n\n    dst_linesize = frame->linesize[0];\n\n    for (i = 0; i < num_rects; i++)\n\n        sub2video_copy_rect(dst, dst_linesize, frame->width, frame->height, sub->rects[i]);\n\n    sub2video_push_ref(ist, pts);\n\n    ist->sub2video.end_pts = end_pts;\n\n}\n", "idx": 21843, "_split": "valid", "_hash": "01c7fcbe89fe28717657896c918d4749"}
{"project": "FFmpeg", "commit_id": "e53c9065ca08a9153ecc73a6a8940bcc6d667e58", "target": 0, "func": "static int test_butterflies_float(AVFloatDSPContext *fdsp, AVFloatDSPContext *cdsp,\n\n                                  const float *v1, const float *v2)\n\n{\n\n    LOCAL_ALIGNED(32, float, cv1, [LEN]);\n\n    LOCAL_ALIGNED(32, float, cv2, [LEN]);\n\n    LOCAL_ALIGNED(32, float, ov1, [LEN]);\n\n    LOCAL_ALIGNED(32, float, ov2, [LEN]);\n\n    int ret;\n\n\n\n    memcpy(cv1, v1, LEN * sizeof(*v1));\n\n    memcpy(cv2, v2, LEN * sizeof(*v2));\n\n    memcpy(ov1, v1, LEN * sizeof(*v1));\n\n    memcpy(ov2, v2, LEN * sizeof(*v2));\n\n\n\n    cdsp->butterflies_float(cv1, cv2, LEN);\n\n    fdsp->butterflies_float(ov1, ov2, LEN);\n\n\n\n    if ((ret = compare_floats(cv1, ov1, LEN, FLT_EPSILON)) ||\n\n        (ret = compare_floats(cv2, ov2, LEN, FLT_EPSILON)))\n\n        av_log(NULL, AV_LOG_ERROR, \"butterflies_float failed\\n\");\n\n\n\n    return ret;\n\n}\n", "idx": 21883, "_split": "valid", "_hash": "29d796dcc8c0e2ec0fb00f06af458212"}
{"project": "FFmpeg", "commit_id": "5faf168940d6a9787552637c260b18329453bda3", "target": 0, "func": "static int64_t mpegps_read_dts(AVFormatContext *s, int stream_index,\n\n                               int64_t *ppos, int64_t pos_limit)\n\n{\n\n    int len, startcode;\n\n    int64_t pos, pts, dts;\n\n\n\n    pos = *ppos;\n\n#ifdef DEBUG_SEEK\n\n    printf(\"read_dts: pos=0x%\"PRIx64\" next=%d -> \", pos, find_next);\n\n#endif\n\n    url_fseek(s->pb, pos, SEEK_SET);\n\n    for(;;) {\n\n        len = mpegps_read_pes_header(s, &pos, &startcode, &pts, &dts);\n\n        if (len < 0) {\n\n#ifdef DEBUG_SEEK\n\n            printf(\"none (ret=%d)\\n\", len);\n\n#endif\n\n            return AV_NOPTS_VALUE;\n\n        }\n\n        if (startcode == s->streams[stream_index]->id &&\n\n            dts != AV_NOPTS_VALUE) {\n\n            break;\n\n        }\n\n        url_fskip(s->pb, len);\n\n    }\n\n#ifdef DEBUG_SEEK\n\n    printf(\"pos=0x%\"PRIx64\" dts=0x%\"PRIx64\" %0.3f\\n\", pos, dts, dts / 90000.0);\n\n#endif\n\n    *ppos = pos;\n\n    return dts;\n\n}\n", "idx": 21885, "_split": "valid", "_hash": "c794da40fa71a9225233b35084ae8275"}
{"project": "FFmpeg", "commit_id": "8ba77dfbc2e04c6d1070a8ea57f3dbbf477b95a7", "target": 1, "func": "static int libssh_open(URLContext *h, const char *url, int flags)\n\n{\n\n    static const int verbosity = SSH_LOG_NOLOG;\n\n    LIBSSHContext *s = h->priv_data;\n\n    char proto[10], path[MAX_URL_SIZE], hostname[1024], credencials[1024];\n\n    int port = 22, access, ret;\n\n    long timeout = s->rw_timeout * 1000;\n\n    const char *user = NULL, *pass = NULL;\n\n    char *end = NULL;\n\n    sftp_attributes stat;\n\n\n\n    av_url_split(proto, sizeof(proto),\n\n                 credencials, sizeof(credencials),\n\n                 hostname, sizeof(hostname),\n\n                 &port,\n\n                 path, sizeof(path),\n\n                 url);\n\n\n\n    if (port <= 0 || port > 65535)\n\n        port = 22;\n\n\n\n    if (!(s->session = ssh_new())) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    user = av_strtok(credencials, \":\", &end);\n\n    pass = av_strtok(end, \":\", &end);\n\n    ssh_options_set(s->session, SSH_OPTIONS_HOST, hostname);\n\n    ssh_options_set(s->session, SSH_OPTIONS_PORT, &port);\n\n    ssh_options_set(s->session, SSH_OPTIONS_LOG_VERBOSITY, &verbosity);\n\n    if (timeout > 0)\n\n        ssh_options_set(s->session, SSH_OPTIONS_TIMEOUT_USEC, &timeout);\n\n    if (user)\n\n        ssh_options_set(s->session, SSH_OPTIONS_USER, user);\n\n\n\n    if (ssh_connect(s->session) != SSH_OK) {\n\n        av_log(h, AV_LOG_ERROR, \"Connection failed. %s\\n\", ssh_get_error(s->session));\n\n        ret = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n\n\n    if (pass && ssh_userauth_password(s->session, NULL, pass) != SSH_AUTH_SUCCESS) {\n\n        av_log(h, AV_LOG_ERROR, \"Error authenticating with password: %s\\n\", ssh_get_error(s->session));\n\n        ret = AVERROR(EACCES);\n\n        goto fail;\n\n    }\n\n\n\n    if (!(s->sftp = sftp_new(s->session))) {\n\n        av_log(h, AV_LOG_ERROR, \"SFTP session creation failed: %s\\n\", ssh_get_error(s->session));\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    if (sftp_init(s->sftp) != SSH_OK) {\n\n        av_log(h, AV_LOG_ERROR, \"Error initializing sftp session: %s\\n\", ssh_get_error(s->session));\n\n        ret = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n\n\n    if ((flags & AVIO_FLAG_WRITE) && (flags & AVIO_FLAG_READ)) {\n\n        access = O_CREAT | O_RDWR;\n\n        if (s->trunc)\n\n            access |= O_TRUNC;\n\n    } else if (flags & AVIO_FLAG_WRITE) {\n\n        access = O_CREAT | O_WRONLY;\n\n        if (s->trunc)\n\n            access |= O_TRUNC;\n\n    } else {\n\n        access = O_RDONLY;\n\n    }\n\n\n\n    /* 0666 = -rw-rw-rw- = read+write for everyone, minus umask */\n\n    if (!(s->file = sftp_open(s->sftp, path, access, 0666))) {\n\n        av_log(h, AV_LOG_ERROR, \"Error opening sftp file: %s\\n\", ssh_get_error(s->session));\n\n        ret = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n\n\n    if (!(stat = sftp_fstat(s->file))) {\n\n        av_log(h, AV_LOG_WARNING, \"Cannot stat remote file %s.\\n\", path);\n\n        s->filesize = -1;\n\n    } else {\n\n        s->filesize = stat->size;\n\n        sftp_attributes_free(stat);\n\n    }\n\n\n\n    return 0;\n\n\n\n  fail:\n\n    libssh_close(h);\n\n    return ret;\n\n}\n", "idx": 21914, "_split": "valid", "_hash": "74a59253b1c14b4cea924661ab390818"}
{"project": "FFmpeg", "commit_id": "a5398aa56cfbf80acb409451cd807660402a34d4", "target": 1, "func": "static int hevc_init(AVCodecParserContext *s)\n\n{\n\n    HEVCContext  *h  = &((HEVCParseContext *)s->priv_data)->h;\n\n    h->HEVClc = av_mallocz(sizeof(HEVCLocalContext));\n\n\n\n    h->skipped_bytes_pos_size = INT_MAX;\n\n\n\n    return 0;\n\n}", "idx": 21948, "_split": "valid", "_hash": "cb8a67a965ff1e0b84a9ff6f20a97e0d"}
{"project": "FFmpeg", "commit_id": "ebfcf31ddf654b6e44c8cebb51bfe0ba0964b33e", "target": 1, "func": "matroska_probe (AVProbeData *p)\n\n{\n\n    uint64_t total = 0;\n\n    int len_mask = 0x80, size = 1, n = 1;\n\n    uint8_t probe_data[] = { 'm', 'a', 't', 'r', 'o', 's', 'k', 'a' };\n\n\n\n    if (p->buf_size < 5)\n\n        return 0;\n\n\n\n    /* ebml header? */\n\n    if ((p->buf[0] << 24 | p->buf[1] << 16 |\n\n         p->buf[2] << 8 | p->buf[3]) != EBML_ID_HEADER)\n\n        return 0;\n\n\n\n    /* length of header */\n\n    total = p->buf[4];\n\n    while (size <= 8 && !(total & len_mask)) {\n\n        size++;\n\n        len_mask >>= 1;\n\n    }\n\n    if (size > 8)\n\n      return 0;\n\n    total &= (len_mask - 1);\n\n    while (n < size)\n\n        total = (total << 8) | p->buf[4 + n++];\n\n\n\n    /* does the probe data contain the whole header? */\n\n    if (p->buf_size < 4 + size + total)\n\n      return 0;\n\n\n\n    /* the header must contain the document type 'matroska'. For now,\n\n     * we don't parse the whole header but simply check for the\n\n     * availability of that array of characters inside the header.\n\n     * Not fully fool-proof, but good enough. */\n\n    for (n = 4 + size; n < 4 + size + total - sizeof(probe_data); n++)\n\n        if (!memcmp (&p->buf[n], probe_data, sizeof(probe_data)))\n\n            return AVPROBE_SCORE_MAX;\n\n\n\n    return 0;\n\n}\n", "idx": 21951, "_split": "valid", "_hash": "24162b18b6b669a67b3d51614dd46ade"}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred16x16_vertical)(uint8_t *_src, int _stride){\n\n    int i;\n\n    pixel *src = (pixel*)_src;\n\n    int stride = _stride/sizeof(pixel);\n\n    const pixel4 a = ((pixel4*)(src-stride))[0];\n\n    const pixel4 b = ((pixel4*)(src-stride))[1];\n\n    const pixel4 c = ((pixel4*)(src-stride))[2];\n\n    const pixel4 d = ((pixel4*)(src-stride))[3];\n\n\n\n    for(i=0; i<16; i++){\n\n        ((pixel4*)(src+i*stride))[0] = a;\n\n        ((pixel4*)(src+i*stride))[1] = b;\n\n        ((pixel4*)(src+i*stride))[2] = c;\n\n        ((pixel4*)(src+i*stride))[3] = d;\n\n    }\n\n}\n", "idx": 21972, "_split": "valid", "_hash": "bc6f4fa35e4bdb065b5f2fc8d2585e10"}
{"project": "FFmpeg", "commit_id": "7e7e59409294af9caa63808e56c5cc824c98b4fc", "target": 0, "func": "static void rgb24_to_pal8(AVPicture *dst, AVPicture *src,\n\n                          int width, int height)\n\n{\n\n    const unsigned char *p;\n\n    unsigned char *q;\n\n    int r, g, b, dst_wrap, src_wrap;\n\n    int x, y, i;\n\n    static const uint8_t pal_value[6] = { 0x00, 0x33, 0x66, 0x99, 0xcc, 0xff };\n\n    uint32_t *pal;\n\n\n\n    p = src->data[0];\n\n    src_wrap = src->linesize[0] - 3 * width;\n\n\n\n    q = dst->data[0];\n\n    dst_wrap = dst->linesize[0] - width;\n\n\n\n    for(y=0;y<height;y++) {\n\n        for(x=0;x<width;x++) {\n\n            r = p[0];\n\n            g = p[1];\n\n            b = p[2];\n\n\n\n            q[0] = gif_clut_index(r, g, b);\n\n            q++;\n\n            p += 3;\n\n        }\n\n        p += src_wrap;\n\n        q += dst_wrap;\n\n    }\n\n\n\n    /* build palette */\n\n    pal = (uint32_t *)dst->data[1];\n\n    i = 0;\n\n    for(r = 0; r < 6; r++) {\n\n        for(g = 0; g < 6; g++) {\n\n            for(b = 0; b < 6; b++) {\n\n                pal[i++] = (0xff << 24) | (pal_value[r] << 16) | \n\n                    (pal_value[g] << 8) | pal_value[b];\n\n            }\n\n        }\n\n    }\n\n    while (i < 256)\n\n        pal[i++] = 0;\n\n}\n", "idx": 21974, "_split": "valid", "_hash": "bf6e4609533402db0bc1e84fc6824629"}
{"project": "FFmpeg", "commit_id": "8000d484b83aafa752d84fbdbfb352ffe0dc64f8", "target": 1, "func": "int ff_h264_decode_mb_cabac(const H264Context *h, H264SliceContext *sl)\n\n{\n\n    int mb_xy;\n\n    int mb_type, partition_count, cbp = 0;\n\n    int dct8x8_allowed= h->pps.transform_8x8_mode;\n\n    int decode_chroma = h->sps.chroma_format_idc == 1 || h->sps.chroma_format_idc == 2;\n\n    const int pixel_shift = h->pixel_shift;\n\n\n\n    mb_xy = sl->mb_xy = sl->mb_x + sl->mb_y*h->mb_stride;\n\n\n\n    ff_tlog(h->avctx, \"pic:%d mb:%d/%d\\n\", h->frame_num, sl->mb_x, sl->mb_y);\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        int skip;\n\n        /* a skipped mb needs the aff flag from the following mb */\n\n        if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 1 && sl->prev_mb_skipped)\n\n            skip = sl->next_mb_skipped;\n\n        else\n\n            skip = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y );\n\n        /* read skip flags */\n\n        if( skip ) {\n\n            if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 0) {\n\n                h->cur_pic.mb_type[mb_xy] = MB_TYPE_SKIP;\n\n                sl->next_mb_skipped = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y+1 );\n\n                if(!sl->next_mb_skipped)\n\n                    sl->mb_mbaff = sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n            }\n\n\n\n            decode_mb_skip(h, sl);\n\n\n\n            h->cbp_table[mb_xy] = 0;\n\n            h->chroma_pred_mode_table[mb_xy] = 0;\n\n            sl->last_qscale_diff = 0;\n\n\n\n            return 0;\n\n\n\n        }\n\n    }\n\n    if (FRAME_MBAFF(h)) {\n\n        if ((sl->mb_y & 1) == 0)\n\n            sl->mb_mbaff =\n\n            sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n    }\n\n\n\n    sl->prev_mb_skipped = 0;\n\n\n\n    fill_decode_neighbors(h, sl, -(MB_FIELD(sl)));\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        int ctx = 0;\n\n        av_assert2(sl->slice_type_nos == AV_PICTURE_TYPE_B);\n\n\n\n        if (!IS_DIRECT(sl->left_type[LTOP] - 1))\n\n            ctx++;\n\n        if (!IS_DIRECT(sl->top_type - 1))\n\n            ctx++;\n\n\n\n        if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+ctx] ) ){\n\n            mb_type= 0; /* B_Direct_16x16 */\n\n        }else if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+3] ) ) {\n\n            mb_type= 1 + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ); /* B_L[01]_16x16 */\n\n        }else{\n\n            int bits;\n\n            bits = get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+4] ) << 3;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 2;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 1;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n            if( bits < 8 ){\n\n                mb_type= bits + 3; /* B_Bi_16x16 through B_L1_L0_16x8 */\n\n            }else if( bits == 13 ){\n\n                mb_type = decode_cabac_intra_mb_type(sl, 32, 0);\n\n                goto decode_intra_mb;\n\n            }else if( bits == 14 ){\n\n                mb_type= 11; /* B_L1_L0_8x16 */\n\n            }else if( bits == 15 ){\n\n                mb_type= 22; /* B_8x8 */\n\n            }else{\n\n                bits= ( bits<<1 ) + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n                mb_type= bits - 4; /* B_L0_Bi_* through B_Bi_Bi_* */\n\n            }\n\n        }\n\n            partition_count= b_mb_type_info[mb_type].partition_count;\n\n            mb_type=         b_mb_type_info[mb_type].type;\n\n    } else if (sl->slice_type_nos == AV_PICTURE_TYPE_P) {\n\n        if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[14] ) == 0 ) {\n\n            /* P-type */\n\n            if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[15] ) == 0 ) {\n\n                /* P_L0_D16x16, P_8x8 */\n\n                mb_type= 3 * get_cabac_noinline( &sl->cabac, &sl->cabac_state[16] );\n\n            } else {\n\n                /* P_L0_D8x16, P_L0_D16x8 */\n\n                mb_type= 2 - get_cabac_noinline( &sl->cabac, &sl->cabac_state[17] );\n\n            }\n\n            partition_count= p_mb_type_info[mb_type].partition_count;\n\n            mb_type=         p_mb_type_info[mb_type].type;\n\n        } else {\n\n            mb_type = decode_cabac_intra_mb_type(sl, 17, 0);\n\n            goto decode_intra_mb;\n\n        }\n\n    } else {\n\n        mb_type = decode_cabac_intra_mb_type(sl, 3, 1);\n\n        if (sl->slice_type == AV_PICTURE_TYPE_SI && mb_type)\n\n            mb_type--;\n\n        av_assert2(sl->slice_type_nos == AV_PICTURE_TYPE_I);\n\ndecode_intra_mb:\n\n        partition_count = 0;\n\n        cbp= i_mb_type_info[mb_type].cbp;\n\n        sl->intra16x16_pred_mode = i_mb_type_info[mb_type].pred_mode;\n\n        mb_type= i_mb_type_info[mb_type].type;\n\n    }\n\n    if (MB_FIELD(sl))\n\n        mb_type |= MB_TYPE_INTERLACED;\n\n\n\n    h->slice_table[mb_xy] = sl->slice_num;\n\n\n\n    if(IS_INTRA_PCM(mb_type)) {\n\n        const int mb_size = ff_h264_mb_sizes[h->sps.chroma_format_idc] *\n\n                            h->sps.bit_depth_luma >> 3;\n\n        const uint8_t *ptr;\n\n\n\n        // We assume these blocks are very rare so we do not optimize it.\n\n        // FIXME The two following lines get the bitstream position in the cabac\n\n        // decode, I think it should be done by a function in cabac.h (or cabac.c).\n\n        ptr= sl->cabac.bytestream;\n\n        if(sl->cabac.low&0x1) ptr--;\n\n        if(CABAC_BITS==16){\n\n            if(sl->cabac.low&0x1FF) ptr--;\n\n        }\n\n\n\n        // The pixels are stored in the same order as levels in h->mb array.\n\n        if ((int) (sl->cabac.bytestream_end - ptr) < mb_size)\n\n            return -1;\n\n        sl->intra_pcm_ptr = ptr;\n\n        ptr += mb_size;\n\n\n\n        ff_init_cabac_decoder(&sl->cabac, ptr, sl->cabac.bytestream_end - ptr);\n\n\n\n        // All blocks are present\n\n        h->cbp_table[mb_xy] = 0xf7ef;\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        // In deblocking, the quantizer is 0\n\n        h->cur_pic.qscale_table[mb_xy] = 0;\n\n        // All coeffs are present\n\n        memset(h->non_zero_count[mb_xy], 16, 48);\n\n        h->cur_pic.mb_type[mb_xy] = mb_type;\n\n        sl->last_qscale_diff = 0;\n\n        return 0;\n\n    }\n\n\n\n    fill_decode_caches(h, sl, mb_type);\n\n\n\n    if( IS_INTRA( mb_type ) ) {\n\n        int i, pred_mode;\n\n        if( IS_INTRA4x4( mb_type ) ) {\n\n            if (dct8x8_allowed && get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size])) {\n\n                mb_type |= MB_TYPE_8x8DCT;\n\n                for( i = 0; i < 16; i+=4 ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    int mode = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n                    fill_rectangle(&sl->intra4x4_pred_mode_cache[scan8[i]], 2, 2, 8, mode, 1);\n\n                }\n\n            } else {\n\n                for( i = 0; i < 16; i++ ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    sl->intra4x4_pred_mode_cache[scan8[i]] = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n\n\n                    ff_tlog(h->avctx, \"i4x4 pred=%d mode=%d\\n\", pred,\n\n                            sl->intra4x4_pred_mode_cache[scan8[i]]);\n\n                }\n\n            }\n\n            write_back_intra_pred_mode(h, sl);\n\n            if (ff_h264_check_intra4x4_pred_mode(h, sl) < 0 ) return -1;\n\n        } else {\n\n            sl->intra16x16_pred_mode = ff_h264_check_intra_pred_mode(h, sl, sl->intra16x16_pred_mode, 0);\n\n            if (sl->intra16x16_pred_mode < 0) return -1;\n\n        }\n\n        if(decode_chroma){\n\n            h->chroma_pred_mode_table[mb_xy] =\n\n            pred_mode                        = decode_cabac_mb_chroma_pre_mode(h, sl);\n\n\n\n            pred_mode= ff_h264_check_intra_pred_mode(h, sl, pred_mode, 1 );\n\n            if( pred_mode < 0 ) return -1;\n\n            sl->chroma_pred_mode = pred_mode;\n\n        } else {\n\n            sl->chroma_pred_mode = DC_128_PRED8x8;\n\n        }\n\n    } else if( partition_count == 4 ) {\n\n        int i, j, sub_partition_count[4], list, ref[2][4];\n\n\n\n        if (sl->slice_type_nos == AV_PICTURE_TYPE_B ) {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_b_mb_sub_type(sl);\n\n                sub_partition_count[i] = b_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = b_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n            if (IS_DIRECT(sl->sub_mb_type[0] | sl->sub_mb_type[1] |\n\n                          sl->sub_mb_type[2] | sl->sub_mb_type[3])) {\n\n                ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n                sl->ref_cache[0][scan8[4]] =\n\n                sl->ref_cache[1][scan8[4]] =\n\n                sl->ref_cache[0][scan8[12]] =\n\n                sl->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;\n\n                    for( i = 0; i < 4; i++ )\n\n                        fill_rectangle(&sl->direct_cache[scan8[4*i]], 2, 2, 8, (sl->sub_mb_type[i] >> 1) & 0xFF, 1);\n\n            }\n\n        } else {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_p_mb_sub_type(sl);\n\n                sub_partition_count[i] = p_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = p_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n        }\n\n\n\n        for( list = 0; list < sl->list_count; list++ ) {\n\n                for( i = 0; i < 4; i++ ) {\n\n                    if(IS_DIRECT(sl->sub_mb_type[i])) continue;\n\n                    if(IS_DIR(sl->sub_mb_type[i], 0, list)){\n\n                        unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                        if (rc > 1) {\n\n                            ref[list][i] = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                            if (ref[list][i] >= rc) {\n\n                                av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref[list][i], rc);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            ref[list][i] = 0;\n\n                    } else {\n\n                        ref[list][i] = -1;\n\n                    }\n\n                    sl->ref_cache[list][scan8[4 * i] + 1] =\n\n                    sl->ref_cache[list][scan8[4 * i] + 8] = sl->ref_cache[list][scan8[4 * i] + 9] = ref[list][i];\n\n                }\n\n        }\n\n\n\n        if(dct8x8_allowed)\n\n            dct8x8_allowed = get_dct8x8_allowed(h, sl);\n\n\n\n        for (list = 0; list < sl->list_count; list++) {\n\n            for(i=0; i<4; i++){\n\n                sl->ref_cache[list][scan8[4 * i]] = sl->ref_cache[list][scan8[4 * i] + 1];\n\n                if(IS_DIRECT(sl->sub_mb_type[i])){\n\n                    fill_rectangle(sl->mvd_cache[list][scan8[4*i]], 2, 2, 8, 0, 2);\n\n                    continue;\n\n                }\n\n\n\n                if(IS_DIR(sl->sub_mb_type[i], 0, list) && !IS_DIRECT(sl->sub_mb_type[i])){\n\n                    const int sub_mb_type= sl->sub_mb_type[i];\n\n                    const int block_width= (sub_mb_type & (MB_TYPE_16x16|MB_TYPE_16x8)) ? 2 : 1;\n\n                    for(j=0; j<sub_partition_count[i]; j++){\n\n                        int mpx, mpy;\n\n                        int mx, my;\n\n                        const int index= 4*i + block_width*j;\n\n                        int16_t (* mv_cache)[2] = &sl->mv_cache[list][ scan8[index] ];\n\n                        uint8_t (* mvd_cache)[2]= &sl->mvd_cache[list][ scan8[index] ];\n\n                        pred_motion(h, sl, index, block_width, list, sl->ref_cache[list][ scan8[index] ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, index)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        if(IS_SUB_8X8(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]=\n\n                            mv_cache[ 8 ][0]= mv_cache[ 9 ][0]= mx;\n\n                            mv_cache[ 1 ][1]=\n\n                            mv_cache[ 8 ][1]= mv_cache[ 9 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=\n\n                            mvd_cache[ 8 ][0]= mvd_cache[ 9 ][0]= mpx;\n\n                            mvd_cache[ 1 ][1]=\n\n                            mvd_cache[ 8 ][1]= mvd_cache[ 9 ][1]= mpy;\n\n                        }else if(IS_SUB_8X4(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]= mx;\n\n                            mv_cache[ 1 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=  mpx;\n\n                            mvd_cache[ 1 ][1]= mpy;\n\n                        }else if(IS_SUB_4X8(sub_mb_type)){\n\n                            mv_cache[ 8 ][0]= mx;\n\n                            mv_cache[ 8 ][1]= my;\n\n\n\n                            mvd_cache[ 8 ][0]= mpx;\n\n                            mvd_cache[ 8 ][1]= mpy;\n\n                        }\n\n                        mv_cache[ 0 ][0]= mx;\n\n                        mv_cache[ 0 ][1]= my;\n\n\n\n                        mvd_cache[ 0 ][0]= mpx;\n\n                        mvd_cache[ 0 ][1]= mpy;\n\n                    }\n\n                }else{\n\n                    fill_rectangle(sl->mv_cache [list][ scan8[4*i] ], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[4*i] ], 2, 2, 8, 0, 2);\n\n                }\n\n            }\n\n        }\n\n    } else if( IS_DIRECT(mb_type) ) {\n\n        ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n        fill_rectangle(sl->mvd_cache[0][scan8[0]], 4, 4, 8, 0, 2);\n\n        fill_rectangle(sl->mvd_cache[1][scan8[0]], 4, 4, 8, 0, 2);\n\n        dct8x8_allowed &= h->sps.direct_8x8_inference_flag;\n\n    } else {\n\n        int list, i;\n\n        if(IS_16X16(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int ref;\n\n                    unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                    if (rc > 1) {\n\n                        ref= decode_cabac_mb_ref(sl, list, 0);\n\n                        if (ref >= rc) {\n\n                            av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                            return -1;\n\n                        }\n\n                    }else\n\n                        ref=0;\n\n                    fill_rectangle(&sl->ref_cache[list][ scan8[0] ], 4, 4, 8, ref, 1);\n\n                }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int mx,my,mpx,mpy;\n\n                    pred_motion(h, sl, 0, 4, list, sl->ref_cache[list][ scan8[0] ], &mx, &my);\n\n                    DECODE_CABAC_MB_MVD(sl, list, 0)\n\n                    ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[0] ], 4, 4, 8, pack8to16(mpx,mpy), 2);\n\n                    fill_rectangle(sl->mv_cache[list][ scan8[0] ], 4, 4, 8, pack16to32(mx,my), 4);\n\n                }\n\n            }\n\n        }\n\n        else if(IS_16X8(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){\n\n                            int ref;\n\n                            unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref= decode_cabac_mb_ref(sl, list, 8 * i);\n\n                                if (ref >= rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_16x8_motion(h, sl, 8*i, list, sl->ref_cache[list][scan8[0] + 16*i], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 8*i)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            av_assert2(IS_8X16(mb_type));\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){ //FIXME optimize\n\n                            int ref;\n\n                            unsigned rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                                if (ref >= rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_8x16_motion(h, sl, i*4, list, sl->ref_cache[list][ scan8[0] + 2*i ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 4*i)\n\n\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n   if( IS_INTER( mb_type ) ) {\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        write_back_motion(h, sl, mb_type);\n\n   }\n\n\n\n    if( !IS_INTRA16x16( mb_type ) ) {\n\n        cbp  = decode_cabac_mb_cbp_luma(sl);\n\n        if(decode_chroma)\n\n            cbp |= decode_cabac_mb_cbp_chroma(sl) << 4;\n\n    } else {\n\n        if (!decode_chroma && cbp>15) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"gray chroma\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    h->cbp_table[mb_xy] = sl->cbp = cbp;\n\n\n\n    if( dct8x8_allowed && (cbp&15) && !IS_INTRA( mb_type ) ) {\n\n        mb_type |= MB_TYPE_8x8DCT * get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size]);\n\n    }\n\n\n\n    /* It would be better to do this in fill_decode_caches, but we don't know\n\n     * the transform mode of the current macroblock there. */\n\n    if (CHROMA444(h) && IS_8x8DCT(mb_type)){\n\n        int i;\n\n        uint8_t *nnz_cache = sl->non_zero_count_cache;\n\n        for (i = 0; i < 2; i++){\n\n            if (sl->left_type[LEFT(i)] && !IS_8x8DCT(sl->left_type[LEFT(i)])) {\n\n                nnz_cache[3+8* 1 + 2*8*i]=\n\n                nnz_cache[3+8* 2 + 2*8*i]=\n\n                nnz_cache[3+8* 6 + 2*8*i]=\n\n                nnz_cache[3+8* 7 + 2*8*i]=\n\n                nnz_cache[3+8*11 + 2*8*i]=\n\n                nnz_cache[3+8*12 + 2*8*i]= IS_INTRA(mb_type) ? 64 : 0;\n\n            }\n\n        }\n\n        if (sl->top_type && !IS_8x8DCT(sl->top_type)){\n\n            uint32_t top_empty = CABAC(h) && !IS_INTRA(mb_type) ? 0 : 0x40404040;\n\n            AV_WN32A(&nnz_cache[4+8* 0], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8* 5], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8*10], top_empty);\n\n        }\n\n    }\n\n    h->cur_pic.mb_type[mb_xy] = mb_type;\n\n\n\n    if( cbp || IS_INTRA16x16( mb_type ) ) {\n\n        const uint8_t *scan, *scan8x8;\n\n        const uint32_t *qmul;\n\n\n\n        if(IS_INTERLACED(mb_type)){\n\n            scan8x8 = sl->qscale ? h->field_scan8x8 : h->field_scan8x8_q0;\n\n            scan    = sl->qscale ? h->field_scan : h->field_scan_q0;\n\n        }else{\n\n            scan8x8 = sl->qscale ? h->zigzag_scan8x8 : h->zigzag_scan8x8_q0;\n\n            scan    = sl->qscale ? h->zigzag_scan : h->zigzag_scan_q0;\n\n        }\n\n\n\n        // decode_cabac_mb_dqp\n\n        if(get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + (sl->last_qscale_diff != 0)])){\n\n            int val = 1;\n\n            int ctx= 2;\n\n            const int max_qp = 51 + 6*(h->sps.bit_depth_luma-8);\n\n\n\n            while( get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + ctx] ) ) {\n\n                ctx= 3;\n\n                val++;\n\n                if(val > 2*max_qp){ //prevent infinite loop\n\n                    av_log(h->avctx, AV_LOG_ERROR, \"cabac decode of qscale diff failed at %d %d\\n\", sl->mb_x, sl->mb_y);\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            if( val&0x01 )\n\n                val=   (val + 1)>>1 ;\n\n            else\n\n                val= -((val + 1)>>1);\n\n            sl->last_qscale_diff = val;\n\n            sl->qscale += val;\n\n            if (((unsigned)sl->qscale) > max_qp){\n\n                if (sl->qscale < 0) sl->qscale += max_qp + 1;\n\n                else                sl->qscale -= max_qp + 1;\n\n            }\n\n            sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n            sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n        }else\n\n            sl->last_qscale_diff=0;\n\n\n\n        decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 0);\n\n        if (CHROMA444(h)) {\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 1);\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 2);\n\n        } else if (CHROMA422(h)) {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc_422(h, sl, sl->mb + ((256 + 16*16*c) << pixel_shift), 3,\n\n                                                 CHROMA_DC_BLOCK_INDEX + c,\n\n                                                 chroma422_dc_scan, 8);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i, i8x8;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    int16_t *mb = sl->mb + (16*(16 + 16*c) << pixel_shift);\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for (i8x8 = 0; i8x8 < 2; i8x8++) {\n\n                        for (i = 0; i < 4; i++) {\n\n                            const int index = 16 + 16 * c + 8*i8x8 + i;\n\n                            decode_cabac_residual_nondc(h, sl, mb, 4, index, scan + 1, qmul, 15);\n\n                            mb += 16<<pixel_shift;\n\n                        }\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        } else /* yuv420 */ {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc(h, sl, sl->mb + ((256 + 16*16*c) << pixel_shift), 3, CHROMA_DC_BLOCK_INDEX+c, chroma_dc_scan, 4);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for( i = 0; i < 4; i++ ) {\n\n                        const int index = 16 + 16 * c + i;\n\n                        decode_cabac_residual_nondc(h, sl, sl->mb + (16*index << pixel_shift), 4, index, scan + 1, qmul, 15);\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        }\n\n    } else {\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[ 0]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n        sl->last_qscale_diff = 0;\n\n    }\n\n\n\n    h->cur_pic.qscale_table[mb_xy] = sl->qscale;\n\n    write_back_non_zero_count(h, sl);\n\n\n\n    return 0;\n\n}\n", "idx": 22028, "_split": "valid", "_hash": "be9f1f9d1bb151dfb332d0f5fae38cb9"}
{"project": "FFmpeg", "commit_id": "6ea7dd25c773145b50eed55c2059647bb086aaca", "target": 1, "func": "static int swf_write_header(AVFormatContext *s)\n\n{\n\n    SWFContext *swf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    PutBitContext p;\n\n    uint8_t buf1[256];\n\n    int i, width, height, rate, rate_base;\n\n    int version;\n\n\n\n    swf->sound_samples = 0;\n\n    swf->swf_frame_number = 0;\n\n    swf->video_frame_number = 0;\n\n\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        AVCodecContext *enc = s->streams[i]->codec;\n\n        if (enc->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (swf->audio_enc) {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports 1 audio stream\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n\n            if (enc->codec_id == AV_CODEC_ID_MP3) {\n\n                if (!enc->frame_size) {\n\n                    av_log(s, AV_LOG_ERROR, \"audio frame size not set\\n\");\n\n                    return -1;\n\n\n                swf->audio_enc = enc;\n\n                swf->audio_fifo= av_fifo_alloc(AUDIO_FIFO_SIZE);\n\n                if (!swf->audio_fifo)\n\n                    return AVERROR(ENOMEM);\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports MP3\\n\");\n\n                return -1;\n\n\n        } else {\n\n            if (swf->video_enc) {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports 1 video stream\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n\n            if (enc->codec_id == AV_CODEC_ID_VP6F ||\n\n                enc->codec_id == AV_CODEC_ID_FLV1 ||\n\n                enc->codec_id == AV_CODEC_ID_MJPEG) {\n\n                swf->video_st  = s->streams[i];\n\n                swf->video_enc = enc;\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"SWF muxer only supports VP6, FLV1 and MJPEG\\n\");\n\n                return -1;\n\n\n\n\n\n\n    if (!swf->video_enc) {\n\n        /* currently, cannot work correctly if audio only */\n\n        width = 320;\n\n        height = 200;\n\n        rate = 10;\n\n        rate_base= 1;\n\n    } else {\n\n        width = swf->video_enc->width;\n\n        height = swf->video_enc->height;\n\n        // TODO: should be avg_frame_rate\n\n        rate = swf->video_st->time_base.den;\n\n        rate_base = swf->video_st->time_base.num;\n\n\n\n\n    if (!swf->audio_enc)\n\n        swf->samples_per_frame = (44100LL * rate_base) / rate;\n\n    else\n\n        swf->samples_per_frame = (swf->audio_enc->sample_rate * rate_base) / rate;\n\n\n\n    avio_write(pb, \"FWS\", 3);\n\n\n\n    if (!strcmp(\"avm2\", s->oformat->name))\n\n        version = 9;\n\n    else if (swf->video_enc && swf->video_enc->codec_id == AV_CODEC_ID_VP6F)\n\n        version = 8; /* version 8 and above support VP6 codec */\n\n    else if (swf->video_enc && swf->video_enc->codec_id == AV_CODEC_ID_FLV1)\n\n        version = 6; /* version 6 and above support FLV1 codec */\n\n    else\n\n        version = 4; /* version 4 for mpeg audio support */\n\n    avio_w8(pb, version);\n\n\n\n    avio_wl32(pb, DUMMY_FILE_SIZE); /* dummy size\n\n                                      (will be patched if not streamed) */\n\n\n\n    put_swf_rect(pb, 0, width * 20, 0, height * 20);\n\n\n\n\n\n    avio_wl16(pb, (rate * 256) / rate_base); /* frame rate */\n\n    swf->duration_pos = avio_tell(pb);\n\n    avio_wl16(pb, (uint16_t)(DUMMY_DURATION * (int64_t)rate / rate_base)); /* frame count */\n\n\n\n    /* avm2/swf v9 (also v8?) files require a file attribute tag */\n\n    if (version == 9) {\n\n        put_swf_tag(s, TAG_FILEATTRIBUTES);\n\n        avio_wl32(pb, 1<<3); /* set ActionScript v3/AVM2 flag */\n\n        put_swf_end_tag(s);\n\n\n\n\n    /* define a shape with the jpeg inside */\n\n    if (swf->video_enc && swf->video_enc->codec_id == AV_CODEC_ID_MJPEG) {\n\n        put_swf_tag(s, TAG_DEFINESHAPE);\n\n\n\n        avio_wl16(pb, SHAPE_ID); /* ID of shape */\n\n        /* bounding rectangle */\n\n        put_swf_rect(pb, 0, width, 0, height);\n\n        /* style info */\n\n        avio_w8(pb, 1); /* one fill style */\n\n        avio_w8(pb, 0x41); /* clipped bitmap fill */\n\n        avio_wl16(pb, BITMAP_ID); /* bitmap ID */\n\n        /* position of the bitmap */\n\n        put_swf_matrix(pb, 1 << FRAC_BITS, 0,\n\n                       0,  1 << FRAC_BITS, 0, 0);\n\n        avio_w8(pb, 0); /* no line style */\n\n\n\n        /* shape drawing */\n\n        init_put_bits(&p, buf1, sizeof(buf1));\n\n        put_bits(&p, 4, 1); /* one fill bit */\n\n        put_bits(&p, 4, 0); /* zero line bit */\n\n\n\n        put_bits(&p, 1, 0); /* not an edge */\n\n        put_bits(&p, 5, FLAG_MOVETO | FLAG_SETFILL0);\n\n        put_bits(&p, 5, 1); /* nbits */\n\n        put_bits(&p, 1, 0); /* X */\n\n        put_bits(&p, 1, 0); /* Y */\n\n        put_bits(&p, 1, 1); /* set fill style 1 */\n\n\n\n        /* draw the rectangle ! */\n\n        put_swf_line_edge(&p, width, 0);\n\n        put_swf_line_edge(&p, 0, height);\n\n        put_swf_line_edge(&p, -width, 0);\n\n        put_swf_line_edge(&p, 0, -height);\n\n\n\n        /* end of shape */\n\n        put_bits(&p, 1, 0); /* not an edge */\n\n        put_bits(&p, 5, 0);\n\n\n\n        flush_put_bits(&p);\n\n        avio_write(pb, buf1, put_bits_ptr(&p) - p.buf);\n\n\n\n        put_swf_end_tag(s);\n\n\n\n\n    if (swf->audio_enc && swf->audio_enc->codec_id == AV_CODEC_ID_MP3) {\n\n        int v = 0;\n\n\n\n        /* start sound */\n\n        put_swf_tag(s, TAG_STREAMHEAD2);\n\n        switch(swf->audio_enc->sample_rate) {\n\n        case 11025: v |= 1 << 2; break;\n\n        case 22050: v |= 2 << 2; break;\n\n        case 44100: v |= 3 << 2; break;\n\n        default:\n\n            /* not supported */\n\n            av_log(s, AV_LOG_ERROR, \"swf does not support that sample rate, choose from (44100, 22050, 11025).\\n\");\n\n            return -1;\n\n\n        v |= 0x02; /* 16 bit playback */\n\n        if (swf->audio_enc->channels == 2)\n\n            v |= 0x01; /* stereo playback */\n\n        avio_w8(s->pb, v);\n\n        v |= 0x20; /* mp3 compressed */\n\n        avio_w8(s->pb, v);\n\n        avio_wl16(s->pb, swf->samples_per_frame);  /* avg samples per frame */\n\n        avio_wl16(s->pb, 0);\n\n\n\n        put_swf_end_tag(s);\n\n\n\n\n    avio_flush(s->pb);\n\n    return 0;\n", "idx": 22031, "_split": "valid", "_hash": "bb422a6b2bf64d67b50bdb4696faf529"}
{"project": "FFmpeg", "commit_id": "23edd41a0d6994cb5d9983d8f035e8eef78960ad", "target": 1, "func": "static void decode(AVCodecContext *dec_ctx, AVFrame *frame, AVPacket *pkt,\n\n                   const char *filename)\n\n{\n\n    char buf[1024];\n\n    int ret;\n\n\n\n    ret = avcodec_send_packet(dec_ctx, pkt);\n\n    if (ret < 0) {\n\n        fprintf(stderr, \"Error sending a packet for decoding\\n\");\n\n        exit(1);\n\n    }\n\n\n\n    while (ret >= 0) {\n\n        ret = avcodec_receive_frame(dec_ctx, frame);\n\n        if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)\n\n            return;\n\n        else if (ret < 0) {\n\n            fprintf(stderr, \"Error during decoding\\n\");\n\n            exit(1);\n\n        }\n\n\n\n        printf(\"saving frame %3d\\n\", dec_ctx->frame_number);\n\n        fflush(stdout);\n\n\n\n        /* the picture is allocated by the decoder. no need to\n\n           free it */\n\n        snprintf(buf, sizeof(buf), filename, dec_ctx->frame_number);\n\n        pgm_save(frame->data[0], frame->linesize[0],\n\n                 frame->width, frame->height, buf);\n\n    }\n\n}\n", "idx": 22043, "_split": "valid", "_hash": "e67338ba0499c7353496cdd47034cda4"}
{"project": "FFmpeg", "commit_id": "452ac2aaecf7210a2912d9156869c6314142a794", "target": 0, "func": "static void ripemd128_transform(uint32_t *state, const uint8_t buffer[64], int ext)\n\n{\n\n    uint32_t a, b, c, d, e, f, g, h;\n\n    uint32_t block[16];\n\n    int n;\n\n\n\n    if (ext) {\n\n        a = state[0]; b = state[1]; c = state[2]; d = state[3];\n\n        e = state[4]; f = state[5]; g = state[6]; h = state[7];\n\n    } else {\n\n        a = e = state[0];\n\n        b = f = state[1];\n\n        c = g = state[2];\n\n        d = h = state[3];\n\n    }\n\n\n\n    for (n = 0; n < 16; n++)\n\n        block[n] = AV_RL32(buffer + 4 * n);\n\n\n\n    for (n = 0; n < 16;) {\n\n        ROUND128_0_TO_15(a,b,c,d,e,f,g,h);\n\n        ROUND128_0_TO_15(d,a,b,c,h,e,f,g);\n\n        ROUND128_0_TO_15(c,d,a,b,g,h,e,f);\n\n        ROUND128_0_TO_15(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(a,e)\n\n\n\n    for (; n < 32;) {\n\n        ROUND128_16_TO_31(a,b,c,d,e,f,g,h);\n\n        ROUND128_16_TO_31(d,a,b,c,h,e,f,g);\n\n        ROUND128_16_TO_31(c,d,a,b,g,h,e,f);\n\n        ROUND128_16_TO_31(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(b,f)\n\n\n\n    for (; n < 48;) {\n\n        ROUND128_32_TO_47(a,b,c,d,e,f,g,h);\n\n        ROUND128_32_TO_47(d,a,b,c,h,e,f,g);\n\n        ROUND128_32_TO_47(c,d,a,b,g,h,e,f);\n\n        ROUND128_32_TO_47(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(c,g)\n\n\n\n    for (; n < 64;) {\n\n        ROUND128_48_TO_63(a,b,c,d,e,f,g,h);\n\n        ROUND128_48_TO_63(d,a,b,c,h,e,f,g);\n\n        ROUND128_48_TO_63(c,d,a,b,g,h,e,f);\n\n        ROUND128_48_TO_63(b,c,d,a,f,g,h,e);\n\n    }\n\n    SWAP(d,h)\n\n\n\n    if (ext) {\n\n        state[0] += a; state[1] += b; state[2] += c; state[3] += d;\n\n        state[4] += e; state[5] += f; state[6] += g; state[7] += h;\n\n    } else {\n\n        h += c + state[1];\n\n        state[1] = state[2] + d + e;\n\n        state[2] = state[3] + a + f;\n\n        state[3] = state[0] + b + g;\n\n        state[0] = h;\n\n    }\n\n}\n", "idx": 22049, "_split": "valid", "_hash": "55b6658b5510134c3fe8a1d2325b5fcb"}
{"project": "FFmpeg", "commit_id": "d1cacdb8dda4eb2a5532267b0aeb1d2afdf95f05", "target": 0, "func": "static av_cold int a64multi_init_encoder(AVCodecContext *avctx)\n\n{\n\n    A64Context *c = avctx->priv_data;\n\n    int a;\n\n    av_lfg_init(&c->randctx, 1);\n\n\n\n    if (avctx->global_quality < 1) {\n\n        c->mc_lifetime = 4;\n\n    } else {\n\n        c->mc_lifetime = avctx->global_quality /= FF_QP2LAMBDA;\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_INFO, \"charset lifetime set to %d frame(s)\\n\", c->mc_lifetime);\n\n\n\n    /* precalc luma values for later use */\n\n    for (a = 0; a < 5; a++) {\n\n        c->mc_luma_vals[a]=a64_palette[mc_colors[a]][0] * 0.30 +\n\n                           a64_palette[mc_colors[a]][1] * 0.59 +\n\n                           a64_palette[mc_colors[a]][2] * 0.11;\n\n    }\n\n\n\n    c->mc_frame_counter = 0;\n\n    c->mc_use_5col      = avctx->codec->id == CODEC_ID_A64_MULTI5;\n\n    c->mc_meta_charset  = av_malloc (32000 * c->mc_lifetime * sizeof(int));\n\n    c->mc_best_cb       = av_malloc (CHARSET_CHARS * 32 * sizeof(int));\n\n    c->mc_charmap       = av_mallocz(1000 * c->mc_lifetime * sizeof(int));\n\n    c->mc_colram        = av_mallocz(CHARSET_CHARS * sizeof(uint8_t));\n\n    c->mc_charset       = av_malloc (0x800 * (INTERLACED+1) * sizeof(uint8_t));\n\n\n\n    /* set up extradata */\n\n    avctx->extradata      = av_mallocz(8 * 4 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    avctx->extradata_size = 8 * 4;\n\n    AV_WB32(avctx->extradata, c->mc_lifetime);\n\n    AV_WB32(avctx->extradata+16, INTERLACED);\n\n\n\n    avcodec_get_frame_defaults(&c->picture);\n\n    avctx->coded_frame            = &c->picture;\n\n    avctx->coded_frame->pict_type = FF_I_TYPE;\n\n    avctx->coded_frame->key_frame = 1;\n\n    if (!avctx->codec_tag)\n\n         avctx->codec_tag = AV_RL32(\"a64m\");\n\n\n\n    return 0;\n\n}\n", "idx": 22091, "_split": "valid", "_hash": "fd44a6e8200e34c3d863ba90c3417471"}
{"project": "FFmpeg", "commit_id": "1c37848f9029985d1271da9a0d161c2ebf0aca81", "target": 1, "func": "static int webm_dash_manifest_write_header(AVFormatContext *s)\n\n{\n\n    int i;\n\n    double start = 0.0;\n\n    WebMDashMuxContext *w = s->priv_data;\n\n    parse_adaptation_sets(s);\n\n    write_header(s);\n\n    avio_printf(s->pb, \"<Period id=\\\"0\\\"\");\n\n    avio_printf(s->pb, \" start=\\\"PT%gS\\\"\", start);\n\n    if (!w->is_live) {\n\n        avio_printf(s->pb, \" duration=\\\"PT%gS\\\"\", get_duration(s));\n\n    }\n\n    avio_printf(s->pb, \" >\\n\");\n\n\n\n    for (i = 0; i < w->nb_as; i++) {\n\n        if (write_adaptation_set(s, i) < 0) return -1;\n\n    }\n\n\n\n    avio_printf(s->pb, \"</Period>\\n\");\n\n    write_footer(s);\n\n    return 0;\n\n}\n", "idx": 22124, "_split": "valid", "_hash": "318bbeda2abd815cea440e5b058d9e52"}
{"project": "FFmpeg", "commit_id": "a29a0aba79dad35a80cfcdf6db6b506afb48dcaa", "target": 1, "func": "static int analyze_chunk(AVFormatContext *s, const uint8_t *chunk)\n{\n    TYDemuxContext *ty = s->priv_data;\n    int num_recs, i;\n    TyRecHdr *hdrs;\n    int num_6e0, num_be0, num_9c0, num_3c0;\n    /* skip if it's a Part header */\n    if (AV_RB32(&chunk[0]) == TIVO_PES_FILEID)\n        return 0;\n    /* number of records in chunk (we ignore high order byte;\n     * rarely are there > 256 chunks & we don't need that many anyway) */\n    num_recs = chunk[0];\n    if (num_recs < 5) {\n        /* try again with the next chunk.  Sometimes there are dead ones */\n        return 0;\n    }\n    chunk += 4;       /* skip past rec count & SEQ bytes */\n    ff_dlog(s, \"probe: chunk has %d recs\\n\", num_recs);\n    hdrs = parse_chunk_headers(chunk, num_recs);\n    if (!hdrs)\n        return AVERROR(ENOMEM);\n    /* scan headers.\n     * 1. check video packets.  Presence of 0x6e0 means S1.\n     *    No 6e0 but have be0 means S2.\n     * 2. probe for audio 0x9c0 vs 0x3c0 (AC3 vs Mpeg)\n     *    If AC-3, then we have DTivo.\n     *    If MPEG, search for PTS offset.  This will determine SA vs. DTivo.\n     */\n    num_6e0 = num_be0 = num_9c0 = num_3c0 = 0;\n    for (i = 0; i < num_recs; i++) {\n        switch (hdrs[i].subrec_type << 8 | hdrs[i].rec_type) {\n        case 0x6e0:\n            num_6e0++;\n        case 0xbe0:\n            num_be0++;\n        case 0x3c0:\n            num_3c0++;\n        case 0x9c0:\n            num_9c0++;\n        }\n    }\n    ff_dlog(s, \"probe: chunk has %d 0x6e0 recs, %d 0xbe0 recs.\\n\",\n            num_6e0, num_be0);\n    /* set up our variables */\n    if (num_6e0 > 0) {\n        ff_dlog(s, \"detected Series 1 Tivo\\n\");\n        ty->tivo_series = TIVO_SERIES1;\n        ty->pes_length = SERIES1_PES_LENGTH;\n    } else if (num_be0 > 0) {\n        ff_dlog(s, \"detected Series 2 Tivo\\n\");\n        ty->tivo_series = TIVO_SERIES2;\n        ty->pes_length = SERIES2_PES_LENGTH;\n    }\n    if (num_9c0 > 0) {\n        ff_dlog(s, \"detected AC-3 Audio (DTivo)\\n\");\n        ty->audio_type = TIVO_AUDIO_AC3;\n        ty->tivo_type = TIVO_TYPE_DTIVO;\n        ty->pts_offset = AC3_PTS_OFFSET;\n        ty->pes_length = AC3_PES_LENGTH;\n    } else if (num_3c0 > 0) {\n        ty->audio_type = TIVO_AUDIO_MPEG;\n        ff_dlog(s, \"detected MPEG Audio\\n\");\n    }\n    /* if tivo_type still unknown, we can check PTS location\n     * in MPEG packets to determine tivo_type */\n    if (ty->tivo_type == TIVO_TYPE_UNKNOWN) {\n        uint32_t data_offset = 16 * num_recs;\n        for (i = 0; i < num_recs; i++) {\n            if ((hdrs[i].subrec_type << 0x08 | hdrs[i].rec_type) == 0x3c0 && hdrs[i].rec_size > 15) {\n                /* first make sure we're aligned */\n                int pes_offset = find_es_header(ty_MPEGAudioPacket,\n                        &chunk[data_offset], 5);\n                if (pes_offset >= 0) {\n                    /* pes found. on SA, PES has hdr data at offset 6, not PTS. */\n                    if ((chunk[data_offset + 6 + pes_offset] & 0x80) == 0x80) {\n                        /* S1SA or S2(any) Mpeg Audio (PES hdr, not a PTS start) */\n                        if (ty->tivo_series == TIVO_SERIES1)\n                            ff_dlog(s, \"detected Stand-Alone Tivo\\n\");\n                        ty->tivo_type = TIVO_TYPE_SA;\n                        ty->pts_offset = SA_PTS_OFFSET;\n                    } else {\n                        if (ty->tivo_series == TIVO_SERIES1)\n                            ff_dlog(s, \"detected DirecTV Tivo\\n\");\n                        ty->tivo_type = TIVO_TYPE_DTIVO;\n                        ty->pts_offset = DTIVO_PTS_OFFSET;\n                    }\n                }\n            }\n            data_offset += hdrs[i].rec_size;\n        }\n    }\n    av_free(hdrs);\n    return 0;\n}", "idx": 22222, "_split": "valid", "_hash": "c1f006a9939c13609b014df21327c98e"}
{"project": "FFmpeg", "commit_id": "cbba331aa02f29870581ff0b7ded7477b279ae2c", "target": 0, "func": "static inline int writer_print_string(WriterContext *wctx,\n\n                                      const char *key, const char *val, int opt)\n\n{\n\n    const struct section *section = wctx->section[wctx->level];\n\n    int ret = 0;\n\n\n\n    if (opt && !(wctx->writer->flags & WRITER_FLAG_DISPLAY_OPTIONAL_FIELDS))\n\n        return 0;\n\n\n\n    if (section->show_all_entries || av_dict_get(section->entries_to_show, key, NULL, 0)) {\n\n        wctx->writer->print_string(wctx, key, val);\n\n        wctx->nb_item[wctx->level]++;\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 22273, "_split": "valid", "_hash": "f06b2203acd265854f7f481d46f1371b"}
{"project": "FFmpeg", "commit_id": "c5d4f87e81111427c0952278ec247fa8ab1e6e52", "target": 1, "func": "static av_always_inline float quantize_and_encode_band_cost_template(\n\n                                struct AACEncContext *s,\n\n                                PutBitContext *pb, const float *in,\n\n                                const float *scaled, int size, int scale_idx,\n\n                                int cb, const float lambda, const float uplim,\n\n                                int *bits, int BT_ZERO, int BT_UNSIGNED,\n\n                                int BT_PAIR, int BT_ESC)\n\n{\n\n    const int q_idx = POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512;\n\n    const float Q   = ff_aac_pow2sf_tab [q_idx];\n\n    const float Q34 = ff_aac_pow34sf_tab[q_idx];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    const float CLIPPED_ESCAPE = 165140.0f*IQ;\n\n    int i, j;\n\n    float cost = 0;\n\n    const int dim = BT_PAIR ? 2 : 4;\n\n    int resbits = 0;\n\n    const int range  = aac_cb_range[cb];\n\n    const int maxval = aac_cb_maxval[cb];\n\n    int off;\n\n\n\n    if (BT_ZERO) {\n\n        for (i = 0; i < size; i++)\n\n            cost += in[i]*in[i];\n\n        if (bits)\n\n            *bits = 0;\n\n        return cost * lambda;\n\n    }\n\n    if (!scaled) {\n\n        abs_pow34_v(s->scoefs, in, size);\n\n        scaled = s->scoefs;\n\n    }\n\n    quantize_bands(s->qcoefs, in, scaled, size, Q34, !BT_UNSIGNED, maxval);\n\n    if (BT_UNSIGNED) {\n\n        off = 0;\n\n    } else {\n\n        off = maxval;\n\n    }\n\n    for (i = 0; i < size; i += dim) {\n\n        const float *vec;\n\n        int *quants = s->qcoefs + i;\n\n        int curidx = 0;\n\n        int curbits;\n\n        float rd = 0.0f;\n\n        for (j = 0; j < dim; j++) {\n\n            curidx *= range;\n\n            curidx += quants[j] + off;\n\n        }\n\n        curbits =  ff_aac_spectral_bits[cb-1][curidx];\n\n        vec     = &ff_aac_codebook_vectors[cb-1][curidx*dim];\n\n        if (BT_UNSIGNED) {\n\n            for (j = 0; j < dim; j++) {\n\n                float t = fabsf(in[i+j]);\n\n                float di;\n\n                if (BT_ESC && vec[j] == 64.0f) { //FIXME: slow\n\n                    if (t >= CLIPPED_ESCAPE) {\n\n                        di = t - CLIPPED_ESCAPE;\n\n                        curbits += 21;\n\n                    } else {\n\n                        int c = av_clip_uintp2(quant(t, Q), 13);\n\n                        di = t - c*cbrtf(c)*IQ;\n\n                        curbits += av_log2(c)*2 - 4 + 1;\n\n                    }\n\n                } else {\n\n                    di = t - vec[j]*IQ;\n\n                }\n\n                if (vec[j] != 0.0f)\n\n                    curbits++;\n\n                rd += di*di;\n\n            }\n\n        } else {\n\n            for (j = 0; j < dim; j++) {\n\n                float di = in[i+j] - vec[j]*IQ;\n\n                rd += di*di;\n\n            }\n\n        }\n\n        cost    += rd * lambda + curbits;\n\n        resbits += curbits;\n\n        if (cost >= uplim)\n\n            return uplim;\n\n        if (pb) {\n\n            put_bits(pb, ff_aac_spectral_bits[cb-1][curidx], ff_aac_spectral_codes[cb-1][curidx]);\n\n            if (BT_UNSIGNED)\n\n                for (j = 0; j < dim; j++)\n\n                    if (ff_aac_codebook_vectors[cb-1][curidx*dim+j] != 0.0f)\n\n                        put_bits(pb, 1, in[i+j] < 0.0f);\n\n            if (BT_ESC) {\n\n                for (j = 0; j < 2; j++) {\n\n                    if (ff_aac_codebook_vectors[cb-1][curidx*2+j] == 64.0f) {\n\n                        int coef = av_clip_uintp2(quant(fabsf(in[i+j]), Q), 13);\n\n                        int len = av_log2(coef);\n\n\n\n                        put_bits(pb, len - 4 + 1, (1 << (len - 4 + 1)) - 2);\n\n                        put_bits(pb, len, coef & ((1 << len) - 1));\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if (bits)\n\n        *bits = resbits;\n\n    return cost;\n\n}\n", "idx": 22313, "_split": "valid", "_hash": "d4f314008f8d8bfe294e453e28d37e38"}
{"project": "FFmpeg", "commit_id": "fbdb2059684ff27be61cfe40446e68cb2f9a12f8", "target": 0, "func": "static int encode_init(AVCodecContext * avctx){\n\n    WMACodecContext *s = avctx->priv_data;\n\n    int i, flags1, flags2;\n\n    uint8_t *extradata;\n\n\n\n    s->avctx = avctx;\n\n\n\n    if(avctx->channels > MAX_CHANNELS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"too many channels: got %i, need %i or fewer\",\n\n               avctx->channels, MAX_CHANNELS);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (avctx->sample_rate > 48000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"sample rate is too high: %d > 48kHz\",\n\n               avctx->sample_rate);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if(avctx->bit_rate < 24*1000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"bitrate too low: got %i, need 24000 or higher\\n\",\n\n               avctx->bit_rate);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    /* extract flag infos */\n\n    flags1 = 0;\n\n    flags2 = 1;\n\n    if (avctx->codec->id == CODEC_ID_WMAV1) {\n\n        extradata= av_malloc(4);\n\n        avctx->extradata_size= 4;\n\n        AV_WL16(extradata, flags1);\n\n        AV_WL16(extradata+2, flags2);\n\n    } else if (avctx->codec->id == CODEC_ID_WMAV2) {\n\n        extradata= av_mallocz(10);\n\n        avctx->extradata_size= 10;\n\n        AV_WL32(extradata, flags1);\n\n        AV_WL16(extradata+4, flags2);\n\n    }else\n\n        av_assert0(0);\n\n    avctx->extradata= extradata;\n\n    s->use_exp_vlc = flags2 & 0x0001;\n\n    s->use_bit_reservoir = flags2 & 0x0002;\n\n    s->use_variable_block_len = flags2 & 0x0004;\n\n    if (avctx->channels == 2)\n\n        s->ms_stereo = 1;\n\n\n\n    ff_wma_init(avctx, flags2);\n\n\n\n    /* init MDCT */\n\n    for(i = 0; i < s->nb_block_sizes; i++)\n\n        ff_mdct_init(&s->mdct_ctx[i], s->frame_len_bits - i + 1, 0, 1.0);\n\n\n\n    s->block_align     = avctx->bit_rate * (int64_t)s->frame_len /\n\n                         (avctx->sample_rate * 8);\n\n    s->block_align     = FFMIN(s->block_align, MAX_CODED_SUPERFRAME_SIZE);\n\n    avctx->block_align = s->block_align;\n\n    avctx->bit_rate    = avctx->block_align * 8LL * avctx->sample_rate /\n\n                         s->frame_len;\n\n//av_log(NULL, AV_LOG_ERROR, \"%d %d %d %d\\n\", s->block_align, avctx->bit_rate, s->frame_len, avctx->sample_rate);\n\n    avctx->frame_size = avctx->delay = s->frame_len;\n\n\n\n#if FF_API_OLD_ENCODE_AUDIO\n\n    avctx->coded_frame = &s->frame;\n\n    avcodec_get_frame_defaults(avctx->coded_frame);\n\n#endif\n\n\n\n    return 0;\n\n}\n", "idx": 22333, "_split": "valid", "_hash": "86f6a2aa44b485425e31ace554e3fb8a"}
{"project": "FFmpeg", "commit_id": "4dcb69cc12d00d46f93a07178e2087a8d27c8f64", "target": 0, "func": "void ff_aac_search_for_is(AACEncContext *s, AVCodecContext *avctx, ChannelElement *cpe)\n\n{\n\n    SingleChannelElement *sce0 = &cpe->ch[0];\n\n    SingleChannelElement *sce1 = &cpe->ch[1];\n\n    int start = 0, count = 0, w, w2, g, i, prev_sf1 = -1;\n\n    const float freq_mult = avctx->sample_rate/(1024.0f/sce0->ics.num_windows)/2.0f;\n\n    uint8_t nextband1[128];\n\n\n\n    if (!cpe->common_window)\n\n        return;\n\n\n\n    /** Scout out next nonzero bands */\n\n    ff_init_nextband_map(sce1, nextband1);\n\n\n\n    for (w = 0; w < sce0->ics.num_windows; w += sce0->ics.group_len[w]) {\n\n        start = 0;\n\n        for (g = 0;  g < sce0->ics.num_swb; g++) {\n\n            if (start*freq_mult > INT_STEREO_LOW_LIMIT*(s->lambda/170.0f) &&\n\n                cpe->ch[0].band_type[w*16+g] != NOISE_BT && !cpe->ch[0].zeroes[w*16+g] &&\n\n                cpe->ch[1].band_type[w*16+g] != NOISE_BT && !cpe->ch[1].zeroes[w*16+g] &&\n\n                ff_sfdelta_can_remove_band(sce1, nextband1, prev_sf1, w*16+g)) {\n\n                float ener0 = 0.0f, ener1 = 0.0f, ener01 = 0.0f, ener01p = 0.0f;\n\n                struct AACISError ph_err1, ph_err2, *best;\n\n                if (sce0->band_type[w*16+g] == NOISE_BT ||\n\n                    sce1->band_type[w*16+g] == NOISE_BT) {\n\n                    start += sce0->ics.swb_sizes[g];\n\n                    continue;\n\n                }\n\n                for (w2 = 0; w2 < sce0->ics.group_len[w]; w2++) {\n\n                    for (i = 0; i < sce0->ics.swb_sizes[g]; i++) {\n\n                        float coef0 = fabsf(sce0->coeffs[start+(w+w2)*128+i]);\n\n                        float coef1 = fabsf(sce1->coeffs[start+(w+w2)*128+i]);\n\n                        ener0  += coef0*coef0;\n\n                        ener1  += coef1*coef1;\n\n                        ener01 += (coef0 + coef1)*(coef0 + coef1);\n\n                        ener01p += (coef0 - coef1)*(coef0 - coef1);\n\n                    }\n\n                }\n\n                ph_err1 = ff_aac_is_encoding_err(s, cpe, start, w, g,\n\n                                                 ener0, ener1, ener01p, 0, -1);\n\n                ph_err2 = ff_aac_is_encoding_err(s, cpe, start, w, g,\n\n                                                 ener0, ener1, ener01, 0, +1);\n\n                best = (ph_err1.pass && ph_err1.error < ph_err2.error) ? &ph_err1 : &ph_err2;\n\n                if (best->pass) {\n\n                    cpe->is_mask[w*16+g] = 1;\n\n                    cpe->ms_mask[w*16+g] = 0;\n\n                    cpe->ch[0].is_ener[w*16+g] = sqrt(ener0 / best->ener01);\n\n                    cpe->ch[1].is_ener[w*16+g] = ener0/ener1;\n\n                    cpe->ch[1].band_type[w*16+g] = (best->phase > 0) ? INTENSITY_BT : INTENSITY_BT2;\n\n                    count++;\n\n                }\n\n            }\n\n            if (!sce1->zeroes[w*16+g] && sce1->band_type[w*16+g] < RESERVED_BT)\n\n                prev_sf1 = sce1->sf_idx[w*16+g];\n\n            start += sce0->ics.swb_sizes[g];\n\n        }\n\n    }\n\n    cpe->is_mode = !!count;\n\n}\n", "idx": 22405, "_split": "valid", "_hash": "60c55224ca5684f5a5f0d9e33d4fc0ca"}
{"project": "FFmpeg", "commit_id": "deabb52ab4c1fdb3dd319f3980b1489a182011f1", "target": 1, "func": "static int ivi_decode_blocks(GetBitContext *gb, IVIBandDesc *band, IVITile *tile,\n                             AVCodecContext *avctx)\n{\n    int         mbn, blk, num_blocks, num_coeffs, blk_size, scan_pos, run, val,\n                pos, is_intra, mc_type = 0, mv_x, mv_y, col_mask;\n    uint8_t     col_flags[8];\n    int32_t     prev_dc, trvec[64];\n    uint32_t    cbp, sym, lo, hi, quant, buf_offs, q;\n    IVIMbInfo   *mb;\n    RVMapDesc   *rvmap = band->rv_map;\n    void (*mc_with_delta_func)(int16_t *buf, const int16_t *ref_buf, uint32_t pitch, int mc_type);\n    void (*mc_no_delta_func)  (int16_t *buf, const int16_t *ref_buf, uint32_t pitch, int mc_type);\n    const uint16_t  *base_tab;\n    const uint8_t   *scale_tab;\n    prev_dc = 0; /* init intra prediction for the DC coefficient */\n    blk_size   = band->blk_size;\n    col_mask   = blk_size - 1; /* column mask for tracking non-zero coeffs */\n    num_blocks = (band->mb_size != blk_size) ? 4 : 1; /* number of blocks per mb */\n    num_coeffs = blk_size * blk_size;\n    if (blk_size == 8) {\n        mc_with_delta_func = ff_ivi_mc_8x8_delta;\n        mc_no_delta_func   = ff_ivi_mc_8x8_no_delta;\n    } else {\n        mc_with_delta_func = ff_ivi_mc_4x4_delta;\n        mc_no_delta_func   = ff_ivi_mc_4x4_no_delta;\n    for (mbn = 0, mb = tile->mbs; mbn < tile->num_MBs; mb++, mbn++) {\n        is_intra = !mb->type;\n        cbp      = mb->cbp;\n        buf_offs = mb->buf_offs;\n        quant = av_clip(band->glob_quant + mb->q_delta, 0, 23);\n        base_tab  = is_intra ? band->intra_base  : band->inter_base;\n        scale_tab = is_intra ? band->intra_scale : band->inter_scale;\n        if (scale_tab)\n            quant = scale_tab[quant];\n        if (!is_intra) {\n            mv_x = mb->mv_x;\n            mv_y = mb->mv_y;\n            if (band->is_halfpel) {\n                mc_type = ((mv_y & 1) << 1) | (mv_x & 1);\n                mv_x >>= 1;\n                mv_y >>= 1; /* convert halfpel vectors into fullpel ones */\n            if (mb->type) {\n                int dmv_x, dmv_y, cx, cy;\n                dmv_x = mb->mv_x >> band->is_halfpel;\n                dmv_y = mb->mv_y >> band->is_halfpel;\n                cx    = mb->mv_x &  band->is_halfpel;\n                cy    = mb->mv_y &  band->is_halfpel;\n                if (   mb->xpos + dmv_x < 0\n                    || mb->xpos + dmv_x + band->mb_size + cx > band->pitch\n                    || mb->ypos + dmv_y < 0\n                    || mb->ypos + dmv_y + band->mb_size + cy > band->aheight) {\n        for (blk = 0; blk < num_blocks; blk++) {\n            /* adjust block position in the buffer according to its number */\n            if (blk & 1) {\n                buf_offs += blk_size;\n            } else if (blk == 2) {\n                buf_offs -= blk_size;\n                buf_offs += blk_size * band->pitch;\n            if (cbp & 1) { /* block coded ? */\n                scan_pos = -1;\n                memset(trvec, 0, num_coeffs*sizeof(trvec[0])); /* zero transform vector */\n                memset(col_flags, 0, sizeof(col_flags));      /* zero column flags */\n                while (scan_pos <= num_coeffs) {\n                    sym = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1);\n                    if (sym == rvmap->eob_sym)\n                        break; /* End of block */\n                    if (sym == rvmap->esc_sym) { /* Escape - run/val explicitly coded using 3 vlc codes */\n                        run = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1) + 1;\n                        lo  = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1);\n                        hi  = get_vlc2(gb, band->blk_vlc.tab->table, IVI_VLC_BITS, 1);\n                        val = IVI_TOSIGNED((hi << 6) | lo); /* merge them and convert into signed val */\n                    } else {\n                        if (sym >= 256U) {\n                            av_log(avctx, AV_LOG_ERROR, \"Invalid sym encountered: %d.\\n\", sym);\n                            return -1;\n                        run = rvmap->runtab[sym];\n                        val = rvmap->valtab[sym];\n                    /* de-zigzag and dequantize */\n                    scan_pos += run;\n                    if (scan_pos >= num_coeffs)\n                        break;\n                    pos = band->scan[scan_pos];\n                    if (!val)\n                        av_dlog(avctx, \"Val = 0 encountered!\\n\");\n                    q = (base_tab[pos] * quant) >> 9;\n                    if (q > 1)\n                        val = val * q + FFSIGN(val) * (((q ^ 1) - 1) >> 1);\n                    trvec[pos] = val;\n                    col_flags[pos & col_mask] |= !!val; /* track columns containing non-zero coeffs */\n                }// while\n                if (scan_pos >= num_coeffs && sym != rvmap->eob_sym)\n                    return -1; /* corrupt block data */\n                /* undoing DC coeff prediction for intra-blocks */\n                if (is_intra && band->is_2d_trans) {\n                    prev_dc      += trvec[0];\n                    trvec[0]      = prev_dc;\n                    col_flags[0] |= !!prev_dc;\n                /* apply inverse transform */\n                band->inv_transform(trvec, band->buf + buf_offs,\n                                    band->pitch, col_flags);\n                /* apply motion compensation */\n                if (!is_intra)\n                    mc_with_delta_func(band->buf + buf_offs,\n                                       band->ref_buf + buf_offs + mv_y * band->pitch + mv_x,\n                                       band->pitch, mc_type);\n            } else {\n                /* block not coded */\n                /* for intra blocks apply the dc slant transform */\n                /* for inter - perform the motion compensation without delta */\n                if (is_intra && band->dc_transform) {\n                    band->dc_transform(&prev_dc, band->buf + buf_offs,\n                                       band->pitch, blk_size);\n                } else\n                    mc_no_delta_func(band->buf + buf_offs,\n                                     band->ref_buf + buf_offs + mv_y * band->pitch + mv_x,\n                                     band->pitch, mc_type);\n            cbp >>= 1;\n        }// for blk\n    }// for mbn\n    align_get_bits(gb);\n    return 0;", "idx": 22437, "_split": "valid", "_hash": "48688466c1f4b9a884bc23c82881ecd5"}
{"project": "FFmpeg", "commit_id": "dbe29db8cb09fb39bd8dc5b25934e92279d0aa8d", "target": 1, "func": "static int skip_data_stream_element(AACContext *ac, GetBitContext *gb)\n\n{\n\n    int byte_align = get_bits1(gb);\n\n    int count = get_bits(gb, 8);\n\n    if (count == 255)\n\n        count += get_bits(gb, 8);\n\n    if (byte_align)\n\n        align_get_bits(gb);\n\n\n\n    if (get_bits_left(gb) < 8 * count) {\n\n        av_log(ac->avctx, AV_LOG_ERROR, overread_err);\n\n        return -1;\n\n    }\n\n    skip_bits_long(gb, 8 * count);\n\n    return 0;\n\n}\n", "idx": 22442, "_split": "valid", "_hash": "ab14b5b4b90227750c9f839e4f1d3aac"}
{"project": "FFmpeg", "commit_id": "c90b88090c260a0af018b6c1e955266e24ebf6f4", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *inbuf)\n\n{\n\n    AudioPhaserContext *s = inlink->dst->priv;\n\n    AVFilterLink *outlink = inlink->dst->outputs[0];\n\n    AVFrame *outbuf;\n\n\n\n    if (av_frame_is_writable(inbuf)) {\n\n        outbuf = inbuf;\n\n    } else {\n\n        outbuf = ff_get_audio_buffer(inlink, inbuf->nb_samples);\n\n        if (!outbuf)\n\n            return AVERROR(ENOMEM);\n\n        av_frame_copy_props(outbuf, inbuf);\n\n    }\n\n\n\n    s->phaser(s, inbuf->extended_data, outbuf->extended_data,\n\n              outbuf->nb_samples, outbuf->channels);\n\n\n\n    if (inbuf != outbuf)\n\n        av_frame_free(&inbuf);\n\n\n\n    return ff_filter_frame(outlink, outbuf);\n\n}\n", "idx": 22445, "_split": "valid", "_hash": "f326bf27d9640758d109d1bfbddc8eae"}
{"project": "FFmpeg", "commit_id": "adaa7743f5fdca0c0aca0b7ffdebf61c7d868571", "target": 0, "func": "static AVStream *find_stream(void *log, AVFormatContext *avf, const char *spec)\n\n{\n\n    int i, ret, already = 0, stream_id = -1;\n\n    char type_char, dummy;\n\n    AVStream *found = NULL;\n\n    enum AVMediaType type;\n\n\n\n    ret = sscanf(spec, \"d%[av]%d%c\", &type_char, &stream_id, &dummy);\n\n    if (ret >= 1 && ret <= 2) {\n\n        type = type_char == 'v' ? AVMEDIA_TYPE_VIDEO : AVMEDIA_TYPE_AUDIO;\n\n        ret = av_find_best_stream(avf, type, stream_id, -1, NULL, 0);\n\n        if (ret < 0) {\n\n            av_log(log, AV_LOG_ERROR, \"No %s stream with index '%d' found\\n\",\n\n                   av_get_media_type_string(type), stream_id);\n\n            return NULL;\n\n        }\n\n        return avf->streams[ret];\n\n    }\n\n    for (i = 0; i < avf->nb_streams; i++) {\n\n        ret = avformat_match_stream_specifier(avf, avf->streams[i], spec);\n\n        if (ret < 0) {\n\n            av_log(log, AV_LOG_ERROR,\n\n                   \"Invalid stream specifier \\\"%s\\\"\\n\", spec);\n\n            return NULL;\n\n        }\n\n        if (!ret)\n\n            continue;\n\n        if (avf->streams[i]->discard != AVDISCARD_ALL) {\n\n            already++;\n\n            continue;\n\n        }\n\n        if (found) {\n\n            av_log(log, AV_LOG_WARNING,\n\n                   \"Ambiguous stream specifier \\\"%s\\\", using #%d\\n\", spec, i);\n\n            break;\n\n        }\n\n        found = avf->streams[i];\n\n    }\n\n    if (!found) {\n\n        av_log(log, AV_LOG_WARNING, \"Stream specifier \\\"%s\\\" %s\\n\", spec,\n\n               already ? \"matched only already used streams\" :\n\n                         \"did not match any stream\");\n\n        return NULL;\n\n    }\n\n    if (found->codec->codec_type != AVMEDIA_TYPE_VIDEO &&\n\n        found->codec->codec_type != AVMEDIA_TYPE_AUDIO) {\n\n        av_log(log, AV_LOG_ERROR, \"Stream specifier \\\"%s\\\" matched a %s stream,\"\n\n               \"currently unsupported by libavfilter\\n\", spec,\n\n               av_get_media_type_string(found->codec->codec_type));\n\n        return NULL;\n\n    }\n\n    return found;\n\n}\n", "idx": 22453, "_split": "valid", "_hash": "af0389d0cb0e0555fb7641e9fdd7daaa"}
{"project": "FFmpeg", "commit_id": "4d59d075a96c7bc9fc7a118f96015fbf5156708a", "target": 0, "func": "static void check_rgb2yuv(void)\n\n{\n\n    declare_func(void, uint8_t *dst[3], ptrdiff_t dst_stride[3],\n\n                 int16_t *src[3], ptrdiff_t src_stride,\n\n                 int w, int h, const int16_t coeff[3][3][8],\n\n                 const int16_t off[8]);\n\n    ColorSpaceDSPContext dsp;\n\n    int odepth, fmt, n;\n\n    LOCAL_ALIGNED_32(int16_t, src_y, [W * H * 2]);\n\n    LOCAL_ALIGNED_32(int16_t, src_u, [W * H * 2]);\n\n    LOCAL_ALIGNED_32(int16_t, src_v, [W * H * 2]);\n\n    int16_t *src[3] = { src_y, src_u, src_v };\n\n    LOCAL_ALIGNED_32(uint8_t, dst0_y, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst0_u, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst0_v, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst1_y, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst1_u, [W * H]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst1_v, [W * H]);\n\n    uint8_t *dst0[3] = { dst0_y, dst0_u, dst0_v }, *dst1[3] = { dst1_y, dst1_u, dst1_v };\n\n    LOCAL_ALIGNED_32(int16_t, offset, [8]);\n\n    LOCAL_ALIGNED_32(int16_t, coeff_buf, [3 * 3 * 8]);\n\n    int16_t (*coeff)[3][8] = (int16_t(*)[3][8]) coeff_buf;\n\n\n\n    ff_colorspacedsp_init(&dsp);\n\n    for (n = 0; n < 8; n++) {\n\n        offset[n] = 16;\n\n\n\n        // these somewhat resemble bt601/smpte170m coefficients\n\n        coeff[0][0][n] = lrint(0.3 * (1 << 14));\n\n        coeff[0][1][n] = lrint(0.6 * (1 << 14));\n\n        coeff[0][2][n] = lrint(0.1 * (1 << 14));\n\n        coeff[1][0][n] = lrint(-0.15 * (1 << 14));\n\n        coeff[1][1][n] = lrint(-0.35 * (1 << 14));\n\n        coeff[1][2][n] = lrint(0.5 * (1 << 14));\n\n        coeff[2][0][n] = lrint(0.5 * (1 << 14));\n\n        coeff[2][1][n] = lrint(-0.42 * (1 << 14));\n\n        coeff[2][2][n] = lrint(-0.08 * (1 << 14));\n\n    }\n\n    for (odepth = 0; odepth < 3; odepth++) {\n\n        for (fmt = 0; fmt < 3; fmt++) {\n\n            if (check_func(dsp.rgb2yuv[odepth][fmt],\n\n                           \"ff_colorspacedsp_rgb2yuv_%sp%d\",\n\n                           format_string[fmt], odepth * 2 + 8)) {\n\n                int ss_w = !!fmt, ss_h = fmt == 2;\n\n                int y_dst_stride = W << !!odepth;\n\n                int uv_dst_stride = y_dst_stride >> ss_w;\n\n\n\n                randomize_buffers();\n\n                call_ref(dst0, (ptrdiff_t[3]) { y_dst_stride, uv_dst_stride, uv_dst_stride },\n\n                         src, W, W, H, coeff, offset);\n\n                call_new(dst1, (ptrdiff_t[3]) { y_dst_stride, uv_dst_stride, uv_dst_stride },\n\n                         src, W, W, H, coeff, offset);\n\n                if (memcmp(dst0[0], dst1[0], H * y_dst_stride) ||\n\n                    memcmp(dst0[1], dst1[1], H * uv_dst_stride >> ss_h) ||\n\n                    memcmp(dst0[2], dst1[2], H * uv_dst_stride >> ss_h)) {\n\n                    fail();\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    report(\"rgb2yuv\");\n\n}\n", "idx": 22456, "_split": "valid", "_hash": "79d8185fa11589a5272cddd46af635c3"}
{"project": "FFmpeg", "commit_id": "2c1e075308e14810149f53be87959a62cb83a730", "target": 0, "func": "flac_header (AVFormatContext * s, int idx)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    struct ogg_stream *os = ogg->streams + idx;\n\n    AVStream *st = s->streams[idx];\n\n    GetBitContext gb;\n\n    FLACStreaminfo si;\n\n    int mdt;\n\n\n\n    if (os->buf[os->pstart] == 0xff)\n\n        return 0;\n\n\n\n    init_get_bits(&gb, os->buf + os->pstart, os->psize*8);\n\n    skip_bits1(&gb); /* metadata_last */\n\n    mdt = get_bits(&gb, 7);\n\n\n\n    if (mdt == OGG_FLAC_METADATA_TYPE_STREAMINFO) {\n\n        uint8_t *streaminfo_start = os->buf + os->pstart + 5 + 4 + 4 + 4;\n\n        skip_bits_long(&gb, 4*8); /* \"FLAC\" */\n\n        if(get_bits(&gb, 8) != 1) /* unsupported major version */\n\n            return -1;\n\n        skip_bits_long(&gb, 8 + 16); /* minor version + header count */\n\n        skip_bits_long(&gb, 4*8); /* \"fLaC\" */\n\n\n\n        /* METADATA_BLOCK_HEADER */\n\n        if (get_bits_long(&gb, 32) != FLAC_STREAMINFO_SIZE)\n\n            return -1;\n\n\n\n        avpriv_flac_parse_streaminfo(st->codec, &si, streaminfo_start);\n\n\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_id = AV_CODEC_ID_FLAC;\n\n        st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n\n\n        ff_alloc_extradata(st->codec, FLAC_STREAMINFO_SIZE);\n\n        memcpy(st->codec->extradata, streaminfo_start, st->codec->extradata_size);\n\n\n\n        avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n    } else if (mdt == FLAC_METADATA_TYPE_VORBIS_COMMENT) {\n\n        ff_vorbis_comment (s, &st->metadata, os->buf + os->pstart + 4, os->psize - 4);\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 22458, "_split": "valid", "_hash": "03ff89afdd15e16b689c34d478ffda75"}
{"project": "FFmpeg", "commit_id": "e5540b3fd30367ce3cc33b2f34a04b660dbc4b38", "target": 0, "func": "static int decode_i_picture_header(VC9Context *v)\n\n{\n\n  int pqindex, status = 0, ac_pred, condover;\n\n\n\n    /* Prolog common to all frametypes should be done in caller */\n\n    //BF = Buffer Fullness\n\n    if (v->profile <= PROFILE_MAIN && get_bits(&v->gb, 7))\n\n    {\n\n        av_log(v, AV_LOG_DEBUG, \"I BufferFullness not 0\\n\");\n\n    }\n\n\n\n    /* Quantizer stuff */\n\n    pqindex = get_bits(&v->gb, 5);\n\n    if (v->quantizer_mode == QUANT_FRAME_IMPLICIT)\n\n        v->pq = pquant_table[0][pqindex];\n\n    else\n\n    {\n\n        v->pq = pquant_table[v->quantizer_mode-1][pqindex];\n\n    }\n\n    if (pqindex < 9) v->halfpq = get_bits(&v->gb, 1);\n\n    if (v->quantizer_mode == QUANT_FRAME_EXPLICIT)\n\n        v->pquantizer = get_bits(&v->gb, 1);\n\n    av_log(v->avctx, AV_LOG_DEBUG, \"I frame: QP=%i (+%i/2)\\n\",\n\n           v->pq, v->halfpq);\n\n#if HAS_ADVANCED_PROFILE\n\n    if (v->profile <= PROFILE_MAIN)\n\n#endif\n\n    {\n\n        if (v->extended_mv) v->mvrange = get_prefix(&v->gb, 0, 3);\n\n        if (v->multires) v->respic = get_bits(&v->gb, 2);\n\n    }\n\n#if HAS_ADVANCED_PROFILE\n\n    else\n\n    {\n\n        ac_pred = get_bits(&v->gb, 1);\n\n        if (v->postprocflag) v->postproc = get_bits(&v->gb, 1);\n\n        /* 7.1.1.34 + 8.5.2 */\n\n        if (v->overlap && v->pq<9)\n\n        {\n\n            condover = get_bits(&v->gb, 1);\n\n            if (condover)\n\n            {\n\n                condover = 2+get_bits(&v->gb, 1);\n\n                if (condover == 3)\n\n                    status = bitplane_decoding(v->over_flags_plane,\n\n                                                   v->width_mb, v->height_mb, v);\n\n            }\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* Epilog should be done in caller */\n\n    return status;\n\n}\n", "idx": 22479, "_split": "valid", "_hash": "9a0505de83da774dc72feb1ef48e3b66"}
{"project": "FFmpeg", "commit_id": "0491a2a07a44f6e5e6f34081835e402c07025fd2", "target": 0, "func": "static char *time_value_string(char *buf, int buf_size, int64_t val, const AVRational *time_base)\n\n{\n\n    if (val == AV_NOPTS_VALUE) {\n\n        snprintf(buf, buf_size, \"N/A\");\n\n    } else {\n\n        double d = val * av_q2d(*time_base);\n\n        value_string(buf, buf_size, (struct unit_value){.val.d=d, .unit=unit_second_str});\n\n    }\n\n\n\n    return buf;\n\n}\n", "idx": 22511, "_split": "valid", "_hash": "31c402bf1cb97f389300a623d7a9e421"}
{"project": "FFmpeg", "commit_id": "625b582d5a9196c582e7702b542b3e0face30ccf", "target": 0, "func": "static int read_sbr_single_channel_element(AACContext *ac,\n\n                                            SpectralBandReplication *sbr,\n\n                                            GetBitContext *gb)\n\n{\n\n    int ret;\n\n\n\n    if (get_bits1(gb)) // bs_data_extra\n\n        skip_bits(gb, 4); // bs_reserved\n\n\n\n    if (read_sbr_grid(ac, sbr, gb, &sbr->data[0]))\n\n        return -1;\n\n    read_sbr_dtdf(sbr, gb, &sbr->data[0]);\n\n    read_sbr_invf(sbr, gb, &sbr->data[0]);\n\n    read_sbr_envelope(sbr, gb, &sbr->data[0], 0);\n\n    if((ret = read_sbr_noise(ac, sbr, gb, &sbr->data[0], 0)) < 0)\n\n        return ret;\n\n\n\n    if ((sbr->data[0].bs_add_harmonic_flag = get_bits1(gb)))\n\n        get_bits1_vector(gb, sbr->data[0].bs_add_harmonic, sbr->n[1]);\n\n\n\n    return 0;\n\n}\n", "idx": 22565, "_split": "valid", "_hash": "e237282f82d0f693a2af166a492b617a"}
{"project": "FFmpeg", "commit_id": "29ba091136a5e04574f7bfc1b17536c923958f6f", "target": 0, "func": "const char *swscale_configuration(void)\n\n{\n\n    return FFMPEG_CONFIGURATION;\n\n}\n", "idx": 22573, "_split": "valid", "_hash": "e0b7af2f20eea920f781877f7239a261"}
{"project": "FFmpeg", "commit_id": "a2f7314ba231cde459c4f33f1a7602ae9d9d2d28", "target": 1, "func": "static inline void RENAME(duplicate)(uint8_t src[], int stride)\n\n{\n\n#if TEMPLATE_PP_MMX\n\n    __asm__ volatile(\n\n        \"movq (%0), %%mm0               \\n\\t\"\n\n        \"add %1, %0                     \\n\\t\"\n\n        \"movq %%mm0, (%0)               \\n\\t\"\n\n        \"movq %%mm0, (%0, %1)           \\n\\t\"\n\n        \"movq %%mm0, (%0, %1, 2)        \\n\\t\"\n\n        : \"+r\" (src)\n\n        : \"r\" ((x86_reg)-stride)\n\n    );\n\n#else\n\n    int i;\n\n    uint8_t *p=src;\n\n    for(i=0; i<3; i++){\n\n        p-= stride;\n\n        memcpy(p, src, 8);\n\n    }\n\n#endif\n\n}\n", "idx": 22591, "_split": "valid", "_hash": "ba939e9a3a3f7a1d303d45000b8d909c"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static void RENAME(extract_even2)(const uint8_t *src, uint8_t *dst0, uint8_t *dst1, x86_reg count)\n\n{\n\n    dst0+=   count;\n\n    dst1+=   count;\n\n    src += 4*count;\n\n    count= - count;\n\n#if COMPILE_TEMPLATE_MMX\n\n    if(count <= -8) {\n\n        count += 7;\n\n        __asm__ volatile(\n\n            \"pcmpeqw       %%mm7, %%mm7        \\n\\t\"\n\n            \"psrlw            $8, %%mm7        \\n\\t\"\n\n            \"1:                                \\n\\t\"\n\n            \"movq -28(%1, %0, 4), %%mm0        \\n\\t\"\n\n            \"movq -20(%1, %0, 4), %%mm1        \\n\\t\"\n\n            \"movq -12(%1, %0, 4), %%mm2        \\n\\t\"\n\n            \"movq  -4(%1, %0, 4), %%mm3        \\n\\t\"\n\n            \"pand          %%mm7, %%mm0        \\n\\t\"\n\n            \"pand          %%mm7, %%mm1        \\n\\t\"\n\n            \"pand          %%mm7, %%mm2        \\n\\t\"\n\n            \"pand          %%mm7, %%mm3        \\n\\t\"\n\n            \"packuswb      %%mm1, %%mm0        \\n\\t\"\n\n            \"packuswb      %%mm3, %%mm2        \\n\\t\"\n\n            \"movq          %%mm0, %%mm1        \\n\\t\"\n\n            \"movq          %%mm2, %%mm3        \\n\\t\"\n\n            \"psrlw            $8, %%mm0        \\n\\t\"\n\n            \"psrlw            $8, %%mm2        \\n\\t\"\n\n            \"pand          %%mm7, %%mm1        \\n\\t\"\n\n            \"pand          %%mm7, %%mm3        \\n\\t\"\n\n            \"packuswb      %%mm2, %%mm0        \\n\\t\"\n\n            \"packuswb      %%mm3, %%mm1        \\n\\t\"\n\n            MOVNTQ\"        %%mm0,- 7(%3, %0)   \\n\\t\"\n\n            MOVNTQ\"        %%mm1,- 7(%2, %0)   \\n\\t\"\n\n            \"add              $8, %0           \\n\\t\"\n\n            \" js 1b                            \\n\\t\"\n\n            : \"+r\"(count)\n\n            : \"r\"(src), \"r\"(dst0), \"r\"(dst1)\n\n        );\n\n        count -= 7;\n\n    }\n\n#endif\n\n    while(count<0) {\n\n        dst0[count]= src[4*count+0];\n\n        dst1[count]= src[4*count+2];\n\n        count++;\n\n    }\n\n}\n", "idx": 22600, "_split": "valid", "_hash": "6510bfc9bc4d5e38187569f97c0e55c4"}
{"project": "FFmpeg", "commit_id": "87ecefdab0097537c5c30014e57b19113ab05eee", "target": 1, "func": "static void evaluate_utility_inc(elbg_data *elbg)\n\n{\n\n    int i, inc=0;\n\n\n\n    for (i=0; i < elbg->numCB; i++) {\n\n        if (elbg->numCB*elbg->utility[i] > elbg->error)\n\n            inc += elbg->utility[i];\n\n        elbg->utility_inc[i] = inc;\n\n    }\n\n}\n", "idx": 22626, "_split": "valid", "_hash": "db2f1bfce608c2d9a8ea604b71888c21"}
{"project": "FFmpeg", "commit_id": "c3d7f00ee3e09801f56f25db8b5961f25e842bd2", "target": 0, "func": "static void sdt_cb(MpegTSFilter *filter, const uint8_t *section, int section_len)\n\n{\n\n    MpegTSContext *ts = filter->u.section_filter.opaque;\n\n    SectionHeader h1, *h = &h1;\n\n    const uint8_t *p, *p_end, *desc_list_end, *desc_end;\n\n    int onid, val, sid, desc_list_len, desc_tag, desc_len, service_type;\n\n    char *name, *provider_name;\n\n\n\n    av_dlog(ts->stream, \"SDT:\\n\");\n\n    hex_dump_debug(ts->stream, section, section_len);\n\n\n\n    p_end = section + section_len - 4;\n\n    p     = section;\n\n    if (parse_section_header(h, &p, p_end) < 0)\n\n        return;\n\n    if (h->tid != SDT_TID)\n\n        return;\n\n    if (ts->skip_changes)\n\n        return;\n\n    onid = get16(&p, p_end);\n\n    if (onid < 0)\n\n        return;\n\n    val = get8(&p, p_end);\n\n    if (val < 0)\n\n        return;\n\n    for (;;) {\n\n        sid = get16(&p, p_end);\n\n        if (sid < 0)\n\n            break;\n\n        val = get8(&p, p_end);\n\n        if (val < 0)\n\n            break;\n\n        desc_list_len = get16(&p, p_end);\n\n        if (desc_list_len < 0)\n\n            break;\n\n        desc_list_len &= 0xfff;\n\n        desc_list_end  = p + desc_list_len;\n\n        if (desc_list_end > p_end)\n\n            break;\n\n        for (;;) {\n\n            desc_tag = get8(&p, desc_list_end);\n\n            if (desc_tag < 0)\n\n                break;\n\n            desc_len = get8(&p, desc_list_end);\n\n            desc_end = p + desc_len;\n\n            if (desc_end > desc_list_end)\n\n                break;\n\n\n\n            av_dlog(ts->stream, \"tag: 0x%02x len=%d\\n\",\n\n                    desc_tag, desc_len);\n\n\n\n            switch (desc_tag) {\n\n            case 0x48:\n\n                service_type = get8(&p, p_end);\n\n                if (service_type < 0)\n\n                    break;\n\n                provider_name = getstr8(&p, p_end);\n\n                if (!provider_name)\n\n                    break;\n\n                name = getstr8(&p, p_end);\n\n                if (name) {\n\n                    AVProgram *program = av_new_program(ts->stream, sid);\n\n                    if (program) {\n\n                        av_dict_set(&program->metadata, \"service_name\", name, 0);\n\n                        av_dict_set(&program->metadata, \"service_provider\",\n\n                                    provider_name, 0);\n\n                    }\n\n                }\n\n                av_free(name);\n\n                av_free(provider_name);\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n            p = desc_end;\n\n        }\n\n        p = desc_list_end;\n\n    }\n\n}\n", "idx": 22664, "_split": "valid", "_hash": "75ed743efc6f2adc32cebcddb11872fb"}
{"project": "FFmpeg", "commit_id": "88281a5256f0034451c09acab3aff44acb43c2a3", "target": 0, "func": "static int nppscale_query_formats(AVFilterContext *ctx)\n\n{\n\n    static const enum AVPixelFormat pixel_formats[] = {\n\n        AV_PIX_FMT_CUDA, AV_PIX_FMT_NONE,\n\n    };\n\n    AVFilterFormats *pix_fmts  = ff_make_format_list(pixel_formats);\n\n\n\n    ff_set_common_formats(ctx, pix_fmts);\n\n\n\n    return 0;\n\n}\n", "idx": 22697, "_split": "valid", "_hash": "e5ee0dcf83f5a18fc16e1684a59e6e4e"}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "static void delete_next_frame(AudioFrameQueue *afq)\n\n{\n\n    AudioFrame *f = afq->frame_queue;\n\n    if (f) {\n\n        afq->frame_queue = f->next;\n\n        f->next = NULL;\n\n        av_freep(&f);\n\n    }\n\n}\n", "idx": 22699, "_split": "valid", "_hash": "e31b60876cc2d813ec38f69cc716e7af"}
{"project": "FFmpeg", "commit_id": "083300bea935d125b83f60d7030f78a7ffb0f3df", "target": 1, "func": "int ff_thread_get_buffer(AVCodecContext *avctx, ThreadFrame *f, int flags)\n\n{\n\n    f->owner = avctx;\n\n    return ff_get_buffer(avctx, f->f, flags);\n\n}\n", "idx": 22710, "_split": "valid", "_hash": "abab8db197113213855a94ed3c086b68"}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "void ff_msmpeg4_encode_init(MpegEncContext *s)\n\n{\n\n    static int init_done=0;\n\n    int i;\n\n\n\n    common_init(s);\n\n    if(s->msmpeg4_version>=4){\n\n        s->min_qcoeff= -255;\n\n        s->max_qcoeff=  255;\n\n    }\n\n\n\n    if (!init_done) {\n\n        /* init various encoding tables */\n\n        init_done = 1;\n\n        init_mv_table(&mv_tables[0]);\n\n        init_mv_table(&mv_tables[1]);\n\n        for(i=0;i<NB_RL_TABLES;i++)\n\n            init_rl(&rl_table[i]);\n\n\n\n        for(i=0; i<NB_RL_TABLES; i++){\n\n            int level;\n\n            for(level=0; level<=MAX_LEVEL; level++){\n\n                int run;\n\n                for(run=0; run<=MAX_RUN; run++){\n\n                    int last;\n\n                    for(last=0; last<2; last++){\n\n                        rl_length[i][level][run][last]= get_size_of_code(s, &rl_table[  i], last, run, level, 0);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 22811, "_split": "valid", "_hash": "645cd004f7ae996267ffce7d9ae1936a"}
{"project": "FFmpeg", "commit_id": "da2e774fd6841da7cede8c8ef30337449329727c", "target": 1, "func": "static int kmvc_decode_inter_8x8(KmvcContext * ctx, const uint8_t * src, int src_size, int w, int h)\n\n{\n\n    BitBuf bb;\n\n    int res, val;\n\n    int i, j;\n\n    int bx, by;\n\n    int l0x, l1x, l0y, l1y;\n\n    int mx, my;\n\n    const uint8_t *src_end = src + src_size;\n\n\n\n    kmvc_init_getbits(bb, src);\n\n\n\n    for (by = 0; by < h; by += 8)\n\n        for (bx = 0; bx < w; bx += 8) {\n\n            kmvc_getbit(bb, src, src_end, res);\n\n            if (!res) {\n\n                kmvc_getbit(bb, src, src_end, res);\n\n                if (!res) {     // fill whole 8x8 block\n\n                    if (src >= src_end) {\n\n                        av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    val = *src++;\n\n                    for (i = 0; i < 64; i++)\n\n                        BLK(ctx->cur, bx + (i & 0x7), by + (i >> 3)) = val;\n\n                } else {        // copy block from previous frame\n\n                    for (i = 0; i < 64; i++)\n\n                        BLK(ctx->cur, bx + (i & 0x7), by + (i >> 3)) =\n\n                            BLK(ctx->prev, bx + (i & 0x7), by + (i >> 3));\n\n                }\n\n            } else {            // handle four 4x4 subblocks\n\n                for (i = 0; i < 4; i++) {\n\n                    l0x = bx + (i & 1) * 4;\n\n                    l0y = by + (i & 2) * 2;\n\n                    kmvc_getbit(bb, src, src_end, res);\n\n                    if (!res) {\n\n                        kmvc_getbit(bb, src, src_end, res);\n\n                        if (!res) {     // fill whole 4x4 block\n\n                            if (src >= src_end) {\n\n                                av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                return AVERROR_INVALIDDATA;\n\n                            }\n\n                            val = *src++;\n\n                            for (j = 0; j < 16; j++)\n\n                                BLK(ctx->cur, l0x + (j & 3), l0y + (j >> 2)) = val;\n\n                        } else {        // copy block\n\n                            if (src >= src_end) {\n\n                                av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                return AVERROR_INVALIDDATA;\n\n                            }\n\n                            val = *src++;\n\n                            mx = (val & 0xF) - 8;\n\n                            my = (val >> 4) - 8;\n\n                            for (j = 0; j < 16; j++)\n\n                                BLK(ctx->cur, l0x + (j & 3), l0y + (j >> 2)) =\n\n                                    BLK(ctx->prev, l0x + (j & 3) + mx, l0y + (j >> 2) + my);\n\n                        }\n\n                    } else {    // descend to 2x2 sub-sub-blocks\n\n                        for (j = 0; j < 4; j++) {\n\n                            l1x = l0x + (j & 1) * 2;\n\n                            l1y = l0y + (j & 2);\n\n                            kmvc_getbit(bb, src, src_end, res);\n\n                            if (!res) {\n\n                                kmvc_getbit(bb, src, src_end, res);\n\n                                if (!res) {     // fill whole 2x2 block\n\n                                    if (src >= src_end) {\n\n                                        av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                        return AVERROR_INVALIDDATA;\n\n                                    }\n\n                                    val = *src++;\n\n                                    BLK(ctx->cur, l1x, l1y) = val;\n\n                                    BLK(ctx->cur, l1x + 1, l1y) = val;\n\n                                    BLK(ctx->cur, l1x, l1y + 1) = val;\n\n                                    BLK(ctx->cur, l1x + 1, l1y + 1) = val;\n\n                                } else {        // copy block\n\n                                    if (src >= src_end) {\n\n                                        av_log(ctx->avctx, AV_LOG_ERROR, \"Data overrun\\n\");\n\n                                        return AVERROR_INVALIDDATA;\n\n                                    }\n\n                                    val = *src++;\n\n                                    mx = (val & 0xF) - 8;\n\n                                    my = (val >> 4) - 8;\n\n                                    BLK(ctx->cur, l1x, l1y) = BLK(ctx->prev, l1x + mx, l1y + my);\n\n                                    BLK(ctx->cur, l1x + 1, l1y) =\n\n                                        BLK(ctx->prev, l1x + 1 + mx, l1y + my);\n\n                                    BLK(ctx->cur, l1x, l1y + 1) =\n\n                                        BLK(ctx->prev, l1x + mx, l1y + 1 + my);\n\n                                    BLK(ctx->cur, l1x + 1, l1y + 1) =\n\n                                        BLK(ctx->prev, l1x + 1 + mx, l1y + 1 + my);\n\n                                }\n\n                            } else {    // read values for block\n\n                                BLK(ctx->cur, l1x, l1y) = *src++;\n\n                                BLK(ctx->cur, l1x + 1, l1y) = *src++;\n\n                                BLK(ctx->cur, l1x, l1y + 1) = *src++;\n\n                                BLK(ctx->cur, l1x + 1, l1y + 1) = *src++;\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n    return 0;\n\n}\n", "idx": 22818, "_split": "valid", "_hash": "097070912be623bbd83c3faf03738701"}
{"project": "FFmpeg", "commit_id": "4a6a29a7fbf023b19797c38a86099d9f81d25524", "target": 0, "func": "static int amr_nb_decode_frame(AVCodecContext *avctx, void *data,\n\n                               int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    AMRContext *s      = avctx->priv_data;\n\n    static const uint8_t block_size[16] = { 12, 13, 15, 17, 19, 20, 26, 31, 5, 0, 0, 0, 0, 0, 0, 0 };\n\n    enum Mode dec_mode;\n\n    int packet_size;\n\n\n\n    av_dlog(avctx, \"amr_decode_frame buf=%p buf_size=%d frame_count=%d!!\\n\",\n\n            buf, buf_size, avctx->frame_number);\n\n\n\n    dec_mode    = (buf[0] >> 3) & 0x000F;\n\n    packet_size = block_size[dec_mode] + 1;\n\n\n\n    if (packet_size > buf_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"amr frame too short (%u, should be %u)\\n\",\n\n               buf_size, packet_size);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    av_dlog(avctx, \"packet_size=%d buf= 0x%X %X %X %X\\n\",\n\n              packet_size, buf[0], buf[1], buf[2], buf[3]);\n\n    /* call decoder */\n\n    Decoder_Interface_Decode(s->dec_state, buf, data, 0);\n\n    *data_size = 160 * 2;\n\n\n\n    return packet_size;\n\n}\n", "idx": 22822, "_split": "valid", "_hash": "b3c52574e53b340dc49aa82a508440d5"}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_h_loop_filter_chroma422_mbaff_msa(uint8_t *src,\n\n                                                  int32_t stride,\n\n                                                  int32_t alpha_in,\n\n                                                  int32_t beta_in,\n\n                                                  int8_t *tc0)\n\n{\n\n    int32_t col, tc_val;\n\n    int16_t out0, out1;\n\n    v16u8 alpha, beta, res;\n\n\n\n    alpha = (v16u8) __msa_fill_b(alpha_in);\n\n    beta = (v16u8) __msa_fill_b(beta_in);\n\n\n\n    for (col = 0; col < 4; col++) {\n\n        tc_val = (tc0[col] - 1) + 1;\n\n\n\n        if (tc_val <= 0) {\n\n            src += 4 * stride;\n\n            continue;\n\n        }\n\n\n\n        AVC_LPF_H_2BYTE_CHROMA_422(src, stride, tc_val, alpha, beta, res);\n\n\n\n        out0 = __msa_copy_s_h((v8i16) res, 0);\n\n        out1 = __msa_copy_s_h((v8i16) res, 1);\n\n\n\n        STORE_HWORD((src - 1), out0);\n\n        src += stride;\n\n        STORE_HWORD((src - 1), out1);\n\n        src += stride;\n\n    }\n\n}\n", "idx": 22825, "_split": "valid", "_hash": "b2197a97406b86479cc1cbea253e9364"}
{"project": "FFmpeg", "commit_id": "a0a872d0733f60876b0c93f236bc4606f36fbf89", "target": 0, "func": "static void copy_cell(Indeo3DecodeContext *ctx, Plane *plane, Cell *cell)\n\n{\n\n    int     h, w, mv_x, mv_y, offset, offset_dst;\n\n    uint8_t *src, *dst;\n\n\n\n    /* setup output and reference pointers */\n\n    offset_dst  = (cell->ypos << 2) * plane->pitch + (cell->xpos << 2);\n\n    dst         = plane->pixels[ctx->buf_sel] + offset_dst;\n\n    mv_y        = cell->mv_ptr[0];\n\n    mv_x        = cell->mv_ptr[1];\n\n    offset      = offset_dst + mv_y * plane->pitch + mv_x;\n\n    src         = plane->pixels[ctx->buf_sel ^ 1] + offset;\n\n\n\n    h = cell->height << 2;\n\n\n\n    for (w = cell->width; w > 0;) {\n\n        /* copy using 16xH blocks */\n\n        if (!((cell->xpos << 2) & 15) && w >= 4) {\n\n            for (; w >= 4; src += 16, dst += 16, w -= 4)\n\n                ctx->dsp.put_no_rnd_pixels_tab[0][0](dst, src, plane->pitch, h);\n\n        }\n\n\n\n        /* copy using 8xH blocks */\n\n        if (!((cell->xpos << 2) & 7) && w >= 2) {\n\n            ctx->dsp.put_no_rnd_pixels_tab[1][0](dst, src, plane->pitch, h);\n\n            w -= 2;\n\n            src += 8;\n\n            dst += 8;\n\n        }\n\n\n\n        if (w >= 1) {\n\n            ctx->dsp.put_no_rnd_pixels_tab[2][0](dst, src, plane->pitch, h);\n\n            w--;\n\n            src += 4;\n\n            dst += 4;\n\n        }\n\n    }\n\n}\n", "idx": 22828, "_split": "valid", "_hash": "6255c9f32f0835e902e2f5efb165758f"}
{"project": "FFmpeg", "commit_id": "831274fba4b14c542458ce5a3d0135b49499299a", "target": 1, "func": "static void flac_lpc_16_c(int32_t *decoded, const int coeffs[32],\n\n                          int pred_order, int qlevel, int len)\n\n{\n\n    int i, j;\n\n\n\n    for (i = pred_order; i < len - 1; i += 2, decoded += 2) {\n\n        int c = coeffs[0];\n\n        int d = decoded[0];\n\n        int s0 = 0, s1 = 0;\n\n        for (j = 1; j < pred_order; j++) {\n\n            s0 += c*d;\n\n            d = decoded[j];\n\n            s1 += c*d;\n\n            c = coeffs[j];\n\n        }\n\n        s0 += c*d;\n\n        d = decoded[j] += s0 >> qlevel;\n\n        s1 += c*d;\n\n        decoded[j + 1] += s1 >> qlevel;\n\n    }\n\n    if (i < len) {\n\n        int sum = 0;\n\n        for (j = 0; j < pred_order; j++)\n\n            sum += coeffs[j] * decoded[j];\n\n        decoded[j] += sum >> qlevel;\n\n    }\n\n}\n", "idx": 22850, "_split": "valid", "_hash": "84f07e53a65c2ece3bca50cab227f59b"}
{"project": "FFmpeg", "commit_id": "fc86f88b32a288b252a088ee3c77b4f6219d54d5", "target": 1, "func": "int ff_h264_decode_ref_pic_marking(H264Context *h, GetBitContext *gb,\n\n                                   int first_slice)\n\n{\n\n    MpegEncContext * const s = &h->s;\n\n    int i, ret;\n\n    MMCO mmco_temp[MAX_MMCO_COUNT], *mmco = first_slice ? h->mmco : mmco_temp;\n\n    int mmco_index = 0;\n\n\n\n    if (h->nal_unit_type == NAL_IDR_SLICE){ // FIXME fields\n\n        s->broken_link = get_bits1(gb) - 1;\n\n        if (get_bits1(gb)){\n\n            mmco[0].opcode = MMCO_LONG;\n\n            mmco[0].long_arg = 0;\n\n            mmco_index = 1;\n\n        }\n\n    } else {\n\n        if (get_bits1(gb)) { // adaptive_ref_pic_marking_mode_flag\n\n            for (i = 0; i < MAX_MMCO_COUNT; i++) {\n\n                MMCOOpcode opcode = get_ue_golomb_31(gb);\n\n\n\n                mmco[i].opcode = opcode;\n\n                if (opcode == MMCO_SHORT2UNUSED || opcode == MMCO_SHORT2LONG){\n\n                    mmco[i].short_pic_num =\n\n                        (h->curr_pic_num - get_ue_golomb(gb) - 1) &\n\n                            (h->max_pic_num - 1);\n\n#if 0\n\n                    if (mmco[i].short_pic_num >= h->short_ref_count ||\n\n                        h->short_ref[ mmco[i].short_pic_num ] == NULL){\n\n                        av_log(s->avctx, AV_LOG_ERROR,\n\n                               \"illegal short ref in memory management control \"\n\n                               \"operation %d\\n\", mmco);\n\n                        return -1;\n\n                    }\n\n#endif\n\n                }\n\n                if (opcode == MMCO_SHORT2LONG || opcode == MMCO_LONG2UNUSED ||\n\n                    opcode == MMCO_LONG || opcode == MMCO_SET_MAX_LONG) {\n\n                    unsigned int long_arg = get_ue_golomb_31(gb);\n\n                    if (long_arg >= 32 ||\n\n                        (long_arg >= 16 && !(opcode == MMCO_SET_MAX_LONG &&\n\n                                             long_arg == 16) &&\n\n                         !(opcode == MMCO_LONG2UNUSED && FIELD_PICTURE))){\n\n                        av_log(h->s.avctx, AV_LOG_ERROR,\n\n                               \"illegal long ref in memory management control \"\n\n                               \"operation %d\\n\", opcode);\n\n                        return -1;\n\n                    }\n\n                    mmco[i].long_arg = long_arg;\n\n                }\n\n\n\n                if (opcode > (unsigned) MMCO_LONG){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR,\n\n                           \"illegal memory management control operation %d\\n\",\n\n                           opcode);\n\n                    return -1;\n\n                }\n\n                if (opcode == MMCO_END)\n\n                    break;\n\n            }\n\n            mmco_index = i;\n\n        } else {\n\n            if (first_slice) {\n\n                ret = ff_generate_sliding_window_mmcos(h, first_slice);\n\n                if (ret < 0 && s->avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return ret;\n\n            }\n\n            mmco_index = -1;\n\n        }\n\n    }\n\n\n\n    if (first_slice && mmco_index != -1) {\n\n        h->mmco_index = mmco_index;\n\n    } else if (!first_slice && mmco_index >= 0 &&\n\n               (mmco_index != h->mmco_index ||\n\n                (i = check_opcodes(h->mmco, mmco_temp, mmco_index)))) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR,\n\n               \"Inconsistent MMCO state between slices [%d, %d, %d]\\n\",\n\n               mmco_index, h->mmco_index, i);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22890, "_split": "valid", "_hash": "8e6111b46747d328387dc948a1651dd0"}
{"project": "FFmpeg", "commit_id": "9d0b45ade864f3d2ccd8610149fe1fff53c4e937", "target": 1, "func": "static int rprobe(AVFormatContext *s, uint8_t *enc_header, const uint8_t *r_val)\n\n{\n\n    OMAContext *oc = s->priv_data;\n\n    unsigned int pos;\n\n    struct AVDES av_des;\n\n\n\n    if (!enc_header || !r_val)\n\n        return -1;\n\n\n\n    /* m_val */\n\n    av_des_init(&av_des, r_val, 192, 1);\n\n    av_des_crypt(&av_des, oc->m_val, &enc_header[48], 1, NULL, 1);\n\n\n\n    /* s_val */\n\n    av_des_init(&av_des, oc->m_val, 64, 0);\n\n    av_des_crypt(&av_des, oc->s_val, NULL, 1, NULL, 0);\n\n\n\n    /* sm_val */\n\n    pos = OMA_ENC_HEADER_SIZE + oc->k_size + oc->e_size;\n\n    av_des_init(&av_des, oc->s_val, 64, 0);\n\n    av_des_mac(&av_des, oc->sm_val, &enc_header[pos], (oc->i_size >> 3));\n\n\n\n    pos += oc->i_size;\n\n\n\n    return memcmp(&enc_header[pos], oc->sm_val, 8) ? -1 : 0;\n\n}\n", "idx": 22895, "_split": "valid", "_hash": "2b8851a4e72deacf0b936eb2607cca2c"}
{"project": "FFmpeg", "commit_id": "dcbe15813ed09cf491e75a21cce0e751f5bc2b34", "target": 0, "func": "static int check_opcodes(MMCO *mmco1, MMCO *mmco2, int n_mmcos)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < n_mmcos; i++) {\n\n        if (mmco1[i].opcode != mmco2[i].opcode)\n\n            return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 22902, "_split": "valid", "_hash": "04bb4f81d0679e653b74ac7aba939637"}
{"project": "FFmpeg", "commit_id": "6796a1dd8c14843b77925cb83a3ef88706ae1dd0", "target": 0, "func": "void ff_put_h264_qpel4_mc03_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_vt_qrt_4w_msa(src - (stride * 2), stride, dst, stride, 4, 1);\n\n}\n", "idx": 22937, "_split": "valid", "_hash": "c13ce9898b4dbda79bbc9765659585a3"}
{"project": "FFmpeg", "commit_id": "189fbcede89bb5d7ec6c3b05d1e30f1bab3a060a", "target": 0, "func": "static int tak_parse(AVCodecParserContext *s, AVCodecContext *avctx,\n\n                     const uint8_t **poutbuf, int *poutbuf_size,\n\n                     const uint8_t *buf, int buf_size)\n\n{\n\n    TAKParseContext *t = s->priv_data;\n\n    ParseContext *pc = &t->pc;\n\n    int next = END_NOT_FOUND;\n\n    GetBitContext gb;\n\n    int consumed = 0;\n\n    int needed = buf_size ? TAK_MAX_FRAME_HEADER_BYTES : 8;\n\n\n\n    if (s->flags & PARSER_FLAG_COMPLETE_FRAMES) {\n\n        TAKStreamInfo ti;\n\n        init_get_bits(&gb, buf, buf_size);\n\n        if (!ff_tak_decode_frame_header(avctx, &gb, &ti, 127))\n\n            s->duration = t->ti.last_frame_samples ? t->ti.last_frame_samples :\n\n                                                     t->ti.frame_samples;\n\n        *poutbuf      = buf;\n\n        *poutbuf_size = buf_size;\n\n        return buf_size;\n\n    }\n\n\n\n    while (buf_size || t->index + needed <= pc->index) {\n\n        if (buf_size && t->index + TAK_MAX_FRAME_HEADER_BYTES > pc->index) {\n\n            int tmp_buf_size = FFMIN(2 * TAK_MAX_FRAME_HEADER_BYTES, buf_size);\n\n            const uint8_t *tmp_buf = buf;\n\n\n\n            ff_combine_frame(pc, END_NOT_FOUND, &tmp_buf, &tmp_buf_size);\n\n            consumed += tmp_buf_size;\n\n            buf      += tmp_buf_size;\n\n            buf_size -= tmp_buf_size;\n\n        }\n\n\n\n        for (; t->index + needed <= pc->index; t->index++) {\n\n            if (pc->buffer[ t->index     ] == 0xFF &&\n\n                pc->buffer[ t->index + 1 ] == 0xA0) {\n\n                TAKStreamInfo ti;\n\n\n\n                init_get_bits(&gb, pc->buffer + t->index,\n\n                              8 * (pc->index - t->index));\n\n                if (!ff_tak_decode_frame_header(avctx, &gb,\n\n                        pc->frame_start_found ? &ti : &t->ti, 127) &&\n\n                    !ff_tak_check_crc(pc->buffer + t->index,\n\n                                      get_bits_count(&gb) / 8)) {\n\n                    if (!pc->frame_start_found) {\n\n                        pc->frame_start_found = 1;\n\n                        s->duration = t->ti.last_frame_samples ?\n\n                                      t->ti.last_frame_samples :\n\n                                      t->ti.frame_samples;\n\n                    } else {\n\n                        pc->frame_start_found = 0;\n\n                        next = t->index - pc->index;\n\n                        t->index = 0;\n\n                        goto found;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\nfound:\n\n\n\n    if (consumed && !buf_size && next == END_NOT_FOUND ||\n\n        ff_combine_frame(pc, next, &buf, &buf_size) < 0) {\n\n        *poutbuf      = NULL;\n\n        *poutbuf_size = 0;\n\n        return buf_size + consumed;\n\n    }\n\n\n\n    if (next != END_NOT_FOUND) {\n\n        next += consumed;\n\n        pc->overread = FFMAX(0, -next);\n\n    }\n\n\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return next;\n\n}\n", "idx": 22958, "_split": "valid", "_hash": "90bf37e98a01e17eb184ade9bf7a5304"}
{"project": "FFmpeg", "commit_id": "0b54f3c0878a3acaa9142e4f24942e762d97e350", "target": 1, "func": "static int gif_read_header(AVFormatContext * s1,\n\n                           AVFormatParameters * ap)\n\n{\n\n    GifState *s = s1->priv_data;\n\n    ByteIOContext *f = s1->pb;\n\n    AVStream *st;\n\n\n\n    s->f = f;\n\n    if (gif_read_header1(s) < 0)\n\n        return -1;\n\n\n\n    /* allocate image buffer */\n\n    s->image_linesize = s->screen_width * 3;\n\n    s->image_buf = av_malloc(s->screen_height * s->image_linesize);\n\n    if (!s->image_buf)\n\n        return AVERROR(ENOMEM);\n\n    s->pix_fmt = PIX_FMT_RGB24;\n\n    /* now we are ready: build format streams */\n\n    st = av_new_stream(s1, 0);\n\n    if (!st)\n\n        return -1;\n\n\n\n    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n    st->codec->codec_id = CODEC_ID_RAWVIDEO;\n\n    st->codec->time_base.den = 5;\n\n    st->codec->time_base.num = 1;\n\n    /* XXX: check if screen size is always valid */\n\n    st->codec->width = s->screen_width;\n\n    st->codec->height = s->screen_height;\n\n    st->codec->pix_fmt = PIX_FMT_RGB24;\n\n    return 0;\n\n}\n", "idx": 22978, "_split": "valid", "_hash": "905de5e368e99cb8ee4c0bf30b8eba17"}
{"project": "FFmpeg", "commit_id": "0a771e6b32429f9195d431415bf707c28ef31fff", "target": 0, "func": "static int decode_frame_common(AVCodecContext *avctx, PNGDecContext *s,\n\n                               AVFrame *p, AVPacket *avpkt)\n\n{\n\n    AVDictionary **metadatap = NULL;\n\n    uint32_t tag, length;\n\n    int decode_next_dat = 0;\n\n    int ret;\n\n\n\n    for (;;) {\n\n        length = bytestream2_get_bytes_left(&s->gb);\n\n        if (length <= 0) {\n\n\n\n            if (avctx->codec_id == AV_CODEC_ID_PNG &&\n\n                avctx->skip_frame == AVDISCARD_ALL) {\n\n                return 0;\n\n            }\n\n\n\n            if (CONFIG_APNG_DECODER && avctx->codec_id == AV_CODEC_ID_APNG && length == 0) {\n\n                if (!(s->pic_state & PNG_IDAT))\n\n                    return 0;\n\n                else\n\n                    goto exit_loop;\n\n            }\n\n            av_log(avctx, AV_LOG_ERROR, \"%d bytes left\\n\", length);\n\n            if (   s->pic_state & PNG_ALLIMAGE\n\n                && avctx->strict_std_compliance <= FF_COMPLIANCE_NORMAL)\n\n                goto exit_loop;\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        length = bytestream2_get_be32(&s->gb);\n\n        if (length > 0x7fffffff || length > bytestream2_get_bytes_left(&s->gb)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"chunk too big\\n\");\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n        tag = bytestream2_get_le32(&s->gb);\n\n        if (avctx->debug & FF_DEBUG_STARTCODE)\n\n            av_log(avctx, AV_LOG_DEBUG, \"png: tag=%s length=%u\\n\",\n\n                   av_fourcc2str(tag), length);\n\n\n\n        if (avctx->codec_id == AV_CODEC_ID_PNG &&\n\n            avctx->skip_frame == AVDISCARD_ALL) {\n\n            switch(tag) {\n\n            case MKTAG('I', 'H', 'D', 'R'):\n\n            case MKTAG('p', 'H', 'Y', 's'):\n\n            case MKTAG('t', 'E', 'X', 't'):\n\n            case MKTAG('I', 'D', 'A', 'T'):\n\n            case MKTAG('t', 'R', 'N', 'S'):\n\n                break;\n\n            default:\n\n                goto skip_tag;\n\n            }\n\n        }\n\n\n\n        metadatap = &p->metadata;\n\n        switch (tag) {\n\n        case MKTAG('I', 'H', 'D', 'R'):\n\n            if ((ret = decode_ihdr_chunk(avctx, s, length)) < 0)\n\n                goto fail;\n\n            break;\n\n        case MKTAG('p', 'H', 'Y', 's'):\n\n            if ((ret = decode_phys_chunk(avctx, s)) < 0)\n\n                goto fail;\n\n            break;\n\n        case MKTAG('f', 'c', 'T', 'L'):\n\n            if (!CONFIG_APNG_DECODER || avctx->codec_id != AV_CODEC_ID_APNG)\n\n                goto skip_tag;\n\n            if ((ret = decode_fctl_chunk(avctx, s, length)) < 0)\n\n                goto fail;\n\n            decode_next_dat = 1;\n\n            break;\n\n        case MKTAG('f', 'd', 'A', 'T'):\n\n            if (!CONFIG_APNG_DECODER || avctx->codec_id != AV_CODEC_ID_APNG)\n\n                goto skip_tag;\n\n            if (!decode_next_dat) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            bytestream2_get_be32(&s->gb);\n\n            length -= 4;\n\n            /* fallthrough */\n\n        case MKTAG('I', 'D', 'A', 'T'):\n\n            if (CONFIG_APNG_DECODER && avctx->codec_id == AV_CODEC_ID_APNG && !decode_next_dat)\n\n                goto skip_tag;\n\n            if ((ret = decode_idat_chunk(avctx, s, length, p)) < 0)\n\n                goto fail;\n\n            break;\n\n        case MKTAG('P', 'L', 'T', 'E'):\n\n            if (decode_plte_chunk(avctx, s, length) < 0)\n\n                goto skip_tag;\n\n            break;\n\n        case MKTAG('t', 'R', 'N', 'S'):\n\n            if (decode_trns_chunk(avctx, s, length) < 0)\n\n                goto skip_tag;\n\n            break;\n\n        case MKTAG('t', 'E', 'X', 't'):\n\n            if (decode_text_chunk(s, length, 0, metadatap) < 0)\n\n                av_log(avctx, AV_LOG_WARNING, \"Broken tEXt chunk\\n\");\n\n            bytestream2_skip(&s->gb, length + 4);\n\n            break;\n\n        case MKTAG('z', 'T', 'X', 't'):\n\n            if (decode_text_chunk(s, length, 1, metadatap) < 0)\n\n                av_log(avctx, AV_LOG_WARNING, \"Broken zTXt chunk\\n\");\n\n            bytestream2_skip(&s->gb, length + 4);\n\n            break;\n\n        case MKTAG('s', 'T', 'E', 'R'): {\n\n            int mode = bytestream2_get_byte(&s->gb);\n\n            AVStereo3D *stereo3d = av_stereo3d_create_side_data(p);\n\n            if (!stereo3d)\n\n                goto fail;\n\n\n\n            if (mode == 0 || mode == 1) {\n\n                stereo3d->type  = AV_STEREO3D_SIDEBYSIDE;\n\n                stereo3d->flags = mode ? 0 : AV_STEREO3D_FLAG_INVERT;\n\n            } else {\n\n                 av_log(avctx, AV_LOG_WARNING,\n\n                        \"Unknown value in sTER chunk (%d)\\n\", mode);\n\n            }\n\n            bytestream2_skip(&s->gb, 4); /* crc */\n\n            break;\n\n        }\n\n        case MKTAG('i', 'C', 'C', 'P'): {\n\n            if (decode_iccp_chunk(s, length, p) < 0)\n\n                goto fail;\n\n            break;\n\n        }\n\n        case MKTAG('I', 'E', 'N', 'D'):\n\n            if (!(s->pic_state & PNG_ALLIMAGE))\n\n                av_log(avctx, AV_LOG_ERROR, \"IEND without all image\\n\");\n\n            if (!(s->pic_state & (PNG_ALLIMAGE|PNG_IDAT))) {\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            bytestream2_skip(&s->gb, 4); /* crc */\n\n            goto exit_loop;\n\n        default:\n\n            /* skip tag */\n\nskip_tag:\n\n            bytestream2_skip(&s->gb, length + 4);\n\n            break;\n\n        }\n\n    }\n\nexit_loop:\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_PNG &&\n\n        avctx->skip_frame == AVDISCARD_ALL) {\n\n        return 0;\n\n    }\n\n\n\n    if (s->bits_per_pixel <= 4)\n\n        handle_small_bpp(s, p);\n\n\n\n    /* apply transparency if needed */\n\n    if (s->has_trns && s->color_type != PNG_COLOR_TYPE_PALETTE) {\n\n        size_t byte_depth = s->bit_depth > 8 ? 2 : 1;\n\n        size_t raw_bpp = s->bpp - byte_depth;\n\n        unsigned x, y;\n\n\n\n        av_assert0(s->bit_depth > 1);\n\n\n\n        for (y = 0; y < s->height; ++y) {\n\n            uint8_t *row = &s->image_buf[s->image_linesize * y];\n\n\n\n            /* since we're updating in-place, we have to go from right to left */\n\n            for (x = s->width; x > 0; --x) {\n\n                uint8_t *pixel = &row[s->bpp * (x - 1)];\n\n                memmove(pixel, &row[raw_bpp * (x - 1)], raw_bpp);\n\n\n\n                if (!memcmp(pixel, s->transparent_color_be, raw_bpp)) {\n\n                    memset(&pixel[raw_bpp], 0, byte_depth);\n\n                } else {\n\n                    memset(&pixel[raw_bpp], 0xff, byte_depth);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    /* handle P-frames only if a predecessor frame is available */\n\n    if (s->last_picture.f->data[0]) {\n\n        if (   !(avpkt->flags & AV_PKT_FLAG_KEY) && avctx->codec_tag != AV_RL32(\"MPNG\")\n\n            && s->last_picture.f->width == p->width\n\n            && s->last_picture.f->height== p->height\n\n            && s->last_picture.f->format== p->format\n\n         ) {\n\n            if (CONFIG_PNG_DECODER && avctx->codec_id != AV_CODEC_ID_APNG)\n\n                handle_p_frame_png(s, p);\n\n            else if (CONFIG_APNG_DECODER &&\n\n                     avctx->codec_id == AV_CODEC_ID_APNG &&\n\n                     (ret = handle_p_frame_apng(avctx, s, p)) < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n    ff_thread_report_progress(&s->picture, INT_MAX, 0);\n\n    ff_thread_report_progress(&s->previous_picture, INT_MAX, 0);\n\n\n\n    return 0;\n\n\n\nfail:\n\n    ff_thread_report_progress(&s->picture, INT_MAX, 0);\n\n    ff_thread_report_progress(&s->previous_picture, INT_MAX, 0);\n\n    return ret;\n\n}\n", "idx": 23017, "_split": "valid", "_hash": "6d9f7e09ddb422639a0681c93c70833c"}
{"project": "FFmpeg", "commit_id": "e75e603c1a5d1b56b6297d2cbc1f32e6bf7b2b15", "target": 0, "func": "static int sync(AVFormatContext *s, int64_t *timestamp, int *flags, int *stream_index, int64_t *pos){\n\n    RMDemuxContext *rm = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    int len, num, res, i;\n\n    AVStream *st;\n\n    uint32_t state=0xFFFFFFFF;\n\n\n\n    while(!url_feof(pb)){\n\n        *pos= url_ftell(pb) - 3;\n\n        if(rm->remaining_len > 0){\n\n            num= rm->current_stream;\n\n            len= rm->remaining_len;\n\n            *timestamp = AV_NOPTS_VALUE;\n\n            *flags= 0;\n\n        }else{\n\n            state= (state<<8) + get_byte(pb);\n\n\n\n            if(state == MKBETAG('I', 'N', 'D', 'X')){\n\n                int n_pkts, expected_len;\n\n                len = get_be32(pb);\n\n                url_fskip(pb, 2);\n\n                n_pkts = get_be32(pb);\n\n                expected_len = 20 + n_pkts * 14;\n\n                if (len == 20)\n\n                    /* some files don't add index entries to chunk size... */\n\n                    len = expected_len;\n\n                else if (len != expected_len)\n\n                    av_log(s, AV_LOG_WARNING,\n\n                           \"Index size %d (%d pkts) is wrong, should be %d.\\n\",\n\n                           len, n_pkts, expected_len);\n\n                len -= 14; // we already read part of the index header\n\n                if(len<0)\n\n                    continue;\n\n                goto skip;\n\n            }\n\n\n\n            if(state > (unsigned)0xFFFF || state < 12)\n\n                continue;\n\n            len=state;\n\n            state= 0xFFFFFFFF;\n\n\n\n            num = get_be16(pb);\n\n            *timestamp = get_be32(pb);\n\n            res= get_byte(pb); /* reserved */\n\n            *flags = get_byte(pb); /* flags */\n\n\n\n\n\n            len -= 12;\n\n        }\n\n        for(i=0;i<s->nb_streams;i++) {\n\n            st = s->streams[i];\n\n            if (num == st->id)\n\n                break;\n\n        }\n\n        if (i == s->nb_streams) {\n\nskip:\n\n            /* skip packet if unknown number */\n\n            url_fskip(pb, len);\n\n            rm->remaining_len = 0;\n\n            continue;\n\n        }\n\n        *stream_index= i;\n\n\n\n        return len;\n\n    }\n\n    return -1;\n\n}\n", "idx": 23019, "_split": "valid", "_hash": "ebf0b55bee3b46d1b9053a5a8cfc62c7"}
{"project": "FFmpeg", "commit_id": "ef4c71e8f83a46fb31a11f0a066efb90821c579f", "target": 0, "func": "static int config_props(AVFilterLink *link)\n\n{\n\n    UnsharpContext *unsharp = link->dst->priv;\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(link->format);\n\n\n\n    unsharp->hsub = desc->log2_chroma_w;\n\n    unsharp->vsub = desc->log2_chroma_h;\n\n\n\n    init_filter_param(link->dst, &unsharp->luma,   \"luma\",   link->w);\n\n    init_filter_param(link->dst, &unsharp->chroma, \"chroma\", SHIFTUP(link->w, unsharp->hsub));\n\n\n\n    return 0;\n\n}\n", "idx": 23022, "_split": "valid", "_hash": "8227084eb6bc4ef0bc7477b44b35670d"}
{"project": "FFmpeg", "commit_id": "dc2e4c2e532b80565f5fbacd3a24a6db7567c257", "target": 0, "func": "static int64_t wav_seek_tag(AVIOContext *s, int64_t offset, int whence)\n\n{\n\n    offset += offset < INT64_MAX && offset & 1;\n\n\n\n    return avio_seek(s, offset, whence);\n\n}\n", "idx": 23027, "_split": "valid", "_hash": "b187e9129e3ed23f351a6589a0b5a30a"}
{"project": "FFmpeg", "commit_id": "91abb473fb8432226918da4fe03365ebaf688978", "target": 0, "func": "static void put_pixels_y2_mmx(UINT8 *block, const UINT8 *pixels, int line_size, int h)\n\n{\n\n#if 0\n\n  UINT8 *p;\n\n  const UINT8 *pix;\n\n  p = block;\n\n  pix = pixels;\n\n  MOVQ_ZERO(mm7);\n\n  MOVQ_WONE(mm4);\n\n  JUMPALIGN();\n\n  do {\n\n    __asm __volatile(\n\n\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\"movq\t%2, %%mm1\\n\\t\"\n\n\t\"movq\t%%mm0, %%mm2\\n\\t\"\n\n\t\"movq\t%%mm1, %%mm3\\n\\t\"\n\n\t\"punpcklbw %%mm7, %%mm0\\n\\t\"\n\n\t\"punpcklbw %%mm7, %%mm1\\n\\t\"\n\n\t\"punpckhbw %%mm7, %%mm2\\n\\t\"\n\n\t\"punpckhbw %%mm7, %%mm3\\n\\t\"\n\n\t\"paddusw %%mm1, %%mm0\\n\\t\"\n\n\t\"paddusw %%mm3, %%mm2\\n\\t\"\n\n\t\"paddusw %%mm4, %%mm0\\n\\t\"\n\n\t\"paddusw %%mm4, %%mm2\\n\\t\"\n\n\t\"psrlw\t$1, %%mm0\\n\\t\"\n\n\t\"psrlw\t$1, %%mm2\\n\\t\"\n\n\t\"packuswb  %%mm2, %%mm0\\n\\t\"\n\n\t\"movq\t%%mm0, %0\\n\\t\"\n\n\t:\"=m\"(*p)\n\n\t:\"m\"(*pix),\n\n\t \"m\"(*(pix+line_size))\n\n\t:\"memory\");\n\n   pix += line_size;\n\n   p += line_size;\n\n  } while (--h);\n\n#else\n\n  __asm __volatile(\n\n  \tMOVQ_BFE(%%mm7)\n\n\t\"lea (%3, %3), %%eax\t\\n\\t\"\n\n\t\"movq (%1), %%mm0\t\\n\\t\"\n\n\t\".balign 8     \t\t\\n\\t\"\n\n\t\"1:\t\t\t\\n\\t\"\n\n\t\"movq (%1, %3), %%mm1\t\\n\\t\"\n\n\t\"movq (%1, %%eax),%%mm2\t\\n\\t\"\n\n\tPAVG_MMX(%%mm1, %%mm0)\n\n\t\"movq %%mm6, (%2)\t\\n\\t\"\n\n\tPAVG_MMX(%%mm2, %%mm1)\n\n\t\"movq %%mm6, (%2, %3)\t\\n\\t\"\n\n\t\"addl %%eax, %1\t\t\\n\\t\"\n\n\t\"addl %%eax, %2\t\t\\n\\t\"\n\n#ifdef LONG_UNROLL\n\n\t\"movq (%1, %3), %%mm1\t\\n\\t\"\n\n\t\"movq (%1, %%eax),%%mm0\t\\n\\t\"\n\n\tPAVG_MMX(%%mm1, %%mm2)\n\n\t\"movq %%mm6, (%2)\t\\n\\t\"\n\n\tPAVG_MMX(%%mm0, %%mm1)\n\n\t\"movq %%mm6, (%2, %3)\t\\n\\t\"\n\n\t\"addl %%eax, %1\t\t\\n\\t\"\n\n\t\"addl %%eax, %2\t\t\\n\\t\"\n\n\t\"subl $4, %0\t\t\\n\\t\"\n\n#else\n\n\t\"subl $2, %0\t\t\\n\\t\"\n\n#endif\n\n\t\"jnz 1b\t\t\t\\n\\t\"\n\n\t:\"+g\"(h), \"+S\"(pixels), \"+D\"(block)\n\n\t:\"r\"(line_size)\n\n\t:\"eax\", \"memory\");\n\n#endif\n\n\n\n\n\n}\n", "idx": 23112, "_split": "valid", "_hash": "7cc16022a184bdb3c87287ecd15f5599"}
{"project": "FFmpeg", "commit_id": "b754978a3b0aa17e7794f64c69bf4491762797fd", "target": 0, "func": "static int av_seek_frame_generic(AVFormatContext *s, \n\n                                 int stream_index, int64_t timestamp)\n\n{\n\n    int index;\n\n    AVStream *st;\n\n    AVIndexEntry *ie;\n\n\n\n    if (!s->index_built) {\n\n        if (is_raw_stream(s)) {\n\n            av_build_index_raw(s);\n\n        } else {\n\n            return -1;\n\n        }\n\n        s->index_built = 1;\n\n    }\n\n\n\n    if (stream_index < 0)\n\n        stream_index = 0;\n\n    st = s->streams[stream_index];\n\n    index = index_search_timestamp(st->index_entries, st->nb_index_entries,\n\n                                   timestamp);\n\n    if (index < 0)\n\n        return -1;\n\n\n\n    /* now we have found the index, we can seek */\n\n    ie = &st->index_entries[index];\n\n    av_read_frame_flush(s);\n\n    url_fseek(&s->pb, ie->pos, SEEK_SET);\n\n    st->cur_dts = ie->timestamp;\n\n    return 0;\n\n}\n", "idx": 23156, "_split": "valid", "_hash": "372559ba76c7f5d33f1553eddc754551"}
{"project": "FFmpeg", "commit_id": "fd34dbea58e097609ff09cf7dcc59f74930195d3", "target": 1, "func": "static int mxf_read_index_table_segment(void *arg, AVIOContext *pb, int tag, int size, UID uid)\n\n{\n\n    MXFIndexTableSegment *segment = arg;\n\n    switch(tag) {\n\n    case 0x3F05:\n\n        segment->edit_unit_byte_count = avio_rb32(pb);\n\n        av_dlog(NULL, \"EditUnitByteCount %d\\n\", segment->edit_unit_byte_count);\n\n        break;\n\n    case 0x3F06:\n\n        segment->index_sid = avio_rb32(pb);\n\n        av_dlog(NULL, \"IndexSID %d\\n\", segment->index_sid);\n\n        break;\n\n    case 0x3F07:\n\n        segment->body_sid = avio_rb32(pb);\n\n        av_dlog(NULL, \"BodySID %d\\n\", segment->body_sid);\n\n        break;\n\n    case 0x3F08:\n\n        segment->slice_count = avio_r8(pb);\n\n        av_dlog(NULL, \"SliceCount %d\\n\", segment->slice_count);\n\n        break;\n\n    case 0x3F09:\n\n        av_dlog(NULL, \"DeltaEntryArray found\\n\");\n\n        return mxf_read_delta_entry_array(pb, segment);\n\n    case 0x3F0A:\n\n        av_dlog(NULL, \"IndexEntryArray found\\n\");\n\n        return mxf_read_index_entry_array(pb, segment);\n\n    case 0x3F0B:\n\n        segment->index_edit_rate.num = avio_rb32(pb);\n\n        segment->index_edit_rate.den = avio_rb32(pb);\n\n        av_dlog(NULL, \"IndexEditRate %d/%d\\n\", segment->index_edit_rate.num,\n\n                segment->index_edit_rate.den);\n\n        break;\n\n    case 0x3F0C:\n\n        segment->index_start_position = avio_rb64(pb);\n\n        av_dlog(NULL, \"IndexStartPosition %\"PRId64\"\\n\", segment->index_start_position);\n\n        break;\n\n    case 0x3F0D:\n\n        segment->index_duration = avio_rb64(pb);\n\n        av_dlog(NULL, \"IndexDuration %\"PRId64\"\\n\", segment->index_duration);\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23160, "_split": "valid", "_hash": "2cc6b0432010fefbbe803a75657f3d49"}
{"project": "FFmpeg", "commit_id": "31c7c0e156975be615479948824c1528952c0731", "target": 1, "func": "static int mov_write_video_tag(AVIOContext *pb, MOVMuxContext *mov, MOVTrack *track)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    char compressor_name[32] = { 0 };\n\n\n\n    avio_wb32(pb, 0); /* size */\n\n    avio_wl32(pb, track->tag); // store it byteswapped\n\n    avio_wb32(pb, 0); /* Reserved */\n\n    avio_wb16(pb, 0); /* Reserved */\n\n    avio_wb16(pb, 1); /* Data-reference index */\n\n\n\n    avio_wb16(pb, 0); /* Codec stream version */\n\n    avio_wb16(pb, 0); /* Codec stream revision (=0) */\n\n    if (track->mode == MODE_MOV) {\n\n        ffio_wfourcc(pb, \"FFMP\"); /* Vendor */\n\n        if (track->enc->codec_id == AV_CODEC_ID_RAWVIDEO) {\n\n            avio_wb32(pb, 0); /* Temporal Quality */\n\n            avio_wb32(pb, 0x400); /* Spatial Quality = lossless*/\n\n        } else {\n\n            avio_wb32(pb, 0x200); /* Temporal Quality = normal */\n\n            avio_wb32(pb, 0x200); /* Spatial Quality = normal */\n\n        }\n\n    } else {\n\n        avio_wb32(pb, 0); /* Reserved */\n\n        avio_wb32(pb, 0); /* Reserved */\n\n        avio_wb32(pb, 0); /* Reserved */\n\n    }\n\n    avio_wb16(pb, track->enc->width); /* Video width */\n\n    avio_wb16(pb, track->height); /* Video height */\n\n    avio_wb32(pb, 0x00480000); /* Horizontal resolution 72dpi */\n\n    avio_wb32(pb, 0x00480000); /* Vertical resolution 72dpi */\n\n    avio_wb32(pb, 0); /* Data size (= 0) */\n\n    avio_wb16(pb, 1); /* Frame count (= 1) */\n\n\n\n    /* FIXME not sure, ISO 14496-1 draft where it shall be set to 0 */\n\n    find_compressor(compressor_name, 32, track);\n\n    avio_w8(pb, strlen(compressor_name));\n\n    avio_write(pb, compressor_name, 31);\n\n\n\n    if (track->mode == MODE_MOV && track->enc->bits_per_coded_sample)\n\n        avio_wb16(pb, track->enc->bits_per_coded_sample);\n\n    else\n\n        avio_wb16(pb, 0x18); /* Reserved */\n\n    avio_wb16(pb, 0xffff); /* Reserved */\n\n    if (track->tag == MKTAG('m','p','4','v'))\n\n        mov_write_esds_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_H263)\n\n        mov_write_d263_tag(pb);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_AVUI ||\n\n            track->enc->codec_id == AV_CODEC_ID_SVQ3) {\n\n        mov_write_extradata_tag(pb, track);\n\n        avio_wb32(pb, 0);\n\n    } else if (track->enc->codec_id == AV_CODEC_ID_DNXHD)\n\n        mov_write_avid_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_HEVC)\n\n        mov_write_hvcc_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_H264 && !TAG_IS_AVCI(track->tag)) {\n\n        mov_write_avcc_tag(pb, track);\n\n        if (track->mode == MODE_IPOD)\n\n            mov_write_uuid_tag_ipod(pb);\n\n    } else if (track->enc->codec_id == AV_CODEC_ID_VC1 && track->vos_len > 0)\n\n        mov_write_dvc1_tag(pb, track);\n\n    else if (track->enc->codec_id == AV_CODEC_ID_VP6F ||\n\n             track->enc->codec_id == AV_CODEC_ID_VP6A) {\n\n        /* Don't write any potential extradata here - the cropping\n\n         * is signalled via the normal width/height fields. */\n\n    } else if (track->enc->codec_id == AV_CODEC_ID_R10K) {\n\n        if (track->enc->codec_tag == MKTAG('R','1','0','k'))\n\n            mov_write_dpxe_tag(pb, track);\n\n    } else if (track->vos_len > 0)\n\n        mov_write_glbl_tag(pb, track);\n\n\n\n    if (track->enc->codec_id != AV_CODEC_ID_H264 &&\n\n        track->enc->codec_id != AV_CODEC_ID_MPEG4 &&\n\n        track->enc->codec_id != AV_CODEC_ID_DNXHD)\n\n        if (track->enc->field_order != AV_FIELD_UNKNOWN)\n\n            mov_write_fiel_tag(pb, track);\n\n\n\n    if (mov->flags & FF_MOV_FLAG_WRITE_COLR)\n\n        mov_write_colr_tag(pb, track);\n\n\n\n    if (track->enc->sample_aspect_ratio.den && track->enc->sample_aspect_ratio.num &&\n\n        track->enc->sample_aspect_ratio.den != track->enc->sample_aspect_ratio.num) {\n\n        mov_write_pasp_tag(pb, track);\n\n    }\n\n\n\n    return update_size(pb, pos);\n\n}\n", "idx": 23187, "_split": "valid", "_hash": "e8e1533ac4390dd54d7c298ae7643eb7"}
{"project": "FFmpeg", "commit_id": "fef7b2e0bef6972d8d48df51e477af7b017d1a38", "target": 0, "func": "static int null_draw_slice(AVFilterLink *link, int y, int h, int slice_dir) { return 0; }\n", "idx": 23249, "_split": "valid", "_hash": "dc3f609b000f6e4531471ad778a88d19"}
{"project": "FFmpeg", "commit_id": "c16e99e3b3c02edcf33245468731d414eab97dac", "target": 0, "func": "D(float, sse)\n\nD(float, avx)\n\nD(int16, mmx)\n\nD(int16, sse2)\n\n\n\nav_cold int swri_rematrix_init_x86(struct SwrContext *s){\n\n#if HAVE_YASM\n\n    int mm_flags = av_get_cpu_flags();\n\n    int nb_in  = av_get_channel_layout_nb_channels(s->in_ch_layout);\n\n    int nb_out = av_get_channel_layout_nb_channels(s->out_ch_layout);\n\n    int num    = nb_in * nb_out;\n\n    int i,j;\n\n\n\n    s->mix_1_1_simd = NULL;\n\n    s->mix_2_1_simd = NULL;\n\n\n\n    if (s->midbuf.fmt == AV_SAMPLE_FMT_S16P){\n\n        if(EXTERNAL_MMX(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_int16_mmx;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_int16_mmx;\n\n        }\n\n        if(EXTERNAL_SSE2(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_int16_sse2;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_int16_sse2;\n\n        }\n\n        s->native_simd_matrix = av_mallocz_array(num,  2 * sizeof(int16_t));\n\n        s->native_simd_one    = av_mallocz(2 * sizeof(int16_t));\n\n        if (!s->native_simd_matrix || !s->native_simd_one)\n\n            return AVERROR(ENOMEM);\n\n\n\n        for(i=0; i<nb_out; i++){\n\n            int sh = 0;\n\n            for(j=0; j<nb_in; j++)\n\n                sh = FFMAX(sh, FFABS(((int*)s->native_matrix)[i * nb_in + j]));\n\n            sh = FFMAX(av_log2(sh) - 14, 0);\n\n            for(j=0; j<nb_in; j++) {\n\n                ((int16_t*)s->native_simd_matrix)[2*(i * nb_in + j)+1] = 15 - sh;\n\n                ((int16_t*)s->native_simd_matrix)[2*(i * nb_in + j)] =\n\n                    ((((int*)s->native_matrix)[i * nb_in + j]) + (1<<sh>>1)) >> sh;\n\n            }\n\n        }\n\n        ((int16_t*)s->native_simd_one)[1] = 14;\n\n        ((int16_t*)s->native_simd_one)[0] = 16384;\n\n    } else if(s->midbuf.fmt == AV_SAMPLE_FMT_FLTP){\n\n        if(EXTERNAL_SSE(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_float_sse;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_float_sse;\n\n        }\n\n        if(EXTERNAL_AVX(mm_flags)) {\n\n            s->mix_1_1_simd = ff_mix_1_1_a_float_avx;\n\n            s->mix_2_1_simd = ff_mix_2_1_a_float_avx;\n\n        }\n\n        s->native_simd_matrix = av_mallocz_array(num, sizeof(float));\n\n        s->native_simd_one = av_mallocz(sizeof(float));\n\n        if (!s->native_simd_matrix || !s->native_simd_one)\n\n            return AVERROR(ENOMEM);\n\n        memcpy(s->native_simd_matrix, s->native_matrix, num * sizeof(float));\n\n        memcpy(s->native_simd_one, s->native_one, sizeof(float));\n\n    }\n\n#endif\n\n\n\n    return 0;\n\n}\n", "idx": 23251, "_split": "valid", "_hash": "96b7ff7a1a3a3fade64a5caf6703f2f4"}
{"project": "FFmpeg", "commit_id": "0c22311b56e66115675c4a96e4c78547886a4171", "target": 0, "func": "static int av_transcode(AVFormatContext **output_files,\n\n                        int nb_output_files,\n\n                        AVFormatContext **input_files,\n\n                        int nb_input_files,\n\n                        AVStreamMap *stream_maps, int nb_stream_maps)\n\n{\n\n    int ret = 0, i, j, k, n, nb_istreams = 0, nb_ostreams = 0;\n\n    AVFormatContext *is, *os;\n\n    AVCodecContext *codec, *icodec;\n\n    AVOutputStream *ost, **ost_table = NULL;\n\n    AVInputStream *ist, **ist_table = NULL;\n\n    AVInputFile *file_table;\n\n    char error[1024];\n\n    int key;\n\n    int want_sdp = 1;\n\n    uint8_t no_packet[MAX_FILES]={0};\n\n    int no_packet_count=0;\n\n\n\n    file_table= av_mallocz(nb_input_files * sizeof(AVInputFile));\n\n    if (!file_table)\n\n        goto fail;\n\n\n\n    /* input stream init */\n\n    j = 0;\n\n    for(i=0;i<nb_input_files;i++) {\n\n        is = input_files[i];\n\n        file_table[i].ist_index = j;\n\n        file_table[i].nb_streams = is->nb_streams;\n\n        j += is->nb_streams;\n\n    }\n\n    nb_istreams = j;\n\n\n\n    ist_table = av_mallocz(nb_istreams * sizeof(AVInputStream *));\n\n    if (!ist_table)\n\n        goto fail;\n\n\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = av_mallocz(sizeof(AVInputStream));\n\n        if (!ist)\n\n            goto fail;\n\n        ist_table[i] = ist;\n\n    }\n\n    j = 0;\n\n    for(i=0;i<nb_input_files;i++) {\n\n        is = input_files[i];\n\n        for(k=0;k<is->nb_streams;k++) {\n\n            ist = ist_table[j++];\n\n            ist->st = is->streams[k];\n\n            ist->file_index = i;\n\n            ist->index = k;\n\n            ist->discard = 1; /* the stream is discarded by default\n\n                                 (changed later) */\n\n\n\n            if (rate_emu) {\n\n                ist->start = av_gettime();\n\n            }\n\n        }\n\n    }\n\n\n\n    /* output stream init */\n\n    nb_ostreams = 0;\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        if (!os->nb_streams) {\n\n            dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n            fprintf(stderr, \"Output file #%d does not contain any stream\\n\", i);\n\n            av_exit(1);\n\n        }\n\n        nb_ostreams += os->nb_streams;\n\n    }\n\n    if (nb_stream_maps > 0 && nb_stream_maps != nb_ostreams) {\n\n        fprintf(stderr, \"Number of stream maps must match number of output streams\\n\");\n\n        av_exit(1);\n\n    }\n\n\n\n    /* Sanity check the mapping args -- do the input files & streams exist? */\n\n    for(i=0;i<nb_stream_maps;i++) {\n\n        int fi = stream_maps[i].file_index;\n\n        int si = stream_maps[i].stream_index;\n\n\n\n        if (fi < 0 || fi > nb_input_files - 1 ||\n\n            si < 0 || si > file_table[fi].nb_streams - 1) {\n\n            fprintf(stderr,\"Could not find input stream #%d.%d\\n\", fi, si);\n\n            av_exit(1);\n\n        }\n\n        fi = stream_maps[i].sync_file_index;\n\n        si = stream_maps[i].sync_stream_index;\n\n        if (fi < 0 || fi > nb_input_files - 1 ||\n\n            si < 0 || si > file_table[fi].nb_streams - 1) {\n\n            fprintf(stderr,\"Could not find sync stream #%d.%d\\n\", fi, si);\n\n            av_exit(1);\n\n        }\n\n    }\n\n\n\n    ost_table = av_mallocz(sizeof(AVOutputStream *) * nb_ostreams);\n\n    if (!ost_table)\n\n        goto fail;\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = av_mallocz(sizeof(AVOutputStream));\n\n        if (!ost)\n\n            goto fail;\n\n        ost_table[i] = ost;\n\n    }\n\n\n\n    n = 0;\n\n    for(k=0;k<nb_output_files;k++) {\n\n        os = output_files[k];\n\n        for(i=0;i<os->nb_streams;i++,n++) {\n\n            int found;\n\n            ost = ost_table[n];\n\n            ost->file_index = k;\n\n            ost->index = i;\n\n            ost->st = os->streams[i];\n\n            if (nb_stream_maps > 0) {\n\n                ost->source_index = file_table[stream_maps[n].file_index].ist_index +\n\n                    stream_maps[n].stream_index;\n\n\n\n                /* Sanity check that the stream types match */\n\n                if (ist_table[ost->source_index]->st->codec->codec_type != ost->st->codec->codec_type) {\n\n                    int i= ost->file_index;\n\n                    dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n                    fprintf(stderr, \"Codec type mismatch for mapping #%d.%d -> #%d.%d\\n\",\n\n                        stream_maps[n].file_index, stream_maps[n].stream_index,\n\n                        ost->file_index, ost->index);\n\n                    av_exit(1);\n\n                }\n\n\n\n            } else {\n\n                int best_nb_frames=-1;\n\n                    /* get corresponding input stream index : we select the first one with the right type */\n\n                    found = 0;\n\n                    for(j=0;j<nb_istreams;j++) {\n\n                        int skip=0;\n\n                        ist = ist_table[j];\n\n                        if(opt_programid){\n\n                            int pi,si;\n\n                            AVFormatContext *f= input_files[ ist->file_index ];\n\n                            skip=1;\n\n                            for(pi=0; pi<f->nb_programs; pi++){\n\n                                AVProgram *p= f->programs[pi];\n\n                                if(p->id == opt_programid)\n\n                                    for(si=0; si<p->nb_stream_indexes; si++){\n\n                                        if(f->streams[ p->stream_index[si] ] == ist->st)\n\n                                            skip=0;\n\n                                    }\n\n                            }\n\n                        }\n\n                        if (ist->discard && ist->st->discard != AVDISCARD_ALL && !skip &&\n\n                            ist->st->codec->codec_type == ost->st->codec->codec_type) {\n\n                            if(best_nb_frames < ist->st->codec_info_nb_frames){\n\n                                best_nb_frames= ist->st->codec_info_nb_frames;\n\n                                ost->source_index = j;\n\n                                found = 1;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                if (!found) {\n\n                    if(! opt_programid) {\n\n                        /* try again and reuse existing stream */\n\n                        for(j=0;j<nb_istreams;j++) {\n\n                            ist = ist_table[j];\n\n                            if (   ist->st->codec->codec_type == ost->st->codec->codec_type\n\n                                && ist->st->discard != AVDISCARD_ALL) {\n\n                                ost->source_index = j;\n\n                                found = 1;\n\n                            }\n\n                        }\n\n                    }\n\n                    if (!found) {\n\n                        int i= ost->file_index;\n\n                        dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n                        fprintf(stderr, \"Could not find input stream matching output stream #%d.%d\\n\",\n\n                                ost->file_index, ost->index);\n\n                        av_exit(1);\n\n                    }\n\n                }\n\n            }\n\n            ist = ist_table[ost->source_index];\n\n            ist->discard = 0;\n\n            ost->sync_ist = (nb_stream_maps > 0) ?\n\n                ist_table[file_table[stream_maps[n].sync_file_index].ist_index +\n\n                         stream_maps[n].sync_stream_index] : ist;\n\n        }\n\n    }\n\n\n\n    /* for each output stream, we compute the right encoding parameters */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        AVMetadataTag *t = NULL;\n\n        ost = ost_table[i];\n\n        os = output_files[ost->file_index];\n\n        ist = ist_table[ost->source_index];\n\n\n\n        codec = ost->st->codec;\n\n        icodec = ist->st->codec;\n\n\n\n        while ((t = av_metadata_get(ist->st->metadata, \"\", t, AV_METADATA_IGNORE_SUFFIX))) {\n\n            av_metadata_set2(&ost->st->metadata, t->key, t->value, AV_METADATA_DONT_OVERWRITE);\n\n        }\n\n\n\n        ost->st->disposition = ist->st->disposition;\n\n        codec->bits_per_raw_sample= icodec->bits_per_raw_sample;\n\n        codec->chroma_sample_location = icodec->chroma_sample_location;\n\n\n\n        if (ost->st->stream_copy) {\n\n            /* if stream_copy is selected, no need to decode or encode */\n\n            codec->codec_id = icodec->codec_id;\n\n            codec->codec_type = icodec->codec_type;\n\n\n\n            if(!codec->codec_tag){\n\n                if(   !os->oformat->codec_tag\n\n                   || av_codec_get_id (os->oformat->codec_tag, icodec->codec_tag) == codec->codec_id\n\n                   || av_codec_get_tag(os->oformat->codec_tag, icodec->codec_id) <= 0)\n\n                    codec->codec_tag = icodec->codec_tag;\n\n            }\n\n\n\n            codec->bit_rate = icodec->bit_rate;\n\n            codec->extradata= icodec->extradata;\n\n            codec->extradata_size= icodec->extradata_size;\n\n            if(av_q2d(icodec->time_base)*icodec->ticks_per_frame > av_q2d(ist->st->time_base) && av_q2d(ist->st->time_base) < 1.0/1000){\n\n                codec->time_base = icodec->time_base;\n\n                codec->time_base.num *= icodec->ticks_per_frame;\n\n            }else\n\n                codec->time_base = ist->st->time_base;\n\n            switch(codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                if(audio_volume != 256) {\n\n                    fprintf(stderr,\"-acodec copy and -vol are incompatible (frames are not decoded)\\n\");\n\n                    av_exit(1);\n\n                }\n\n                codec->channel_layout = icodec->channel_layout;\n\n                codec->sample_rate = icodec->sample_rate;\n\n                codec->channels = icodec->channels;\n\n                codec->frame_size = icodec->frame_size;\n\n                codec->block_align= icodec->block_align;\n\n                if(codec->block_align == 1 && codec->codec_id == CODEC_ID_MP3)\n\n                    codec->block_align= 0;\n\n                if(codec->codec_id == CODEC_ID_AC3)\n\n                    codec->block_align= 0;\n\n                break;\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                codec->pix_fmt = icodec->pix_fmt;\n\n                codec->width = icodec->width;\n\n                codec->height = icodec->height;\n\n                codec->has_b_frames = icodec->has_b_frames;\n\n                break;\n\n            case AVMEDIA_TYPE_SUBTITLE:\n\n                codec->width = icodec->width;\n\n                codec->height = icodec->height;\n\n                break;\n\n            default:\n\n                abort();\n\n            }\n\n        } else {\n\n            switch(codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                ost->fifo= av_fifo_alloc(1024);\n\n                if(!ost->fifo)\n\n                    goto fail;\n\n                ost->reformat_pair = MAKE_SFMT_PAIR(SAMPLE_FMT_NONE,SAMPLE_FMT_NONE);\n\n                ost->audio_resample = codec->sample_rate != icodec->sample_rate || audio_sync_method > 1;\n\n                icodec->request_channels = codec->channels;\n\n                ist->decoding_needed = 1;\n\n                ost->encoding_needed = 1;\n\n                break;\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                if (ost->st->codec->pix_fmt == PIX_FMT_NONE) {\n\n                    fprintf(stderr, \"Video pixel format is unknown, stream cannot be encoded\\n\");\n\n                    av_exit(1);\n\n                }\n\n                ost->video_crop = ((frame_leftBand + frame_rightBand + frame_topBand + frame_bottomBand) != 0);\n\n                ost->video_pad = ((frame_padleft + frame_padright + frame_padtop + frame_padbottom) != 0);\n\n                ost->video_resample = ((codec->width != icodec->width -\n\n                                (frame_leftBand + frame_rightBand) +\n\n                                (frame_padleft + frame_padright)) ||\n\n                        (codec->height != icodec->height -\n\n                                (frame_topBand  + frame_bottomBand) +\n\n                                (frame_padtop + frame_padbottom)) ||\n\n                        (codec->pix_fmt != icodec->pix_fmt));\n\n                if (ost->video_crop) {\n\n                    ost->topBand    = ost->original_topBand    = frame_topBand;\n\n                    ost->bottomBand = ost->original_bottomBand = frame_bottomBand;\n\n                    ost->leftBand   = ost->original_leftBand   = frame_leftBand;\n\n                    ost->rightBand  = ost->original_rightBand  = frame_rightBand;\n\n                }\n\n                if (ost->video_pad) {\n\n                    ost->padtop = frame_padtop;\n\n                    ost->padleft = frame_padleft;\n\n                    ost->padbottom = frame_padbottom;\n\n                    ost->padright = frame_padright;\n\n                    if (!ost->video_resample) {\n\n                        avcodec_get_frame_defaults(&ost->pict_tmp);\n\n                        if(avpicture_alloc((AVPicture*)&ost->pict_tmp, codec->pix_fmt,\n\n                                         codec->width, codec->height))\n\n                            goto fail;\n\n                    }\n\n                }\n\n                if (ost->video_resample) {\n\n                    avcodec_get_frame_defaults(&ost->pict_tmp);\n\n                    if(avpicture_alloc((AVPicture*)&ost->pict_tmp, codec->pix_fmt,\n\n                                         codec->width, codec->height)) {\n\n                        fprintf(stderr, \"Cannot allocate temp picture, check pix fmt\\n\");\n\n                        av_exit(1);\n\n                    }\n\n                    sws_flags = av_get_int(sws_opts, \"sws_flags\", NULL);\n\n                    ost->img_resample_ctx = sws_getContext(\n\n                            icodec->width - (frame_leftBand + frame_rightBand),\n\n                            icodec->height - (frame_topBand + frame_bottomBand),\n\n                            icodec->pix_fmt,\n\n                            codec->width - (frame_padleft + frame_padright),\n\n                            codec->height - (frame_padtop + frame_padbottom),\n\n                            codec->pix_fmt,\n\n                            sws_flags, NULL, NULL, NULL);\n\n                    if (ost->img_resample_ctx == NULL) {\n\n                        fprintf(stderr, \"Cannot get resampling context\\n\");\n\n                        av_exit(1);\n\n                    }\n\n\n\n#if !CONFIG_AVFILTER\n\n                    ost->original_height = icodec->height;\n\n                    ost->original_width  = icodec->width;\n\n#endif\n\n                    codec->bits_per_raw_sample= 0;\n\n                }\n\n                ost->resample_height = icodec->height - (frame_topBand  + frame_bottomBand);\n\n                ost->resample_width  = icodec->width  - (frame_leftBand + frame_rightBand);\n\n                ost->resample_pix_fmt= icodec->pix_fmt;\n\n                ost->encoding_needed = 1;\n\n                ist->decoding_needed = 1;\n\n\n\n#if CONFIG_AVFILTER\n\n                if (configure_filters(ist, ost)) {\n\n                    fprintf(stderr, \"Error opening filters!\\n\");\n\n                    exit(1);\n\n                }\n\n#endif\n\n                break;\n\n            case AVMEDIA_TYPE_SUBTITLE:\n\n                ost->encoding_needed = 1;\n\n                ist->decoding_needed = 1;\n\n                break;\n\n            default:\n\n                abort();\n\n                break;\n\n            }\n\n            /* two pass mode */\n\n            if (ost->encoding_needed &&\n\n                (codec->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2))) {\n\n                char logfilename[1024];\n\n                FILE *f;\n\n\n\n                snprintf(logfilename, sizeof(logfilename), \"%s-%d.log\",\n\n                         pass_logfilename_prefix ? pass_logfilename_prefix : DEFAULT_PASS_LOGFILENAME_PREFIX,\n\n                         i);\n\n                if (codec->flags & CODEC_FLAG_PASS1) {\n\n                    f = fopen(logfilename, \"w\");\n\n                    if (!f) {\n\n                        fprintf(stderr, \"Cannot write log file '%s' for pass-1 encoding: %s\\n\", logfilename, strerror(errno));\n\n                        av_exit(1);\n\n                    }\n\n                    ost->logfile = f;\n\n                } else {\n\n                    char  *logbuffer;\n\n                    size_t logbuffer_size;\n\n                    if (read_file(logfilename, &logbuffer, &logbuffer_size) < 0) {\n\n                        fprintf(stderr, \"Error reading log file '%s' for pass-2 encoding\\n\", logfilename);\n\n                        av_exit(1);\n\n                    }\n\n                    codec->stats_in = logbuffer;\n\n                }\n\n            }\n\n        }\n\n        if(codec->codec_type == AVMEDIA_TYPE_VIDEO){\n\n            int size= codec->width * codec->height;\n\n            bit_buffer_size= FFMAX(bit_buffer_size, 6*size + 200);\n\n        }\n\n    }\n\n\n\n    if (!bit_buffer)\n\n        bit_buffer = av_malloc(bit_buffer_size);\n\n    if (!bit_buffer) {\n\n        fprintf(stderr, \"Cannot allocate %d bytes output buffer\\n\",\n\n                bit_buffer_size);\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    /* open each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            AVCodec *codec = output_codecs[i];\n\n            if (!codec)\n\n                codec = avcodec_find_encoder(ost->st->codec->codec_id);\n\n            if (!codec) {\n\n                snprintf(error, sizeof(error), \"Encoder (codec id %d) not found for output stream #%d.%d\",\n\n                         ost->st->codec->codec_id, ost->file_index, ost->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            if (avcodec_open(ost->st->codec, codec) < 0) {\n\n                snprintf(error, sizeof(error), \"Error while opening encoder for output stream #%d.%d - maybe incorrect parameters such as bit_rate, rate, width or height\",\n\n                        ost->file_index, ost->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            extra_size += ost->st->codec->extradata_size;\n\n        }\n\n    }\n\n\n\n    /* open each decoder */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            AVCodec *codec = input_codecs[i];\n\n            if (!codec)\n\n                codec = avcodec_find_decoder(ist->st->codec->codec_id);\n\n            if (!codec) {\n\n                snprintf(error, sizeof(error), \"Decoder (codec id %d) not found for input stream #%d.%d\",\n\n                        ist->st->codec->codec_id, ist->file_index, ist->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            if (avcodec_open(ist->st->codec, codec) < 0) {\n\n                snprintf(error, sizeof(error), \"Error while opening decoder for input stream #%d.%d\",\n\n                        ist->file_index, ist->index);\n\n                ret = AVERROR(EINVAL);\n\n                goto dump_format;\n\n            }\n\n            //if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            //    ist->st->codec->flags |= CODEC_FLAG_REPEAT_FIELD;\n\n        }\n\n    }\n\n\n\n    /* init pts */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        AVStream *st;\n\n        ist = ist_table[i];\n\n        st= ist->st;\n\n        ist->pts = st->avg_frame_rate.num ? - st->codec->has_b_frames*AV_TIME_BASE / av_q2d(st->avg_frame_rate) : 0;\n\n        ist->next_pts = AV_NOPTS_VALUE;\n\n        ist->is_start = 1;\n\n    }\n\n\n\n    /* set meta data information from input file if required */\n\n    for (i=0;i<nb_meta_data_maps;i++) {\n\n        AVFormatContext *out_file;\n\n        AVFormatContext *in_file;\n\n        AVMetadataTag *mtag;\n\n\n\n        int out_file_index = meta_data_maps[i].out_file;\n\n        int in_file_index = meta_data_maps[i].in_file;\n\n        if (out_file_index < 0 || out_file_index >= nb_output_files) {\n\n            snprintf(error, sizeof(error), \"Invalid output file index %d map_meta_data(%d,%d)\",\n\n                     out_file_index, out_file_index, in_file_index);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n        if (in_file_index < 0 || in_file_index >= nb_input_files) {\n\n            snprintf(error, sizeof(error), \"Invalid input file index %d map_meta_data(%d,%d)\",\n\n                     in_file_index, out_file_index, in_file_index);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n\n\n        out_file = output_files[out_file_index];\n\n        in_file = input_files[in_file_index];\n\n\n\n\n\n        mtag=NULL;\n\n        while((mtag=av_metadata_get(in_file->metadata, \"\", mtag, AV_METADATA_IGNORE_SUFFIX)))\n\n            av_metadata_set2(&out_file->metadata, mtag->key, mtag->value, AV_METADATA_DONT_OVERWRITE);\n\n        av_metadata_conv(out_file, out_file->oformat->metadata_conv,\n\n                                    in_file->iformat->metadata_conv);\n\n    }\n\n\n\n    /* copy chapters from the first input file that has them*/\n\n    for (i = 0; i < nb_input_files; i++) {\n\n        if (!input_files[i]->nb_chapters)\n\n            continue;\n\n\n\n        for (j = 0; j < nb_output_files; j++)\n\n            if ((ret = copy_chapters(i, j)) < 0)\n\n                goto dump_format;\n\n    }\n\n\n\n    /* open files and write file headers */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        if (av_write_header(os) < 0) {\n\n            snprintf(error, sizeof(error), \"Could not write header for output file #%d (incorrect codec parameters ?)\", i);\n\n            ret = AVERROR(EINVAL);\n\n            goto dump_format;\n\n        }\n\n        if (strcmp(output_files[i]->oformat->name, \"rtp\")) {\n\n            want_sdp = 0;\n\n        }\n\n    }\n\n\n\n dump_format:\n\n    /* dump the file output parameters - cannot be done before in case\n\n       of stream copy */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n    }\n\n\n\n    /* dump the stream mapping */\n\n    if (verbose >= 0) {\n\n        fprintf(stderr, \"Stream mapping:\\n\");\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            ost = ost_table[i];\n\n            fprintf(stderr, \"  Stream #%d.%d -> #%d.%d\",\n\n                    ist_table[ost->source_index]->file_index,\n\n                    ist_table[ost->source_index]->index,\n\n                    ost->file_index,\n\n                    ost->index);\n\n            if (ost->sync_ist != ist_table[ost->source_index])\n\n                fprintf(stderr, \" [sync #%d.%d]\",\n\n                        ost->sync_ist->file_index,\n\n                        ost->sync_ist->index);\n\n            fprintf(stderr, \"\\n\");\n\n        }\n\n    }\n\n\n\n    if (ret) {\n\n        fprintf(stderr, \"%s\\n\", error);\n\n        goto fail;\n\n    }\n\n\n\n    if (want_sdp) {\n\n        print_sdp(output_files, nb_output_files);\n\n    }\n\n\n\n    if (!using_stdin && verbose >= 0) {\n\n        fprintf(stderr, \"Press [q] to stop encoding\\n\");\n\n        url_set_interrupt_cb(decode_interrupt_cb);\n\n    }\n\n    term_init();\n\n\n\n    timer_start = av_gettime();\n\n\n\n    for(; received_sigterm == 0;) {\n\n        int file_index, ist_index;\n\n        AVPacket pkt;\n\n        double ipts_min;\n\n        double opts_min;\n\n\n\n    redo:\n\n        ipts_min= 1e100;\n\n        opts_min= 1e100;\n\n        /* if 'q' pressed, exits */\n\n        if (!using_stdin) {\n\n            if (q_pressed)\n\n                break;\n\n            /* read_key() returns 0 on EOF */\n\n            key = read_key();\n\n            if (key == 'q')\n\n                break;\n\n        }\n\n\n\n        /* select the stream that we must read now by looking at the\n\n           smallest output pts */\n\n        file_index = -1;\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            double ipts, opts;\n\n            ost = ost_table[i];\n\n            os = output_files[ost->file_index];\n\n            ist = ist_table[ost->source_index];\n\n            if(ist->is_past_recording_time || no_packet[ist->file_index])\n\n                continue;\n\n                opts = ost->st->pts.val * av_q2d(ost->st->time_base);\n\n            ipts = (double)ist->pts;\n\n            if (!file_table[ist->file_index].eof_reached){\n\n                if(ipts < ipts_min) {\n\n                    ipts_min = ipts;\n\n                    if(input_sync ) file_index = ist->file_index;\n\n                }\n\n                if(opts < opts_min) {\n\n                    opts_min = opts;\n\n                    if(!input_sync) file_index = ist->file_index;\n\n                }\n\n            }\n\n            if(ost->frame_number >= max_frames[ost->st->codec->codec_type]){\n\n                file_index= -1;\n\n                break;\n\n            }\n\n        }\n\n        /* if none, if is finished */\n\n        if (file_index < 0) {\n\n            if(no_packet_count){\n\n                no_packet_count=0;\n\n                memset(no_packet, 0, sizeof(no_packet));\n\n                usleep(10000);\n\n                continue;\n\n            }\n\n            break;\n\n        }\n\n\n\n        /* finish if limit size exhausted */\n\n        if (limit_filesize != 0 && limit_filesize < url_ftell(output_files[0]->pb))\n\n            break;\n\n\n\n        /* read a frame from it and output it in the fifo */\n\n        is = input_files[file_index];\n\n        ret= av_read_frame(is, &pkt);\n\n        if(ret == AVERROR(EAGAIN)){\n\n            no_packet[file_index]=1;\n\n            no_packet_count++;\n\n            continue;\n\n        }\n\n        if (ret < 0) {\n\n            file_table[file_index].eof_reached = 1;\n\n            if (opt_shortest)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        no_packet_count=0;\n\n        memset(no_packet, 0, sizeof(no_packet));\n\n\n\n        if (do_pkt_dump) {\n\n            av_pkt_dump_log(NULL, AV_LOG_DEBUG, &pkt, do_hex_dump);\n\n        }\n\n        /* the following test is needed in case new streams appear\n\n           dynamically in stream : we ignore them */\n\n        if (pkt.stream_index >= file_table[file_index].nb_streams)\n\n            goto discard_packet;\n\n        ist_index = file_table[file_index].ist_index + pkt.stream_index;\n\n        ist = ist_table[ist_index];\n\n        if (ist->discard)\n\n            goto discard_packet;\n\n\n\n        if (pkt.dts != AV_NOPTS_VALUE)\n\n            pkt.dts += av_rescale_q(input_files_ts_offset[ist->file_index], AV_TIME_BASE_Q, ist->st->time_base);\n\n        if (pkt.pts != AV_NOPTS_VALUE)\n\n            pkt.pts += av_rescale_q(input_files_ts_offset[ist->file_index], AV_TIME_BASE_Q, ist->st->time_base);\n\n\n\n        if(input_files_ts_scale[file_index][pkt.stream_index]){\n\n            if(pkt.pts != AV_NOPTS_VALUE)\n\n                pkt.pts *= input_files_ts_scale[file_index][pkt.stream_index];\n\n            if(pkt.dts != AV_NOPTS_VALUE)\n\n                pkt.dts *= input_files_ts_scale[file_index][pkt.stream_index];\n\n        }\n\n\n\n//        fprintf(stderr, \"next:%\"PRId64\" dts:%\"PRId64\" off:%\"PRId64\" %d\\n\", ist->next_pts, pkt.dts, input_files_ts_offset[ist->file_index], ist->st->codec->codec_type);\n\n        if (pkt.dts != AV_NOPTS_VALUE && ist->next_pts != AV_NOPTS_VALUE\n\n            && (is->iformat->flags & AVFMT_TS_DISCONT)) {\n\n            int64_t pkt_dts= av_rescale_q(pkt.dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n            int64_t delta= pkt_dts - ist->next_pts;\n\n            if((FFABS(delta) > 1LL*dts_delta_threshold*AV_TIME_BASE || pkt_dts+1<ist->pts)&& !copy_ts){\n\n                input_files_ts_offset[ist->file_index]-= delta;\n\n                if (verbose > 2)\n\n                    fprintf(stderr, \"timestamp discontinuity %\"PRId64\", new offset= %\"PRId64\"\\n\", delta, input_files_ts_offset[ist->file_index]);\n\n                pkt.dts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n                if(pkt.pts != AV_NOPTS_VALUE)\n\n                    pkt.pts-= av_rescale_q(delta, AV_TIME_BASE_Q, ist->st->time_base);\n\n            }\n\n        }\n\n\n\n        /* finish if recording time exhausted */\n\n        if (recording_time != INT64_MAX &&\n\n            av_compare_ts(pkt.pts, ist->st->time_base, recording_time + start_time, (AVRational){1, 1000000}) >= 0) {\n\n            ist->is_past_recording_time = 1;\n\n            goto discard_packet;\n\n        }\n\n\n\n        //fprintf(stderr,\"read #%d.%d size=%d\\n\", ist->file_index, ist->index, pkt.size);\n\n        if (output_packet(ist, ist_index, ost_table, nb_ostreams, &pkt) < 0) {\n\n\n\n            if (verbose >= 0)\n\n                fprintf(stderr, \"Error while decoding stream #%d.%d\\n\",\n\n                        ist->file_index, ist->index);\n\n            if (exit_on_error)\n\n                av_exit(1);\n\n            av_free_packet(&pkt);\n\n            goto redo;\n\n        }\n\n\n\n    discard_packet:\n\n        av_free_packet(&pkt);\n\n\n\n        /* dump report by using the output first video and audio streams */\n\n        print_report(output_files, ost_table, nb_ostreams, 0);\n\n    }\n\n\n\n    /* at the end of stream, we must flush the decoder buffers */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            output_packet(ist, i, ost_table, nb_ostreams, NULL);\n\n        }\n\n    }\n\n\n\n    term_exit();\n\n\n\n    /* write the trailer if needed and close file */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        av_write_trailer(os);\n\n    }\n\n\n\n    /* dump report by using the first video and audio streams */\n\n    print_report(output_files, ost_table, nb_ostreams, 1);\n\n\n\n    /* close each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            av_freep(&ost->st->codec->stats_in);\n\n            avcodec_close(ost->st->codec);\n\n        }\n\n    }\n\n\n\n    /* close each decoder */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            avcodec_close(ist->st->codec);\n\n        }\n\n    }\n\n#if CONFIG_AVFILTER\n\n    if (filt_graph_all) {\n\n        avfilter_graph_destroy(filt_graph_all);\n\n        av_freep(&filt_graph_all);\n\n    }\n\n#endif\n\n\n\n    /* finished ! */\n\n    ret = 0;\n\n\n\n fail:\n\n    av_freep(&bit_buffer);\n\n    av_free(file_table);\n\n\n\n    if (ist_table) {\n\n        for(i=0;i<nb_istreams;i++) {\n\n            ist = ist_table[i];\n\n            av_free(ist);\n\n        }\n\n        av_free(ist_table);\n\n    }\n\n    if (ost_table) {\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            ost = ost_table[i];\n\n            if (ost) {\n\n                if (ost->logfile) {\n\n                    fclose(ost->logfile);\n\n                    ost->logfile = NULL;\n\n                }\n\n                av_fifo_free(ost->fifo); /* works even if fifo is not\n\n                                             initialized but set to zero */\n\n                av_free(ost->pict_tmp.data[0]);\n\n                if (ost->video_resample)\n\n                    sws_freeContext(ost->img_resample_ctx);\n\n                if (ost->resample)\n\n                    audio_resample_close(ost->resample);\n\n                if (ost->reformat_ctx)\n\n                    av_audio_convert_free(ost->reformat_ctx);\n\n                av_free(ost);\n\n            }\n\n        }\n\n        av_free(ost_table);\n\n    }\n\n    return ret;\n\n}\n", "idx": 23260, "_split": "valid", "_hash": "b3db53f59bc70efc99dbf2c15a5e5d30"}
{"project": "FFmpeg", "commit_id": "46911c7ab803607fd9285927ed23426a9d297723", "target": 0, "func": "static int mpegts_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVStream *st = s->streams[pkt->stream_index];\n\n    int size= pkt->size;\n\n    uint8_t *buf= pkt->data;\n\n    MpegTSWriteStream *ts_st = st->priv_data;\n\n    int len, max_payload_size;\n\n    const uint8_t *access_unit_index = NULL;\n\n\n\n    if (st->codec->codec_type == CODEC_TYPE_SUBTITLE) {\n\n        /* for subtitle, a single PES packet must be generated */\n\n        mpegts_write_pes(s, st, buf, size, pkt->pts, AV_NOPTS_VALUE);\n\n        return 0;\n\n    }\n\n\n\n    if (st->codec->codec_id == CODEC_ID_DIRAC) {\n\n        /* for Dirac, a single PES packet must be generated */\n\n        mpegts_write_pes(s, st, buf, size, pkt->pts, pkt->dts);\n\n        return 0;\n\n    }\n\n    max_payload_size = DEFAULT_PES_PAYLOAD_SIZE;\n\n    if (st->codec->codec_id == CODEC_ID_MPEG2VIDEO ||\n\n        st->codec->codec_id == CODEC_ID_MPEG1VIDEO) {\n\n        const uint8_t *p = pkt->data;\n\n        const uint8_t *end = pkt->data+pkt->size;\n\n        uint32_t state = -1;\n\n        while (p < end) {\n\n            p = ff_find_start_code(p, end, &state);\n\n            if (state == PICTURE_START_CODE) {\n\n                access_unit_index = p - 4;\n\n                break;\n\n            }\n\n        }\n\n    } else if (st->codec->codec_type == CODEC_TYPE_AUDIO) {\n\n        access_unit_index = pkt->data;\n\n    }\n\n\n\n    if (!access_unit_index) {\n\n        av_log(s, AV_LOG_ERROR, \"error, could not find access unit start\\n\");\n\n        return -1;\n\n    }\n\n\n\n    while (size > 0) {\n\n        len = max_payload_size - ts_st->payload_index;\n\n        if (len > size)\n\n            len = size;\n\n        memcpy(ts_st->payload + ts_st->payload_index, buf, len);\n\n        buf += len;\n\n        size -= len;\n\n        ts_st->payload_index += len;\n\n        if (access_unit_index && access_unit_index < buf &&\n\n            ts_st->payload_pts == AV_NOPTS_VALUE &&\n\n            ts_st->payload_dts == AV_NOPTS_VALUE) {\n\n            ts_st->payload_dts = pkt->dts;\n\n            ts_st->payload_pts = pkt->pts;\n\n        }\n\n        if (ts_st->payload_index >= max_payload_size) {\n\n            mpegts_write_pes(s, st, ts_st->payload, ts_st->payload_index,\n\n                             ts_st->payload_pts, ts_st->payload_dts);\n\n            ts_st->payload_pts = AV_NOPTS_VALUE;\n\n            ts_st->payload_dts = AV_NOPTS_VALUE;\n\n            ts_st->payload_index = 0;\n\n            access_unit_index = NULL; // unset access unit to avoid setting pts/dts again\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 23263, "_split": "valid", "_hash": "60b81e11fd56f8663438d5b3e1191cfa"}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(yuv2packedX)(SwsContext *c, const int16_t *lumFilter, const int16_t **lumSrc, int lumFilterSize,\n\n                                       const int16_t *chrFilter, const int16_t **chrSrc, int chrFilterSize,\n\n                                       const int16_t **alpSrc, uint8_t *dest, int dstW, int dstY)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    x86_reg dummy=0;\n\n    if(!(c->flags & SWS_BITEXACT)) {\n\n        if (c->flags & SWS_ACCURATE_RND) {\n\n            switch(c->dstFormat) {\n\n            case PIX_FMT_RGB32:\n\n                if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n                    YSCALEYUV2PACKEDX_ACCURATE\n\n                    YSCALEYUV2RGBX\n\n                    \"movq                      %%mm2, \"U_TEMP\"(%0)  \\n\\t\"\n\n                    \"movq                      %%mm4, \"V_TEMP\"(%0)  \\n\\t\"\n\n                    \"movq                      %%mm5, \"Y_TEMP\"(%0)  \\n\\t\"\n\n                    YSCALEYUV2PACKEDX_ACCURATE_YA(ALP_MMX_FILTER_OFFSET)\n\n                    \"movq               \"Y_TEMP\"(%0), %%mm5         \\n\\t\"\n\n                    \"psraw                        $3, %%mm1         \\n\\t\"\n\n                    \"psraw                        $3, %%mm7         \\n\\t\"\n\n                    \"packuswb                  %%mm7, %%mm1         \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm3, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm2, %%mm6)\n\n\n\n                    YSCALEYUV2PACKEDX_END\n\n                } else {\n\n                    YSCALEYUV2PACKEDX_ACCURATE\n\n                    YSCALEYUV2RGBX\n\n                    \"pcmpeqd %%mm7, %%mm7 \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n\n\n                    YSCALEYUV2PACKEDX_END\n\n                }\n\n                return;\n\n            case PIX_FMT_BGR24:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                \"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_c\"\\n\\t\" //FIXME optimize\n\n                \"add %4, %%\"REG_c\"                        \\n\\t\"\n\n                WRITEBGR24(%%REGc, %5, %%REGa)\n\n\n\n\n\n                :: \"r\" (&c->redDither),\n\n                \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n                \"r\" (dest), \"m\" (dstW)\n\n                : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S\n\n                );\n\n                return;\n\n            case PIX_FMT_RGB555:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2\\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4\\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5\\n\\t\"\n\n#endif\n\n\n\n                WRITERGB15(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_RGB565:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2\\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4\\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5\\n\\t\"\n\n#endif\n\n\n\n                WRITERGB16(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_YUYV422:\n\n                YSCALEYUV2PACKEDX_ACCURATE\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n\n\n                \"psraw $3, %%mm3    \\n\\t\"\n\n                \"psraw $3, %%mm4    \\n\\t\"\n\n                \"psraw $3, %%mm1    \\n\\t\"\n\n                \"psraw $3, %%mm7    \\n\\t\"\n\n                WRITEYUY2(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            }\n\n        } else {\n\n            switch(c->dstFormat) {\n\n            case PIX_FMT_RGB32:\n\n                if (CONFIG_SWSCALE_ALPHA && c->alpPixBuf) {\n\n                    YSCALEYUV2PACKEDX\n\n                    YSCALEYUV2RGBX\n\n                    YSCALEYUV2PACKEDX_YA(ALP_MMX_FILTER_OFFSET, %%mm0, %%mm3, %%mm6, %%mm1, %%mm7)\n\n                    \"psraw                        $3, %%mm1         \\n\\t\"\n\n                    \"psraw                        $3, %%mm7         \\n\\t\"\n\n                    \"packuswb                  %%mm7, %%mm1         \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm1, %%mm0, %%mm7, %%mm3, %%mm6)\n\n                    YSCALEYUV2PACKEDX_END\n\n                } else {\n\n                    YSCALEYUV2PACKEDX\n\n                    YSCALEYUV2RGBX\n\n                    \"pcmpeqd %%mm7, %%mm7 \\n\\t\"\n\n                    WRITEBGR32(%4, %5, %%REGa, %%mm2, %%mm4, %%mm5, %%mm7, %%mm0, %%mm1, %%mm3, %%mm6)\n\n                    YSCALEYUV2PACKEDX_END\n\n                }\n\n                return;\n\n            case PIX_FMT_BGR24:\n\n                YSCALEYUV2PACKEDX\n\n                YSCALEYUV2RGBX\n\n                \"pxor                    %%mm7, %%mm7       \\n\\t\"\n\n                \"lea (%%\"REG_a\", %%\"REG_a\", 2), %%\"REG_c\"   \\n\\t\" //FIXME optimize\n\n                \"add                        %4, %%\"REG_c\"   \\n\\t\"\n\n                WRITEBGR24(%%REGc, %5, %%REGa)\n\n\n\n                :: \"r\" (&c->redDither),\n\n                \"m\" (dummy), \"m\" (dummy), \"m\" (dummy),\n\n                \"r\" (dest),  \"m\" (dstW)\n\n                : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S\n\n                );\n\n                return;\n\n            case PIX_FMT_RGB555:\n\n                YSCALEYUV2PACKEDX\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2  \\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4  \\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5  \\n\\t\"\n\n#endif\n\n\n\n                WRITERGB15(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_RGB565:\n\n                YSCALEYUV2PACKEDX\n\n                YSCALEYUV2RGBX\n\n                \"pxor %%mm7, %%mm7 \\n\\t\"\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n                \"paddusb \"BLUE_DITHER\"(%0), %%mm2  \\n\\t\"\n\n                \"paddusb \"GREEN_DITHER\"(%0), %%mm4  \\n\\t\"\n\n                \"paddusb \"RED_DITHER\"(%0), %%mm5  \\n\\t\"\n\n#endif\n\n\n\n                WRITERGB16(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            case PIX_FMT_YUYV422:\n\n                YSCALEYUV2PACKEDX\n\n                /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n\n\n                \"psraw $3, %%mm3    \\n\\t\"\n\n                \"psraw $3, %%mm4    \\n\\t\"\n\n                \"psraw $3, %%mm1    \\n\\t\"\n\n                \"psraw $3, %%mm7    \\n\\t\"\n\n                WRITEYUY2(%4, %5, %%REGa)\n\n                YSCALEYUV2PACKEDX_END\n\n                return;\n\n            }\n\n        }\n\n    }\n\n#endif /* COMPILE_TEMPLATE_MMX */\n\n#if COMPILE_TEMPLATE_ALTIVEC\n\n    /* The following list of supported dstFormat values should\n\n       match what's found in the body of ff_yuv2packedX_altivec() */\n\n    if (!(c->flags & SWS_BITEXACT) && !c->alpPixBuf &&\n\n         (c->dstFormat==PIX_FMT_ABGR  || c->dstFormat==PIX_FMT_BGRA  ||\n\n          c->dstFormat==PIX_FMT_BGR24 || c->dstFormat==PIX_FMT_RGB24 ||\n\n          c->dstFormat==PIX_FMT_RGBA  || c->dstFormat==PIX_FMT_ARGB))\n\n            ff_yuv2packedX_altivec(c, lumFilter, lumSrc, lumFilterSize,\n\n                                   chrFilter, chrSrc, chrFilterSize,\n\n                                   dest, dstW, dstY);\n\n    else\n\n#endif\n\n        yuv2packedXinC(c, lumFilter, lumSrc, lumFilterSize,\n\n                       chrFilter, chrSrc, chrFilterSize,\n\n                       alpSrc, dest, dstW, dstY);\n\n}\n", "idx": 23279, "_split": "valid", "_hash": "a83ea4eab0d11bac74651fabde4633b0"}
{"project": "FFmpeg", "commit_id": "158763312f97dd1cf635114c52c550800eda83d2", "target": 0, "func": "static av_cold int frei0r_init(AVFilterContext *ctx,\n\n                               const char *dl_name, int type)\n\n{\n\n    Frei0rContext *frei0r = ctx->priv;\n\n    f0r_init_f            f0r_init;\n\n    f0r_get_plugin_info_f f0r_get_plugin_info;\n\n    f0r_plugin_info_t *pi;\n\n    char *path;\n\n    int ret = 0;\n\n\n\n    /* see: http://frei0r.dyne.org/codedoc/html/group__pluglocations.html */\n\n    if ((path = av_strdup(getenv(\"FREI0R_PATH\")))) {\n\n#ifdef _WIN32\n\n        const char *separator = \";\";\n\n#else\n\n        const char *separator = \":\";\n\n#endif\n\n        char *p, *ptr = NULL;\n\n        for (p = path; p = av_strtok(p, separator, &ptr); p = NULL) {\n\n            /* add additional trailing slash in case it is missing */\n\n            char *p1 = av_asprintf(\"%s/\", p);\n\n            if (!p1) {\n\n                av_free(path);\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            ret = load_path(ctx, &frei0r->dl_handle, p1, dl_name);\n\n            av_free(p1);\n\n            if (ret < 0) {\n\n                av_free(path);\n\n                return ret;\n\n            }\n\n            if (frei0r->dl_handle)\n\n                break;\n\n        }\n\n        av_free(path);\n\n    }\n\n    if (!frei0r->dl_handle && (path = getenv(\"HOME\"))) {\n\n        char *prefix = av_asprintf(\"%s/.frei0r-1/lib/\", path);\n\n        if (!prefix)\n\n            return AVERROR(ENOMEM);\n\n        ret = load_path(ctx, &frei0r->dl_handle, prefix, dl_name);\n\n        av_free(prefix);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (!frei0r->dl_handle) {\n\n        ret = load_path(ctx, &frei0r->dl_handle, \"/usr/local/lib/frei0r-1/\", dl_name);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (!frei0r->dl_handle) {\n\n        ret = load_path(ctx, &frei0r->dl_handle, \"/usr/lib/frei0r-1/\", dl_name);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (!frei0r->dl_handle) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Could not find module '%s'\\n\", dl_name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (!(f0r_init                = load_sym(ctx, \"f0r_init\"           )) ||\n\n        !(f0r_get_plugin_info     = load_sym(ctx, \"f0r_get_plugin_info\")) ||\n\n        !(frei0r->get_param_info  = load_sym(ctx, \"f0r_get_param_info\" )) ||\n\n        !(frei0r->get_param_value = load_sym(ctx, \"f0r_get_param_value\")) ||\n\n        !(frei0r->set_param_value = load_sym(ctx, \"f0r_set_param_value\")) ||\n\n        !(frei0r->update          = load_sym(ctx, \"f0r_update\"         )) ||\n\n        !(frei0r->construct       = load_sym(ctx, \"f0r_construct\"      )) ||\n\n        !(frei0r->destruct        = load_sym(ctx, \"f0r_destruct\"       )) ||\n\n        !(frei0r->deinit          = load_sym(ctx, \"f0r_deinit\"         )))\n\n        return AVERROR(EINVAL);\n\n\n\n    if (f0r_init() < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Could not init the frei0r module\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    f0r_get_plugin_info(&frei0r->plugin_info);\n\n    pi = &frei0r->plugin_info;\n\n    if (pi->plugin_type != type) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Invalid type '%s' for the plugin\\n\",\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_FILTER ? \"filter\" :\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_SOURCE ? \"source\" :\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER2 ? \"mixer2\" :\n\n               pi->plugin_type == F0R_PLUGIN_TYPE_MIXER3 ? \"mixer3\" : \"unknown\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    av_log(ctx, AV_LOG_VERBOSE,\n\n           \"name:%s author:'%s' explanation:'%s' color_model:%s \"\n\n           \"frei0r_version:%d version:%d.%d num_params:%d\\n\",\n\n           pi->name, pi->author, pi->explanation,\n\n           pi->color_model == F0R_COLOR_MODEL_BGRA8888 ? \"bgra8888\" :\n\n           pi->color_model == F0R_COLOR_MODEL_RGBA8888 ? \"rgba8888\" :\n\n           pi->color_model == F0R_COLOR_MODEL_PACKED32 ? \"packed32\" : \"unknown\",\n\n           pi->frei0r_version, pi->major_version, pi->minor_version, pi->num_params);\n\n\n\n    return 0;\n\n}\n", "idx": 23286, "_split": "valid", "_hash": "4d918cf776c07c0ba0e4d9ac82f726aa"}
{"project": "FFmpeg", "commit_id": "83e34ae3c2b36e7b20169a8866e3f49294db1f5a", "target": 1, "func": "static inline int wv_unpack_stereo(WavpackFrameContext *s, GetBitContext *gb,\n\n                                   void *dst_l, void *dst_r, const int type)\n\n{\n\n    int i, j, count = 0;\n\n    int last, t;\n\n    int A, B, L, L2, R, R2;\n\n    int pos                 = s->pos;\n\n    uint32_t crc            = s->sc.crc;\n\n    uint32_t crc_extra_bits = s->extra_sc.crc;\n\n    int16_t *dst16_l        = dst_l;\n\n    int16_t *dst16_r        = dst_r;\n\n    int32_t *dst32_l        = dst_l;\n\n    int32_t *dst32_r        = dst_r;\n\n    float *dstfl_l          = dst_l;\n\n    float *dstfl_r          = dst_r;\n\n\n\n    s->one = s->zero = s->zeroes = 0;\n\n    do {\n\n        L = wv_get_value(s, gb, 0, &last);\n\n        if (last)\n\n            break;\n\n        R = wv_get_value(s, gb, 1, &last);\n\n        if (last)\n\n            break;\n\n        for (i = 0; i < s->terms; i++) {\n\n            t = s->decorr[i].value;\n\n            if (t > 0) {\n\n                if (t > 8) {\n\n                    if (t & 1) {\n\n                        A = 2U * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1];\n\n                        B = 2U * s->decorr[i].samplesB[0] - s->decorr[i].samplesB[1];\n\n                    } else {\n\n                        A = (int)(3U * s->decorr[i].samplesA[0] - s->decorr[i].samplesA[1]) >> 1;\n\n                        B = (int)(3U * s->decorr[i].samplesB[0] - s->decorr[i].samplesB[1]) >> 1;\n\n                    }\n\n                    s->decorr[i].samplesA[1] = s->decorr[i].samplesA[0];\n\n                    s->decorr[i].samplesB[1] = s->decorr[i].samplesB[0];\n\n                    j                        = 0;\n\n                } else {\n\n                    A = s->decorr[i].samplesA[pos];\n\n                    B = s->decorr[i].samplesB[pos];\n\n                    j = (pos + t) & 7;\n\n                }\n\n                if (type != AV_SAMPLE_FMT_S16P) {\n\n                    L2 = L + ((s->decorr[i].weightA * (int64_t)A + 512) >> 10);\n\n                    R2 = R + ((s->decorr[i].weightB * (int64_t)B + 512) >> 10);\n\n                } else {\n\n                    L2 = L + ((int)(s->decorr[i].weightA * (unsigned)A + 512) >> 10);\n\n                    R2 = R + ((int)(s->decorr[i].weightB * (unsigned)B + 512) >> 10);\n\n                }\n\n                if (A && L)\n\n                    s->decorr[i].weightA -= ((((L ^ A) >> 30) & 2) - 1) * s->decorr[i].delta;\n\n                if (B && R)\n\n                    s->decorr[i].weightB -= ((((R ^ B) >> 30) & 2) - 1) * s->decorr[i].delta;\n\n                s->decorr[i].samplesA[j] = L = L2;\n\n                s->decorr[i].samplesB[j] = R = R2;\n\n            } else if (t == -1) {\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    L2 = L + ((s->decorr[i].weightA * (int64_t)s->decorr[i].samplesA[0] + 512) >> 10);\n\n                else\n\n                    L2 = L + ((int)(s->decorr[i].weightA * (unsigned)s->decorr[i].samplesA[0] + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightA, s->decorr[i].delta, s->decorr[i].samplesA[0], L);\n\n                L = L2;\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    R2 = R + ((s->decorr[i].weightB * (int64_t)L2 + 512) >> 10);\n\n                else\n\n                    R2 = R + ((int)(s->decorr[i].weightB * (unsigned)L2 + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightB, s->decorr[i].delta, L2, R);\n\n                R                        = R2;\n\n                s->decorr[i].samplesA[0] = R;\n\n            } else {\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    R2 = R + ((s->decorr[i].weightB * (int64_t)s->decorr[i].samplesB[0] + 512) >> 10);\n\n                else\n\n                    R2 = R + ((int)(s->decorr[i].weightB * (unsigned)s->decorr[i].samplesB[0] + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightB, s->decorr[i].delta, s->decorr[i].samplesB[0], R);\n\n                R = R2;\n\n\n\n                if (t == -3) {\n\n                    R2                       = s->decorr[i].samplesA[0];\n\n                    s->decorr[i].samplesA[0] = R;\n\n                }\n\n\n\n                if (type != AV_SAMPLE_FMT_S16P)\n\n                    L2 = L + ((s->decorr[i].weightA * (int64_t)R2 + 512) >> 10);\n\n                else\n\n                    L2 = L + ((int)(s->decorr[i].weightA * (unsigned)R2 + 512) >> 10);\n\n                UPDATE_WEIGHT_CLIP(s->decorr[i].weightA, s->decorr[i].delta, R2, L);\n\n                L                        = L2;\n\n                s->decorr[i].samplesB[0] = L;\n\n            }\n\n        }\n\n\n\n        if (type == AV_SAMPLE_FMT_S16P) {\n\n            if (FFABS(L) + (unsigned)FFABS(R) > (1<<19)) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"sample %d %d too large\\n\", L, R);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n\n\n        pos = (pos + 1) & 7;\n\n        if (s->joint)\n\n            L += (unsigned)(R -= (unsigned)(L >> 1));\n\n        crc = (crc * 3 + L) * 3 + R;\n\n\n\n        if (type == AV_SAMPLE_FMT_FLTP) {\n\n            *dstfl_l++ = wv_get_value_float(s, &crc_extra_bits, L);\n\n            *dstfl_r++ = wv_get_value_float(s, &crc_extra_bits, R);\n\n        } else if (type == AV_SAMPLE_FMT_S32P) {\n\n            *dst32_l++ = wv_get_value_integer(s, &crc_extra_bits, L);\n\n            *dst32_r++ = wv_get_value_integer(s, &crc_extra_bits, R);\n\n        } else {\n\n            *dst16_l++ = wv_get_value_integer(s, &crc_extra_bits, L);\n\n            *dst16_r++ = wv_get_value_integer(s, &crc_extra_bits, R);\n\n        }\n\n        count++;\n\n    } while (!last && count < s->samples);\n\n\n\n    wv_reset_saved_context(s);\n\n\n\n    if (last && count < s->samples) {\n\n        int size = av_get_bytes_per_sample(type);\n\n        memset((uint8_t*)dst_l + count*size, 0, (s->samples-count)*size);\n\n        memset((uint8_t*)dst_r + count*size, 0, (s->samples-count)*size);\n\n    }\n\n\n\n    if ((s->avctx->err_recognition & AV_EF_CRCCHECK) &&\n\n        wv_check_crc(s, crc, crc_extra_bits))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    return 0;\n\n}\n", "idx": 23308, "_split": "valid", "_hash": "872bffce70d844bbaa31a9e7bfe7e3c6"}
{"project": "FFmpeg", "commit_id": "0953736b7e97f6e121a0587a95434bf1857a27da", "target": 1, "func": "static inline int signed_shift(int i, int shift) {\n\n    if (shift > 0)\n\n        return i << shift;\n\n    return i >> -shift;\n\n}\n", "idx": 23316, "_split": "valid", "_hash": "905df7368230148f6c71341b1fc09b32"}
{"project": "FFmpeg", "commit_id": "38beab19ab3b997bcbe2e95699d4952922f1f673", "target": 1, "func": "static int r3d_read_redv(AVFormatContext *s, AVPacket *pkt, Atom *atom)\n\n{\n\n    AVStream *st = s->streams[0];\n\n    int tmp, tmp2;\n\n    uint64_t pos = url_ftell(s->pb);\n\n    unsigned dts;\n\n\n\n    dts = get_be32(s->pb);\n\n\n\n    tmp = get_be32(s->pb);\n\n    dprintf(s, \"frame num %d\\n\", tmp);\n\n\n\n    tmp  = get_byte(s->pb); // major version\n\n    tmp2 = get_byte(s->pb); // minor version\n\n    dprintf(s, \"version %d.%d\\n\", tmp, tmp2);\n\n\n\n    tmp = get_be16(s->pb); // unknown\n\n    dprintf(s, \"unknown %d\\n\", tmp);\n\n\n\n    if (tmp > 4) {\n\n        tmp = get_be16(s->pb); // unknown\n\n        dprintf(s, \"unknown %d\\n\", tmp);\n\n\n\n        tmp = get_be16(s->pb); // unknown\n\n        dprintf(s, \"unknown %d\\n\", tmp);\n\n\n\n        tmp = get_be32(s->pb);\n\n        dprintf(s, \"width %d\\n\", tmp);\n\n        tmp = get_be32(s->pb);\n\n        dprintf(s, \"height %d\\n\", tmp);\n\n\n\n        tmp = get_be32(s->pb);\n\n        dprintf(s, \"metadata len %d\\n\", tmp);\n\n    }\n\n    tmp = atom->size - 8 - (url_ftell(s->pb) - pos);\n\n    if (tmp < 0)\n\n        return -1;\n\n\n\n    if (av_get_packet(s->pb, pkt, tmp) != tmp) {\n\n        av_log(s, AV_LOG_ERROR, \"error reading video packet\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pkt->stream_index = 0;\n\n    pkt->dts = dts;\n\n    if (st->codec->time_base.den)\n\n        pkt->duration = (uint64_t)st->time_base.den*\n\n            st->codec->time_base.num/st->codec->time_base.den;\n\n    dprintf(s, \"pkt dts %lld duration %d\\n\", pkt->dts, pkt->duration);\n\n\n\n    return 0;\n\n}\n", "idx": 23384, "_split": "valid", "_hash": "d9757ef1e2d7b311ac0cd0bf7df0e9d4"}
{"project": "FFmpeg", "commit_id": "308429e124b97337a768839c1d5091900e974e7e", "target": 0, "func": "static int wav_write_trailer(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb  = s->pb;\n\n    WAVMuxContext    *wav = s->priv_data;\n\n    int64_t file_size, data_size;\n\n    int64_t number_of_samples = 0;\n\n    int rf64 = 0;\n\n\n\n    avio_flush(pb);\n\n\n\n    if (s->pb->seekable) {\n\n        if (wav->write_peak != 2) {\n\n            ff_end_tag(pb, wav->data);\n\n            avio_flush(pb);\n\n        }\n\n\n\n        if (wav->write_peak && wav->peak_output) {\n\n            peak_write_chunk(s);\n\n            avio_flush(pb);\n\n        }\n\n\n\n        /* update file size */\n\n        file_size = avio_tell(pb);\n\n        data_size = file_size - wav->data;\n\n        if (wav->rf64 == RF64_ALWAYS || (wav->rf64 == RF64_AUTO && file_size - 8 > UINT32_MAX)) {\n\n            rf64 = 1;\n\n        } else {\n\n            avio_seek(pb, 4, SEEK_SET);\n\n            avio_wl32(pb, (uint32_t)(file_size - 8));\n\n            avio_seek(pb, file_size, SEEK_SET);\n\n\n\n            avio_flush(pb);\n\n        }\n\n\n\n        number_of_samples = av_rescale(wav->maxpts - wav->minpts + wav->last_duration,\n\n                                       s->streams[0]->codec->sample_rate * (int64_t)s->streams[0]->time_base.num,\n\n                                       s->streams[0]->time_base.den);\n\n\n\n        if(s->streams[0]->codec->codec_tag != 0x01) {\n\n            /* Update num_samps in fact chunk */\n\n            avio_seek(pb, wav->fact_pos, SEEK_SET);\n\n            if (rf64 || (wav->rf64 == RF64_AUTO && number_of_samples > UINT32_MAX)) {\n\n                rf64 = 1;\n\n                avio_wl32(pb, -1);\n\n            } else {\n\n                avio_wl32(pb, number_of_samples);\n\n                avio_seek(pb, file_size, SEEK_SET);\n\n                avio_flush(pb);\n\n            }\n\n        }\n\n\n\n        if (rf64) {\n\n            /* overwrite RIFF with RF64 */\n\n            avio_seek(pb, 0, SEEK_SET);\n\n            ffio_wfourcc(pb, \"RF64\");\n\n            avio_wl32(pb, -1);\n\n\n\n            /* write ds64 chunk (overwrite JUNK if rf64 == RF64_AUTO) */\n\n            avio_seek(pb, wav->ds64 - 8, SEEK_SET);\n\n            ffio_wfourcc(pb, \"ds64\");\n\n            avio_wl32(pb, 28);                  /* ds64 chunk size */\n\n            avio_wl64(pb, file_size - 8);       /* RF64 chunk size */\n\n            avio_wl64(pb, data_size);           /* data chunk size */\n\n            avio_wl64(pb, number_of_samples);   /* fact chunk number of samples */\n\n            avio_wl32(pb, 0);                   /* number of table entries for non-'data' chunks */\n\n\n\n            /* write -1 in data chunk size */\n\n            avio_seek(pb, wav->data - 4, SEEK_SET);\n\n            avio_wl32(pb, -1);\n\n\n\n            avio_seek(pb, file_size, SEEK_SET);\n\n            avio_flush(pb);\n\n        }\n\n    }\n\n\n\n    if (wav->write_peak)\n\n        peak_free_buffers(s);\n\n\n\n    return 0;\n\n}\n", "idx": 23417, "_split": "valid", "_hash": "4005ce10dbf2f308101f6ec3a51f663d"}
{"project": "FFmpeg", "commit_id": "3c77bb5f23b2e149495c814759beab7eedeede6c", "target": 0, "func": "av_cold int swr_init(struct SwrContext *s){\n\n    int ret;\n\n\n\n    clear_context(s);\n\n\n\n    if(s-> in_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested input sample format %d is invalid\\n\", s->in_sample_fmt);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if(s->out_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested output sample format %d is invalid\\n\", s->out_sample_fmt);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    s->out.ch_count  = s-> user_out_ch_count;\n\n    s-> in.ch_count  = s->  user_in_ch_count;\n\n    s->used_ch_count = s->user_used_ch_count;\n\n\n\n    s-> in_ch_layout = s-> user_in_ch_layout;\n\n    s->out_ch_layout = s->user_out_ch_layout;\n\n\n\n    if(av_get_channel_layout_nb_channels(s-> in_ch_layout) > SWR_CH_MAX) {\n\n        av_log(s, AV_LOG_WARNING, \"Input channel layout 0x%\"PRIx64\" is invalid or unsupported.\\n\", s-> in_ch_layout);\n\n        s->in_ch_layout = 0;\n\n    }\n\n\n\n    if(av_get_channel_layout_nb_channels(s->out_ch_layout) > SWR_CH_MAX) {\n\n        av_log(s, AV_LOG_WARNING, \"Output channel layout 0x%\"PRIx64\" is invalid or unsupported.\\n\", s->out_ch_layout);\n\n        s->out_ch_layout = 0;\n\n    }\n\n\n\n    switch(s->engine){\n\n#if CONFIG_LIBSOXR\n\n        case SWR_ENGINE_SOXR: s->resampler = &swri_soxr_resampler; break;\n\n#endif\n\n        case SWR_ENGINE_SWR : s->resampler = &swri_resampler; break;\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"Requested resampling engine is unavailable\\n\");\n\n            return AVERROR(EINVAL);\n\n    }\n\n\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n\n\n    if(s->used_ch_count && s-> in_ch_layout && s->used_ch_count != av_get_channel_layout_nb_channels(s-> in_ch_layout)){\n\n        av_log(s, AV_LOG_WARNING, \"Input channel layout has a different number of channels than the number of used channels, ignoring layout\\n\");\n\n        s-> in_ch_layout= 0;\n\n    }\n\n\n\n    if(!s-> in_ch_layout)\n\n        s-> in_ch_layout= av_get_default_channel_layout(s->used_ch_count);\n\n    if(!s->out_ch_layout)\n\n        s->out_ch_layout= av_get_default_channel_layout(s->out.ch_count);\n\n\n\n    s->rematrix= s->out_ch_layout  !=s->in_ch_layout || s->rematrix_volume!=1.0 ||\n\n                 s->rematrix_custom;\n\n\n\n    if(s->int_sample_fmt == AV_SAMPLE_FMT_NONE){\n\n        if(av_get_planar_sample_fmt(s->in_sample_fmt) <= AV_SAMPLE_FMT_S16P){\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_S16P;\n\n        }else if(   av_get_planar_sample_fmt(s-> in_sample_fmt) == AV_SAMPLE_FMT_S32P\n\n                 && av_get_planar_sample_fmt(s->out_sample_fmt) == AV_SAMPLE_FMT_S32P\n\n                 && !s->rematrix\n\n                 && s->engine != SWR_ENGINE_SOXR){\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_S32P;\n\n        }else if(av_get_planar_sample_fmt(s->in_sample_fmt) <= AV_SAMPLE_FMT_FLTP){\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_FLTP;\n\n        }else{\n\n            av_log(s, AV_LOG_DEBUG, \"Using double precision mode\\n\");\n\n            s->int_sample_fmt= AV_SAMPLE_FMT_DBLP;\n\n        }\n\n    }\n\n\n\n    if(   s->int_sample_fmt != AV_SAMPLE_FMT_S16P\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_S32P\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_FLTP\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_DBLP){\n\n        av_log(s, AV_LOG_ERROR, \"Requested sample format %s is not supported internally, S16/S32/FLT/DBL is supported\\n\", av_get_sample_fmt_name(s->int_sample_fmt));\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    set_audiodata_fmt(&s-> in, s-> in_sample_fmt);\n\n    set_audiodata_fmt(&s->out, s->out_sample_fmt);\n\n\n\n    if (s->firstpts_in_samples != AV_NOPTS_VALUE) {\n\n        if (!s->async && s->min_compensation >= FLT_MAX/2)\n\n            s->async = 1;\n\n        s->firstpts =\n\n        s->outpts   = s->firstpts_in_samples * s->out_sample_rate;\n\n    } else\n\n        s->firstpts = AV_NOPTS_VALUE;\n\n\n\n    if (s->async) {\n\n        if (s->min_compensation >= FLT_MAX/2)\n\n            s->min_compensation = 0.001;\n\n        if (s->async > 1.0001) {\n\n            s->max_soft_compensation = s->async / (double) s->in_sample_rate;\n\n        }\n\n    }\n\n\n\n    if (s->out_sample_rate!=s->in_sample_rate || (s->flags & SWR_FLAG_RESAMPLE)){\n\n        s->resample = s->resampler->init(s->resample, s->out_sample_rate, s->in_sample_rate, s->filter_size, s->phase_shift, s->linear_interp, s->cutoff, s->int_sample_fmt, s->filter_type, s->kaiser_beta, s->precision, s->cheby);\n\n    }else\n\n        s->resampler->free(&s->resample);\n\n    if(    s->int_sample_fmt != AV_SAMPLE_FMT_S16P\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_S32P\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_FLTP\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_DBLP\n\n        && s->resample){\n\n        av_log(s, AV_LOG_ERROR, \"Resampling only supported with internal s16/s32/flt/dbl\\n\");\n\n        return -1;\n\n    }\n\n\n\n#define RSC 1 //FIXME finetune\n\n    if(!s-> in.ch_count)\n\n        s-> in.ch_count= av_get_channel_layout_nb_channels(s-> in_ch_layout);\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n    if(!s->out.ch_count)\n\n        s->out.ch_count= av_get_channel_layout_nb_channels(s->out_ch_layout);\n\n\n\n    if(!s-> in.ch_count){\n\n        av_assert0(!s->in_ch_layout);\n\n        av_log(s, AV_LOG_ERROR, \"Input channel count and layout are unset\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((!s->out_ch_layout || !s->in_ch_layout) && s->used_ch_count != s->out.ch_count && !s->rematrix_custom) {\n\n        char l1[1024], l2[1024];\n\n        av_get_channel_layout_string(l1, sizeof(l1), s-> in.ch_count, s-> in_ch_layout);\n\n        av_get_channel_layout_string(l2, sizeof(l2), s->out.ch_count, s->out_ch_layout);\n\n        av_log(s, AV_LOG_ERROR, \"Rematrix is needed between %s and %s \"\n\n               \"but there is not enough information to do it\\n\", l1, l2);\n\n        return -1;\n\n    }\n\n\n\nav_assert0(s->used_ch_count);\n\nav_assert0(s->out.ch_count);\n\n    s->resample_first= RSC*s->out.ch_count/s->in.ch_count - RSC < s->out_sample_rate/(float)s-> in_sample_rate - 1.0;\n\n\n\n    s->in_buffer= s->in;\n\n    s->silence  = s->in;\n\n    s->drop_temp= s->out;\n\n\n\n    if(!s->resample && !s->rematrix && !s->channel_map && !s->dither.method){\n\n        s->full_convert = swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                                   s-> in_sample_fmt, s-> in.ch_count, NULL, 0);\n\n        return 0;\n\n    }\n\n\n\n    s->in_convert = swri_audio_convert_alloc(s->int_sample_fmt,\n\n                                             s-> in_sample_fmt, s->used_ch_count, s->channel_map, 0);\n\n    s->out_convert= swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                             s->int_sample_fmt, s->out.ch_count, NULL, 0);\n\n\n\n    if (!s->in_convert || !s->out_convert)\n\n        return AVERROR(ENOMEM);\n\n\n\n    s->postin= s->in;\n\n    s->preout= s->out;\n\n    s->midbuf= s->in;\n\n\n\n    if(s->channel_map){\n\n        s->postin.ch_count=\n\n        s->midbuf.ch_count= s->used_ch_count;\n\n        if(s->resample)\n\n            s->in_buffer.ch_count= s->used_ch_count;\n\n    }\n\n    if(!s->resample_first){\n\n        s->midbuf.ch_count= s->out.ch_count;\n\n        if(s->resample)\n\n            s->in_buffer.ch_count = s->out.ch_count;\n\n    }\n\n\n\n    set_audiodata_fmt(&s->postin, s->int_sample_fmt);\n\n    set_audiodata_fmt(&s->midbuf, s->int_sample_fmt);\n\n    set_audiodata_fmt(&s->preout, s->int_sample_fmt);\n\n\n\n    if(s->resample){\n\n        set_audiodata_fmt(&s->in_buffer, s->int_sample_fmt);\n\n    }\n\n\n\n    if ((ret = swri_dither_init(s, s->out_sample_fmt, s->int_sample_fmt)) < 0)\n\n        return ret;\n\n\n\n    if(s->rematrix || s->dither.method)\n\n        return swri_rematrix_init(s);\n\n\n\n    return 0;\n\n}\n", "idx": 23426, "_split": "valid", "_hash": "76e907ce6a972698f23a147101f3b1da"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "void rgb16tobgr32(const uint8_t *src, uint8_t *dst, unsigned int src_size)\n\n{\n\n\tconst uint16_t *end;\n\n\tuint8_t *d = (uint8_t *)dst;\n\n\tconst uint16_t *s = (uint16_t *)src;\n\n\tend = s + src_size/2;\n\n\twhile(s < end)\n\n\t{\n\n\t\tregister uint16_t bgr;\n\n\t\tbgr = *s++;\n\n\t\t*d++ = (bgr&0xF800)>>8;\n\n\t\t*d++ = (bgr&0x7E0)>>3;\n\n\t\t*d++ = (bgr&0x1F)<<3;\n\n\t\t*d++ = 0;\n\n\t}\n\n}\n", "idx": 23431, "_split": "valid", "_hash": "5edaf3e25e432ba9b0ae087ac19af4c4"}
{"project": "FFmpeg", "commit_id": "c55e637072b694a1db40e21948d218bfa2e744bb", "target": 1, "func": "static int decode_audio_block(AC3DecodeContext *s, int blk)\n\n{\n\n    int fbw_channels = s->fbw_channels;\n\n    int channel_mode = s->channel_mode;\n\n    int i, bnd, seg, ch, ret;\n\n    int different_transforms;\n\n    int downmix_output;\n\n    int cpl_in_use;\n\n    GetBitContext *gbc = &s->gbc;\n\n    uint8_t bit_alloc_stages[AC3_MAX_CHANNELS] = { 0 };\n\n\n\n    /* block switch flags */\n\n    different_transforms = 0;\n\n    if (s->block_switch_syntax) {\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->block_switch[ch] = get_bits1(gbc);\n\n            if (ch > 1 && s->block_switch[ch] != s->block_switch[1])\n\n                different_transforms = 1;\n\n        }\n\n    }\n\n\n\n    /* dithering flags */\n\n    if (s->dither_flag_syntax) {\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->dither_flag[ch] = get_bits1(gbc);\n\n        }\n\n    }\n\n\n\n    /* dynamic range */\n\n    i = !s->channel_mode;\n\n    do {\n\n        if (get_bits1(gbc)) {\n\n            /* Allow asymmetric application of DRC when drc_scale > 1.\n\n               Amplification of quiet sounds is enhanced */\n\n            int range_bits = get_bits(gbc, 8);\n\n            INTFLOAT range = AC3_RANGE(range_bits);\n\n            if (range_bits <= 127 || s->drc_scale <= 1.0)\n\n                s->dynamic_range[i] = AC3_DYNAMIC_RANGE(range);\n\n            else\n\n                s->dynamic_range[i] = range;\n\n        } else if (blk == 0) {\n\n            s->dynamic_range[i] = AC3_DYNAMIC_RANGE1;\n\n        }\n\n    } while (i--);\n\n\n\n    /* spectral extension strategy */\n\n    if (s->eac3 && (!blk || get_bits1(gbc))) {\n\n        s->spx_in_use = get_bits1(gbc);\n\n        if (s->spx_in_use) {\n\n            if ((ret = spx_strategy(s, blk)) < 0)\n\n                return ret;\n\n        }\n\n    }\n\n    if (!s->eac3 || !s->spx_in_use) {\n\n        s->spx_in_use = 0;\n\n        for (ch = 1; ch <= fbw_channels; ch++) {\n\n            s->channel_uses_spx[ch] = 0;\n\n            s->first_spx_coords[ch] = 1;\n\n        }\n\n    }\n\n\n\n    /* spectral extension coordinates */\n\n    if (s->spx_in_use)\n\n        spx_coordinates(s);\n\n\n\n    /* coupling strategy */\n\n    if (s->eac3 ? s->cpl_strategy_exists[blk] : get_bits1(gbc)) {\n\n        if ((ret = coupling_strategy(s, blk, bit_alloc_stages)) < 0)\n\n            return ret;\n\n    } else if (!s->eac3) {\n\n        if (!blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new coupling strategy must \"\n\n                   \"be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        } else {\n\n            s->cpl_in_use[blk] = s->cpl_in_use[blk-1];\n\n        }\n\n    }\n\n    cpl_in_use = s->cpl_in_use[blk];\n\n\n\n    /* coupling coordinates */\n\n    if (cpl_in_use) {\n\n        if ((ret = coupling_coordinates(s, blk)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    /* stereo rematrixing strategy and band structure */\n\n    if (channel_mode == AC3_CHMODE_STEREO) {\n\n        if ((s->eac3 && !blk) || get_bits1(gbc)) {\n\n            s->num_rematrixing_bands = 4;\n\n            if (cpl_in_use && s->start_freq[CPL_CH] <= 61) {\n\n                s->num_rematrixing_bands -= 1 + (s->start_freq[CPL_CH] == 37);\n\n            } else if (s->spx_in_use && s->spx_src_start_freq <= 61) {\n\n                s->num_rematrixing_bands--;\n\n            }\n\n            for (bnd = 0; bnd < s->num_rematrixing_bands; bnd++)\n\n                s->rematrixing_flags[bnd] = get_bits1(gbc);\n\n        } else if (!blk) {\n\n            av_log(s->avctx, AV_LOG_WARNING, \"Warning: \"\n\n                   \"new rematrixing strategy not present in block 0\\n\");\n\n            s->num_rematrixing_bands = 0;\n\n        }\n\n    }\n\n\n\n    /* exponent strategies for each channel */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (!s->eac3)\n\n            s->exp_strategy[blk][ch] = get_bits(gbc, 2 - (ch == s->lfe_ch));\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE)\n\n            bit_alloc_stages[ch] = 3;\n\n    }\n\n\n\n    /* channel bandwidth */\n\n    for (ch = 1; ch <= fbw_channels; ch++) {\n\n        s->start_freq[ch] = 0;\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE) {\n\n            int group_size;\n\n            int prev = s->end_freq[ch];\n\n            if (s->channel_in_cpl[ch])\n\n                s->end_freq[ch] = s->start_freq[CPL_CH];\n\n            else if (s->channel_uses_spx[ch])\n\n                s->end_freq[ch] = s->spx_src_start_freq;\n\n            else {\n\n                int bandwidth_code = get_bits(gbc, 6);\n\n                if (bandwidth_code > 60) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"bandwidth code = %d > 60\\n\", bandwidth_code);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                s->end_freq[ch] = bandwidth_code * 3 + 73;\n\n            }\n\n            group_size = 3 << (s->exp_strategy[blk][ch] - 1);\n\n            s->num_exp_groups[ch] = (s->end_freq[ch] + group_size-4) / group_size;\n\n            if (blk > 0 && s->end_freq[ch] != prev)\n\n                memset(bit_alloc_stages, 3, AC3_MAX_CHANNELS);\n\n        }\n\n    }\n\n    if (cpl_in_use && s->exp_strategy[blk][CPL_CH] != EXP_REUSE) {\n\n        s->num_exp_groups[CPL_CH] = (s->end_freq[CPL_CH] - s->start_freq[CPL_CH]) /\n\n                                    (3 << (s->exp_strategy[blk][CPL_CH] - 1));\n\n    }\n\n\n\n    /* decode exponents for each channel */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (s->exp_strategy[blk][ch] != EXP_REUSE) {\n\n            s->dexps[ch][0] = get_bits(gbc, 4) << !ch;\n\n            if (decode_exponents(s, gbc, s->exp_strategy[blk][ch],\n\n                                 s->num_exp_groups[ch], s->dexps[ch][0],\n\n                                 &s->dexps[ch][s->start_freq[ch]+!!ch])) {\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (ch != CPL_CH && ch != s->lfe_ch)\n\n                skip_bits(gbc, 2); /* skip gainrng */\n\n        }\n\n    }\n\n\n\n    /* bit allocation information */\n\n    if (s->bit_allocation_syntax) {\n\n        if (get_bits1(gbc)) {\n\n            s->bit_alloc_params.slow_decay = ff_ac3_slow_decay_tab[get_bits(gbc, 2)] >> s->bit_alloc_params.sr_shift;\n\n            s->bit_alloc_params.fast_decay = ff_ac3_fast_decay_tab[get_bits(gbc, 2)] >> s->bit_alloc_params.sr_shift;\n\n            s->bit_alloc_params.slow_gain  = ff_ac3_slow_gain_tab[get_bits(gbc, 2)];\n\n            s->bit_alloc_params.db_per_bit = ff_ac3_db_per_bit_tab[get_bits(gbc, 2)];\n\n            s->bit_alloc_params.floor  = ff_ac3_floor_tab[get_bits(gbc, 3)];\n\n            for (ch = !cpl_in_use; ch <= s->channels; ch++)\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        } else if (!blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new bit allocation info must \"\n\n                   \"be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* signal-to-noise ratio offsets and fast gains (signal-to-mask ratios) */\n\n    if (!s->eac3 || !blk) {\n\n        if (s->snr_offset_strategy && get_bits1(gbc)) {\n\n            int snr = 0;\n\n            int csnr;\n\n            csnr = (get_bits(gbc, 6) - 15) << 4;\n\n            for (i = ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n                /* snr offset */\n\n                if (ch == i || s->snr_offset_strategy == 2)\n\n                    snr = (csnr + get_bits(gbc, 4)) << 2;\n\n                /* run at least last bit allocation stage if snr offset changes */\n\n                if (blk && s->snr_offset[ch] != snr) {\n\n                    bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 1);\n\n                }\n\n                s->snr_offset[ch] = snr;\n\n\n\n                /* fast gain (normal AC-3 only) */\n\n                if (!s->eac3) {\n\n                    int prev = s->fast_gain[ch];\n\n                    s->fast_gain[ch] = ff_ac3_fast_gain_tab[get_bits(gbc, 3)];\n\n                    /* run last 2 bit allocation stages if fast gain changes */\n\n                    if (blk && prev != s->fast_gain[ch])\n\n                        bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n                }\n\n            }\n\n        } else if (!s->eac3 && !blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new snr offsets must be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* fast gain (E-AC-3 only) */\n\n    if (s->fast_gain_syntax && get_bits1(gbc)) {\n\n        for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n            int prev = s->fast_gain[ch];\n\n            s->fast_gain[ch] = ff_ac3_fast_gain_tab[get_bits(gbc, 3)];\n\n            /* run last 2 bit allocation stages if fast gain changes */\n\n            if (blk && prev != s->fast_gain[ch])\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        }\n\n    } else if (s->eac3 && !blk) {\n\n        for (ch = !cpl_in_use; ch <= s->channels; ch++)\n\n            s->fast_gain[ch] = ff_ac3_fast_gain_tab[4];\n\n    }\n\n\n\n    /* E-AC-3 to AC-3 converter SNR offset */\n\n    if (s->frame_type == EAC3_FRAME_TYPE_INDEPENDENT && get_bits1(gbc)) {\n\n        skip_bits(gbc, 10); // skip converter snr offset\n\n    }\n\n\n\n    /* coupling leak information */\n\n    if (cpl_in_use) {\n\n        if (s->first_cpl_leak || get_bits1(gbc)) {\n\n            int fl = get_bits(gbc, 3);\n\n            int sl = get_bits(gbc, 3);\n\n            /* run last 2 bit allocation stages for coupling channel if\n\n               coupling leak changes */\n\n            if (blk && (fl != s->bit_alloc_params.cpl_fast_leak ||\n\n                sl != s->bit_alloc_params.cpl_slow_leak)) {\n\n                bit_alloc_stages[CPL_CH] = FFMAX(bit_alloc_stages[CPL_CH], 2);\n\n            }\n\n            s->bit_alloc_params.cpl_fast_leak = fl;\n\n            s->bit_alloc_params.cpl_slow_leak = sl;\n\n        } else if (!s->eac3 && !blk) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"new coupling leak info must \"\n\n                   \"be present in block 0\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->first_cpl_leak = 0;\n\n    }\n\n\n\n    /* delta bit allocation information */\n\n    if (s->dba_syntax && get_bits1(gbc)) {\n\n        /* delta bit allocation exists (strategy) */\n\n        for (ch = !cpl_in_use; ch <= fbw_channels; ch++) {\n\n            s->dba_mode[ch] = get_bits(gbc, 2);\n\n            if (s->dba_mode[ch] == DBA_RESERVED) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"delta bit allocation strategy reserved\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n        }\n\n        /* channel delta offset, len and bit allocation */\n\n        for (ch = !cpl_in_use; ch <= fbw_channels; ch++) {\n\n            if (s->dba_mode[ch] == DBA_NEW) {\n\n                s->dba_nsegs[ch] = get_bits(gbc, 3) + 1;\n\n                for (seg = 0; seg < s->dba_nsegs[ch]; seg++) {\n\n                    s->dba_offsets[ch][seg] = get_bits(gbc, 5);\n\n                    s->dba_lengths[ch][seg] = get_bits(gbc, 4);\n\n                    s->dba_values[ch][seg]  = get_bits(gbc, 3);\n\n                }\n\n                /* run last 2 bit allocation stages if new dba values */\n\n                bit_alloc_stages[ch] = FFMAX(bit_alloc_stages[ch], 2);\n\n            }\n\n        }\n\n    } else if (blk == 0) {\n\n        for (ch = 0; ch <= s->channels; ch++) {\n\n            s->dba_mode[ch] = DBA_NONE;\n\n        }\n\n    }\n\n\n\n    /* Bit allocation */\n\n    for (ch = !cpl_in_use; ch <= s->channels; ch++) {\n\n        if (bit_alloc_stages[ch] > 2) {\n\n            /* Exponent mapping into PSD and PSD integration */\n\n            ff_ac3_bit_alloc_calc_psd(s->dexps[ch],\n\n                                      s->start_freq[ch], s->end_freq[ch],\n\n                                      s->psd[ch], s->band_psd[ch]);\n\n        }\n\n        if (bit_alloc_stages[ch] > 1) {\n\n            /* Compute excitation function, Compute masking curve, and\n\n               Apply delta bit allocation */\n\n            if (ff_ac3_bit_alloc_calc_mask(&s->bit_alloc_params, s->band_psd[ch],\n\n                                           s->start_freq[ch],  s->end_freq[ch],\n\n                                           s->fast_gain[ch],   (ch == s->lfe_ch),\n\n                                           s->dba_mode[ch],    s->dba_nsegs[ch],\n\n                                           s->dba_offsets[ch], s->dba_lengths[ch],\n\n                                           s->dba_values[ch],  s->mask[ch])) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"error in bit allocation\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n        if (bit_alloc_stages[ch] > 0) {\n\n            /* Compute bit allocation */\n\n            const uint8_t *bap_tab = s->channel_uses_aht[ch] ?\n\n                                     ff_eac3_hebap_tab : ff_ac3_bap_tab;\n\n            s->ac3dsp.bit_alloc_calc_bap(s->mask[ch], s->psd[ch],\n\n                                      s->start_freq[ch], s->end_freq[ch],\n\n                                      s->snr_offset[ch],\n\n                                      s->bit_alloc_params.floor,\n\n                                      bap_tab, s->bap[ch]);\n\n        }\n\n    }\n\n\n\n    /* unused dummy data */\n\n    if (s->skip_syntax && get_bits1(gbc)) {\n\n        int skipl = get_bits(gbc, 9);\n\n        skip_bits_long(gbc, 8 * skipl);\n\n    }\n\n\n\n    /* unpack the transform coefficients\n\n       this also uncouples channels if coupling is in use. */\n\n    decode_transform_coeffs(s, blk);\n\n\n\n    /* TODO: generate enhanced coupling coordinates and uncouple */\n\n\n\n    /* recover coefficients if rematrixing is in use */\n\n    if (s->channel_mode == AC3_CHMODE_STEREO)\n\n        do_rematrixing(s);\n\n\n\n    /* apply scaling to coefficients (headroom, dynrng) */\n\n    for (ch = 1; ch <= s->channels; ch++) {\n\n        int audio_channel = 0;\n\n        INTFLOAT gain;\n\n        if (s->channel_mode == AC3_CHMODE_DUALMONO)\n\n            audio_channel = 2-ch;\n\n        if (s->heavy_compression && s->compression_exists[audio_channel])\n\n            gain = s->heavy_dynamic_range[audio_channel];\n\n        else\n\n            gain = s->dynamic_range[audio_channel];\n\n\n\n#if USE_FIXED\n\n        scale_coefs(s->transform_coeffs[ch], s->fixed_coeffs[ch], gain, 256);\n\n#else\n\n        if (s->target_level != 0)\n\n          gain = gain * s->level_gain[audio_channel];\n\n        gain *= 1.0 / 4194304.0f;\n\n        s->fmt_conv.int32_to_float_fmul_scalar(s->transform_coeffs[ch],\n\n                                               s->fixed_coeffs[ch], gain, 256);\n\n#endif\n\n    }\n\n\n\n    /* apply spectral extension to high frequency bins */\n\n    if (CONFIG_EAC3_DECODER && s->spx_in_use) {\n\n        ff_eac3_apply_spectral_extension(s);\n\n    }\n\n\n\n    /* downmix and MDCT. order depends on whether block switching is used for\n\n       any channel in this block. this is because coefficients for the long\n\n       and short transforms cannot be mixed. */\n\n    downmix_output = s->channels != s->out_channels &&\n\n                     !((s->output_mode & AC3_OUTPUT_LFEON) &&\n\n                     s->fbw_channels == s->out_channels);\n\n    if (different_transforms) {\n\n        /* the delay samples have already been downmixed, so we upmix the delay\n\n           samples in order to reconstruct all channels before downmixing. */\n\n        if (s->downmixed) {\n\n            s->downmixed = 0;\n\n            ac3_upmix_delay(s);\n\n        }\n\n\n\n        do_imdct(s, s->channels);\n\n\n\n        if (downmix_output) {\n\n#if USE_FIXED\n\n            ac3_downmix_c_fixed16(s->outptr, s->downmix_coeffs,\n\n                              s->out_channels, s->fbw_channels, 256);\n\n#else\n\n            ff_ac3dsp_downmix(&s->ac3dsp, s->outptr, s->downmix_coeffs,\n\n                              s->out_channels, s->fbw_channels, 256);\n\n#endif\n\n        }\n\n    } else {\n\n        if (downmix_output) {\n\n            AC3_RENAME(ff_ac3dsp_downmix)(&s->ac3dsp, s->xcfptr + 1, s->downmix_coeffs,\n\n                                          s->out_channels, s->fbw_channels, 256);\n\n        }\n\n\n\n        if (downmix_output && !s->downmixed) {\n\n            s->downmixed = 1;\n\n            AC3_RENAME(ff_ac3dsp_downmix)(&s->ac3dsp, s->dlyptr, s->downmix_coeffs,\n\n                                          s->out_channels, s->fbw_channels, 128);\n\n        }\n\n\n\n        do_imdct(s, s->out_channels);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23432, "_split": "valid", "_hash": "18516604cf0b7128d4178a740dd2d026"}
{"project": "FFmpeg", "commit_id": "26f2e2f3f73f0da088e6765291d0839ebb077b03", "target": 1, "func": "static void write_header(AVFormatContext *s)\n\n{\n\n    double min_buffer_time = 1.0;\n\n    avio_printf(s->pb, \"<?xml version=\\\"1.0\\\" encoding=\\\"UTF-8\\\"?>\\n\");\n\n    avio_printf(s->pb, \"<MPD\\n\");\n\n    avio_printf(s->pb, \"  xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\"\\n\");\n\n    avio_printf(s->pb, \"  xmlns=\\\"urn:mpeg:DASH:schema:MPD:2011\\\"\\n\");\n\n    avio_printf(s->pb, \"  xsi:schemaLocation=\\\"urn:mpeg:DASH:schema:MPD:2011\\\"\\n\");\n\n    avio_printf(s->pb, \"  type=\\\"static\\\"\\n\");\n\n    avio_printf(s->pb, \"  mediaPresentationDuration=\\\"PT%gS\\\"\\n\",\n\n                get_duration(s));\n\n    avio_printf(s->pb, \"  minBufferTime=\\\"PT%gS\\\"\\n\",\n\n                min_buffer_time);\n\n    avio_printf(s->pb, \"  profiles=\\\"urn:webm:dash:profile:webm-on-demand:2012\\\"\");\n\n    avio_printf(s->pb, \">\\n\");\n\n}\n", "idx": 23434, "_split": "valid", "_hash": "6f3699541af717c6fef7132f41d6c3e3"}
{"project": "FFmpeg", "commit_id": "636ced8e1dc8248a1353b416240b93d70ad03edb", "target": 1, "func": "static void opt_input_file(void *optctx, const char *arg)\n\n{\n\n    if (input_filename) {\n\n        fprintf(stderr,\n\n                \"Argument '%s' provided as input filename, but '%s' was already specified.\\n\",\n\n                arg, input_filename);\n\n        exit(1);\n\n    }\n\n    if (!strcmp(arg, \"-\"))\n\n        arg = \"pipe:\";\n\n    input_filename = arg;\n\n}\n", "idx": 23440, "_split": "valid", "_hash": "36b22a9594e78f785cecde679f3b56d4"}
{"project": "FFmpeg", "commit_id": "398f015f077c6a2406deffd9e37ff34b9c7bb3bc", "target": 0, "func": "static int transcode_subtitles(InputStream *ist, AVPacket *pkt, int *got_output)\n\n{\n\n    AVSubtitle subtitle;\n\n    int i, ret = avcodec_decode_subtitle2(ist->dec_ctx,\n\n                                          &subtitle, got_output, pkt);\n\n    if (ret < 0)\n\n        return ret;\n\n    if (!*got_output)\n\n        return ret;\n\n\n\n    ist->frames_decoded++;\n\n\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        OutputStream *ost = output_streams[i];\n\n\n\n        if (!check_output_constraints(ist, ost) || !ost->encoding_needed)\n\n            continue;\n\n\n\n        do_subtitle_out(output_files[ost->file_index]->ctx, ost, ist, &subtitle, pkt->pts);\n\n    }\n\n\n\n    avsubtitle_free(&subtitle);\n\n    return ret;\n\n}\n", "idx": 23471, "_split": "valid", "_hash": "299c808fc0635c2649e835a7954fe6f6"}
{"project": "FFmpeg", "commit_id": "1d16a1cf99488f16492b1bb48e023f4da8377e07", "target": 0, "func": "static void ff_h264_idct8_add4_mmx(uint8_t *dst, const int *block_offset, DCTELEM *block, int stride, const uint8_t nnzc[6*8]){\n\n    int i;\n\n    for(i=0; i<16; i+=4){\n\n        if(nnzc[ scan8[i] ])\n\n            ff_h264_idct8_add_mmx(dst + block_offset[i], block + i*16, stride);\n\n    }\n\n}\n", "idx": 23488, "_split": "valid", "_hash": "c81d31f0d593d2936708304fb7f15fad"}
{"project": "FFmpeg", "commit_id": "3cec81f4d4f26b62bc2d22bb450bbf51ec3a7f09", "target": 0, "func": "static int mov_read_udta_string(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    char tmp_key[5];\n\n    char str[1024], key2[32], language[4] = {0};\n\n    const char *key = NULL;\n\n    uint16_t langcode = 0;\n\n    uint32_t data_type = 0, str_size;\n\n    int (*parse)(MOVContext*, AVIOContext*, unsigned, const char*) = NULL;\n\n\n\n    switch (atom.type) {\n\n    case MKTAG(0xa9,'n','a','m'): key = \"title\";     break;\n\n    case MKTAG(0xa9,'a','u','t'):\n\n    case MKTAG(0xa9,'A','R','T'): key = \"artist\";    break;\n\n    case MKTAG( 'a','A','R','T'): key = \"album_artist\";    break;\n\n    case MKTAG(0xa9,'w','r','t'): key = \"composer\";  break;\n\n    case MKTAG( 'c','p','r','t'):\n\n    case MKTAG(0xa9,'c','p','y'): key = \"copyright\"; break;\n\n    case MKTAG(0xa9,'c','m','t'):\n\n    case MKTAG(0xa9,'i','n','f'): key = \"comment\";   break;\n\n    case MKTAG(0xa9,'a','l','b'): key = \"album\";     break;\n\n    case MKTAG(0xa9,'d','a','y'): key = \"date\";      break;\n\n    case MKTAG(0xa9,'g','e','n'): key = \"genre\";     break;\n\n    case MKTAG( 'g','n','r','e'): key = \"genre\";\n\n        parse = mov_metadata_gnre; break;\n\n    case MKTAG(0xa9,'t','o','o'):\n\n    case MKTAG(0xa9,'s','w','r'): key = \"encoder\";   break;\n\n    case MKTAG(0xa9,'e','n','c'): key = \"encoder\";   break;\n\n    case MKTAG(0xa9,'x','y','z'): key = \"location\";  break;\n\n    case MKTAG( 'd','e','s','c'): key = \"description\";break;\n\n    case MKTAG( 'l','d','e','s'): key = \"synopsis\";  break;\n\n    case MKTAG( 't','v','s','h'): key = \"show\";      break;\n\n    case MKTAG( 't','v','e','n'): key = \"episode_id\";break;\n\n    case MKTAG( 't','v','n','n'): key = \"network\";   break;\n\n    case MKTAG( 't','r','k','n'): key = \"track\";\n\n        parse = mov_metadata_track_or_disc_number; break;\n\n    case MKTAG( 'd','i','s','k'): key = \"disc\";\n\n        parse = mov_metadata_track_or_disc_number; break;\n\n    case MKTAG( 't','v','e','s'): key = \"episode_sort\";\n\n        parse = mov_metadata_int8_bypass_padding; break;\n\n    case MKTAG( 't','v','s','n'): key = \"season_number\";\n\n        parse = mov_metadata_int8_bypass_padding; break;\n\n    case MKTAG( 's','t','i','k'): key = \"media_type\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'h','d','v','d'): key = \"hd_video\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'p','g','a','p'): key = \"gapless_playback\";\n\n        parse = mov_metadata_int8_no_padding; break;\n\n    case MKTAG( 'l','o','c','i'):\n\n        return mov_metadata_loci(c, pb, atom.size);\n\n    }\n\n\n\n    if (c->itunes_metadata && atom.size > 8) {\n\n        int data_size = avio_rb32(pb);\n\n        int tag = avio_rl32(pb);\n\n        if (tag == MKTAG('d','a','t','a')) {\n\n            data_type = avio_rb32(pb); // type\n\n            avio_rb32(pb); // unknown\n\n            str_size = data_size - 16;\n\n            atom.size -= 16;\n\n\n\n            if (atom.type == MKTAG('c', 'o', 'v', 'r')) {\n\n                int ret = mov_read_covr(c, pb, data_type, str_size);\n\n                if (ret < 0) {\n\n                    av_log(c->fc, AV_LOG_ERROR, \"Error parsing cover art.\\n\");\n\n                    return ret;\n\n                }\n\n            }\n\n        } else return 0;\n\n    } else if (atom.size > 4 && key && !c->itunes_metadata) {\n\n        str_size = avio_rb16(pb); // string length\n\n        langcode = avio_rb16(pb);\n\n        ff_mov_lang_to_iso639(langcode, language);\n\n        atom.size -= 4;\n\n    } else\n\n        str_size = atom.size;\n\n\n\n    if (c->export_all && !key) {\n\n        snprintf(tmp_key, 5, \"%.4s\", (char*)&atom.type);\n\n        key = tmp_key;\n\n    }\n\n\n\n    if (!key)\n\n        return 0;\n\n    if (atom.size < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    str_size = FFMIN3(sizeof(str)-1, str_size, atom.size);\n\n\n\n    if (parse)\n\n        parse(c, pb, str_size, key);\n\n    else {\n\n        if (data_type == 3 || (data_type == 0 && (langcode < 0x400 || langcode == 0x7fff))) { // MAC Encoded\n\n            mov_read_mac_string(c, pb, str_size, str, sizeof(str));\n\n        } else {\n\n            avio_read(pb, str, str_size);\n\n            str[str_size] = 0;\n\n        }\n\n        c->fc->event_flags |= AVFMT_EVENT_FLAG_METADATA_UPDATED;\n\n        av_dict_set(&c->fc->metadata, key, str, 0);\n\n        if (*language && strcmp(language, \"und\")) {\n\n            snprintf(key2, sizeof(key2), \"%s-%s\", key, language);\n\n            av_dict_set(&c->fc->metadata, key2, str, 0);\n\n        }\n\n    }\n\n    av_dlog(c->fc, \"lang \\\"%3s\\\" \", language);\n\n    av_dlog(c->fc, \"tag \\\"%s\\\" value \\\"%s\\\" atom \\\"%.4s\\\" %d %\"PRId64\"\\n\",\n\n            key, str, (char*)&atom.type, str_size, atom.size);\n\n\n\n    return 0;\n\n}\n", "idx": 23509, "_split": "valid", "_hash": "3cc48477a77db31b36446e85cf8b672e"}
{"project": "FFmpeg", "commit_id": "7546964f96168cd6ac819ef4c3212ee586619f1a", "target": 0, "func": "static int nvdec_h264_decode_init(AVCodecContext *avctx)\n\n{\n\n    const H264Context *h = avctx->priv_data;\n\n    const SPS       *sps = h->ps.sps;\n\n    return ff_nvdec_decode_init(avctx, sps->ref_frame_count + sps->num_reorder_frames);\n\n}\n", "idx": 23575, "_split": "valid", "_hash": "a636598b08c2981bff5bd4ab681ca9da"}
{"project": "FFmpeg", "commit_id": "e5755893786ecab2e6f0414d1b2983dcaa3d237e", "target": 1, "func": "static void mxf_free_metadataset(MXFMetadataSet **ctx, int freectx)\n\n{\n\n    MXFIndexTableSegment *seg;\n\n    switch ((*ctx)->type) {\n\n    case Descriptor:\n\n        av_freep(&((MXFDescriptor *)*ctx)->extradata);\n\n        break;\n\n    case MultipleDescriptor:\n\n        av_freep(&((MXFDescriptor *)*ctx)->sub_descriptors_refs);\n\n        break;\n\n    case Sequence:\n\n        av_freep(&((MXFSequence *)*ctx)->structural_components_refs);\n\n        break;\n\n    case EssenceGroup:\n\n        av_freep(&((MXFEssenceGroup *)*ctx)->structural_components_refs);\n\n        break;\n\n    case SourcePackage:\n\n    case MaterialPackage:\n\n        av_freep(&((MXFPackage *)*ctx)->tracks_refs);\n\n        av_freep(&((MXFPackage *)*ctx)->name);\n\n\n        break;\n\n    case TaggedValue:\n\n        av_freep(&((MXFTaggedValue *)*ctx)->name);\n\n        av_freep(&((MXFTaggedValue *)*ctx)->value);\n\n        break;\n\n    case IndexTableSegment:\n\n        seg = (MXFIndexTableSegment *)*ctx;\n\n        av_freep(&seg->temporal_offset_entries);\n\n        av_freep(&seg->flag_entries);\n\n        av_freep(&seg->stream_offset_entries);\n\n    default:\n\n        break;\n\n    }\n\n    if (freectx)\n\n    av_freep(ctx);\n\n}", "idx": 23580, "_split": "valid", "_hash": "77d75dc9af03dbf38644b2177462c266"}
{"project": "FFmpeg", "commit_id": "61d43a265176e8e724301b7721affbe9f61729d5", "target": 0, "func": "static int lag_decode_arith_plane(LagarithContext *l, uint8_t *dst,\n\n                                  int width, int height, int stride,\n\n                                  const uint8_t *src, int src_size)\n\n{\n\n    int i = 0;\n\n    int read = 0;\n\n    uint32_t length;\n\n    uint32_t offset = 1;\n\n    int esc_count;\n\n    GetBitContext gb;\n\n    lag_rac rac;\n\n    const uint8_t *src_end = src + src_size;\n\n\n\n    rac.avctx = l->avctx;\n\n    l->zeros = 0;\n\n\n\n    if(src_size < 2)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    esc_count = src[0];\n\n    if (esc_count < 4) {\n\n        length = width * height;\n\n        if(src_size < 5)\n\n            return AVERROR_INVALIDDATA;\n\n        if (esc_count && AV_RL32(src + 1) < length) {\n\n            length = AV_RL32(src + 1);\n\n            offset += 4;\n\n        }\n\n\n\n        init_get_bits8(&gb, src + offset, src_size - offset);\n\n\n\n        if (lag_read_prob_header(&rac, &gb) < 0)\n\n            return -1;\n\n\n\n        ff_lag_rac_init(&rac, &gb, length - stride);\n\n\n\n        for (i = 0; i < height; i++)\n\n            read += lag_decode_line(l, &rac, dst + (i * stride), width,\n\n                                    stride, esc_count);\n\n\n\n        if (read > length)\n\n            av_log(l->avctx, AV_LOG_WARNING,\n\n                   \"Output more bytes than length (%d of %d)\\n\", read,\n\n                   length);\n\n    } else if (esc_count < 8) {\n\n        esc_count -= 4;\n\n        src ++;\n\n        src_size --;\n\n        if (esc_count > 0) {\n\n            /* Zero run coding only, no range coding. */\n\n            for (i = 0; i < height; i++) {\n\n                int res = lag_decode_zero_run_line(l, dst + (i * stride), src,\n\n                                                   src_end, width, esc_count);\n\n                if (res < 0)\n\n                    return res;\n\n                src += res;\n\n            }\n\n        } else {\n\n            if (src_size < width * height)\n\n                return AVERROR_INVALIDDATA; // buffer not big enough\n\n            /* Plane is stored uncompressed */\n\n            for (i = 0; i < height; i++) {\n\n                memcpy(dst + (i * stride), src, width);\n\n                src += width;\n\n            }\n\n        }\n\n    } else if (esc_count == 0xff) {\n\n        /* Plane is a solid run of given value */\n\n        for (i = 0; i < height; i++)\n\n            memset(dst + i * stride, src[1], width);\n\n        /* Do not apply prediction.\n\n           Note: memset to 0 above, setting first value to src[1]\n\n           and applying prediction gives the same result. */\n\n        return 0;\n\n    } else {\n\n        av_log(l->avctx, AV_LOG_ERROR,\n\n               \"Invalid zero run escape code! (%#x)\\n\", esc_count);\n\n        return -1;\n\n    }\n\n\n\n    if (l->avctx->pix_fmt != AV_PIX_FMT_YUV422P) {\n\n        for (i = 0; i < height; i++) {\n\n            lag_pred_line(l, dst, width, stride, i);\n\n            dst += stride;\n\n        }\n\n    } else {\n\n        for (i = 0; i < height; i++) {\n\n            lag_pred_line_yuy2(l, dst, width, stride, i,\n\n                               width == l->avctx->width);\n\n            dst += stride;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23613, "_split": "valid", "_hash": "4c0c4fa1de753030f8aa918980939b2a"}
{"project": "FFmpeg", "commit_id": "3b199d29cd597a3518136d78860e172060b9e83d", "target": 0, "func": "static av_cold int smc_decode_init(AVCodecContext *avctx)\n\n{\n\n    SmcContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n\n\n    s->frame.data[0] = NULL;\n\n\n\n    return 0;\n\n}\n", "idx": 23653, "_split": "valid", "_hash": "10d0d3f1cc978692dec5fd1f5c4ebee6"}
{"project": "FFmpeg", "commit_id": "290e7eb77bee5a54182fb3d5fb122c1e117190da", "target": 1, "func": "void ff_set_fixed_vector(float *out, const AMRFixed *in, float scale, int size)\n\n{\n\n    int i;\n\n\n\n    for (i=0; i < in->n; i++) {\n\n        int x   = in->x[i], repeats = !((in->no_repeat_mask >> i) & 1);\n\n        float y = in->y[i] * scale;\n\n\n\n\n        do {\n\n            out[x] += y;\n\n            y *= in->pitch_fac;\n\n            x += in->pitch_lag;\n\n        } while (x < size && repeats);\n\n    }\n\n}", "idx": 23665, "_split": "valid", "_hash": "d060201c86fabfc9602b22867f435e3b"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static void fill_scaling_lists(const AVCodecContext *avctx, AVDXVAContext *ctx, const H264Context *h, DXVA_Qmatrix_H264 *qm)\n\n{\n\n    unsigned i, j;\n\n    memset(qm, 0, sizeof(*qm));\n\n    if (DXVA_CONTEXT_WORKAROUND(avctx, ctx) & FF_DXVA2_WORKAROUND_SCALING_LIST_ZIGZAG) {\n\n        for (i = 0; i < 6; i++)\n\n            for (j = 0; j < 16; j++)\n\n                qm->bScalingLists4x4[i][j] = h->pps.scaling_matrix4[i][j];\n\n\n\n        for (i = 0; i < 64; i++) {\n\n            qm->bScalingLists8x8[0][i] = h->pps.scaling_matrix8[0][i];\n\n            qm->bScalingLists8x8[1][i] = h->pps.scaling_matrix8[3][i];\n\n        }\n\n    } else {\n\n        for (i = 0; i < 6; i++)\n\n            for (j = 0; j < 16; j++)\n\n                qm->bScalingLists4x4[i][j] = h->pps.scaling_matrix4[i][ff_zigzag_scan[j]];\n\n\n\n        for (i = 0; i < 64; i++) {\n\n            qm->bScalingLists8x8[0][i] = h->pps.scaling_matrix8[0][ff_zigzag_direct[i]];\n\n            qm->bScalingLists8x8[1][i] = h->pps.scaling_matrix8[3][ff_zigzag_direct[i]];\n\n        }\n\n    }\n\n}\n", "idx": 23731, "_split": "valid", "_hash": "4865d7df452b0a41e59acde01e4fd523"}
{"project": "FFmpeg", "commit_id": "8b31c086b6065084644b86a63c9171f3094cf6ad", "target": 0, "func": "static int decode_tag(AVCodecContext * avctx,\n\n                      void *data, int *data_size,\n\n                      AVPacket *avpkt) {\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    NellyMoserDecodeContext *s = avctx->priv_data;\n\n    int blocks, i;\n\n    int16_t* samples;\n\n    *data_size = 0;\n\n    samples = (int16_t*)data;\n\n\n\n    if (buf_size < avctx->block_align)\n\n        return buf_size;\n\n\n\n    if (buf_size % 64) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Tag size %d.\\n\", buf_size);\n\n        return buf_size;\n\n    }\n\n    blocks = buf_size / 64;\n\n    /* Normal numbers of blocks for sample rates:\n\n     *  8000 Hz - 1\n\n     * 11025 Hz - 2\n\n     * 16000 Hz - 3\n\n     * 22050 Hz - 4\n\n     * 44100 Hz - 8\n\n     */\n\n\n\n    for (i=0 ; i<blocks ; i++) {\n\n        nelly_decode_block(s, &buf[i*NELLY_BLOCK_LEN], s->float_buf);\n\n        s->fmt_conv.float_to_int16(&samples[i*NELLY_SAMPLES], s->float_buf, NELLY_SAMPLES);\n\n        *data_size += NELLY_SAMPLES*sizeof(int16_t);\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 23756, "_split": "valid", "_hash": "d9f838efa6e7fe28c7c95350ba12ac06"}
{"project": "FFmpeg", "commit_id": "8fa18e042ad2c078f759692f1db5629d16d70595", "target": 0, "func": "static int http_connect(URLContext *h, const char *path, const char *local_path,\n\n                        const char *hoststr, const char *auth,\n\n                        const char *proxyauth, int *new_location)\n\n{\n\n    HTTPContext *s = h->priv_data;\n\n    int post, err;\n\n    char headers[HTTP_HEADERS_SIZE] = \"\";\n\n    char *authstr = NULL, *proxyauthstr = NULL;\n\n    uint64_t off = s->off;\n\n    int len = 0;\n\n    const char *method;\n\n    int send_expect_100 = 0;\n\n\n\n    /* send http header */\n\n    post = h->flags & AVIO_FLAG_WRITE;\n\n\n\n    if (s->post_data) {\n\n        /* force POST method and disable chunked encoding when\n\n         * custom HTTP post data is set */\n\n        post            = 1;\n\n        s->chunked_post = 0;\n\n    }\n\n\n\n    if (s->method)\n\n        method = s->method;\n\n    else\n\n        method = post ? \"POST\" : \"GET\";\n\n\n\n    authstr      = ff_http_auth_create_response(&s->auth_state, auth,\n\n                                                local_path, method);\n\n    proxyauthstr = ff_http_auth_create_response(&s->proxy_auth_state, proxyauth,\n\n                                                local_path, method);\n\n    if (post && !s->post_data) {\n\n        send_expect_100 = s->send_expect_100;\n\n        /* The user has supplied authentication but we don't know the auth type,\n\n         * send Expect: 100-continue to get the 401 response including the\n\n         * WWW-Authenticate header, or an 100 continue if no auth actually\n\n         * is needed. */\n\n        if (auth && *auth &&\n\n            s->auth_state.auth_type == HTTP_AUTH_NONE &&\n\n            s->http_code != 401)\n\n            send_expect_100 = 1;\n\n    }\n\n\n\n#if FF_API_HTTP_USER_AGENT\n\n    if (strcmp(s->user_agent_deprecated, DEFAULT_USER_AGENT)) {\n\n        av_log(s, AV_LOG_WARNING, \"the user-agent option is deprecated, please use user_agent option\\n\");\n\n        s->user_agent = av_strdup(s->user_agent_deprecated);\n\n    }\n\n#endif\n\n    /* set default headers if needed */\n\n    if (!has_header(s->headers, \"\\r\\nUser-Agent: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"User-Agent: %s\\r\\n\", s->user_agent);\n\n    if (!has_header(s->headers, \"\\r\\nAccept: \"))\n\n        len += av_strlcpy(headers + len, \"Accept: */*\\r\\n\",\n\n                          sizeof(headers) - len);\n\n    // Note: we send this on purpose even when s->off is 0 when we're probing,\n\n    // since it allows us to detect more reliably if a (non-conforming)\n\n    // server supports seeking by analysing the reply headers.\n\n    if (!has_header(s->headers, \"\\r\\nRange: \") && !post && (s->off > 0 || s->end_off || s->seekable == -1)) {\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Range: bytes=%\"PRIu64\"-\", s->off);\n\n        if (s->end_off)\n\n            len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                               \"%\"PRId64, s->end_off - 1);\n\n        len += av_strlcpy(headers + len, \"\\r\\n\",\n\n                          sizeof(headers) - len);\n\n    }\n\n    if (send_expect_100 && !has_header(s->headers, \"\\r\\nExpect: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Expect: 100-continue\\r\\n\");\n\n\n\n    if (!has_header(s->headers, \"\\r\\nConnection: \")) {\n\n        if (s->multiple_requests)\n\n            len += av_strlcpy(headers + len, \"Connection: keep-alive\\r\\n\",\n\n                              sizeof(headers) - len);\n\n        else\n\n            len += av_strlcpy(headers + len, \"Connection: close\\r\\n\",\n\n                              sizeof(headers) - len);\n\n    }\n\n\n\n    if (!has_header(s->headers, \"\\r\\nHost: \"))\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Host: %s\\r\\n\", hoststr);\n\n    if (!has_header(s->headers, \"\\r\\nContent-Length: \") && s->post_data)\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Content-Length: %d\\r\\n\", s->post_datalen);\n\n\n\n    if (!has_header(s->headers, \"\\r\\nContent-Type: \") && s->content_type)\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Content-Type: %s\\r\\n\", s->content_type);\n\n    if (!has_header(s->headers, \"\\r\\nCookie: \") && s->cookies) {\n\n        char *cookies = NULL;\n\n        if (!get_cookies(s, &cookies, path, hoststr) && cookies) {\n\n            len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                               \"Cookie: %s\\r\\n\", cookies);\n\n            av_free(cookies);\n\n        }\n\n    }\n\n    if (!has_header(s->headers, \"\\r\\nIcy-MetaData: \") && s->icy)\n\n        len += av_strlcatf(headers + len, sizeof(headers) - len,\n\n                           \"Icy-MetaData: %d\\r\\n\", 1);\n\n\n\n    /* now add in custom headers */\n\n    if (s->headers)\n\n        av_strlcpy(headers + len, s->headers, sizeof(headers) - len);\n\n\n\n    snprintf(s->buffer, sizeof(s->buffer),\n\n             \"%s %s HTTP/1.1\\r\\n\"\n\n             \"%s\"\n\n             \"%s\"\n\n             \"%s\"\n\n             \"%s%s\"\n\n             \"\\r\\n\",\n\n             method,\n\n             path,\n\n             post && s->chunked_post ? \"Transfer-Encoding: chunked\\r\\n\" : \"\",\n\n             headers,\n\n             authstr ? authstr : \"\",\n\n             proxyauthstr ? \"Proxy-\" : \"\", proxyauthstr ? proxyauthstr : \"\");\n\n\n\n    av_log(h, AV_LOG_DEBUG, \"request: %s\\n\", s->buffer);\n\n\n\n    if ((err = ffurl_write(s->hd, s->buffer, strlen(s->buffer))) < 0)\n\n        goto done;\n\n\n\n    if (s->post_data)\n\n        if ((err = ffurl_write(s->hd, s->post_data, s->post_datalen)) < 0)\n\n            goto done;\n\n\n\n    /* init input buffer */\n\n    s->buf_ptr          = s->buffer;\n\n    s->buf_end          = s->buffer;\n\n    s->line_count       = 0;\n\n    s->off              = 0;\n\n    s->icy_data_read    = 0;\n\n    s->filesize         = UINT64_MAX;\n\n    s->willclose        = 0;\n\n    s->end_chunked_post = 0;\n\n    s->end_header       = 0;\n\n    if (post && !s->post_data && !send_expect_100) {\n\n        /* Pretend that it did work. We didn't read any header yet, since\n\n         * we've still to send the POST data, but the code calling this\n\n         * function will check http_code after we return. */\n\n        s->http_code = 200;\n\n        err = 0;\n\n        goto done;\n\n    }\n\n\n\n    /* wait for header */\n\n    err = http_read_header(h, new_location);\n\n    if (err < 0)\n\n        goto done;\n\n\n\n    if (*new_location)\n\n        s->off = off;\n\n\n\n    err = (off == s->off) ? 0 : -1;\n\ndone:\n\n    av_freep(&authstr);\n\n    av_freep(&proxyauthstr);\n\n    return err;\n\n}\n", "idx": 23797, "_split": "valid", "_hash": "3270e1c01d7892b288aecae17d8f6e22"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "int ff_h264_decode_mb_cabac(const H264Context *h, H264SliceContext *sl)\n\n{\n\n    int mb_xy;\n\n    int mb_type, partition_count, cbp = 0;\n\n    int dct8x8_allowed= h->pps.transform_8x8_mode;\n\n    int decode_chroma = h->sps.chroma_format_idc == 1 || h->sps.chroma_format_idc == 2;\n\n    const int pixel_shift = h->pixel_shift;\n\n\n\n    mb_xy = sl->mb_xy = sl->mb_x + sl->mb_y*h->mb_stride;\n\n\n\n    ff_tlog(h->avctx, \"pic:%d mb:%d/%d\\n\", h->frame_num, sl->mb_x, sl->mb_y);\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        int skip;\n\n        /* a skipped mb needs the aff flag from the following mb */\n\n        if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 1 && sl->prev_mb_skipped)\n\n            skip = sl->next_mb_skipped;\n\n        else\n\n            skip = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y );\n\n        /* read skip flags */\n\n        if( skip ) {\n\n            if (FRAME_MBAFF(h) && (sl->mb_y & 1) == 0) {\n\n                h->cur_pic.mb_type[mb_xy] = MB_TYPE_SKIP;\n\n                sl->next_mb_skipped = decode_cabac_mb_skip(h, sl, sl->mb_x, sl->mb_y+1 );\n\n                if(!sl->next_mb_skipped)\n\n                    sl->mb_mbaff = sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n            }\n\n\n\n            decode_mb_skip(h, sl);\n\n\n\n            h->cbp_table[mb_xy] = 0;\n\n            h->chroma_pred_mode_table[mb_xy] = 0;\n\n            sl->last_qscale_diff = 0;\n\n\n\n            return 0;\n\n\n\n        }\n\n    }\n\n    if (FRAME_MBAFF(h)) {\n\n        if ((sl->mb_y & 1) == 0)\n\n            sl->mb_mbaff =\n\n            sl->mb_field_decoding_flag = decode_cabac_field_decoding_flag(h, sl);\n\n    }\n\n\n\n    sl->prev_mb_skipped = 0;\n\n\n\n    fill_decode_neighbors(h, sl, -(MB_FIELD(sl)));\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        int ctx = 0;\n\n        assert(sl->slice_type_nos == AV_PICTURE_TYPE_B);\n\n\n\n        if (!IS_DIRECT(sl->left_type[LTOP] - 1))\n\n            ctx++;\n\n        if (!IS_DIRECT(sl->top_type - 1))\n\n            ctx++;\n\n\n\n        if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+ctx] ) ){\n\n            mb_type= 0; /* B_Direct_16x16 */\n\n        }else if( !get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+3] ) ) {\n\n            mb_type= 1 + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ); /* B_L[01]_16x16 */\n\n        }else{\n\n            int bits;\n\n            bits = get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+4] ) << 3;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 2;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] ) << 1;\n\n            bits+= get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n            if( bits < 8 ){\n\n                mb_type= bits + 3; /* B_Bi_16x16 through B_L1_L0_16x8 */\n\n            }else if( bits == 13 ){\n\n                mb_type = decode_cabac_intra_mb_type(sl, 32, 0);\n\n                goto decode_intra_mb;\n\n            }else if( bits == 14 ){\n\n                mb_type= 11; /* B_L1_L0_8x16 */\n\n            }else if( bits == 15 ){\n\n                mb_type= 22; /* B_8x8 */\n\n            }else{\n\n                bits= ( bits<<1 ) + get_cabac_noinline( &sl->cabac, &sl->cabac_state[27+5] );\n\n                mb_type= bits - 4; /* B_L0_Bi_* through B_Bi_Bi_* */\n\n            }\n\n        }\n\n            partition_count = ff_h264_b_mb_type_info[mb_type].partition_count;\n\n            mb_type         = ff_h264_b_mb_type_info[mb_type].type;\n\n    } else if (sl->slice_type_nos == AV_PICTURE_TYPE_P) {\n\n        if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[14] ) == 0 ) {\n\n            /* P-type */\n\n            if( get_cabac_noinline( &sl->cabac, &sl->cabac_state[15] ) == 0 ) {\n\n                /* P_L0_D16x16, P_8x8 */\n\n                mb_type= 3 * get_cabac_noinline( &sl->cabac, &sl->cabac_state[16] );\n\n            } else {\n\n                /* P_L0_D8x16, P_L0_D16x8 */\n\n                mb_type= 2 - get_cabac_noinline( &sl->cabac, &sl->cabac_state[17] );\n\n            }\n\n            partition_count = ff_h264_p_mb_type_info[mb_type].partition_count;\n\n            mb_type         = ff_h264_p_mb_type_info[mb_type].type;\n\n        } else {\n\n            mb_type = decode_cabac_intra_mb_type(sl, 17, 0);\n\n            goto decode_intra_mb;\n\n        }\n\n    } else {\n\n        mb_type = decode_cabac_intra_mb_type(sl, 3, 1);\n\n        if (sl->slice_type == AV_PICTURE_TYPE_SI && mb_type)\n\n            mb_type--;\n\n        assert(sl->slice_type_nos == AV_PICTURE_TYPE_I);\n\ndecode_intra_mb:\n\n        partition_count = 0;\n\n        cbp                      = ff_h264_i_mb_type_info[mb_type].cbp;\n\n        sl->intra16x16_pred_mode = ff_h264_i_mb_type_info[mb_type].pred_mode;\n\n        mb_type                  = ff_h264_i_mb_type_info[mb_type].type;\n\n    }\n\n    if (MB_FIELD(sl))\n\n        mb_type |= MB_TYPE_INTERLACED;\n\n\n\n    h->slice_table[mb_xy] = sl->slice_num;\n\n\n\n    if(IS_INTRA_PCM(mb_type)) {\n\n        const int mb_size = ff_h264_mb_sizes[h->sps.chroma_format_idc] *\n\n                            h->sps.bit_depth_luma >> 3;\n\n        const uint8_t *ptr;\n\n\n\n        // We assume these blocks are very rare so we do not optimize it.\n\n        // FIXME The two following lines get the bitstream position in the cabac\n\n        // decode, I think it should be done by a function in cabac.h (or cabac.c).\n\n        ptr= sl->cabac.bytestream;\n\n        if(sl->cabac.low&0x1) ptr--;\n\n        if(CABAC_BITS==16){\n\n            if(sl->cabac.low&0x1FF) ptr--;\n\n        }\n\n\n\n        // The pixels are stored in the same order as levels in h->mb array.\n\n        if ((int) (sl->cabac.bytestream_end - ptr) < mb_size)\n\n            return -1;\n\n        sl->intra_pcm_ptr = ptr;\n\n        ptr += mb_size;\n\n\n\n        ff_init_cabac_decoder(&sl->cabac, ptr, sl->cabac.bytestream_end - ptr);\n\n\n\n        // All blocks are present\n\n        h->cbp_table[mb_xy] = 0xf7ef;\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        // In deblocking, the quantizer is 0\n\n        h->cur_pic.qscale_table[mb_xy] = 0;\n\n        // All coeffs are present\n\n        memset(h->non_zero_count[mb_xy], 16, 48);\n\n        h->cur_pic.mb_type[mb_xy] = mb_type;\n\n        sl->last_qscale_diff = 0;\n\n        return 0;\n\n    }\n\n\n\n    fill_decode_caches(h, sl, mb_type);\n\n\n\n    if( IS_INTRA( mb_type ) ) {\n\n        int i, pred_mode;\n\n        if( IS_INTRA4x4( mb_type ) ) {\n\n            if (dct8x8_allowed && get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size])) {\n\n                mb_type |= MB_TYPE_8x8DCT;\n\n                for( i = 0; i < 16; i+=4 ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    int mode = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n                    fill_rectangle(&sl->intra4x4_pred_mode_cache[scan8[i]], 2, 2, 8, mode, 1);\n\n                }\n\n            } else {\n\n                for( i = 0; i < 16; i++ ) {\n\n                    int pred = pred_intra_mode(h, sl, i);\n\n                    sl->intra4x4_pred_mode_cache[scan8[i]] = decode_cabac_mb_intra4x4_pred_mode(sl, pred);\n\n\n\n                    ff_dlog(h->avctx, \"i4x4 pred=%d mode=%d\\n\", pred,\n\n                            sl->intra4x4_pred_mode_cache[scan8[i]]);\n\n                }\n\n            }\n\n            write_back_intra_pred_mode(h, sl);\n\n            if (ff_h264_check_intra4x4_pred_mode(sl->intra4x4_pred_mode_cache, h->avctx,\n\n                                                 sl->top_samples_available, sl->left_samples_available) < 0 )\n\n                return -1;\n\n        } else {\n\n            sl->intra16x16_pred_mode = ff_h264_check_intra_pred_mode(h->avctx, sl->top_samples_available,\n\n                                                                     sl->left_samples_available, sl->intra16x16_pred_mode, 0);\n\n            if (sl->intra16x16_pred_mode < 0) return -1;\n\n        }\n\n        if(decode_chroma){\n\n            h->chroma_pred_mode_table[mb_xy] =\n\n            pred_mode                        = decode_cabac_mb_chroma_pre_mode(h, sl);\n\n\n\n            pred_mode= ff_h264_check_intra_pred_mode(h->avctx, sl->top_samples_available,\n\n                                                     sl->left_samples_available, pred_mode, 1 );\n\n            if( pred_mode < 0 ) return -1;\n\n            sl->chroma_pred_mode = pred_mode;\n\n        } else {\n\n            sl->chroma_pred_mode = DC_128_PRED8x8;\n\n        }\n\n    } else if( partition_count == 4 ) {\n\n        int i, j, sub_partition_count[4], list, ref[2][4];\n\n\n\n        if (sl->slice_type_nos == AV_PICTURE_TYPE_B ) {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_b_mb_sub_type(sl);\n\n                sub_partition_count[i] = ff_h264_b_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = ff_h264_b_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n            if (IS_DIRECT(sl->sub_mb_type[0] | sl->sub_mb_type[1] |\n\n                          sl->sub_mb_type[2] | sl->sub_mb_type[3])) {\n\n                ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n                sl->ref_cache[0][scan8[4]] =\n\n                sl->ref_cache[1][scan8[4]] =\n\n                sl->ref_cache[0][scan8[12]] =\n\n                sl->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;\n\n                    for( i = 0; i < 4; i++ )\n\n                        fill_rectangle(&sl->direct_cache[scan8[4*i]], 2, 2, 8, (sl->sub_mb_type[i] >> 1) & 0xFF, 1);\n\n            }\n\n        } else {\n\n            for( i = 0; i < 4; i++ ) {\n\n                sl->sub_mb_type[i] = decode_cabac_p_mb_sub_type(sl);\n\n                sub_partition_count[i] = ff_h264_p_sub_mb_type_info[sl->sub_mb_type[i]].partition_count;\n\n                sl->sub_mb_type[i]     = ff_h264_p_sub_mb_type_info[sl->sub_mb_type[i]].type;\n\n            }\n\n        }\n\n\n\n        for( list = 0; list < sl->list_count; list++ ) {\n\n                for( i = 0; i < 4; i++ ) {\n\n                    if(IS_DIRECT(sl->sub_mb_type[i])) continue;\n\n                    if(IS_DIR(sl->sub_mb_type[i], 0, list)){\n\n                        int rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                        if (rc > 1) {\n\n                            ref[list][i] = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                            if (ref[list][i] >= (unsigned) rc) {\n\n                                av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref[list][i], rc);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            ref[list][i] = 0;\n\n                    } else {\n\n                        ref[list][i] = -1;\n\n                    }\n\n                    sl->ref_cache[list][scan8[4 * i] + 1] =\n\n                    sl->ref_cache[list][scan8[4 * i] + 8] = sl->ref_cache[list][scan8[4 * i] + 9] = ref[list][i];\n\n                }\n\n        }\n\n\n\n        if(dct8x8_allowed)\n\n            dct8x8_allowed = get_dct8x8_allowed(h, sl);\n\n\n\n        for (list = 0; list < sl->list_count; list++) {\n\n            for(i=0; i<4; i++){\n\n                sl->ref_cache[list][scan8[4 * i]] = sl->ref_cache[list][scan8[4 * i] + 1];\n\n                if(IS_DIRECT(sl->sub_mb_type[i])){\n\n                    fill_rectangle(sl->mvd_cache[list][scan8[4*i]], 2, 2, 8, 0, 2);\n\n                    continue;\n\n                }\n\n\n\n                if(IS_DIR(sl->sub_mb_type[i], 0, list) && !IS_DIRECT(sl->sub_mb_type[i])){\n\n                    const int sub_mb_type= sl->sub_mb_type[i];\n\n                    const int block_width= (sub_mb_type & (MB_TYPE_16x16|MB_TYPE_16x8)) ? 2 : 1;\n\n                    for(j=0; j<sub_partition_count[i]; j++){\n\n                        int mpx, mpy;\n\n                        int mx, my;\n\n                        const int index= 4*i + block_width*j;\n\n                        int16_t (* mv_cache)[2] = &sl->mv_cache[list][ scan8[index] ];\n\n                        uint8_t (* mvd_cache)[2]= &sl->mvd_cache[list][ scan8[index] ];\n\n                        pred_motion(h, sl, index, block_width, list, sl->ref_cache[list][ scan8[index] ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, index)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        if(IS_SUB_8X8(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]=\n\n                            mv_cache[ 8 ][0]= mv_cache[ 9 ][0]= mx;\n\n                            mv_cache[ 1 ][1]=\n\n                            mv_cache[ 8 ][1]= mv_cache[ 9 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=\n\n                            mvd_cache[ 8 ][0]= mvd_cache[ 9 ][0]= mpx;\n\n                            mvd_cache[ 1 ][1]=\n\n                            mvd_cache[ 8 ][1]= mvd_cache[ 9 ][1]= mpy;\n\n                        }else if(IS_SUB_8X4(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]= mx;\n\n                            mv_cache[ 1 ][1]= my;\n\n\n\n                            mvd_cache[ 1 ][0]=  mpx;\n\n                            mvd_cache[ 1 ][1]= mpy;\n\n                        }else if(IS_SUB_4X8(sub_mb_type)){\n\n                            mv_cache[ 8 ][0]= mx;\n\n                            mv_cache[ 8 ][1]= my;\n\n\n\n                            mvd_cache[ 8 ][0]= mpx;\n\n                            mvd_cache[ 8 ][1]= mpy;\n\n                        }\n\n                        mv_cache[ 0 ][0]= mx;\n\n                        mv_cache[ 0 ][1]= my;\n\n\n\n                        mvd_cache[ 0 ][0]= mpx;\n\n                        mvd_cache[ 0 ][1]= mpy;\n\n                    }\n\n                }else{\n\n                    fill_rectangle(sl->mv_cache [list][ scan8[4*i] ], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[4*i] ], 2, 2, 8, 0, 2);\n\n                }\n\n            }\n\n        }\n\n    } else if( IS_DIRECT(mb_type) ) {\n\n        ff_h264_pred_direct_motion(h, sl, &mb_type);\n\n        fill_rectangle(sl->mvd_cache[0][scan8[0]], 4, 4, 8, 0, 2);\n\n        fill_rectangle(sl->mvd_cache[1][scan8[0]], 4, 4, 8, 0, 2);\n\n        dct8x8_allowed &= h->sps.direct_8x8_inference_flag;\n\n    } else {\n\n        int list, i;\n\n        if(IS_16X16(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int ref, rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                    if (rc > 1) {\n\n                        ref= decode_cabac_mb_ref(sl, list, 0);\n\n                        if (ref >= (unsigned) rc) {\n\n                            av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                            return -1;\n\n                        }\n\n                    }else\n\n                        ref=0;\n\n                    fill_rectangle(&sl->ref_cache[list][ scan8[0] ], 4, 4, 8, ref, 1);\n\n                }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    int mx,my,mpx,mpy;\n\n                    pred_motion(h, sl, 0, 4, list, sl->ref_cache[list][ scan8[0] ], &mx, &my);\n\n                    DECODE_CABAC_MB_MVD(sl, list, 0)\n\n                    ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                    fill_rectangle(sl->mvd_cache[list][ scan8[0] ], 4, 4, 8, pack8to16(mpx,mpy), 2);\n\n                    fill_rectangle(sl->mv_cache[list][ scan8[0] ], 4, 4, 8, pack16to32(mx,my), 4);\n\n                }\n\n            }\n\n        }\n\n        else if(IS_16X8(mb_type)){\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){\n\n                            int ref, rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref= decode_cabac_mb_ref(sl, list, 8 * i);\n\n                                if (ref >= (unsigned) rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_16x8_motion(h, sl, 8*i, list, sl->ref_cache[list][scan8[0] + 16*i], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 8*i)\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            assert(IS_8X16(mb_type));\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                    for(i=0; i<2; i++){\n\n                        if(IS_DIR(mb_type, i, list)){ //FIXME optimize\n\n                            int ref, rc = sl->ref_count[list] << MB_MBAFF(sl);\n\n                            if (rc > 1) {\n\n                                ref = decode_cabac_mb_ref(sl, list, 4 * i);\n\n                                if (ref >= (unsigned) rc) {\n\n                                    av_log(h->avctx, AV_LOG_ERROR, \"Reference %d >= %d\\n\", ref, rc);\n\n                                    return -1;\n\n                                }\n\n                            }else\n\n                                ref=0;\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, ref, 1);\n\n                        }else\n\n                            fill_rectangle(&sl->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, (LIST_NOT_USED&0xFF), 1);\n\n                    }\n\n            }\n\n            for (list = 0; list < sl->list_count; list++) {\n\n                for(i=0; i<2; i++){\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        int mx,my,mpx,mpy;\n\n                        pred_8x16_motion(h, sl, i*4, list, sl->ref_cache[list][ scan8[0] + 2*i ], &mx, &my);\n\n                        DECODE_CABAC_MB_MVD(sl, list, 4*i)\n\n\n\n                        ff_tlog(h->avctx, \"final mv:%d %d\\n\", mx, my);\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack8to16(mpx,mpy), 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, pack16to32(mx,my), 4);\n\n                    }else{\n\n                        fill_rectangle(sl->mvd_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 2);\n\n                        fill_rectangle(sl->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, 0, 4);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n   if( IS_INTER( mb_type ) ) {\n\n        h->chroma_pred_mode_table[mb_xy] = 0;\n\n        write_back_motion(h, sl, mb_type);\n\n   }\n\n\n\n    if( !IS_INTRA16x16( mb_type ) ) {\n\n        cbp  = decode_cabac_mb_cbp_luma(sl);\n\n        if(decode_chroma)\n\n            cbp |= decode_cabac_mb_cbp_chroma(sl) << 4;\n\n    }\n\n\n\n    h->cbp_table[mb_xy] = sl->cbp = cbp;\n\n\n\n    if( dct8x8_allowed && (cbp&15) && !IS_INTRA( mb_type ) ) {\n\n        mb_type |= MB_TYPE_8x8DCT * get_cabac_noinline(&sl->cabac, &sl->cabac_state[399 + sl->neighbor_transform_size]);\n\n    }\n\n\n\n    /* It would be better to do this in fill_decode_caches, but we don't know\n\n     * the transform mode of the current macroblock there. */\n\n    if (CHROMA444(h) && IS_8x8DCT(mb_type)){\n\n        int i;\n\n        uint8_t *nnz_cache = sl->non_zero_count_cache;\n\n        for (i = 0; i < 2; i++){\n\n            if (sl->left_type[LEFT(i)] && !IS_8x8DCT(sl->left_type[LEFT(i)])) {\n\n                nnz_cache[3+8* 1 + 2*8*i]=\n\n                nnz_cache[3+8* 2 + 2*8*i]=\n\n                nnz_cache[3+8* 6 + 2*8*i]=\n\n                nnz_cache[3+8* 7 + 2*8*i]=\n\n                nnz_cache[3+8*11 + 2*8*i]=\n\n                nnz_cache[3+8*12 + 2*8*i]= IS_INTRA(mb_type) ? 64 : 0;\n\n            }\n\n        }\n\n        if (sl->top_type && !IS_8x8DCT(sl->top_type)){\n\n            uint32_t top_empty = CABAC(h) && !IS_INTRA(mb_type) ? 0 : 0x40404040;\n\n            AV_WN32A(&nnz_cache[4+8* 0], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8* 5], top_empty);\n\n            AV_WN32A(&nnz_cache[4+8*10], top_empty);\n\n        }\n\n    }\n\n    h->cur_pic.mb_type[mb_xy] = mb_type;\n\n\n\n    if( cbp || IS_INTRA16x16( mb_type ) ) {\n\n        const uint8_t *scan, *scan8x8;\n\n        const uint32_t *qmul;\n\n\n\n        if(IS_INTERLACED(mb_type)){\n\n            scan8x8 = sl->qscale ? h->field_scan8x8 : h->field_scan8x8_q0;\n\n            scan    = sl->qscale ? h->field_scan : h->field_scan_q0;\n\n        }else{\n\n            scan8x8 = sl->qscale ? h->zigzag_scan8x8 : h->zigzag_scan8x8_q0;\n\n            scan    = sl->qscale ? h->zigzag_scan : h->zigzag_scan_q0;\n\n        }\n\n\n\n        // decode_cabac_mb_dqp\n\n        if(get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + (sl->last_qscale_diff != 0)])){\n\n            int val = 1;\n\n            int ctx= 2;\n\n            const int max_qp = 51 + 6*(h->sps.bit_depth_luma-8);\n\n\n\n            while( get_cabac_noinline( &sl->cabac, &sl->cabac_state[60 + ctx] ) ) {\n\n                ctx= 3;\n\n                val++;\n\n                if(val > 2*max_qp){ //prevent infinite loop\n\n                    av_log(h->avctx, AV_LOG_ERROR, \"cabac decode of qscale diff failed at %d %d\\n\", sl->mb_x, sl->mb_y);\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            if( val&0x01 )\n\n                val=   (val + 1)>>1 ;\n\n            else\n\n                val= -((val + 1)>>1);\n\n            sl->last_qscale_diff = val;\n\n            sl->qscale += val;\n\n            if (((unsigned)sl->qscale) > max_qp){\n\n                if (sl->qscale < 0) sl->qscale += max_qp + 1;\n\n                else                sl->qscale -= max_qp + 1;\n\n            }\n\n            sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n            sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n        }else\n\n            sl->last_qscale_diff=0;\n\n\n\n        decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 0);\n\n        if (CHROMA444(h)) {\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 1);\n\n            decode_cabac_luma_residual(h, sl, scan, scan8x8, pixel_shift, mb_type, cbp, 2);\n\n        } else if (CHROMA422(h)) {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc_422(h, sl, sl->mb + ((256 + 16*16*c) << pixel_shift), 3,\n\n                                                 CHROMA_DC_BLOCK_INDEX + c,\n\n                                                 ff_h264_chroma422_dc_scan, 8);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i, i8x8;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    int16_t *mb = sl->mb + (16*(16 + 16*c) << pixel_shift);\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for (i8x8 = 0; i8x8 < 2; i8x8++) {\n\n                        for (i = 0; i < 4; i++) {\n\n                            const int index = 16 + 16 * c + 8*i8x8 + i;\n\n                            decode_cabac_residual_nondc(h, sl, mb, 4, index, scan + 1, qmul, 15);\n\n                            mb += 16<<pixel_shift;\n\n                        }\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        } else /* yuv420 */ {\n\n            if( cbp&0x30 ){\n\n                int c;\n\n                for (c = 0; c < 2; c++)\n\n                    decode_cabac_residual_dc(h, sl, sl->mb + ((256 + 16 * 16 * c) << pixel_shift),\n\n                                             3, CHROMA_DC_BLOCK_INDEX + c, ff_h264_chroma_dc_scan, 4);\n\n            }\n\n\n\n            if( cbp&0x20 ) {\n\n                int c, i;\n\n                for( c = 0; c < 2; c++ ) {\n\n                    qmul = h->dequant4_coeff[c+1+(IS_INTRA( mb_type ) ? 0:3)][sl->chroma_qp[c]];\n\n                    for( i = 0; i < 4; i++ ) {\n\n                        const int index = 16 + 16 * c + i;\n\n                        decode_cabac_residual_nondc(h, sl, sl->mb + (16*index << pixel_shift), 4, index, scan + 1, qmul, 15);\n\n                    }\n\n                }\n\n            } else {\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n            }\n\n        }\n\n    } else {\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[ 0]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[16]], 4, 4, 8, 0, 1);\n\n        fill_rectangle(&sl->non_zero_count_cache[scan8[32]], 4, 4, 8, 0, 1);\n\n        sl->last_qscale_diff = 0;\n\n    }\n\n\n\n    h->cur_pic.qscale_table[mb_xy] = sl->qscale;\n\n    write_back_non_zero_count(h, sl);\n\n\n\n    return 0;\n\n}\n", "idx": 23871, "_split": "valid", "_hash": "5175b397aa9b477478fdd3404ef8f32e"}
{"project": "FFmpeg", "commit_id": "8155233413540c63e53a620ff5734fb4b0635611", "target": 1, "func": "static int int_pow(int i, int *exp_ptr)\n\n{\n\n    int e, er, eq, j;\n\n    int a, a1;\n\n    \n\n    /* renormalize */\n\n    a = i;\n\n    e = POW_FRAC_BITS;\n\n    while (a < (1 << (POW_FRAC_BITS - 1))) {\n\n        a = a << 1;\n\n        e--;\n\n    }\n\n    a -= (1 << POW_FRAC_BITS);\n\n    a1 = 0;\n\n    for(j = DEV_ORDER - 1; j >= 0; j--)\n\n        a1 = POW_MULL(a, dev_4_3_coefs[j] + a1);\n\n    a = (1 << POW_FRAC_BITS) + a1;\n\n    /* exponent compute (exact) */\n\n    e = e * 4;\n\n    er = e % 3;\n\n    eq = e / 3;\n\n    a = POW_MULL(a, pow_mult3[er]);\n\n    while (a >= 2 * POW_FRAC_ONE) {\n\n        a = a >> 1;\n\n        eq++;\n\n    }\n\n    /* convert to float */\n\n    while (a < POW_FRAC_ONE) {\n\n        a = a << 1;\n\n        eq--;\n\n    }\n\n    /* now POW_FRAC_ONE <= a < 2 * POW_FRAC_ONE */\n\n#if (POW_FRAC_BITS - 1) > FRAC_BITS\n\n    a = (a + (1 << (POW_FRAC_BITS - FRAC_BITS - 1))) >> (POW_FRAC_BITS - FRAC_BITS);\n\n    /* correct overflow */\n\n    if (a >= 2 * (1 << FRAC_BITS)) {\n\n        a = a >> 1;\n\n        eq++;\n\n    }\n\n#endif\n\n    *exp_ptr = eq;\n\n    return a;\n\n}\n", "idx": 23903, "_split": "valid", "_hash": "66f7e9510406dab2cf5039725c52d826"}
{"project": "FFmpeg", "commit_id": "153b36fc62849e0e1540a43829794e0503994ebb", "target": 0, "func": "unsigned ff_dxva2_get_surface_index(const AVCodecContext *avctx,\n\n                                    const AVDXVAContext *ctx,\n\n                                    const AVFrame *frame)\n\n{\n\n    void *surface = get_surface(frame);\n\n    unsigned i;\n\n\n\n    for (i = 0; i < DXVA_CONTEXT_COUNT(avctx, ctx); i++) {\n\n#if CONFIG_D3D11VA\n\n        if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD && ctx->d3d11va.surface[i] == surface)\n\n        {\n\n            D3D11_VIDEO_DECODER_OUTPUT_VIEW_DESC viewDesc;\n\n            ID3D11VideoDecoderOutputView_GetDesc(ctx->d3d11va.surface[i], &viewDesc);\n\n            return viewDesc.Texture2D.ArraySlice;\n\n        }\n\n#endif\n\n#if CONFIG_DXVA2\n\n        if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD && ctx->dxva2.surface[i] == surface)\n\n            return i;\n\n#endif\n\n    }\n\n\n\n    assert(0);\n\n    return 0;\n\n}\n", "idx": 23929, "_split": "valid", "_hash": "77d4ee3476798414d79eff34536df21e"}
{"project": "FFmpeg", "commit_id": "c0b17ea106b94f79255f81ec36ea50096e1ae985", "target": 1, "func": "static int roq_dpcm_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                                 const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    int i, stereo, data_size, ret;\n\n    const int16_t *in = frame ? (const int16_t *)frame->data[0] : NULL;\n\n    uint8_t *out;\n\n    ROQDPCMContext *context = avctx->priv_data;\n\n\n\n    stereo = (avctx->channels == 2);\n\n\n\n    if (!in && context->input_frames >= 8)\n\n        return 0;\n\n\n\n    if (in && context->input_frames < 8) {\n\n        memcpy(&context->frame_buffer[context->buffered_samples * avctx->channels],\n\n               in, avctx->frame_size * avctx->channels * sizeof(*in));\n\n        context->buffered_samples += avctx->frame_size;\n\n        if (context->input_frames == 0)\n\n            context->first_pts = frame->pts;\n\n        if (context->input_frames < 7) {\n\n            context->input_frames++;\n\n            return 0;\n\n\n\n\n        in = context->frame_buffer;\n\n\n\n\n    if (stereo) {\n\n        context->lastSample[0] &= 0xFF00;\n\n        context->lastSample[1] &= 0xFF00;\n\n\n\n\n    if (context->input_frames == 7 || !in)\n\n        data_size = avctx->channels * context->buffered_samples;\n\n    else\n\n        data_size = avctx->channels * avctx->frame_size;\n\n\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, ROQ_HEADER_SIZE + data_size)))\n\n        return ret;\n\n    out = avpkt->data;\n\n\n\n    bytestream_put_byte(&out, stereo ? 0x21 : 0x20);\n\n    bytestream_put_byte(&out, 0x10);\n\n    bytestream_put_le32(&out, data_size);\n\n\n\n    if (stereo) {\n\n        bytestream_put_byte(&out, (context->lastSample[1])>>8);\n\n        bytestream_put_byte(&out, (context->lastSample[0])>>8);\n\n    } else\n\n        bytestream_put_le16(&out, context->lastSample[0]);\n\n\n\n    /* Write the actual samples */\n\n    for (i = 0; i < data_size; i++)\n\n        *out++ = dpcm_predict(&context->lastSample[i & 1], *in++);\n\n\n\n    avpkt->pts      = context->input_frames <= 7 ? context->first_pts : frame->pts;\n\n    avpkt->duration = data_size / avctx->channels;\n\n\n\n    context->input_frames++;\n\n    if (!in)\n\n        context->input_frames = FFMAX(context->input_frames, 8);\n\n\n\n    *got_packet_ptr = 1;\n\n    return 0;\n", "idx": 24013, "_split": "valid", "_hash": "0ac843126a39671cbf614d4f50df7a98"}
{"project": "FFmpeg", "commit_id": "14bd2a9f25fc0de4fb1a2d4afaef09162c51bb35", "target": 0, "func": "static int find_optimal_param(uint32_t sum, int n)\n\n{\n\n    int k, k_opt;\n\n    uint32_t nbits[MAX_RICE_PARAM+1];\n\n\n\n    k_opt = 0;\n\n    nbits[0] = UINT32_MAX;\n\n    for(k=0; k<=MAX_RICE_PARAM; k++) {\n\n        nbits[k] = rice_encode_count(sum, n, k);\n\n        if(nbits[k] < nbits[k_opt]) {\n\n            k_opt = k;\n\n        }\n\n    }\n\n    return k_opt;\n\n}\n", "idx": 24037, "_split": "valid", "_hash": "f400e35bd1b00ccddedcf079f9c02288"}
{"project": "FFmpeg", "commit_id": "cd2f7ed0007f4803b6bd845366b2398abb32c355", "target": 0, "func": "static void ts_str(char buffer[60], int64_t ts, AVRational base)\n\n{\n\n    if (ts == AV_NOPTS_VALUE) {\n\n        strcpy(buffer, \" NOPTS   \");\n\n        return;\n\n    }\n\n    ts= av_rescale_q(ts, base, (AVRational){1, 1000000});\n\n    snprintf(buffer, 60, \"%c%Ld.%06Ld\", ts<0 ? '-' : ' ', FFABS(ts)/1000000, FFABS(ts)%1000000);\n\n}\n", "idx": 24048, "_split": "valid", "_hash": "6f5f79463835f9a4a702b5511de6f76a"}
{"project": "FFmpeg", "commit_id": "78cb39d2b2ad731dd3b984b0c0711b9f1d6de004", "target": 1, "func": "static void lz_unpack(const unsigned char *src, int src_len,\n\n                      unsigned char *dest, int dest_len)\n\n{\n\n    const unsigned char *s;\n\n    const unsigned char *s_end;\n\n    unsigned char *d;\n\n    unsigned char *d_end;\n\n    unsigned char queue[QUEUE_SIZE];\n\n    unsigned int qpos;\n\n    unsigned int dataleft;\n\n    unsigned int chainofs;\n\n    unsigned int chainlen;\n\n    unsigned int speclen;\n\n    unsigned char tag;\n\n    unsigned int i, j;\n\n\n\n    s = src;\n\n    s_end = src + src_len;\n\n    d = dest;\n\n    d_end = d + dest_len;\n\n\n\n    if (s_end - s < 8)\n\n        return;\n\n    dataleft = AV_RL32(s);\n\n    s += 4;\n\n    memset(queue, 0x20, QUEUE_SIZE);\n\n    if (AV_RL32(s) == 0x56781234) {\n\n        s += 4;\n\n        qpos = 0x111;\n\n        speclen = 0xF + 3;\n\n    } else {\n\n        qpos = 0xFEE;\n\n        speclen = 100;  /* no speclen */\n\n    }\n\n\n\n    while (s_end - s > 0 && dataleft > 0) {\n\n        tag = *s++;\n\n        if ((tag == 0xFF) && (dataleft > 8)) {\n\n            if (d + 8 > d_end || s_end - s < 8)\n\n                return;\n\n            for (i = 0; i < 8; i++) {\n\n                queue[qpos++] = *d++ = *s++;\n\n                qpos &= QUEUE_MASK;\n\n            }\n\n            dataleft -= 8;\n\n        } else {\n\n            for (i = 0; i < 8; i++) {\n\n                if (dataleft == 0)\n\n                    break;\n\n                if (tag & 0x01) {\n\n                    if (d + 1 > d_end || s_end - s < 1)\n\n                        return;\n\n                    queue[qpos++] = *d++ = *s++;\n\n                    qpos &= QUEUE_MASK;\n\n                    dataleft--;\n\n                } else {\n\n                    if (s_end - s < 2)\n\n                        return;\n\n                    chainofs = *s++;\n\n                    chainofs |= ((*s & 0xF0) << 4);\n\n                    chainlen = (*s++ & 0x0F) + 3;\n\n                    if (chainlen == speclen) {\n\n                        if (s_end - s < 1)\n\n                            return;\n\n                        chainlen = *s++ + 0xF + 3;\n\n                    }\n\n                    if (d + chainlen > d_end)\n\n                        return;\n\n                    for (j = 0; j < chainlen; j++) {\n\n                        *d = queue[chainofs++ & QUEUE_MASK];\n\n                        queue[qpos++] = *d++;\n\n                        qpos &= QUEUE_MASK;\n\n                    }\n\n                    dataleft -= chainlen;\n\n                }\n\n                tag >>= 1;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24063, "_split": "valid", "_hash": "47e002a7fda39ae1cd1c8a92ecf4bb07"}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0x9(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char P[4];\n\n\n\n    /* 4-color encoding */\n\n    CHECK_STREAM_PTR(4);\n\n\n\n    memcpy(P, s->stream_ptr, 4);\n\n    s->stream_ptr += 4;\n\n\n\n    if (P[0] <= P[1]) {\n\n        if (P[2] <= P[3]) {\n\n\n\n            /* 1 of 4 colors for each pixel, need 16 more bytes */\n\n            CHECK_STREAM_PTR(16);\n\n\n\n            for (y = 0; y < 8; y++) {\n\n                /* get the next set of 8 2-bit flags */\n\n                int flags = bytestream_get_le16(&s->stream_ptr);\n\n                for (x = 0; x < 8; x++, flags >>= 2)\n\n                    *s->pixel_ptr++ = P[flags & 0x03];\n\n                s->pixel_ptr += s->line_inc;\n\n            }\n\n\n\n        } else {\n\n            uint32_t flags;\n\n\n\n            /* 1 of 4 colors for each 2x2 block, need 4 more bytes */\n\n            CHECK_STREAM_PTR(4);\n\n\n\n            flags = bytestream_get_le32(&s->stream_ptr);\n\n\n\n            for (y = 0; y < 8; y += 2) {\n\n                for (x = 0; x < 8; x += 2, flags >>= 2) {\n\n                    s->pixel_ptr[x                ] =\n\n                    s->pixel_ptr[x + 1            ] =\n\n                    s->pixel_ptr[x +     s->stride] =\n\n                    s->pixel_ptr[x + 1 + s->stride] = P[flags & 0x03];\n\n                }\n\n                s->pixel_ptr += s->stride * 2;\n\n            }\n\n\n\n        }\n\n    } else {\n\n        uint64_t flags;\n\n\n\n        /* 1 of 4 colors for each 2x1 or 1x2 block, need 8 more bytes */\n\n        CHECK_STREAM_PTR(8);\n\n\n\n        flags = bytestream_get_le64(&s->stream_ptr);\n\n        if (P[2] <= P[3]) {\n\n            for (y = 0; y < 8; y++) {\n\n                for (x = 0; x < 8; x += 2, flags >>= 2) {\n\n                    s->pixel_ptr[x    ] =\n\n                    s->pixel_ptr[x + 1] = P[flags & 0x03];\n\n                }\n\n                s->pixel_ptr += s->stride;\n\n            }\n\n        } else {\n\n            for (y = 0; y < 8; y += 2) {\n\n                for (x = 0; x < 8; x++, flags >>= 2) {\n\n                    s->pixel_ptr[x            ] =\n\n                    s->pixel_ptr[x + s->stride] = P[flags & 0x03];\n\n                }\n\n                s->pixel_ptr += s->stride * 2;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 24069, "_split": "valid", "_hash": "dcdf4ee63e231c5946126f7916c650c4"}
{"project": "FFmpeg", "commit_id": "b6c04b682176e72125b747b5982bcc4dea1f34c5", "target": 0, "func": "int ff_mjpeg_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *data_size,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MJpegDecodeContext *s = avctx->priv_data;\n\n    const uint8_t *buf_end, *buf_ptr;\n\n    const uint8_t *unescaped_buf_ptr;\n\n    int unescaped_buf_size;\n\n    int start_code;\n\n    AVFrame *picture = data;\n\n\n\n    s->got_picture = 0; // picture from previous image can not be reused\n\n    buf_ptr = buf;\n\n    buf_end = buf + buf_size;\n\n    while (buf_ptr < buf_end) {\n\n        /* find start next marker */\n\n        start_code = ff_mjpeg_find_marker(s, &buf_ptr, buf_end,\n\n                                          &unescaped_buf_ptr, &unescaped_buf_size);\n\n        {\n\n            /* EOF */\n\n            if (start_code < 0) {\n\n                goto the_end;\n\n            } else {\n\n                av_log(avctx, AV_LOG_DEBUG, \"marker=%x avail_size_in_buf=%td\\n\", start_code, buf_end - buf_ptr);\n\n\n\n                init_get_bits(&s->gb, unescaped_buf_ptr, unescaped_buf_size*8);\n\n\n\n                s->start_code = start_code;\n\n                if(s->avctx->debug & FF_DEBUG_STARTCODE){\n\n                    av_log(avctx, AV_LOG_DEBUG, \"startcode: %X\\n\", start_code);\n\n                }\n\n\n\n                /* process markers */\n\n                if (start_code >= 0xd0 && start_code <= 0xd7) {\n\n                    av_log(avctx, AV_LOG_DEBUG, \"restart marker: %d\\n\", start_code&0x0f);\n\n                    /* APP fields */\n\n                } else if (start_code >= APP0 && start_code <= APP15) {\n\n                    mjpeg_decode_app(s);\n\n                    /* Comment */\n\n                } else if (start_code == COM){\n\n                    mjpeg_decode_com(s);\n\n                }\n\n\n\n                switch(start_code) {\n\n                case SOI:\n\n                    s->restart_interval = 0;\n\n\n\n                    s->restart_count = 0;\n\n                    /* nothing to do on SOI */\n\n                    break;\n\n                case DQT:\n\n                    ff_mjpeg_decode_dqt(s);\n\n                    break;\n\n                case DHT:\n\n                    if(ff_mjpeg_decode_dht(s) < 0){\n\n                        av_log(avctx, AV_LOG_ERROR, \"huffman table decode error\\n\");\n\n                        return -1;\n\n                    }\n\n                    break;\n\n                case SOF0:\n\n                case SOF1:\n\n                    s->lossless=0;\n\n                    s->ls=0;\n\n                    s->progressive=0;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case SOF2:\n\n                    s->lossless=0;\n\n                    s->ls=0;\n\n                    s->progressive=1;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case SOF3:\n\n                    s->lossless=1;\n\n                    s->ls=0;\n\n                    s->progressive=0;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case SOF48:\n\n                    s->lossless=1;\n\n                    s->ls=1;\n\n                    s->progressive=0;\n\n                    if (ff_mjpeg_decode_sof(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case LSE:\n\n                    if (!CONFIG_JPEGLS_DECODER || ff_jpegls_decode_lse(s) < 0)\n\n                        return -1;\n\n                    break;\n\n                case EOI:\n\n                    if ((s->buggy_avid && !s->interlaced) || s->restart_interval)\n\n                        break;\n\neoi_parser:\n\n                    s->cur_scan = 0;\n\n                    if (!s->got_picture) {\n\n                        av_log(avctx, AV_LOG_WARNING, \"Found EOI before any SOF, ignoring\\n\");\n\n                        break;\n\n                    }\n\n                    if (s->interlaced) {\n\n                        s->bottom_field ^= 1;\n\n                        /* if not bottom field, do not output image yet */\n\n                        if (s->bottom_field == !s->interlace_polarity)\n\n                            break;\n\n                    }\n\n                    *picture = *s->picture_ptr;\n\n                    *data_size = sizeof(AVFrame);\n\n\n\n                    if(!s->lossless){\n\n                        picture->quality= FFMAX3(s->qscale[0], s->qscale[1], s->qscale[2]);\n\n                        picture->qstride= 0;\n\n                        picture->qscale_table= s->qscale_table;\n\n                        memset(picture->qscale_table, picture->quality, (s->width+15)/16);\n\n                        if(avctx->debug & FF_DEBUG_QP)\n\n                            av_log(avctx, AV_LOG_DEBUG, \"QP: %d\\n\", picture->quality);\n\n                        picture->quality*= FF_QP2LAMBDA;\n\n                    }\n\n\n\n                    goto the_end;\n\n                case SOS:\n\n                    if (!s->got_picture) {\n\n                        av_log(avctx, AV_LOG_WARNING, \"Can not process SOS before SOF, skipping\\n\");\n\n                        break;\n\n                    }\n\n                    if (ff_mjpeg_decode_sos(s, NULL, NULL) < 0 &&\n\n                        avctx->error_recognition >= FF_ER_EXPLODE)\n\n                      return AVERROR_INVALIDDATA;\n\n                    /* buggy avid puts EOI every 10-20th frame */\n\n                    /* if restart period is over process EOI */\n\n                    if ((s->buggy_avid && !s->interlaced) || s->restart_interval)\n\n                        goto eoi_parser;\n\n                    break;\n\n                case DRI:\n\n                    mjpeg_decode_dri(s);\n\n                    break;\n\n                case SOF5:\n\n                case SOF6:\n\n                case SOF7:\n\n                case SOF9:\n\n                case SOF10:\n\n                case SOF11:\n\n                case SOF13:\n\n                case SOF14:\n\n                case SOF15:\n\n                case JPG:\n\n                    av_log(avctx, AV_LOG_ERROR, \"mjpeg: unsupported coding type (%x)\\n\", start_code);\n\n                    break;\n\n//                default:\n\n//                    printf(\"mjpeg: unsupported marker (%x)\\n\", start_code);\n\n//                    break;\n\n                }\n\n\n\n                /* eof process start code */\n\n                buf_ptr += (get_bits_count(&s->gb)+7)/8;\n\n                av_log(avctx, AV_LOG_DEBUG, \"marker parser used %d bytes (%d bits)\\n\",\n\n                       (get_bits_count(&s->gb)+7)/8, get_bits_count(&s->gb));\n\n            }\n\n        }\n\n    }\n\n    if (s->got_picture) {\n\n        av_log(avctx, AV_LOG_WARNING, \"EOI missing, emulating\\n\");\n\n        goto eoi_parser;\n\n    }\n\n    av_log(avctx, AV_LOG_FATAL, \"No JPEG data found in image\\n\");\n\n    return -1;\n\nthe_end:\n\n    av_log(avctx, AV_LOG_DEBUG, \"mjpeg decode frame unused %td bytes\\n\", buf_end - buf_ptr);\n\n//    return buf_end - buf_ptr;\n\n    return buf_ptr - buf;\n\n}\n", "idx": 24070, "_split": "valid", "_hash": "4cce88013aae48e547657bb617e05772"}
{"project": "FFmpeg", "commit_id": "a057ef6923fba7947d8ccf27b751bf91fde3a755", "target": 0, "func": "static int mp_decode_layer3(MPADecodeContext *s)\n\n{\n\n    int nb_granules, main_data_begin;\n\n    int gr, ch, blocksplit_flag, i, j, k, n, bits_pos;\n\n    GranuleDef *g;\n\n    int16_t exponents[576]; //FIXME try INTFLOAT\n\n\n\n    /* read side info */\n\n    if (s->lsf) {\n\n        main_data_begin = get_bits(&s->gb, 8);\n\n        skip_bits(&s->gb, s->nb_channels);\n\n        nb_granules = 1;\n\n    } else {\n\n        main_data_begin = get_bits(&s->gb, 9);\n\n        if (s->nb_channels == 2)\n\n            skip_bits(&s->gb, 3);\n\n        else\n\n            skip_bits(&s->gb, 5);\n\n        nb_granules = 2;\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            s->granules[ch][0].scfsi = 0;/* all scale factors are transmitted */\n\n            s->granules[ch][1].scfsi = get_bits(&s->gb, 4);\n\n        }\n\n    }\n\n\n\n    for (gr = 0; gr < nb_granules; gr++) {\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            av_dlog(s->avctx, \"gr=%d ch=%d: side_info\\n\", gr, ch);\n\n            g = &s->granules[ch][gr];\n\n            g->part2_3_length = get_bits(&s->gb, 12);\n\n            g->big_values     = get_bits(&s->gb,  9);\n\n            if (g->big_values > 288) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"big_values too big\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            g->global_gain = get_bits(&s->gb, 8);\n\n            /* if MS stereo only is selected, we precompute the\n\n               1/sqrt(2) renormalization factor */\n\n            if ((s->mode_ext & (MODE_EXT_MS_STEREO | MODE_EXT_I_STEREO)) ==\n\n                MODE_EXT_MS_STEREO)\n\n                g->global_gain -= 2;\n\n            if (s->lsf)\n\n                g->scalefac_compress = get_bits(&s->gb, 9);\n\n            else\n\n                g->scalefac_compress = get_bits(&s->gb, 4);\n\n            blocksplit_flag = get_bits1(&s->gb);\n\n            if (blocksplit_flag) {\n\n                g->block_type = get_bits(&s->gb, 2);\n\n                if (g->block_type == 0) {\n\n                    av_log(s->avctx, AV_LOG_ERROR, \"invalid block type\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                g->switch_point = get_bits1(&s->gb);\n\n                for (i = 0; i < 2; i++)\n\n                    g->table_select[i] = get_bits(&s->gb, 5);\n\n                for (i = 0; i < 3; i++)\n\n                    g->subblock_gain[i] = get_bits(&s->gb, 3);\n\n                ff_init_short_region(s, g);\n\n            } else {\n\n                int region_address1, region_address2;\n\n                g->block_type = 0;\n\n                g->switch_point = 0;\n\n                for (i = 0; i < 3; i++)\n\n                    g->table_select[i] = get_bits(&s->gb, 5);\n\n                /* compute huffman coded region sizes */\n\n                region_address1 = get_bits(&s->gb, 4);\n\n                region_address2 = get_bits(&s->gb, 3);\n\n                av_dlog(s->avctx, \"region1=%d region2=%d\\n\",\n\n                        region_address1, region_address2);\n\n                ff_init_long_region(s, g, region_address1, region_address2);\n\n            }\n\n            ff_region_offset2size(g);\n\n            ff_compute_band_indexes(s, g);\n\n\n\n            g->preflag = 0;\n\n            if (!s->lsf)\n\n                g->preflag = get_bits1(&s->gb);\n\n            g->scalefac_scale     = get_bits1(&s->gb);\n\n            g->count1table_select = get_bits1(&s->gb);\n\n            av_dlog(s->avctx, \"block_type=%d switch_point=%d\\n\",\n\n                    g->block_type, g->switch_point);\n\n        }\n\n    }\n\n\n\n    if (!s->adu_mode) {\n\n        const uint8_t *ptr = s->gb.buffer + (get_bits_count(&s->gb)>>3);\n\n        int extrasize = av_clip(get_bits_left(&s->gb) >> 3, 0, EXTRABYTES);\n\n        assert((get_bits_count(&s->gb) & 7) == 0);\n\n        /* now we get bits from the main_data_begin offset */\n\n        av_dlog(s->avctx, \"seekback: %d\\n\", main_data_begin);\n\n    //av_log(NULL, AV_LOG_ERROR, \"backstep:%d, lastbuf:%d\\n\", main_data_begin, s->last_buf_size);\n\n\n\n        memcpy(s->last_buf + s->last_buf_size, ptr, extrasize);\n\n        s->in_gb = s->gb;\n\n        init_get_bits(&s->gb, s->last_buf, s->last_buf_size*8);\n\n#if !UNCHECKED_BITSTREAM_READER\n\n        s->gb.size_in_bits_plus8 += FFMAX(extrasize, LAST_BUF_SIZE - s->last_buf_size) * 8;\n\n#endif\n\n        skip_bits_long(&s->gb, 8*(s->last_buf_size - main_data_begin));\n\n    }\n\n\n\n    for (gr = 0; gr < nb_granules; gr++) {\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            g = &s->granules[ch][gr];\n\n            if (get_bits_count(&s->gb) < 0) {\n\n                av_log(s->avctx, AV_LOG_DEBUG, \"mdb:%d, lastbuf:%d skipping granule %d\\n\",\n\n                       main_data_begin, s->last_buf_size, gr);\n\n                skip_bits_long(&s->gb, g->part2_3_length);\n\n                memset(g->sb_hybrid, 0, sizeof(g->sb_hybrid));\n\n                if (get_bits_count(&s->gb) >= s->gb.size_in_bits && s->in_gb.buffer) {\n\n                    skip_bits_long(&s->in_gb, get_bits_count(&s->gb) - s->gb.size_in_bits);\n\n                    s->gb           = s->in_gb;\n\n                    s->in_gb.buffer = NULL;\n\n                }\n\n                continue;\n\n            }\n\n\n\n            bits_pos = get_bits_count(&s->gb);\n\n\n\n            if (!s->lsf) {\n\n                uint8_t *sc;\n\n                int slen, slen1, slen2;\n\n\n\n                /* MPEG1 scale factors */\n\n                slen1 = slen_table[0][g->scalefac_compress];\n\n                slen2 = slen_table[1][g->scalefac_compress];\n\n                av_dlog(s->avctx, \"slen1=%d slen2=%d\\n\", slen1, slen2);\n\n                if (g->block_type == 2) {\n\n                    n = g->switch_point ? 17 : 18;\n\n                    j = 0;\n\n                    if (slen1) {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = get_bits(&s->gb, slen1);\n\n                    } else {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    }\n\n                    if (slen2) {\n\n                        for (i = 0; i < 18; i++)\n\n                            g->scale_factors[j++] = get_bits(&s->gb, slen2);\n\n                        for (i = 0; i < 3; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    } else {\n\n                        for (i = 0; i < 21; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    }\n\n                } else {\n\n                    sc = s->granules[ch][0].scale_factors;\n\n                    j = 0;\n\n                    for (k = 0; k < 4; k++) {\n\n                        n = k == 0 ? 6 : 5;\n\n                        if ((g->scfsi & (0x8 >> k)) == 0) {\n\n                            slen = (k < 2) ? slen1 : slen2;\n\n                            if (slen) {\n\n                                for (i = 0; i < n; i++)\n\n                                    g->scale_factors[j++] = get_bits(&s->gb, slen);\n\n                            } else {\n\n                                for (i = 0; i < n; i++)\n\n                                    g->scale_factors[j++] = 0;\n\n                            }\n\n                        } else {\n\n                            /* simply copy from last granule */\n\n                            for (i = 0; i < n; i++) {\n\n                                g->scale_factors[j] = sc[j];\n\n                                j++;\n\n                            }\n\n                        }\n\n                    }\n\n                    g->scale_factors[j++] = 0;\n\n                }\n\n            } else {\n\n                int tindex, tindex2, slen[4], sl, sf;\n\n\n\n                /* LSF scale factors */\n\n                if (g->block_type == 2)\n\n                    tindex = g->switch_point ? 2 : 1;\n\n                else\n\n                    tindex = 0;\n\n\n\n                sf = g->scalefac_compress;\n\n                if ((s->mode_ext & MODE_EXT_I_STEREO) && ch == 1) {\n\n                    /* intensity stereo case */\n\n                    sf >>= 1;\n\n                    if (sf < 180) {\n\n                        lsf_sf_expand(slen, sf, 6, 6, 0);\n\n                        tindex2 = 3;\n\n                    } else if (sf < 244) {\n\n                        lsf_sf_expand(slen, sf - 180, 4, 4, 0);\n\n                        tindex2 = 4;\n\n                    } else {\n\n                        lsf_sf_expand(slen, sf - 244, 3, 0, 0);\n\n                        tindex2 = 5;\n\n                    }\n\n                } else {\n\n                    /* normal case */\n\n                    if (sf < 400) {\n\n                        lsf_sf_expand(slen, sf, 5, 4, 4);\n\n                        tindex2 = 0;\n\n                    } else if (sf < 500) {\n\n                        lsf_sf_expand(slen, sf - 400, 5, 4, 0);\n\n                        tindex2 = 1;\n\n                    } else {\n\n                        lsf_sf_expand(slen, sf - 500, 3, 0, 0);\n\n                        tindex2 = 2;\n\n                        g->preflag = 1;\n\n                    }\n\n                }\n\n\n\n                j = 0;\n\n                for (k = 0; k < 4; k++) {\n\n                    n  = lsf_nsf_table[tindex2][tindex][k];\n\n                    sl = slen[k];\n\n                    if (sl) {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = get_bits(&s->gb, sl);\n\n                    } else {\n\n                        for (i = 0; i < n; i++)\n\n                            g->scale_factors[j++] = 0;\n\n                    }\n\n                }\n\n                /* XXX: should compute exact size */\n\n                for (; j < 40; j++)\n\n                    g->scale_factors[j] = 0;\n\n            }\n\n\n\n            exponents_from_scale_factors(s, g, exponents);\n\n\n\n            /* read Huffman coded residue */\n\n            huffman_decode(s, g, exponents, bits_pos + g->part2_3_length);\n\n        } /* ch */\n\n\n\n        if (s->nb_channels == 2)\n\n            compute_stereo(s, &s->granules[0][gr], &s->granules[1][gr]);\n\n\n\n        for (ch = 0; ch < s->nb_channels; ch++) {\n\n            g = &s->granules[ch][gr];\n\n\n\n            reorder_block(s, g);\n\n            compute_antialias(s, g);\n\n            compute_imdct(s, g, &s->sb_samples[ch][18 * gr][0], s->mdct_buf[ch]);\n\n        }\n\n    } /* gr */\n\n    if (get_bits_count(&s->gb) < 0)\n\n        skip_bits_long(&s->gb, -get_bits_count(&s->gb));\n\n    return nb_granules * 18;\n\n}\n", "idx": 24155, "_split": "valid", "_hash": "0dba4f180a1699e7f5bc8ebab8969b4f"}
{"project": "FFmpeg", "commit_id": "26fc6ffec45c954cd8ca46342ac75cd90bcc7e02", "target": 1, "func": "static inline void libopenjpeg_copy_to_packed16(AVFrame *picture, opj_image_t *image) {\n\n    uint16_t *img_ptr;\n\n    int index, x, y, c;\n\n    int adjust[4];\n\n    for (x = 0; x < image->numcomps; x++)\n\n        adjust[x] = FFMAX(FFMIN(av_pix_fmt_desc_get(picture->format)->comp[x].depth_minus1 + 1 - image->comps[x].prec, 8), 0);\n\n\n\n    for (y = 0; y < picture->height; y++) {\n\n        index = y*picture->width;\n\n        img_ptr = (uint16_t*) (picture->data[0] + y*picture->linesize[0]);\n\n        for (x = 0; x < picture->width; x++, index++) {\n\n            for (c = 0; c < image->numcomps; c++) {\n\n                *img_ptr++ = 0x8000 * image->comps[c].sgnd + (image->comps[c].data[index] << adjust[c]);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24221, "_split": "valid", "_hash": "31a84e3d53734046f8e5d1bbdd3d89c0"}
{"project": "FFmpeg", "commit_id": "075060023d978975ed5328e269d6e20163e669d2", "target": 1, "func": "int MPV_encode_picture(AVCodecContext *avctx,\n\n                       unsigned char *buf, int buf_size, void *data)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    AVFrame *pic_arg = data;\n\n    int i, stuffing_count;\n\n\n\n    for(i=0; i<avctx->thread_count; i++){\n\n        int start_y= s->thread_context[i]->start_mb_y;\n\n        int   end_y= s->thread_context[i]->  end_mb_y;\n\n        int h= s->mb_height;\n\n        uint8_t *start= buf + (size_t)(((int64_t) buf_size)*start_y/h);\n\n        uint8_t *end  = buf + (size_t)(((int64_t) buf_size)*  end_y/h);\n\n\n\n        init_put_bits(&s->thread_context[i]->pb, start, end - start);\n\n    }\n\n\n\n    s->picture_in_gop_number++;\n\n\n\n    if(load_input_picture(s, pic_arg) < 0)\n\n        return -1;\n\n\n\n    select_input_picture(s);\n\n\n\n    /* output? */\n\n    if(s->new_picture.data[0]){\n\n        s->pict_type= s->new_picture.pict_type;\n\n//emms_c();\n\n//printf(\"qs:%f %f %d\\n\", s->new_picture.quality, s->current_picture.quality, s->qscale);\n\n        MPV_frame_start(s, avctx);\n\n\n\n        if (encode_picture(s, s->picture_number) < 0)\n\n            return -1;\n\n\n\n        avctx->real_pict_num  = s->picture_number;\n\n        avctx->header_bits = s->header_bits;\n\n        avctx->mv_bits     = s->mv_bits;\n\n        avctx->misc_bits   = s->misc_bits;\n\n        avctx->i_tex_bits  = s->i_tex_bits;\n\n        avctx->p_tex_bits  = s->p_tex_bits;\n\n        avctx->i_count     = s->i_count;\n\n        avctx->p_count     = s->mb_num - s->i_count - s->skip_count; //FIXME f/b_count in avctx\n\n        avctx->skip_count  = s->skip_count;\n\n\n\n        MPV_frame_end(s);\n\n\n\n        if (s->out_format == FMT_MJPEG)\n\n            mjpeg_picture_trailer(s);\n\n\n\n        if(s->flags&CODEC_FLAG_PASS1)\n\n            ff_write_pass1_stats(s);\n\n\n\n        for(i=0; i<4; i++){\n\n            s->current_picture_ptr->error[i]= s->current_picture.error[i];\n\n            avctx->error[i] += s->current_picture_ptr->error[i];\n\n        }\n\n\n\n        if(s->flags&CODEC_FLAG_PASS1)\n\n            assert(avctx->header_bits + avctx->mv_bits + avctx->misc_bits + avctx->i_tex_bits + avctx->p_tex_bits == put_bits_count(&s->pb));\n\n        flush_put_bits(&s->pb);\n\n        s->frame_bits  = put_bits_count(&s->pb);\n\n\n\n        stuffing_count= ff_vbv_update(s, s->frame_bits);\n\n        if(stuffing_count){\n\n            if(s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb)>>3) < stuffing_count + 50){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"stuffing too large\\n\");\n\n                return -1;\n\n            }\n\n\n\n            switch(s->codec_id){\n\n            case CODEC_ID_MPEG1VIDEO:\n\n            case CODEC_ID_MPEG2VIDEO:\n\n                while(stuffing_count--){\n\n                    put_bits(&s->pb, 8, 0);\n\n                }\n\n            break;\n\n            case CODEC_ID_MPEG4:\n\n                put_bits(&s->pb, 16, 0);\n\n                put_bits(&s->pb, 16, 0x1C3);\n\n                stuffing_count -= 4;\n\n                while(stuffing_count--){\n\n                    put_bits(&s->pb, 8, 0xFF);\n\n                }\n\n            break;\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"vbv buffer overflow\\n\");\n\n            }\n\n            flush_put_bits(&s->pb);\n\n            s->frame_bits  = put_bits_count(&s->pb);\n\n        }\n\n\n\n        /* update mpeg1/2 vbv_delay for CBR */\n\n        if(s->avctx->rc_max_rate && s->avctx->rc_min_rate == s->avctx->rc_max_rate && s->out_format == FMT_MPEG1\n\n           && 90000LL * (avctx->rc_buffer_size-1) <= s->avctx->rc_max_rate*0xFFFFLL){\n\n            int vbv_delay;\n\n\n\n            assert(s->repeat_first_field==0);\n\n\n\n            vbv_delay= lrintf(90000 * s->rc_context.buffer_index / s->avctx->rc_max_rate);\n\n            assert(vbv_delay < 0xFFFF);\n\n\n\n            s->vbv_delay_ptr[0] &= 0xF8;\n\n            s->vbv_delay_ptr[0] |= vbv_delay>>13;\n\n            s->vbv_delay_ptr[1]  = vbv_delay>>5;\n\n            s->vbv_delay_ptr[2] &= 0x07;\n\n            s->vbv_delay_ptr[2] |= vbv_delay<<3;\n\n        }\n\n        s->total_bits += s->frame_bits;\n\n        avctx->frame_bits  = s->frame_bits;\n\n    }else{\n\n        assert((pbBufPtr(&s->pb) == s->pb.buf));\n\n        s->frame_bits=0;\n\n    }\n\n    assert((s->frame_bits&7)==0);\n\n\n\n    return s->frame_bits/8;\n\n}\n", "idx": 24224, "_split": "valid", "_hash": "85869c9db4de890ac6a8e70c599f1129"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static void vp3_draw_horiz_band(Vp3DecodeContext *s, int y)\n\n{\n\n    int h, cy, i;\n\n    int offset[AV_NUM_DATA_POINTERS];\n\n\n\n    if (HAVE_THREADS && s->avctx->active_thread_type & FF_THREAD_FRAME) {\n\n        int y_flipped = s->flipped_image ? s->avctx->height - y : y;\n\n\n\n        /* At the end of the frame, report INT_MAX instead of the height of\n\n         * the frame. This makes the other threads' ff_thread_await_progress()\n\n         * calls cheaper, because they don't have to clip their values. */\n\n        ff_thread_report_progress(&s->current_frame,\n\n                                  y_flipped == s->avctx->height ? INT_MAX\n\n                                                                : y_flipped - 1,\n\n                                  0);\n\n    }\n\n\n\n    if (s->avctx->draw_horiz_band == NULL)\n\n        return;\n\n\n\n    h = y - s->last_slice_end;\n\n    s->last_slice_end = y;\n\n    y -= h;\n\n\n\n    if (!s->flipped_image)\n\n        y = s->avctx->height - y - h;\n\n\n\n    cy        = y >> s->chroma_y_shift;\n\n    offset[0] = s->current_frame.f->linesize[0] * y;\n\n    offset[1] = s->current_frame.f->linesize[1] * cy;\n\n    offset[2] = s->current_frame.f->linesize[2] * cy;\n\n    for (i = 3; i < AV_NUM_DATA_POINTERS; i++)\n\n        offset[i] = 0;\n\n\n\n    emms_c();\n\n    s->avctx->draw_horiz_band(s->avctx, s->current_frame.f, offset, y, 3, h);\n\n}\n", "idx": 24226, "_split": "valid", "_hash": "8b44a266141e031fa45a92695a715279"}
{"project": "FFmpeg", "commit_id": "d31e3f7ccc5d1e198b3a582f4413ce7342928d8c", "target": 0, "func": "static int gif_write_header(AVFormatContext *s)\n\n{\n\n    GIFContext *gif = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVCodecContext *enc, *video_enc;\n\n    int i, width, height, loop_count /*, rate*/;\n\n\n\n/* XXX: do we reject audio streams or just ignore them ?\n\n    if(s->nb_streams > 1)\n\n        return -1;\n\n*/\n\n    gif->time = 0;\n\n    gif->file_time = 0;\n\n\n\n    video_enc = NULL;\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        enc = s->streams[i]->codec;\n\n        if (enc->codec_type != AVMEDIA_TYPE_AUDIO)\n\n            video_enc = enc;\n\n    }\n\n\n\n    if (!video_enc) {\n\n        av_free(gif);\n\n        return -1;\n\n    } else {\n\n        width = video_enc->width;\n\n        height = video_enc->height;\n\n        loop_count = s->loop_output;\n\n//        rate = video_enc->time_base.den;\n\n    }\n\n\n\n    if (video_enc->pix_fmt != PIX_FMT_RGB24) {\n\n        av_log(s, AV_LOG_ERROR, \"ERROR: gif only handles the rgb24 pixel format. Use -pix_fmt rgb24.\\n\");\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    gif_image_write_header(pb, width, height, loop_count, NULL);\n\n\n\n    avio_flush(s->pb);\n\n    return 0;\n\n}\n", "idx": 24227, "_split": "valid", "_hash": "ac4394b25b9d8791c7dc2ff1d294b37d"}
{"project": "FFmpeg", "commit_id": "033f1644b59abd755bb529afa5db394d18d9c30b", "target": 1, "func": "fixup_vorbis_headers(AVFormatContext * as, struct oggvorbis_private *priv,\n\n                     uint8_t **buf)\n\n{\n\n    int i,offset, len, buf_len;\n\n    unsigned char *ptr;\n\n\n\n    len = priv->len[0] + priv->len[1] + priv->len[2];\n\n    buf_len = len + len/255 + 64;\n\n    ptr = *buf = av_realloc(NULL, buf_len);\n\n\n\n    memset(*buf, '\\0', buf_len);\n\n\n\n    ptr[0] = 2;\n\n    offset = 1;\n\n    offset += av_xiphlacing(&ptr[offset], priv->len[0]);\n\n    offset += av_xiphlacing(&ptr[offset], priv->len[1]);\n\n    for (i = 0; i < 3; i++) {\n\n        memcpy(&ptr[offset], priv->packet[i], priv->len[i]);\n\n        offset += priv->len[i];\n\n        av_freep(&priv->packet[i]);\n\n    }\n\n    *buf = av_realloc(*buf, offset + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    return offset;\n\n}", "idx": 24235, "_split": "valid", "_hash": "f4d11edb11ba0f0e88d174d29e9ebe9d"}
{"project": "FFmpeg", "commit_id": "0d21a84605bad4e75dacb8196e5859902ed36f01", "target": 0, "func": "static inline int small_diamond_search4MV(MpegEncContext * s, int *best, int dmin,\n\n                                       UINT8 *new_pic, UINT8 *old_pic, int pic_stride,\n\n                                       int pred_x, int pred_y, UINT16 *mv_penalty, int quant,\n\n                                       int xmin, int ymin, int xmax, int ymax, int shift)\n\n{\n\n    int next_dir=-1;\n\n\n\n    for(;;){\n\n        int d;\n\n        const int dir= next_dir;\n\n        const int x= best[0];\n\n        const int y= best[1];\n\n        next_dir=-1;\n\n\n\n//printf(\"%d\", dir);\n\n        if(dir!=2 && x>xmin) CHECK_MV4_DIR(x-1, y  , 0)\n\n        if(dir!=3 && y>ymin) CHECK_MV4_DIR(x  , y-1, 1)\n\n        if(dir!=0 && x<xmax) CHECK_MV4_DIR(x+1, y  , 2)\n\n        if(dir!=1 && y<ymax) CHECK_MV4_DIR(x  , y+1, 3)\n\n\n\n        if(next_dir==-1){\n\n            return dmin;\n\n        }\n\n    }\n\n}\n", "idx": 24251, "_split": "valid", "_hash": "9a351b711af4abbd478d5e1d9a75aade"}
{"project": "FFmpeg", "commit_id": "e09ad5bd0de40da9ac33d86f973a85beed85cc47", "target": 0, "func": "void ff_h264_remove_all_refs(H264Context *h)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 16; i++) {\n\n        remove_long(h, i, 0);\n\n    }\n\n    assert(h->long_ref_count == 0);\n\n\n\n    ff_h264_unref_picture(h, &h->last_pic_for_ec);\n\n    if (h->short_ref_count)\n\n        ff_h264_ref_picture(h, &h->last_pic_for_ec, h->short_ref[0]);\n\n\n\n    for (i = 0; i < h->short_ref_count; i++) {\n\n        unreference_pic(h, h->short_ref[i], 0);\n\n        h->short_ref[i] = NULL;\n\n    }\n\n    h->short_ref_count = 0;\n\n\n\n    memset(h->default_ref_list, 0, sizeof(h->default_ref_list));\n\n    memset(h->ref_list, 0, sizeof(h->ref_list));\n\n}\n", "idx": 24285, "_split": "valid", "_hash": "eaf42e61f76fa464521b0efc74eec81b"}
{"project": "FFmpeg", "commit_id": "474176bf927870168a20413f2a9c28f09b6b1afa", "target": 0, "func": "static int get_max_p_order(int max_porder, int n, int order)\n\n{\n\n    int porder, max_parts;\n\n\n\n    porder = max_porder;\n\n    while(porder > 0) {\n\n        max_parts = (1 << porder);\n\n        if(!(n % max_parts) && (n > max_parts*order)) {\n\n            break;\n\n        }\n\n        porder--;\n\n    }\n\n    return porder;\n\n}\n", "idx": 24290, "_split": "valid", "_hash": "acbcc333fffe1082331fcc90ced32ebe"}
{"project": "FFmpeg", "commit_id": "5b0e811a65737463c7e4206b68a23e19d4473519", "target": 1, "func": "static void qtrle_decode_16bpp(QtrleContext *s)\n\n{\n\n    int stream_ptr;\n\n    int header;\n\n    int start_line;\n\n    int lines_to_change;\n\n    signed char rle_code;\n\n    int row_ptr, pixel_ptr;\n\n    int row_inc = s->frame.linesize[0];\n\n    unsigned short rgb16;\n\n    unsigned char *rgb = s->frame.data[0];\n\n    int pixel_limit = s->frame.linesize[0] * s->avctx->height;\n\n\n\n    /* check if this frame is even supposed to change */\n\n    if (s->size < 8)\n\n        return;\n\n\n\n    /* start after the chunk size */\n\n    stream_ptr = 4;\n\n\n\n    /* fetch the header */\n\n    CHECK_STREAM_PTR(2);\n\n    header = BE_16(&s->buf[stream_ptr]);\n\n    stream_ptr += 2;\n\n\n\n    /* if a header is present, fetch additional decoding parameters */\n\n    if (header & 0x0008) {\n\n        CHECK_STREAM_PTR(8);\n\n        start_line = BE_16(&s->buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n        lines_to_change = BE_16(&s->buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n    } else {\n\n        start_line = 0;\n\n        lines_to_change = s->avctx->height;\n\n    }\n\n\n\n    row_ptr = row_inc * start_line;\n\n    while (lines_to_change--) {\n\n        CHECK_STREAM_PTR(2);\n\n        pixel_ptr = row_ptr + (s->buf[stream_ptr++] - 1) * 2;\n\n\n\n        while ((rle_code = (signed char)s->buf[stream_ptr++]) != -1) {\n\n            if (rle_code == 0) {\n\n                /* there's another skip code in the stream */\n\n                CHECK_STREAM_PTR(1);\n\n                pixel_ptr += (s->buf[stream_ptr++] - 1) * 2;\n\n                CHECK_PIXEL_PTR(0);  /* make sure pixel_ptr is positive */\n\n            } else if (rle_code < 0) {\n\n                /* decode the run length code */\n\n                rle_code = -rle_code;\n\n                CHECK_STREAM_PTR(2);\n\n                rgb16 = BE_16(&s->buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n\n\n                CHECK_PIXEL_PTR(rle_code * 2);\n\n\n\n                while (rle_code--) {\n\n                    *(unsigned short *)(&rgb[pixel_ptr]) = rgb16;\n\n                    pixel_ptr += 2;\n\n                }\n\n            } else {\n\n                CHECK_STREAM_PTR(rle_code * 2);\n\n                CHECK_PIXEL_PTR(rle_code * 2);\n\n\n\n                /* copy pixels directly to output */\n\n                while (rle_code--) {\n\n                    rgb16 = BE_16(&s->buf[stream_ptr]);\n\n                    stream_ptr += 2;\n\n                    *(unsigned short *)(&rgb[pixel_ptr]) = rgb16;\n\n                    pixel_ptr += 2;\n\n                }\n\n            }\n\n        }\n\n        row_ptr += row_inc;\n\n    }\n\n}\n", "idx": 24340, "_split": "valid", "_hash": "15e036269953f808732c28423061c7ca"}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(palToY)(uint8_t *dst, uint8_t *src, int width, uint32_t *pal)\n\n{\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tint d= src[i];\n\n\n\n\t\tdst[i]= pal[d] & 0xFF;\n\n\t}\n\n}\n", "idx": 24379, "_split": "valid", "_hash": "b0976edab5260bc4492fc38f965a8b97"}
{"project": "FFmpeg", "commit_id": "99e5a9d1ea2a61ac9429427431e5b9c2fefb76a5", "target": 0, "func": "void ff_dsputil_init_neon(DSPContext *c, AVCodecContext *avctx)\n\n{\n\n    c->put_pixels_tab[0][0] = ff_put_pixels16_neon;\n\n    c->put_pixels_tab[0][1] = ff_put_pixels16_x2_neon;\n\n    c->put_pixels_tab[0][2] = ff_put_pixels16_y2_neon;\n\n    c->put_pixels_tab[0][3] = ff_put_pixels16_xy2_neon;\n\n    c->put_pixels_tab[1][0] = ff_put_pixels8_neon;\n\n    c->put_pixels_tab[1][1] = ff_put_pixels8_x2_neon;\n\n    c->put_pixels_tab[1][2] = ff_put_pixels8_y2_neon;\n\n    c->put_pixels_tab[1][3] = ff_put_pixels8_xy2_neon;\n\n\n\n    c->put_no_rnd_pixels_tab[0][0] = ff_put_pixels16_neon;\n\n    c->put_no_rnd_pixels_tab[0][1] = ff_put_pixels16_x2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[0][2] = ff_put_pixels16_y2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[0][3] = ff_put_pixels16_xy2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[1][0] = ff_put_pixels8_neon;\n\n    c->put_no_rnd_pixels_tab[1][1] = ff_put_pixels8_x2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[1][2] = ff_put_pixels8_y2_no_rnd_neon;\n\n    c->put_no_rnd_pixels_tab[1][3] = ff_put_pixels8_xy2_no_rnd_neon;\n\n\n\n    c->avg_pixels_tab[0][0] = ff_avg_pixels16_neon;\n\n\n\n    c->add_pixels_clamped = ff_add_pixels_clamped_neon;\n\n    c->put_pixels_clamped = ff_put_pixels_clamped_neon;\n\n    c->put_signed_pixels_clamped = ff_put_signed_pixels_clamped_neon;\n\n\n\n    c->put_h264_chroma_pixels_tab[0] = ff_put_h264_chroma_mc8_neon;\n\n    c->put_h264_chroma_pixels_tab[1] = ff_put_h264_chroma_mc4_neon;\n\n\n\n    c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_neon;\n\n    c->avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_neon;\n\n\n\n    c->put_h264_qpel_pixels_tab[0][ 0] = ff_put_h264_qpel16_mc00_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 1] = ff_put_h264_qpel16_mc10_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 2] = ff_put_h264_qpel16_mc20_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 3] = ff_put_h264_qpel16_mc30_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 4] = ff_put_h264_qpel16_mc01_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 5] = ff_put_h264_qpel16_mc11_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 6] = ff_put_h264_qpel16_mc21_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 7] = ff_put_h264_qpel16_mc31_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 8] = ff_put_h264_qpel16_mc02_neon;\n\n    c->put_h264_qpel_pixels_tab[0][ 9] = ff_put_h264_qpel16_mc12_neon;\n\n    c->put_h264_qpel_pixels_tab[0][10] = ff_put_h264_qpel16_mc22_neon;\n\n    c->put_h264_qpel_pixels_tab[0][11] = ff_put_h264_qpel16_mc32_neon;\n\n    c->put_h264_qpel_pixels_tab[0][12] = ff_put_h264_qpel16_mc03_neon;\n\n    c->put_h264_qpel_pixels_tab[0][13] = ff_put_h264_qpel16_mc13_neon;\n\n    c->put_h264_qpel_pixels_tab[0][14] = ff_put_h264_qpel16_mc23_neon;\n\n    c->put_h264_qpel_pixels_tab[0][15] = ff_put_h264_qpel16_mc33_neon;\n\n\n\n    c->put_h264_qpel_pixels_tab[1][ 0] = ff_put_h264_qpel8_mc00_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 1] = ff_put_h264_qpel8_mc10_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 2] = ff_put_h264_qpel8_mc20_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 3] = ff_put_h264_qpel8_mc30_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 4] = ff_put_h264_qpel8_mc01_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 5] = ff_put_h264_qpel8_mc11_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 6] = ff_put_h264_qpel8_mc21_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 7] = ff_put_h264_qpel8_mc31_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 8] = ff_put_h264_qpel8_mc02_neon;\n\n    c->put_h264_qpel_pixels_tab[1][ 9] = ff_put_h264_qpel8_mc12_neon;\n\n    c->put_h264_qpel_pixels_tab[1][10] = ff_put_h264_qpel8_mc22_neon;\n\n    c->put_h264_qpel_pixels_tab[1][11] = ff_put_h264_qpel8_mc32_neon;\n\n    c->put_h264_qpel_pixels_tab[1][12] = ff_put_h264_qpel8_mc03_neon;\n\n    c->put_h264_qpel_pixels_tab[1][13] = ff_put_h264_qpel8_mc13_neon;\n\n    c->put_h264_qpel_pixels_tab[1][14] = ff_put_h264_qpel8_mc23_neon;\n\n    c->put_h264_qpel_pixels_tab[1][15] = ff_put_h264_qpel8_mc33_neon;\n\n\n\n    c->avg_h264_qpel_pixels_tab[0][ 0] = ff_avg_h264_qpel16_mc00_neon;\n\n\n\n    c->h264_v_loop_filter_luma = ff_h264_v_loop_filter_luma_neon;\n\n    c->h264_h_loop_filter_luma = ff_h264_h_loop_filter_luma_neon;\n\n    c->h264_v_loop_filter_chroma = ff_h264_v_loop_filter_chroma_neon;\n\n    c->h264_h_loop_filter_chroma = ff_h264_h_loop_filter_chroma_neon;\n\n\n\n    c->weight_h264_pixels_tab[0] = ff_weight_h264_pixels_16x16_neon;\n\n    c->weight_h264_pixels_tab[1] = ff_weight_h264_pixels_16x8_neon;\n\n    c->weight_h264_pixels_tab[2] = ff_weight_h264_pixels_8x16_neon;\n\n    c->weight_h264_pixels_tab[3] = ff_weight_h264_pixels_8x8_neon;\n\n    c->weight_h264_pixels_tab[4] = ff_weight_h264_pixels_8x4_neon;\n\n    c->weight_h264_pixels_tab[5] = ff_weight_h264_pixels_4x8_neon;\n\n    c->weight_h264_pixels_tab[6] = ff_weight_h264_pixels_4x4_neon;\n\n    c->weight_h264_pixels_tab[7] = ff_weight_h264_pixels_4x2_neon;\n\n\n\n    c->biweight_h264_pixels_tab[0] = ff_biweight_h264_pixels_16x16_neon;\n\n    c->biweight_h264_pixels_tab[1] = ff_biweight_h264_pixels_16x8_neon;\n\n    c->biweight_h264_pixels_tab[2] = ff_biweight_h264_pixels_8x16_neon;\n\n    c->biweight_h264_pixels_tab[3] = ff_biweight_h264_pixels_8x8_neon;\n\n    c->biweight_h264_pixels_tab[4] = ff_biweight_h264_pixels_8x4_neon;\n\n    c->biweight_h264_pixels_tab[5] = ff_biweight_h264_pixels_4x8_neon;\n\n    c->biweight_h264_pixels_tab[6] = ff_biweight_h264_pixels_4x4_neon;\n\n    c->biweight_h264_pixels_tab[7] = ff_biweight_h264_pixels_4x2_neon;\n\n\n\n    c->h264_idct_add = ff_h264_idct_add_neon;\n\n    c->h264_idct_dc_add = ff_h264_idct_dc_add_neon;\n\n    c->h264_idct_add16      = ff_h264_idct_add16_neon;\n\n    c->h264_idct_add16intra = ff_h264_idct_add16intra_neon;\n\n    c->h264_idct_add8       = ff_h264_idct_add8_neon;\n\n\n\n    if (CONFIG_VP3_DECODER || CONFIG_THEORA_DECODER) {\n\n        c->vp3_v_loop_filter = ff_vp3_v_loop_filter_neon;\n\n        c->vp3_h_loop_filter = ff_vp3_h_loop_filter_neon;\n\n    }\n\n\n\n    c->vector_fmul = ff_vector_fmul_neon;\n\n    c->vector_fmul_window = ff_vector_fmul_window_neon;\n\n\n\n    if (!(avctx->flags & CODEC_FLAG_BITEXACT)) {\n\n        c->float_to_int16 = ff_float_to_int16_neon;\n\n        c->float_to_int16_interleave = ff_float_to_int16_interleave_neon;\n\n    }\n\n}\n", "idx": 24398, "_split": "valid", "_hash": "43b8b871becfadee35ffcc332e8a93eb"}
{"project": "FFmpeg", "commit_id": "d1b284119bd5c6a52124443de2c45dbe569c25fc", "target": 0, "func": "static int filter_frame(AVFilterLink *link, AVFrame *frame)\n\n{\n\n    AVFilterContext *ctx = link->dst;\n\n    AudioFIRContext *s = ctx->priv;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    int ret = 0;\n\n\n\n    av_audio_fifo_write(s->fifo[0], (void **)frame->extended_data,\n\n                        frame->nb_samples);\n\n    if (s->pts == AV_NOPTS_VALUE)\n\n        s->pts = frame->pts;\n\n\n\n    av_frame_free(&frame);\n\n\n\n    if (!s->have_coeffs && s->eof_coeffs) {\n\n        ret = convert_coeffs(ctx);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    if (s->have_coeffs) {\n\n        while (av_audio_fifo_size(s->fifo[0]) >= s->part_size) {\n\n            ret = fir_frame(s, outlink);\n\n            if (ret < 0)\n\n                break;\n\n        }\n\n    }\n\n    return ret;\n\n}\n", "idx": 24430, "_split": "valid", "_hash": "4b51e1e01eae1a457f034ff1e79998c9"}
{"project": "FFmpeg", "commit_id": "9d602a0b0e955ac8553b16fc1b98731d66fdde2b", "target": 0, "func": "static int dnxhd_encode_init(AVCodecContext *avctx)\n\n{\n\n    DNXHDEncContext *ctx = avctx->priv_data;\n\n    int i, index, bit_depth;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_YUV422P:\n\n        bit_depth = 8;\n\n        break;\n\n    case AV_PIX_FMT_YUV422P10:\n\n        bit_depth = 10;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"pixel format is incompatible with DNxHD\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->cid = ff_dnxhd_find_cid(avctx, bit_depth);\n\n    if (!ctx->cid) {\n\n        av_log(avctx, AV_LOG_ERROR, \"video parameters incompatible with DNxHD\\n\");\n\n        return -1;\n\n    }\n\n    av_log(avctx, AV_LOG_DEBUG, \"cid %d\\n\", ctx->cid);\n\n\n\n    index = ff_dnxhd_get_cid_table(ctx->cid);\n\n    av_assert0(index >= 0);\n\n    ctx->cid_table = &ff_dnxhd_cid_table[index];\n\n\n\n    ctx->m.avctx = avctx;\n\n    ctx->m.mb_intra = 1;\n\n    ctx->m.h263_aic = 1;\n\n\n\n    avctx->bits_per_raw_sample = ctx->cid_table->bit_depth;\n\n\n\n    ff_dct_common_init(&ctx->m);\n\n    ff_dct_encode_init(&ctx->m);\n\n\n\n    if (!ctx->m.dct_quantize)\n\n        ctx->m.dct_quantize = ff_dct_quantize_c;\n\n\n\n    if (ctx->cid_table->bit_depth == 10) {\n\n       ctx->m.dct_quantize = dnxhd_10bit_dct_quantize;\n\n       ctx->get_pixels_8x4_sym = dnxhd_10bit_get_pixels_8x4_sym;\n\n       ctx->block_width_l2 = 4;\n\n    } else {\n\n       ctx->get_pixels_8x4_sym = dnxhd_8bit_get_pixels_8x4_sym;\n\n       ctx->block_width_l2 = 3;\n\n    }\n\n\n\n    if (ARCH_X86)\n\n        ff_dnxhdenc_init_x86(ctx);\n\n\n\n    ctx->m.mb_height = (avctx->height + 15) / 16;\n\n    ctx->m.mb_width  = (avctx->width  + 15) / 16;\n\n\n\n    if (avctx->flags & CODEC_FLAG_INTERLACED_DCT) {\n\n        ctx->interlaced = 1;\n\n        ctx->m.mb_height /= 2;\n\n    }\n\n\n\n    ctx->m.mb_num = ctx->m.mb_height * ctx->m.mb_width;\n\n\n\n    if (avctx->intra_quant_bias != FF_DEFAULT_QUANT_BIAS)\n\n        ctx->m.intra_quant_bias = avctx->intra_quant_bias;\n\n    if (dnxhd_init_qmat(ctx, ctx->m.intra_quant_bias, 0) < 0) // XXX tune lbias/cbias\n\n        return -1;\n\n\n\n    // Avid Nitris hardware decoder requires a minimum amount of padding in the coding unit payload\n\n    if (ctx->nitris_compat)\n\n        ctx->min_padding = 1600;\n\n\n\n    if (dnxhd_init_vlc(ctx) < 0)\n\n        return -1;\n\n    if (dnxhd_init_rc(ctx) < 0)\n\n        return -1;\n\n\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->slice_size, ctx->m.mb_height*sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->slice_offs, ctx->m.mb_height*sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_bits,    ctx->m.mb_num   *sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_qscale,  ctx->m.mb_num   *sizeof(uint8_t),  fail);\n\n\n\n    ctx->frame.key_frame = 1;\n\n    ctx->frame.pict_type = AV_PICTURE_TYPE_I;\n\n    ctx->m.avctx->coded_frame = &ctx->frame;\n\n\n\n    if (avctx->thread_count > MAX_THREADS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"too many threads\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->thread[0] = ctx;\n\n    for (i = 1; i < avctx->thread_count; i++) {\n\n        ctx->thread[i] =  av_malloc(sizeof(DNXHDEncContext));\n\n        memcpy(ctx->thread[i], ctx, sizeof(DNXHDEncContext));\n\n    }\n\n\n\n    return 0;\n\n fail: //for FF_ALLOCZ_OR_GOTO\n\n    return -1;\n\n}\n", "idx": 24442, "_split": "valid", "_hash": "37b753cf6aff5b6b7537e9d681b20704"}
{"project": "FFmpeg", "commit_id": "44273f19512f96a6e7bd1a4cbcec6c75c93ab488", "target": 0, "func": "static inline int msmpeg4_decode_block(MpegEncContext * s, DCTELEM * block,\n\n                              int n, int coded)\n\n{\n\n    int level, i, last, run, run_diff;\n\n    int dc_pred_dir;\n\n    RLTable *rl;\n\n    RL_VLC_ELEM *rl_vlc;\n\n    const UINT8 *scan_table;\n\n    int qmul, qadd;\n\n\n\n    if (s->mb_intra) {\n\n        qmul=1;\n\n        qadd=0;\n\n\n\n\t/* DC coef */\n\n        set_stat(ST_DC);\n\n        level = msmpeg4_decode_dc(s, n, &dc_pred_dir);\n\n#ifdef PRINT_MB\n\n{\n\n    static int c;\n\n    if(n==0) c=0;\n\n    if(n==4) printf(\"%X\", c);\n\n    c+= c +dc_pred_dir;\n\n}\n\n#endif\n\n        if (level < 0){\n\n            fprintf(stderr, \"dc overflow- block: %d qscale: %d//\\n\", n, s->qscale);\n\n            if(s->inter_intra_pred) level=0;\n\n            else                    return -1;\n\n        }\n\n        if (n < 4) {\n\n            rl = &rl_table[s->rl_table_index];\n\n            if(level > 256*s->y_dc_scale){\n\n                fprintf(stderr, \"dc overflow+ L qscale: %d//\\n\", s->qscale);\n\n                if(!s->inter_intra_pred) return -1;\n\n            }\n\n        } else {\n\n            rl = &rl_table[3 + s->rl_chroma_table_index];\n\n            if(level > 256*s->c_dc_scale){\n\n                fprintf(stderr, \"dc overflow+ C qscale: %d//\\n\", s->qscale);\n\n                if(!s->inter_intra_pred) return -1;\n\n            }\n\n        }\n\n        block[0] = level;\n\n\n\n        run_diff = 0;\n\n        i = 0;\n\n        if (!coded) {\n\n            goto not_coded;\n\n        }\n\n        if (s->ac_pred) {\n\n            if (dc_pred_dir == 0) \n\n                scan_table = s->intra_v_scantable; /* left */\n\n            else\n\n                scan_table = s->intra_h_scantable; /* top */\n\n        } else {\n\n            scan_table = s->intra_scantable;\n\n        }\n\n        set_stat(ST_INTRA_AC);\n\n        rl_vlc= rl->rl_vlc[0];\n\n    } else {\n\n        qmul = s->qscale << 1;\n\n        qadd = (s->qscale - 1) | 1;\n\n        i = -1;\n\n        rl = &rl_table[3 + s->rl_table_index];\n\n\n\n        if(s->msmpeg4_version==2)\n\n            run_diff = 0;\n\n        else\n\n            run_diff = 1;\n\n\n\n        if (!coded) {\n\n            s->block_last_index[n] = i;\n\n            return 0;\n\n        }\n\n        scan_table = s->inter_scantable;\n\n        set_stat(ST_INTER_AC);\n\n        rl_vlc= rl->rl_vlc[s->qscale];\n\n    }\n\n  {\n\n    OPEN_READER(re, &s->gb);\n\n    for(;;) {\n\n        UPDATE_CACHE(re, &s->gb);\n\n        GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n        if (level==0) {\n\n            int cache;\n\n            cache= GET_CACHE(re, &s->gb);\n\n            /* escape */\n\n            if (s->msmpeg4_version==1 || (cache&0x80000000)==0) {\n\n                if (s->msmpeg4_version==1 || (cache&0x40000000)==0) {\n\n                    /* third escape */\n\n                    if(s->msmpeg4_version!=1) LAST_SKIP_BITS(re, &s->gb, 2);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n                    if(s->msmpeg4_version<=3){\n\n                        last=  SHOW_UBITS(re, &s->gb, 1); SKIP_CACHE(re, &s->gb, 1);\n\n                        run=   SHOW_UBITS(re, &s->gb, 6); SKIP_CACHE(re, &s->gb, 6);\n\n                        level= SHOW_SBITS(re, &s->gb, 8); LAST_SKIP_CACHE(re, &s->gb, 8);\n\n                        SKIP_COUNTER(re, &s->gb, 1+6+8);\n\n                    }else{                        \n\n                        int sign;\n\n                        last=  SHOW_UBITS(re, &s->gb, 1); SKIP_BITS(re, &s->gb, 1);\n\n                        if(!s->esc3_level_length){\n\n                            int ll;\n\n                            //printf(\"ESC-3 %X at %d %d\\n\", show_bits(&s->gb, 24), s->mb_x, s->mb_y);\n\n                            if(s->qscale<8){\n\n                                ll= SHOW_UBITS(re, &s->gb, 3); SKIP_BITS(re, &s->gb, 3);\n\n                                if(ll==0){\n\n                                    if(SHOW_UBITS(re, &s->gb, 1)) printf(\"cool a new vlc code ,contact the ffmpeg developers and upload the file\\n\");\n\n                                    SKIP_BITS(re, &s->gb, 1);\n\n                                    ll=8;\n\n                                }\n\n                            }else{\n\n                                ll=2;\n\n                                while(ll<8 && SHOW_UBITS(re, &s->gb, 1)==0){\n\n                                    ll++;\n\n                                    SKIP_BITS(re, &s->gb, 1);\n\n                                }\n\n                                if(ll<8) SKIP_BITS(re, &s->gb, 1);\n\n                            }\n\n\n\n                            s->esc3_level_length= ll;\n\n                            s->esc3_run_length= SHOW_UBITS(re, &s->gb, 2) + 3; SKIP_BITS(re, &s->gb, 2);\n\n//printf(\"level length:%d, run length: %d\\n\", ll, s->esc3_run_length);\n\n                            UPDATE_CACHE(re, &s->gb);\n\n                        }\n\n                        run=   SHOW_UBITS(re, &s->gb, s->esc3_run_length); \n\n                        SKIP_BITS(re, &s->gb, s->esc3_run_length);\n\n                        \n\n                        sign=  SHOW_UBITS(re, &s->gb, 1); \n\n                        SKIP_BITS(re, &s->gb, 1);\n\n                        \n\n                        level= SHOW_UBITS(re, &s->gb, s->esc3_level_length); \n\n                        SKIP_BITS(re, &s->gb, s->esc3_level_length);\n\n                        if(sign) level= -level;\n\n                    }\n\n//printf(\"level: %d, run: %d at %d %d\\n\", level, run, s->mb_x, s->mb_y);\n\n#if 0 // waste of time / this will detect very few errors\n\n                    {\n\n                        const int abs_level= ABS(level);\n\n                        const int run1= run - rl->max_run[last][abs_level] - run_diff;\n\n                        if(abs_level<=MAX_LEVEL && run<=MAX_RUN){\n\n                            if(abs_level <= rl->max_level[last][run]){\n\n                                fprintf(stderr, \"illegal 3. esc, vlc encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                            if(abs_level <= rl->max_level[last][run]*2){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 1 encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                            if(run1>=0 && abs_level <= rl->max_level[last][run1]){\n\n                                fprintf(stderr, \"illegal 3. esc, esc 2 encoding possible\\n\");\n\n                                return DECODING_AC_LOST;\n\n                            }\n\n                        }\n\n                    }\n\n#endif\n\n\t\t    //level = level * qmul + (level>0) * qadd - (level<=0) * qadd ;\n\n\t\t    if (level>0) level= level * qmul + qadd;\n\n                    else         level= level * qmul - qadd;\n\n#if 0 // waste of time too :(\n\n                    if(level>2048 || level<-2048){\n\n                        fprintf(stderr, \"|level| overflow in 3. esc\\n\");\n\n                        return DECODING_AC_LOST;\n\n                    }\n\n#endif\n\n                    i+= run + 1;\n\n                    if(last) i+=192;\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC3 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC3 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n                } else {\n\n                    /* second escape */\n\n#if MIN_CACHE_BITS < 23\n\n                    LAST_SKIP_BITS(re, &s->gb, 2);\n\n                    UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                    SKIP_BITS(re, &s->gb, 2);\n\n#endif\n\n                    GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                    i+= run + rl->max_run[run>>7][level/qmul] + run_diff; //FIXME opt indexing\n\n                    level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                    LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC2 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC2 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n                }\n\n            } else {\n\n                /* first escape */\n\n#if MIN_CACHE_BITS < 22\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n                UPDATE_CACHE(re, &s->gb);\n\n#else\n\n                SKIP_BITS(re, &s->gb, 1);\n\n#endif\n\n                GET_RL_VLC(level, run, re, &s->gb, rl_vlc, TEX_VLC_BITS, 2);\n\n                i+= run;\n\n                level = level + rl->max_level[run>>7][(run-1)&63] * qmul;//FIXME opt indexing\n\n                level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n                LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code in ESC1 level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow in ESC1 i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n            }\n\n        } else {\n\n            i+= run;\n\n            level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n            LAST_SKIP_BITS(re, &s->gb, 1);\n\n#ifdef ERROR_DETAILS\n\n                if(run==66)\n\n                    fprintf(stderr, \"illegal vlc code level=%d\\n\", level);\n\n                else if((i>62 && i<192) || i>192+63)\n\n                    fprintf(stderr, \"run overflow i=%d run=%d level=%d\\n\", i, run, level);\n\n#endif\n\n        }\n\n        if (i > 62){\n\n            i-= 192;\n\n            if(i&(~63)){\n\n                if(i+192 == 64 && level/qmul==-1){\n\n                    fprintf(stderr, \"ignoring overflow at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    break;\n\n                }else{\n\n                    fprintf(stderr, \"ac-tex damaged at %d %d\\n\", s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            block[scan_table[i]] = level;\n\n            break;\n\n        }\n\n\n\n        block[scan_table[i]] = level;\n\n    }\n\n    CLOSE_READER(re, &s->gb);\n\n  }\n\n not_coded:\n\n    if (s->mb_intra) {\n\n        mpeg4_pred_ac(s, block, n, dc_pred_dir);\n\n        if (s->ac_pred) {\n\n            i = 63; /* XXX: not optimal */\n\n        }\n\n    }\n\n    if(s->msmpeg4_version==4 && i>0) i=63; //FIXME/XXX optimize\n\n    s->block_last_index[n] = i;\n\n    \n\n    return 0;\n\n}\n", "idx": 24469, "_split": "valid", "_hash": "f138f34c18d02011d7d01134383276d0"}
{"project": "FFmpeg", "commit_id": "bacc4b6e8173fa944c24f297435dc507a60efb10", "target": 1, "func": "static void revert_acfilter(WmallDecodeCtx *s, int tile_size)\n\n{\n\n    int ich, pred, i, j;\n\n    int16_t *filter_coeffs = s->acfilter_coeffs;\n\n    int scaling            = s->acfilter_scaling;\n\n    int order              = s->acfilter_order;\n\n\n\n    for (ich = 0; ich < s->num_channels; ich++) {\n\n        int *prevvalues = s->acfilter_prevvalues[ich];\n\n        for (i = 0; i < order; i++) {\n\n            pred = 0;\n\n            for (j = 0; j < order; j++) {\n\n                if (i <= j)\n\n                    pred += filter_coeffs[j] * prevvalues[j - i];\n\n                else\n\n                    pred += s->channel_residues[ich][i - j - 1] * filter_coeffs[j];\n\n            }\n\n            pred >>= scaling;\n\n            s->channel_residues[ich][i] += pred;\n\n        }\n\n        for (i = order; i < tile_size; i++) {\n\n            pred = 0;\n\n            for (j = 0; j < order; j++)\n\n                pred += s->channel_residues[ich][i - j - 1] * filter_coeffs[j];\n\n            pred >>= scaling;\n\n            s->channel_residues[ich][i] += pred;\n\n        }\n\n        for (j = 0; j < order; j++)\n\n            prevvalues[j] = s->channel_residues[ich][tile_size - j - 1];\n\n    }\n\n}\n", "idx": 24471, "_split": "valid", "_hash": "8b4b5a67409f8fd1e9917021a4a6988b"}
{"project": "FFmpeg", "commit_id": "2272ab0e84de6ef29548e0c89bb041a5c2e55a18", "target": 0, "func": "static int mp3_write_xing(AVFormatContext *s)\n\n{\n\n    MP3Context       *mp3 = s->priv_data;\n\n    AVCodecContext *codec = s->streams[mp3->audio_stream_idx]->codec;\n\n    AVDictionaryEntry *enc = av_dict_get(s->streams[mp3->audio_stream_idx]->metadata, \"encoder\", NULL, 0);\n\n    AVIOContext *dyn_ctx;\n\n    int32_t        header;\n\n    MPADecodeHeader  mpah;\n\n    int srate_idx, i, channels;\n\n    int bitrate_idx;\n\n    int best_bitrate_idx = -1;\n\n    int best_bitrate_error = INT_MAX;\n\n    int ret;\n\n    int ver = 0;\n\n    int bytes_needed;\n\n\n\n    if (!s->pb->seekable || !mp3->write_xing)\n\n        return 0;\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(avpriv_mpa_freq_tab); i++) {\n\n        const uint16_t base_freq = avpriv_mpa_freq_tab[i];\n\n\n\n        if      (codec->sample_rate == base_freq)     ver = 0x3; // MPEG 1\n\n        else if (codec->sample_rate == base_freq / 2) ver = 0x2; // MPEG 2\n\n        else if (codec->sample_rate == base_freq / 4) ver = 0x0; // MPEG 2.5\n\n        else continue;\n\n\n\n        srate_idx = i;\n\n        break;\n\n    }\n\n    if (i == FF_ARRAY_ELEMS(avpriv_mpa_freq_tab)) {\n\n        av_log(s, AV_LOG_WARNING, \"Unsupported sample rate, not writing Xing header.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    switch (codec->channels) {\n\n    case 1:  channels = MPA_MONO;                                          break;\n\n    case 2:  channels = MPA_STEREO;                                        break;\n\n    default: av_log(s, AV_LOG_WARNING, \"Unsupported number of channels, \"\n\n                    \"not writing Xing header.\\n\");\n\n             return -1;\n\n    }\n\n\n\n    /* dummy MPEG audio header */\n\n    header  =  0xffU                                 << 24; // sync\n\n    header |= (0x7 << 5 | ver << 3 | 0x1 << 1 | 0x1) << 16; // sync/audio-version/layer 3/no crc*/\n\n    header |= (srate_idx << 2) << 8;\n\n    header |= channels << 6;\n\n\n\n    for (bitrate_idx = 1; bitrate_idx < 15; bitrate_idx++) {\n\n        int bit_rate = 1000 * avpriv_mpa_bitrate_tab[ver != 3][3 - 1][bitrate_idx];\n\n        int error    = FFABS(bit_rate - codec->bit_rate);\n\n\n\n        if (error < best_bitrate_error) {\n\n            best_bitrate_error = error;\n\n            best_bitrate_idx   = bitrate_idx;\n\n        }\n\n    }\n\n    av_assert0(best_bitrate_idx >= 0);\n\n\n\n    for (bitrate_idx = best_bitrate_idx; ; bitrate_idx++) {\n\n        int32_t mask = bitrate_idx << (4 + 8);\n\n        if (15 == bitrate_idx)\n\n            return -1;\n\n        header |= mask;\n\n\n\n        avpriv_mpegaudio_decode_header(&mpah, header);\n\n        mp3->xing_offset = xing_offtbl[mpah.lsf == 1][mpah.nb_channels == 1] + 4;\n\n        bytes_needed     = mp3->xing_offset + XING_SIZE;\n\n\n\n        if (bytes_needed <= mpah.frame_size)\n\n            break;\n\n\n\n        header &= ~mask;\n\n    }\n\n\n\n    ret = avio_open_dyn_buf(&dyn_ctx);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    avio_wb32(dyn_ctx, header);\n\n\n\n    ffio_fill(dyn_ctx, 0, mp3->xing_offset - 4);\n\n    ffio_wfourcc(dyn_ctx, \"Xing\");\n\n    avio_wb32(dyn_ctx, 0x01 | 0x02 | 0x04 | 0x08);  // frames / size / TOC / vbr scale\n\n\n\n    mp3->size = mpah.frame_size;\n\n    mp3->want=1;\n\n    mp3->seen=0;\n\n    mp3->pos=0;\n\n\n\n    avio_wb32(dyn_ctx, 0);  // frames\n\n    avio_wb32(dyn_ctx, 0);  // size\n\n\n\n    // TOC\n\n    for (i = 0; i < XING_TOC_SIZE; i++)\n\n        avio_w8(dyn_ctx, (uint8_t)(255 * i / XING_TOC_SIZE));\n\n\n\n    // vbr quality\n\n    // we write it, because some (broken) tools always expect it to be present\n\n    avio_wb32(dyn_ctx, 0);\n\n\n\n    // encoder short version string\n\n    if (enc) {\n\n        uint8_t encoder_str[9] = { 0 };\n\n        if (   strlen(enc->value) > sizeof(encoder_str)\n\n            && !strcmp(\"Lavc libmp3lame\", enc->value)) {\n\n            memcpy(encoder_str, \"Lavf lame\", 9);\n\n        } else\n\n            memcpy(encoder_str, enc->value, FFMIN(strlen(enc->value), sizeof(encoder_str)));\n\n\n\n        avio_write(dyn_ctx, encoder_str, sizeof(encoder_str));\n\n    } else\n\n        avio_write(dyn_ctx, \"Lavf\\0\\0\\0\\0\\0\", 9);\n\n\n\n    avio_w8(dyn_ctx, 0);      // tag revision 0 / unknown vbr method\n\n    avio_w8(dyn_ctx, 0);      // unknown lowpass filter value\n\n    ffio_fill(dyn_ctx, 0, 8); // empty replaygain fields\n\n    avio_w8(dyn_ctx, 0);      // unknown encoding flags\n\n    avio_w8(dyn_ctx, 0);      // unknown abr/minimal bitrate\n\n\n\n    // encoder delay\n\n    if (codec->initial_padding - 528 - 1 >= 1 << 12) {\n\n        av_log(s, AV_LOG_WARNING, \"Too many samples of initial padding.\\n\");\n\n    }\n\n    avio_wb24(dyn_ctx, FFMAX(codec->initial_padding - 528 - 1, 0)<<12);\n\n\n\n    avio_w8(dyn_ctx,   0); // misc\n\n    avio_w8(dyn_ctx,   0); // mp3gain\n\n    avio_wb16(dyn_ctx, 0); // preset\n\n\n\n    // audio length and CRCs (will be updated later)\n\n    avio_wb32(dyn_ctx, 0); // music length\n\n    avio_wb16(dyn_ctx, 0); // music crc\n\n    avio_wb16(dyn_ctx, 0); // tag crc\n\n\n\n    ffio_fill(dyn_ctx, 0, mpah.frame_size - bytes_needed);\n\n\n\n    mp3->xing_frame_size   = avio_close_dyn_buf(dyn_ctx, &mp3->xing_frame);\n\n    mp3->xing_frame_offset = avio_tell(s->pb);\n\n    avio_write(s->pb, mp3->xing_frame, mp3->xing_frame_size);\n\n\n\n    mp3->audio_size = mp3->xing_frame_size;\n\n\n\n    return 0;\n\n}\n", "idx": 24506, "_split": "valid", "_hash": "373feb0ecc9ba7efd09d33b96578f828"}
{"project": "FFmpeg", "commit_id": "ea5366670e26b2c6c396e6a5f49827a2b71e6dd6", "target": 1, "func": "static void dwt_decode97_int(DWTContext *s, int32_t *t)\n\n{\n\n    int lev;\n\n    int w       = s->linelen[s->ndeclevels - 1][0];\n\n    int h       = s->linelen[s->ndeclevels - 1][1];\n\n    int i;\n\n    int32_t *line = s->i_linebuf;\n\n    int32_t *data = t;\n\n    /* position at index O of line range [0-5,w+5] cf. extend function */\n\n    line += 5;\n\n\n\n    for (i = 0; i < w * h; i++)\n\n        data[i] *= 1 << I_PRESHIFT;\n\n\n\n    for (lev = 0; lev < s->ndeclevels; lev++) {\n\n        int lh = s->linelen[lev][0],\n\n            lv = s->linelen[lev][1],\n\n            mh = s->mod[lev][0],\n\n            mv = s->mod[lev][1],\n\n            lp;\n\n        int32_t *l;\n\n        // HOR_SD\n\n        l = line + mh;\n\n        for (lp = 0; lp < lv; lp++) {\n\n            int i, j = 0;\n\n            // rescale with interleaving\n\n            for (i = mh; i < lh; i += 2, j++)\n\n                l[i] = ((data[w * lp + j] * I_LFTG_K) + (1 << 15)) >> 16;\n\n            for (i = 1 - mh; i < lh; i += 2, j++)\n\n                l[i] = data[w * lp + j];\n\n\n\n            sr_1d97_int(line, mh, mh + lh);\n\n\n\n            for (i = 0; i < lh; i++)\n\n                data[w * lp + i] = l[i];\n\n        }\n\n\n\n        // VER_SD\n\n        l = line + mv;\n\n        for (lp = 0; lp < lh; lp++) {\n\n            int i, j = 0;\n\n            // rescale with interleaving\n\n            for (i = mv; i < lv; i += 2, j++)\n\n                l[i] = ((data[w * j + lp] * I_LFTG_K) + (1 << 15)) >> 16;\n\n            for (i = 1 - mv; i < lv; i += 2, j++)\n\n                l[i] = data[w * j + lp];\n\n\n\n            sr_1d97_int(line, mv, mv + lv);\n\n\n\n            for (i = 0; i < lv; i++)\n\n                data[w * i + lp] = l[i];\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < w * h; i++)\n\n        data[i] = (data[i] + ((1<<I_PRESHIFT)>>1)) >> I_PRESHIFT;\n\n}\n", "idx": 24524, "_split": "valid", "_hash": "ee890b225e91507fc6614345cae35415"}
{"project": "FFmpeg", "commit_id": "add41decd94b2d3581a3715ba10f27168b8cdb1b", "target": 0, "func": "static int get_http_header_data(MMSHContext *mmsh)\n\n{\n\n    MMSContext *mms = &mmsh->mms;\n\n    int res, len;\n\n    ChunkType chunk_type;\n\n\n\n    for (;;) {\n\n        len = 0;\n\n        res = chunk_type = get_chunk_header(mmsh, &len);\n\n        if (res < 0) {\n\n            return res;\n\n        } else if (chunk_type == CHUNK_TYPE_ASF_HEADER){\n\n            // get asf header and stored it\n\n            if (!mms->header_parsed) {\n\n                if (mms->asf_header) {\n\n                    if (len != mms->asf_header_size) {\n\n                        mms->asf_header_size = len;\n\n                        av_dlog(NULL, \"Header len changed from %d to %d\\n\",\n\n                                mms->asf_header_size, len);\n\n                        av_freep(&mms->asf_header);\n\n                    }\n\n                }\n\n                mms->asf_header = av_mallocz(len);\n\n                if (!mms->asf_header) {\n\n                    return AVERROR(ENOMEM);\n\n                }\n\n                mms->asf_header_size = len;\n\n            }\n\n            if (len > mms->asf_header_size) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Asf header packet len = %d exceed the asf header buf size %d\\n\",\n\n                       len, mms->asf_header_size);\n\n                return AVERROR(EIO);\n\n            }\n\n            res = ffurl_read_complete(mms->mms_hd, mms->asf_header, len);\n\n            if (res != len) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Recv asf header data len %d != expected len %d\\n\", res, len);\n\n                return AVERROR(EIO);\n\n            }\n\n            mms->asf_header_size = len;\n\n            if (!mms->header_parsed) {\n\n                res = ff_mms_asf_header_parser(mms);\n\n                mms->header_parsed = 1;\n\n                return res;\n\n            }\n\n        } else if (chunk_type == CHUNK_TYPE_DATA) {\n\n            // read data packet and do padding\n\n            return read_data_packet(mmsh, len);\n\n        } else {\n\n            if (len) {\n\n                if (len > sizeof(mms->in_buffer)) {\n\n                    av_log(NULL, AV_LOG_ERROR,\n\n                           \"Other packet len = %d exceed the in_buffer size %zu\\n\",\n\n                           len, sizeof(mms->in_buffer));\n\n                    return AVERROR(EIO);\n\n                }\n\n                res = ffurl_read_complete(mms->mms_hd, mms->in_buffer, len);\n\n                if (res != len) {\n\n                    av_log(NULL, AV_LOG_ERROR, \"Read other chunk type data failed!\\n\");\n\n                    return AVERROR(EIO);\n\n                } else {\n\n                    av_dlog(NULL, \"Skip chunk type %d \\n\", chunk_type);\n\n                    continue;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24545, "_split": "valid", "_hash": "5522ac1d2a2ed61f16f67bdbf45f4383"}
{"project": "FFmpeg", "commit_id": "4a745b41770893116405c22f832192510f9bcc9b", "target": 1, "func": "static int pnm_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf   = avpkt->data;\n\n    int buf_size         = avpkt->size;\n\n    PNMContext * const s = avctx->priv_data;\n\n    AVFrame *picture     = data;\n\n    AVFrame * const p    = (AVFrame*)&s->picture;\n\n    int i, j, n, linesize, h, upgrade = 0;\n\n    unsigned char *ptr;\n\n    int components, sample_len;\n\n\n\n    s->bytestream_start =\n\n    s->bytestream       = buf;\n\n    s->bytestream_end   = buf + buf_size;\n\n\n\n    if (ff_pnm_decode_header(avctx, s) < 0)\n\n        return -1;\n\n\n\n    if (p->data[0])\n\n        avctx->release_buffer(avctx, p);\n\n\n\n    p->reference = 0;\n\n    if (avctx->get_buffer(avctx, p) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n    p->key_frame = 1;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    default:\n\n        return -1;\n\n    case PIX_FMT_RGB48BE:\n\n        n = avctx->width * 6;\n\n        components=3;\n\n        sample_len=16;\n\n        goto do_read;\n\n    case PIX_FMT_RGB24:\n\n        n = avctx->width * 3;\n\n        components=3;\n\n        sample_len=8;\n\n        goto do_read;\n\n    case PIX_FMT_GRAY8:\n\n        n = avctx->width;\n\n        components=1;\n\n        sample_len=8;\n\n        if (s->maxval < 255)\n\n            upgrade = 1;\n\n        goto do_read;\n\n    case PIX_FMT_GRAY16BE:\n\n    case PIX_FMT_GRAY16LE:\n\n        n = avctx->width * 2;\n\n        components=1;\n\n        sample_len=16;\n\n        if (s->maxval < 65535)\n\n            upgrade = 2;\n\n        goto do_read;\n\n    case PIX_FMT_MONOWHITE:\n\n    case PIX_FMT_MONOBLACK:\n\n        n = (avctx->width + 7) >> 3;\n\n        components=1;\n\n        sample_len=1;\n\n    do_read:\n\n        ptr      = p->data[0];\n\n        linesize = p->linesize[0];\n\n        if (s->bytestream + n * avctx->height > s->bytestream_end)\n\n            return -1;\n\n        if(s->type < 4){\n\n            for (i=0; i<avctx->height; i++) {\n\n                PutBitContext pb;\n\n                init_put_bits(&pb, ptr, linesize);\n\n                for(j=0; j<avctx->width * components; j++){\n\n                    unsigned int c=0;\n\n                    int v=0;\n\n                    while(s->bytestream < s->bytestream_end && (*s->bytestream < '0' || *s->bytestream > '9' ))\n\n                        s->bytestream++;\n\n                    if(s->bytestream >= s->bytestream_end)\n\n                        return -1;\n\n                    do{\n\n                        v= 10*v + c;\n\n                        c= (*s->bytestream++) - '0';\n\n                    }while(c <= 9);\n\n                    put_bits(&pb, sample_len, (((1<<sample_len)-1)*v + (s->maxval>>1))/s->maxval);\n\n                }\n\n                flush_put_bits(&pb);\n\n                ptr+= linesize;\n\n            }\n\n        }else{\n\n        for (i = 0; i < avctx->height; i++) {\n\n            if (!upgrade)\n\n                memcpy(ptr, s->bytestream, n);\n\n            else if (upgrade == 1) {\n\n                unsigned int j, f = (255 * 128 + s->maxval / 2) / s->maxval;\n\n                for (j = 0; j < n; j++)\n\n                    ptr[j] = (s->bytestream[j] * f + 64) >> 7;\n\n            } else if (upgrade == 2) {\n\n                unsigned int j, v, f = (65535 * 32768 + s->maxval / 2) / s->maxval;\n\n                for (j = 0; j < n / 2; j++) {\n\n                    v = av_be2ne16(((uint16_t *)s->bytestream)[j]);\n\n                    ((uint16_t *)ptr)[j] = (v * f + 16384) >> 15;\n\n                }\n\n            }\n\n            s->bytestream += n;\n\n            ptr           += linesize;\n\n        }\n\n        }\n\n        break;\n\n    case PIX_FMT_YUV420P:\n\n        {\n\n            unsigned char *ptr1, *ptr2;\n\n\n\n            n        = avctx->width;\n\n            ptr      = p->data[0];\n\n            linesize = p->linesize[0];\n\n            if (s->bytestream + n * avctx->height * 3 / 2 > s->bytestream_end)\n\n                return -1;\n\n            for (i = 0; i < avctx->height; i++) {\n\n                memcpy(ptr, s->bytestream, n);\n\n                s->bytestream += n;\n\n                ptr           += linesize;\n\n            }\n\n            ptr1 = p->data[1];\n\n            ptr2 = p->data[2];\n\n            n >>= 1;\n\n            h = avctx->height >> 1;\n\n            for (i = 0; i < h; i++) {\n\n                memcpy(ptr1, s->bytestream, n);\n\n                s->bytestream += n;\n\n                memcpy(ptr2, s->bytestream, n);\n\n                s->bytestream += n;\n\n                ptr1 += p->linesize[1];\n\n                ptr2 += p->linesize[2];\n\n            }\n\n        }\n\n        break;\n\n    case PIX_FMT_RGB32:\n\n        ptr      = p->data[0];\n\n        linesize = p->linesize[0];\n\n        if (s->bytestream + avctx->width * avctx->height * 4 > s->bytestream_end)\n\n            return -1;\n\n        for (i = 0; i < avctx->height; i++) {\n\n            int j, r, g, b, a;\n\n\n\n            for (j = 0; j < avctx->width; j++) {\n\n                r = *s->bytestream++;\n\n                g = *s->bytestream++;\n\n                b = *s->bytestream++;\n\n                a = *s->bytestream++;\n\n                ((uint32_t *)ptr)[j] = (a << 24) | (r << 16) | (g << 8) | b;\n\n            }\n\n            ptr += linesize;\n\n        }\n\n        break;\n\n    }\n\n    *picture   = *(AVFrame*)&s->picture;\n\n    *data_size = sizeof(AVPicture);\n\n\n\n    return s->bytestream - s->bytestream_start;\n\n}\n", "idx": 24558, "_split": "valid", "_hash": "b5f52971059924346e9e4d83a17b7096"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int estimate_best_b_count(MpegEncContext *s)\n\n{\n\n    AVCodec *codec    = avcodec_find_encoder(s->avctx->codec_id);\n\n    AVCodecContext *c = avcodec_alloc_context3(NULL);\n\n    const int scale = s->avctx->brd_scale;\n\n    int i, j, out_size, p_lambda, b_lambda, lambda2;\n\n    int64_t best_rd  = INT64_MAX;\n\n    int best_b_count = -1;\n\n\n\n    assert(scale >= 0 && scale <= 3);\n\n\n\n    //emms_c();\n\n    //s->next_picture_ptr->quality;\n\n    p_lambda = s->last_lambda_for[AV_PICTURE_TYPE_P];\n\n    //p_lambda * FFABS(s->avctx->b_quant_factor) + s->avctx->b_quant_offset;\n\n    b_lambda = s->last_lambda_for[AV_PICTURE_TYPE_B];\n\n    if (!b_lambda) // FIXME we should do this somewhere else\n\n        b_lambda = p_lambda;\n\n    lambda2  = (b_lambda * b_lambda + (1 << FF_LAMBDA_SHIFT) / 2) >>\n\n               FF_LAMBDA_SHIFT;\n\n\n\n    c->width        = s->width  >> scale;\n\n    c->height       = s->height >> scale;\n\n    c->flags        = CODEC_FLAG_QSCALE | CODEC_FLAG_PSNR |\n\n                      CODEC_FLAG_INPUT_PRESERVED;\n\n    c->flags       |= s->avctx->flags & CODEC_FLAG_QPEL;\n\n    c->mb_decision  = s->avctx->mb_decision;\n\n    c->me_cmp       = s->avctx->me_cmp;\n\n    c->mb_cmp       = s->avctx->mb_cmp;\n\n    c->me_sub_cmp   = s->avctx->me_sub_cmp;\n\n    c->pix_fmt      = AV_PIX_FMT_YUV420P;\n\n    c->time_base    = s->avctx->time_base;\n\n    c->max_b_frames = s->max_b_frames;\n\n\n\n    if (avcodec_open2(c, codec, NULL) < 0)\n\n        return -1;\n\n\n\n    for (i = 0; i < s->max_b_frames + 2; i++) {\n\n        Picture pre_input, *pre_input_ptr = i ? s->input_picture[i - 1] :\n\n                                                s->next_picture_ptr;\n\n\n\n        if (pre_input_ptr && (!i || s->input_picture[i - 1])) {\n\n            pre_input = *pre_input_ptr;\n\n\n\n            if (!pre_input.shared && i) {\n\n                pre_input.f.data[0] += INPLACE_OFFSET;\n\n                pre_input.f.data[1] += INPLACE_OFFSET;\n\n                pre_input.f.data[2] += INPLACE_OFFSET;\n\n            }\n\n\n\n            s->dsp.shrink[scale](s->tmp_frames[i]->data[0], s->tmp_frames[i]->linesize[0],\n\n                                 pre_input.f.data[0], pre_input.f.linesize[0],\n\n                                 c->width,      c->height);\n\n            s->dsp.shrink[scale](s->tmp_frames[i]->data[1], s->tmp_frames[i]->linesize[1],\n\n                                 pre_input.f.data[1], pre_input.f.linesize[1],\n\n                                 c->width >> 1, c->height >> 1);\n\n            s->dsp.shrink[scale](s->tmp_frames[i]->data[2], s->tmp_frames[i]->linesize[2],\n\n                                 pre_input.f.data[2], pre_input.f.linesize[2],\n\n                                 c->width >> 1, c->height >> 1);\n\n        }\n\n    }\n\n\n\n    for (j = 0; j < s->max_b_frames + 1; j++) {\n\n        int64_t rd = 0;\n\n\n\n        if (!s->input_picture[j])\n\n            break;\n\n\n\n        c->error[0] = c->error[1] = c->error[2] = 0;\n\n\n\n        s->tmp_frames[0]->pict_type = AV_PICTURE_TYPE_I;\n\n        s->tmp_frames[0]->quality   = 1 * FF_QP2LAMBDA;\n\n\n\n        out_size = encode_frame(c, s->tmp_frames[0]);\n\n\n\n        //rd += (out_size * lambda2) >> FF_LAMBDA_SHIFT;\n\n\n\n        for (i = 0; i < s->max_b_frames + 1; i++) {\n\n            int is_p = i % (j + 1) == j || i == s->max_b_frames;\n\n\n\n            s->tmp_frames[i + 1]->pict_type = is_p ?\n\n                                     AV_PICTURE_TYPE_P : AV_PICTURE_TYPE_B;\n\n            s->tmp_frames[i + 1]->quality   = is_p ? p_lambda : b_lambda;\n\n\n\n            out_size = encode_frame(c, s->tmp_frames[i + 1]);\n\n\n\n            rd += (out_size * lambda2) >> (FF_LAMBDA_SHIFT - 3);\n\n        }\n\n\n\n        /* get the delayed frames */\n\n        while (out_size) {\n\n            out_size = encode_frame(c, NULL);\n\n            rd += (out_size * lambda2) >> (FF_LAMBDA_SHIFT - 3);\n\n        }\n\n\n\n        rd += c->error[0] + c->error[1] + c->error[2];\n\n\n\n        if (rd < best_rd) {\n\n            best_rd = rd;\n\n            best_b_count = j;\n\n        }\n\n    }\n\n\n\n    avcodec_close(c);\n\n    av_freep(&c);\n\n\n\n    return best_b_count;\n\n}\n", "idx": 24570, "_split": "valid", "_hash": "a4117a42c8ed37af31996ba4d515e266"}
{"project": "FFmpeg", "commit_id": "435a6082f9e368196e0d8347858c63de1126af2c", "target": 0, "func": "static int str_read_packet(AVFormatContext *s,\n\n                           AVPacket *ret_pkt)\n\n{\n\n    ByteIOContext *pb = s->pb;\n\n    StrDemuxContext *str = s->priv_data;\n\n    unsigned char sector[RAW_CD_SECTOR_SIZE];\n\n    int channel;\n\n    AVPacket *pkt;\n\n    AVStream *st;\n\n\n\n    while (1) {\n\n\n\n        if (get_buffer(pb, sector, RAW_CD_SECTOR_SIZE) != RAW_CD_SECTOR_SIZE)\n\n            return AVERROR(EIO);\n\n\n\n        channel = sector[0x11];\n\n        if (channel >= 32)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        switch (sector[0x12] & CDXA_TYPE_MASK) {\n\n\n\n        case CDXA_TYPE_DATA:\n\n        case CDXA_TYPE_VIDEO:\n\n            {\n\n\n\n                int current_sector = AV_RL16(&sector[0x1C]);\n\n                int sector_count   = AV_RL16(&sector[0x1E]);\n\n                int frame_size = AV_RL32(&sector[0x24]);\n\n\n\n                if(!(   frame_size>=0\n\n                     && current_sector < sector_count\n\n                     && sector_count*VIDEO_DATA_CHUNK_SIZE >=frame_size)){\n\n                    av_log(s, AV_LOG_ERROR, \"Invalid parameters %d %d %d\\n\", current_sector, sector_count, frame_size);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                if(str->channels[channel].video_stream_index < 0){\n\n                    /* allocate a new AVStream */\n\n                    st = av_new_stream(s, 0);\n\n                    if (!st)\n\n                        return AVERROR(ENOMEM);\n\n                    av_set_pts_info(st, 64, 1, 15);\n\n\n\n                    str->channels[channel].video_stream_index = st->index;\n\n\n\n                    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n                    st->codec->codec_id   = CODEC_ID_MDEC;\n\n                    st->codec->codec_tag  = 0;  /* no fourcc */\n\n                    st->codec->width      = AV_RL16(&sector[0x28]);\n\n                    st->codec->height     = AV_RL16(&sector[0x2A]);\n\n                }\n\n\n\n                /* if this is the first sector of the frame, allocate a pkt */\n\n                pkt = &str->channels[channel].tmp_pkt;\n\n\n\n                if(pkt->size != sector_count*VIDEO_DATA_CHUNK_SIZE){\n\n                    if(pkt->data)\n\n                        av_log(s, AV_LOG_ERROR, \"missmatching sector_count\\n\");\n\n                    av_free_packet(pkt);\n\n                    if (av_new_packet(pkt, sector_count*VIDEO_DATA_CHUNK_SIZE))\n\n                        return AVERROR(EIO);\n\n\n\n                    pkt->pos= url_ftell(pb) - RAW_CD_SECTOR_SIZE;\n\n                    pkt->stream_index =\n\n                        str->channels[channel].video_stream_index;\n\n                }\n\n\n\n                memcpy(pkt->data + current_sector*VIDEO_DATA_CHUNK_SIZE,\n\n                       sector + VIDEO_DATA_HEADER_SIZE,\n\n                       VIDEO_DATA_CHUNK_SIZE);\n\n\n\n                if (current_sector == sector_count-1) {\n\n                    pkt->size= frame_size;\n\n                    *ret_pkt = *pkt;\n\n                    pkt->data= NULL;\n\n                    pkt->size= -1;\n\n                    return 0;\n\n                }\n\n\n\n            }\n\n            break;\n\n\n\n        case CDXA_TYPE_AUDIO:\n\n            if(str->channels[channel].audio_stream_index < 0){\n\n                int fmt = sector[0x13];\n\n                /* allocate a new AVStream */\n\n                st = av_new_stream(s, 0);\n\n                if (!st)\n\n                    return AVERROR(ENOMEM);\n\n\n\n                str->channels[channel].audio_stream_index = st->index;\n\n\n\n                st->codec->codec_type  = CODEC_TYPE_AUDIO;\n\n                st->codec->codec_id    = CODEC_ID_ADPCM_XA;\n\n                st->codec->codec_tag   = 0;  /* no fourcc */\n\n                st->codec->channels    = (fmt&1)?2:1;\n\n                st->codec->sample_rate = (fmt&4)?18900:37800;\n\n            //    st->codec->bit_rate = 0; //FIXME;\n\n                st->codec->block_align = 128;\n\n\n\n                av_set_pts_info(st, 64, 128, st->codec->sample_rate);\n\n            }\n\n                pkt = ret_pkt;\n\n                if (av_new_packet(pkt, 2304))\n\n                    return AVERROR(EIO);\n\n                memcpy(pkt->data,sector+24,2304);\n\n\n\n                pkt->stream_index =\n\n                    str->channels[channel].audio_stream_index;\n\n                return 0;\n\n            break;\n\n        default:\n\n            /* drop the sector and move on */\n\n            break;\n\n        }\n\n\n\n        if (url_feof(pb))\n\n            return AVERROR(EIO);\n\n    }\n\n}\n", "idx": 24575, "_split": "valid", "_hash": "3f5e14d45372e2c571787a8897bb42ff"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb32tobgr24)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n    uint8_t *dest = dst;\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n#if COMPILE_TEMPLATE_MMX\n\n    const uint8_t *mm_end;\n\n#endif\n\n    end = s + src_size;\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s):\"memory\");\n\n    mm_end = end - 31;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movq          %1, %%mm0    \\n\\t\"\n\n            \"movq         8%1, %%mm1    \\n\\t\"\n\n            \"movq        16%1, %%mm4    \\n\\t\"\n\n            \"movq        24%1, %%mm5    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm1, %%mm3    \\n\\t\"\n\n            \"movq       %%mm4, %%mm6    \\n\\t\"\n\n            \"movq       %%mm5, %%mm7    \\n\\t\"\n\n            STORE_BGR24_MMX\n\n            :\"=m\"(*dest)\n\n            :\"m\"(*s)\n\n            :\"memory\");\n\n        dest += 24;\n\n        s += 32;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n#endif\n\n    while (s < end) {\n\n#if HAVE_BIGENDIAN\n\n        /* RGB32 (= A,B,G,R) -> RGB24 (= R,G,B) */\n\n        s++;\n\n        dest[2] = *s++;\n\n        dest[1] = *s++;\n\n        dest[0] = *s++;\n\n        dest += 3;\n\n#else\n\n        *dest++ = *s++;\n\n        *dest++ = *s++;\n\n        *dest++ = *s++;\n\n        s++;\n\n#endif\n\n    }\n\n}\n", "idx": 24587, "_split": "valid", "_hash": "ca0210da06df40dbbcdb0367ddbe1545"}
{"project": "FFmpeg", "commit_id": "ca203e9985cd2dcf42a0c0853940850d3a8edf3a", "target": 1, "func": "static void search_for_ms_mips(AACEncContext *s, ChannelElement *cpe)\n\n{\n\n    int start = 0, i, w, w2, g;\n\n    float M[128], S[128];\n\n    float *L34 = s->scoefs, *R34 = s->scoefs + 128, *M34 = s->scoefs + 128*2, *S34 = s->scoefs + 128*3;\n\n    const float lambda = s->lambda;\n\n    SingleChannelElement *sce0 = &cpe->ch[0];\n\n    SingleChannelElement *sce1 = &cpe->ch[1];\n\n    if (!cpe->common_window)\n\n        return;\n\n    for (w = 0; w < sce0->ics.num_windows; w += sce0->ics.group_len[w]) {\n\n        start = 0;\n\n        for (g = 0;  g < sce0->ics.num_swb; g++) {\n\n            if (!cpe->ch[0].zeroes[w*16+g] && !cpe->ch[1].zeroes[w*16+g]) {\n\n                float dist1 = 0.0f, dist2 = 0.0f;\n\n                for (w2 = 0; w2 < sce0->ics.group_len[w]; w2++) {\n\n                    FFPsyBand *band0 = &s->psy.ch[s->cur_channel+0].psy_bands[(w+w2)*16+g];\n\n                    FFPsyBand *band1 = &s->psy.ch[s->cur_channel+1].psy_bands[(w+w2)*16+g];\n\n                    float minthr = FFMIN(band0->threshold, band1->threshold);\n\n                    float maxthr = FFMAX(band0->threshold, band1->threshold);\n\n                    for (i = 0; i < sce0->ics.swb_sizes[g]; i+=4) {\n\n                        M[i  ] = (sce0->coeffs[start+w2*128+i  ]\n\n                                + sce1->coeffs[start+w2*128+i  ]) * 0.5;\n\n                        M[i+1] = (sce0->coeffs[start+w2*128+i+1]\n\n                                + sce1->coeffs[start+w2*128+i+1]) * 0.5;\n\n                        M[i+2] = (sce0->coeffs[start+w2*128+i+2]\n\n                                + sce1->coeffs[start+w2*128+i+2]) * 0.5;\n\n                        M[i+3] = (sce0->coeffs[start+w2*128+i+3]\n\n                                + sce1->coeffs[start+w2*128+i+3]) * 0.5;\n\n\n\n                        S[i  ] =  M[i  ]\n\n                                - sce1->coeffs[start+w2*128+i  ];\n\n                        S[i+1] =  M[i+1]\n\n                                - sce1->coeffs[start+w2*128+i+1];\n\n                        S[i+2] =  M[i+2]\n\n                                - sce1->coeffs[start+w2*128+i+2];\n\n                        S[i+3] =  M[i+3]\n\n                                - sce1->coeffs[start+w2*128+i+3];\n\n                   }\n\n                    abs_pow34_v(L34, sce0->coeffs+start+(w+w2)*128, sce0->ics.swb_sizes[g]);\n\n                    abs_pow34_v(R34, sce1->coeffs+start+(w+w2)*128, sce0->ics.swb_sizes[g]);\n\n                    abs_pow34_v(M34, M,                         sce0->ics.swb_sizes[g]);\n\n                    abs_pow34_v(S34, S,                         sce0->ics.swb_sizes[g]);\n\n                    dist1 += quantize_band_cost(s, &sce0->coeffs[start + (w+w2)*128],\n\n                                                L34,\n\n                                                sce0->ics.swb_sizes[g],\n\n                                                sce0->sf_idx[(w+w2)*16+g],\n\n                                                sce0->band_type[(w+w2)*16+g],\n\n                                                lambda / band0->threshold, INFINITY, NULL, NULL, 0);\n\n                    dist1 += quantize_band_cost(s, &sce1->coeffs[start + (w+w2)*128],\n\n                                                R34,\n\n                                                sce1->ics.swb_sizes[g],\n\n                                                sce1->sf_idx[(w+w2)*16+g],\n\n                                                sce1->band_type[(w+w2)*16+g],\n\n                                                lambda / band1->threshold, INFINITY, NULL, NULL, 0);\n\n                    dist2 += quantize_band_cost(s, M,\n\n                                                M34,\n\n                                                sce0->ics.swb_sizes[g],\n\n                                                sce0->sf_idx[(w+w2)*16+g],\n\n                                                sce0->band_type[(w+w2)*16+g],\n\n                                                lambda / maxthr, INFINITY, NULL, NULL, 0);\n\n                    dist2 += quantize_band_cost(s, S,\n\n                                                S34,\n\n                                                sce1->ics.swb_sizes[g],\n\n                                                sce1->sf_idx[(w+w2)*16+g],\n\n                                                sce1->band_type[(w+w2)*16+g],\n\n                                                lambda / minthr, INFINITY, NULL, NULL, 0);\n\n                }\n\n                cpe->ms_mask[w*16+g] = dist2 < dist1;\n\n            }\n\n            start += sce0->ics.swb_sizes[g];\n\n        }\n\n    }\n\n}\n", "idx": 24612, "_split": "valid", "_hash": "3662bb6f7ab1a237861b962fd4b3871e"}
{"project": "FFmpeg", "commit_id": "6a69a175e7b5c5393528ed0f5753e41573fa0df2", "target": 1, "func": "static void clear_context(MpegEncContext *s)\n\n{\n\n    int i, j, k;\n\n\n\n    memset(&s->next_picture, 0, sizeof(s->next_picture));\n\n    memset(&s->last_picture, 0, sizeof(s->last_picture));\n\n    memset(&s->current_picture, 0, sizeof(s->current_picture));\n\n    memset(&s->new_picture, 0, sizeof(s->new_picture));\n\n\n\n    memset(s->thread_context, 0, sizeof(s->thread_context));\n\n\n\n    s->me.map = NULL;\n\n    s->me.score_map = NULL;\n\n    s->dct_error_sum = NULL;\n\n    s->block = NULL;\n\n    s->blocks = NULL;\n\n    memset(s->pblocks, 0, sizeof(s->pblocks));\n\n    s->ac_val_base = NULL;\n\n    s->ac_val[0] =\n\n    s->ac_val[1] =\n\n    s->ac_val[2] =NULL;\n\n    s->sc.edge_emu_buffer = NULL;\n\n    s->me.scratchpad = NULL;\n\n    s->me.temp =\n\n    s->sc.rd_scratchpad =\n\n    s->sc.b_scratchpad =\n\n    s->sc.obmc_scratchpad = NULL;\n\n\n\n    s->parse_context.buffer = NULL;\n\n    s->parse_context.buffer_size = 0;\n\n\n    s->bitstream_buffer = NULL;\n\n    s->allocated_bitstream_buffer_size = 0;\n\n    s->picture          = NULL;\n\n    s->mb_type          = NULL;\n\n    s->p_mv_table_base  = NULL;\n\n    s->b_forw_mv_table_base = NULL;\n\n    s->b_back_mv_table_base = NULL;\n\n    s->b_bidir_forw_mv_table_base = NULL;\n\n    s->b_bidir_back_mv_table_base = NULL;\n\n    s->b_direct_mv_table_base = NULL;\n\n    s->p_mv_table            = NULL;\n\n    s->b_forw_mv_table       = NULL;\n\n    s->b_back_mv_table       = NULL;\n\n    s->b_bidir_forw_mv_table = NULL;\n\n    s->b_bidir_back_mv_table = NULL;\n\n    s->b_direct_mv_table     = NULL;\n\n    for (i = 0; i < 2; i++) {\n\n        for (j = 0; j < 2; j++) {\n\n            for (k = 0; k < 2; k++) {\n\n                s->b_field_mv_table_base[i][j][k] = NULL;\n\n                s->b_field_mv_table[i][j][k] = NULL;\n\n            }\n\n            s->b_field_select_table[i][j] = NULL;\n\n            s->p_field_mv_table_base[i][j] = NULL;\n\n            s->p_field_mv_table[i][j] = NULL;\n\n        }\n\n        s->p_field_select_table[i] = NULL;\n\n    }\n\n\n\n    s->dc_val_base = NULL;\n\n    s->coded_block_base = NULL;\n\n    s->mbintra_table = NULL;\n\n    s->cbp_table = NULL;\n\n    s->pred_dir_table = NULL;\n\n\n\n    s->mbskip_table = NULL;\n\n\n\n    s->er.error_status_table = NULL;\n\n    s->er.er_temp_buffer = NULL;\n\n    s->mb_index2xy = NULL;\n\n    s->lambda_table = NULL;\n\n\n\n    s->cplx_tab = NULL;\n\n    s->bits_tab = NULL;\n\n}", "idx": 24651, "_split": "valid", "_hash": "b14b960e32718b2b41a999c9e472dd7f"}
{"project": "FFmpeg", "commit_id": "d05bdba2428dd0c1c5cd3426d69c712b127f996c", "target": 1, "func": "static int rac_get_model256_sym(RangeCoder *c, Model256 *m)\n\n{\n\n    int prob, prob2, helper, val;\n\n    int start, end;\n\n    int ssym;\n\n\n\n    prob2      = c->range;\n\n    c->range >>= MODEL_SCALE;\n\n\n\n    helper     = c->low / c->range;\n\n    ssym       = helper >> MODEL256_SEC_SCALE;\n\n    val        = m->secondary[ssym];\n\n\n\n    end = start = m->secondary[ssym + 1] + 1;\n\n    while (end > val + 1) {\n\n        ssym = (end + val) >> 1;\n\n        if (m->freqs[ssym] <= helper) {\n\n            end = start;\n\n            val = ssym;\n\n        } else {\n\n            end   = (end + val) >> 1;\n\n            start = ssym;\n\n        }\n\n    }\n\n    prob = m->freqs[val] * c->range;\n\n    if (val != 255)\n\n        prob2 = m->freqs[val + 1] * c->range;\n\n\n\n    c->low  -= prob;\n\n    c->range = prob2 - prob;\n\n    if (c->range < RAC_BOTTOM)\n\n        rac_normalise(c);\n\n\n\n    model256_update(m, val);\n\n\n\n    return val;\n\n}\n", "idx": 24654, "_split": "valid", "_hash": "f43688d72d1528a54ade99d2e8f19ed7"}
{"project": "FFmpeg", "commit_id": "ae43c10e36197000de2f3cc99ea35727ce98a796", "target": 0, "func": "int ff_replaygain_export(AVStream *st, AVDictionary *metadata)\n\n{\n\n    const AVDictionaryEntry *tg, *tp, *ag, *ap;\n\n\n\n    tg = av_dict_get(metadata, \"REPLAYGAIN_TRACK_GAIN\", NULL, 0);\n\n    tp = av_dict_get(metadata, \"REPLAYGAIN_TRACK_PEAK\", NULL, 0);\n\n    ag = av_dict_get(metadata, \"REPLAYGAIN_ALBUM_GAIN\", NULL, 0);\n\n    ap = av_dict_get(metadata, \"REPLAYGAIN_ALBUM_PEAK\", NULL, 0);\n\n\n\n    return replaygain_export(st,\n\n                             tg ? tg->value : NULL,\n\n                             tp ? tp->value : NULL,\n\n                             ag ? ag->value : NULL,\n\n                             ap ? ap->value : NULL);\n\n}\n", "idx": 24659, "_split": "valid", "_hash": "4dcb094e458a9fb1d5318fc81e98d9e0"}
{"project": "FFmpeg", "commit_id": "34a8dcd031d637273cdea021e5a79cf720c4c51c", "target": 0, "func": "static int decode_end(AVCodecContext * avctx)\n\n{\n\n    KmvcContext *const c = (KmvcContext *) avctx->priv_data;\n\n\n\n    if (c->frm0)\n\n        av_free(c->frm0);\n\n    if (c->frm1)\n\n        av_free(c->frm1);\n\n    if (c->pic.data[0])\n\n        avctx->release_buffer(avctx, &c->pic);\n\n\n\n    return 0;\n\n}\n", "idx": 24673, "_split": "valid", "_hash": "35b782be41af957c7abd18ffb7ae25c3"}
{"project": "FFmpeg", "commit_id": "1d16a1cf99488f16492b1bb48e023f4da8377e07", "target": 0, "func": "static void ff_h264_idct_add16_mmx2(uint8_t *dst, const int *block_offset, DCTELEM *block, int stride, const uint8_t nnzc[6*8]){\n\n    int i;\n\n    for(i=0; i<16; i++){\n\n        int nnz = nnzc[ scan8[i] ];\n\n        if(nnz){\n\n            if(nnz==1 && block[i*16]) ff_h264_idct_dc_add_mmx2(dst + block_offset[i], block + i*16, stride);\n\n            else                      ff_h264_idct_add_mmx    (dst + block_offset[i], block + i*16, stride);\n\n        }\n\n    }\n\n}\n", "idx": 24688, "_split": "valid", "_hash": "20bb0578efb12faf8fca1160ccb566d2"}
{"project": "FFmpeg", "commit_id": "99982524f93a5fc5f8eadd3e8f9b4e3af446cdaa", "target": 0, "func": "static void check_cpu_flag(const char *name, int flag)\n\n{\n\n    int old_cpu_flag = state.cpu_flag;\n\n\n\n    flag |= old_cpu_flag;\n\n    av_set_cpu_flags_mask(flag);\n\n    state.cpu_flag = av_get_cpu_flags();\n\n\n\n    if (!flag || state.cpu_flag != old_cpu_flag) {\n\n        int i;\n\n\n\n        state.cpu_flag_name = name;\n\n        for (i = 0; tests[i].func; i++) {\n\n            state.current_test_name = tests[i].name;\n\n            tests[i].func();\n\n        }\n\n    }\n\n}\n", "idx": 24699, "_split": "valid", "_hash": "e9dbfade7556a3aa46ce0b5e11f2eb47"}
{"project": "FFmpeg", "commit_id": "4c0080b7e7d501e2720d2a61f5186a18377f9d63", "target": 0, "func": "static int decode_packet(AVCodecContext *avctx, void *data,\n\n                         int *got_frame_ptr, AVPacket* avpkt)\n\n{\n\n    WMAProDecodeCtx *s = avctx->priv_data;\n\n    GetBitContext* gb  = &s->pgb;\n\n    const uint8_t* buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    int num_bits_prev_frame;\n\n    int packet_sequence_number;\n\n\n\n    *got_frame_ptr = 0;\n\n\n\n    if (s->packet_done || s->packet_loss) {\n\n        s->packet_done = 0;\n\n\n\n        /** sanity check for the buffer length */\n\n        if (buf_size < avctx->block_align)\n\n            return 0;\n\n\n\n        s->next_packet_start = buf_size - avctx->block_align;\n\n        buf_size = avctx->block_align;\n\n        s->buf_bit_size = buf_size << 3;\n\n\n\n        /** parse packet header */\n\n        init_get_bits(gb, buf, s->buf_bit_size);\n\n        packet_sequence_number = get_bits(gb, 4);\n\n        skip_bits(gb, 2);\n\n\n\n        /** get number of bits that need to be added to the previous frame */\n\n        num_bits_prev_frame = get_bits(gb, s->log2_frame_size);\n\n        av_dlog(avctx, \"packet[%d]: nbpf %x\\n\", avctx->frame_number,\n\n                num_bits_prev_frame);\n\n\n\n        /** check for packet loss */\n\n        if (!s->packet_loss &&\n\n            ((s->packet_sequence_number + 1) & 0xF) != packet_sequence_number) {\n\n            s->packet_loss = 1;\n\n            av_log(avctx, AV_LOG_ERROR, \"Packet loss detected! seq %x vs %x\\n\",\n\n                   s->packet_sequence_number, packet_sequence_number);\n\n        }\n\n        s->packet_sequence_number = packet_sequence_number;\n\n\n\n        if (num_bits_prev_frame > 0) {\n\n            int remaining_packet_bits = s->buf_bit_size - get_bits_count(gb);\n\n            if (num_bits_prev_frame >= remaining_packet_bits) {\n\n                num_bits_prev_frame = remaining_packet_bits;\n\n                s->packet_done = 1;\n\n            }\n\n\n\n            /** append the previous frame data to the remaining data from the\n\n                previous packet to create a full frame */\n\n            save_bits(s, gb, num_bits_prev_frame, 1);\n\n            av_dlog(avctx, \"accumulated %x bits of frame data\\n\",\n\n                    s->num_saved_bits - s->frame_offset);\n\n\n\n            /** decode the cross packet frame if it is valid */\n\n            if (!s->packet_loss)\n\n                decode_frame(s, data, got_frame_ptr);\n\n        } else if (s->num_saved_bits - s->frame_offset) {\n\n            av_dlog(avctx, \"ignoring %x previously saved bits\\n\",\n\n                    s->num_saved_bits - s->frame_offset);\n\n        }\n\n\n\n        if (s->packet_loss) {\n\n            /** reset number of saved bits so that the decoder\n\n                does not start to decode incomplete frames in the\n\n                s->len_prefix == 0 case */\n\n            s->num_saved_bits = 0;\n\n            s->packet_loss = 0;\n\n        }\n\n\n\n    } else {\n\n        int frame_size;\n\n        s->buf_bit_size = (avpkt->size - s->next_packet_start) << 3;\n\n        init_get_bits(gb, avpkt->data, s->buf_bit_size);\n\n        skip_bits(gb, s->packet_offset);\n\n        if (s->len_prefix && remaining_bits(s, gb) > s->log2_frame_size &&\n\n            (frame_size = show_bits(gb, s->log2_frame_size)) &&\n\n            frame_size <= remaining_bits(s, gb)) {\n\n            save_bits(s, gb, frame_size, 0);\n\n            s->packet_done = !decode_frame(s, data, got_frame_ptr);\n\n        } else if (!s->len_prefix\n\n                   && s->num_saved_bits > get_bits_count(&s->gb)) {\n\n            /** when the frames do not have a length prefix, we don't know\n\n                the compressed length of the individual frames\n\n                however, we know what part of a new packet belongs to the\n\n                previous frame\n\n                therefore we save the incoming packet first, then we append\n\n                the \"previous frame\" data from the next packet so that\n\n                we get a buffer that only contains full frames */\n\n            s->packet_done = !decode_frame(s, data, got_frame_ptr);\n\n        } else\n\n            s->packet_done = 1;\n\n    }\n\n\n\n    if (s->packet_done && !s->packet_loss &&\n\n        remaining_bits(s, gb) > 0) {\n\n        /** save the rest of the data so that it can be decoded\n\n            with the next packet */\n\n        save_bits(s, gb, remaining_bits(s, gb), 0);\n\n    }\n\n\n\n    s->packet_offset = get_bits_count(gb) & 7;\n\n    if (s->packet_loss)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    return get_bits_count(gb) >> 3;\n\n}\n", "idx": 24757, "_split": "valid", "_hash": "e0c66dff5808b9e56c275d576af1438b"}
{"project": "FFmpeg", "commit_id": "d2c5f0a4bf23758abd49ec2d0e1f7c3d17eea466", "target": 0, "func": "static int avi_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    int n, d[8], size;\n\n    offset_t i;\n\n    void* dstr;\n\n\n\n    memset(d, -1, sizeof(int)*8);\n\n   \n\n    if (avi->dv_demux) {\n\n        size = dv_get_packet(avi->dv_demux, pkt);\n\n\tif (size >= 0)\n\n\t    return size;\n\n    }\n\n        \n\n    for(i=url_ftell(pb); !url_feof(pb); i++) {\n\n        int j;\n\n\n\n\tif (i >= avi->movi_end) {\n\n\t    if (avi->is_odml) {\n\n\t\turl_fskip(pb, avi->riff_end - i);\n\n\t        avi->riff_end = avi->movi_end = url_filesize(url_fileno(pb));\n\n\t    } else\n\n\t        break;\n\n\t}\n\n\n\n        for(j=0; j<7; j++)\n\n            d[j]= d[j+1];\n\n        d[7]= get_byte(pb);\n\n        \n\n        size= d[4] + (d[5]<<8) + (d[6]<<16) + (d[7]<<24);\n\n        \n\n        //parse ix##\n\n        n= (d[2] - '0') * 10 + (d[3] - '0');\n\n        if(    d[2] >= '0' && d[2] <= '9'\n\n            && d[3] >= '0' && d[3] <= '9'\n\n            && d[0] == 'i' && d[1] == 'x'\n\n            && n < s->nb_streams\n\n            && i + size <= avi->movi_end){\n\n            \n\n            url_fskip(pb, size);\n\n        }\n\n\n\n\t//parse JUNK\n\n        if(d[0] == 'J' && d[1] == 'U' && d[2] == 'N' && d[3] == 'K' &&\n\n           i + size <= avi->movi_end) {\n\n            \n\n            url_fskip(pb, size);\n\n        }\n\n        \n\n        //parse ##dc/##wb\n\n        n= (d[0] - '0') * 10 + (d[1] - '0');\n\n        if(    d[0] >= '0' && d[0] <= '9'\n\n            && d[1] >= '0' && d[1] <= '9'\n\n            && ((d[2] == 'd' && d[3] == 'c') || \n\n\t        (d[2] == 'w' && d[3] == 'b') || \n\n\t\t(d[2] == 'd' && d[3] == 'b') ||\n\n\t\t(d[2] == '_' && d[3] == '_'))\n\n            && n < s->nb_streams\n\n            && i + size <= avi->movi_end) {\n\n        \n\n            av_new_packet(pkt, size);\n\n            get_buffer(pb, pkt->data, size);\n\n            if (size & 1) {\n\n                get_byte(pb);\n\n\t\tsize++;\n\n\t    }\n\n\t\n\n\t    if (avi->dv_demux) {\n\n\t        dstr = pkt->destruct;\n\n\t        size = dv_produce_packet(avi->dv_demux, pkt,\n\n\t\t                         pkt->data, pkt->size);\n\n\t\tpkt->destruct = dstr;\n\n                pkt->flags |= PKT_FLAG_KEY;\n\n\t    } else {\n\n                AVStream *st;\n\n                AVIStream *ast;\n\n                st = s->streams[n];\n\n                ast = st->priv_data;\n\n                \n\n                /* XXX: how to handle B frames in avi ? */\n\n                pkt->dts = ast->frame_offset;\n\n//                pkt->dts += ast->start;\n\n                if(ast->sample_size)\n\n                    pkt->dts /= ast->sample_size;\n\n//av_log(NULL, AV_LOG_DEBUG, \"dts:%Ld offset:%d %d/%d smpl_siz:%d base:%d st:%d size:%d\\n\", pkt->dts, ast->frame_offset, ast->scale, ast->rate, ast->sample_size, AV_TIME_BASE, n, size);\n\n                pkt->stream_index = n;\n\n                /* FIXME: We really should read index for that */\n\n                if (st->codec.codec_type == CODEC_TYPE_VIDEO) {\n\n                    if (ast->frame_offset < ast->nb_index_entries) {\n\n                        if (ast->index_entries[ast->frame_offset].flags & AVIIF_INDEX)\n\n                            pkt->flags |= PKT_FLAG_KEY; \n\n                    } else {\n\n                        /* if no index, better to say that all frames\n\n                           are key frames */\n\n                        pkt->flags |= PKT_FLAG_KEY;\n\n                    }\n\n                } else {\n\n                    pkt->flags |= PKT_FLAG_KEY; \n\n                }\n\n                if(ast->sample_size)\n\n                    ast->frame_offset += pkt->size;\n\n                else\n\n                    ast->frame_offset++;\n\n\t    }\n\n            return size;\n\n        }\n\n    }\n\n    return -1;\n\n}\n", "idx": 24790, "_split": "valid", "_hash": "363af8a905a2d0c88750d64bd8efed49"}
{"project": "FFmpeg", "commit_id": "add41decd94b2d3581a3715ba10f27168b8cdb1b", "target": 0, "func": "static int decode_slice(struct AVCodecContext *avctx, void *arg){\n\n    H264Context *h = *(void**)arg;\n\n    MpegEncContext * const s = &h->s;\n\n    const int part_mask= s->partitioned_frame ? (AC_END|AC_ERROR) : 0x7F;\n\n    int lf_x_start = s->mb_x;\n\n\n\n    s->mb_skip_run= -1;\n\n\n\n    h->is_complex = FRAME_MBAFF || s->picture_structure != PICT_FRAME || s->codec_id != CODEC_ID_H264 ||\n\n                    (CONFIG_GRAY && (s->flags&CODEC_FLAG_GRAY));\n\n\n\n    if( h->pps.cabac ) {\n\n        /* realign */\n\n        align_get_bits( &s->gb );\n\n\n\n        /* init cabac */\n\n        ff_init_cabac_states( &h->cabac);\n\n        ff_init_cabac_decoder( &h->cabac,\n\n                               s->gb.buffer + get_bits_count(&s->gb)/8,\n\n                               (get_bits_left(&s->gb) + 7)/8);\n\n\n\n        ff_h264_init_cabac_states(h);\n\n\n\n        for(;;){\n\n//START_TIMER\n\n            int ret = ff_h264_decode_mb_cabac(h);\n\n            int eos;\n\n//STOP_TIMER(\"decode_mb_cabac\")\n\n\n\n            if(ret>=0) ff_h264_hl_decode_mb(h);\n\n\n\n            if( ret >= 0 && FRAME_MBAFF ) { //FIXME optimal? or let mb_decode decode 16x32 ?\n\n                s->mb_y++;\n\n\n\n                ret = ff_h264_decode_mb_cabac(h);\n\n\n\n                if(ret>=0) ff_h264_hl_decode_mb(h);\n\n                s->mb_y--;\n\n            }\n\n            eos = get_cabac_terminate( &h->cabac );\n\n\n\n            if((s->workaround_bugs & FF_BUG_TRUNCATED) && h->cabac.bytestream > h->cabac.bytestream_end + 2){\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n                if (s->mb_x >= lf_x_start) loop_filter(h, lf_x_start, s->mb_x + 1);\n\n                return 0;\n\n            }\n\n            if( ret < 0 || h->cabac.bytestream > h->cabac.bytestream_end + 2) {\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"error while decoding MB %d %d, bytestream (%td)\\n\", s->mb_x, s->mb_y, h->cabac.bytestream_end - h->cabac.bytestream);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n                return -1;\n\n            }\n\n\n\n            if( ++s->mb_x >= s->mb_width ) {\n\n                loop_filter(h, lf_x_start, s->mb_x);\n\n                s->mb_x = lf_x_start = 0;\n\n                decode_finish_row(h);\n\n                ++s->mb_y;\n\n                if(FIELD_OR_MBAFF_PICTURE) {\n\n                    ++s->mb_y;\n\n                    if(FRAME_MBAFF && s->mb_y < s->mb_height)\n\n                        predict_field_decoding_flag(h);\n\n                }\n\n            }\n\n\n\n            if( eos || s->mb_y >= s->mb_height ) {\n\n                tprintf(s->avctx, \"slice end %d %d\\n\", get_bits_count(&s->gb), s->gb.size_in_bits);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n                if (s->mb_x > lf_x_start) loop_filter(h, lf_x_start, s->mb_x);\n\n                return 0;\n\n            }\n\n        }\n\n\n\n    } else {\n\n        for(;;){\n\n            int ret = ff_h264_decode_mb_cavlc(h);\n\n\n\n            if(ret>=0) ff_h264_hl_decode_mb(h);\n\n\n\n            if(ret>=0 && FRAME_MBAFF){ //FIXME optimal? or let mb_decode decode 16x32 ?\n\n                s->mb_y++;\n\n                ret = ff_h264_decode_mb_cavlc(h);\n\n\n\n                if(ret>=0) ff_h264_hl_decode_mb(h);\n\n                s->mb_y--;\n\n            }\n\n\n\n            if(ret<0){\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"error while decoding MB %d %d\\n\", s->mb_x, s->mb_y);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n                return -1;\n\n            }\n\n\n\n            if(++s->mb_x >= s->mb_width){\n\n                loop_filter(h, lf_x_start, s->mb_x);\n\n                s->mb_x = lf_x_start = 0;\n\n                decode_finish_row(h);\n\n                ++s->mb_y;\n\n                if(FIELD_OR_MBAFF_PICTURE) {\n\n                    ++s->mb_y;\n\n                    if(FRAME_MBAFF && s->mb_y < s->mb_height)\n\n                        predict_field_decoding_flag(h);\n\n                }\n\n                if(s->mb_y >= s->mb_height){\n\n                    tprintf(s->avctx, \"slice end %d %d\\n\", get_bits_count(&s->gb), s->gb.size_in_bits);\n\n\n\n                    if(get_bits_count(&s->gb) == s->gb.size_in_bits ) {\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return 0;\n\n                    }else{\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if(get_bits_count(&s->gb) >= s->gb.size_in_bits && s->mb_skip_run<=0){\n\n                tprintf(s->avctx, \"slice end %d %d\\n\", get_bits_count(&s->gb), s->gb.size_in_bits);\n\n                if(get_bits_count(&s->gb) == s->gb.size_in_bits ){\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n                    if (s->mb_x > lf_x_start) loop_filter(h, lf_x_start, s->mb_x);\n\n\n\n                    return 0;\n\n                }else{\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n#if 0\n\n    for(;s->mb_y < s->mb_height; s->mb_y++){\n\n        for(;s->mb_x < s->mb_width; s->mb_x++){\n\n            int ret= decode_mb(h);\n\n\n\n            ff_h264_hl_decode_mb(h);\n\n\n\n            if(ret<0){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"error while decoding MB %d %d\\n\", s->mb_x, s->mb_y);\n\n                ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n\n\n                return -1;\n\n            }\n\n\n\n            if(++s->mb_x >= s->mb_width){\n\n                s->mb_x=0;\n\n                if(++s->mb_y >= s->mb_height){\n\n                    if(get_bits_count(s->gb) == s->gb.size_in_bits){\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return 0;\n\n                    }else{\n\n                        ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if(get_bits_count(s->?gb) >= s->gb?.size_in_bits){\n\n                if(get_bits_count(s->gb) == s->gb.size_in_bits){\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x-1, s->mb_y, (AC_END|DC_END|MV_END)&part_mask);\n\n\n\n                    return 0;\n\n                }else{\n\n                    ff_er_add_slice(s, s->resync_mb_x, s->resync_mb_y, s->mb_x, s->mb_y, (AC_ERROR|DC_ERROR|MV_ERROR)&part_mask);\n\n\n\n                    return -1;\n\n                }\n\n            }\n\n        }\n\n        s->mb_x=0;\n\n        ff_draw_horiz_band(s, 16*s->mb_y, 16);\n\n    }\n\n#endif\n\n    return -1; //not reached\n\n}\n", "idx": 24806, "_split": "valid", "_hash": "9182794c3de1d6ab1ce1b1d066b1f4c7"}
{"project": "FFmpeg", "commit_id": "1d8c4af396b6ed84c84b5ebf0bf1163c4a7a3017", "target": 1, "func": "void updateMMXDitherTables(SwsContext *c, int dstY, int lumBufIndex, int chrBufIndex,\n                           int lastInLumBuf, int lastInChrBuf)\n{\n    const int dstH= c->dstH;\n    const int flags= c->flags;\n    int16_t **lumPixBuf= c->lumPixBuf;\n    int16_t **chrUPixBuf= c->chrUPixBuf;\n    int16_t **alpPixBuf= c->alpPixBuf;\n    const int vLumBufSize= c->vLumBufSize;\n    const int vChrBufSize= c->vChrBufSize;\n    int16_t *vLumFilterPos= c->vLumFilterPos;\n    int16_t *vChrFilterPos= c->vChrFilterPos;\n    int16_t *vLumFilter= c->vLumFilter;\n    int16_t *vChrFilter= c->vChrFilter;\n    int32_t *lumMmxFilter= c->lumMmxFilter;\n    int32_t *chrMmxFilter= c->chrMmxFilter;\n    int32_t av_unused *alpMmxFilter= c->alpMmxFilter;\n    const int vLumFilterSize= c->vLumFilterSize;\n    const int vChrFilterSize= c->vChrFilterSize;\n    const int chrDstY= dstY>>c->chrDstVSubSample;\n    const int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n    const int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n    c->blueDither= ff_dither8[dstY&1];\n    if (c->dstFormat == PIX_FMT_RGB555 || c->dstFormat == PIX_FMT_BGR555)\n        c->greenDither= ff_dither8[dstY&1];\n    else\n        c->greenDither= ff_dither4[dstY&1];\n    c->redDither= ff_dither8[(dstY+1)&1];\n    if (dstY < dstH - 2) {\n        const int16_t **lumSrcPtr= (const int16_t **) lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n        const int16_t **chrUSrcPtr= (const int16_t **) chrUPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n        const int16_t **alpSrcPtr= (CONFIG_SWSCALE_ALPHA && alpPixBuf) ? (const int16_t **) alpPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize : NULL;\n        int i;\n        if (flags & SWS_ACCURATE_RND) {\n            int s= APCK_SIZE / 8;\n            for (i=0; i<vLumFilterSize; i+=2) {\n                *(const void**)&lumMmxFilter[s*i              ]= lumSrcPtr[i  ];\n                *(const void**)&lumMmxFilter[s*i+APCK_PTR2/4  ]= lumSrcPtr[i+(vLumFilterSize>1)];\n                lumMmxFilter[s*i+APCK_COEF/4  ]=\n                lumMmxFilter[s*i+APCK_COEF/4+1]= vLumFilter[dstY*vLumFilterSize + i    ]\n                + (vLumFilterSize>1 ? vLumFilter[dstY*vLumFilterSize + i + 1]<<16 : 0);\n                if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n                    *(const void**)&alpMmxFilter[s*i              ]= alpSrcPtr[i  ];\n                    *(const void**)&alpMmxFilter[s*i+APCK_PTR2/4  ]= alpSrcPtr[i+(vLumFilterSize>1)];\n                    alpMmxFilter[s*i+APCK_COEF/4  ]=\n                    alpMmxFilter[s*i+APCK_COEF/4+1]= lumMmxFilter[s*i+APCK_COEF/4  ];\n            for (i=0; i<vChrFilterSize; i+=2) {\n                *(const void**)&chrMmxFilter[s*i              ]= chrUSrcPtr[i  ];\n                *(const void**)&chrMmxFilter[s*i+APCK_PTR2/4  ]= chrUSrcPtr[i+(vChrFilterSize>1)];\n                chrMmxFilter[s*i+APCK_COEF/4  ]=\n                chrMmxFilter[s*i+APCK_COEF/4+1]= vChrFilter[chrDstY*vChrFilterSize + i    ]\n                + (vChrFilterSize>1 ? vChrFilter[chrDstY*vChrFilterSize + i + 1]<<16 : 0);\n        } else {\n            for (i=0; i<vLumFilterSize; i++) {\n                *(const void**)&lumMmxFilter[4*i+0]= lumSrcPtr[i];\n                lumMmxFilter[4*i+2]=\n                lumMmxFilter[4*i+3]=\n                ((uint16_t)vLumFilter[dstY*vLumFilterSize + i])*0x10001;\n                if (CONFIG_SWSCALE_ALPHA && alpPixBuf) {\n                    *(const void**)&alpMmxFilter[4*i+0]= alpSrcPtr[i];\n                    alpMmxFilter[4*i+2]=\n                    alpMmxFilter[4*i+3]= lumMmxFilter[4*i+2];\n            for (i=0; i<vChrFilterSize; i++) {\n                *(const void**)&chrMmxFilter[4*i+0]= chrUSrcPtr[i];\n                chrMmxFilter[4*i+2]=\n                chrMmxFilter[4*i+3]=\n                ((uint16_t)vChrFilter[chrDstY*vChrFilterSize + i])*0x10001;", "idx": 24815, "_split": "valid", "_hash": "bc912718afc9035285456953e31926ce"}
{"project": "FFmpeg", "commit_id": "853a97530e0aabfd1474b1679e3dc8be978e5ef8", "target": 0, "func": "static void mp3_parse_vbr_tags(AVFormatContext *s, AVStream *st, int64_t base)\n\n{\n\n    uint32_t v, spf;\n\n    int frames = -1; /* Total number of frames in file */\n\n    const int64_t xing_offtbl[2][2] = {{32, 17}, {17,9}};\n\n    MPADecodeContext c;\n\n\n\n    v = get_be32(s->pb);\n\n    if(ff_mpa_check_header(v) < 0)\n\n      return;\n\n\n\n    ff_mpegaudio_decode_header(&c, v);\n\n    if(c.layer != 3)\n\n        return;\n\n\n\n    /* Check for Xing / Info tag */\n\n    url_fseek(s->pb, xing_offtbl[c.lsf == 1][c.nb_channels == 1], SEEK_CUR);\n\n    v = get_be32(s->pb);\n\n    if(v == MKBETAG('X', 'i', 'n', 'g') || v == MKBETAG('I', 'n', 'f', 'o')) {\n\n        v = get_be32(s->pb);\n\n        if(v & 0x1)\n\n            frames = get_be32(s->pb);\n\n    }\n\n\n\n    /* Check for VBRI tag (always 32 bytes after end of mpegaudio header) */\n\n    url_fseek(s->pb, base + 4 + 32, SEEK_SET);\n\n    v = get_be32(s->pb);\n\n    if(v == MKBETAG('V', 'B', 'R', 'I')) {\n\n        /* Check tag version */\n\n        if(get_be16(s->pb) == 1) {\n\n            /* skip delay, quality and total bytes */\n\n            url_fseek(s->pb, 8, SEEK_CUR);\n\n            frames = get_be32(s->pb);\n\n        }\n\n    }\n\n\n\n    if(frames < 0)\n\n        return;\n\n\n\n    spf = c.lsf ? 576 : 1152; /* Samples per frame, layer 3 */\n\n    st->duration = av_rescale_q(frames, (AVRational){spf, c.sample_rate},\n\n                                st->time_base);\n\n}\n", "idx": 24827, "_split": "valid", "_hash": "57aed9107be50420b895f0259575cb95"}
{"project": "FFmpeg", "commit_id": "9d8533368f55e1f6a0ea30d6492b26399b030066", "target": 0, "func": "static void mdct512(int32_t *out, int16_t *in)\n\n{\n\n    int i, re, im, re1, im1;\n\n    int16_t rot[MDCT_SAMPLES];\n\n    IComplex x[MDCT_SAMPLES/4];\n\n\n\n    /* shift to simplify computations */\n\n    for (i = 0; i < MDCT_SAMPLES/4; i++)\n\n        rot[i] = -in[i + 3*MDCT_SAMPLES/4];\n\n    for (;i < MDCT_SAMPLES; i++)\n\n        rot[i] =  in[i -   MDCT_SAMPLES/4];\n\n\n\n    /* pre rotation */\n\n    for (i = 0; i < MDCT_SAMPLES/4; i++) {\n\n        re =  ((int)rot[               2*i] - (int)rot[MDCT_SAMPLES  -1-2*i]) >> 1;\n\n        im = -((int)rot[MDCT_SAMPLES/2+2*i] - (int)rot[MDCT_SAMPLES/2-1-2*i]) >> 1;\n\n        CMUL(x[i].re, x[i].im, re, im, -xcos1[i], xsin1[i]);\n\n    }\n\n\n\n    fft(x, MDCT_NBITS - 2);\n\n\n\n    /* post rotation */\n\n    for (i = 0; i < MDCT_SAMPLES/4; i++) {\n\n        re = x[i].re;\n\n        im = x[i].im;\n\n        CMUL(re1, im1, re, im, xsin1[i], xcos1[i]);\n\n        out[                 2*i] = im1;\n\n        out[MDCT_SAMPLES/2-1-2*i] = re1;\n\n    }\n\n}\n", "idx": 24859, "_split": "valid", "_hash": "75d73537af3f5a0f96f472eb2238ffb6"}
{"project": "FFmpeg", "commit_id": "b348c852aa8312d361123df0fa20e16feff7c2f1", "target": 1, "func": "static int flic_decode_frame_15_16BPP(AVCodecContext *avctx,\n\n                                      void *data, int *data_size,\n\n                                      const uint8_t *buf, int buf_size)\n\n{\n\n    /* Note, the only difference between the 15Bpp and 16Bpp */\n\n    /* Format is the pixel format, the packets are processed the same. */\n\n    FlicDecodeContext *s = avctx->priv_data;\n\n\n\n    int stream_ptr = 0;\n\n    int pixel_ptr;\n\n    unsigned char palette_idx1;\n\n\n\n    unsigned int frame_size;\n\n    int num_chunks;\n\n\n\n    unsigned int chunk_size;\n\n    int chunk_type;\n\n\n\n    int i, j;\n\n\n\n    int lines;\n\n    int compressed_lines;\n\n    signed short line_packets;\n\n    int y_ptr;\n\n    int byte_run;\n\n    int pixel_skip;\n\n    int pixel_countdown;\n\n    unsigned char *pixels;\n\n    int pixel;\n\n    unsigned int pixel_limit;\n\n\n\n    s->frame.reference = 1;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pixels = s->frame.data[0];\n\n    pixel_limit = s->avctx->height * s->frame.linesize[0];\n\n\n\n    frame_size = AV_RL32(&buf[stream_ptr]);\n\n    stream_ptr += 6;  /* skip the magic number */\n\n    num_chunks = AV_RL16(&buf[stream_ptr]);\n\n    stream_ptr += 10;  /* skip padding */\n\n\n\n    frame_size -= 16;\n\n\n\n    /* iterate through the chunks */\n\n    while ((frame_size > 0) && (num_chunks > 0)) {\n\n        chunk_size = AV_RL32(&buf[stream_ptr]);\n\n        stream_ptr += 4;\n\n        chunk_type = AV_RL16(&buf[stream_ptr]);\n\n        stream_ptr += 2;\n\n\n\n        switch (chunk_type) {\n\n        case FLI_256_COLOR:\n\n        case FLI_COLOR:\n\n            /* For some reason, it seems that non-palettized flics do\n\n             * include one of these chunks in their first frame.\n\n             * Why I do not know, it seems rather extraneous. */\n\n/*            av_log(avctx, AV_LOG_ERROR, \"Unexpected Palette chunk %d in non-paletised FLC\\n\",chunk_type);*/\n\n            stream_ptr = stream_ptr + chunk_size - 6;\n\n            break;\n\n\n\n        case FLI_DELTA:\n\n        case FLI_DTA_LC:\n\n            y_ptr = 0;\n\n            compressed_lines = AV_RL16(&buf[stream_ptr]);\n\n            stream_ptr += 2;\n\n            while (compressed_lines > 0) {\n\n                line_packets = AV_RL16(&buf[stream_ptr]);\n\n                stream_ptr += 2;\n\n                if (line_packets < 0) {\n\n                    line_packets = -line_packets;\n\n                    y_ptr += line_packets * s->frame.linesize[0];\n\n                } else {\n\n                    compressed_lines--;\n\n                    pixel_ptr = y_ptr;\n\n                    CHECK_PIXEL_PTR(0);\n\n                    pixel_countdown = s->avctx->width;\n\n                    for (i = 0; i < line_packets; i++) {\n\n                        /* account for the skip bytes */\n\n                        pixel_skip = buf[stream_ptr++];\n\n                        pixel_ptr += (pixel_skip*2); /* Pixel is 2 bytes wide */\n\n                        pixel_countdown -= pixel_skip;\n\n                        byte_run = (signed char)(buf[stream_ptr++]);\n\n                        if (byte_run < 0) {\n\n                            byte_run = -byte_run;\n\n                            pixel    = AV_RL16(&buf[stream_ptr]);\n\n                            stream_ptr += 2;\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown -= 2) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        } else {\n\n                            CHECK_PIXEL_PTR(2 * byte_run);\n\n                            for (j = 0; j < byte_run; j++, pixel_countdown--) {\n\n                                *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[stream_ptr]);\n\n                                stream_ptr += 2;\n\n                                pixel_ptr += 2;\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    y_ptr += s->frame.linesize[0];\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_LC:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unexpected FLI_LC chunk in non-paletised FLC\\n\");\n\n            stream_ptr = stream_ptr + chunk_size - 6;\n\n            break;\n\n\n\n        case FLI_BLACK:\n\n            /* set the whole frame to 0x0000 which is black in both 15Bpp and 16Bpp modes. */\n\n            memset(pixels, 0x0000,\n\n                   s->frame.linesize[0] * s->avctx->height);\n\n            break;\n\n\n\n        case FLI_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                stream_ptr++;\n\n                pixel_countdown = (s->avctx->width * 2);\n\n\n\n                while (pixel_countdown > 0) {\n\n                    byte_run = (signed char)(buf[stream_ptr++]);\n\n                    if (byte_run > 0) {\n\n                        palette_idx1 = buf[stream_ptr++];\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) (linea%d)\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    } else {  /* copy bytes if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        CHECK_PIXEL_PTR(byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            palette_idx1 = buf[stream_ptr++];\n\n                            pixels[pixel_ptr++] = palette_idx1;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d) at line %d\\n\",\n\n                                       pixel_countdown, lines);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                /* Now FLX is strange, in that it is \"byte\" as opposed to \"pixel\" run length compressed.\n\n                 * This does not give us any good oportunity to perform word endian conversion\n\n                 * during decompression. So if it is required (i.e., this is not a LE target, we do\n\n                 * a second pass over the line here, swapping the bytes.\n\n                 */\n\n#if HAVE_BIGENDIAN\n\n                pixel_ptr = y_ptr;\n\n                pixel_countdown = s->avctx->width;\n\n                while (pixel_countdown > 0) {\n\n                    *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[pixel_ptr]);\n\n                    pixel_ptr += 2;\n\n                }\n\n#endif\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_DTA_BRUN:\n\n            y_ptr = 0;\n\n            for (lines = 0; lines < s->avctx->height; lines++) {\n\n                pixel_ptr = y_ptr;\n\n                /* disregard the line packets; instead, iterate through all\n\n                 * pixels on a row */\n\n                stream_ptr++;\n\n                pixel_countdown = s->avctx->width; /* Width is in pixels, not bytes */\n\n\n\n                while (pixel_countdown > 0) {\n\n                    byte_run = (signed char)(buf[stream_ptr++]);\n\n                    if (byte_run > 0) {\n\n                        pixel    = AV_RL16(&buf[stream_ptr]);\n\n                        stream_ptr += 2;\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = pixel;\n\n                            pixel_ptr += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    } else {  /* copy pixels if byte_run < 0 */\n\n                        byte_run = -byte_run;\n\n                        CHECK_PIXEL_PTR(2 * byte_run);\n\n                        for (j = 0; j < byte_run; j++) {\n\n                            *((signed short*)(&pixels[pixel_ptr])) = AV_RL16(&buf[stream_ptr]);\n\n                            stream_ptr += 2;\n\n                            pixel_ptr  += 2;\n\n                            pixel_countdown--;\n\n                            if (pixel_countdown < 0)\n\n                                av_log(avctx, AV_LOG_ERROR, \"pixel_countdown < 0 (%d)\\n\",\n\n                                       pixel_countdown);\n\n                        }\n\n                    }\n\n                }\n\n\n\n                y_ptr += s->frame.linesize[0];\n\n            }\n\n            break;\n\n\n\n        case FLI_COPY:\n\n        case FLI_DTA_COPY:\n\n            /* copy the chunk (uncompressed frame) */\n\n            if (chunk_size - 6 > (unsigned int)(s->avctx->width * s->avctx->height)*2) {\n\n                av_log(avctx, AV_LOG_ERROR, \"In chunk FLI_COPY : source data (%d bytes) \" \\\n\n                       \"bigger than image, skipping chunk\\n\", chunk_size - 6);\n\n                stream_ptr += chunk_size - 6;\n\n            } else {\n\n\n\n                for (y_ptr = 0; y_ptr < s->frame.linesize[0] * s->avctx->height;\n\n                     y_ptr += s->frame.linesize[0]) {\n\n\n\n                    pixel_countdown = s->avctx->width;\n\n                    pixel_ptr = 0;\n\n                    while (pixel_countdown > 0) {\n\n                      *((signed short*)(&pixels[y_ptr + pixel_ptr])) = AV_RL16(&buf[stream_ptr+pixel_ptr]);\n\n                      pixel_ptr += 2;\n\n                      pixel_countdown--;\n\n                    }\n\n                    stream_ptr += s->avctx->width*2;\n\n                }\n\n            }\n\n            break;\n\n\n\n        case FLI_MINI:\n\n            /* some sort of a thumbnail? disregard this chunk... */\n\n            stream_ptr += chunk_size - 6;\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unrecognized chunk type: %d\\n\", chunk_type);\n\n            break;\n\n        }\n\n\n\n        frame_size -= chunk_size;\n\n        num_chunks--;\n\n    }\n\n\n\n    /* by the end of the chunk, the stream ptr should equal the frame\n\n     * size (minus 1, possibly); if it doesn't, issue a warning */\n\n    if ((stream_ptr != buf_size) && (stream_ptr != buf_size - 1))\n\n        av_log(avctx, AV_LOG_ERROR, \"Processed FLI chunk where chunk size = %d \" \\\n\n               \"and final chunk ptr = %d\\n\", buf_size, stream_ptr);\n\n\n\n\n\n    *data_size=sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 24903, "_split": "valid", "_hash": "c4235f6a35dd5efef01207f7cb4f6e6b"}
{"project": "FFmpeg", "commit_id": "b933c72b5e36967b6be73555e8289cc074fb44a7", "target": 0, "func": "static void write_audio_frame(AVFormatContext *oc, AVStream *st)\n\n{\n\n    AVCodecContext *c;\n\n    AVPacket pkt = { 0 }; // data and size must be 0;\n\n    int got_packet, ret, dst_nb_samples;\n\n\n\n    av_init_packet(&pkt);\n\n    c = st->codec;\n\n\n\n    get_audio_frame((int16_t *)src_samples_data[0], src_nb_samples, c->channels);\n\n\n\n    /* convert samples from native format to destination codec format, using the resampler */\n\n    if (swr_ctx) {\n\n        /* compute destination number of samples */\n\n        dst_nb_samples = av_rescale_rnd(swr_get_delay(swr_ctx, c->sample_rate) + src_nb_samples,\n\n                                        c->sample_rate, c->sample_rate, AV_ROUND_UP);\n\n        if (dst_nb_samples > max_dst_nb_samples) {\n\n            av_free(dst_samples_data[0]);\n\n            ret = av_samples_alloc(dst_samples_data, &dst_samples_linesize, c->channels,\n\n                                   dst_nb_samples, c->sample_fmt, 0);\n\n            if (ret < 0)\n\n                exit(1);\n\n            max_dst_nb_samples = dst_nb_samples;\n\n            dst_samples_size = av_samples_get_buffer_size(NULL, c->channels, dst_nb_samples,\n\n                                                          c->sample_fmt, 0);\n\n        }\n\n\n\n        /* convert to destination format */\n\n        ret = swr_convert(swr_ctx,\n\n                          dst_samples_data, dst_nb_samples,\n\n                          (const uint8_t **)src_samples_data, src_nb_samples);\n\n        if (ret < 0) {\n\n            fprintf(stderr, \"Error while converting\\n\");\n\n            exit(1);\n\n        }\n\n    } else {\n\n        dst_nb_samples = src_nb_samples;\n\n    }\n\n\n\n    audio_frame->nb_samples = dst_nb_samples;\n\n    audio_frame->pts = av_rescale_q(samples_count, (AVRational){1, c->sample_rate}, c->time_base);\n\n    avcodec_fill_audio_frame(audio_frame, c->channels, c->sample_fmt,\n\n                             dst_samples_data[0], dst_samples_size, 0);\n\n    samples_count += dst_nb_samples;\n\n\n\n    ret = avcodec_encode_audio2(c, &pkt, audio_frame, &got_packet);\n\n    if (ret < 0) {\n\n        fprintf(stderr, \"Error encoding audio frame: %s\\n\", av_err2str(ret));\n\n        exit(1);\n\n    }\n\n\n\n    if (!got_packet)\n\n        return;\n\n\n\n    ret = write_frame(oc, &c->time_base, st, &pkt);\n\n    if (ret != 0) {\n\n        fprintf(stderr, \"Error while writing audio frame: %s\\n\",\n\n                av_err2str(ret));\n\n        exit(1);\n\n    }\n\n}\n", "idx": 24939, "_split": "valid", "_hash": "818d62bc21f3ca33918bfb0ae56e2f15"}
{"project": "FFmpeg", "commit_id": "c084a975aa13eb1d0161f36a06051a9b2d4abb83", "target": 1, "func": "AVFrame *avcodec_alloc_frame(void)\n\n{\n\n    AVFrame *frame = av_malloc(sizeof(AVFrame));\n\n\n\n    if (frame == NULL)\n\n        return NULL;\n\n\n\n    avcodec_get_frame_defaults(frame);\n\n\n\n    return frame;\n\n}\n", "idx": 24953, "_split": "valid", "_hash": "63860cd5e113999ba6dd578f2419abab"}
{"project": "FFmpeg", "commit_id": "985688b8e597b616246746a16649653db6dcf023", "target": 1, "func": "static int mov_write_hdlr_tag(ByteIOContext *pb, MOVTrack *track)\n\n{\n\n    const char *descr, *hdlr, *hdlr_type;\n\n    int64_t pos = url_ftell(pb);\n\n\n\n    if (!track) { /* no media --> data handler */\n\n        hdlr = \"dhlr\";\n\n        hdlr_type = \"url \";\n\n        descr = \"DataHandler\";\n\n    } else {\n\n        hdlr = (track->mode == MODE_MOV) ? \"mhlr\" : \"\\0\\0\\0\\0\";\n\n        if (track->enc->codec_type == CODEC_TYPE_VIDEO) {\n\n            hdlr_type = \"vide\";\n\n            descr = \"VideoHandler\";\n\n        } else if (track->enc->codec_type == CODEC_TYPE_AUDIO){\n\n            hdlr_type = \"soun\";\n\n            descr = \"SoundHandler\";\n\n        } else if (track->enc->codec_type == CODEC_TYPE_SUBTITLE){\n\n            if (track->mode == MODE_IPOD) hdlr_type = \"sbtl\";\n\n            else                          hdlr_type = \"text\";\n\n            descr = \"SubtitleHandler\";\n\n        }\n\n    }\n\n\n\n    put_be32(pb, 0); /* size */\n\n    put_tag(pb, \"hdlr\");\n\n    put_be32(pb, 0); /* Version & flags */\n\n    put_buffer(pb, hdlr, 4); /* handler */\n\n    put_tag(pb, hdlr_type); /* handler type */\n\n    put_be32(pb ,0); /* reserved */\n\n    put_be32(pb ,0); /* reserved */\n\n    put_be32(pb ,0); /* reserved */\n\n    put_byte(pb, strlen(descr)); /* string counter */\n\n    put_buffer(pb, descr, strlen(descr)); /* handler description */\n\n    return updateSize(pb, pos);\n\n}\n", "idx": 24966, "_split": "valid", "_hash": "465a7508367d282edb45716cee44159c"}
{"project": "FFmpeg", "commit_id": "47775cb8de880dfd2f82029d109229ae65aae767", "target": 0, "func": "static av_always_inline void decode_cabac_residual_internal( H264Context *h, DCTELEM *block, int cat, int n, const uint8_t *scantable, const uint32_t *qmul, int max_coeff, int is_dc ) {\n\n    static const int significant_coeff_flag_offset[2][6] = {\n\n      { 105+0, 105+15, 105+29, 105+44, 105+47, 402 },\n\n      { 277+0, 277+15, 277+29, 277+44, 277+47, 436 }\n\n    };\n\n    static const int last_coeff_flag_offset[2][6] = {\n\n      { 166+0, 166+15, 166+29, 166+44, 166+47, 417 },\n\n      { 338+0, 338+15, 338+29, 338+44, 338+47, 451 }\n\n    };\n\n    static const int coeff_abs_level_m1_offset[6] = {\n\n        227+0, 227+10, 227+20, 227+30, 227+39, 426\n\n    };\n\n    static const uint8_t significant_coeff_flag_offset_8x8[2][63] = {\n\n      { 0, 1, 2, 3, 4, 5, 5, 4, 4, 3, 3, 4, 4, 4, 5, 5,\n\n        4, 4, 4, 4, 3, 3, 6, 7, 7, 7, 8, 9,10, 9, 8, 7,\n\n        7, 6,11,12,13,11, 6, 7, 8, 9,14,10, 9, 8, 6,11,\n\n       12,13,11, 6, 9,14,10, 9,11,12,13,11,14,10,12 },\n\n      { 0, 1, 1, 2, 2, 3, 3, 4, 5, 6, 7, 7, 7, 8, 4, 5,\n\n        6, 9,10,10, 8,11,12,11, 9, 9,10,10, 8,11,12,11,\n\n        9, 9,10,10, 8,11,12,11, 9, 9,10,10, 8,13,13, 9,\n\n        9,10,10, 8,13,13, 9, 9,10,10,14,14,14,14,14 }\n\n    };\n\n    /* node ctx: 0..3: abslevel1 (with abslevelgt1 == 0).\n\n     * 4..7: abslevelgt1 + 3 (and abslevel1 doesn't matter).\n\n     * map node ctx => cabac ctx for level=1 */\n\n    static const uint8_t coeff_abs_level1_ctx[8] = { 1, 2, 3, 4, 0, 0, 0, 0 };\n\n    /* map node ctx => cabac ctx for level>1 */\n\n    static const uint8_t coeff_abs_levelgt1_ctx[8] = { 5, 5, 5, 5, 6, 7, 8, 9 };\n\n    static const uint8_t coeff_abs_level_transition[2][8] = {\n\n    /* update node ctx after decoding a level=1 */\n\n        { 1, 2, 3, 3, 4, 5, 6, 7 },\n\n    /* update node ctx after decoding a level>1 */\n\n        { 4, 4, 4, 4, 5, 6, 7, 7 }\n\n    };\n\n\n\n    int index[64];\n\n\n\n    int av_unused last;\n\n    int coeff_count = 0;\n\n    int node_ctx = 0;\n\n\n\n    uint8_t *significant_coeff_ctx_base;\n\n    uint8_t *last_coeff_ctx_base;\n\n    uint8_t *abs_level_m1_ctx_base;\n\n\n\n#ifndef ARCH_X86\n\n#define CABAC_ON_STACK\n\n#endif\n\n#ifdef CABAC_ON_STACK\n\n#define CC &cc\n\n    CABACContext cc;\n\n    cc.range     = h->cabac.range;\n\n    cc.low       = h->cabac.low;\n\n    cc.bytestream= h->cabac.bytestream;\n\n#else\n\n#define CC &h->cabac\n\n#endif\n\n\n\n\n\n    /* cat: 0-> DC 16x16  n = 0\n\n     *      1-> AC 16x16  n = luma4x4idx\n\n     *      2-> Luma4x4   n = luma4x4idx\n\n     *      3-> DC Chroma n = iCbCr\n\n     *      4-> AC Chroma n = 4 * iCbCr + chroma4x4idx\n\n     *      5-> Luma8x8   n = 4 * luma8x8idx\n\n     */\n\n\n\n    /* read coded block flag */\n\n    if( is_dc || cat != 5 ) {\n\n        if( get_cabac( CC, &h->cabac_state[85 + get_cabac_cbf_ctx( h, cat, n, is_dc ) ] ) == 0 ) {\n\n            if( !is_dc ) {\n\n                if( cat == 1 || cat == 2 )\n\n                    h->non_zero_count_cache[scan8[n]] = 0;\n\n                else\n\n                    h->non_zero_count_cache[scan8[16+n]] = 0;\n\n            }\n\n\n\n#ifdef CABAC_ON_STACK\n\n            h->cabac.range     = cc.range     ;\n\n            h->cabac.low       = cc.low       ;\n\n            h->cabac.bytestream= cc.bytestream;\n\n#endif\n\n            return;\n\n        }\n\n    }\n\n\n\n    significant_coeff_ctx_base = h->cabac_state\n\n        + significant_coeff_flag_offset[MB_FIELD][cat];\n\n    last_coeff_ctx_base = h->cabac_state\n\n        + last_coeff_flag_offset[MB_FIELD][cat];\n\n    abs_level_m1_ctx_base = h->cabac_state\n\n        + coeff_abs_level_m1_offset[cat];\n\n\n\n    if( !is_dc && cat == 5 ) {\n\n#define DECODE_SIGNIFICANCE( coefs, sig_off, last_off ) \\\n\n        for(last= 0; last < coefs; last++) { \\\n\n            uint8_t *sig_ctx = significant_coeff_ctx_base + sig_off; \\\n\n            if( get_cabac( CC, sig_ctx )) { \\\n\n                uint8_t *last_ctx = last_coeff_ctx_base + last_off; \\\n\n                index[coeff_count++] = last; \\\n\n                if( get_cabac( CC, last_ctx ) ) { \\\n\n                    last= max_coeff; \\\n\n                    break; \\\n\n                } \\\n\n            } \\\n\n        }\\\n\n        if( last == max_coeff -1 ) {\\\n\n            index[coeff_count++] = last;\\\n\n        }\n\n        const uint8_t *sig_off = significant_coeff_flag_offset_8x8[MB_FIELD];\n\n#if defined(ARCH_X86) && defined(HAVE_7REGS) && defined(HAVE_EBX_AVAILABLE) && !defined(BROKEN_RELOCATIONS)\n\n        coeff_count= decode_significance_8x8_x86(CC, significant_coeff_ctx_base, index, sig_off);\n\n    } else {\n\n        coeff_count= decode_significance_x86(CC, max_coeff, significant_coeff_ctx_base, index);\n\n#else\n\n        DECODE_SIGNIFICANCE( 63, sig_off[last], last_coeff_flag_offset_8x8[last] );\n\n    } else {\n\n        DECODE_SIGNIFICANCE( max_coeff - 1, last, last );\n\n#endif\n\n    }\n\n    assert(coeff_count > 0);\n\n\n\n    if( is_dc ) {\n\n        if( cat == 0 )\n\n            h->cbp_table[h->mb_xy] |= 0x100;\n\n        else\n\n            h->cbp_table[h->mb_xy] |= 0x40 << n;\n\n    } else {\n\n        if( cat == 1 || cat == 2 )\n\n            h->non_zero_count_cache[scan8[n]] = coeff_count;\n\n        else if( cat == 4 )\n\n            h->non_zero_count_cache[scan8[16+n]] = coeff_count;\n\n        else {\n\n            assert( cat == 5 );\n\n            fill_rectangle(&h->non_zero_count_cache[scan8[n]], 2, 2, 8, coeff_count, 1);\n\n        }\n\n    }\n\n\n\n    for( coeff_count--; coeff_count >= 0; coeff_count-- ) {\n\n        uint8_t *ctx = coeff_abs_level1_ctx[node_ctx] + abs_level_m1_ctx_base;\n\n\n\n        int j= scantable[index[coeff_count]];\n\n\n\n        if( get_cabac( CC, ctx ) == 0 ) {\n\n            node_ctx = coeff_abs_level_transition[0][node_ctx];\n\n            if( is_dc ) {\n\n                block[j] = get_cabac_bypass_sign( CC, -1);\n\n            }else{\n\n                block[j] = (get_cabac_bypass_sign( CC, -qmul[j]) + 32) >> 6;\n\n            }\n\n        } else {\n\n            int coeff_abs = 2;\n\n            ctx = coeff_abs_levelgt1_ctx[node_ctx] + abs_level_m1_ctx_base;\n\n            node_ctx = coeff_abs_level_transition[1][node_ctx];\n\n\n\n            while( coeff_abs < 15 && get_cabac( CC, ctx ) ) {\n\n                coeff_abs++;\n\n            }\n\n\n\n            if( coeff_abs >= 15 ) {\n\n                int j = 0;\n\n                while( get_cabac_bypass( CC ) ) {\n\n                    j++;\n\n                }\n\n\n\n                coeff_abs=1;\n\n                while( j-- ) {\n\n                    coeff_abs += coeff_abs + get_cabac_bypass( CC );\n\n                }\n\n                coeff_abs+= 14;\n\n            }\n\n\n\n            if( is_dc ) {\n\n                if( get_cabac_bypass( CC ) ) block[j] = -coeff_abs;\n\n                else                                block[j] =  coeff_abs;\n\n            }else{\n\n                if( get_cabac_bypass( CC ) ) block[j] = (-coeff_abs * qmul[j] + 32) >> 6;\n\n                else                                block[j] = ( coeff_abs * qmul[j] + 32) >> 6;\n\n            }\n\n        }\n\n    }\n\n#ifdef CABAC_ON_STACK\n\n            h->cabac.range     = cc.range     ;\n\n            h->cabac.low       = cc.low       ;\n\n            h->cabac.bytestream= cc.bytestream;\n\n#endif\n\n\n\n}\n", "idx": 24976, "_split": "valid", "_hash": "453654dde8d114826a901913ccbf0b3b"}
{"project": "FFmpeg", "commit_id": "26ce266e3df8d50b0e6b3b402f2436903424c30c", "target": 0, "func": "static void mpc8_parse_seektable(AVFormatContext *s, int64_t off)\n\n{\n\n    MPCContext *c = s->priv_data;\n\n    int tag;\n\n    int64_t size, pos, ppos[2];\n\n    uint8_t *buf;\n\n    int i, t, seekd;\n\n    GetBitContext gb;\n\n\n\n    if (s->nb_streams == 0) {\n\n        av_log(s, AV_LOG_ERROR, \"No stream added before parsing seek table\\n\");\n\n        return;\n\n    }\n\n\n\n    avio_seek(s->pb, off, SEEK_SET);\n\n    mpc8_get_chunk_header(s->pb, &tag, &size);\n\n    if(tag != TAG_SEEKTABLE){\n\n        av_log(s, AV_LOG_ERROR, \"No seek table at given position\\n\");\n\n        return;\n\n    }\n\n    if (size > INT_MAX/10 || size<=0) {\n\n        av_log(s, AV_LOG_ERROR, \"Bad seek table size\\n\");\n\n        return;\n\n    }\n\n    if(!(buf = av_malloc(size + FF_INPUT_BUFFER_PADDING_SIZE)))\n\n        return;\n\n    avio_read(s->pb, buf, size);\n\n    memset(buf+size, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n    init_get_bits(&gb, buf, size * 8);\n\n    size = gb_get_v(&gb);\n\n    if(size > UINT_MAX/4 || size > c->samples/1152){\n\n        av_log(s, AV_LOG_ERROR, \"Seek table is too big\\n\");\n\n        return;\n\n    }\n\n    seekd = get_bits(&gb, 4);\n\n    for(i = 0; i < 2; i++){\n\n        pos = gb_get_v(&gb) + c->header_pos;\n\n        ppos[1 - i] = pos;\n\n        av_add_index_entry(s->streams[0], pos, i, 0, 0, AVINDEX_KEYFRAME);\n\n    }\n\n    for(; i < size; i++){\n\n        t = get_unary(&gb, 1, 33) << 12;\n\n        t += get_bits(&gb, 12);\n\n        if(t & 1)\n\n            t = -(t & ~1);\n\n        pos = (t >> 1) + ppos[0]*2 - ppos[1];\n\n        av_add_index_entry(s->streams[0], pos, i << seekd, 0, 0, AVINDEX_KEYFRAME);\n\n        ppos[1] = ppos[0];\n\n        ppos[0] = pos;\n\n    }\n\n    av_free(buf);\n\n}\n", "idx": 24978, "_split": "valid", "_hash": "00dd722740411c32a97f7421ace266fc"}
{"project": "FFmpeg", "commit_id": "db85d11d9d880c932b13d37b5f1ca2bc9e3a253b", "target": 1, "func": "static int ftp_features(FTPContext *s)\n\n{\n\n    static const char *feat_command        = \"FEAT\\r\\n\";\n\n    static const char *enable_utf8_command = \"OPTS UTF8 ON\\r\\n\";\n\n    static const int feat_codes[] = {211, 0};\n\n    static const int opts_codes[] = {200, 451};\n\n    char *feat;\n\n\n\n    if (ftp_send_command(s, feat_command, feat_codes, &feat) == 211) {\n\n        if (av_stristr(feat, \"UTF8\"))\n\n            ftp_send_command(s, enable_utf8_command, opts_codes, NULL);\n\n    }\n\n    return 0;\n\n}\n", "idx": 24985, "_split": "valid", "_hash": "17fb139ff1386abe639437cab599b47f"}
{"project": "FFmpeg", "commit_id": "9c097f1cfc1825882353dc73e24a0d707d2495f2", "target": 0, "func": "static int ffserver_apply_stream_config(AVCodecContext *enc, const AVDictionary *conf, AVDictionary **opts)\n\n{\n\n    AVDictionaryEntry *e;\n\n    int ret = 0;\n\n\n\n    /* Return values from ffserver_set_*_param are ignored.\n\n       Values are initially parsed and checked before inserting to AVDictionary. */\n\n\n\n    //video params\n\n    if ((e = av_dict_get(conf, \"VideoBitRateRangeMin\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->rc_min_rate, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBitRateRangeMax\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->rc_max_rate, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"Debug\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->debug, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"Strict\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->strict_std_compliance, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBufferSize\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->rc_buffer_size, e->value, 8*1024, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBitRateTolerance\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->bit_rate_tolerance, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoBitRate\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->bit_rate, e->value, 1000, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoSizeWidth\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->width, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoSizeHeight\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->height, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"PixelFormat\", NULL, 0))) {\n\n        int val;\n\n        ffserver_set_int_param(&val, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n        enc->pix_fmt = val;\n\n    }\n\n    if ((e = av_dict_get(conf, \"VideoGopSize\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->gop_size, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoFrameRateNum\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->time_base.num, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoFrameRateDen\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->time_base.den, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoQDiff\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->max_qdiff, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoQMax\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->qmax, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"VideoQMin\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->qmin, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"LumiMask\", NULL, 0)))\n\n        ffserver_set_float_param(&enc->lumi_masking, e->value, 0, -FLT_MAX, FLT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"DarkMask\", NULL, 0)))\n\n        ffserver_set_float_param(&enc->dark_masking, e->value, 0, -FLT_MAX, FLT_MAX, NULL, 0, NULL);\n\n    if (av_dict_get(conf, \"BitExact\", NULL, 0))\n\n        enc->flags |= CODEC_FLAG_BITEXACT;\n\n    if (av_dict_get(conf, \"DctFastint\", NULL, 0))\n\n        enc->dct_algo  = FF_DCT_FASTINT;\n\n    if (av_dict_get(conf, \"IdctSimple\", NULL, 0))\n\n        enc->idct_algo = FF_IDCT_SIMPLE;\n\n    if (av_dict_get(conf, \"VideoHighQuality\", NULL, 0))\n\n        enc->mb_decision = FF_MB_DECISION_BITS;\n\n    if ((e = av_dict_get(conf, \"VideoTag\", NULL, 0)))\n\n        enc->codec_tag = MKTAG(e->value[0], e->value[1], e->value[2], e->value[3]);\n\n    if (av_dict_get(conf, \"Qscale\", NULL, 0)) {\n\n        enc->flags |= CODEC_FLAG_QSCALE;\n\n        ffserver_set_int_param(&enc->global_quality, e->value, FF_QP2LAMBDA, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    }\n\n    if (av_dict_get(conf, \"Video4MotionVector\", NULL, 0)) {\n\n        enc->mb_decision = FF_MB_DECISION_BITS; //FIXME remove\n\n        enc->flags |= CODEC_FLAG_4MV;\n\n    }\n\n    //audio params\n\n    if ((e = av_dict_get(conf, \"AudioChannels\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->channels, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"AudioSampleRate\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->sample_rate, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n    if ((e = av_dict_get(conf, \"AudioBitRate\", NULL, 0)))\n\n        ffserver_set_int_param(&enc->bit_rate, e->value, 0, INT_MIN, INT_MAX, NULL, 0, NULL);\n\n\n\n    av_opt_set_dict2(enc, opts, AV_OPT_SEARCH_CHILDREN);\n\n    e = NULL;\n\n    while (e = av_dict_get(*opts, \"\", e, AV_DICT_IGNORE_SUFFIX)) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Provided AVOption '%s' doesn't match any existing option.\\n\", e->key);\n\n        ret = AVERROR(EINVAL);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 25011, "_split": "valid", "_hash": "dcc6b1070f6813236e1468a5b3ab8a22"}
{"project": "FFmpeg", "commit_id": "8055433b492fe971a145a07470119ef8c2c71571", "target": 1, "func": "int avfilter_graph_parse(AVFilterGraph *graph, const char *filters,\n\n                         AVFilterInOut **open_inputs, AVFilterInOut **open_outputs,\n\n                         void *log_ctx)\n\n{\n\n    int index = 0, ret;\n\n    char chr = 0;\n\n\n\n    AVFilterInOut *curr_inputs = NULL;\n\n\n\n    do {\n\n        AVFilterContext *filter;\n\n        const char *filterchain = filters;\n\n        filters += strspn(filters, WHITESPACES);\n\n\n\n        if ((ret = parse_inputs(&filters, &curr_inputs, open_outputs, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if ((ret = parse_filter(&filter, &filters, graph, index, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if (filter->input_count == 1 && !curr_inputs && !index) {\n\n            /* First input can be omitted if it is \"[in]\" */\n\n            const char *tmp = \"[in]\";\n\n            if ((ret = parse_inputs(&tmp, &curr_inputs, open_outputs, log_ctx)) < 0)\n\n                goto fail;\n\n        }\n\n\n\n        if ((ret = link_filter_inouts(filter, &curr_inputs, open_inputs, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if ((ret = parse_outputs(&filters, &curr_inputs, open_inputs, open_outputs,\n\n                                 log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        filters += strspn(filters, WHITESPACES);\n\n        chr = *filters++;\n\n\n\n        if (chr == ';' && curr_inputs) {\n\n            av_log(log_ctx, AV_LOG_ERROR,\n\n                   \"Invalid filterchain containing an unlabelled output pad: \\\"%s\\\"\\n\",\n\n                   filterchain);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        index++;\n\n    } while (chr == ',' || chr == ';');\n\n\n\n    if (chr) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Unable to parse graph description substring: \\\"%s\\\"\\n\",\n\n               filters - 1);\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    if (*open_inputs && !strcmp((*open_inputs)->name, \"out\") && curr_inputs) {\n\n        /* Last output can be omitted if it is \"[out]\" */\n\n        const char *tmp = \"[out]\";\n\n        if ((ret = parse_outputs(&tmp, &curr_inputs, open_inputs, open_outputs,\n\n                                 log_ctx)) < 0)\n\n            goto fail;\n\n    }\n\n\n\n    return 0;\n\n\n\n fail:\n\n    for (; graph->filter_count > 0; graph->filter_count--)\n\n        avfilter_free(graph->filters[graph->filter_count - 1]);\n\n    av_freep(&graph->filters);\n\n    avfilter_inout_free(open_inputs);\n\n    avfilter_inout_free(open_outputs);\n\n    avfilter_inout_free(&curr_inputs);\n\n    return ret;\n\n}\n", "idx": 25051, "_split": "valid", "_hash": "7a27211091d41c936761636888944c58"}
{"project": "FFmpeg", "commit_id": "02fb320adadacfc8446a1278582351078a024dee", "target": 1, "func": "static int libopenjpeg_decode_frame(AVCodecContext *avctx,\n\n                                    void *data, int *data_size,\n\n                                    AVPacket *avpkt)\n\n{\n\n    uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    LibOpenJPEGContext *ctx = avctx->priv_data;\n\n    AVFrame *picture = &ctx->image, *output = data;\n\n    opj_dinfo_t *dec;\n\n    opj_cio_t *stream;\n\n    opj_image_t *image;\n\n    int width, height, ret = -1;\n\n    int pixel_size = 0;\n\n    int ispacked = 0;\n\n\n\n    *data_size = 0;\n\n\n\n    // Check if input is a raw jpeg2k codestream or in jp2 wrapping\n\n    if((AV_RB32(buf) == 12) &&\n\n       (AV_RB32(buf + 4) == JP2_SIG_TYPE) &&\n\n       (AV_RB32(buf + 8) == JP2_SIG_VALUE)) {\n\n        dec = opj_create_decompress(CODEC_JP2);\n\n    } else {\n\n        // If the AVPacket contains a jp2c box, then skip to\n\n        // the starting byte of the codestream.\n\n        if (AV_RB32(buf + 4) == AV_RB32(\"jp2c\"))\n\n            buf += 8;\n\n        dec = opj_create_decompress(CODEC_J2K);\n\n\n\n\n    if(!dec) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing decoder.\\n\");\n\n\n\n    opj_set_event_mgr((opj_common_ptr)dec, NULL, NULL);\n\n\n\n    ctx->dec_params.cp_limit_decoding = LIMIT_TO_MAIN_HEADER;\n\n    // Tie decoder with decoding parameters\n\n    opj_setup_decoder(dec, &ctx->dec_params);\n\n    stream = opj_cio_open((opj_common_ptr)dec, buf, buf_size);\n\n    if(!stream) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Codestream could not be opened for reading.\\n\");\n\n\n\n\n\n\n    // Decode the header only\n\n    image = opj_decode_with_info(dec, stream, NULL);\n\n    opj_cio_close(stream);\n\n\n\n\n\n\n    width  = image->x1 - image->x0;\n\n    height = image->y1 - image->y0;\n\n    if(av_image_check_size(width, height, 0, avctx) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"%dx%d dimension invalid.\\n\", width, height);\n\n        goto done;\n\n\n    avcodec_set_dimensions(avctx, width, height);\n\n\n\n    switch (image->numcomps) {\n\n    case 1:  avctx->pix_fmt = (image->comps[0].bpp == 8) ? PIX_FMT_GRAY8 : PIX_FMT_GRAY16;\n\n             break;\n\n    case 2:  avctx->pix_fmt = PIX_FMT_GRAY8A;\n\n             break;\n\n    case 3:\n\n    case 4:  avctx->pix_fmt = check_image_attributes(avctx, image);\n\n             break;\n\n    default: av_log(avctx, AV_LOG_ERROR, \"%d components unsupported.\\n\", image->numcomps);\n\n             goto done;\n\n\n\n\n    if(picture->data[0])\n\n        ff_thread_release_buffer(avctx, picture);\n\n\n\n    if(ff_thread_get_buffer(avctx, picture) < 0){\n\n        av_log(avctx, AV_LOG_ERROR, \"ff_thread_get_buffer() failed\\n\");\n\n\n\n\n\n    ctx->dec_params.cp_limit_decoding = NO_LIMITATION;\n\n    ctx->dec_params.cp_reduce = avctx->lowres;\n\n    // Tie decoder with decoding parameters\n\n    opj_setup_decoder(dec, &ctx->dec_params);\n\n    stream = opj_cio_open((opj_common_ptr)dec, buf, buf_size);\n\n    if(!stream) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Codestream could not be opened for reading.\\n\");\n\n\n\n\n\n\n    // Decode the codestream\n\n    image = opj_decode_with_info(dec, stream, NULL);\n\n    opj_cio_close(stream);\n\n\n\n\n\n\n\n\n    pixel_size = av_pix_fmt_descriptors[avctx->pix_fmt].comp[0].step_minus1 + 1;\n\n    ispacked = libopenjpeg_ispacked(avctx->pix_fmt);\n\n\n\n    switch (pixel_size) {\n\n    case 1:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed8(picture, image);\n\n        } else {\n\n            libopenjpeg_copyto8(picture, image);\n\n\n        break;\n\n    case 2:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed8(picture, image);\n\n        } else {\n\n            libopenjpeg_copyto16(picture, image);\n\n\n        break;\n\n    case 3:\n\n    case 4:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed8(picture, image);\n\n\n        break;\n\n    case 6:\n\n    case 8:\n\n        if (ispacked) {\n\n            libopenjpeg_copy_to_packed16(picture, image);\n\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported pixel size %d\\n\", pixel_size);\n\n        goto done;\n\n\n\n\n    *output    = ctx->image;\n\n    *data_size = sizeof(AVPicture);\n\n    ret = buf_size;\n\n\n\ndone:\n\n    opj_image_destroy(image);\n\n\n    return ret;\n", "idx": 25058, "_split": "valid", "_hash": "1dadd6f56c25aff0bdd8de55ba7b6c6b"}
{"project": "FFmpeg", "commit_id": "4bb1070c154e49d35805fbcdac9c9e92f702ef96", "target": 0, "func": "void ffv1_clear_slice_state(FFV1Context *f, FFV1Context *fs)\n\n{\n\n    int i, j;\n\n\n\n    for (i = 0; i < f->plane_count; i++) {\n\n        PlaneContext *p = &fs->plane[i];\n\n\n\n        p->interlace_bit_state[0] = 128;\n\n        p->interlace_bit_state[1] = 128;\n\n\n\n        if (fs->ac) {\n\n            if (f->initial_states[p->quant_table_index]) {\n\n                memcpy(p->state, f->initial_states[p->quant_table_index],\n\n                       CONTEXT_SIZE * p->context_count);\n\n            } else\n\n                memset(p->state, 128, CONTEXT_SIZE * p->context_count);\n\n        } else {\n\n            for (j = 0; j < p->context_count; j++) {\n\n                p->vlc_state[j].drift     = 0;\n\n                p->vlc_state[j].error_sum = 4;    //FFMAX((RANGE + 32)/64, 2);\n\n                p->vlc_state[j].bias      = 0;\n\n                p->vlc_state[j].count     = 1;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 25071, "_split": "valid", "_hash": "d120a31c2df066ff474129c0f6ae9de9"}
{"project": "FFmpeg", "commit_id": "d8dccf69ff2df7014a2bb8e0e17828a820f45b27", "target": 1, "func": "static int av_buffersrc_add_frame_internal(AVFilterContext *ctx,\n\n                                           AVFrame *frame, int flags)\n\n{\n\n    BufferSourceContext *s = ctx->priv;\n\n    AVFrame *copy;\n\n    int ret;\n\n\n\n    if (!frame) {\n\n        s->eof = 1;\n\n        return 0;\n\n    } else if (s->eof)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (!(flags & AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT)) {\n\n\n\n    switch (ctx->outputs[0]->type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        CHECK_VIDEO_PARAM_CHANGE(ctx, s, frame->width, frame->height,\n\n                                 frame->format);\n\n        break;\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        CHECK_AUDIO_PARAM_CHANGE(ctx, s, frame->sample_rate, frame->channel_layout,\n\n                                 frame->format);\n\n        break;\n\n    default:\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    }\n\n\n\n    if (!av_fifo_space(s->fifo) &&\n\n        (ret = av_fifo_realloc2(s->fifo, av_fifo_size(s->fifo) +\n\n                                         sizeof(copy))) < 0)\n\n        return ret;\n\n\n\n    if (!(copy = av_frame_alloc()))\n\n        return AVERROR(ENOMEM);\n\n    av_frame_move_ref(copy, frame);\n\n\n\n    if ((ret = av_fifo_generic_write(s->fifo, &copy, sizeof(copy), NULL)) < 0) {\n\n        av_frame_move_ref(frame, copy);\n\n        av_frame_free(&copy);\n\n        return ret;\n\n    }\n\n\n\n    if ((flags & AV_BUFFERSRC_FLAG_PUSH))\n\n        if ((ret = ctx->output_pads[0].request_frame(ctx->outputs[0])) < 0)\n\n            return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 25077, "_split": "valid", "_hash": "42ad35ecb43682992fb2e835924fd9af"}
{"project": "FFmpeg", "commit_id": "ac1d489320f476c18d6a8125f73389aecb73f3d3", "target": 0, "func": "static int asf_read_seek(AVFormatContext *s, int stream_index, int64_t pts, int flags)\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    AVStream *st = s->streams[stream_index];\n\n    int64_t pos;\n\n    int index;\n\n\n\n    if (s->packet_size <= 0)\n\n        return -1;\n\n\n\n    /* Try using the protocol's read_seek if available */\n\n    if(s->pb) {\n\n        int ret = avio_seek_time(s->pb, stream_index, pts, flags);\n\n        if(ret >= 0)\n\n            asf_reset_header(s);\n\n        if (ret != AVERROR(ENOSYS))\n\n            return ret;\n\n    }\n\n\n\n    if (!asf->index_read)\n\n        asf_build_simple_index(s, stream_index);\n\n\n\n    if((asf->index_read && st->index_entries)){\n\n        index= av_index_search_timestamp(st, pts, flags);\n\n        if(index >= 0) {\n\n            /* find the position */\n\n            pos = st->index_entries[index].pos;\n\n\n\n            /* do the seek */\n\n            av_log(s, AV_LOG_DEBUG, \"SEEKTO: %\"PRId64\"\\n\", pos);\n\n            avio_seek(s->pb, pos, SEEK_SET);\n\n            asf_reset_header(s);\n\n            return 0;\n\n        }\n\n    }\n\n    /* no index or seeking by index failed */\n\n    if(av_seek_frame_binary(s, stream_index, pts, flags)<0)\n\n        return -1;\n\n    asf_reset_header(s);\n\n    return 0;\n\n}\n", "idx": 25089, "_split": "valid", "_hash": "83b05e918948bbc046d1b8d167ec25fb"}
{"project": "FFmpeg", "commit_id": "e3751aa6ec8147ab7ca2649d4daadf8d4dce27d5", "target": 0, "func": "static void decode(RA288Context *ractx, float gain, int cb_coef)\n\n{\n\n    int i, j;\n\n    double sumsum;\n\n    float sum, buffer[5];\n\n\n\n    memmove(ractx->sp_block + 5, ractx->sp_block, 36*sizeof(*ractx->sp_block));\n\n\n\n    for (i=4; i >= 0; i--)\n\n        ractx->sp_block[i] = -scalar_product_float(ractx->sp_block + i + 1,\n\n                                             ractx->sp_lpc, 36);\n\n\n\n    /* block 46 of G.728 spec */\n\n    sum = 32. - scalar_product_float(ractx->gain_lpc, ractx->gain_block, 10);\n\n\n\n    /* block 47 of G.728 spec */\n\n    sum = av_clipf(sum, 0, 60);\n\n\n\n    /* block 48 of G.728 spec */\n\n    sumsum = exp(sum * 0.1151292546497) * gain; /* pow(10.0,sum/20)*gain */\n\n\n\n    for (i=0; i < 5; i++)\n\n        buffer[i] = codetable[cb_coef][i] * sumsum;\n\n\n\n    sum = scalar_product_float(buffer, buffer, 5) / 5;\n\n\n\n    sum = FFMAX(sum, 1);\n\n\n\n    /* shift and store */\n\n    memmove(ractx->gain_block, ractx->gain_block - 1,\n\n            10 * sizeof(*ractx->gain_block));\n\n\n\n    *ractx->gain_block = 10 * log10(sum) - 32;\n\n\n\n    for (i=1; i < 5; i++)\n\n        for (j=i-1; j >= 0; j--)\n\n            buffer[i] -= ractx->sp_lpc[i-j-1] * buffer[j];\n\n\n\n    /* output */\n\n    for (i=0; i < 5; i++)\n\n        ractx->sp_block[4-i] =\n\n            av_clipf(ractx->sp_block[4-i] + buffer[i], -4095, 4095);\n\n}\n", "idx": 25090, "_split": "valid", "_hash": "b1a81a0a9c146748746a05ba70b50467"}
{"project": "FFmpeg", "commit_id": "db592f3b03a21d5bd5237021c00af3ce0431fc60", "target": 0, "func": "static void color16(WaveformContext *s, AVFrame *in, AVFrame *out,\n\n                    int component, int intensity, int offset, int column)\n\n{\n\n    const int plane = s->desc->comp[component].plane;\n\n    const int mirror = s->mirror;\n\n    const int limit = s->size - 1;\n\n    const uint16_t *c0_data = (const uint16_t *)in->data[plane + 0];\n\n    const uint16_t *c1_data = (const uint16_t *)in->data[(plane + 1) % s->ncomp];\n\n    const uint16_t *c2_data = (const uint16_t *)in->data[(plane + 2) % s->ncomp];\n\n    const int c0_linesize = in->linesize[ plane + 0 ] / 2;\n\n    const int c1_linesize = in->linesize[(plane + 1) % s->ncomp] / 2;\n\n    const int c2_linesize = in->linesize[(plane + 2) % s->ncomp] / 2;\n\n    const int d0_linesize = out->linesize[ plane + 0 ] / 2;\n\n    const int d1_linesize = out->linesize[(plane + 1) % s->ncomp] / 2;\n\n    const int d2_linesize = out->linesize[(plane + 2) % s->ncomp] / 2;\n\n    const int src_h = in->height;\n\n    const int src_w = in->width;\n\n    int x, y;\n\n\n\n    if (s->mode) {\n\n        const int d0_signed_linesize = d0_linesize * (mirror == 1 ? -1 : 1);\n\n        const int d1_signed_linesize = d1_linesize * (mirror == 1 ? -1 : 1);\n\n        const int d2_signed_linesize = d2_linesize * (mirror == 1 ? -1 : 1);\n\n        uint16_t *d0_data = (uint16_t *)out->data[plane] + offset * d0_linesize;\n\n        uint16_t *d1_data = (uint16_t *)out->data[(plane + 1) % s->ncomp] + offset * d1_linesize;\n\n        uint16_t *d2_data = (uint16_t *)out->data[(plane + 2) % s->ncomp] + offset * d2_linesize;\n\n        uint16_t * const d0_bottom_line = d0_data + d0_linesize * (s->size - 1);\n\n        uint16_t * const d0 = (mirror ? d0_bottom_line : d0_data);\n\n        uint16_t * const d1_bottom_line = d1_data + d1_linesize * (s->size - 1);\n\n        uint16_t * const d1 = (mirror ? d1_bottom_line : d1_data);\n\n        uint16_t * const d2_bottom_line = d2_data + d2_linesize * (s->size - 1);\n\n        uint16_t * const d2 = (mirror ? d2_bottom_line : d2_data);\n\n\n\n        for (y = 0; y < src_h; y++) {\n\n            for (x = 0; x < src_w; x++) {\n\n                const int c0 = FFMIN(c0_data[x], limit);\n\n                const int c1 = c1_data[x];\n\n                const int c2 = c2_data[x];\n\n\n\n                *(d0 + d0_signed_linesize * c0 + x) = c0;\n\n                *(d1 + d1_signed_linesize * c0 + x) = c1;\n\n                *(d2 + d2_signed_linesize * c0 + x) = c2;\n\n            }\n\n\n\n            c0_data += c0_linesize;\n\n            c1_data += c1_linesize;\n\n            c2_data += c2_linesize;\n\n            d0_data += d0_linesize;\n\n            d1_data += d1_linesize;\n\n            d2_data += d2_linesize;\n\n        }\n\n    } else {\n\n        uint16_t *d0_data = (uint16_t *)out->data[plane] + offset;\n\n        uint16_t *d1_data = (uint16_t *)out->data[(plane + 1) % s->ncomp] + offset;\n\n        uint16_t *d2_data = (uint16_t *)out->data[(plane + 2) % s->ncomp] + offset;\n\n\n\n        if (mirror) {\n\n            d0_data += s->size - 1;\n\n            d1_data += s->size - 1;\n\n            d2_data += s->size - 1;\n\n        }\n\n\n\n        for (y = 0; y < src_h; y++) {\n\n            for (x = 0; x < src_w; x++) {\n\n                const int c0 = FFMIN(c0_data[x], limit);\n\n                const int c1 = c1_data[x];\n\n                const int c2 = c2_data[x];\n\n\n\n                if (mirror) {\n\n                    *(d0_data - c0) = c0;\n\n                    *(d1_data - c0) = c1;\n\n                    *(d2_data - c0) = c2;\n\n                } else {\n\n                    *(d0_data + c0) = c0;\n\n                    *(d1_data + c0) = c1;\n\n                    *(d2_data + c0) = c2;\n\n                }\n\n            }\n\n\n\n            c0_data += c0_linesize;\n\n            c1_data += c1_linesize;\n\n            c2_data += c2_linesize;\n\n            d0_data += d0_linesize;\n\n            d1_data += d1_linesize;\n\n            d2_data += d2_linesize;\n\n        }\n\n    }\n\n\n\n    envelope16(s, out, plane, plane);\n\n}\n", "idx": 25098, "_split": "valid", "_hash": "b7dbf29f22e0b7387fad45b02bb38693"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(yuvPlanartoyuy2)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n\tunsigned int width, unsigned int height,\n\n\tint lumStride, int chromStride, int dstStride, int vertLumPerChroma)\n\n{\n\n\tunsigned y;\n\n\tconst unsigned chromWidth= width>>1;\n\n\tfor(y=0; y<height; y++)\n\n\t{\n\n#ifdef HAVE_MMX\n\n//FIXME handle 2 lines a once (fewer prefetch, reuse some chrom, but very likely limited by mem anyway)\n\n\t\tasm volatile(\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%1, %%\"REG_a\", 2)\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\t\"movq (%2, %%\"REG_a\"), %%mm0\t\\n\\t\" // U(0)\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // U(0)\n\n\t\t\t\"movq (%3, %%\"REG_a\"), %%mm1\t\\n\\t\" // V(0)\n\n\t\t\t\"punpcklbw %%mm1, %%mm0\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"punpckhbw %%mm1, %%mm2\t\t\\n\\t\" // UVUV UVUV(8)\n\n\n\n\t\t\t\"movq (%1, %%\"REG_a\",2), %%mm3\t\\n\\t\" // Y(0)\n\n\t\t\t\"movq 8(%1, %%\"REG_a\",2), %%mm5\t\\n\\t\" // Y(8)\n\n\t\t\t\"movq %%mm3, %%mm4\t\t\\n\\t\" // Y(0)\n\n\t\t\t\"movq %%mm5, %%mm6\t\t\\n\\t\" // Y(8)\n\n\t\t\t\"punpcklbw %%mm0, %%mm3\t\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"punpckhbw %%mm0, %%mm4\t\t\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"punpcklbw %%mm2, %%mm5\t\t\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"punpckhbw %%mm2, %%mm6\t\t\\n\\t\" // YUYV YUYV(12)\n\n\n\n\t\t\tMOVNTQ\" %%mm3, (%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm4, 8(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm5, 16(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, 24(%0, %%\"REG_a\", 4)\\n\\t\"\n\n\n\n\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"cmp %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t\t::\"r\"(dst), \"r\"(ysrc), \"r\"(usrc), \"r\"(vsrc), \"g\" ((long)chromWidth)\n\n\t\t\t: \"%\"REG_a\n\n\t\t);\n\n#else\n\n\n\n#if defined ARCH_ALPHA && defined HAVE_MVI\n\n#define pl2yuy2(n)\t\t\t\t\t\\\n\n\ty1 = yc[n];\t\t\t\t\t\\\n\n\ty2 = yc2[n];\t\t\t\t\t\\\n\n\tu = uc[n];\t\t\t\t\t\\\n\n\tv = vc[n];\t\t\t\t\t\\\n\n\tasm(\"unpkbw %1, %0\" : \"=r\"(y1) : \"r\"(y1));\t\\\n\n\tasm(\"unpkbw %1, %0\" : \"=r\"(y2) : \"r\"(y2));\t\\\n\n\tasm(\"unpkbl %1, %0\" : \"=r\"(u) : \"r\"(u));\t\\\n\n\tasm(\"unpkbl %1, %0\" : \"=r\"(v) : \"r\"(v));\t\\\n\n\tyuv1 = (u << 8) + (v << 24);\t\t\t\\\n\n\tyuv2 = yuv1 + y2;\t\t\t\t\\\n\n\tyuv1 += y1;\t\t\t\t\t\\\n\n\tqdst[n] = yuv1;\t\t\t\t\t\\\n\n\tqdst2[n] = yuv2;\n\n\n\n\t\tint i;\n\n\t\tuint64_t *qdst = (uint64_t *) dst;\n\n\t\tuint64_t *qdst2 = (uint64_t *) (dst + dstStride);\n\n\t\tconst uint32_t *yc = (uint32_t *) ysrc;\n\n\t\tconst uint32_t *yc2 = (uint32_t *) (ysrc + lumStride);\n\n\t\tconst uint16_t *uc = (uint16_t*) usrc, *vc = (uint16_t*) vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i += 8){\n\n\t\t\tuint64_t y1, y2, yuv1, yuv2;\n\n\t\t\tuint64_t u, v;\n\n\t\t\t/* Prefetch */\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(yc));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(yc2));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(uc));\n\n\t\t\tasm(\"ldq $31,64(%0)\" :: \"r\"(vc));\n\n\n\n\t\t\tpl2yuy2(0);\n\n\t\t\tpl2yuy2(1);\n\n\t\t\tpl2yuy2(2);\n\n\t\t\tpl2yuy2(3);\n\n\n\n\t\t\tyc += 4;\n\n\t\t\tyc2 += 4;\n\n\t\t\tuc += 4;\n\n\t\t\tvc += 4;\n\n\t\t\tqdst += 4;\n\n\t\t\tqdst2 += 4;\n\n\t\t}\n\n\t\ty++;\n\n\t\tysrc += lumStride;\n\n\t\tdst += dstStride;\n\n\n\n#elif __WORDSIZE >= 64\n\n\t\tint i;\n\n\t\tuint64_t *ldst = (uint64_t *) dst;\n\n\t\tconst uint8_t *yc = ysrc, *uc = usrc, *vc = vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i += 2){\n\n\t\t\tuint64_t k, l;\n\n\t\t\tk = yc[0] + (uc[0] << 8) +\n\n\t\t\t    (yc[1] << 16) + (vc[0] << 24);\n\n\t\t\tl = yc[2] + (uc[1] << 8) +\n\n\t\t\t    (yc[3] << 16) + (vc[1] << 24);\n\n\t\t\t*ldst++ = k + (l << 32);\n\n\t\t\tyc += 4;\n\n\t\t\tuc += 2;\n\n\t\t\tvc += 2;\n\n\t\t}\n\n\n\n#else\n\n\t\tint i, *idst = (int32_t *) dst;\n\n\t\tconst uint8_t *yc = ysrc, *uc = usrc, *vc = vsrc;\n\n\t\tfor(i = 0; i < chromWidth; i++){\n\n#ifdef WORDS_BIGENDIAN\n\n\t\t\t*idst++ = (yc[0] << 24)+ (uc[0] << 16) +\n\n\t\t\t    (yc[1] << 8) + (vc[0] << 0);\n\n#else\n\n\t\t\t*idst++ = yc[0] + (uc[0] << 8) +\n\n\t\t\t    (yc[1] << 16) + (vc[0] << 24);\n\n#endif\n\n\t\t\tyc += 2;\n\n\t\t\tuc++;\n\n\t\t\tvc++;\n\n\t\t}\n\n#endif\n\n#endif\n\n\t\tif((y&(vertLumPerChroma-1))==(vertLumPerChroma-1) )\n\n\t\t{\n\n\t\t\tusrc += chromStride;\n\n\t\t\tvsrc += chromStride;\n\n\t\t}\n\n\t\tysrc += lumStride;\n\n\t\tdst += dstStride;\n\n\t}\n\n#ifdef HAVE_MMX\n\nasm(    EMMS\" \\n\\t\"\n\n        SFENCE\" \\n\\t\"\n\n        :::\"memory\");\n\n#endif\n\n}\n", "idx": 25184, "_split": "valid", "_hash": "b4db05be6c6951a5dbe50884484459a2"}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void vc1_inv_trans_4x4_dc_c(uint8_t *dest, int linesize, DCTELEM *block)\n\n{\n\n    int i;\n\n    int dc = block[0];\n\n    const uint8_t *cm;\n\n    dc = (17 * dc +  4) >> 3;\n\n    dc = (17 * dc + 64) >> 7;\n\n    cm = ff_cropTbl + MAX_NEG_CROP + dc;\n\n    for(i = 0; i < 4; i++){\n\n        dest[0] = cm[dest[0]];\n\n        dest[1] = cm[dest[1]];\n\n        dest[2] = cm[dest[2]];\n\n        dest[3] = cm[dest[3]];\n\n        dest += linesize;\n\n    }\n\n}\n", "idx": 25194, "_split": "valid", "_hash": "3225fab32b58e9e3f768d51d1be83828"}
{"project": "FFmpeg", "commit_id": "bfd0e02dd64e912a6b67c25d9f86b3b0b849ad10", "target": 0, "func": "static void read_sbr_noise(SpectralBandReplication *sbr, GetBitContext *gb,\n\n                           SBRData *ch_data, int ch)\n\n{\n\n    int i, j;\n\n    VLC_TYPE (*t_huff)[2], (*f_huff)[2];\n\n    int t_lav, f_lav;\n\n    int delta = (ch == 1 && sbr->bs_coupling == 1) + 1;\n\n\n\n    if (sbr->bs_coupling && ch) {\n\n        t_huff = vlc_sbr[T_HUFFMAN_NOISE_BAL_3_0DB].table;\n\n        t_lav  = vlc_sbr_lav[T_HUFFMAN_NOISE_BAL_3_0DB];\n\n        f_huff = vlc_sbr[F_HUFFMAN_ENV_BAL_3_0DB].table;\n\n        f_lav  = vlc_sbr_lav[F_HUFFMAN_ENV_BAL_3_0DB];\n\n    } else {\n\n        t_huff = vlc_sbr[T_HUFFMAN_NOISE_3_0DB].table;\n\n        t_lav  = vlc_sbr_lav[T_HUFFMAN_NOISE_3_0DB];\n\n        f_huff = vlc_sbr[F_HUFFMAN_ENV_3_0DB].table;\n\n        f_lav  = vlc_sbr_lav[F_HUFFMAN_ENV_3_0DB];\n\n    }\n\n\n\n#if USE_FIXED\n\n    for (i = 0; i < ch_data->bs_num_noise; i++) {\n\n        if (ch_data->bs_df_noise[i]) {\n\n            for (j = 0; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j].mant = ch_data->noise_facs[i][j].mant + delta * (get_vlc2(gb, t_huff, 9, 2) - t_lav);\n\n        } else {\n\n            ch_data->noise_facs[i + 1][0].mant = delta * get_bits(gb, 5); // bs_noise_start_value_balance or bs_noise_start_value_level\n\n            for (j = 1; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j].mant = ch_data->noise_facs[i + 1][j - 1].mant + delta * (get_vlc2(gb, f_huff, 9, 3) - f_lav);\n\n        }\n\n    }\n\n#else\n\n    for (i = 0; i < ch_data->bs_num_noise; i++) {\n\n        if (ch_data->bs_df_noise[i]) {\n\n            for (j = 0; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j] = ch_data->noise_facs[i][j] + delta * (get_vlc2(gb, t_huff, 9, 2) - t_lav);\n\n        } else {\n\n            ch_data->noise_facs[i + 1][0] = delta * get_bits(gb, 5); // bs_noise_start_value_balance or bs_noise_start_value_level\n\n            for (j = 1; j < sbr->n_q; j++)\n\n                ch_data->noise_facs[i + 1][j] = ch_data->noise_facs[i + 1][j - 1] + delta * (get_vlc2(gb, f_huff, 9, 3) - f_lav);\n\n        }\n\n    }\n\n#endif /* USE_FIXED */\n\n\n\n    //assign 0th elements of noise_facs from last elements\n\n    memcpy(ch_data->noise_facs[0], ch_data->noise_facs[ch_data->bs_num_noise],\n\n           sizeof(ch_data->noise_facs[0]));\n\n}\n", "idx": 25197, "_split": "valid", "_hash": "aa66406fb823df5d6630cdea941a66d2"}
{"project": "FFmpeg", "commit_id": "6950cca97fed890ec56259a2f868f37b65513d92", "target": 0, "func": "int av_image_fill_pointers(uint8_t *data[4], enum PixelFormat pix_fmt, int height,\n\n                           uint8_t *ptr, const int linesizes[4])\n\n{\n\n    int i, total_size, size[4], has_plane[4];\n\n\n\n    const AVPixFmtDescriptor *desc = &av_pix_fmt_descriptors[pix_fmt];\n\n    memset(data     , 0, sizeof(data[0])*4);\n\n    memset(size     , 0, sizeof(size));\n\n    memset(has_plane, 0, sizeof(has_plane));\n\n\n\n    if (desc->flags & PIX_FMT_HWACCEL)\n\n        return AVERROR(EINVAL);\n\n\n\n    data[0] = ptr;\n\n    size[0] = linesizes[0] * height;\n\n\n\n    if (desc->flags & PIX_FMT_PAL) {\n\n        size[0] = (size[0] + 3) & ~3;\n\n        data[1] = ptr + size[0]; /* palette is stored here as 256 32 bits words */\n\n        return size[0] + 256 * 4;\n\n    }\n\n\n\n    for (i = 0; i < 4; i++)\n\n        has_plane[desc->comp[i].plane] = 1;\n\n\n\n    total_size = size[0];\n\n    for (i = 1; has_plane[i] && i < 4; i++) {\n\n        int h, s = (i == 1 || i == 2) ? desc->log2_chroma_h : 0;\n\n        data[i] = data[i-1] + size[i-1];\n\n        h = (height + (1 << s) - 1) >> s;\n\n        size[i] = h * linesizes[i];\n\n        total_size += size[i];\n\n    }\n\n\n\n    return total_size;\n\n}\n", "idx": 25266, "_split": "valid", "_hash": "026d6bea7391637344ff9c1da5e35062"}
{"project": "FFmpeg", "commit_id": "a42e3a6700547e4e49445bda81d3a89ec3e081a9", "target": 1, "func": "static int pcm_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    const uint8_t *src = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    PCMDecode *s       = avctx->priv_data;\n\n    AVFrame *frame     = data;\n\n    int sample_size, c, n, ret, samples_per_block;\n\n    uint8_t *samples;\n\n    int32_t *dst_int32_t;\n\n\n\n    sample_size = av_get_bits_per_sample(avctx->codec_id) / 8;\n\n\n\n    /* av_get_bits_per_sample returns 0 for AV_CODEC_ID_PCM_DVD */\n\n    samples_per_block = 1;\n\n    if (avctx->codec->id == AV_CODEC_ID_PCM_DVD) {\n\n        if (avctx->bits_per_coded_sample != 20 &&\n\n            avctx->bits_per_coded_sample != 24) {\n\n            av_log(avctx, AV_LOG_ERROR, \"PCM DVD unsupported sample depth\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        /* 2 samples are interleaved per block in PCM_DVD */\n\n        samples_per_block = 2;\n\n        sample_size       = avctx->bits_per_coded_sample * 2 / 8;\n\n    } else if (avctx->codec_id == AV_CODEC_ID_PCM_LXF) {\n\n        /* we process 40-bit blocks per channel for LXF */\n\n        samples_per_block = 2;\n\n        sample_size       = 5;\n\n    }\n\n\n\n    if (sample_size == 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid sample_size\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    n = avctx->channels * sample_size;\n\n\n\n    if (n && buf_size % n) {\n\n        if (buf_size < n) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid PCM packet\\n\");\n\n            return -1;\n\n        } else\n\n            buf_size -= buf_size % n;\n\n    }\n\n\n\n    n = buf_size / sample_size;\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = n * samples_per_block / avctx->channels;\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    samples = frame->data[0];\n\n\n\n    switch (avctx->codec->id) {\n\n    case AV_CODEC_ID_PCM_U32LE:\n\n        DECODE(32, le32, src, samples, n, 0, 0x80000000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U32BE:\n\n        DECODE(32, be32, src, samples, n, 0, 0x80000000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24LE:\n\n        DECODE(32, le24, src, samples, n, 8, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24BE:\n\n        DECODE(32, be24, src, samples, n, 8, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U24LE:\n\n        DECODE(32, le24, src, samples, n, 8, 0x800000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U24BE:\n\n        DECODE(32, be24, src, samples, n, 8, 0x800000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S24DAUD:\n\n        for (; n > 0; n--) {\n\n            uint32_t v = bytestream_get_be24(&src);\n\n            v >>= 4; // sync flags are here\n\n            AV_WN16A(samples, ff_reverse[(v >> 8) & 0xff] +\n\n                             (ff_reverse[v        & 0xff] << 8));\n\n            samples += 2;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16LE_PLANAR:\n\n    {\n\n        int av_unused n2;\n\n        n /= avctx->channels;\n\n        for (c = 0; c < avctx->channels; c++) {\n\n            samples = frame->extended_data[c];\n\n#if HAVE_BIGENDIAN\n\n            n2 = n;\n\n            DECODE(16, le16, src, samples, n2, 0, 0)\n\n#else\n\n            memcpy(samples, src, n * 2);\n\n            src += n * 2;\n\n#endif\n\n        }\n\n        break;\n\n    }\n\n    case AV_CODEC_ID_PCM_U16LE:\n\n        DECODE(16, le16, src, samples, n, 0, 0x8000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_U16BE:\n\n        DECODE(16, be16, src, samples, n, 0, 0x8000)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S8:\n\n        for (; n > 0; n--)\n\n            *samples++ = *src++ + 128;\n\n        break;\n\n#if HAVE_BIGENDIAN\n\n    case AV_CODEC_ID_PCM_F64LE:\n\n        DECODE(64, le64, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S32LE:\n\n    case AV_CODEC_ID_PCM_F32LE:\n\n        DECODE(32, le32, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16LE:\n\n        DECODE(16, le16, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F64BE:\n\n    case AV_CODEC_ID_PCM_F32BE:\n\n    case AV_CODEC_ID_PCM_S32BE:\n\n    case AV_CODEC_ID_PCM_S16BE:\n\n#else\n\n    case AV_CODEC_ID_PCM_F64BE:\n\n        DECODE(64, be64, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F32BE:\n\n    case AV_CODEC_ID_PCM_S32BE:\n\n        DECODE(32, be32, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_S16BE:\n\n        DECODE(16, be16, src, samples, n, 0, 0)\n\n        break;\n\n    case AV_CODEC_ID_PCM_F64LE:\n\n    case AV_CODEC_ID_PCM_F32LE:\n\n    case AV_CODEC_ID_PCM_S32LE:\n\n    case AV_CODEC_ID_PCM_S16LE:\n\n#endif /* HAVE_BIGENDIAN */\n\n    case AV_CODEC_ID_PCM_U8:\n\n        memcpy(samples, src, n * sample_size);\n\n        break;\n\n    case AV_CODEC_ID_PCM_ZORK:\n\n        for (; n > 0; n--) {\n\n            int v = *src++;\n\n            if (v < 128)\n\n                v = 128 - v;\n\n            *samples++ = v;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_ALAW:\n\n    case AV_CODEC_ID_PCM_MULAW:\n\n        for (; n > 0; n--) {\n\n            AV_WN16A(samples, s->table[*src++]);\n\n            samples += 2;\n\n        }\n\n        break;\n\n    case AV_CODEC_ID_PCM_DVD:\n\n    {\n\n        const uint8_t *src8;\n\n        dst_int32_t = (int32_t *)frame->data[0];\n\n        n /= avctx->channels;\n\n        switch (avctx->bits_per_coded_sample) {\n\n        case 20:\n\n            while (n--) {\n\n                c    = avctx->channels;\n\n                src8 = src + 4 * c;\n\n                while (c--) {\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8   & 0xf0) <<  8);\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++ & 0x0f) << 12);\n\n                }\n\n                src = src8;\n\n            }\n\n            break;\n\n        case 24:\n\n            while (n--) {\n\n                c    = avctx->channels;\n\n                src8 = src + 4 * c;\n\n                while (c--) {\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n\n                }\n\n                src = src8;\n\n            }\n\n            break;\n\n        }\n\n        break;\n\n    }\n\n    case AV_CODEC_ID_PCM_LXF:\n\n    {\n\n        int i;\n\n        n /= avctx->channels;\n\n        for (c = 0; c < avctx->channels; c++) {\n\n            dst_int32_t = (int32_t *)frame->extended_data[c];\n\n            for (i = 0; i < n; i++) {\n\n                // extract low 20 bits and expand to 32 bits\n\n                *dst_int32_t++ =  (src[2]         << 28) |\n\n                                  (src[1]         << 20) |\n\n                                  (src[0]         << 12) |\n\n                                 ((src[2] & 0x0F) <<  8) |\n\n                                   src[1];\n\n                // extract high 20 bits and expand to 32 bits\n\n                *dst_int32_t++ =  (src[4]         << 24) |\n\n                                  (src[3]         << 16) |\n\n                                 ((src[2] & 0xF0) <<  8) |\n\n                                  (src[4]         <<  4) |\n\n                                  (src[3]         >>  4);\n\n                src += 5;\n\n            }\n\n        }\n\n        break;\n\n    }\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 25271, "_split": "valid", "_hash": "1ba51f7919fc970e79f0770e78f72463"}
{"project": "FFmpeg", "commit_id": "15c41cb6adc4d6720d51c21f8baebebce923b213", "target": 1, "func": "void ff_thread_await_progress(ThreadFrame *f, int n, int field)\n\n{\n\n    PerThreadContext *p;\n\n    atomic_int *progress = f->progress ? (atomic_int*)f->progress->data : NULL;\n\n\n\n    if (!progress ||\n\n        atomic_load_explicit(&progress[field], memory_order_acquire) >= n)\n\n        return;\n\n\n\n    p = f->owner[field]->internal->thread_ctx;\n\n\n\n    pthread_mutex_lock(&p->progress_mutex);\n\n    if (f->owner[field]->debug&FF_DEBUG_THREADS)\n\n        av_log(f->owner[field], AV_LOG_DEBUG,\n\n               \"thread awaiting %d field %d from %p\\n\", n, field, progress);\n\n    while (atomic_load_explicit(&progress[field], memory_order_relaxed) < n)\n\n        pthread_cond_wait(&p->progress_cond, &p->progress_mutex);\n\n    pthread_mutex_unlock(&p->progress_mutex);\n\n}\n", "idx": 25306, "_split": "valid", "_hash": "64ebda5e7a25d8b3de07c115ccf1d8e0"}
{"project": "FFmpeg", "commit_id": "f0ff20a197dd98d2c0ecef3d183185a5c45c7196", "target": 0, "func": "AVResampleContext *av_resample_init(int out_rate, int in_rate, int filter_size, int phase_shift, int linear, double cutoff){\n\n    AVResampleContext *c= av_mallocz(sizeof(AVResampleContext));\n\n    double factor= FFMIN(out_rate * cutoff / in_rate, 1.0);\n\n    int phase_count= 1<<phase_shift;\n\n    \n\n    c->phase_shift= phase_shift;\n\n    c->phase_mask= phase_count-1;\n\n    c->linear= linear;\n\n\n\n    c->filter_length= FFMAX(ceil(filter_size/factor), 1);\n\n    c->filter_bank= av_mallocz(c->filter_length*(phase_count+1)*sizeof(FELEM));\n\n    av_build_filter(c->filter_bank, factor, c->filter_length, phase_count, 1<<FILTER_SHIFT, 1);\n\n    memcpy(&c->filter_bank[c->filter_length*phase_count+1], c->filter_bank, (c->filter_length-1)*sizeof(FELEM));\n\n    c->filter_bank[c->filter_length*phase_count]= c->filter_bank[c->filter_length - 1];\n\n\n\n    c->src_incr= out_rate;\n\n    c->ideal_dst_incr= c->dst_incr= in_rate * phase_count;\n\n    c->index= -phase_count*((c->filter_length-1)/2);\n\n\n\n    return c;\n\n}\n", "idx": 25347, "_split": "valid", "_hash": "10e7c53af7e4bf62f9328b410e4be5dc"}
{"project": "FFmpeg", "commit_id": "baf2ffd3297b707dbb5794ec568c61091acf5c0c", "target": 0, "func": "static int mov_read_elst(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    MOVStreamContext *sc = c->fc->streams[c->fc->nb_streams-1]->priv_data;\n\n    int i, edit_count;\n\n\n\n    get_byte(pb); /* version */\n\n    get_be24(pb); /* flags */\n\n    edit_count= sc->edit_count = get_be32(pb);     /* entries */\n\n\n\n    for(i=0; i<edit_count; i++){\n\n        int time;\n\n        get_be32(pb); /* Track duration */\n\n        time = get_be32(pb); /* Media time */\n\n        get_be32(pb); /* Media rate */\n\n        if (time != 0)\n\n            av_log(c->fc, AV_LOG_WARNING, \"edit list not starting at 0, \"\n\n                   \"a/v desync might occur, patch welcome\\n\");\n\n    }\n\n    dprintf(c->fc, \"track[%i].edit_count = %i\\n\", c->fc->nb_streams-1, sc->edit_count);\n\n    return 0;\n\n}\n", "idx": 25348, "_split": "valid", "_hash": "d4e16001c4e62b042f3e9d858bcd8b8b"}
{"project": "FFmpeg", "commit_id": "332f9ac4e31ce5e6d0c42ac9e0229d7d1b2b4d60", "target": 0, "func": "static int decode_vop_header(MpegEncContext *s, GetBitContext *gb){\n\n    int time_incr, time_increment;\n\n\n\n    s->pict_type = get_bits(gb, 2) + I_TYPE;\t/* pict type: I = 0 , P = 1 */\n\n    if(s->pict_type==B_TYPE && s->low_delay && s->vol_control_parameters==0 && !(s->flags & CODEC_FLAG_LOW_DELAY)){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"low_delay flag set, but shouldnt, clearing it\\n\");\n\n        s->low_delay=0;\n\n    }\n\n \n\n    s->partitioned_frame= s->data_partitioning && s->pict_type!=B_TYPE;\n\n    if(s->partitioned_frame)\n\n        s->decode_mb= mpeg4_decode_partitioned_mb;\n\n    else\n\n        s->decode_mb= ff_h263_decode_mb;\n\n\n\n    if(s->time_increment_resolution==0){\n\n        s->time_increment_resolution=1;\n\n//        fprintf(stderr, \"time_increment_resolution is illegal\\n\");\n\n    }\n\n    time_incr=0;\n\n    while (get_bits1(gb) != 0) \n\n        time_incr++;\n\n\n\n    check_marker(gb, \"before time_increment\");\n\n    \n\n    if(s->time_increment_bits==0){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"hmm, seems the headers arnt complete, trying to guess time_increment_bits\\n\");\n\n\n\n        for(s->time_increment_bits=1 ;s->time_increment_bits<16; s->time_increment_bits++){\n\n            if(show_bits(gb, s->time_increment_bits+1)&1) break;\n\n        }\n\n\n\n        av_log(s->avctx, AV_LOG_ERROR, \"my guess is %d bits ;)\\n\",s->time_increment_bits);\n\n    }\n\n    \n\n    if(IS_3IV1) time_increment= get_bits1(gb); //FIXME investigate further\n\n    else time_increment= get_bits(gb, s->time_increment_bits);\n\n    \n\n//    printf(\"%d %X\\n\", s->time_increment_bits, time_increment);\n\n//printf(\" type:%d modulo_time_base:%d increment:%d\\n\", s->pict_type, time_incr, time_increment);\n\n    if(s->pict_type!=B_TYPE){\n\n        s->last_time_base= s->time_base;\n\n        s->time_base+= time_incr;\n\n        s->time= s->time_base*s->time_increment_resolution + time_increment;\n\n        if(s->workaround_bugs&FF_BUG_UMP4){\n\n            if(s->time < s->last_non_b_time){\n\n//                fprintf(stderr, \"header is not mpeg4 compatible, broken encoder, trying to workaround\\n\");\n\n                s->time_base++;\n\n                s->time+= s->time_increment_resolution;\n\n            }\n\n        }\n\n        s->pp_time= s->time - s->last_non_b_time;\n\n        s->last_non_b_time= s->time;\n\n    }else{\n\n        s->time= (s->last_time_base + time_incr)*s->time_increment_resolution + time_increment;\n\n        s->pb_time= s->pp_time - (s->last_non_b_time - s->time);\n\n        if(s->pp_time <=s->pb_time || s->pp_time <= s->pp_time - s->pb_time || s->pp_time<=0){\n\n//            printf(\"messed up order, seeking?, skiping current b frame\\n\");\n\n            return FRAME_SKIPED;\n\n        }\n\n        \n\n        if(s->t_frame==0) s->t_frame= s->time - s->last_time_base;\n\n        if(s->t_frame==0) s->t_frame=1; // 1/0 protection\n\n//printf(\"%Ld %Ld %d %d\\n\", s->last_non_b_time, s->time, s->pp_time, s->t_frame); fflush(stdout);\n\n        s->pp_field_time= (  ROUNDED_DIV(s->last_non_b_time, s->t_frame) \n\n                           - ROUNDED_DIV(s->last_non_b_time - s->pp_time, s->t_frame))*2;\n\n        s->pb_field_time= (  ROUNDED_DIV(s->time, s->t_frame) \n\n                           - ROUNDED_DIV(s->last_non_b_time - s->pp_time, s->t_frame))*2;\n\n    }\n\n    \n\n    s->current_picture_ptr->pts= s->time*1000LL*1000LL / s->time_increment_resolution;\n\n    if(s->avctx->debug&FF_DEBUG_PTS)\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"MPEG4 PTS: %f\\n\", s->current_picture_ptr->pts/(1000.0*1000.0));\n\n    \n\n    check_marker(gb, \"before vop_coded\");\n\n    \n\n    /* vop coded */\n\n    if (get_bits1(gb) != 1){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"vop not coded\\n\");\n\n        return FRAME_SKIPED;\n\n    }\n\n//printf(\"time %d %d %d || %Ld %Ld %Ld\\n\", s->time_increment_bits, s->time_increment_resolution, s->time_base,\n\n//s->time, s->last_non_b_time, s->last_non_b_time - s->pp_time);  \n\n    if (s->shape != BIN_ONLY_SHAPE && ( s->pict_type == P_TYPE\n\n                          || (s->pict_type == S_TYPE && s->vol_sprite_usage==GMC_SPRITE))) {\n\n        /* rounding type for motion estimation */\n\n\ts->no_rounding = get_bits1(gb);\n\n    } else {\n\n\ts->no_rounding = 0;\n\n    }\n\n//FIXME reduced res stuff\n\n\n\n     if (s->shape != RECT_SHAPE) {\n\n         if (s->vol_sprite_usage != 1 || s->pict_type != I_TYPE) {\n\n             int width, height, hor_spat_ref, ver_spat_ref;\n\n \n\n             width = get_bits(gb, 13);\n\n             skip_bits1(gb);   /* marker */\n\n             height = get_bits(gb, 13);\n\n             skip_bits1(gb);   /* marker */\n\n             hor_spat_ref = get_bits(gb, 13); /* hor_spat_ref */\n\n             skip_bits1(gb);   /* marker */\n\n             ver_spat_ref = get_bits(gb, 13); /* ver_spat_ref */\n\n         }\n\n         skip_bits1(gb); /* change_CR_disable */\n\n \n\n         if (get_bits1(gb) != 0) {\n\n             skip_bits(gb, 8); /* constant_alpha_value */\n\n         }\n\n     }\n\n//FIXME complexity estimation stuff\n\n     \n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         s->intra_dc_threshold= mpeg4_dc_threshold[ get_bits(gb, 3) ];\n\n         if(!s->progressive_sequence){\n\n             s->top_field_first= get_bits1(gb);\n\n             s->alternate_scan= get_bits1(gb);\n\n         }else\n\n             s->alternate_scan= 0;\n\n     }\n\n\n\n     if(s->alternate_scan){\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_vertical_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n     } else{\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->inter_scantable  , ff_zigzag_direct);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_scantable  , ff_zigzag_direct);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_h_scantable, ff_alternate_horizontal_scan);\n\n         ff_init_scantable(s->dsp.idct_permutation, &s->intra_v_scantable, ff_alternate_vertical_scan);\n\n     }\n\n \n\n     if(s->pict_type == S_TYPE && (s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE)){\n\n         mpeg4_decode_sprite_trajectory(s);\n\n         if(s->sprite_brightness_change) av_log(s->avctx, AV_LOG_ERROR, \"sprite_brightness_change not supported\\n\");\n\n         if(s->vol_sprite_usage==STATIC_SPRITE) av_log(s->avctx, AV_LOG_ERROR, \"static sprite not supported\\n\");\n\n     }\n\n\n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         s->qscale = get_bits(gb, s->quant_precision);\n\n         if(s->qscale==0){\n\n             av_log(s->avctx, AV_LOG_ERROR, \"Error, header damaged or not MPEG4 header (qscale=0)\\n\");\n\n             return -1; // makes no sense to continue, as there is nothing left from the image then\n\n         }\n\n  \n\n         if (s->pict_type != I_TYPE) {\n\n             s->f_code = get_bits(gb, 3);\t/* fcode_for */\n\n             if(s->f_code==0){\n\n                 av_log(s->avctx, AV_LOG_ERROR, \"Error, header damaged or not MPEG4 header (f_code=0)\\n\");\n\n                 return -1; // makes no sense to continue, as the MV decoding will break very quickly\n\n             }\n\n         }else\n\n             s->f_code=1;\n\n     \n\n         if (s->pict_type == B_TYPE) {\n\n             s->b_code = get_bits(gb, 3);\n\n         }else\n\n             s->b_code=1;\n\n\n\n         if(s->avctx->debug&FF_DEBUG_PICT_INFO){\n\n             av_log(s->avctx, AV_LOG_DEBUG, \"qp:%d fc:%d,%d %s size:%d pro:%d alt:%d top:%d %spel part:%d resync:%d w:%d a:%d rnd:%d vot:%d%s dc:%d\\n\", \n\n                 s->qscale, s->f_code, s->b_code, \n\n                 s->pict_type == I_TYPE ? \"I\" : (s->pict_type == P_TYPE ? \"P\" : (s->pict_type == B_TYPE ? \"B\" : \"S\")), \n\n                 gb->size_in_bits,s->progressive_sequence, s->alternate_scan, s->top_field_first, \n\n                 s->quarter_sample ? \"q\" : \"h\", s->data_partitioning, s->resync_marker, s->num_sprite_warping_points,\n\n                 s->sprite_warping_accuracy, 1-s->no_rounding, s->vo_type, s->vol_control_parameters ? \" VOLC\" : \" \", s->intra_dc_threshold); \n\n         }\n\n\n\n         if(!s->scalability){\n\n             if (s->shape!=RECT_SHAPE && s->pict_type!=I_TYPE) {\n\n                 skip_bits1(gb); // vop shape coding type\n\n             }\n\n         }else{\n\n             if(s->enhancement_type){\n\n                 int load_backward_shape= get_bits1(gb);\n\n                 if(load_backward_shape){\n\n                     av_log(s->avctx, AV_LOG_ERROR, \"load backward shape isnt supported\\n\");\n\n                 }\n\n             }\n\n             skip_bits(gb, 2); //ref_select_code\n\n         }\n\n     }\n\n     /* detect buggy encoders which dont set the low_delay flag (divx4/xvid/opendivx)*/\n\n     // note we cannot detect divx5 without b-frames easyly (allthough its buggy too)\n\n     if(s->vo_type==0 && s->vol_control_parameters==0 && s->divx_version==0 && s->picture_number==0){\n\n         av_log(s->avctx, AV_LOG_ERROR, \"looks like this file was encoded with (divx4/(old)xvid/opendivx) -> forcing low_delay flag\\n\");\n\n         s->low_delay=1;\n\n     }\n\n\n\n     s->picture_number++; // better than pic number==0 allways ;)\n\n\n\n     s->y_dc_scale_table= ff_mpeg4_y_dc_scale_table; //FIXME add short header support \n\n     s->c_dc_scale_table= ff_mpeg4_c_dc_scale_table;\n\n\n\n     if(s->workaround_bugs&FF_BUG_EDGE){\n\n         s->h_edge_pos= s->width;\n\n         s->v_edge_pos= s->height;\n\n     }\n\n     return 0;\n\n}\n", "idx": 25368, "_split": "valid", "_hash": "b35db04911c63a5ef04234b26df02148"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(uyvytoyv12)(const uint8_t *src, uint8_t *ydst, uint8_t *udst, uint8_t *vdst,\n\n\tlong width, long height,\n\n\tlong lumStride, long chromStride, long srcStride)\n\n{\n\n\tlong y;\n\n\tconst long chromWidth= width>>1;\n\n\tfor(y=0; y<height; y+=2)\n\n\t{\n\n#ifdef HAVE_MMX\n\n\t\tasm volatile(\n\n\t\t\t\"xorl %%eax, %%eax\t\t\\n\\t\"\n\n\t\t\t\"pcmpeqw %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"psrlw $8, %%mm7\t\t\\n\\t\" // FF,00,FF,00...\n\n\t\t\tASMALIGN(4)\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%0, %%eax, 4)\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%eax, 4), %%mm0\t\\n\\t\" // UYVY UYVY(0)\n\n\t\t\t\"movq 8(%0, %%eax, 4), %%mm1\t\\n\\t\" // UYVY UYVY(4)\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // UYVY UYVY(0)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // UYVY UYVY(4)\n\n\t\t\t\"pand %%mm7, %%mm0\t\t\\n\\t\" // U0V0 U0V0(0)\n\n\t\t\t\"pand %%mm7, %%mm1\t\t\\n\\t\" // U0V0 U0V0(4)\n\n\t\t\t\"psrlw $8, %%mm2\t\t\\n\\t\" // Y0Y0 Y0Y0(0)\n\n\t\t\t\"psrlw $8, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(4)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // YYYY YYYY(0)\n\n\n\n\t\t\tMOVNTQ\" %%mm2, (%1, %%eax, 2)\t\\n\\t\"\n\n\n\n\t\t\t\"movq 16(%0, %%eax, 4), %%mm1\t\\n\\t\" // UYVY UYVY(8)\n\n\t\t\t\"movq 24(%0, %%eax, 4), %%mm2\t\\n\\t\" // UYVY UYVY(12)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // UYVY UYVY(8)\n\n\t\t\t\"movq %%mm2, %%mm4\t\t\\n\\t\" // UYVY UYVY(12)\n\n\t\t\t\"pand %%mm7, %%mm1\t\t\\n\\t\" // U0V0 U0V0(8)\n\n\t\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\" // U0V0 U0V0(12)\n\n\t\t\t\"psrlw $8, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(8)\n\n\t\t\t\"psrlw $8, %%mm4\t\t\\n\\t\" // Y0Y0 Y0Y0(12)\n\n\t\t\t\"packuswb %%mm2, %%mm1\t\t\\n\\t\" // UVUV UVUV(8)\n\n\t\t\t\"packuswb %%mm4, %%mm3\t\t\\n\\t\" // YYYY YYYY(8)\n\n\n\n\t\t\tMOVNTQ\" %%mm3, 8(%1, %%eax, 2)\t\\n\\t\"\n\n\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // UVUV UVUV(8)\n\n\t\t\t\"psrlw $8, %%mm0\t\t\\n\\t\" // V0V0 V0V0(0)\n\n\t\t\t\"psrlw $8, %%mm1\t\t\\n\\t\" // V0V0 V0V0(8)\n\n\t\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\" // U0U0 U0U0(0)\n\n\t\t\t\"pand %%mm7, %%mm3\t\t\\n\\t\" // U0U0 U0U0(8)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // VVVV VVVV(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // UUUU UUUU(0)\n\n\n\n\t\t\tMOVNTQ\" %%mm0, (%3, %%eax)\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm2, (%2, %%eax)\t\\n\\t\"\n\n\n\n\t\t\t\"addl $8, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\"cmpl %4, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t\t::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n\t\t\t: \"memory\", \"%eax\"\n\n\t\t);\n\n\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\n\n\t\tasm volatile(\n\n\t\t\t\"xorl %%eax, %%eax\t\t\\n\\t\"\n\n\t\t\tASMALIGN(4)\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%0, %%eax, 4)\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%eax, 4), %%mm0\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"movq 8(%0, %%eax, 4), %%mm1\t\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"movq 16(%0, %%eax, 4), %%mm2\t\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"movq 24(%0, %%eax, 4), %%mm3\t\\n\\t\" // YUYV YUYV(12)\n\n\t\t\t\"psrlw $8, %%mm0\t\t\\n\\t\" // Y0Y0 Y0Y0(0)\n\n\t\t\t\"psrlw $8, %%mm1\t\t\\n\\t\" // Y0Y0 Y0Y0(4)\n\n\t\t\t\"psrlw $8, %%mm2\t\t\\n\\t\" // Y0Y0 Y0Y0(8)\n\n\t\t\t\"psrlw $8, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(12)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // YYYY YYYY(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // YYYY YYYY(8)\n\n\n\n\t\t\tMOVNTQ\" %%mm0, (%1, %%eax, 2)\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm2, 8(%1, %%eax, 2)\t\\n\\t\"\n\n\n\n\t\t\t\"addl $8, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\"cmpl %4, %%eax\t\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n\t\t\t::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n\t\t\t: \"memory\", \"%eax\"\n\n\t\t);\n\n#else\n\n\t\tlong i;\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tudst[i] \t= src[4*i+0];\n\n\t\t\tydst[2*i+0] \t= src[4*i+1];\n\n\t\t\tvdst[i] \t= src[4*i+2];\n\n\t\t\tydst[2*i+1] \t= src[4*i+3];\n\n\t\t}\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tydst[2*i+0] \t= src[4*i+1];\n\n\t\t\tydst[2*i+1] \t= src[4*i+3];\n\n\t\t}\n\n#endif\n\n\t\tudst += chromStride;\n\n\t\tvdst += chromStride;\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\t}\n\n#ifdef HAVE_MMX\n\nasm volatile(   EMMS\" \\n\\t\"\n\n        \tSFENCE\" \\n\\t\"\n\n        \t:::\"memory\");\n\n#endif\n\n}\n", "idx": 25375, "_split": "valid", "_hash": "34170a26b9ef0b2d1140d77b8407bf83"}
{"project": "FFmpeg", "commit_id": "06205b5efdcf0bc4c5463bfdd02f09b5f79fc4cd", "target": 1, "func": "static int hls_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    HLSContext *c = s->priv_data;\n\n    int ret, i, minvariant = -1;\n\n\n\n    if (c->first_packet) {\n\n        recheck_discard_flags(s, 1);\n\n        c->first_packet = 0;\n\n    }\n\n\n\nstart:\n\n    c->end_of_segment = 0;\n\n    for (i = 0; i < c->n_variants; i++) {\n\n        struct variant *var = c->variants[i];\n\n        /* Make sure we've got one buffered packet from each open variant\n\n         * stream */\n\n        if (var->needed && !var->pkt.data) {\n\n            while (1) {\n\n                int64_t ts_diff;\n\n                AVStream *st;\n\n                ret = av_read_frame(var->ctx, &var->pkt);\n\n                if (ret < 0) {\n\n                    if (!var->pb.eof_reached)\n\n                        return ret;\n\n\n                    break;\n\n                } else {\n\n                    if (c->first_timestamp == AV_NOPTS_VALUE &&\n\n                        var->pkt.dts       != AV_NOPTS_VALUE)\n\n                        c->first_timestamp = av_rescale_q(var->pkt.dts,\n\n                            var->ctx->streams[var->pkt.stream_index]->time_base,\n\n                            AV_TIME_BASE_Q);\n\n                }\n\n\n\n                if (c->seek_timestamp == AV_NOPTS_VALUE)\n\n                    break;\n\n\n\n                if (var->pkt.dts == AV_NOPTS_VALUE) {\n\n                    c->seek_timestamp = AV_NOPTS_VALUE;\n\n                    break;\n\n                }\n\n\n\n                st = var->ctx->streams[var->pkt.stream_index];\n\n                ts_diff = av_rescale_rnd(var->pkt.dts, AV_TIME_BASE,\n\n                                         st->time_base.den, AV_ROUND_DOWN) -\n\n                          c->seek_timestamp;\n\n                if (ts_diff >= 0 && (c->seek_flags  & AVSEEK_FLAG_ANY ||\n\n                                     var->pkt.flags & AV_PKT_FLAG_KEY)) {\n\n                    c->seek_timestamp = AV_NOPTS_VALUE;\n\n                    break;\n\n                }\n\n\n\n            }\n\n        }\n\n        /* Check if this stream still is on an earlier segment number, or\n\n         * has the packet with the lowest dts */\n\n        if (var->pkt.data) {\n\n            struct variant *minvar = c->variants[minvariant];\n\n            if (minvariant < 0 || var->cur_seq_no < minvar->cur_seq_no) {\n\n                minvariant = i;\n\n            } else if (var->cur_seq_no == minvar->cur_seq_no) {\n\n                int64_t dts     =    var->pkt.dts;\n\n                int64_t mindts  = minvar->pkt.dts;\n\n                AVStream *st    =    var->ctx->streams[var->pkt.stream_index];\n\n                AVStream *minst = minvar->ctx->streams[minvar->pkt.stream_index];\n\n\n\n                if (dts == AV_NOPTS_VALUE) {\n\n                    minvariant = i;\n\n                } else if (mindts != AV_NOPTS_VALUE) {\n\n                    if (st->start_time    != AV_NOPTS_VALUE)\n\n                        dts    -= st->start_time;\n\n                    if (minst->start_time != AV_NOPTS_VALUE)\n\n                        mindts -= minst->start_time;\n\n\n\n                    if (av_compare_ts(dts, st->time_base,\n\n                                      mindts, minst->time_base) < 0)\n\n                        minvariant = i;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    if (c->end_of_segment) {\n\n        if (recheck_discard_flags(s, 0))\n\n            goto start;\n\n    }\n\n    /* If we got a packet, return it */\n\n    if (minvariant >= 0) {\n\n        *pkt = c->variants[minvariant]->pkt;\n\n        pkt->stream_index += c->variants[minvariant]->stream_offset;\n\n        reset_packet(&c->variants[minvariant]->pkt);\n\n        return 0;\n\n    }\n\n    return AVERROR_EOF;\n\n}", "idx": 25383, "_split": "valid", "_hash": "7bd851ad100c1b205caed99baff06966"}
{"project": "FFmpeg", "commit_id": "1a3598aae768465a8efc8475b6df5a8261bc62fc", "target": 1, "func": "static int jpeg2000_decode_packets(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile)\n\n{\n\n    int layno, reslevelno, compno, precno, ok_reslevel, ret;\n\n    uint8_t prog_order = tile->codsty[0].prog_order;\n\n    uint16_t x;\n\n    uint16_t y;\n\n\n\n    s->bit_index = 8;\n\n    switch (prog_order) {\n\n    case JPEG2000_PGOD_LRCP:\n\n        for (layno = 0; layno < tile->codsty[0].nlayers; layno++) {\n\n            ok_reslevel = 1;\n\n            for (reslevelno = 0; ok_reslevel; reslevelno++) {\n\n                ok_reslevel = 0;\n\n                for (compno = 0; compno < s->ncomponents; compno++) {\n\n                    Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n                    Jpeg2000QuantStyle *qntsty  = tile->qntsty + compno;\n\n                    if (reslevelno < codsty->nreslevels) {\n\n                        Jpeg2000ResLevel *rlevel = tile->comp[compno].reslevel +\n\n                                                   reslevelno;\n\n                        ok_reslevel = 1;\n\n                        for (precno = 0; precno < rlevel->num_precincts_x * rlevel->num_precincts_y; precno++)\n\n                            if ((ret = jpeg2000_decode_packet(s,\n\n                                                              codsty, rlevel,\n\n                                                              precno, layno,\n\n                                                              qntsty->expn + (reslevelno ? 3 * (reslevelno - 1) + 1 : 0),\n\n                                                              qntsty->nguardbits)) < 0)\n\n                                return ret;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        break;\n\n\n\n    case JPEG2000_PGOD_CPRL:\n\n        for (compno = 0; compno < s->ncomponents; compno++) {\n\n            Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n            Jpeg2000QuantStyle *qntsty  = tile->qntsty + compno;\n\n\n\n            /* Set bit stream buffer address according to tile-part.\n\n             * For DCinema one tile-part per component, so can be\n\n             * indexed by component. */\n\n            s->buf = tile->tile_part[compno].tp_start_bstrm;\n\n\n\n            /* Position loop (y axis)\n\n             * TODO: Automate computing of step 256.\n\n             * Fixed here, but to be computed before entering here. */\n\n            for (y = 0; y < s->height; y += 256) {\n\n                /* Position loop (y axis)\n\n                 * TODO: automate computing of step 256.\n\n                 * Fixed here, but to be computed before entering here. */\n\n                for (x = 0; x < s->width; x += 256) {\n\n                    for (reslevelno = 0; reslevelno < codsty->nreslevels; reslevelno++) {\n\n                        uint16_t prcx, prcy;\n\n                        uint8_t reducedresno = codsty->nreslevels - 1 -reslevelno; //  ==> N_L - r\n\n                        Jpeg2000ResLevel *rlevel = tile->comp[compno].reslevel + reslevelno;\n\n\n\n                        if (!((y % (1 << (rlevel->log2_prec_height + reducedresno)) == 0) ||\n\n                              (y == 0))) // TODO: 2nd condition simplified as try0 always =0 for dcinema\n\n                            continue;\n\n\n\n                        if (!((x % (1 << (rlevel->log2_prec_width + reducedresno)) == 0) ||\n\n                              (x == 0))) // TODO: 2nd condition simplified as try0 always =0 for dcinema\n\n                            continue;\n\n\n\n                        // check if a precinct exists\n\n                        prcx   = ff_jpeg2000_ceildivpow2(x, reducedresno) >> rlevel->log2_prec_width;\n\n                        prcy   = ff_jpeg2000_ceildivpow2(y, reducedresno) >> rlevel->log2_prec_height;\n\n                        precno = prcx + rlevel->num_precincts_x * prcy;\n\n                        for (layno = 0; layno < tile->codsty[0].nlayers; layno++) {\n\n                            if ((ret = jpeg2000_decode_packet(s, codsty, rlevel,\n\n                                                              precno, layno,\n\n                                                              qntsty->expn + (reslevelno ? 3 * (reslevelno - 1) + 1 : 0),\n\n                                                              qntsty->nguardbits)) < 0)\n\n                                return ret;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        break;\n\n\n\n    default:\n\n        break;\n\n    }\n\n\n\n    /* EOC marker reached */\n\n    s->buf += 2;\n\n\n\n    return 0;\n\n}\n", "idx": 25460, "_split": "valid", "_hash": "714f3bc24fef4aa8b2ea138e6c941412"}
{"project": "FFmpeg", "commit_id": "53e0d5d7247548743e13c59c35e59fc2161e9582", "target": 1, "func": "static int io_open_default(AVFormatContext *s, AVIOContext **pb,\n                           const char *url, int flags, AVDictionary **options)\n{\n#if FF_API_OLD_OPEN_CALLBACKS\nFF_DISABLE_DEPRECATION_WARNINGS\n    if (s->open_cb)\n        return s->open_cb(s, pb, url, flags, &s->interrupt_callback, options);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n    return ffio_open_whitelist(pb, url, flags, &s->interrupt_callback, options, s->protocol_whitelist, s->protocol_blacklist);\n}", "idx": 25466, "_split": "valid", "_hash": "c90f1715c3a9b752a0ef799effc3dc0d"}
{"project": "FFmpeg", "commit_id": "f4ae3cce64bd46b1d539bdeac39753f83015f114", "target": 1, "func": "static void rstrip_spaces_buf(AVBPrint *buf)\n\n{\n\n    while (buf->len > 0 && buf->str[buf->len - 1] == ' ')\n\n        buf->str[--buf->len] = 0;\n\n}\n", "idx": 25477, "_split": "valid", "_hash": "9a5c98188857c94c23c8a00b21f631d4"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(rgb24ToY)(uint8_t *dst, const uint8_t *src, long width, uint32_t *unused)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    RENAME(bgr24ToY_mmx)(dst, src, width, PIX_FMT_RGB24);\n\n#else\n\n    int i;\n\n    for (i=0; i<width; i++) {\n\n        int r= src[i*3+0];\n\n        int g= src[i*3+1];\n\n        int b= src[i*3+2];\n\n\n\n        dst[i]= ((RY*r + GY*g + BY*b + (33<<(RGB2YUV_SHIFT-1)))>>RGB2YUV_SHIFT);\n\n    }\n\n#endif\n\n}\n", "idx": 25481, "_split": "valid", "_hash": "ae8dc5acba7e68db988cbf767809c829"}
{"project": "FFmpeg", "commit_id": "6c23a85000fd5956a2820495b2a081f65d03b962", "target": 1, "func": "static int compand_drain(AVFilterLink *outlink)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    CompandContext *s    = ctx->priv;\n\n    const int channels   = outlink->channels;\n\n    AVFrame *frame       = NULL;\n\n    int chan, i, dindex;\n\n\n\n    /* 2048 is to limit output frame size during drain */\n\n    frame = ff_get_audio_buffer(outlink, FFMIN(2048, s->delay_count));\n\n    if (!frame)\n\n        return AVERROR(ENOMEM);\n\n    frame->pts = s->pts;\n\n    s->pts += av_rescale_q(frame->nb_samples,\n\n            (AVRational){ 1, outlink->sample_rate }, outlink->time_base);\n\n\n\n\n    for (chan = 0; chan < channels; chan++) {\n\n        AVFrame *delay_frame = s->delay_frame;\n\n        double *dbuf = (double *)delay_frame->extended_data[chan];\n\n        double *dst = (double *)frame->extended_data[chan];\n\n        ChanParam *cp = &s->channels[chan];\n\n\n\n        dindex = s->delay_index;\n\n        for (i = 0; i < frame->nb_samples; i++) {\n\n            dst[i] = av_clipd(dbuf[dindex] * get_volume(s, cp->volume),\n\n                    -1, 1);\n\n            dindex = MOD(dindex + 1, s->delay_samples);\n\n        }\n\n    }\n\n    s->delay_count -= frame->nb_samples;\n\n    s->delay_index = dindex;\n\n\n\n    return ff_filter_frame(outlink, frame);\n\n}", "idx": 25489, "_split": "valid", "_hash": "f1a05ac588df9a755388d3603b23fe11"}
{"project": "FFmpeg", "commit_id": "74ef8b434d8d8ef02bee6a5394da849136ed1bf1", "target": 1, "func": "static int rtsp_read_packet(AVFormatContext *s,\n\n                            AVPacket *pkt)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    RTSPStream *rtsp_st;\n\n    int ret, len;\n\n    uint8_t buf[RTP_MAX_PACKET_LENGTH];\n\n\n\n    /* get next frames from the same RTP packet */\n\n    if (rt->cur_rtp) {\n\n        ret = rtp_parse_packet(rt->cur_rtp, pkt, NULL, 0);\n\n        if (ret == 0) {\n\n            rt->cur_rtp = NULL;\n\n            return 0;\n\n        } else if (ret == 1) {\n\n            return 0;\n\n        } else {\n\n            rt->cur_rtp = NULL;\n\n        }\n\n    }\n\n\n\n    /* read next RTP packet */\n\n redo:\n\n    switch(rt->protocol) {\n\n    default:\n\n    case RTSP_PROTOCOL_RTP_TCP:\n\n        len = tcp_read_packet(s, &rtsp_st, buf, sizeof(buf));\n\n        break;\n\n    case RTSP_PROTOCOL_RTP_UDP:\n\n    case RTSP_PROTOCOL_RTP_UDP_MULTICAST:\n\n        len = udp_read_packet(s, &rtsp_st, buf, sizeof(buf));\n\n        if (rtsp_st->rtp_ctx)\n\n            rtp_check_and_send_back_rr(rtsp_st->rtp_ctx, len);\n\n        break;\n\n    }\n\n    if (len < 0)\n\n        return AVERROR_IO;\n\n    ret = rtp_parse_packet(rtsp_st->rtp_ctx, pkt, buf, len);\n\n    if (ret < 0)\n\n        goto redo;\n\n    if (ret == 1) {\n\n        /* more packets may follow, so we save the RTP context */\n\n        rt->cur_rtp = rtsp_st->rtp_ctx;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25500, "_split": "valid", "_hash": "720ea69abb2c52678e556e124e0bb197"}
{"project": "FFmpeg", "commit_id": "d371c3c2e2830d9783465ecfe1ab7d93351083b7", "target": 1, "func": "static int source_config_props(AVFilterLink *outlink)\n\n{\n\n    AVFilterContext *ctx = outlink->src;\n\n    Frei0rContext *s = ctx->priv;\n\n\n\n    if (av_image_check_size(s->w, s->h, 0, ctx) < 0)\n\n        return AVERROR(EINVAL);\n\n    outlink->w = s->w;\n\n    outlink->h = s->h;\n\n    outlink->time_base = s->time_base;\n\n\n\n\n\n    if (!(s->instance = s->construct(outlink->w, outlink->h))) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Impossible to load frei0r instance\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    return set_params(ctx, s->params);\n\n}", "idx": 25528, "_split": "valid", "_hash": "389439f0dbe8125e2a9f53eb2dcbd840"}
{"project": "FFmpeg", "commit_id": "51b0694bc051cda2bfed048a35e694d1047c6ef0", "target": 0, "func": "const DVprofile* ff_dv_frame_profile2(AVCodecContext* codec, const DVprofile *sys,\n\n                                  const uint8_t* frame, unsigned buf_size)\n\n{\n\n   int i;\n\n\n\n   int dsf = (frame[3] & 0x80) >> 7;\n\n\n\n   int stype = frame[80*5 + 48 + 3] & 0x1f;\n\n\n\n   /* 576i50 25Mbps 4:1:1 is a special case */\n\n   if (dsf == 1 && stype == 0 && frame[4] & 0x07 /* the APT field */) {\n\n       return &dv_profiles[2];\n\n   }\n\n\n\n   if(codec && codec->codec_tag==AV_RL32(\"dvsd\") &&  codec->width==720 && codec->height==576)\n\n       return &dv_profiles[1];\n\n\n\n   for (i=0; i<FF_ARRAY_ELEMS(dv_profiles); i++)\n\n       if (dsf == dv_profiles[i].dsf && stype == dv_profiles[i].video_stype)\n\n           return &dv_profiles[i];\n\n\n\n   /* check if old sys matches and assumes corrupted input */\n\n   if (sys && buf_size == sys->frame_size)\n\n       return sys;\n\n\n\n   return NULL;\n\n}\n", "idx": 25577, "_split": "valid", "_hash": "468bf49e4ce28ae4533e4dd1b2745931"}
{"project": "FFmpeg", "commit_id": "caedd51e56e2ad47991a1b8bddcfaa8f7094a060", "target": 1, "func": "static int mxf_compute_sample_count(MXFContext *mxf, int stream_index, uint64_t *sample_count)\n\n{\n\n    int i, total = 0, size = 0;\n\n    AVStream *st = mxf->fc->streams[stream_index];\n\n    MXFTrack *track = st->priv_data;\n\n    AVRational time_base = av_inv_q(track->edit_rate);\n\n    AVRational sample_rate = av_inv_q(st->time_base);\n\n    const MXFSamplesPerFrame *spf = NULL;\n\n\n\n    if ((sample_rate.num / sample_rate.den) == 48000)\n\n        spf = ff_mxf_get_samples_per_frame(mxf->fc, time_base);\n\n    if (!spf) {\n\n        int remainder = (sample_rate.num * time_base.num) % (time_base.den * sample_rate.den);\n\n        *sample_count = av_q2d(av_mul_q((AVRational){mxf->current_edit_unit, 1},\n\n                                        av_mul_q(sample_rate, time_base)));\n\n        if (remainder)\n\n            av_log(mxf->fc, AV_LOG_WARNING,\n\n                   \"seeking detected on stream #%d with time base (%d/%d) and sample rate (%d/%d), audio pts won't be accurate.\\n\",\n\n                   stream_index, time_base.num, time_base.den, sample_rate.num, sample_rate.den);\n\n        return 0;\n\n    }\n\n\n\n    while (spf->samples_per_frame[size]) {\n\n        total += spf->samples_per_frame[size];\n\n        size++;\n\n    }\n\n\n\n    av_assert2(size);\n\n\n\n    *sample_count = (mxf->current_edit_unit / size) * total;\n\n    for (i = 0; i < mxf->current_edit_unit % size; i++) {\n\n        *sample_count += spf->samples_per_frame[i];\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 25610, "_split": "valid", "_hash": "59d6e0d64de31a6260873bfd0cb273c9"}
{"project": "FFmpeg", "commit_id": "c7d5049c98ee4a0c9c0b6c085892a875b6302f2f", "target": 0, "func": "int mpeg4_decode_picture_header(MpegEncContext * s)\n\n{\n\n    int time_incr, startcode, state, v;\n\n\n\n redo:\n\n    /* search next start code */\n\n    align_get_bits(&s->gb);\n\n    state = 0xff;\n\n    for(;;) {\n\n        v = get_bits(&s->gb, 8);\n\n        if (state == 0x000001) {\n\n            state = ((state << 8) | v) & 0xffffff;\n\n            startcode = state;\n\n            break;\n\n        }\n\n        state = ((state << 8) | v) & 0xffffff;\n\n        if( get_bits_count(&s->gb) > s->gb.size*8){\n\n            printf(\"no VOP startcode found\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n//printf(\"startcode %X %d\\n\", startcode, get_bits_count(&s->gb));\n\n    if (startcode == 0x120) { // Video Object Layer\n\n        int width, height, vo_ver_id;\n\n\n\n        /* vol header */\n\n        skip_bits(&s->gb, 1); /* random access */\n\n        skip_bits(&s->gb, 8); /* vo_type */\n\n        if (get_bits1(&s->gb) != 0) { /* is_ol_id */\n\n            vo_ver_id = get_bits(&s->gb, 4); /* vo_ver_id */\n\n            skip_bits(&s->gb, 3); /* vo_priority */\n\n        } else {\n\n            vo_ver_id = 1;\n\n        }\n\n        \n\n        s->aspect_ratio_info= get_bits(&s->gb, 4);\n\n\tif(s->aspect_ratio_info == EXTENDET_PAR){\n\n            skip_bits(&s->gb, 8); //par_width\n\n            skip_bits(&s->gb, 8); // par_height\n\n        }\n\n        if(get_bits1(&s->gb)){ /* vol control parameter */\n\n            printf(\"vol control parameter not supported\\n\");\n\n            return -1;   \n\n        }\n\n        s->shape = get_bits(&s->gb, 2); /* vol shape */\n\n        if(s->shape != RECT_SHAPE) printf(\"only rectangular vol supported\\n\");\n\n        if(s->shape == GRAY_SHAPE && vo_ver_id != 1){\n\n            printf(\"Gray shape not supported\\n\");\n\n            skip_bits(&s->gb, 4);  //video_object_layer_shape_extension\n\n        }\n\n\n\n        skip_bits1(&s->gb);   /* marker */\n\n        \n\n        s->time_increment_resolution = get_bits(&s->gb, 16);\n\n        s->time_increment_bits = av_log2(s->time_increment_resolution - 1) + 1;\n\n        if (s->time_increment_bits < 1)\n\n            s->time_increment_bits = 1;\n\n        skip_bits1(&s->gb);   /* marker */\n\n\n\n        if (get_bits1(&s->gb) != 0) {   /* fixed_vop_rate  */\n\n            skip_bits(&s->gb, s->time_increment_bits);\n\n        }\n\n\n\n        if (s->shape != BIN_ONLY_SHAPE) {\n\n            if (s->shape == RECT_SHAPE) {\n\n                skip_bits1(&s->gb);   /* marker */\n\n                width = get_bits(&s->gb, 13);\n\n                skip_bits1(&s->gb);   /* marker */\n\n                height = get_bits(&s->gb, 13);\n\n                skip_bits1(&s->gb);   /* marker */\n\n                if(width && height){ /* they should be non zero but who knows ... */\n\n                    s->width = width;\n\n                    s->height = height;\n\n//                    printf(\"%d %d\\n\", width, height);\n\n                }\n\n            }\n\n            \n\n            if(get_bits1(&s->gb)) printf(\"interlaced not supported\\n\");   /* interlaced */\n\n            if(!get_bits1(&s->gb)) printf(\"OBMC not supported\\n\");   /* OBMC Disable */\n\n            if (vo_ver_id == 1) {\n\n                s->vol_sprite_usage = get_bits1(&s->gb); /* vol_sprite_usage */\n\n            } else {\n\n                s->vol_sprite_usage = get_bits(&s->gb, 2); /* vol_sprite_usage */\n\n            }\n\n            if(s->vol_sprite_usage==STATIC_SPRITE) printf(\"Static Sprites not supported\\n\");\n\n            if(s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE){\n\n                if(s->vol_sprite_usage==STATIC_SPRITE){\n\n                    s->sprite_width = get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                    s->sprite_height= get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                    s->sprite_left  = get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                    s->sprite_top   = get_bits(&s->gb, 13);\n\n                    skip_bits1(&s->gb); /* marker */\n\n                }\n\n                s->num_sprite_warping_points= get_bits(&s->gb, 6);\n\n                s->sprite_warping_accuracy = get_bits(&s->gb, 2);\n\n                s->sprite_brightness_change= get_bits1(&s->gb);\n\n                if(s->vol_sprite_usage==STATIC_SPRITE)\n\n                    s->low_latency_sprite= get_bits1(&s->gb);            \n\n            }\n\n            // FIXME sadct disable bit if verid!=1 && shape not rect\n\n            \n\n            if (get_bits1(&s->gb) == 1) {   /* not_8_bit */\n\n                s->quant_precision = get_bits(&s->gb, 4); /* quant_precision */\n\n                if(get_bits(&s->gb, 4)!=8) printf(\"N-bit not supported\\n\"); /* bits_per_pixel */\n\n            } else {\n\n                s->quant_precision = 5;\n\n            }\n\n            \n\n            // FIXME a bunch of grayscale shape things\n\n            if(get_bits1(&s->gb)) printf(\"Quant-Type not supported\\n\");  /* vol_quant_type */ //FIXME\n\n            if(vo_ver_id != 1)\n\n                 s->quarter_sample= get_bits1(&s->gb);\n\n            else s->quarter_sample=0;\n\n\n\n            if(!get_bits1(&s->gb)) printf(\"Complexity estimation not supported\\n\");\n\n#if 0\n\n            if(get_bits1(&s->gb)) printf(\"resync disable\\n\");\n\n#else\n\n            skip_bits1(&s->gb);   /* resync_marker_disabled */\n\n#endif\n\n            s->data_partioning= get_bits1(&s->gb);\n\n            if(s->data_partioning){\n\n                printf(\"data partitioning not supported\\n\");\n\n                skip_bits1(&s->gb); // reversible vlc\n\n            }\n\n            \n\n            if(vo_ver_id != 1) {\n\n                s->new_pred= get_bits1(&s->gb);\n\n                if(s->new_pred){\n\n                    printf(\"new pred not supported\\n\");\n\n                    skip_bits(&s->gb, 2); /* requested upstream message type */\n\n                    skip_bits1(&s->gb); /* newpred segment type */\n\n                }\n\n                s->reduced_res_vop= get_bits1(&s->gb);\n\n                if(s->reduced_res_vop) printf(\"reduced resolution VOP not supported\\n\");\n\n            }\n\n            else{\n\n                s->new_pred=0;\n\n                s->reduced_res_vop= 0;\n\n            }\n\n\n\n            s->scalability= get_bits1(&s->gb);\n\n            if (s->scalability) {\n\n                printf(\"bad scalability!!!\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n//printf(\"end Data %X %d\\n\", show_bits(&s->gb, 32), get_bits_count(&s->gb)&0x7);\n\n        goto redo;\n\n    } else if (startcode == 0x1b2) { //userdata\n\n        char buf[256];\n\n        int i;\n\n        int e;\n\n        int ver, build;\n\n\n\n//printf(\"user Data %X\\n\", show_bits(&s->gb, 32));\n\n        buf[0]= show_bits(&s->gb, 8);\n\n        for(i=1; i<256; i++){\n\n            buf[i]= show_bits(&s->gb, 16)&0xFF;\n\n            if(buf[i]==0) break;\n\n            skip_bits(&s->gb, 8);\n\n        }\n\n        buf[255]=0;\n\n        e=sscanf(buf, \"DivX%dBuild%d\", &ver, &build);\n\n        if(e==2){\n\n            s->divx_version= ver;\n\n            s->divx_build= build;\n\n            if(s->picture_number==0){\n\n                printf(\"This file was encoded with DivX%d Build%d\\n\", ver, build);\n\n                if(ver==500 && build==413){ //most likely all version are indeed totally buggy but i dunno for sure ...\n\n                    printf(\"WARNING: this version of DivX is not MPEG4 compatible, trying to workaround these bugs...\\n\");\n\n                }else{\n\n                    printf(\"hmm, i havnt seen that version of divx yet, lets assume they fixed these bugs ...\\n\"\n\n                           \"using mpeg4 decoder, if it fails contact the developers (of ffmpeg)\\n\");\n\n                }\n\n            }\n\n        }\n\n//printf(\"User Data: %s\\n\", buf);\n\n        goto redo;\n\n    } else if (startcode != 0x1b6) { //VOP\n\n        goto redo;\n\n    }\n\n\n\n    s->pict_type = get_bits(&s->gb, 2) + 1;\t/* pict type: I = 0 , P = 1 */\n\n//printf(\"pic: %d\\n\", s->pict_type); \n\n    time_incr=0;\n\n    while (get_bits1(&s->gb) != 0) \n\n        time_incr++;\n\n\n\n    check_marker(&s->gb, \"before time_increment\");\n\n    s->time_increment= get_bits(&s->gb, s->time_increment_bits);\n\n    if(s->pict_type!=B_TYPE){\n\n        s->time_base+= time_incr;\n\n        s->last_non_b_time[1]= s->last_non_b_time[0];\n\n        s->last_non_b_time[0]= s->time_base*s->time_increment_resolution + s->time_increment;\n\n    }else{\n\n        s->time= (s->last_non_b_time[1]/s->time_increment_resolution + time_incr)*s->time_increment_resolution;\n\n        s->time+= s->time_increment;\n\n    }\n\n\n\n    if(check_marker(&s->gb, \"before vop_coded\")==0 && s->picture_number==0){\n\n        printf(\"hmm, seems the headers arnt complete, trying to guess time_increment_bits\\n\");\n\n        for(s->time_increment_bits++ ;s->time_increment_bits<16; s->time_increment_bits++){\n\n            if(get_bits1(&s->gb)) break;\n\n        }\n\n        printf(\"my guess is %d bits ;)\\n\",s->time_increment_bits);\n\n    }\n\n    /* vop coded */\n\n    if (get_bits1(&s->gb) != 1)\n\n        goto redo;\n\n//printf(\"time %d %d %d || %d %d %d\\n\", s->time_increment_bits, s->time_increment, s->time_base,\n\n//s->time, s->last_non_b_time[0], s->last_non_b_time[1]);  \n\n    if (s->shape != BIN_ONLY_SHAPE && ( s->pict_type == P_TYPE\n\n                          || (s->pict_type == S_TYPE && s->vol_sprite_usage==GMC_SPRITE))) {\n\n        /* rounding type for motion estimation */\n\n\ts->no_rounding = get_bits1(&s->gb);\n\n    } else {\n\n\ts->no_rounding = 0;\n\n    }\n\n//FIXME reduced res stuff\n\n\n\n     if (s->shape != RECT_SHAPE) {\n\n         if (s->vol_sprite_usage != 1 || s->pict_type != I_TYPE) {\n\n             int width, height, hor_spat_ref, ver_spat_ref;\n\n \n\n             width = get_bits(&s->gb, 13);\n\n             skip_bits1(&s->gb);   /* marker */\n\n             height = get_bits(&s->gb, 13);\n\n             skip_bits1(&s->gb);   /* marker */\n\n             hor_spat_ref = get_bits(&s->gb, 13); /* hor_spat_ref */\n\n             skip_bits1(&s->gb);   /* marker */\n\n             ver_spat_ref = get_bits(&s->gb, 13); /* ver_spat_ref */\n\n         }\n\n         skip_bits1(&s->gb); /* change_CR_disable */\n\n \n\n         if (get_bits1(&s->gb) != 0) {\n\n             skip_bits(&s->gb, 8); /* constant_alpha_value */\n\n         }\n\n     }\n\n//FIXME complexity estimation stuff\n\n     \n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         skip_bits(&s->gb, 3); /* intra dc VLC threshold */\n\n         //FIXME interlaced specific bits\n\n     }\n\n\n\n     if(s->pict_type == S_TYPE && (s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE)){\n\n         if(s->num_sprite_warping_points){\n\n             mpeg4_decode_sprite_trajectory(s);\n\n         }\n\n         if(s->sprite_brightness_change) printf(\"sprite_brightness_change not supported\\n\");\n\n         if(s->vol_sprite_usage==STATIC_SPRITE) printf(\"static sprite not supported\\n\");\n\n     }\n\n\n\n     if (s->shape != BIN_ONLY_SHAPE) {\n\n         /* note: we do not use quant_precision to avoid problem if no\n\n            MPEG4 vol header as it is found on some old opendivx\n\n            movies */\n\n         s->qscale = get_bits(&s->gb, 5);\n\n         if(s->qscale==0){\n\n             printf(\"Error, header damaged or not MPEG4 header (qscale=0)\\n\");\n\n             return -1; // makes no sense to continue, as there is nothing left from the image then\n\n         }\n\n  \n\n         if (s->pict_type != I_TYPE) {\n\n             s->f_code = get_bits(&s->gb, 3);\t/* fcode_for */\n\n             if(s->f_code==0){\n\n                 printf(\"Error, header damaged or not MPEG4 header (f_code=0)\\n\");\n\n                 return -1; // makes no sense to continue, as the MV decoding will break very quickly\n\n             }\n\n         }\n\n         if (s->pict_type == B_TYPE) {\n\n             s->b_code = get_bits(&s->gb, 3);\n\n//printf(\"b-code %d\\n\", s->b_code);\n\n         }\n\n//printf(\"quant:%d fcode:%d\\n\", s->qscale, s->f_code);\n\n\n\n         if(!s->scalability){\n\n             if (s->shape!=RECT_SHAPE && s->pict_type!=I_TYPE) {\n\n                 skip_bits1(&s->gb); // vop shape coding type\n\n             }\n\n         }\n\n     }\n\n     s->picture_number++; // better than pic number==0 allways ;)\n\n     return 0;\n\n}\n", "idx": 25644, "_split": "valid", "_hash": "50714cb88930ae0fde17373def3d9d1a"}
{"project": "FFmpeg", "commit_id": "a6af5da7a2f817d52ea00e2aa93ccf5804afa3e0", "target": 0, "func": "static int resample(SwrContext *s, AudioData *out_param, int out_count,\n\n                             const AudioData * in_param, int in_count){\n\n    AudioData in, out, tmp;\n\n    int ret_sum=0;\n\n    int border=0;\n\n\n\n    av_assert1(s->in_buffer.ch_count == in_param->ch_count);\n\n    av_assert1(s->in_buffer.planar   == in_param->planar);\n\n    av_assert1(s->in_buffer.fmt      == in_param->fmt);\n\n\n\n    tmp=out=*out_param;\n\n    in =  *in_param;\n\n\n\n    do{\n\n        int ret, size, consumed;\n\n        if(!s->resample_in_constraint && s->in_buffer_count){\n\n            buf_set(&tmp, &s->in_buffer, s->in_buffer_index);\n\n            ret= s->resampler->multiple_resample(s->resample, &out, out_count, &tmp, s->in_buffer_count, &consumed);\n\n            out_count -= ret;\n\n            ret_sum += ret;\n\n            buf_set(&out, &out, ret);\n\n            s->in_buffer_count -= consumed;\n\n            s->in_buffer_index += consumed;\n\n\n\n            if(!in_count)\n\n                break;\n\n            if(s->in_buffer_count <= border){\n\n                buf_set(&in, &in, -s->in_buffer_count);\n\n                in_count += s->in_buffer_count;\n\n                s->in_buffer_count=0;\n\n                s->in_buffer_index=0;\n\n                border = 0;\n\n            }\n\n        }\n\n\n\n        if((s->flushed || in_count) && !s->in_buffer_count){\n\n            s->in_buffer_index=0;\n\n            ret= s->resampler->multiple_resample(s->resample, &out, out_count, &in, in_count, &consumed);\n\n            out_count -= ret;\n\n            ret_sum += ret;\n\n            buf_set(&out, &out, ret);\n\n            in_count -= consumed;\n\n            buf_set(&in, &in, consumed);\n\n        }\n\n\n\n        //TODO is this check sane considering the advanced copy avoidance below\n\n        size= s->in_buffer_index + s->in_buffer_count + in_count;\n\n        if(   size > s->in_buffer.count\n\n           && s->in_buffer_count + in_count <= s->in_buffer_index){\n\n            buf_set(&tmp, &s->in_buffer, s->in_buffer_index);\n\n            copy(&s->in_buffer, &tmp, s->in_buffer_count);\n\n            s->in_buffer_index=0;\n\n        }else\n\n            if((ret=swri_realloc_audio(&s->in_buffer, size)) < 0)\n\n                return ret;\n\n\n\n        if(in_count){\n\n            int count= in_count;\n\n            if(s->in_buffer_count && s->in_buffer_count+2 < count && out_count) count= s->in_buffer_count+2;\n\n\n\n            buf_set(&tmp, &s->in_buffer, s->in_buffer_index + s->in_buffer_count);\n\n            copy(&tmp, &in, /*in_*/count);\n\n            s->in_buffer_count += count;\n\n            in_count -= count;\n\n            border += count;\n\n            buf_set(&in, &in, count);\n\n            s->resample_in_constraint= 0;\n\n            if(s->in_buffer_count != count || in_count)\n\n                continue;\n\n        }\n\n        break;\n\n    }while(1);\n\n\n\n    s->resample_in_constraint= !!out_count;\n\n\n\n    return ret_sum;\n\n}\n", "idx": 25694, "_split": "valid", "_hash": "b7506435f5996a648f3e9e7d4d7ee5cd"}
{"project": "FFmpeg", "commit_id": "e398990eb87785e20e065cd3f14d1dbb69df4392", "target": 0, "func": "static int msrle_decode_8_16_24_32(AVCodecContext *avctx, AVPicture *pic,\n\n                                   int depth, GetByteContext *gb)\n\n{\n\n    uint8_t *output, *output_end;\n\n    int p1, p2, line=avctx->height - 1, pos=0, i;\n\n    uint16_t pix16;\n\n    uint32_t pix32;\n\n    unsigned int width= FFABS(pic->linesize[0]) / (depth >> 3);\n\n\n\n    output     = pic->data[0] + (avctx->height - 1) * pic->linesize[0];\n\n    output_end = pic->data[0] +  avctx->height      * pic->linesize[0];\n\n    while (bytestream2_get_bytes_left(gb) > 0) {\n\n        p1 = bytestream2_get_byteu(gb);\n\n        if(p1 == 0) { //Escape code\n\n            p2 = bytestream2_get_byte(gb);\n\n            if(p2 == 0) { //End-of-line\n\n                if (--line < 0) {\n\n                    if (bytestream2_get_be16(gb) == 1) { // end-of-picture\n\n                        return 0;\n\n                    } else {\n\n                        av_log(avctx, AV_LOG_ERROR,\n\n                               \"Next line is beyond picture bounds (%d bytes left)\\n\",\n\n                               bytestream2_get_bytes_left(gb));\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                }\n\n                output = pic->data[0] + line * pic->linesize[0];\n\n                pos = 0;\n\n                continue;\n\n            } else if(p2 == 1) { //End-of-picture\n\n                return 0;\n\n            } else if(p2 == 2) { //Skip\n\n                p1 = bytestream2_get_byte(gb);\n\n                p2 = bytestream2_get_byte(gb);\n\n                line -= p2;\n\n                pos += p1;\n\n                if (line < 0 || pos >= width){\n\n                    av_log(avctx, AV_LOG_ERROR, \"Skip beyond picture bounds\\n\");\n\n                    return -1;\n\n                }\n\n                output = pic->data[0] + line * pic->linesize[0] + pos * (depth >> 3);\n\n                continue;\n\n            }\n\n            // Copy data\n\n            if ((pic->linesize[0] > 0 && output + p2 * (depth >> 3) > output_end) ||\n\n                (pic->linesize[0] < 0 && output + p2 * (depth >> 3) < output_end)) {\n\n                bytestream2_skip(gb, 2 * (depth >> 3));\n\n                continue;\n\n            } else if (bytestream2_get_bytes_left(gb) < p2 * (depth >> 3)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"bytestream overrun\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if ((depth == 8) || (depth == 24)) {\n\n                for(i = 0; i < p2 * (depth >> 3); i++) {\n\n                    *output++ = bytestream2_get_byteu(gb);\n\n                }\n\n                // RLE8 copy is actually padded - and runs are not!\n\n                if(depth == 8 && (p2 & 1)) {\n\n                    bytestream2_skip(gb, 1);\n\n                }\n\n            } else if (depth == 16) {\n\n                for(i = 0; i < p2; i++) {\n\n                    *(uint16_t*)output = bytestream2_get_le16u(gb);\n\n                    output += 2;\n\n                }\n\n            } else if (depth == 32) {\n\n                for(i = 0; i < p2; i++) {\n\n                    *(uint32_t*)output = bytestream2_get_le32u(gb);\n\n                    output += 4;\n\n                }\n\n            }\n\n            pos += p2;\n\n        } else { //run of pixels\n\n            uint8_t pix[3]; //original pixel\n\n            if ((pic->linesize[0] > 0 && output + p1 * (depth >> 3) > output_end) ||\n\n                (pic->linesize[0] < 0 && output + p1 * (depth >> 3) < output_end))\n\n                continue;\n\n\n\n            switch(depth){\n\n            case  8:\n\n                pix[0] = bytestream2_get_byte(gb);\n\n                for(i = 0; i < p1; i++)\n\n                        *output++ = pix[0];\n\n                break;\n\n            case 16:\n\n                pix16  = bytestream2_get_le16(gb);\n\n                for(i = 0; i < p1; i++) {\n\n                        *(uint16_t*)output = pix16;\n\n                        output += 2;\n\n                }\n\n                break;\n\n            case 24:\n\n                pix[0] = bytestream2_get_byte(gb);\n\n                pix[1] = bytestream2_get_byte(gb);\n\n                pix[2] = bytestream2_get_byte(gb);\n\n                for(i = 0; i < p1; i++) {\n\n                        *output++ = pix[0];\n\n                        *output++ = pix[1];\n\n                        *output++ = pix[2];\n\n                }\n\n                break;\n\n            case 32:\n\n                pix32  = bytestream2_get_le32(gb);\n\n                for(i = 0; i < p1; i++) {\n\n                        *(uint32_t*)output = pix32;\n\n                        output += 4;\n\n                }\n\n                break;\n\n            }\n\n            pos += p1;\n\n        }\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_WARNING, \"MS RLE warning: no end-of-picture code\\n\");\n\n    return 0;\n\n}\n", "idx": 25732, "_split": "valid", "_hash": "161a613b338c2cf5f10ad88d5a4b5021"}
{"project": "FFmpeg", "commit_id": "e3d2500fe498289a878b956f6efb4995438c9515", "target": 1, "func": "static void RENAME(SwScale_YV12slice)(unsigned char* srcptr[],int stride[], int srcSliceY ,\n\n\t\t\t     int srcSliceH, uint8_t* dstptr[], int dststride, int dstbpp,\n\n\t\t\t     int srcW, int srcH, int dstW, int dstH){\n\n\n\n\n\nunsigned int lumXInc= (srcW << 16) / dstW;\n\nunsigned int lumYInc= (srcH << 16) / dstH;\n\nunsigned int chrXInc;\n\nunsigned int chrYInc;\n\n\n\nstatic int dstY;\n\n\n\n// used to detect a size change\n\nstatic int oldDstW= -1;\n\nstatic int oldSrcW= -1;\n\nstatic int oldDstH= -1;\n\nstatic int oldSrcH= -1;\n\nstatic int oldFlags=-1;\n\n\n\nstatic int lastInLumBuf;\n\nstatic int lastInChrBuf;\n\n\n\nint chrDstW, chrDstH;\n\n\n\nstatic int lumBufIndex=0;\n\nstatic int chrBufIndex=0;\n\n\n\nstatic int firstTime=1;\n\n\n\nint widthAlign= dstbpp==12 ? 16 : 8;\n\nif(((dstW + widthAlign-1)&(~(widthAlign-1))) > dststride)\n\n{\n\n\tdstW&= ~(widthAlign-1);\n\n\tif(firstTime)\n\n\t\tfprintf(stderr, \"SwScaler: Warning: dstStride is not a multiple of %d!\\n\"\n\n\t\t\t\t\"SwScaler: ->lowering width to compensate, new width=%d\\n\"\n\n\t\t\t\t\"SwScaler: ->cannot do aligned memory acesses anymore\\n\",\n\n\t\t\t\twidthAlign, dstW);\n\n}\n\n\n\n//printf(\"%d %d %d %d\\n\", srcW, srcH, dstW, dstH);\n\n//printf(\"%d %d %d %d\\n\", lumXInc, lumYInc, srcSliceY, srcSliceH);\n\n\n\n#ifdef HAVE_MMX2\n\ncanMMX2BeUsed= (lumXInc <= 0x10000 && (dstW&31)==0 && (srcW&15)==0) ? 1 : 0;\n\nif(!canMMX2BeUsed && lumXInc <= 0x10000 && (srcW&15)==0 && sws_flags==SWS_FAST_BILINEAR)\n\n{\n\n\tif(firstTime) //FIXME only if verbose ?\n\n\t\tfprintf(stderr, \"SwScaler: output Width is not a multiple of 32 -> no MMX2 scaler\\n\");\n\n}\n\n#endif\n\n\n\nif(firstTime)\n\n{\n\n#if defined (DITHER1XBPP) && defined (HAVE_MMX)\n\n\tchar *dither= \" dithered\";\n\n#else\n\n\tchar *dither= \"\";\n\n#endif\n\n\tif(sws_flags==SWS_FAST_BILINEAR)\n\n\t\tfprintf(stderr, \"SwScaler: FAST_BILINEAR scaler \");\n\n\telse if(sws_flags==SWS_BILINEAR)\n\n\t\tfprintf(stderr, \"SwScaler: BILINEAR scaler \");\n\n\telse if(sws_flags==SWS_BICUBIC)\n\n\t\tfprintf(stderr, \"SwScaler: BICUBIC scaler \");\n\n\telse\n\n\t\tfprintf(stderr, \"SwScaler: ehh flags invalid?! \");\n\n\n\n\tif(dstbpp==15)\n\n\t\tfprintf(stderr, \"with%s BGR15 output \", dither);\n\n\telse if(dstbpp==16)\n\n\t\tfprintf(stderr, \"with%s BGR16 output \", dither);\n\n\telse if(dstbpp==24)\n\n\t\tfprintf(stderr, \"with BGR24 output \");\n\n\telse if(dstbpp==32)\n\n\t\tfprintf(stderr, \"with BGR32 output \");\n\n\telse if(dstbpp==12)\n\n\t\tfprintf(stderr, \"with YV12 output \");\n\n\telse\n\n\t\tfprintf(stderr, \"without output \");\n\n\n\n#ifdef HAVE_MMX2\n\n\t\tfprintf(stderr, \"using MMX2\\n\");\n\n#elif defined (HAVE_3DNOW)\n\n\t\tfprintf(stderr, \"using 3DNOW\\n\");\n\n#elif defined (HAVE_MMX)\n\n\t\tfprintf(stderr, \"using MMX\\n\");\n\n#elif defined (ARCH_X86)\n\n\t\tfprintf(stderr, \"using X86 ASM2\\n\");\n\n#else\n\n\t\tfprintf(stderr, \"using C\\n\");\n\n#endif\n\n}\n\n\n\n\n\n// match pixel 0 of the src to pixel 0 of dst and match pixel n-2 of src to pixel n-2 of dst\n\n// n-2 is the last chrominance sample available\n\n// this is not perfect, but noone shuld notice the difference, the more correct variant\n\n// would be like the vertical one, but that would require some special code for the\n\n// first and last pixel\n\nif(sws_flags==SWS_FAST_BILINEAR)\n\n{\n\n\tif(canMMX2BeUsed) \tlumXInc+= 20;\n\n\telse\t\t\tlumXInc = ((srcW-2)<<16)/(dstW-2) - 20;\n\n}\n\n\n\nif(fullUVIpol && !(dstbpp==12)) \tchrXInc= lumXInc>>1, chrDstW= dstW;\n\nelse\t\t\t\t\tchrXInc= lumXInc,    chrDstW= dstW>>1;\n\n\n\nif(dstbpp==12)\tchrYInc= lumYInc,    chrDstH= dstH>>1;\n\nelse\t\tchrYInc= lumYInc>>1, chrDstH= dstH;\n\n\n\n  // force calculation of the horizontal interpolation of the first line\n\n\n\n  if(srcSliceY ==0){\n\n//\tprintf(\"dstW %d, srcw %d, mmx2 %d\\n\", dstW, srcW, canMMX2BeUsed);\n\n\tlumBufIndex=0;\n\n\tchrBufIndex=0;\n\n\tdstY=0;\n\n\n\n\t//precalculate horizontal scaler filter coefficients\n\n\tif(oldDstW!=dstW || oldSrcW!=srcW || oldFlags!=sws_flags)\n\n\t{\n\n#ifdef HAVE_MMX\n\n\t\tconst int filterAlign=4;\n\n#else\n\n\t\tconst int filterAlign=1;\n\n#endif\n\n\t\toldDstW= dstW; oldSrcW= srcW; oldFlags= sws_flags;\n\n\n\n\t\tif(sws_flags != SWS_FAST_BILINEAR)\n\n\t\t{\n\n\t\t\tRENAME(initFilter)(hLumFilter, hLumFilterPos, &hLumFilterSize, lumXInc,\n\n\t\t\t\t\t   srcW   , dstW   , filterAlign, 1<<14);\n\n\t\t\tRENAME(initFilter)(hChrFilter, hChrFilterPos, &hChrFilterSize, chrXInc,\n\n\t\t\t\t\t   srcW>>1, chrDstW, filterAlign, 1<<14);\n\n\t\t}\n\n\n\n#ifdef HAVE_MMX2\n\n// cant downscale !!!\n\n\t\tif(canMMX2BeUsed && sws_flags == SWS_FAST_BILINEAR)\n\n\t\t{\n\n\t\t\tinitMMX2HScaler(dstW   , lumXInc, funnyYCode);\n\n\t\t\tinitMMX2HScaler(chrDstW, chrXInc, funnyUVCode);\n\n\t\t}\n\n#endif\n\n\t} // Init Horizontal stuff\n\n\n\n\tif(oldDstH!=dstH || oldSrcH!=srcH || oldFlags!=sws_flags)\n\n\t{\n\n\t\tint i;\n\n\t\toldDstH= dstH; oldSrcH= srcH; oldFlags= sws_flags; //FIXME swsflags conflict with x check\n\n\n\n\t\t// deallocate pixbufs\n\n\t\tfor(i=0; i<vLumBufSize; i++) free(lumPixBuf[i]);\n\n\t\tfor(i=0; i<vChrBufSize; i++) free(chrPixBuf[i]);\n\n\n\n\t\tRENAME(initFilter)(vLumFilter, vLumFilterPos, &vLumFilterSize, lumYInc,\n\n\t\t\t\tsrcH   , dstH,    1, (1<<12)-4);\n\n\t\tRENAME(initFilter)(vChrFilter, vChrFilterPos, &vChrFilterSize, chrYInc,\n\n\t\t\t\tsrcH>>1, chrDstH, 1, (1<<12)-4);\n\n\n\n\t\t// Calculate Buffer Sizes so that they wont run out while handling these damn slices\n\n\t\tvLumBufSize= vLumFilterSize; vChrBufSize= vChrFilterSize;\n\n\t\tfor(i=0; i<dstH; i++)\n\n\t\t{\n\n\t\t\tint chrI= i*chrDstH / dstH;\n\n\t\t\tint nextSlice= MAX(vLumFilterPos[i   ] + vLumFilterSize - 1,\n\n\t\t\t\t\t ((vChrFilterPos[chrI] + vChrFilterSize - 1)<<1));\n\n\t\t\tnextSlice&= ~1; // Slices start at even boundaries\n\n\t\t\tif(vLumFilterPos[i   ] + vLumBufSize < nextSlice)\n\n\t\t\t\tvLumBufSize= nextSlice - vLumFilterPos[i   ];\n\n\t\t\tif(vChrFilterPos[chrI] + vChrBufSize < (nextSlice>>1))\n\n\t\t\t\tvChrBufSize= (nextSlice>>1) - vChrFilterPos[chrI];\n\n\t\t}\n\n\n\n\t\t// allocate pixbufs (we use dynamic allocation because otherwise we would need to\n\n\t\t// allocate several megabytes to handle all possible cases)\n\n\t\tfor(i=0; i<vLumBufSize; i++)\n\n\t\t\tlumPixBuf[i]= lumPixBuf[i+vLumBufSize]= (uint16_t*)memalign(8, 4000);\n\n\t\tfor(i=0; i<vChrBufSize; i++)\n\n\t\t\tchrPixBuf[i]= chrPixBuf[i+vChrBufSize]= (uint16_t*)memalign(8, 8000);\n\n\n\n\t\t//try to avoid drawing green stuff between the right end and the stride end\n\n\t\tfor(i=0; i<vLumBufSize; i++) memset(lumPixBuf[i], 0, 4000);\n\n\t\tfor(i=0; i<vChrBufSize; i++) memset(chrPixBuf[i], 64, 8000);\n\n\n\n#ifdef HAVE_MMX\n\n\t\t// pack filter data for mmx code\n\n\t\tfor(i=0; i<vLumFilterSize*dstH; i++)\n\n\t\t\tlumMmxFilter[4*i]=lumMmxFilter[4*i+1]=lumMmxFilter[4*i+2]=lumMmxFilter[4*i+3]=\n\n\t\t\t\tvLumFilter[i];\n\n\n\n\t\tfor(i=0; i<vChrFilterSize*chrDstH; i++)\n\n\t\t\tchrMmxFilter[4*i]=chrMmxFilter[4*i+1]=chrMmxFilter[4*i+2]=chrMmxFilter[4*i+3]=\n\n\t\t\t\tvChrFilter[i];\n\n#endif\n\n\t}\n\n\n\n\tlastInLumBuf= -1;\n\n\tlastInChrBuf= -1;\n\n  } // if(firstLine)\n\n\n\n\tfor(;dstY < dstH; dstY++){\n\n\t\tunsigned char *dest =dstptr[0]+dststride*dstY;\n\n\t\tunsigned char *uDest=dstptr[1]+(dststride>>1)*(dstY>>1);\n\n\t\tunsigned char *vDest=dstptr[2]+(dststride>>1)*(dstY>>1);\n\n\t\tconst int chrDstY= dstbpp==12 ? (dstY>>1) : dstY;\n\n\n\n\t\tconst int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n\t\tconst int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n\t\tconst int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n\t\tconst int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n\n\n\t\tif(sws_flags == SWS_FAST_BILINEAR)\n\n\t\t{\n\n\t\t\t//handle holes\n\n\t\t\tif(firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n\t\t\tif(firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n\t\t}\n\n\n\n\t\tASSERT(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1)\n\n\t\tASSERT(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1)\n\n\n\n\t\t// Do we have enough lines in this slice to output the dstY line\n\n\t\tif(lastLumSrcY < srcSliceY + srcSliceH && lastChrSrcY < ((srcSliceY + srcSliceH)>>1))\n\n\t\t{\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf < lastLumSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src= srcptr[0]+(lastInLumBuf + 1 - srcSliceY)*stride[0];\n\n\t\t\t\tlumBufIndex++;\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n//\t\t\t\tprintf(\"%d %d\\n\", lumBufIndex, vLumBufSize);\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, src, srcW, lumXInc);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf < lastChrSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= srcptr[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[1];\n\n\t\t\t\tuint8_t *src2= srcptr[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < (srcSliceH>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, srcW>>1, chrXInc);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t}\n\n\t\telse // not enough lines left in this slice -> load the rest in the buffer\n\n\t\t{\n\n/*\t\tprintf(\"%d %d Last:%d %d LastInBuf:%d %d Index:%d %d Y:%d FSize: %d %d BSize: %d %d\\n\",\n\n\t\t\tfirstChrSrcY,firstLumSrcY,lastChrSrcY,lastLumSrcY,\n\n\t\t\tlastInChrBuf,lastInLumBuf,chrBufIndex,lumBufIndex,dstY,vChrFilterSize,vLumFilterSize,\n\n\t\t\tvChrBufSize, vLumBufSize);\n\n*/\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf+1 < srcSliceY + srcSliceH)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src= srcptr[0]+(lastInLumBuf + 1 - srcSliceY)*stride[0];\n\n\t\t\t\tlumBufIndex++;\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, src, srcW, lumXInc);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf+1 < ((srcSliceY + srcSliceH)>>1))\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= srcptr[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[1];\n\n\t\t\t\tuint8_t *src2= srcptr[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*stride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < (srcSliceH>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, srcW>>1, chrXInc);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t\tbreak; //we cant output a dstY line so lets try with the next slice\n\n\t\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t\tb5Dither= dither8[dstY&1];\n\n\t\tg6Dither= dither4[dstY&1];\n\n\t\tg5Dither= dither8[dstY&1];\n\n\t\tr5Dither= dither8[(dstY+1)&1];\n\n#endif\n\n\n\n\t\tif(dstbpp==12) //YV12\n\n\t\t{\n\n\t\t\tif(dstY&1) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 1) // Unscaled YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t *lumBuf = lumPixBuf[0];\n\n\t\t\t\tint16_t *chrBuf= chrPixBuf[0];\n\n\t\t\t\tRENAME(yuv2yuv1)(lumBuf, chrBuf, dest, uDest, vDest, dstW);\n\n\t\t\t}\n\n\t\t\telse //General YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\t\t\t\tRENAME(yuv2yuvX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize     , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+(dstY>>1)*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, uDest, vDest, dstW,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+(dstY>>1)*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 2) //Unscaled RGB\n\n\t\t\t{\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb1)(*lumSrcPtr, *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, chrAlpha, dstbpp);\n\n\t\t\t}\n\n\t\t\telse if(vLumFilterSize == 2 && vChrFilterSize == 2) //BiLinear Upscale RGB\n\n\t\t\t{\n\n\t\t\t\tint lumAlpha= vLumFilter[2*dstY+1];\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb2)(*lumSrcPtr, *(lumSrcPtr+1), *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, lumAlpha, chrAlpha, dstbpp);\n\n\t\t\t}\n\n\t\t\telse //General RGB\n\n\t\t\t{\n\n\t\t\t\tRENAME(yuv2rgbX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, dstW, dstbpp,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+dstY*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\tfirstTime=0;\n\n}", "idx": 25743, "_split": "valid", "_hash": "3d849aa3aaf6ddb8b9e438061891fb98"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "void ff_mpeg1_encode_picture_header(MpegEncContext *s, int picture_number)\n\n{\n\n    AVFrameSideData *side_data;\n\n    mpeg1_encode_sequence_header(s);\n\n\n\n    /* mpeg1 picture header */\n\n    put_header(s, PICTURE_START_CODE);\n\n    /* temporal reference */\n\n\n\n    // RAL: s->picture_number instead of s->fake_picture_number\n\n    put_bits(&s->pb, 10,\n\n             (s->picture_number - s->gop_picture_number) & 0x3ff);\n\n    put_bits(&s->pb, 3, s->pict_type);\n\n\n\n    s->vbv_delay_ptr = s->pb.buf + put_bits_count(&s->pb) / 8;\n\n    put_bits(&s->pb, 16, 0xFFFF);               /* vbv_delay */\n\n\n\n    // RAL: Forward f_code also needed for B-frames\n\n    if (s->pict_type == AV_PICTURE_TYPE_P ||\n\n        s->pict_type == AV_PICTURE_TYPE_B) {\n\n        put_bits(&s->pb, 1, 0);                 /* half pel coordinates */\n\n        if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO)\n\n            put_bits(&s->pb, 3, s->f_code);     /* forward_f_code */\n\n        else\n\n            put_bits(&s->pb, 3, 7);             /* forward_f_code */\n\n    }\n\n\n\n    // RAL: Backward f_code necessary for B-frames\n\n    if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n        put_bits(&s->pb, 1, 0);                 /* half pel coordinates */\n\n        if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO)\n\n            put_bits(&s->pb, 3, s->b_code);     /* backward_f_code */\n\n        else\n\n            put_bits(&s->pb, 3, 7);             /* backward_f_code */\n\n    }\n\n\n\n    put_bits(&s->pb, 1, 0);                     /* extra bit picture */\n\n\n\n    s->frame_pred_frame_dct = 1;\n\n    if (s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        put_header(s, EXT_START_CODE);\n\n        put_bits(&s->pb, 4, 8);                 /* pic ext */\n\n        if (s->pict_type == AV_PICTURE_TYPE_P ||\n\n            s->pict_type == AV_PICTURE_TYPE_B) {\n\n            put_bits(&s->pb, 4, s->f_code);\n\n            put_bits(&s->pb, 4, s->f_code);\n\n        } else {\n\n            put_bits(&s->pb, 8, 255);\n\n        }\n\n        if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n            put_bits(&s->pb, 4, s->b_code);\n\n            put_bits(&s->pb, 4, s->b_code);\n\n        } else {\n\n            put_bits(&s->pb, 8, 255);\n\n        }\n\n        put_bits(&s->pb, 2, s->intra_dc_precision);\n\n\n\n        assert(s->picture_structure == PICT_FRAME);\n\n        put_bits(&s->pb, 2, s->picture_structure);\n\n        if (s->progressive_sequence)\n\n            put_bits(&s->pb, 1, 0);             /* no repeat */\n\n        else\n\n            put_bits(&s->pb, 1, s->current_picture_ptr->f.top_field_first);\n\n        /* XXX: optimize the generation of this flag with entropy measures */\n\n        s->frame_pred_frame_dct = s->progressive_sequence;\n\n\n\n        put_bits(&s->pb, 1, s->frame_pred_frame_dct);\n\n        put_bits(&s->pb, 1, s->concealment_motion_vectors);\n\n        put_bits(&s->pb, 1, s->q_scale_type);\n\n        put_bits(&s->pb, 1, s->intra_vlc_format);\n\n        put_bits(&s->pb, 1, s->alternate_scan);\n\n        put_bits(&s->pb, 1, s->repeat_first_field);\n\n        s->progressive_frame = s->progressive_sequence;\n\n        /* chroma_420_type */\n\n        put_bits(&s->pb, 1, s->chroma_format ==\n\n                            CHROMA_420 ? s->progressive_frame : 0);\n\n        put_bits(&s->pb, 1, s->progressive_frame);\n\n        put_bits(&s->pb, 1, 0);                 /* composite_display_flag */\n\n    }\n\n    if (s->scan_offset) {\n\n        int i;\n\n\n\n        put_header(s, USER_START_CODE);\n\n        for (i = 0; i < sizeof(svcd_scan_offset_placeholder); i++)\n\n            put_bits(&s->pb, 8, svcd_scan_offset_placeholder[i]);\n\n    }\n\n    side_data = av_frame_get_side_data(&s->current_picture_ptr->f,\n\n                                       AV_FRAME_DATA_STEREO3D);\n\n    if (side_data) {\n\n        AVStereo3D *stereo = (AVStereo3D *)side_data->data;\n\n        uint8_t fpa_type;\n\n\n\n        switch (stereo->type) {\n\n        case AV_STEREO3D_SIDEBYSIDE:\n\n            fpa_type = 0x03;\n\n            break;\n\n        case AV_STEREO3D_TOPBOTTOM:\n\n            fpa_type = 0x04;\n\n            break;\n\n        case AV_STEREO3D_2D:\n\n            fpa_type = 0x08;\n\n            break;\n\n        case AV_STEREO3D_SIDEBYSIDE_QUINCUNX:\n\n            fpa_type = 0x23;\n\n            break;\n\n        default:\n\n            fpa_type = 0;\n\n            break;\n\n        }\n\n\n\n        if (fpa_type != 0) {\n\n            put_header(s, USER_START_CODE);\n\n            put_bits(&s->pb, 8, 'J');   // S3D_video_format_signaling_identifier\n\n            put_bits(&s->pb, 8, 'P');\n\n            put_bits(&s->pb, 8, '3');\n\n            put_bits(&s->pb, 8, 'D');\n\n            put_bits(&s->pb, 8, 0x03);  // S3D_video_format_length\n\n\n\n            put_bits(&s->pb, 1, 1);     // reserved_bit\n\n            put_bits(&s->pb, 7, fpa_type); // S3D_video_format_type\n\n            put_bits(&s->pb, 8, 0x04);  // reserved_data[0]\n\n            put_bits(&s->pb, 8, 0xFF);  // reserved_data[1]\n\n        }\n\n    }\n\n\n\n    s->mb_y = 0;\n\n    ff_mpeg1_encode_slice_header(s);\n\n}\n", "idx": 25744, "_split": "valid", "_hash": "9043e93ccc89f4a0e1541141b1b25b99"}
{"project": "FFmpeg", "commit_id": "1acd7d594c15aa491729c837ad3519d3469e620a", "target": 0, "func": "static void FUNCC(pred8x8l_vertical_add)(uint8_t *_pix, const int16_t *_block,\n\n                                         ptrdiff_t stride)\n\n{\n\n    int i;\n\n    pixel *pix = (pixel*)_pix;\n\n    const dctcoef *block = (const dctcoef*)_block;\n\n    stride >>= sizeof(pixel)-1;\n\n    pix -= stride;\n\n    for(i=0; i<8; i++){\n\n        pixel v = pix[0];\n\n        pix[1*stride]= v += block[0];\n\n        pix[2*stride]= v += block[8];\n\n        pix[3*stride]= v += block[16];\n\n        pix[4*stride]= v += block[24];\n\n        pix[5*stride]= v += block[32];\n\n        pix[6*stride]= v += block[40];\n\n        pix[7*stride]= v += block[48];\n\n        pix[8*stride]= v +  block[56];\n\n        pix++;\n\n        block++;\n\n    }\n\n}\n", "idx": 25777, "_split": "valid", "_hash": "0614a961aca009b039d19ddc28ceaa1b"}
{"project": "FFmpeg", "commit_id": "c37de519202ac2e5f20141673081b0e6b57ab983", "target": 1, "func": "int ff_vorbis_len2vlc(uint8_t *bits, uint32_t *codes, unsigned num)\n\n{\n\n    uint32_t exit_at_level[33] = { 404 };\n\n    unsigned i, j, p, code;\n\n\n\n    for (p = 0; (bits[p] == 0) && (p < num); ++p)\n\n        ;\n\n    if (p == num)\n\n        return 0;\n\n\n\n    codes[p] = 0;\n\n    if (bits[p] > 32)\n\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < bits[p]; ++i)\n\n        exit_at_level[i+1] = 1 << i;\n\n\n\n    ++p;\n\n\n\n    for (i = p; (bits[i] == 0) && (i < num); ++i)\n\n        ;\n\n    if (i == num)\n\n        return 0;\n\n\n\n    for (; p < num; ++p) {\n\n        if (bits[p] > 32)\n\n             return AVERROR_INVALIDDATA;\n\n        if (bits[p] == 0)\n\n             continue;\n\n        // find corresponding exit(node which the tree can grow further from)\n\n        for (i = bits[p]; i > 0; --i)\n\n            if (exit_at_level[i])\n\n                break;\n\n        if (!i) // overspecified tree\n\n             return AVERROR_INVALIDDATA;\n\n        code = exit_at_level[i];\n\n        exit_at_level[i] = 0;\n\n        // construct code (append 0s to end) and introduce new exits\n\n        for (j = i + 1 ;j <= bits[p]; ++j)\n\n            exit_at_level[j] = code + (1 << (j - 1));\n\n        codes[p] = code;\n\n    }\n\n\n\n    //no exits should be left (underspecified tree - ie. unused valid vlcs - not allowed by SPEC)\n\n    for (p = 1; p < 33; p++)\n\n        if (exit_at_level[p])\n\n            return AVERROR_INVALIDDATA;\n\n\n\n    return 0;\n\n}\n", "idx": 25782, "_split": "valid", "_hash": "dd000883c3f4fbff85bd0b45cec7bf2e"}
{"project": "FFmpeg", "commit_id": "dae7ff04160901a30a35af05f2f149b289c4f0b1", "target": 1, "func": "static void decode_cdlms(WmallDecodeCtx *s)\n\n{\n\n    int c, i;\n\n    int cdlms_send_coef = get_bits1(&s->gb);\n\n\n\n    for(c = 0; c < s->num_channels; c++) {\n\n\ts->cdlms_ttl[c] = get_bits(&s->gb, 3) + 1;\n\n\tfor(i = 0; i < s->cdlms_ttl[c]; i++) {\n\n\t    s->cdlms[c][i].order = (get_bits(&s->gb, 7) + 1) * 8;\n\n\t}\n\n\n\n\tfor(i = 0; i < s->cdlms_ttl[c]; i++) {\n\n\t    s->cdlms[c][i].scaling = get_bits(&s->gb, 4);\n\n\t}\n\n\n\n\tif(cdlms_send_coef) {\n\n\t    for(i = 0; i < s->cdlms_ttl[c]; i++) {\n\n\t\tint cbits, shift_l, shift_r, j;\n\n\t\tcbits = av_log2(s->cdlms[c][i].order);\n\n\t\tif(1 << cbits < s->cdlms[c][i].order)\n\n\t\t    cbits++;\n\n\t\ts->cdlms[c][i].coefsend = get_bits(&s->gb, cbits) + 1;\n\n\n\n\t\tcbits = av_log2(s->cdlms[c][i].scaling + 1);\n\n\t\tif(1 << cbits < s->cdlms[c][i].scaling + 1)\n\n\t\t    cbits++;\n\n\n\n\t\ts->cdlms[c][i].bitsend = get_bits(&s->gb, cbits) + 2;\n\n\t\tshift_l = 32 - s->cdlms[c][i].bitsend;\n\n\t\tshift_r = 32 - 2 - s->cdlms[c][i].scaling;\n\n\t\tfor(j = 0; j < s->cdlms[c][i].coefsend; j++) {\n\n\t\t    s->cdlms[c][i].coefs[j] =\n\n\t\t\t(get_bits(&s->gb, s->cdlms[c][i].bitsend) << shift_l) >> shift_r;\n\n\t\t}\n\n\t    }\n\n\t}\n\n    }\n\n}\n", "idx": 25856, "_split": "valid", "_hash": "5b54ff149676a0e11570c41167b457ca"}
{"project": "FFmpeg", "commit_id": "44f1698a3824836d32708ae93e78ac1f2310a07e", "target": 1, "func": "static void imdct12(int *out, int *in)\n\n{\n\n    int in0, in1, in2, in3, in4, in5, t1, t2;\n\n    in0= in[0*3]<<5;\n\n    in1= (in[1*3] + in[0*3])<<5;\n\n    in2= (in[2*3] + in[1*3])<<5;\n\n    in3= (in[3*3] + in[2*3])<<5;\n\n    in4= (in[4*3] + in[3*3])<<5;\n\n    in5= (in[5*3] + in[4*3])<<5;\n\n    in5 += in3;\n\n    in3 += in1;\n\n\n\n    in2= MULH(2*in2, C3);\n\n    in3= MULH(2*in3, C3);\n\n    \n\n    t1 = in0 - in4;\n\n    t2 = MULL(in1 - in5, icos36[4]);\n\n\n\n    out[ 7]= \n\n    out[10]= t1 + t2;\n\n    out[ 1]=\n\n    out[ 4]= t1 - t2;\n\n\n\n    in0 += in4>>1;\n\n    in4 = in0 + in2;\n\n    in1 += in5>>1;\n\n    in5 = MULL(in1 + in3, icos36[1]);    \n\n    out[ 8]= \n\n    out[ 9]= in4 + in5;\n\n    out[ 2]=\n\n    out[ 3]= in4 - in5;\n\n    \n\n    in0 -= in2;\n\n    in1 = MULL(in1 - in3, icos36[7]);\n\n    out[ 0]=\n\n    out[ 5]= in0 - in1;\n\n    out[ 6]=\n\n    out[11]= in0 + in1;    \n\n}\n", "idx": 25889, "_split": "valid", "_hash": "c808cfec2a42bde0c5ef468ddeb27f0c"}
{"project": "FFmpeg", "commit_id": "d0d8a9b1384ba3cd465d6ef3439f3979d4518b4b", "target": 1, "func": "void ff_mov_close_hinting(MOVTrack *track) {\n\n    AVFormatContext* rtp_ctx = track->rtp_ctx;\n\n    uint8_t *ptr;\n\n\n\n    av_freep(&track->enc);\n\n    sample_queue_free(&track->sample_queue);\n\n    if (!rtp_ctx)\n\n        return;\n\n    if (rtp_ctx->pb) {\n\n        av_write_trailer(rtp_ctx);\n\n        url_close_dyn_buf(rtp_ctx->pb, &ptr);\n\n        av_free(ptr);\n\n    }\n\n    av_metadata_free(&rtp_ctx->streams[0]->metadata);\n\n    av_metadata_free(&rtp_ctx->metadata);\n\n\n    av_free(rtp_ctx->streams[0]);\n\n    av_freep(&rtp_ctx);\n\n}", "idx": 26037, "_split": "valid", "_hash": "33d0f03f4f551f0f58cf7527b5275dfc"}
{"project": "FFmpeg", "commit_id": "ac9919b9662f28816cf79c1d5c36719160009588", "target": 0, "func": "static void mxf_write_cdci_common(AVFormatContext *s, AVStream *st, const UID key, unsigned size)\n\n{\n\n    MXFStreamContext *sc = st->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int stored_height = (st->codec->height+15)/16*16;\n\n    int display_height;\n\n    int f1, f2;\n\n    unsigned desc_size = size+8+8+8+8+8+8+5+16+sc->interlaced*4+12+20;\n\n    if (sc->interlaced && sc->field_dominance)\n\n        desc_size += 5;\n\n\n\n    mxf_write_generic_desc(s, st, key, desc_size);\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3203);\n\n    avio_wb32(pb, st->codec->width);\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3202);\n\n    avio_wb32(pb, stored_height>>sc->interlaced);\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3209);\n\n    avio_wb32(pb, st->codec->width);\n\n\n\n    if (st->codec->height == 608) // PAL + VBI\n\n        display_height = 576;\n\n    else if (st->codec->height == 512)  // NTSC + VBI\n\n        display_height = 486;\n\n    else\n\n        display_height = st->codec->height;\n\n\n\n    mxf_write_local_tag(pb, 4, 0x3208);\n\n    avio_wb32(pb, display_height>>sc->interlaced);\n\n\n\n    // component depth\n\n    mxf_write_local_tag(pb, 4, 0x3301);\n\n    avio_wb32(pb, sc->component_depth);\n\n\n\n    // horizontal subsampling\n\n    mxf_write_local_tag(pb, 4, 0x3302);\n\n    avio_wb32(pb, 2);\n\n\n\n    // frame layout\n\n    mxf_write_local_tag(pb, 1, 0x320C);\n\n    avio_w8(pb, sc->interlaced);\n\n\n\n    // video line map\n\n    switch (st->codec->height) {\n\n    case  576: f1 = 23; f2 = st->codec->codec_id == AV_CODEC_ID_DVVIDEO ? 335 : 336; break;\n\n    case  608: f1 =  7; f2 = 320; break;\n\n    case  480: f1 = 20; f2 = st->codec->codec_id == AV_CODEC_ID_DVVIDEO ? 285 : 283; break;\n\n    case  512: f1 =  7; f2 = 270; break;\n\n    case  720: f1 = 26; f2 =   0; break; // progressive\n\n    case 1080: f1 = 21; f2 = 584; break;\n\n    default:   f1 =  0; f2 =   0; break;\n\n    }\n\n\n\n    if (!sc->interlaced) {\n\n        f2  = 0;\n\n        f1 *= 2;\n\n    }\n\n\n\n    mxf_write_local_tag(pb, 12+sc->interlaced*4, 0x320D);\n\n    avio_wb32(pb, sc->interlaced ? 2 : 1);\n\n    avio_wb32(pb, 4);\n\n    avio_wb32(pb, f1);\n\n    if (sc->interlaced)\n\n        avio_wb32(pb, f2);\n\n\n\n    mxf_write_local_tag(pb, 8, 0x320E);\n\n    avio_wb32(pb, sc->aspect_ratio.num);\n\n    avio_wb32(pb, sc->aspect_ratio.den);\n\n\n\n    mxf_write_local_tag(pb, 16, 0x3201);\n\n    avio_write(pb, *sc->codec_ul, 16);\n\n\n\n    if (sc->interlaced && sc->field_dominance) {\n\n        mxf_write_local_tag(pb, 1, 0x3212);\n\n        avio_w8(pb, sc->field_dominance);\n\n    }\n\n\n\n}\n", "idx": 26114, "_split": "valid", "_hash": "61c2c4a7f68f13945860594bb6fb3dc9"}
{"project": "FFmpeg", "commit_id": "a4d70941cd4a82f7db9fbaa2148d60ce550e7611", "target": 1, "func": "static void start_children(FFStream *feed)\n{\n    if (no_launch)\n        return;\n    for (; feed; feed = feed->next) {\n        if (feed->child_argv && !feed->pid) {\n            feed->pid_start = time(0);\n            feed->pid = fork();\n            if (feed->pid < 0) {\n                fprintf(stderr, \"Unable to create children\\n\");\n                exit(1);\n            }\n            if (!feed->pid) {\n                /* In child */\n                char pathname[1024];\n                char *slash;\n                int i;\n                for (i = 3; i < 256; i++) {\n                    close(i);\n                }\n                if (!ffserver_debug) {\n                    i = open(\"/dev/null\", O_RDWR);\n                    if (i)\n                        dup2(i, 0);\n                    dup2(i, 1);\n                    dup2(i, 2);\n                    if (i)\n                        close(i);\n                }\n                pstrcpy(pathname, sizeof(pathname), my_program_name);\n                slash = strrchr(pathname, '/');\n                if (!slash) {\n                    slash = pathname;\n                } else {\n                    slash++;\n                }\n                strcpy(slash, \"ffmpeg\");\n                /* This is needed to make relative pathnames work */\n                chdir(my_program_dir);\n                execvp(pathname, feed->child_argv);\n                _exit(1);\n            }\n        }\n    }\n}", "idx": 26174, "_split": "valid", "_hash": "c89405f12d16d66087569b3a5670cb4b"}
{"project": "FFmpeg", "commit_id": "a4fd95b5d511384ed3ce388d8d20a16b1c4c0530", "target": 0, "func": "int ff_h264_check_intra_pred_mode(H264Context *h, int mode){\n\n    MpegEncContext * const s = &h->s;\n\n    static const int8_t top [7]= {LEFT_DC_PRED8x8, 1,-1,-1};\n\n    static const int8_t left[7]= { TOP_DC_PRED8x8,-1, 2,-1,DC_128_PRED8x8};\n\n\n\n    if(mode > 6U) {\n\n        av_log(h->s.avctx, AV_LOG_ERROR, \"out of range intra chroma pred mode at %d %d\\n\", s->mb_x, s->mb_y);\n\n        return -1;\n\n    }\n\n\n\n    if(!(h->top_samples_available&0x8000)){\n\n        mode= top[ mode ];\n\n        if(mode<0){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"top block unavailable for requested intra mode at %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if((h->left_samples_available&0x8080) != 0x8080){\n\n        mode= left[ mode ];\n\n        if(h->left_samples_available&0x8080){ //mad cow disease mode, aka MBAFF + constrained_intra_pred\n\n            mode= ALZHEIMER_DC_L0T_PRED8x8 + (!(h->left_samples_available&0x8000)) + 2*(mode == DC_128_PRED8x8);\n\n        }\n\n        if(mode<0){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"left block unavailable for requested intra mode at %d %d\\n\", s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    return mode;\n\n}\n", "idx": 26180, "_split": "valid", "_hash": "87e013e90bff5fe112186ac4721635e1"}
{"project": "FFmpeg", "commit_id": "dca2fa10d37022684c61166be59294c9f98530d4", "target": 0, "func": "static int mc_subpel(DiracContext *s, DiracBlock *block, const uint8_t *src[5],\n\n                     int x, int y, int ref, int plane)\n\n{\n\n    Plane *p = &s->plane[plane];\n\n    uint8_t **ref_hpel = s->ref_pics[ref]->hpel[plane];\n\n    int motion_x = block->u.mv[ref][0];\n\n    int motion_y = block->u.mv[ref][1];\n\n    int mx, my, i, epel, nplanes = 0;\n\n\n\n    if (plane) {\n\n        motion_x >>= s->chroma_x_shift;\n\n        motion_y >>= s->chroma_y_shift;\n\n    }\n\n\n\n    mx         = motion_x & ~(-1 << s->mv_precision);\n\n    my         = motion_y & ~(-1 << s->mv_precision);\n\n    motion_x >>= s->mv_precision;\n\n    motion_y >>= s->mv_precision;\n\n    /* normalize subpel coordinates to epel */\n\n    /* TODO: template this function? */\n\n    mx      <<= 3 - s->mv_precision;\n\n    my      <<= 3 - s->mv_precision;\n\n\n\n    x += motion_x;\n\n    y += motion_y;\n\n    epel = (mx|my)&1;\n\n\n\n    /* hpel position */\n\n    if (!((mx|my)&3)) {\n\n        nplanes = 1;\n\n        src[0] = ref_hpel[(my>>1)+(mx>>2)] + y*p->stride + x;\n\n    } else {\n\n        /* qpel or epel */\n\n        nplanes = 4;\n\n        for (i = 0; i < 4; i++)\n\n            src[i] = ref_hpel[i] + y*p->stride + x;\n\n\n\n        /* if we're interpolating in the right/bottom halves, adjust the planes as needed\n\n           we increment x/y because the edge changes for half of the pixels */\n\n        if (mx > 4) {\n\n            src[0] += 1;\n\n            src[2] += 1;\n\n            x++;\n\n        }\n\n        if (my > 4) {\n\n            src[0] += p->stride;\n\n            src[1] += p->stride;\n\n            y++;\n\n        }\n\n\n\n        /* hpel planes are:\n\n           [0]: F  [1]: H\n\n           [2]: V  [3]: C */\n\n        if (!epel) {\n\n            /* check if we really only need 2 planes since either mx or my is\n\n               a hpel position. (epel weights of 0 handle this there) */\n\n            if (!(mx&3)) {\n\n                /* mx == 0: average [0] and [2]\n\n                   mx == 4: average [1] and [3] */\n\n                src[!mx] = src[2 + !!mx];\n\n                nplanes = 2;\n\n            } else if (!(my&3)) {\n\n                src[0] = src[(my>>1)  ];\n\n                src[1] = src[(my>>1)+1];\n\n                nplanes = 2;\n\n            }\n\n        } else {\n\n            /* adjust the ordering if needed so the weights work */\n\n            if (mx > 4) {\n\n                FFSWAP(const uint8_t *, src[0], src[1]);\n\n                FFSWAP(const uint8_t *, src[2], src[3]);\n\n            }\n\n            if (my > 4) {\n\n                FFSWAP(const uint8_t *, src[0], src[2]);\n\n                FFSWAP(const uint8_t *, src[1], src[3]);\n\n            }\n\n            src[4] = epel_weights[my&3][mx&3];\n\n        }\n\n    }\n\n\n\n    /* fixme: v/h _edge_pos */\n\n    if ((unsigned)x > p->width +EDGE_WIDTH/2 - p->xblen ||\n\n        (unsigned)y > p->height+EDGE_WIDTH/2 - p->yblen) {\n\n        for (i = 0; i < nplanes; i++) {\n\n            ff_emulated_edge_mc(s->edge_emu_buffer[i], src[i], p->stride,\n\n                                p->xblen, p->yblen, x, y,\n\n                                p->width+EDGE_WIDTH/2, p->height+EDGE_WIDTH/2);\n\n            src[i] = s->edge_emu_buffer[i];\n\n        }\n\n    }\n\n    return (nplanes>>1) + epel;\n\n}\n", "idx": 26230, "_split": "valid", "_hash": "eb1bce9c2106a38a6375f42e718533f1"}
{"project": "FFmpeg", "commit_id": "7cc01c25727a96eaaa0c177234b626e47c8ea491", "target": 1, "func": "static void implicit_weight_table(const H264Context *h, H264SliceContext *sl, int field)\n\n{\n\n    int ref0, ref1, i, cur_poc, ref_start, ref_count0, ref_count1;\n\n\n\n    for (i = 0; i < 2; i++) {\n\n        sl->luma_weight_flag[i]   = 0;\n\n        sl->chroma_weight_flag[i] = 0;\n\n    }\n\n\n\n    if (field < 0) {\n\n        if (h->picture_structure == PICT_FRAME) {\n\n            cur_poc = h->cur_pic_ptr->poc;\n\n        } else {\n\n            cur_poc = h->cur_pic_ptr->field_poc[h->picture_structure - 1];\n\n        }\n\n        if (sl->ref_count[0] == 1 && sl->ref_count[1] == 1 && !FRAME_MBAFF(h) &&\n\n            sl->ref_list[0][0].poc + sl->ref_list[1][0].poc == 2 * cur_poc) {\n\n            sl->use_weight        = 0;\n\n            sl->use_weight_chroma = 0;\n\n            return;\n\n        }\n\n        ref_start  = 0;\n\n        ref_count0 = sl->ref_count[0];\n\n        ref_count1 = sl->ref_count[1];\n\n    } else {\n\n        cur_poc    = h->cur_pic_ptr->field_poc[field];\n\n        ref_start  = 16;\n\n        ref_count0 = 16 + 2 * sl->ref_count[0];\n\n        ref_count1 = 16 + 2 * sl->ref_count[1];\n\n    }\n\n\n\n    sl->use_weight               = 2;\n\n    sl->use_weight_chroma        = 2;\n\n    sl->luma_log2_weight_denom   = 5;\n\n    sl->chroma_log2_weight_denom = 5;\n\n\n\n    for (ref0 = ref_start; ref0 < ref_count0; ref0++) {\n\n        int poc0 = sl->ref_list[0][ref0].poc;\n\n        for (ref1 = ref_start; ref1 < ref_count1; ref1++) {\n\n            int w = 32;\n\n            if (!sl->ref_list[0][ref0].parent->long_ref && !sl->ref_list[1][ref1].parent->long_ref) {\n\n                int poc1 = sl->ref_list[1][ref1].poc;\n\n                int td   = av_clip_int8(poc1 - poc0);\n\n                if (td) {\n\n                    int tb = av_clip_int8(cur_poc - poc0);\n\n                    int tx = (16384 + (FFABS(td) >> 1)) / td;\n\n                    int dist_scale_factor = (tb * tx + 32) >> 8;\n\n                    if (dist_scale_factor >= -64 && dist_scale_factor <= 128)\n\n                        w = 64 - dist_scale_factor;\n\n                }\n\n            }\n\n            if (field < 0) {\n\n                sl->implicit_weight[ref0][ref1][0] =\n\n                sl->implicit_weight[ref0][ref1][1] = w;\n\n            } else {\n\n                sl->implicit_weight[ref0][ref1][field] = w;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26300, "_split": "valid", "_hash": "cf52296257e64738da592ed74cce72fd"}
{"project": "FFmpeg", "commit_id": "a852db796edce2792525d88ab47cf78222e01512", "target": 1, "func": "static int encode_apng(AVCodecContext *avctx, AVPacket *pkt,\n                       const AVFrame *pict, int *got_packet)\n{\n    PNGEncContext *s = avctx->priv_data;\n    int ret;\n    int enc_row_size;\n    size_t max_packet_size;\n    APNGFctlChunk fctl_chunk = {0};\n    if (pict && avctx->codec_id == AV_CODEC_ID_APNG && s->color_type == PNG_COLOR_TYPE_PALETTE) {\n        uint32_t checksum = ~av_crc(av_crc_get_table(AV_CRC_32_IEEE_LE), ~0U, pict->data[1], 256 * sizeof(uint32_t));\n        if (avctx->frame_number == 0) {\n            s->palette_checksum = checksum;\n        } else if (checksum != s->palette_checksum) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"Input contains more than one unique palette. APNG does not support multiple palettes.\\n\");\n            return -1;\n        }\n    }\n    enc_row_size    = deflateBound(&s->zstream, (avctx->width * s->bits_per_pixel + 7) >> 3);\n    max_packet_size =\n        AV_INPUT_BUFFER_MIN_SIZE + // headers\n        avctx->height * (\n            enc_row_size +\n            (4 + 12) * (((int64_t)enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) // fdAT * ceil(enc_row_size / IOBUF_SIZE)\n        );\n    if (max_packet_size > INT_MAX)\n        return AVERROR(ENOMEM);\n    if (avctx->frame_number == 0) {\n        s->bytestream = avctx->extradata = av_malloc(FF_MIN_BUFFER_SIZE);\n        if (!avctx->extradata)\n            return AVERROR(ENOMEM);\n        ret = encode_headers(avctx, pict);\n        if (ret < 0)\n            return ret;\n        avctx->extradata_size = s->bytestream - avctx->extradata;\n        s->last_frame_packet = av_malloc(max_packet_size);\n        if (!s->last_frame_packet)\n            return AVERROR(ENOMEM);\n    } else if (s->last_frame) {\n        ret = ff_alloc_packet2(avctx, pkt, max_packet_size, 0);\n        if (ret < 0)\n            return ret;\n        memcpy(pkt->data, s->last_frame_packet, s->last_frame_packet_size);\n        pkt->size = s->last_frame_packet_size;\n        pkt->pts = pkt->dts = s->last_frame->pts;\n    }\n    if (pict) {\n        s->bytestream_start =\n        s->bytestream       = s->last_frame_packet;\n        s->bytestream_end   = s->bytestream + max_packet_size;\n        // We're encoding the frame first, so we have to do a bit of shuffling around\n        // to have the image data write to the correct place in the buffer\n        fctl_chunk.sequence_number = s->sequence_number;\n        ++s->sequence_number;\n        s->bytestream += 26 + 12;\n        ret = apng_encode_frame(avctx, pict, &fctl_chunk, &s->last_frame_fctl);\n        if (ret < 0)\n            return ret;\n        fctl_chunk.delay_num = 0; // delay filled in during muxing\n        fctl_chunk.delay_den = 0;\n    } else {\n        s->last_frame_fctl.dispose_op = APNG_DISPOSE_OP_NONE;\n    }\n    if (s->last_frame) {\n        uint8_t* last_fctl_chunk_start = pkt->data;\n        uint8_t buf[26];\n        AV_WB32(buf + 0, s->last_frame_fctl.sequence_number);\n        AV_WB32(buf + 4, s->last_frame_fctl.width);\n        AV_WB32(buf + 8, s->last_frame_fctl.height);\n        AV_WB32(buf + 12, s->last_frame_fctl.x_offset);\n        AV_WB32(buf + 16, s->last_frame_fctl.y_offset);\n        AV_WB16(buf + 20, s->last_frame_fctl.delay_num);\n        AV_WB16(buf + 22, s->last_frame_fctl.delay_den);\n        buf[24] = s->last_frame_fctl.dispose_op;\n        buf[25] = s->last_frame_fctl.blend_op;\n        png_write_chunk(&last_fctl_chunk_start, MKTAG('f', 'c', 'T', 'L'), buf, 26);\n        *got_packet = 1;\n    }\n    if (pict) {\n        if (!s->last_frame) {\n            s->last_frame = av_frame_alloc();\n            if (!s->last_frame)\n                return AVERROR(ENOMEM);\n        } else if (s->last_frame_fctl.dispose_op != APNG_DISPOSE_OP_PREVIOUS) {\n            if (!s->prev_frame) {\n                s->prev_frame = av_frame_alloc();\n                if (!s->prev_frame)\n                    return AVERROR(ENOMEM);\n                s->prev_frame->format = pict->format;\n                s->prev_frame->width = pict->width;\n                s->prev_frame->height = pict->height;\n                if ((ret = av_frame_get_buffer(s->prev_frame, 32)) < 0)\n                    return ret;\n            }\n            // Do disposal, but not blending\n            memcpy(s->prev_frame->data[0], s->last_frame->data[0],\n                   s->last_frame->linesize[0] * s->last_frame->height);\n            if (s->last_frame_fctl.dispose_op == APNG_DISPOSE_OP_BACKGROUND) {\n                uint32_t y;\n                uint8_t bpp = (s->bits_per_pixel + 7) >> 3;\n                for (y = s->last_frame_fctl.y_offset; y < s->last_frame_fctl.y_offset + s->last_frame_fctl.height; ++y) {\n                    size_t row_start = s->last_frame->linesize[0] * y + bpp * s->last_frame_fctl.x_offset;\n                    memset(s->prev_frame->data[0] + row_start, 0, bpp * s->last_frame_fctl.width);\n                }\n            }\n        }\n        av_frame_unref(s->last_frame);\n        ret = av_frame_ref(s->last_frame, (AVFrame*)pict);\n        if (ret < 0)\n            return ret;\n        s->last_frame_fctl = fctl_chunk;\n        s->last_frame_packet_size = s->bytestream - s->bytestream_start;\n    } else {\n        av_frame_free(&s->last_frame);\n    }\n    return 0;\n}", "idx": 26379, "_split": "valid", "_hash": "bf922d6332a661a6f196a67b790c23d0"}
{"project": "FFmpeg", "commit_id": "30011bf20109eef1a0f9ee949b19f9998ad88663", "target": 1, "func": "void decode_mb_mode(VP8Context *s, VP8Macroblock *mb, int mb_x, int mb_y, uint8_t *segment, uint8_t *ref)\n\n{\n\n    VP56RangeCoder *c = &s->c;\n\n\n\n    if (s->segmentation.update_map)\n\n        *segment = vp8_rac_get_tree(c, vp8_segmentid_tree, s->prob->segmentid);\n\n    else\n\n        *segment = ref ? *ref : *segment;\n\n    s->segment = *segment;\n\n\n\n    mb->skip = s->mbskip_enabled ? vp56_rac_get_prob(c, s->prob->mbskip) : 0;\n\n\n\n    if (s->keyframe) {\n\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_intra, vp8_pred16x16_prob_intra);\n\n\n\n        if (mb->mode == MODE_I4x4) {\n\n            decode_intra4x4_modes(s, c, mb_x, 1);\n\n        } else {\n\n            const uint32_t modes = vp8_pred4x4_mode[mb->mode] * 0x01010101u;\n\n            AV_WN32A(s->intra4x4_pred_mode_top + 4 * mb_x, modes);\n\n            AV_WN32A(s->intra4x4_pred_mode_left, modes);\n\n        }\n\n\n\n        s->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree, vp8_pred8x8c_prob_intra);\n\n        mb->ref_frame = VP56_FRAME_CURRENT;\n\n    } else if (vp56_rac_get_prob_branchy(c, s->prob->intra)) {\n\n        // inter MB, 16.2\n\n        if (vp56_rac_get_prob_branchy(c, s->prob->last))\n\n            mb->ref_frame = vp56_rac_get_prob(c, s->prob->golden) ?\n\n                VP56_FRAME_GOLDEN2 /* altref */ : VP56_FRAME_GOLDEN;\n\n        else\n\n            mb->ref_frame = VP56_FRAME_PREVIOUS;\n\n        s->ref_count[mb->ref_frame-1]++;\n\n\n\n        // motion vectors, 16.3\n\n        decode_mvs(s, mb, mb_x, mb_y);\n\n    } else {\n\n        // intra MB, 16.1\n\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_inter, s->prob->pred16x16);\n\n\n\n        if (mb->mode == MODE_I4x4)\n\n            decode_intra4x4_modes(s, c, mb_x, 0);\n\n\n\n        s->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree, s->prob->pred8x8c);\n\n        mb->ref_frame = VP56_FRAME_CURRENT;\n\n        mb->partitioning = VP8_SPLITMVMODE_NONE;\n\n        AV_ZERO32(&mb->bmv[0]);\n\n    }\n\n}\n", "idx": 26381, "_split": "valid", "_hash": "619baec9663ac9aff2a50a62fa2bdbad"}
{"project": "FFmpeg", "commit_id": "db5604ac26f06be34030c8ae8040c19d549280f1", "target": 1, "func": "static av_cold int join_init(AVFilterContext *ctx)\n\n{\n\n    JoinContext *s = ctx->priv;\n\n    int ret, i;\n\n\n\n    if (!(s->channel_layout = av_get_channel_layout(s->channel_layout_str))) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Error parsing channel layout '%s'.\\n\",\n\n               s->channel_layout_str);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    s->nb_channels  = av_get_channel_layout_nb_channels(s->channel_layout);\n\n    s->channels     = av_mallocz_array(s->nb_channels, sizeof(*s->channels));\n\n    s->buffers      = av_mallocz_array(s->nb_channels, sizeof(*s->buffers));\n\n    s->input_frames = av_mallocz_array(s->inputs, sizeof(*s->input_frames));\n\n    if (!s->channels || !s->buffers|| !s->input_frames)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < s->nb_channels; i++) {\n\n        s->channels[i].out_channel = av_channel_layout_extract_channel(s->channel_layout, i);\n\n        s->channels[i].input       = -1;\n\n    }\n\n\n\n    if ((ret = parse_maps(ctx)) < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < s->inputs; i++) {\n\n        char name[32];\n\n        AVFilterPad pad = { 0 };\n\n\n\n        snprintf(name, sizeof(name), \"input%d\", i);\n\n        pad.type           = AVMEDIA_TYPE_AUDIO;\n\n        pad.name           = av_strdup(name);\n\n        if (!pad.name)\n\n            return AVERROR(ENOMEM);\n\n        pad.filter_frame   = filter_frame;\n\n\n\n        pad.needs_fifo = 1;\n\n\n\n        ff_insert_inpad(ctx, i, &pad);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26389, "_split": "valid", "_hash": "5f959fbd1914b6615de3bc2dbfd8e649"}
{"project": "FFmpeg", "commit_id": "a0c624e299730c8c5800375c2f5f3c6c200053ff", "target": 1, "func": "static av_cold int v4l2_encode_init(AVCodecContext *avctx)\n\n{\n\n    V4L2m2mContext *s = avctx->priv_data;\n\n    V4L2Context *capture = &s->capture;\n\n    V4L2Context *output = &s->output;\n\n    int ret;\n\n\n\n    /* common settings output/capture */\n\n    output->height = capture->height = avctx->height;\n\n    output->width = capture->width = avctx->width;\n\n\n\n    /* output context */\n\n    output->av_codec_id = AV_CODEC_ID_RAWVIDEO;\n\n    output->av_pix_fmt = avctx->pix_fmt;\n\n\n\n    /* capture context */\n\n    capture->av_codec_id = avctx->codec_id;\n\n    capture->av_pix_fmt = AV_PIX_FMT_NONE;\n\n\n\n    ret = ff_v4l2_m2m_codec_init(avctx);\n\n    if (ret) {\n\n        av_log(avctx, AV_LOG_ERROR, \"can't configure encoder\\n\");\n\n        return ret;\n\n    }\n\n\n\n    return v4l2_prepare_encoder(s);\n\n}\n", "idx": 26414, "_split": "valid", "_hash": "e2ad745d3284551cd8df4cc15e648cbd"}
{"project": "FFmpeg", "commit_id": "4c7b023d56e09a78a587d036db1b64bf7c493b3d", "target": 0, "func": "static int nvdec_vp9_decode_slice(AVCodecContext *avctx, const uint8_t *buffer, uint32_t size)\n\n{\n\n    NVDECContext *ctx = avctx->internal->hwaccel_priv_data;\n\n    void *tmp;\n\n\n\n    tmp = av_fast_realloc(ctx->slice_offsets, &ctx->slice_offsets_allocated,\n\n                          (ctx->nb_slices + 1) * sizeof(*ctx->slice_offsets));\n\n    if (!tmp)\n\n        return AVERROR(ENOMEM);\n\n    ctx->slice_offsets = tmp;\n\n\n\n    if (!ctx->bitstream)\n\n        ctx->bitstream = (uint8_t*)buffer;\n\n\n\n    ctx->slice_offsets[ctx->nb_slices] = buffer - ctx->bitstream;\n\n    ctx->bitstream_len += size;\n\n    ctx->nb_slices++;\n\n\n\n    return 0;\n\n}\n", "idx": 26423, "_split": "valid", "_hash": "d5f37b4baeb97892de928008bbce8d89"}
{"project": "FFmpeg", "commit_id": "1c010fd035c1a14dc73827b84f21f593e969a5d6", "target": 0, "func": "static int mxf_read_header(AVFormatContext *s)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    KLVPacket klv;\n\n    int64_t essence_offset = 0;\n\n    int ret;\n\n\n\n    mxf->last_forward_tell = INT64_MAX;\n\n    mxf->edit_units_per_packet = 1;\n\n\n\n    if (!mxf_read_sync(s->pb, mxf_header_partition_pack_key, 14)) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find header partition pack key\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, -14, SEEK_CUR);\n\n    mxf->fc = s;\n\n    mxf->run_in = avio_tell(s->pb);\n\n\n\n    mxf_read_random_index_pack(s);\n\n\n\n    while (!url_feof(s->pb)) {\n\n        const MXFMetadataReadTableEntry *metadata;\n\n\n\n        if (klv_read_packet(&klv, s->pb) < 0) {\n\n            /* EOF - seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        PRINT_KEY(s, \"read header\", klv.key);\n\n        av_dlog(s, \"size %\"PRIu64\" offset %#\"PRIx64\"\\n\", klv.length, klv.offset);\n\n        if (IS_KLV_KEY(klv.key, mxf_encrypted_triplet_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_avid_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_system_item_key)) {\n\n\n\n            if (!mxf->current_partition) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"found essence prior to first PartitionPack\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if (!mxf->current_partition->essence_offset) {\n\n                /* for OP1a we compute essence_offset\n\n                 * for OPAtom we point essence_offset after the KL (usually op1a_essence_offset + 20 or 25)\n\n                 * TODO: for OP1a we could eliminate this entire if statement, always stopping parsing at op1a_essence_offset\n\n                 *       for OPAtom we still need the actual essence_offset though (the KL's length can vary)\n\n                 */\n\n                int64_t op1a_essence_offset =\n\n                    round_to_kag(mxf->current_partition->this_partition +\n\n                                 mxf->current_partition->pack_length,       mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->header_byte_count, mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->index_byte_count,  mxf->current_partition->kag_size);\n\n\n\n                if (mxf->op == OPAtom) {\n\n                    /* point essence_offset to the actual data\n\n                    * OPAtom has all the essence in one big KLV\n\n                    */\n\n                    mxf->current_partition->essence_offset = avio_tell(s->pb);\n\n                    mxf->current_partition->essence_length = klv.length;\n\n                } else {\n\n                    /* NOTE: op1a_essence_offset may be less than to klv.offset (C0023S01.mxf)  */\n\n                    mxf->current_partition->essence_offset = op1a_essence_offset;\n\n                }\n\n            }\n\n\n\n            if (!essence_offset)\n\n                essence_offset = klv.offset;\n\n\n\n            /* seek to footer, previous partition or stop */\n\n            if (mxf_parse_handle_essence(mxf) <= 0)\n\n                break;\n\n            continue;\n\n        } else if (!memcmp(klv.key, mxf_header_partition_pack_key, 13) &&\n\n                   klv.key[13] >= 2 && klv.key[13] <= 4 && mxf->current_partition) {\n\n            /* next partition pack - keep going, seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else if (mxf->parsing_backward)\n\n                continue;\n\n            /* we're still parsing forward. proceed to parsing this partition pack */\n\n        }\n\n\n\n        for (metadata = mxf_metadata_read_table; metadata->read; metadata++) {\n\n            if (IS_KLV_KEY(klv.key, metadata->key)) {\n\n                int res;\n\n                if (klv.key[5] == 0x53) {\n\n                    res = mxf_read_local_tags(mxf, &klv, metadata->read, metadata->ctx_size, metadata->type);\n\n                } else {\n\n                    uint64_t next = avio_tell(s->pb) + klv.length;\n\n                    res = metadata->read(mxf, s->pb, 0, klv.length, klv.key, klv.offset);\n\n\n\n                    /* only seek forward, else this can loop for a long time */\n\n                    if (avio_tell(s->pb) > next) {\n\n                        av_log(s, AV_LOG_ERROR, \"read past end of KLV @ %#\"PRIx64\"\\n\",\n\n                               klv.offset);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n\n\n                    avio_seek(s->pb, next, SEEK_SET);\n\n                }\n\n                if (res < 0) {\n\n                    av_log(s, AV_LOG_ERROR, \"error reading header metadata\\n\");\n\n                    return res;\n\n                }\n\n                break;\n\n            }\n\n        }\n\n        if (!metadata->read)\n\n            avio_skip(s->pb, klv.length);\n\n    }\n\n    /* FIXME avoid seek */\n\n    if (!essence_offset)  {\n\n        av_log(s, AV_LOG_ERROR, \"no essence\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, essence_offset, SEEK_SET);\n\n\n\n    mxf_compute_essence_containers(mxf);\n\n\n\n    /* we need to do this before computing the index tables\n\n     * to be able to fill in zero IndexDurations with st->duration */\n\n    if ((ret = mxf_parse_structural_metadata(mxf)) < 0)\n\n        goto fail;\n\n\n\n    if ((ret = mxf_compute_index_tables(mxf)) < 0)\n\n        goto fail;\n\n\n\n    if (mxf->nb_index_tables > 1) {\n\n        /* TODO: look up which IndexSID to use via EssenceContainerData */\n\n        av_log(mxf->fc, AV_LOG_INFO, \"got %i index tables - only the first one (IndexSID %i) will be used\\n\",\n\n               mxf->nb_index_tables, mxf->index_tables[0].index_sid);\n\n    } else if (mxf->nb_index_tables == 0 && mxf->op == OPAtom) {\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"cannot demux OPAtom without an index\\n\");\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n    mxf_handle_small_eubc(s);\n\n\n\n    return 0;\n\nfail:\n\n    mxf_read_close(s);\n\n\n\n    return ret;\n\n}\n", "idx": 26430, "_split": "valid", "_hash": "0162fc896f7cb4cb7746ab1066ce295e"}
{"project": "FFmpeg", "commit_id": "4cb6964244fd6c099383d8b7e99731e72cc844b9", "target": 0, "func": "static void int8x8_fmul_int32_c(float *dst, const int8_t *src, int scale)\n\n{\n\n    float fscale = scale / 16.0;\n\n    int i;\n\n    for (i = 0; i < 8; i++)\n\n        dst[i] = src[i] * fscale;\n\n}\n", "idx": 26459, "_split": "valid", "_hash": "63535d6aae3cb6499198586caa4054f9"}
{"project": "FFmpeg", "commit_id": "697400eac07c0614f6b9f2e7615563982dbcbe4a", "target": 0, "func": "static int mov_read_chap(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    c->chapter_track = avio_rb32(pb);\n\n    return 0;\n\n}\n", "idx": 26521, "_split": "valid", "_hash": "8488046c075c8a9ad018605832263fa5"}
{"project": "FFmpeg", "commit_id": "f863bee841670384fc46f4f99f511b27eb89a216", "target": 0, "func": "static void final(Real144_internal *glob, short *i1, short *i2, void *out,\n\n                  int *statbuf, int len)\n\n{\n\n    int x, sum;\n\n    int buffer[10];\n\n    short *ptr;\n\n    short *ptr2;\n\n\n\n    memcpy(glob->work, statbuf,20);\n\n    memcpy(glob->work + 10, i2, len * 2);\n\n\n\n    buffer[9] = i1[0];\n\n    buffer[8] = i1[1];\n\n    buffer[7] = i1[2];\n\n    buffer[6] = i1[3];\n\n    buffer[5] = i1[4];\n\n    buffer[4] = i1[5];\n\n    buffer[3] = i1[6];\n\n    buffer[2] = i1[7];\n\n    buffer[1] = i1[8];\n\n    buffer[0] = i1[9];\n\n\n\n    ptr2 = (ptr = glob->work) + len;\n\n\n\n    while (ptr < ptr2) {\n\n        for(sum=0, x=0; x<=9; x++)\n\n            sum += buffer[x] * (ptr[x]);\n\n\n\n        sum = sum >> 12;\n\n        x = ptr[10] - sum;\n\n\n\n        if (x<-32768 || x>32767) {\n\n            memset(out, 0, len * 2);\n\n            memset(statbuf, 0, 20);\n\n            return;\n\n        }\n\n\n\n        ptr[10] = x;\n\n        ptr++;\n\n    }\n\n    memcpy(out, ptr+10 - len, len * 2);\n\n    memcpy(statbuf, ptr, 20);\n\n}\n", "idx": 26525, "_split": "valid", "_hash": "73a41508adb839361afa5e9ad5c5aad3"}
{"project": "FFmpeg", "commit_id": "c8241e730f116f1c9cfc0b34110aa7f052e05332", "target": 0, "func": "static AVBufferRef *vaapi_encode_alloc_output_buffer(void *opaque,\n\n                                                     int size)\n\n{\n\n    AVCodecContext   *avctx = opaque;\n\n    VAAPIEncodeContext *ctx = avctx->priv_data;\n\n    VABufferID buffer_id;\n\n    VAStatus vas;\n\n    AVBufferRef *ref;\n\n\n\n    // The output buffer size is fixed, so it needs to be large enough\n\n    // to hold the largest possible compressed frame.  We assume here\n\n    // that the uncompressed frame plus some header data is an upper\n\n    // bound on that.\n\n    vas = vaCreateBuffer(ctx->hwctx->display, ctx->va_context,\n\n                         VAEncCodedBufferType,\n\n                         3 * ctx->aligned_width * ctx->aligned_height +\n\n                         (1 << 16), 1, 0, &buffer_id);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to create bitstream \"\n\n               \"output buffer: %d (%s).\\n\", vas, vaErrorStr(vas));\n\n        return NULL;\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Allocated output buffer %#x\\n\", buffer_id);\n\n\n\n    ref = av_buffer_create((uint8_t*)(uintptr_t)buffer_id,\n\n                           sizeof(buffer_id),\n\n                           &vaapi_encode_free_output_buffer,\n\n                           avctx, AV_BUFFER_FLAG_READONLY);\n\n    if (!ref) {\n\n        vaDestroyBuffer(ctx->hwctx->display, buffer_id);\n\n        return NULL;\n\n    }\n\n\n\n    return ref;\n\n}\n", "idx": 26537, "_split": "valid", "_hash": "ddde63834aaf6841e559e03fd805280c"}
{"project": "FFmpeg", "commit_id": "5d20f19be25c973fe10d0d17db9245002585710d", "target": 1, "func": "static void init_multbl2(uint8_t tbl[1024], const int c[4],\n\n                         const uint8_t *log8, const uint8_t *alog8,\n\n                         const uint8_t *sbox)\n\n{\n\n    int i, j;\n\n\n\n    for (i = 0; i < 1024; i++) {\n\n        int x = sbox[i >> 2];\n\n        if (x)\n\n            tbl[i] = alog8[log8[x] + log8[c[i & 3]]];\n\n    }\n\n#if !CONFIG_SMALL\n\n    for (j = 256; j < 1024; j++)\n\n        for (i = 0; i < 4; i++)\n\n            tbl[4*j + i] = tbl[4*j + ((i - 1) & 3) - 1024];\n\n#endif\n\n}\n", "idx": 26584, "_split": "valid", "_hash": "217d337f30851ec23bd393638e97cbbf"}
{"project": "FFmpeg", "commit_id": "9bff052b51f27f6cce04e8d7d8b405c710d7ad67", "target": 0, "func": "static void blur(uint8_t       *dst, const int dst_linesize,\n\n                 const uint8_t *src, const int src_linesize,\n\n                 const int w, const int h, FilterParam *fp)\n\n{\n\n    int x, y;\n\n    FilterParam f = *fp;\n\n    const int radius = f.dist_width/2;\n\n\n\n    const uint8_t * const src2[NB_PLANES] = { src };\n\n    int          src2_linesize[NB_PLANES] = { src_linesize };\n\n    uint8_t     *dst2[NB_PLANES] = { f.pre_filter_buf };\n\n    int dst2_linesize[NB_PLANES] = { f.pre_filter_linesize };\n\n\n\n    sws_scale(f.pre_filter_context, src2, src2_linesize, 0, h, dst2, dst2_linesize);\n\n\n\n#define UPDATE_FACTOR do {                                              \\\n\n        int factor;                                                     \\\n\n        factor = f.color_diff_coeff[COLOR_DIFF_COEFF_SIZE/2 + pre_val - \\\n\n                 f.pre_filter_buf[ix + iy*f.pre_filter_linesize]] * f.dist_coeff[dx + dy*f.dist_linesize]; \\\n\n        sum += src[ix + iy*src_linesize] * factor;                      \\\n\n        div += factor;                                                  \\\n\n    } while (0)\n\n\n\n    for (y = 0; y < h; y++) {\n\n        for (x = 0; x < w; x++) {\n\n            int sum = 0;\n\n            int div = 0;\n\n            int dy;\n\n            const int pre_val = f.pre_filter_buf[x + y*f.pre_filter_linesize];\n\n            if (x >= radius && x < w - radius) {\n\n                for (dy = 0; dy < radius*2 + 1; dy++) {\n\n                    int dx;\n\n                    int iy = y+dy - radius;\n\n                    if      (iy < 0)  iy = -iy;\n\n                    else if (iy >= h) iy = h+h-iy-1;\n\n\n\n                    for (dx = 0; dx < radius*2 + 1; dx++) {\n\n                        const int ix = x+dx - radius;\n\n                        UPDATE_FACTOR;\n\n                    }\n\n                }\n\n            } else {\n\n                for (dy = 0; dy < radius*2+1; dy++) {\n\n                    int dx;\n\n                    int iy = y+dy - radius;\n\n                    if      (iy <  0) iy = -iy;\n\n                    else if (iy >= h) iy = h+h-iy-1;\n\n\n\n                    for (dx = 0; dx < radius*2 + 1; dx++) {\n\n                        int ix = x+dx - radius;\n\n                        if      (ix < 0)  ix = -ix;\n\n                        else if (ix >= w) ix = w+w-ix-1;\n\n                        UPDATE_FACTOR;\n\n                    }\n\n                }\n\n            }\n\n            dst[x + y*dst_linesize] = (sum + div/2) / div;\n\n        }\n\n    }\n\n}\n", "idx": 26614, "_split": "valid", "_hash": "fb2df6b436e356cbcbd1188f61bd959c"}
{"project": "FFmpeg", "commit_id": "bd737b5178f361a9b592691848f29a7a79603a7e", "target": 0, "func": "static int decode_init_thread_copy(AVCodecContext *avctx)\n\n{\n\n    H264Context *h = avctx->priv_data;\n\n    int ret;\n\n\n\n    if (!avctx->internal->is_copy)\n\n        return 0;\n\n    memset(h->sps_buffers, 0, sizeof(h->sps_buffers));\n\n    memset(h->pps_buffers, 0, sizeof(h->pps_buffers));\n\n\n\n    ret = h264_init_context(avctx, h);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    h->context_initialized = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 26629, "_split": "valid", "_hash": "85ed62b2afb33c4284154716cdafff93"}
{"project": "FFmpeg", "commit_id": "488a0fa68973d48e264d54f1722f7afb18afbea7", "target": 0, "func": "static int configure_input_audio_filter(FilterGraph *fg, InputFilter *ifilter,\n\n                                        AVFilterInOut *in)\n\n{\n\n    AVFilterContext *last_filter;\n\n    const AVFilter *abuffer_filt = avfilter_get_by_name(\"abuffer\");\n\n    InputStream *ist = ifilter->ist;\n\n    InputFile     *f = input_files[ist->file_index];\n\n    char args[255], name[255];\n\n    int ret, pad_idx = 0;\n\n\n\n    snprintf(args, sizeof(args), \"time_base=%d/%d:sample_rate=%d:sample_fmt=%s\"\n\n             \":channel_layout=0x%\"PRIx64,\n\n             1, ist->st->codec->sample_rate,\n\n             ist->st->codec->sample_rate,\n\n             av_get_sample_fmt_name(ist->st->codec->sample_fmt),\n\n             ist->st->codec->channel_layout);\n\n    snprintf(name, sizeof(name), \"graph %d input from stream %d:%d\", fg->index,\n\n             ist->file_index, ist->st->index);\n\n\n\n    if ((ret = avfilter_graph_create_filter(&ifilter->filter, abuffer_filt,\n\n                                            name, args, NULL,\n\n                                            fg->graph)) < 0)\n\n        return ret;\n\n    last_filter = ifilter->filter;\n\n\n\n    if (audio_sync_method > 0) {\n\n        AVFilterContext *async;\n\n        int  len = 0;\n\n\n\n        av_log(NULL, AV_LOG_WARNING, \"-async has been deprecated. Used the \"\n\n               \"asyncts audio filter instead.\\n\");\n\n\n\n        if (audio_sync_method > 1)\n\n            len += snprintf(args + len, sizeof(args) - len, \"compensate=1:\"\n\n                            \"max_comp=%d:\", audio_sync_method);\n\n        snprintf(args + len, sizeof(args) - len, \"min_delta=%f\",\n\n                 audio_drift_threshold);\n\n\n\n        snprintf(name, sizeof(name), \"graph %d audio sync for input stream %d:%d\",\n\n                 fg->index, ist->file_index, ist->st->index);\n\n        ret = avfilter_graph_create_filter(&async,\n\n                                           avfilter_get_by_name(\"asyncts\"),\n\n                                           name, args, NULL, fg->graph);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = avfilter_link(last_filter, 0, async, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        last_filter = async;\n\n    }\n\n    if (audio_volume != 256) {\n\n        AVFilterContext *volume;\n\n\n\n        av_log(NULL, AV_LOG_WARNING, \"-vol has been deprecated. Use the volume \"\n\n               \"audio filter instead.\\n\");\n\n\n\n        snprintf(args, sizeof(args), \"volume=%f\", audio_volume / 256.0);\n\n\n\n        snprintf(name, sizeof(name), \"graph %d volume for input stream %d:%d\",\n\n                 fg->index, ist->file_index, ist->st->index);\n\n        ret = avfilter_graph_create_filter(&volume,\n\n                                           avfilter_get_by_name(\"volume\"),\n\n                                           name, args, NULL, fg->graph);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        ret = avfilter_link(last_filter, 0, volume, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        last_filter = volume;\n\n    }\n\n\n\n    snprintf(name, sizeof(name), \"trim for input stream %d:%d\",\n\n             ist->file_index, ist->st->index);\n\n    ret = insert_trim(((f->start_time == AV_NOPTS_VALUE) || !f->accurate_seek) ?\n\n                      AV_NOPTS_VALUE : 0, INT64_MAX, &last_filter, &pad_idx, name);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if ((ret = avfilter_link(last_filter, 0, in->filter_ctx, in->pad_idx)) < 0)\n\n        return ret;\n\n\n\n    return 0;\n\n}\n", "idx": 26664, "_split": "valid", "_hash": "d885d119b7187e028c140bde8b2063da"}
{"project": "FFmpeg", "commit_id": "8dca0877e3e1457e9ec79ffa1ead1135aabb791c", "target": 0, "func": "static int mpegts_write_packet_internal(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVStream *st = s->streams[pkt->stream_index];\n\n    int size = pkt->size;\n\n    uint8_t *buf = pkt->data;\n\n    uint8_t *data = NULL;\n\n    MpegTSWrite *ts = s->priv_data;\n\n    MpegTSWriteStream *ts_st = st->priv_data;\n\n    const uint64_t delay = av_rescale(s->max_delay, 90000, AV_TIME_BASE) * 2;\n\n    int64_t dts = AV_NOPTS_VALUE, pts = AV_NOPTS_VALUE;\n\n\n\n    if (ts->reemit_pat_pmt) {\n\n        av_log(s, AV_LOG_WARNING,\n\n               \"resend_headers option is deprecated, use -mpegts_flags resend_headers\\n\");\n\n        ts->reemit_pat_pmt = 0;\n\n        ts->flags         |= MPEGTS_FLAG_REEMIT_PAT_PMT;\n\n    }\n\n\n\n    if (ts->flags & MPEGTS_FLAG_REEMIT_PAT_PMT) {\n\n        ts->pat_packet_count = ts->pat_packet_period - 1;\n\n        ts->sdt_packet_count = ts->sdt_packet_period - 1;\n\n        ts->flags           &= ~MPEGTS_FLAG_REEMIT_PAT_PMT;\n\n    }\n\n\n\n    if (pkt->pts != AV_NOPTS_VALUE)\n\n        pts = pkt->pts + delay;\n\n    if (pkt->dts != AV_NOPTS_VALUE)\n\n        dts = pkt->dts + delay;\n\n\n\n    if (ts_st->first_pts_check && pts == AV_NOPTS_VALUE) {\n\n        av_log(s, AV_LOG_ERROR, \"first pts value must set\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    ts_st->first_pts_check = 0;\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_H264) {\n\n        const uint8_t *p = buf, *buf_end = p + size;\n\n        uint32_t state = -1;\n\n\n\n        if (pkt->size < 5 || AV_RB32(pkt->data) != 0x0000001) {\n\n            av_log(s, AV_LOG_ERROR, \"H.264 bitstream malformed, \"\n\n                   \"no startcode found, use -bsf h264_mp4toannexb\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        do {\n\n            p = avpriv_find_start_code(p, buf_end, &state);\n\n            av_dlog(s, \"nal %d\\n\", state & 0x1f);\n\n        } while (p < buf_end && (state & 0x1f) != 9 &&\n\n                 (state & 0x1f) != 5 && (state & 0x1f) != 1);\n\n\n\n        if ((state & 0x1f) != 9) { // AUD NAL\n\n            data = av_malloc(pkt->size + 6);\n\n            if (!data)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(data + 6, pkt->data, pkt->size);\n\n            AV_WB32(data, 0x00000001);\n\n            data[4] = 0x09;\n\n            data[5] = 0xf0; // any slice type (0xe) + rbsp stop one bit\n\n            buf     = data;\n\n            size    = pkt->size + 6;\n\n        }\n\n    } else if (st->codec->codec_id == AV_CODEC_ID_AAC) {\n\n        if (pkt->size < 2) {\n\n            av_log(s, AV_LOG_ERROR, \"AAC packet too short\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        if ((AV_RB16(pkt->data) & 0xfff0) != 0xfff0) {\n\n            int ret;\n\n            AVPacket pkt2;\n\n\n\n            if (!ts_st->amux) {\n\n                av_log(s, AV_LOG_ERROR, \"AAC bitstream not in ADTS format \"\n\n                                        \"and extradata missing\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            av_init_packet(&pkt2);\n\n            pkt2.data = pkt->data;\n\n            pkt2.size = pkt->size;\n\n\n\n            ret = avio_open_dyn_buf(&ts_st->amux->pb);\n\n            if (ret < 0)\n\n                return AVERROR(ENOMEM);\n\n\n\n            ret = av_write_frame(ts_st->amux, &pkt2);\n\n            if (ret < 0) {\n\n                avio_close_dyn_buf(ts_st->amux->pb, &data);\n\n                ts_st->amux->pb = NULL;\n\n                av_free(data);\n\n                return ret;\n\n            }\n\n            size            = avio_close_dyn_buf(ts_st->amux->pb, &data);\n\n            ts_st->amux->pb = NULL;\n\n            buf             = data;\n\n        }\n\n    }\n\n\n\n    if (st->codec->codec_type != AVMEDIA_TYPE_AUDIO) {\n\n        // for video and subtitle, write a single pes packet\n\n        mpegts_write_pes(s, st, buf, size, pts, dts,\n\n                         pkt->flags & AV_PKT_FLAG_KEY);\n\n        av_free(data);\n\n        return 0;\n\n    }\n\n\n\n    if (ts_st->payload_size + size > ts->pes_payload_size) {\n\n        if (ts_st->payload_size) {\n\n            mpegts_write_pes(s, st, ts_st->payload, ts_st->payload_size,\n\n                             ts_st->payload_pts, ts_st->payload_dts,\n\n                             ts_st->payload_flags & AV_PKT_FLAG_KEY);\n\n            ts_st->payload_size = 0;\n\n        }\n\n        if (size > ts->pes_payload_size) {\n\n            mpegts_write_pes(s, st, buf, size, pts, dts,\n\n                             pkt->flags & AV_PKT_FLAG_KEY);\n\n            av_free(data);\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    if (!ts_st->payload_size) {\n\n        ts_st->payload_pts   = pts;\n\n        ts_st->payload_dts   = dts;\n\n        ts_st->payload_flags = pkt->flags;\n\n    }\n\n\n\n    memcpy(ts_st->payload + ts_st->payload_size, buf, size);\n\n    ts_st->payload_size += size;\n\n\n\n    av_free(data);\n\n\n\n    return 0;\n\n}\n", "idx": 26665, "_split": "valid", "_hash": "f545b9b8e74d8fcbac9c98b11d87cec2"}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(hyscale_fast)(SwsContext *c, int16_t *dst,\n\n                                        int dstWidth, const uint8_t *src, int srcW,\n\n                                        int xInc)\n\n{\n\n#if ARCH_X86\n\n#if COMPILE_TEMPLATE_MMX2\n\n    int32_t *filterPos = c->hLumFilterPos;\n\n    int16_t *filter    = c->hLumFilter;\n\n    int     canMMX2BeUsed  = c->canMMX2BeUsed;\n\n    void    *mmx2FilterCode= c->lumMmx2FilterCode;\n\n    int i;\n\n#if defined(PIC)\n\n    DECLARE_ALIGNED(8, uint64_t, ebxsave);\n\n#endif\n\n    if (canMMX2BeUsed) {\n\n        __asm__ volatile(\n\n#if defined(PIC)\n\n            \"mov               %%\"REG_b\", %5        \\n\\t\"\n\n#endif\n\n            \"pxor                  %%mm7, %%mm7     \\n\\t\"\n\n            \"mov                      %0, %%\"REG_c\" \\n\\t\"\n\n            \"mov                      %1, %%\"REG_D\" \\n\\t\"\n\n            \"mov                      %2, %%\"REG_d\" \\n\\t\"\n\n            \"mov                      %3, %%\"REG_b\" \\n\\t\"\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\" // i\n\n            PREFETCH\"        (%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      32(%%\"REG_c\")            \\n\\t\"\n\n            PREFETCH\"      64(%%\"REG_c\")            \\n\\t\"\n\n\n\n#if ARCH_X86_64\n\n\n\n#define CALL_MMX2_FILTER_CODE \\\n\n            \"movl            (%%\"REG_b\"), %%esi     \\n\\t\"\\\n\n            \"call                    *%4            \\n\\t\"\\\n\n            \"movl (%%\"REG_b\", %%\"REG_a\"), %%esi     \\n\\t\"\\\n\n            \"add               %%\"REG_S\", %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#else\n\n\n\n#define CALL_MMX2_FILTER_CODE \\\n\n            \"movl (%%\"REG_b\"), %%esi        \\n\\t\"\\\n\n            \"call         *%4                       \\n\\t\"\\\n\n            \"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\" \\n\\t\"\\\n\n            \"add               %%\"REG_a\", %%\"REG_D\" \\n\\t\"\\\n\n            \"xor               %%\"REG_a\", %%\"REG_a\" \\n\\t\"\\\n\n\n\n#endif /* ARCH_X86_64 */\n\n\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n            CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n            \"mov                      %5, %%\"REG_b\" \\n\\t\"\n\n#endif\n\n            :: \"m\" (src), \"m\" (dst), \"m\" (filter), \"m\" (filterPos),\n\n            \"m\" (mmx2FilterCode)\n\n#if defined(PIC)\n\n            ,\"m\" (ebxsave)\n\n#endif\n\n            : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n            ,\"%\"REG_b\n\n#endif\n\n        );\n\n        for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) dst[i] = src[srcW-1]*128;\n\n    } else {\n\n#endif /* COMPILE_TEMPLATE_MMX2 */\n\n    x86_reg dstWidth_reg = dstWidth;\n\n    x86_reg xInc_shr16 = xInc >> 16;\n\n    uint16_t xInc_mask = xInc & 0xffff;\n\n    //NO MMX just normal asm ...\n\n    __asm__ volatile(\n\n        \"xor %%\"REG_a\", %%\"REG_a\"            \\n\\t\" // i\n\n        \"xor %%\"REG_d\", %%\"REG_d\"            \\n\\t\" // xx\n\n        \"xorl    %%ecx, %%ecx                \\n\\t\" // xalpha\n\n        ASMALIGN(4)\n\n        \"1:                                  \\n\\t\"\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        FAST_BILINEAR_X86\n\n        \"movw     %%si, (%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //xalpha += xInc&0xFFFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>16 + carry\n\n\n\n        \"movzbl    (%0, %%\"REG_d\"), %%edi    \\n\\t\" //src[xx]\n\n        \"movzbl   1(%0, %%\"REG_d\"), %%esi    \\n\\t\" //src[xx+1]\n\n        FAST_BILINEAR_X86\n\n        \"movw     %%si, 2(%%\"REG_D\", %%\"REG_a\", 2)  \\n\\t\"\n\n        \"addw       %4, %%cx                 \\n\\t\" //xalpha += xInc&0xFFFF\n\n        \"adc        %3, %%\"REG_d\"            \\n\\t\" //xx+= xInc>>16 + carry\n\n\n\n\n\n        \"add        $2, %%\"REG_a\"            \\n\\t\"\n\n        \"cmp        %2, %%\"REG_a\"            \\n\\t\"\n\n        \" jb        1b                       \\n\\t\"\n\n\n\n\n\n        :: \"r\" (src), \"m\" (dst), \"m\" (dstWidth_reg), \"m\" (xInc_shr16), \"m\" (xInc_mask)\n\n        : \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n    );\n\n#if COMPILE_TEMPLATE_MMX2\n\n    } //if MMX2 can't be used\n\n#endif\n\n#else\n\n    int i;\n\n    unsigned int xpos=0;\n\n    for (i=0;i<dstWidth;i++) {\n\n        register unsigned int xx=xpos>>16;\n\n        register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n        dst[i]= (src[xx]<<7) + (src[xx+1] - src[xx])*xalpha;\n\n        xpos+=xInc;\n\n    }\n\n#endif /* ARCH_X86 */\n\n}\n", "idx": 26727, "_split": "valid", "_hash": "4ad4e5b547af864875a65954070916e6"}
{"project": "FFmpeg", "commit_id": "9d0b45ade864f3d2ccd8610149fe1fff53c4e937", "target": 1, "func": "static int decrypt_init(AVFormatContext *s, ID3v2ExtraMeta *em, uint8_t *header)\n\n{\n\n    OMAContext *oc = s->priv_data;\n\n    ID3v2ExtraMetaGEOB *geob = NULL;\n\n    uint8_t *gdata;\n\n\n\n    oc->encrypted = 1;\n\n    av_log(s, AV_LOG_INFO, \"File is encrypted\\n\");\n\n\n\n    /* find GEOB metadata */\n\n    while (em) {\n\n        if (!strcmp(em->tag, \"GEOB\") &&\n\n            (geob = em->data) &&\n\n            (!strcmp(geob->description, \"OMG_LSI\") ||\n\n             !strcmp(geob->description, \"OMG_BKLSI\"))) {\n\n            break;\n\n        }\n\n        em = em->next;\n\n    }\n\n    if (!em) {\n\n        av_log(s, AV_LOG_ERROR, \"No encryption header found\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (geob->datasize < 64) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"Invalid GEOB data size: %u\\n\", geob->datasize);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    gdata = geob->data;\n\n\n\n    if (AV_RB16(gdata) != 1)\n\n        av_log(s, AV_LOG_WARNING, \"Unknown version in encryption header\\n\");\n\n\n\n    oc->k_size = AV_RB16(&gdata[2]);\n\n    oc->e_size = AV_RB16(&gdata[4]);\n\n    oc->i_size = AV_RB16(&gdata[6]);\n\n    oc->s_size = AV_RB16(&gdata[8]);\n\n\n\n    if (memcmp(&gdata[OMA_ENC_HEADER_SIZE], \"KEYRING     \", 12)) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid encryption header\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    oc->rid = AV_RB32(&gdata[OMA_ENC_HEADER_SIZE + 28]);\n\n    av_log(s, AV_LOG_DEBUG, \"RID: %.8x\\n\", oc->rid);\n\n\n\n    memcpy(oc->iv, &header[0x58], 8);\n\n    hex_log(s, AV_LOG_DEBUG, \"IV\", oc->iv, 8);\n\n\n\n    hex_log(s, AV_LOG_DEBUG, \"CBC-MAC\",\n\n            &gdata[OMA_ENC_HEADER_SIZE + oc->k_size + oc->e_size + oc->i_size],\n\n            8);\n\n\n\n    if (s->keylen > 0) {\n\n        kset(s, s->key, s->key, s->keylen);\n\n    }\n\n    if (!memcmp(oc->r_val, (const uint8_t[8]){0}, 8) ||\n\n        rprobe(s, gdata, oc->r_val) < 0 &&\n\n        nprobe(s, gdata, geob->datasize, oc->n_val) < 0) {\n\n        int i;\n\n        for (i = 0; i < FF_ARRAY_ELEMS(leaf_table); i += 2) {\n\n            uint8_t buf[16];\n\n            AV_WL64(buf,     leaf_table[i]);\n\n            AV_WL64(&buf[8], leaf_table[i + 1]);\n\n            kset(s, buf, buf, 16);\n\n            if (!rprobe(s, gdata, oc->r_val) ||\n\n                !nprobe(s, gdata, geob->datasize, oc->n_val))\n\n                break;\n\n        }\n\n        if (i >= sizeof(leaf_table)) {\n\n            av_log(s, AV_LOG_ERROR, \"Invalid key\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    /* e_val */\n\n    av_des_init(&oc->av_des, oc->m_val, 64, 0);\n\n    av_des_crypt(&oc->av_des, oc->e_val,\n\n                 &gdata[OMA_ENC_HEADER_SIZE + 40], 1, NULL, 0);\n\n    hex_log(s, AV_LOG_DEBUG, \"EK\", oc->e_val, 8);\n\n\n\n    /* init e_val */\n\n    av_des_init(&oc->av_des, oc->e_val, 64, 1);\n\n\n\n    return 0;\n\n}\n", "idx": 26728, "_split": "valid", "_hash": "0fce8a644e96e0611c452cefac6e2bf0"}
{"project": "FFmpeg", "commit_id": "ee16a0ced01e6a33b7b01a0b21a0e07c1e1c7884", "target": 0, "func": "static int smacker_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    SmackerContext *smk = s->priv_data;\n\n    int flags;\n\n    int ret;\n\n    int i;\n\n    int frame_size = 0;\n\n    int palchange = 0;\n\n\n\n    if (s->pb->eof_reached || smk->cur_frame >= smk->frames)\n\n        return AVERROR_EOF;\n\n\n\n    /* if we demuxed all streams, pass another frame */\n\n    if(smk->curstream < 0) {\n\n        avio_seek(s->pb, smk->nextpos, 0);\n\n        frame_size = smk->frm_size[smk->cur_frame] & (~3);\n\n        flags = smk->frm_flags[smk->cur_frame];\n\n        /* handle palette change event */\n\n        if(flags & SMACKER_PAL){\n\n            int size, sz, t, off, j, pos;\n\n            uint8_t *pal = smk->pal;\n\n            uint8_t oldpal[768];\n\n\n\n            memcpy(oldpal, pal, 768);\n\n            size = avio_r8(s->pb);\n\n            size = size * 4 - 1;\n\n            frame_size -= size;\n\n            frame_size--;\n\n            sz = 0;\n\n            pos = avio_tell(s->pb) + size;\n\n            while(sz < 256){\n\n                t = avio_r8(s->pb);\n\n                if(t & 0x80){ /* skip palette entries */\n\n                    sz += (t & 0x7F) + 1;\n\n                    pal += ((t & 0x7F) + 1) * 3;\n\n                } else if(t & 0x40){ /* copy with offset */\n\n                    off = avio_r8(s->pb);\n\n                    j = (t & 0x3F) + 1;\n\n                    if (off + j > 0x100) {\n\n                        av_log(s, AV_LOG_ERROR,\n\n                               \"Invalid palette update, offset=%d length=%d extends beyond palette size\\n\",\n\n                               off, j);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    off *= 3;\n\n                    while(j-- && sz < 256) {\n\n                        *pal++ = oldpal[off + 0];\n\n                        *pal++ = oldpal[off + 1];\n\n                        *pal++ = oldpal[off + 2];\n\n                        sz++;\n\n                        off += 3;\n\n                    }\n\n                } else { /* new entries */\n\n                    *pal++ = smk_pal[t];\n\n                    *pal++ = smk_pal[avio_r8(s->pb) & 0x3F];\n\n                    *pal++ = smk_pal[avio_r8(s->pb) & 0x3F];\n\n                    sz++;\n\n                }\n\n            }\n\n            avio_seek(s->pb, pos, 0);\n\n            palchange |= 1;\n\n        }\n\n        flags >>= 1;\n\n        smk->curstream = -1;\n\n        /* if audio chunks are present, put them to stack and retrieve later */\n\n        for(i = 0; i < 7; i++) {\n\n            if(flags & 1) {\n\n                int size;\n\n                uint8_t *tmpbuf;\n\n\n\n                size = avio_rl32(s->pb) - 4;\n\n                frame_size -= size;\n\n                frame_size -= 4;\n\n                smk->curstream++;\n\n                tmpbuf = av_realloc(smk->bufs[smk->curstream], size);\n\n                if (!tmpbuf)\n\n                    return AVERROR(ENOMEM);\n\n                smk->bufs[smk->curstream] = tmpbuf;\n\n                smk->buf_sizes[smk->curstream] = size;\n\n                ret = avio_read(s->pb, smk->bufs[smk->curstream], size);\n\n                if(ret != size)\n\n                    return AVERROR(EIO);\n\n                smk->stream_id[smk->curstream] = smk->indexes[i];\n\n            }\n\n            flags >>= 1;\n\n        }\n\n        if (frame_size < 0)\n\n            return AVERROR_INVALIDDATA;\n\n        if (av_new_packet(pkt, frame_size + 769))\n\n            return AVERROR(ENOMEM);\n\n        if(smk->frm_size[smk->cur_frame] & 1)\n\n            palchange |= 2;\n\n        pkt->data[0] = palchange;\n\n        memcpy(pkt->data + 1, smk->pal, 768);\n\n        ret = avio_read(s->pb, pkt->data + 769, frame_size);\n\n        if(ret != frame_size)\n\n            return AVERROR(EIO);\n\n        pkt->stream_index = smk->videoindex;\n\n        pkt->pts          = smk->cur_frame;\n\n        pkt->size = ret + 769;\n\n        smk->cur_frame++;\n\n        smk->nextpos = avio_tell(s->pb);\n\n    } else {\n\n        if (av_new_packet(pkt, smk->buf_sizes[smk->curstream]))\n\n            return AVERROR(ENOMEM);\n\n        memcpy(pkt->data, smk->bufs[smk->curstream], smk->buf_sizes[smk->curstream]);\n\n        pkt->size = smk->buf_sizes[smk->curstream];\n\n        pkt->stream_index = smk->stream_id[smk->curstream];\n\n        pkt->pts = smk->aud_pts[smk->curstream];\n\n        smk->aud_pts[smk->curstream] += AV_RL32(pkt->data);\n\n        smk->curstream--;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26746, "_split": "valid", "_hash": "907355f0025378846150029bbc88b718"}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int parse_fragment(AVFormatContext *s, const char *filename, int64_t *start_ts, int64_t *duration, int64_t *moof_size, int64_t size)\n\n{\n\n    AVIOContext *in;\n\n    int ret;\n\n    uint32_t len;\n\n    if ((ret = avio_open2(&in, filename, AVIO_FLAG_READ, &s->interrupt_callback, NULL)) < 0)\n\n        return ret;\n\n    ret = AVERROR(EIO);\n\n    *moof_size = avio_rb32(in);\n\n    if (*moof_size < 8 || *moof_size > size)\n\n        goto fail;\n\n    if (avio_rl32(in) != MKTAG('m','o','o','f'))\n\n        goto fail;\n\n    len = avio_rb32(in);\n\n    if (len > *moof_size)\n\n        goto fail;\n\n    if (avio_rl32(in) != MKTAG('m','f','h','d'))\n\n        goto fail;\n\n    avio_seek(in, len - 8, SEEK_CUR);\n\n    avio_rb32(in); /* traf size */\n\n    if (avio_rl32(in) != MKTAG('t','r','a','f'))\n\n        goto fail;\n\n    while (avio_tell(in) < *moof_size) {\n\n        uint32_t len = avio_rb32(in);\n\n        uint32_t tag = avio_rl32(in);\n\n        int64_t end = avio_tell(in) + len - 8;\n\n        if (len < 8 || len >= *moof_size)\n\n            goto fail;\n\n        if (tag == MKTAG('u','u','i','d')) {\n\n            const uint8_t tfxd[] = {\n\n                0x6d, 0x1d, 0x9b, 0x05, 0x42, 0xd5, 0x44, 0xe6,\n\n                0x80, 0xe2, 0x14, 0x1d, 0xaf, 0xf7, 0x57, 0xb2\n\n            };\n\n            uint8_t uuid[16];\n\n            avio_read(in, uuid, 16);\n\n            if (!memcmp(uuid, tfxd, 16) && len >= 8 + 16 + 4 + 16) {\n\n                avio_seek(in, 4, SEEK_CUR);\n\n                *start_ts = avio_rb64(in);\n\n                *duration = avio_rb64(in);\n\n                ret = 0;\n\n                break;\n\n            }\n\n        }\n\n        avio_seek(in, end, SEEK_SET);\n\n    }\n\nfail:\n\n    avio_close(in);\n\n    return ret;\n\n}\n", "idx": 26762, "_split": "valid", "_hash": "31f7d0a42920e7bfd9d9e0dd798663d7"}
{"project": "FFmpeg", "commit_id": "240fd8c96f59ebe9dcfc4152a1086cd3f63400c0", "target": 0, "func": "int av_packet_split_side_data(AVPacket *pkt){\n\n    if (!pkt->side_data_elems && pkt->size >12 && AV_RB64(pkt->data + pkt->size - 8) == FF_MERGE_MARKER){\n\n        int i;\n\n        unsigned int size, orig_pktsize = pkt->size;\n\n        uint8_t *p;\n\n\n\n        p = pkt->data + pkt->size - 8 - 5;\n\n        for (i=1; ; i++){\n\n            size = AV_RB32(p);\n\n            if (size>INT_MAX || p - pkt->data < size)\n\n                return 0;\n\n            if (p[4]&128)\n\n                break;\n\n            p-= size+5;\n\n        }\n\n\n\n        pkt->side_data = av_malloc(i * sizeof(*pkt->side_data));\n\n        if (!pkt->side_data)\n\n            return AVERROR(ENOMEM);\n\n\n\n        p= pkt->data + pkt->size - 8 - 5;\n\n        for (i=0; ; i++){\n\n            size= AV_RB32(p);\n\n            av_assert0(size<=INT_MAX && p - pkt->data >= size);\n\n            pkt->side_data[i].data = av_malloc(size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            pkt->side_data[i].size = size;\n\n            pkt->side_data[i].type = p[4]&127;\n\n            if (!pkt->side_data[i].data)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(pkt->side_data[i].data, p-size, size);\n\n            pkt->size -= size + 5;\n\n            if(p[4]&128)\n\n                break;\n\n            p-= size+5;\n\n        }\n\n        pkt->size -= 8;\n\n        /* FFMIN() prevents overflow in case the packet wasn't allocated with\n\n         * proper padding.\n\n         * If the side data is smaller than the buffer padding size, the\n\n         * remaining bytes should have already been filled with zeros by the\n\n         * original packet allocation anyway. */\n\n        memset(pkt->data + pkt->size, 0,\n\n               FFMIN(orig_pktsize - pkt->size, FF_INPUT_BUFFER_PADDING_SIZE));\n\n        pkt->side_data_elems = i+1;\n\n        return 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 26818, "_split": "valid", "_hash": "45acd03541606453a614aa0acc4d7117"}
{"project": "FFmpeg", "commit_id": "f6b7f72461673e4d398b1edf9ed2a7fe70d99c47", "target": 0, "func": "static void av_always_inline filter_mb_edgech( uint8_t *pix, int stride, const int16_t bS[4], unsigned int qp, H264Context *h, int intra ) {\n\n    const int qp_bd_offset = 6 * (h->sps.bit_depth_luma - 8);\n\n    const unsigned int index_a = qp - qp_bd_offset + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = beta_table[qp - qp_bd_offset + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 || !intra ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]]+1;\n\n        tc[1] = tc0_table[index_a][bS[1]]+1;\n\n        tc[2] = tc0_table[index_a][bS[2]]+1;\n\n        tc[3] = tc0_table[index_a][bS[3]]+1;\n\n        h->h264dsp.h264_v_loop_filter_chroma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->h264dsp.h264_v_loop_filter_chroma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 26870, "_split": "valid", "_hash": "2a37f94e94f23f742b98c7b4a2085b4f"}
{"project": "FFmpeg", "commit_id": "fbd6c97f9ca858140df16dd07200ea0d4bdc1a83", "target": 1, "func": "AVBufferRef *av_buffer_pool_get(AVBufferPool *pool)\n\n{\n\n    AVBufferRef *ret;\n\n    BufferPoolEntry *buf;\n\n\n\n    /* check whether the pool is empty */\n\n    buf = get_pool(pool);\n\n    if (!buf)\n\n        return pool_alloc_buffer(pool);\n\n\n\n    /* keep the first entry, return the rest of the list to the pool */\n\n    add_to_pool(buf->next);\n\n    buf->next = NULL;\n\n\n\n    ret = av_buffer_create(buf->data, pool->size, pool_release_buffer,\n\n                           buf, 0);\n\n    if (!ret) {\n\n        add_to_pool(buf);\n\n        return NULL;\n\n    }\n\n    avpriv_atomic_int_add_and_fetch(&pool->refcount, 1);\n\n\n\n    return ret;\n\n}\n", "idx": 26983, "_split": "valid", "_hash": "a9009b8fe92e856f7a1beb530613a235"}
{"project": "FFmpeg", "commit_id": "20035fa24103da9199de3515ca75ba1f6bb275aa", "target": 1, "func": "static int scale_vector(int16_t *dst, const int16_t *vector, int length)\n\n{\n\n    int bits, max = 0;\n\n    int i;\n\n\n\n    for (i = 0; i < length; i++)\n\n        max |= FFABS(vector[i]);\n\n\n\n    bits  = normalize_bits(max, 15);\n\n\n\n    if (bits == 15)\n\n        for (i = 0; i < length; i++)\n\n            dst[i] = vector[i] * 0x7fff >> 3;\n\n    else\n\n        for (i = 0; i < length; i++)\n\n            dst[i] = vector[i] << bits >> 3;\n\n\n\n    return bits - 3;\n\n}\n", "idx": 26997, "_split": "valid", "_hash": "4de663c77e57d763b2950f3961ba565a"}
{"project": "FFmpeg", "commit_id": "c04643a2c24564aed96a5b0760de8bf02eb305c6", "target": 0, "func": "void prepare_grab(void)\n\n{\n\n    int has_video, has_audio, i, j;\n\n    AVFormatContext *oc;\n\n    AVFormatContext *ic;\n\n    AVFormatParameters ap1, *ap = &ap1;\n\n\n\n    /* see if audio/video inputs are needed */\n\n    has_video = 0;\n\n    has_audio = 0;\n\n    memset(ap, 0, sizeof(*ap));\n\n    for(j=0;j<nb_output_files;j++) {\n\n        oc = output_files[j];\n\n        for(i=0;i<oc->nb_streams;i++) {\n\n            AVCodecContext *enc = &oc->streams[i]->codec;\n\n            switch(enc->codec_type) {\n\n            case CODEC_TYPE_AUDIO:\n\n                if (enc->sample_rate > ap->sample_rate)\n\n                    ap->sample_rate = enc->sample_rate;\n\n                if (enc->channels > ap->channels)\n\n                    ap->channels = enc->channels;\n\n                has_audio = 1;\n\n                break;\n\n            case CODEC_TYPE_VIDEO:\n\n                if (enc->width > ap->width)\n\n                    ap->width = enc->width;\n\n                if (enc->height > ap->height)\n\n                    ap->height = enc->height;\n\n                if (enc->frame_rate > ap->frame_rate)\n\n                    ap->frame_rate = enc->frame_rate;\n\n                has_video = 1;\n\n                break;\n\n            default:\n\n                abort();\n\n            }\n\n        }\n\n    }\n\n    \n\n    if (has_video == 0 && has_audio == 0) {\n\n        fprintf(stderr, \"Output file must have at least one audio or video stream\\n\");\n\n        exit(1);\n\n    }\n\n    \n\n    if (has_video) {\n\n        AVInputFormat *fmt1;\n\n        fmt1 = av_find_input_format(\"video_grab_device\");\n\n        if (av_open_input_file(&ic, \"\", fmt1, 0, ap) < 0) {\n\n            fprintf(stderr, \"Could not find video grab device\\n\");\n\n            exit(1);\n\n        }\n\n        /* by now video grab has one stream */\n\n        ic->streams[0]->r_frame_rate = ap->frame_rate;\n\n        input_files[nb_input_files] = ic;\n\n        dump_format(ic, nb_input_files, v4l_device, 0);\n\n        nb_input_files++;\n\n    }\n\n    if (has_audio) {\n\n        AVInputFormat *fmt1;\n\n        fmt1 = av_find_input_format(\"audio_device\");\n\n        if (av_open_input_file(&ic, \"\", fmt1, 0, ap) < 0) {\n\n            fprintf(stderr, \"Could not find audio grab device\\n\");\n\n            exit(1);\n\n        }\n\n        input_files[nb_input_files] = ic;\n\n        dump_format(ic, nb_input_files, audio_device, 0);\n\n        nb_input_files++;\n\n    }\n\n}\n", "idx": 27025, "_split": "valid", "_hash": "5fb3778be6ac99b9c35b488fc62ca31c"}
{"project": "FFmpeg", "commit_id": "9156a5ad72e989e0fa2735741edf894fffad33b9", "target": 0, "func": "static void ipvideo_decode_opcodes(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char opcode;\n\n    int ret;\n\n    static int frame = 0;\n\n    GetBitContext gb;\n\n\n\n    debug_interplay(\"------------------ frame %d\\n\", frame);\n\n    frame++;\n\n\n\n    /* this is PAL8, so make the palette available */\n\n    memcpy(s->current_frame.data[1], s->avctx->palctrl->palette, PALETTE_COUNT * 4);\n\n\n\n    s->stride = s->current_frame.linesize[0];\n\n    s->stream_ptr = s->buf + 14;  /* data starts 14 bytes in */\n\n    s->stream_end = s->buf + s->size;\n\n    s->line_inc = s->stride - 8;\n\n    s->upper_motion_limit_offset = (s->avctx->height - 8) * s->stride\n\n        + s->avctx->width - 8;\n\n\n\n    init_get_bits(&gb, s->decoding_map, s->decoding_map_size * 8);\n\n    for (y = 0; y < (s->stride * s->avctx->height); y += s->stride * 8) {\n\n        for (x = y; x < y + s->avctx->width; x += 8) {\n\n            opcode = get_bits(&gb, 4);\n\n\n\n            debug_interplay(\"  block @ (%3d, %3d): encoding 0x%X, data ptr @ %p\\n\",\n\n                            x - y, y / s->stride, opcode, s->stream_ptr);\n\n\n\n            s->pixel_ptr = s->current_frame.data[0] + x;\n\n            ret = ipvideo_decode_block[opcode](s);\n\n            if (ret != 0) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: decode problem on frame %d, @ block (%d, %d)\\n\",\n\n                       frame, x - y, y / s->stride);\n\n                return;\n\n            }\n\n        }\n\n    }\n\n    if (s->stream_end - s->stream_ptr > 1) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: decode finished with %td bytes left over\\n\",\n\n               s->stream_end - s->stream_ptr);\n\n    }\n\n}\n", "idx": 27026, "_split": "valid", "_hash": "4810966f7c6b7e662d53dca8fc7b32cb"}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static void handle_char(CCaptionSubContext *ctx, char hi, char lo, int64_t pts)\n\n{\n\n    struct Screen *screen = get_writing_screen(ctx);\n\n    char *row = screen->characters[ctx->cursor_row];\n\n    int ret;\n\n\n\n    SET_FLAG(screen->row_used,ctx->cursor_row);\n\n\n\n    ret = write_char(ctx, row, ctx->cursor_column, hi);\n\n    if( ret == 0 )\n\n        ctx->cursor_column++;\n\n\n\n    if(lo) {\n\n        ret = write_char(ctx, row, ctx->cursor_column, lo);\n\n        if ( ret == 0 )\n\n            ctx->cursor_column++;\n\n    }\n\n    write_char(ctx, row, ctx->cursor_column, 0);\n\n\n\n    /* reset prev command since character can repeat */\n\n    ctx->prev_cmd[0] = 0;\n\n    ctx->prev_cmd[1] = 0;\n\n    if (lo)\n\n       av_dlog(ctx, \"(%c,%c)\\n\",hi,lo);\n\n    else\n\n       av_dlog(ctx, \"(%c)\\n\",hi);\n\n}\n", "idx": 27067, "_split": "valid", "_hash": "0ed573ee139e244907da37f931b19794"}
{"project": "FFmpeg", "commit_id": "1f630b97178cdf1637c96f0eecd0975cde30bb7c", "target": 0, "func": "static inline void h264_loop_filter_luma_mmx2(uint8_t *pix, int stride, int alpha1, int beta1, int8_t *tc0)\n\n{\n\n    DECLARE_ALIGNED_8(uint64_t, tmp0[2]);\n\n\n\n    __asm__ volatile(\n\n        \"movq    (%1,%3), %%mm0    \\n\\t\" //p1\n\n        \"movq    (%1,%3,2), %%mm1  \\n\\t\" //p0\n\n        \"movq    (%2),    %%mm2    \\n\\t\" //q0\n\n        \"movq    (%2,%3), %%mm3    \\n\\t\" //q1\n\n        H264_DEBLOCK_MASK(%6, %7)\n\n\n\n        \"movd      %5,    %%mm4    \\n\\t\"\n\n        \"punpcklbw %%mm4, %%mm4    \\n\\t\"\n\n        \"punpcklwd %%mm4, %%mm4    \\n\\t\"\n\n        \"pcmpeqb   %%mm3, %%mm3    \\n\\t\"\n\n        \"movq      %%mm4, %%mm6    \\n\\t\"\n\n        \"pcmpgtb   %%mm3, %%mm4    \\n\\t\"\n\n        \"movq      %%mm6, 8+%0     \\n\\t\"\n\n        \"pand      %%mm4, %%mm7    \\n\\t\"\n\n        \"movq      %%mm7, %0       \\n\\t\"\n\n\n\n        /* filter p1 */\n\n        \"movq     (%1),   %%mm3    \\n\\t\" //p2\n\n        DIFF_GT2_MMX(%%mm1, %%mm3, %%mm5, %%mm6, %%mm4) // |p2-p0|>beta-1\n\n        \"pand     %%mm7,  %%mm6    \\n\\t\" // mask & |p2-p0|<beta\n\n        \"pand     8+%0,   %%mm7    \\n\\t\" // mask & tc0\n\n        \"movq     %%mm7,  %%mm4    \\n\\t\"\n\n        \"psubb    %%mm6,  %%mm7    \\n\\t\"\n\n        \"pand     %%mm4,  %%mm6    \\n\\t\" // mask & |p2-p0|<beta & tc0\n\n        H264_DEBLOCK_Q1(%%mm0, %%mm3, \"(%1)\", \"(%1,%3)\", %%mm6, %%mm4)\n\n\n\n        /* filter q1 */\n\n        \"movq    (%2,%3,2), %%mm4  \\n\\t\" //q2\n\n        DIFF_GT2_MMX(%%mm2, %%mm4, %%mm5, %%mm6, %%mm3) // |q2-q0|>beta-1\n\n        \"pand     %0,     %%mm6    \\n\\t\"\n\n        \"movq     8+%0,   %%mm5    \\n\\t\" // can be merged with the and below but is slower then\n\n        \"pand     %%mm6,  %%mm5    \\n\\t\"\n\n        \"psubb    %%mm6,  %%mm7    \\n\\t\"\n\n        \"movq    (%2,%3), %%mm3    \\n\\t\"\n\n        H264_DEBLOCK_Q1(%%mm3, %%mm4, \"(%2,%3,2)\", \"(%2,%3)\", %%mm5, %%mm6)\n\n\n\n        /* filter p0, q0 */\n\n        H264_DEBLOCK_P0_Q0(%8, unused)\n\n        \"movq      %%mm1, (%1,%3,2) \\n\\t\"\n\n        \"movq      %%mm2, (%2)      \\n\\t\"\n\n\n\n        : \"=m\"(*tmp0)\n\n        : \"r\"(pix-3*stride), \"r\"(pix), \"r\"((x86_reg)stride),\n\n          \"m\"(*tmp0/*unused*/), \"m\"(*(uint32_t*)tc0), \"m\"(alpha1), \"m\"(beta1),\n\n          \"m\"(ff_bone)\n\n    );\n\n}\n", "idx": 27102, "_split": "valid", "_hash": "6f1346d83087f34b301462b80231ef6a"}
{"project": "FFmpeg", "commit_id": "4c55144ee969a63bb5e469e3ebd7179b7b3616e8", "target": 0, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *buf)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    DeflickerContext *s = ctx->priv;\n\n    AVDictionary **metadata;\n\n    AVFrame *out, *in;\n\n    float f;\n\n    int y;\n\n\n\n    if (s->q.available < s->size && !s->eof) {\n\n        s->luminance[s->available] = s->calc_avgy(ctx, buf);\n\n        ff_bufqueue_add(ctx, &s->q, buf);\n\n        s->available++;\n\n        return 0;\n\n    }\n\n\n\n    in = ff_bufqueue_peek(&s->q, 0);\n\n\n\n    out = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n\n    if (!out) {\n\n        av_frame_free(&buf);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    s->get_factor(ctx, &f);\n\n    s->deflicker(ctx, in->data[0], in->linesize[0], out->data[0], out->linesize[0],\n\n                 outlink->w, outlink->h, f);\n\n    for (y = 1; y < s->nb_planes; y++) {\n\n        av_image_copy_plane(out->data[y], out->linesize[y],\n\n                            in->data[y], in->linesize[y],\n\n                            s->planewidth[y] * (1 + (s->depth > 8)), s->planeheight[y]);\n\n    }\n\n\n\n    av_frame_copy_props(out, in);\n\n    metadata = &out->metadata;\n\n    if (metadata) {\n\n        uint8_t value[128];\n\n\n\n        snprintf(value, sizeof(value), \"%f\", s->luminance[0]);\n\n        av_dict_set(metadata, \"lavfi.deflicker.luminance\", value, 0);\n\n\n\n        snprintf(value, sizeof(value), \"%f\", s->luminance[0] * f);\n\n        av_dict_set(metadata, \"lavfi.deflicker.new_luminance\", value, 0);\n\n\n\n        snprintf(value, sizeof(value), \"%f\", f - 1.0f);\n\n        av_dict_set(metadata, \"lavfi.deflicker.relative_change\", value, 0);\n\n    }\n\n\n\n    in = ff_bufqueue_get(&s->q);\n\n    av_frame_free(&in);\n\n    memmove(&s->luminance[0], &s->luminance[1], sizeof(*s->luminance) * (s->size - 1));\n\n    s->luminance[s->available - 1] = s->calc_avgy(ctx, buf);\n\n    ff_bufqueue_add(ctx, &s->q, buf);\n\n\n\n    return ff_filter_frame(outlink, out);\n\n}\n", "idx": 27104, "_split": "valid", "_hash": "bea17d7ae229e564fa27b2b4f4ad16f4"}
{"project": "FFmpeg", "commit_id": "4bff9ef9d0781c4de228bf1f85634d2706fc589b", "target": 0, "func": "inline static void RENAME(hcscale)(uint16_t *dst, long dstWidth, uint8_t *src1, uint8_t *src2,\n\n\t\t\t\t   int srcW, int xInc, int flags, int canMMX2BeUsed, int16_t *hChrFilter,\n\n\t\t\t\t   int16_t *hChrFilterPos, int hChrFilterSize, void *funnyUVCode,\n\n\t\t\t\t   int srcFormat, uint8_t *formatConvBuffer, int16_t *mmx2Filter,\n\n\t\t\t\t   int32_t *mmx2FilterPos)\n\n{\n\n    if(srcFormat==IMGFMT_YUY2)\n\n    {\n\n\tRENAME(yuy2ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_UYVY)\n\n    {\n\n\tRENAME(uyvyToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR32)\n\n    {\n\n\tRENAME(bgr32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR24)\n\n    {\n\n\tRENAME(bgr24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR16)\n\n    {\n\n\tRENAME(bgr16ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_BGR15)\n\n    {\n\n\tRENAME(bgr15ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_RGB32)\n\n    {\n\n\tRENAME(rgb32ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(srcFormat==IMGFMT_RGB24)\n\n    {\n\n\tRENAME(rgb24ToUV)(formatConvBuffer, formatConvBuffer+2048, src1, src2, srcW);\n\n\tsrc1= formatConvBuffer;\n\n\tsrc2= formatConvBuffer+2048;\n\n    }\n\n    else if(isGray(srcFormat))\n\n    {\n\n    \treturn;\n\n    }\n\n\n\n#ifdef HAVE_MMX\n\n\t// use the new MMX scaler if the mmx2 can't be used (its faster than the x86asm one)\n\n    if(!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))\n\n#else\n\n    if(!(flags&SWS_FAST_BILINEAR))\n\n#endif\n\n    {\n\n    \tRENAME(hScale)(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    \tRENAME(hScale)(dst+2048, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    }\n\n    else // Fast Bilinear upscale / crap downscale\n\n    {\n\n#if defined(ARCH_X86) || defined(ARCH_X86_64)\n\n#ifdef HAVE_MMX2\n\n\tint i;\n\n\tif(canMMX2BeUsed)\n\n\t{\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"mov %0, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\t\"mov %2, %%\"REG_d\"\t\t\\n\\t\"\n\n\t\t\t\"mov %3, %%\"REG_b\"\t\t\\n\\t\"\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\n#ifdef ARCH_X86_64\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"movl (%%\"REG_b\", %%\"REG_a\"), %%esi\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_S\", %%\"REG_c\"\t\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#else\n\n\n\n#define FUNNY_UV_CODE \\\n\n\t\t\t\"movl (%%\"REG_b\"), %%esi\t\\n\\t\"\\\n\n\t\t\t\"call *%4\t\t\t\\n\\t\"\\\n\n\t\t\t\"addl (%%\"REG_b\", %%\"REG_a\"), %%\"REG_c\"\\n\\t\"\\\n\n\t\t\t\"add %%\"REG_a\", %%\"REG_D\"\t\\n\\t\"\\\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\\\n\n\n\n#endif\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\t\"mov %5, %%\"REG_c\"\t\t\\n\\t\" // src\n\n\t\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\" // buf1\n\n\t\t\t\"add $4096, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" (%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 32(%%\"REG_c\")\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%%\"REG_c\")\t\t\\n\\t\"\n\n\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\nFUNNY_UV_CODE\n\n\n\n\t\t\t:: \"m\" (src1), \"m\" (dst), \"m\" (mmx2Filter), \"m\" (mmx2FilterPos),\n\n\t\t\t\"m\" (funnyUVCode), \"m\" (src2)\n\n\t\t\t: \"%\"REG_a, \"%\"REG_b, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n\t\t);\n\n\t\tfor(i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--)\n\n\t\t{\n\n//\t\t\tprintf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n\t\t\tdst[i] = src1[srcW-1]*128;\n\n\t\t\tdst[i+2048] = src2[srcW-1]*128;\n\n\t\t}\n\n\t}\n\n\telse\n\n\t{\n\n#endif\n\n\tlong xInc_shr16 = (long) (xInc >> 16);\n\n\tuint16_t xInc_mask = xInc & 0xffff; \n\n\tasm volatile(\n\n\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\" // i\n\n\t\t\"xor %%\"REG_b\", %%\"REG_b\"\t\t\\n\\t\" // xx\n\n\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\" // 2*xalpha\n\n\t\tASMALIGN16\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"mov %0, %%\"REG_S\"\t\t\\n\\t\"\n\n\t\t\"movzbl  (%%\"REG_S\", %%\"REG_b\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%%\"REG_S\", %%\"REG_b\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, (%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"movzbl  (%5, %%\"REG_b\"), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%5, %%\"REG_b\"), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"mov %1, %%\"REG_D\"\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, 4096(%%\"REG_D\", %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\"addw %4, %%cx\t\t\t\\n\\t\" //2*xalpha += xInc&0xFF\n\n\t\t\"adc %3, %%\"REG_b\"\t\t\\n\\t\" //xx+= xInc>>8 + carry\n\n\t\t\"add $1, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"cmp %2, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n/* GCC-3.3 makes MPlayer crash on IA-32 machines when using \"g\" operand here,\n\n   which is needed to support GCC-4.0 */\n\n#if defined(ARCH_X86_64) && ((__GNUC__ > 3) || ( __GNUC__ == 3 && __GNUC_MINOR__ >= 4))\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"g\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#else\n\n\t\t:: \"m\" (src1), \"m\" (dst), \"m\" ((long)dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#endif\n\n\t\t\"r\" (src2)\n\n\t\t: \"%\"REG_a, \"%\"REG_b, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n\t\t);\n\n#ifdef HAVE_MMX2\n\n\t} //if MMX2 can't be used\n\n#endif\n\n#else\n\n\tint i;\n\n\tunsigned int xpos=0;\n\n\tfor(i=0;i<dstWidth;i++)\n\n\t{\n\n\t\tregister unsigned int xx=xpos>>16;\n\n\t\tregister unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n\t\tdst[i]=(src1[xx]*(xalpha^127)+src1[xx+1]*xalpha);\n\n\t\tdst[i+2048]=(src2[xx]*(xalpha^127)+src2[xx+1]*xalpha);\n\n/* slower\n\n\t  dst[i]= (src1[xx]<<7) + (src1[xx+1] - src1[xx])*xalpha;\n\n\t  dst[i+2048]=(src2[xx]<<7) + (src2[xx+1] - src2[xx])*xalpha;\n\n*/\n\n\t\txpos+=xInc;\n\n\t}\n\n#endif\n\n   }\n\n}\n", "idx": 27131, "_split": "valid", "_hash": "f906ab43031a2084bdeb4867182274da"}
{"project": "FFmpeg", "commit_id": "ffa1de8a3b93139097214bc600d356ab62bfdf05", "target": 1, "func": "static void dequantization_int_97(int x, int y, Jpeg2000Cblk *cblk,\n\n                               Jpeg2000Component *comp,\n\n                               Jpeg2000T1Context *t1, Jpeg2000Band *band)\n\n{\n\n    int i, j;\n\n    int w = cblk->coord[0][1] - cblk->coord[0][0];\n\n    for (j = 0; j < (cblk->coord[1][1] - cblk->coord[1][0]); ++j) {\n\n        int32_t *datap = &comp->i_data[(comp->coord[0][1] - comp->coord[0][0]) * (y + j) + x];\n\n        int *src = t1->data[j];\n\n        for (i = 0; i < w; ++i)\n\n            datap[i] = (src[i] * band->i_stepsize + (1<<14)) >> 15;\n\n    }\n\n}\n", "idx": 27135, "_split": "valid", "_hash": "999a497900cc261d92aa85db18e5920c"}
{"project": "FFmpeg", "commit_id": "bdcd36a4c81c50254f6204e83e0c14adc1391e66", "target": 0, "func": "yuv2rgb_full_1_c_template(SwsContext *c, const int16_t *buf0,\n\n                     const int16_t *ubuf[2], const int16_t *vbuf[2],\n\n                     const int16_t *abuf0, uint8_t *dest, int dstW,\n\n                     int uvalpha, int y, enum AVPixelFormat target,\n\n                     int hasAlpha)\n\n{\n\n    const int16_t *ubuf0 = ubuf[0], *vbuf0 = vbuf[0];\n\n    int i;\n\n    int step = (target == AV_PIX_FMT_RGB24 || target == AV_PIX_FMT_BGR24) ? 3 : 4;\n\n    int err[4] = {0};\n\n\n\n    if(   target == AV_PIX_FMT_BGR4_BYTE || target == AV_PIX_FMT_RGB4_BYTE\n\n       || target == AV_PIX_FMT_BGR8      || target == AV_PIX_FMT_RGB8)\n\n        step = 1;\n\n\n\n    if (uvalpha < 2048) {\n\n        int A = 0; //init to silence warning\n\n        for (i = 0; i < dstW; i++) {\n\n            int Y = buf0[i] << 2;\n\n            int U = (ubuf0[i] - (128<<7)) << 2;\n\n            int V = (vbuf0[i] - (128<<7)) << 2;\n\n\n\n            if (hasAlpha) {\n\n                A = (abuf0[i] + 64) >> 7;\n\n                if (A & 0x100)\n\n                    A = av_clip_uint8(A);\n\n            }\n\n\n\n            yuv2rgb_write_full(c, dest, i, Y, A, U, V, y, target, hasAlpha, err);\n\n            dest += step;\n\n        }\n\n    } else {\n\n        const int16_t *ubuf1 = ubuf[1], *vbuf1 = vbuf[1];\n\n        int A = 0; //init to silence warning\n\n        for (i = 0; i < dstW; i++) {\n\n            int Y = buf0[i] << 2;\n\n            int U = (ubuf0[i] + ubuf1[i] - (128<<8)) << 1;\n\n            int V = (vbuf0[i] + vbuf1[i] - (128<<8)) << 1;\n\n\n\n            if (hasAlpha) {\n\n                A = (abuf0[i] + 64) >> 7;\n\n                if (A & 0x100)\n\n                    A = av_clip_uint8(A);\n\n            }\n\n\n\n            yuv2rgb_write_full(c, dest, i, Y, A, U, V, y, target, hasAlpha, err);\n\n            dest += step;\n\n        }\n\n    }\n\n\n\n    c->dither_error[0][i] = err[0];\n\n    c->dither_error[1][i] = err[1];\n\n    c->dither_error[2][i] = err[2];\n\n}\n", "idx": 27137, "_split": "valid", "_hash": "cba0e7a292be5b2d3a0a4772ca261efb"}
{"project": "FFmpeg", "commit_id": "3fd2d1c4bc43aab583f97afbb63ab91145f9e7ba", "target": 1, "func": "void Process(void *ctx, AVPicture *picture, enum PixelFormat pix_fmt, int width, int height, int64_t pts)\n\n{\n\n    int err = 0;\n\n    ContextInfo *ci = (ContextInfo *) ctx;\n\n    AVPicture picture1;\n\n    AVPicture picture2;\n\n    AVPicture *pict = picture;\n\n    int out_width;\n\n    int out_height;\n\n    int i;\n\n    uint8_t *ptr = NULL;\n\n    FILE *in = rwpipe_reader( ci->rw );\n\n    FILE *out = rwpipe_writer( ci->rw );\n\n\n\n    /* Check that we have a pipe to talk to. */\n\n    if ( in == NULL || out == NULL )\n\n        err = 1;\n\n\n\n    /* Convert to RGB24 if necessary */\n\n    if ( !err && pix_fmt != PIX_FMT_RGB24 )\n\n    {\n\n        int size = avpicture_get_size(PIX_FMT_RGB24, width, height);\n\n\n\n        if ( size != ci->size1 )\n\n        {\n\n            av_free( ci->buf1 );\n\n            ci->buf1 = av_malloc(size);\n\n            ci->size1 = size;\n\n            err = ci->buf1 == NULL;\n\n        }\n\n\n\n        if ( !err )\n\n        {\n\n            avpicture_fill(&picture1, ci->buf1, PIX_FMT_RGB24, width, height);\n\n\n\n            // if we already got a SWS context, let's realloc if is not re-useable\n\n            ci->toRGB_convert_ctx = sws_getCachedContext(ci->toRGB_convert_ctx,\n\n                                        width, height, pix_fmt,\n\n                                        width, height, PIX_FMT_RGB24,\n\n                                        sws_flags, NULL, NULL, NULL);\n\n            if (ci->toRGB_convert_ctx == NULL) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Cannot initialize the toRGB conversion context\\n\");\n\n                return;\n\n            }\n\n\n\n// img_convert parameters are          2 first destination, then 4 source\n\n// sws_scale   parameters are context, 4 first source,      then 2 destination\n\n            sws_scale(ci->toRGB_convert_ctx,\n\n                     picture->data, picture->linesize, 0, height,\n\n                     picture1.data, picture1.linesize);\n\n\n\n            pict = &picture1;\n\n        }\n\n    }\n\n\n\n    /* Write out the PPM */\n\n    if ( !err )\n\n    {\n\n        ptr = pict->data[ 0 ];\n\n        fprintf( out, \"P6\\n%d %d\\n255\\n\", width, height );\n\n        for ( i = 0; !err && i < height; i ++ )\n\n        {\n\n            err = !fwrite( ptr, width * 3, 1, out );\n\n            ptr += pict->linesize[ 0 ];\n\n        }\n\n        if ( !err )\n\n            err = fflush( out );\n\n    }\n\n\n\n    /* Read the PPM returned. */\n\n    if ( !err && !rwpipe_read_ppm_header( ci->rw, &out_width, &out_height ) )\n\n    {\n\n        int size = avpicture_get_size(PIX_FMT_RGB24, out_width, out_height);\n\n\n\n        if ( size != ci->size2 )\n\n        {\n\n            av_free( ci->buf2 );\n\n            ci->buf2 = av_malloc(size);\n\n            ci->size2 = size;\n\n            err = ci->buf2 == NULL;\n\n        }\n\n\n\n        if ( !err )\n\n        {\n\n            avpicture_fill(&picture2, ci->buf2, PIX_FMT_RGB24, out_width, out_height);\n\n            ptr = picture2.data[ 0 ];\n\n            for ( i = 0; !err && i < out_height; i ++ )\n\n            {\n\n                err = !fread( ptr, out_width * 3, 1, in );\n\n                ptr += picture2.linesize[ 0 ];\n\n            }\n\n        }\n\n    }\n\n\n\n    /* Convert the returned PPM back to the input format */\n\n    if ( !err )\n\n    {\n\n        /* The out_width/out_height returned from the PPM\n\n         * filter won't necessarily be the same as width and height\n\n         * but it will be scaled anyway to width/height.\n\n         */\n\n        av_log(NULL, AV_LOG_DEBUG,\n\n                  \"PPM vhook: Input dimensions: %d x %d Output dimensions: %d x %d\\n\",\n\n                  width, height, out_width, out_height);\n\n        ci->fromRGB_convert_ctx = sws_getCachedContext(ci->fromRGB_convert_ctx,\n\n                                        out_width, out_height, PIX_FMT_RGB24,\n\n                                        width,     height,     pix_fmt,\n\n                                        sws_flags, NULL, NULL, NULL);\n\n        if (ci->fromRGB_convert_ctx == NULL) {\n\n            av_log(NULL, AV_LOG_ERROR,\n\n                   \"Cannot initialize the fromRGB conversion context\\n\");\n\n            return;\n\n        }\n\n\n\n// img_convert parameters are          2 first destination, then 4 source\n\n// sws_scale   parameters are context, 4 first source,      then 2 destination\n\n        sws_scale(ci->fromRGB_convert_ctx,\n\n                 picture2.data, picture2.linesize, 0, out_height,\n\n                 picture->data, picture->linesize);\n\n    }\n\n}\n", "idx": 27142, "_split": "valid", "_hash": "9c50de91f2cb1090c773ac03863e307b"}
{"project": "FFmpeg", "commit_id": "b6db385922b79939b0dc124d53ddb4824afac040", "target": 0, "func": "static int v4l2_set_parameters(AVFormatContext *s1, AVFormatParameters *ap)\n\n{\n\n    struct video_data *s = s1->priv_data;\n\n    struct v4l2_input input;\n\n    struct v4l2_standard standard;\n\n    struct v4l2_streamparm streamparm = { 0 };\n\n    struct v4l2_fract *tpf = &streamparm.parm.capture.timeperframe;\n\n    int i, ret;\n\n    AVRational framerate_q;\n\n\n\n    streamparm.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;\n\n\n\n    if (s->framerate &&\n\n        (ret = av_parse_video_rate(&framerate_q, s->framerate)) < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"Could not parse framerate '%s'.\\n\",\n\n               s->framerate);\n\n        return ret;\n\n    }\n\n\n\n    /* set tv video input */\n\n    memset (&input, 0, sizeof (input));\n\n    input.index = s->channel;\n\n    if (ioctl(s->fd, VIDIOC_ENUMINPUT, &input) < 0) {\n\n        av_log(s1, AV_LOG_ERROR, \"The V4L2 driver ioctl enum input failed:\\n\");\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    av_log(s1, AV_LOG_DEBUG, \"The V4L2 driver set input_id: %d, input: %s\\n\",\n\n            s->channel, input.name);\n\n    if (ioctl(s->fd, VIDIOC_S_INPUT, &input.index) < 0) {\n\n        av_log(s1, AV_LOG_ERROR,\n\n               \"The V4L2 driver ioctl set input(%d) failed\\n\",\n\n                s->channel);\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    if (s->standard) {\n\n        av_log(s1, AV_LOG_DEBUG, \"The V4L2 driver set standard: %s\\n\",\n\n               s->standard);\n\n        /* set tv standard */\n\n        memset (&standard, 0, sizeof (standard));\n\n        for(i=0;;i++) {\n\n            standard.index = i;\n\n            if (ioctl(s->fd, VIDIOC_ENUMSTD, &standard) < 0) {\n\n                av_log(s1, AV_LOG_ERROR,\n\n                       \"The V4L2 driver ioctl set standard(%s) failed\\n\",\n\n                       s->standard);\n\n                return AVERROR(EIO);\n\n            }\n\n\n\n            if (!av_strcasecmp(standard.name, s->standard)) {\n\n                break;\n\n            }\n\n        }\n\n\n\n        av_log(s1, AV_LOG_DEBUG,\n\n               \"The V4L2 driver set standard: %s, id: %\"PRIu64\"\\n\",\n\n               s->standard, (uint64_t)standard.id);\n\n        if (ioctl(s->fd, VIDIOC_S_STD, &standard.id) < 0) {\n\n            av_log(s1, AV_LOG_ERROR,\n\n                   \"The V4L2 driver ioctl set standard(%s) failed\\n\",\n\n                   s->standard);\n\n            return AVERROR(EIO);\n\n        }\n\n    }\n\n\n\n    if (framerate_q.num && framerate_q.den) {\n\n        av_log(s1, AV_LOG_DEBUG, \"Setting time per frame to %d/%d\\n\",\n\n               framerate_q.den, framerate_q.num);\n\n        tpf->numerator   = framerate_q.den;\n\n        tpf->denominator = framerate_q.num;\n\n\n\n        if (ioctl(s->fd, VIDIOC_S_PARM, &streamparm) != 0) {\n\n            av_log(s1, AV_LOG_ERROR,\n\n                   \"ioctl set time per frame(%d/%d) failed\\n\",\n\n                   framerate_q.den, framerate_q.num);\n\n            return AVERROR(EIO);\n\n        }\n\n\n\n        if (framerate_q.num != tpf->denominator ||\n\n            framerate_q.den != tpf->numerator) {\n\n            av_log(s1, AV_LOG_INFO,\n\n                   \"The driver changed the time per frame from \"\n\n                   \"%d/%d to %d/%d\\n\",\n\n                   framerate_q.den, framerate_q.num,\n\n                   tpf->numerator, tpf->denominator);\n\n        }\n\n    } else {\n\n        if (ioctl(s->fd, VIDIOC_G_PARM, &streamparm) != 0) {\n\n            av_log(s1, AV_LOG_ERROR, \"ioctl(VIDIOC_G_PARM): %s\\n\",\n\n                   strerror(errno));\n\n            return AVERROR(errno);\n\n        }\n\n    }\n\n    s1->streams[0]->codec->time_base.den = tpf->denominator;\n\n    s1->streams[0]->codec->time_base.num = tpf->numerator;\n\n\n\n    s->timeout = 100 +\n\n        av_rescale_q(1, s1->streams[0]->codec->time_base,\n\n                        (AVRational){1, 1000});\n\n\n\n    return 0;\n\n}\n", "idx": 27164, "_split": "valid", "_hash": "018266c0ee497eefcc2b74ef434d3d9f"}
{"project": "FFmpeg", "commit_id": "38c48be213b86baa04e64762622afefbba1afa70", "target": 0, "func": "static int mpegts_read_packet(AVFormatContext *s,\n\n                              AVPacket *pkt)\n\n{\n\n    MpegTSContext *ts = s->priv_data;\n\n\n\n    if (!ts->mpeg2ts_raw) {\n\n        ts->pkt = pkt;\n\n        return handle_packets(ts, 0);\n\n    } else {\n\n        return mpegts_raw_read_packet(s, pkt);\n\n    }\n\n}\n", "idx": 27183, "_split": "valid", "_hash": "1c940e11e9a86eaf7073f8b782bf582c"}
{"project": "FFmpeg", "commit_id": "1dc42050185d63c1de5d16146fbaee92640af187", "target": 0, "func": "static int start_frame(AVFilterLink *link, AVFilterBufferRef *picref)\n\n{\n\n    AVFilterContext *ctx = link->dst;\n\n    YADIFContext *yadif = ctx->priv;\n\n\n\n    if (yadif->frame_pending)\n\n        return_frame(ctx, 1);\n\n\n\n    if (yadif->prev)\n\n        avfilter_unref_buffer(yadif->prev);\n\n    yadif->prev = yadif->cur;\n\n    yadif->cur  = yadif->next;\n\n    yadif->next = picref;\n\n\n\n    if (!yadif->cur)\n\n        return 0;\n\n\n\n    if (yadif->auto_enable && !yadif->cur->video->interlaced) {\n\n        yadif->out  = avfilter_ref_buffer(yadif->cur, AV_PERM_READ);\n\n        avfilter_unref_bufferp(&yadif->prev);\n\n        if (yadif->out->pts != AV_NOPTS_VALUE)\n\n            yadif->out->pts *= 2;\n\n        return ff_start_frame(ctx->outputs[0], yadif->out);\n\n    }\n\n\n\n    if (!yadif->prev)\n\n        yadif->prev = avfilter_ref_buffer(yadif->cur, AV_PERM_READ);\n\n\n\n    yadif->out = ff_get_video_buffer(ctx->outputs[0], AV_PERM_WRITE | AV_PERM_PRESERVE |\n\n                                     AV_PERM_REUSE, link->w, link->h);\n\n\n\n    avfilter_copy_buffer_ref_props(yadif->out, yadif->cur);\n\n    yadif->out->video->interlaced = 0;\n\n    if (yadif->out->pts != AV_NOPTS_VALUE)\n\n        yadif->out->pts *= 2;\n\n    return ff_start_frame(ctx->outputs[0], yadif->out);\n\n}\n", "idx": 27194, "_split": "valid", "_hash": "2566277c7c2d6d8a9eab3230a42fbba5"}
{"project": "FFmpeg", "commit_id": "f6b7f72461673e4d398b1edf9ed2a7fe70d99c47", "target": 0, "func": "static void av_always_inline filter_mb_edgeh( uint8_t *pix, int stride, const int16_t bS[4], unsigned int qp, H264Context *h, int intra ) {\n\n    const int qp_bd_offset = 6 * (h->sps.bit_depth_luma - 8);\n\n    const unsigned int index_a = qp - qp_bd_offset + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = beta_table[qp - qp_bd_offset + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 || !intra ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]];\n\n        tc[1] = tc0_table[index_a][bS[1]];\n\n        tc[2] = tc0_table[index_a][bS[2]];\n\n        tc[3] = tc0_table[index_a][bS[3]];\n\n        h->h264dsp.h264_v_loop_filter_luma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->h264dsp.h264_v_loop_filter_luma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 27199, "_split": "valid", "_hash": "ebb563d4f3744ae6b36b29f2d882ae53"}
{"project": "FFmpeg", "commit_id": "ca203e9985cd2dcf42a0c0853940850d3a8edf3a", "target": 1, "func": "static void calc_thr_3gpp(const FFPsyWindowInfo *wi, const int num_bands, AacPsyChannel *pch,\n\n                          const uint8_t *band_sizes, const float *coefs)\n\n{\n\n    int i, w, g;\n\n    int start = 0;\n\n    for (w = 0; w < wi->num_windows*16; w += 16) {\n\n        for (g = 0; g < num_bands; g++) {\n\n            AacPsyBand *band = &pch->band[w+g];\n\n\n\n            float form_factor = 0.0f;\n\n            float Temp;\n\n            band->energy = 0.0f;\n\n            for (i = 0; i < band_sizes[g]; i++) {\n\n                band->energy += coefs[start+i] * coefs[start+i];\n\n                form_factor  += sqrtf(fabs(coefs[start+i]));\n\n            }\n\n            Temp = band->energy > 0 ? sqrtf((float)band_sizes[g] / band->energy) : 0;\n\n            band->thr      = band->energy * 0.001258925f;\n\n            band->nz_lines = form_factor * sqrtf(Temp);\n\n\n\n            start += band_sizes[g];\n\n        }\n\n    }\n\n}\n", "idx": 27216, "_split": "valid", "_hash": "7d1b81643fa5e1e33fd232c7b10f5c01"}
