{"project": "FFmpeg", "commit_id": "32bf6550cb9cc9f487a6722fe2bfc272a93c1065", "target": 0, "func": "int ff_get_wav_header(AVFormatContext *s, AVIOContext *pb,\n\n                      AVCodecContext *codec, int size, int big_endian)\n\n{\n\n    int id;\n\n    uint64_t bitrate;\n\n\n\n    if (size < 14) {\n\n        avpriv_request_sample(codec, \"wav header size < 14\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    codec->codec_type  = AVMEDIA_TYPE_AUDIO;\n\n    if (!big_endian) {\n\n        id                 = avio_rl16(pb);\n\n        if (id != 0x0165) {\n\n            codec->channels    = avio_rl16(pb);\n\n            codec->sample_rate = avio_rl32(pb);\n\n            bitrate            = avio_rl32(pb) * 8LL;\n\n            codec->block_align = avio_rl16(pb);\n\n        }\n\n    } else {\n\n        id                 = avio_rb16(pb);\n\n        codec->channels    = avio_rb16(pb);\n\n        codec->sample_rate = avio_rb32(pb);\n\n        bitrate            = avio_rb32(pb) * 8LL;\n\n        codec->block_align = avio_rb16(pb);\n\n    }\n\n    if (size == 14) {  /* We're dealing with plain vanilla WAVEFORMAT */\n\n        codec->bits_per_coded_sample = 8;\n\n    } else {\n\n        if (!big_endian) {\n\n            codec->bits_per_coded_sample = avio_rl16(pb);\n\n        } else {\n\n            codec->bits_per_coded_sample = avio_rb16(pb);\n\n        }\n\n    }\n\n    if (id == 0xFFFE) {\n\n        codec->codec_tag = 0;\n\n    } else {\n\n        codec->codec_tag = id;\n\n        codec->codec_id  = ff_wav_codec_get_id(id,\n\n                                               codec->bits_per_coded_sample);\n\n    }\n\n    if (size >= 18 && id != 0x0165) {  /* We're obviously dealing with WAVEFORMATEX */\n\n        int cbSize = avio_rl16(pb); /* cbSize */\n\n        if (big_endian) {\n\n            avpriv_report_missing_feature(codec, \"WAVEFORMATEX support for RIFX files\\n\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        size  -= 18;\n\n        cbSize = FFMIN(size, cbSize);\n\n        if (cbSize >= 22 && id == 0xfffe) { /* WAVEFORMATEXTENSIBLE */\n\n            parse_waveformatex(pb, codec);\n\n            cbSize -= 22;\n\n            size   -= 22;\n\n        }\n\n        if (cbSize > 0) {\n\n            av_freep(&codec->extradata);\n\n            if (ff_get_extradata(codec, pb, cbSize) < 0)\n\n                return AVERROR(ENOMEM);\n\n            size -= cbSize;\n\n        }\n\n\n\n        /* It is possible for the chunk to contain garbage at the end */\n\n        if (size > 0)\n\n            avio_skip(pb, size);\n\n    } else if (id == 0x0165 && size >= 32) {\n\n        int nb_streams, i;\n\n\n\n        size -= 4;\n\n        av_freep(&codec->extradata);\n\n        if (ff_get_extradata(codec, pb, size) < 0)\n\n            return AVERROR(ENOMEM);\n\n        nb_streams         = AV_RL16(codec->extradata + 4);\n\n        codec->sample_rate = AV_RL32(codec->extradata + 12);\n\n        codec->channels    = 0;\n\n        bitrate            = 0;\n\n        if (size < 8 + nb_streams * 20)\n\n            return AVERROR_INVALIDDATA;\n\n        for (i = 0; i < nb_streams; i++)\n\n            codec->channels += codec->extradata[8 + i * 20 + 17];\n\n    }\n\n\n\n    if (bitrate > INT_MAX) {\n\n        if (s->error_recognition & AV_EF_EXPLODE) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"The bitrate %\"PRIu64\" is too large.\\n\",\n\n                    bitrate);\n\n            return AVERROR_INVALIDDATA;\n\n        } else {\n\n            av_log(s, AV_LOG_WARNING,\n\n                   \"The bitrate %\"PRIu64\" is too large, resetting to 0.\",\n\n                   bitrate);\n\n            codec->bit_rate = 0;\n\n        }\n\n    } else {\n\n        codec->bit_rate = bitrate;\n\n    }\n\n\n\n    if (codec->sample_rate <= 0) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"Invalid sample rate: %d\\n\", codec->sample_rate);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (codec->codec_id == AV_CODEC_ID_AAC_LATM) {\n\n        /* Channels and sample_rate values are those prior to applying SBR\n\n         * and/or PS. */\n\n        codec->channels    = 0;\n\n        codec->sample_rate = 0;\n\n    }\n\n    /* override bits_per_coded_sample for G.726 */\n\n    if (codec->codec_id == AV_CODEC_ID_ADPCM_G726 && codec->sample_rate)\n\n        codec->bits_per_coded_sample = codec->bit_rate / codec->sample_rate;\n\n\n\n    return 0;\n\n}\n", "idx": 3, "_split": "test", "_hash": "f920314eb446eb02f4fc77420cec58ce"}
{"project": "FFmpeg", "commit_id": "5ff998a233d759d0de83ea6f95c383d03d25d88e", "target": 1, "func": "static int subframe_count_exact(FlacEncodeContext *s, FlacSubframe *sub,\n\n                                int pred_order)\n\n{\n\n    int p, porder, psize;\n\n    int i, part_end;\n\n    int count = 0;\n\n\n\n    /* subframe header */\n\n    count += 8;\n\n\n\n    /* subframe */\n\n    if (sub->type == FLAC_SUBFRAME_CONSTANT) {\n\n        count += sub->obits;\n\n    } else if (sub->type == FLAC_SUBFRAME_VERBATIM) {\n\n        count += s->frame.blocksize * sub->obits;\n\n    } else {\n\n        /* warm-up samples */\n\n        count += pred_order * sub->obits;\n\n\n\n        /* LPC coefficients */\n\n        if (sub->type == FLAC_SUBFRAME_LPC)\n\n            count += 4 + 5 + pred_order * s->options.lpc_coeff_precision;\n\n\n\n        /* rice-encoded block */\n\n        count += 2;\n\n\n\n        /* partition order */\n\n        porder = sub->rc.porder;\n\n        psize  = s->frame.blocksize >> porder;\n\n        count += 4;\n\n\n\n        /* residual */\n\n        i        = pred_order;\n\n        part_end = psize;\n\n        for (p = 0; p < 1 << porder; p++) {\n\n            int k = sub->rc.params[p];\n\n            count += 4;\n\n            count += rice_count_exact(&sub->residual[i], part_end - i, k);\n\n            i = part_end;\n\n            part_end = FFMIN(s->frame.blocksize, part_end + psize);\n\n        }\n\n    }\n\n\n\n    return count;\n\n}\n", "idx": 35, "_split": "test", "_hash": "3b938b007d92ee3db60f2cc4d5fbaa6d"}
{"project": "FFmpeg", "commit_id": "68f593b48433842f3407586679fe07f3e5199ab9", "target": 0, "func": "static int mpeg1_decode_sequence(AVCodecContext *avctx, \n\n                                 UINT8 *buf, int buf_size)\n\n{\n\n    Mpeg1Context *s1 = avctx->priv_data;\n\n    MpegEncContext *s = &s1->mpeg_enc_ctx;\n\n    int width, height, i, v, j;\n\n    float aspect;\n\n\n\n    init_get_bits(&s->gb, buf, buf_size);\n\n\n\n    width = get_bits(&s->gb, 12);\n\n    height = get_bits(&s->gb, 12);\n\n    s->aspect_ratio_info= get_bits(&s->gb, 4);\n\n    if(!s->mpeg2){\n\n        aspect= mpeg1_aspect[s->aspect_ratio_info];\n\n        if(aspect!=0.0) avctx->aspect_ratio= width/(aspect*height);\n\n    }\n\n\n\n    s->frame_rate_index = get_bits(&s->gb, 4);\n\n    if (s->frame_rate_index == 0)\n\n        return -1;\n\n    s->bit_rate = get_bits(&s->gb, 18) * 400;\n\n    if (get_bits1(&s->gb) == 0) /* marker */\n\n        return -1;\n\n    if (width <= 0 || height <= 0 ||\n\n        (width % 2) != 0 || (height % 2) != 0)\n\n        return -1;\n\n    if (width != s->width ||\n\n        height != s->height) {\n\n        /* start new mpeg1 context decoding */\n\n        s->out_format = FMT_MPEG1;\n\n        if (s1->mpeg_enc_ctx_allocated) {\n\n            MPV_common_end(s);\n\n        }\n\n        s->width = width;\n\n        s->height = height;\n\n        avctx->has_b_frames= 1;\n\n        s->avctx = avctx;\n\n        avctx->width = width;\n\n        avctx->height = height;\n\n        if (s->frame_rate_index >= 9) {\n\n            /* at least give a valid frame rate (some old mpeg1 have this) */\n\n            avctx->frame_rate = 25 * FRAME_RATE_BASE;\n\n        } else {\n\n            avctx->frame_rate = frame_rate_tab[s->frame_rate_index];\n\n        }\n\n        s->frame_rate = avctx->frame_rate;\n\n        avctx->bit_rate = s->bit_rate;\n\n        \n\n        if (MPV_common_init(s) < 0)\n\n            return -1;\n\n        s1->mpeg_enc_ctx_allocated = 1;\n\n    }\n\n\n\n    skip_bits(&s->gb, 10); /* vbv_buffer_size */\n\n    skip_bits(&s->gb, 1);\n\n\n\n    /* get matrix */\n\n    if (get_bits1(&s->gb)) {\n\n        for(i=0;i<64;i++) {\n\n            v = get_bits(&s->gb, 8);\n\n            j = s->intra_scantable.permutated[i];\n\n            s->intra_matrix[j] = v;\n\n            s->chroma_intra_matrix[j] = v;\n\n        }\n\n#ifdef DEBUG\n\n        dprintf(\"intra matrix present\\n\");\n\n        for(i=0;i<64;i++)\n\n            dprintf(\" %d\", s->intra_matrix[s->intra_scantable.permutated[i]]);\n\n        printf(\"\\n\");\n\n#endif\n\n    } else {\n\n        for(i=0;i<64;i++) {\n\n            int j= s->idct_permutation[i];\n\n            v = ff_mpeg1_default_intra_matrix[i];\n\n            s->intra_matrix[j] = v;\n\n            s->chroma_intra_matrix[j] = v;\n\n        }\n\n    }\n\n    if (get_bits1(&s->gb)) {\n\n        for(i=0;i<64;i++) {\n\n            v = get_bits(&s->gb, 8);\n\n            j = s->intra_scantable.permutated[i];\n\n            s->inter_matrix[j] = v;\n\n            s->chroma_inter_matrix[j] = v;\n\n        }\n\n#ifdef DEBUG\n\n        dprintf(\"non intra matrix present\\n\");\n\n        for(i=0;i<64;i++)\n\n            dprintf(\" %d\", s->inter_matrix[s->intra_scantable.permutated[i]]);\n\n        printf(\"\\n\");\n\n#endif\n\n    } else {\n\n        for(i=0;i<64;i++) {\n\n            int j= s->idct_permutation[i];\n\n            v = ff_mpeg1_default_non_intra_matrix[i];\n\n            s->inter_matrix[j] = v;\n\n            s->chroma_inter_matrix[j] = v;\n\n        }\n\n    }\n\n\n\n    /* we set mpeg2 parameters so that it emulates mpeg1 */\n\n    s->progressive_sequence = 1;\n\n    s->progressive_frame = 1;\n\n    s->picture_structure = PICT_FRAME;\n\n    s->frame_pred_frame_dct = 1;\n\n    s->mpeg2 = 0;\n\n    avctx->sub_id = 1; /* indicates mpeg1 */\n\n    return 0;\n\n}\n", "idx": 60, "_split": "test", "_hash": "b2565d652ef675342d60e0225b08a62c"}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void vc1_inv_trans_8x8_dc_c(uint8_t *dest, int linesize, DCTELEM *block)\n\n{\n\n    int i;\n\n    int dc = block[0];\n\n    const uint8_t *cm;\n\n    dc = (3 * dc +  1) >> 1;\n\n    dc = (3 * dc + 16) >> 5;\n\n    cm = ff_cropTbl + MAX_NEG_CROP + dc;\n\n    for(i = 0; i < 8; i++){\n\n        dest[0] = cm[dest[0]];\n\n        dest[1] = cm[dest[1]];\n\n        dest[2] = cm[dest[2]];\n\n        dest[3] = cm[dest[3]];\n\n        dest[4] = cm[dest[4]];\n\n        dest[5] = cm[dest[5]];\n\n        dest[6] = cm[dest[6]];\n\n        dest[7] = cm[dest[7]];\n\n        dest += linesize;\n\n    }\n\n}\n", "idx": 121, "_split": "test", "_hash": "41379c39ed558c52ea6a74919847a640"}
{"project": "FFmpeg", "commit_id": "323e6fead07c75f418e4b60704a4f437bb3483b2", "target": 1, "func": "static void compute_rematrixing_strategy(AC3EncodeContext *s)\n\n{\n\n    int nb_coefs;\n\n    int blk, bnd, i;\n\n    AC3Block *block, *block0;\n\n\n\n    s->num_rematrixing_bands = 4;\n\n\n\n    if (s->rematrixing & AC3_REMATRIXING_IS_STATIC)\n\n        return;\n\n\n\n    nb_coefs = FFMIN(s->nb_coefs[0], s->nb_coefs[1]);\n\n\n\n    for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n        block = &s->blocks[blk];\n\n        block->new_rematrixing_strategy = !blk;\n\n        for (bnd = 0; bnd < s->num_rematrixing_bands; bnd++) {\n\n            /* calculate calculate sum of squared coeffs for one band in one block */\n\n            int start = ff_ac3_rematrix_band_tab[bnd];\n\n            int end   = FFMIN(nb_coefs, ff_ac3_rematrix_band_tab[bnd+1]);\n\n            CoefSumType sum[4] = {0,};\n\n            for (i = start; i < end; i++) {\n\n                CoefType lt = block->mdct_coef[0][i];\n\n                CoefType rt = block->mdct_coef[1][i];\n\n                CoefType md = lt + rt;\n\n                CoefType sd = lt - rt;\n\n                sum[0] += lt * lt;\n\n                sum[1] += rt * rt;\n\n                sum[2] += md * md;\n\n                sum[3] += sd * sd;\n\n            }\n\n\n\n            /* compare sums to determine if rematrixing will be used for this band */\n\n            if (FFMIN(sum[2], sum[3]) < FFMIN(sum[0], sum[1]))\n\n                block->rematrixing_flags[bnd] = 1;\n\n            else\n\n                block->rematrixing_flags[bnd] = 0;\n\n\n\n            /* determine if new rematrixing flags will be sent */\n\n            if (blk &&\n\n                block->rematrixing_flags[bnd] != block0->rematrixing_flags[bnd]) {\n\n                block->new_rematrixing_strategy = 1;\n\n            }\n\n        }\n\n        block0 = block;\n\n    }\n\n}\n", "idx": 149, "_split": "test", "_hash": "8ad893cd74594b7798dabbcf1a74fba9"}
{"project": "FFmpeg", "commit_id": "3547f8e8f8418af0c578eba0de62ecba08e460c2", "target": 0, "func": "static int rv34_decode_mv(RV34DecContext *r, int block_type)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int i, j, k, l;\n\n    int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride;\n\n    int next_bt;\n\n\n\n    memset(r->dmv, 0, sizeof(r->dmv));\n\n    for(i = 0; i < num_mvs[block_type]; i++){\n\n        r->dmv[i][0] = svq3_get_se_golomb(gb);\n\n        r->dmv[i][1] = svq3_get_se_golomb(gb);\n\n    }\n\n    switch(block_type){\n\n    case RV34_MB_TYPE_INTRA:\n\n    case RV34_MB_TYPE_INTRA16x16:\n\n        ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n        return 0;\n\n    case RV34_MB_SKIP:\n\n        if(s->pict_type == AV_PICTURE_TYPE_P){\n\n            ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n            rv34_mc_1mv (r, block_type, 0, 0, 0, 2, 2, 0);\n\n            break;\n\n        }\n\n    case RV34_MB_B_DIRECT:\n\n        //surprisingly, it uses motion scheme from next reference frame\n\n        /* wait for the current mb row to be finished */\n\n        if (HAVE_THREADS && (s->avctx->active_thread_type & FF_THREAD_FRAME))\n\n            ff_thread_await_progress(&s->next_picture_ptr->f, s->mb_y - 1, 0);\n\n\n\n        next_bt = s->next_picture_ptr->f.mb_type[s->mb_x + s->mb_y * s->mb_stride];\n\n        if(IS_INTRA(next_bt) || IS_SKIP(next_bt)){\n\n            ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n            ZERO8x2(s->current_picture_ptr->f.motion_val[1][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n        }else\n\n            for(j = 0; j < 2; j++)\n\n                for(i = 0; i < 2; i++)\n\n                    for(k = 0; k < 2; k++)\n\n                        for(l = 0; l < 2; l++)\n\n                            s->current_picture_ptr->f.motion_val[l][mv_pos + i + j*s->b8_stride][k] = calc_add_mv(r, l, s->next_picture_ptr->f.motion_val[0][mv_pos + i + j*s->b8_stride][k]);\n\n        if(!(IS_16X8(next_bt) || IS_8X16(next_bt) || IS_8X8(next_bt))) //we can use whole macroblock MC\n\n            rv34_mc_2mv(r, block_type);\n\n        else\n\n            rv34_mc_2mv_skip(r);\n\n        ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride);\n\n        break;\n\n    case RV34_MB_P_16x16:\n\n    case RV34_MB_P_MIX16x16:\n\n        rv34_pred_mv(r, block_type, 0, 0);\n\n        rv34_mc_1mv (r, block_type, 0, 0, 0, 2, 2, 0);\n\n        break;\n\n    case RV34_MB_B_FORWARD:\n\n    case RV34_MB_B_BACKWARD:\n\n        r->dmv[1][0] = r->dmv[0][0];\n\n        r->dmv[1][1] = r->dmv[0][1];\n\n        if(r->rv30)\n\n            rv34_pred_mv_rv3(r, block_type, block_type == RV34_MB_B_BACKWARD);\n\n        else\n\n            rv34_pred_mv_b  (r, block_type, block_type == RV34_MB_B_BACKWARD);\n\n        rv34_mc_1mv     (r, block_type, 0, 0, 0, 2, 2, block_type == RV34_MB_B_BACKWARD);\n\n        break;\n\n    case RV34_MB_P_16x8:\n\n    case RV34_MB_P_8x16:\n\n        rv34_pred_mv(r, block_type, 0, 0);\n\n        rv34_pred_mv(r, block_type, 1 + (block_type == RV34_MB_P_16x8), 1);\n\n        if(block_type == RV34_MB_P_16x8){\n\n            rv34_mc_1mv(r, block_type, 0, 0, 0,            2, 1, 0);\n\n            rv34_mc_1mv(r, block_type, 0, 8, s->b8_stride, 2, 1, 0);\n\n        }\n\n        if(block_type == RV34_MB_P_8x16){\n\n            rv34_mc_1mv(r, block_type, 0, 0, 0, 1, 2, 0);\n\n            rv34_mc_1mv(r, block_type, 8, 0, 1, 1, 2, 0);\n\n        }\n\n        break;\n\n    case RV34_MB_B_BIDIR:\n\n        rv34_pred_mv_b  (r, block_type, 0);\n\n        rv34_pred_mv_b  (r, block_type, 1);\n\n        rv34_mc_2mv     (r, block_type);\n\n        break;\n\n    case RV34_MB_P_8x8:\n\n        for(i=0;i< 4;i++){\n\n            rv34_pred_mv(r, block_type, i, i);\n\n            rv34_mc_1mv (r, block_type, (i&1)<<3, (i&2)<<2, (i&1)+(i>>1)*s->b8_stride, 1, 1, 0);\n\n        }\n\n        break;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 185, "_split": "test", "_hash": "da02c00f0505728460cf67b62988fe97"}
{"project": "FFmpeg", "commit_id": "2bfd0a97587d26c0c39413a6291ccc66e4a928d0", "target": 1, "func": "static int read_code_table(CLLCContext *ctx, GetBitContext *gb, VLC *vlc)\n{\n    uint8_t symbols[256];\n    uint8_t bits[256];\n    uint16_t codes[256];\n    int num_lens, num_codes, num_codes_sum, prefix;\n    int i, j, count;\n    prefix        = 0;\n    count         = 0;\n    num_codes_sum = 0;\n    num_lens = get_bits(gb, 5);\n    for (i = 0; i < num_lens; i++) {\n        num_codes      = get_bits(gb, 9);\n        num_codes_sum += num_codes;\n        if (num_codes_sum > 256) {\n            av_log(ctx->avctx, AV_LOG_ERROR,\n                   \"Too many VLCs (%d) to be read.\\n\", num_codes_sum);\n        for (j = 0; j < num_codes; j++) {\n            symbols[count] = get_bits(gb, 8);\n            bits[count]    = i + 1;\n            codes[count]   = prefix++;\n            count++;\n        if (prefix > (65535 - 256)/2) {\n        prefix <<= 1;\n    return ff_init_vlc_sparse(vlc, VLC_BITS, count, bits, 1, 1,\n                              codes, 2, 2, symbols, 1, 1, 0);", "idx": 244, "_split": "test", "_hash": "4052360d8b8b2bad79c18a6bde619607"}
{"project": "FFmpeg", "commit_id": "7bf3f380466eeff24916fd6218aca13e414c6240", "target": 1, "func": "static int cbs_h265_read_nal_unit(CodedBitstreamContext *ctx,\n\n                                  CodedBitstreamUnit *unit)\n\n{\n\n    BitstreamContext bc;\n\n    int err;\n\n\n\n    err = bitstream_init(&bc, unit->data, 8 * unit->data_size);\n\n    if (err < 0)\n\n        return err;\n\n\n\n    switch (unit->type) {\n\n    case HEVC_NAL_VPS:\n\n        {\n\n            H265RawVPS *vps;\n\n\n\n            vps = av_mallocz(sizeof(*vps));\n\n            if (!vps)\n\n                return AVERROR(ENOMEM);\n\n            err = cbs_h265_read_vps(ctx, &bc, vps);\n\n            if (err >= 0)\n\n                err = cbs_h265_replace_vps(ctx, vps);\n\n            if (err < 0) {\n\n                av_free(vps);\n\n                return err;\n\n            }\n\n\n\n            unit->content = vps;\n\n        }\n\n        break;\n\n    case HEVC_NAL_SPS:\n\n        {\n\n            H265RawSPS *sps;\n\n\n\n            sps = av_mallocz(sizeof(*sps));\n\n            if (!sps)\n\n                return AVERROR(ENOMEM);\n\n            err = cbs_h265_read_sps(ctx, &bc, sps);\n\n            if (err >= 0)\n\n                err = cbs_h265_replace_sps(ctx, sps);\n\n            if (err < 0) {\n\n                av_free(sps);\n\n                return err;\n\n            }\n\n\n\n            unit->content = sps;\n\n        }\n\n        break;\n\n\n\n    case HEVC_NAL_PPS:\n\n        {\n\n            H265RawPPS *pps;\n\n\n\n            pps = av_mallocz(sizeof(*pps));\n\n            if (!pps)\n\n                return AVERROR(ENOMEM);\n\n            err = cbs_h265_read_pps(ctx, &bc, pps);\n\n            if (err >= 0)\n\n                err = cbs_h265_replace_pps(ctx, pps);\n\n            if (err < 0) {\n\n                av_free(pps);\n\n                return err;\n\n            }\n\n\n\n            unit->content = pps;\n\n        }\n\n        break;\n\n\n\n    case HEVC_NAL_TRAIL_N:\n\n    case HEVC_NAL_TRAIL_R:\n\n    case HEVC_NAL_TSA_N:\n\n    case HEVC_NAL_TSA_R:\n\n    case HEVC_NAL_STSA_N:\n\n    case HEVC_NAL_STSA_R:\n\n    case HEVC_NAL_RADL_N:\n\n    case HEVC_NAL_RADL_R:\n\n    case HEVC_NAL_RASL_N:\n\n    case HEVC_NAL_RASL_R:\n\n    case HEVC_NAL_BLA_W_LP:\n\n    case HEVC_NAL_BLA_W_RADL:\n\n    case HEVC_NAL_BLA_N_LP:\n\n    case HEVC_NAL_IDR_W_RADL:\n\n    case HEVC_NAL_IDR_N_LP:\n\n    case HEVC_NAL_CRA_NUT:\n\n        {\n\n            H265RawSlice *slice;\n\n            int pos, len;\n\n\n\n            slice = av_mallocz(sizeof(*slice));\n\n            if (!slice)\n\n                return AVERROR(ENOMEM);\n\n            err = cbs_h265_read_slice_segment_header(ctx, &bc, &slice->header);\n\n            if (err < 0) {\n\n                av_free(slice);\n\n                return err;\n\n            }\n\n\n\n            pos = bitstream_tell(&bc);\n\n            len = unit->data_size;\n\n            if (!unit->data[len - 1]) {\n\n                int z;\n\n                for (z = 0; z < len && !unit->data[len - z - 1]; z++);\n\n                av_log(ctx->log_ctx, AV_LOG_DEBUG, \"Deleted %d trailing zeroes \"\n\n                       \"from slice data.\\n\", z);\n\n                len -= z;\n\n            }\n\n\n\n            slice->data_size = len - pos / 8;\n\n            slice->data = av_malloc(slice->data_size);\n\n            if (!slice->data) {\n\n                av_free(slice);\n\n                return AVERROR(ENOMEM);\n\n            }\n\n            memcpy(slice->data,\n\n                   unit->data + pos / 8, slice->data_size);\n\n            slice->data_bit_start = pos % 8;\n\n\n\n            unit->content = slice;\n\n        }\n\n        break;\n\n\n\n    case HEVC_NAL_AUD:\n\n        {\n\n            H265RawAUD *aud;\n\n\n\n            aud = av_mallocz(sizeof(*aud));\n\n            if (!aud)\n\n                return AVERROR(ENOMEM);\n\n            err = cbs_h265_read_aud(ctx, &bc, aud);\n\n            if (err < 0) {\n\n                av_free(aud);\n\n                return err;\n\n            }\n\n\n\n            unit->content = aud;\n\n        }\n\n        break;\n\n\n\n    default:\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 245, "_split": "test", "_hash": "2e816723b294f3b6ce13243c377ead45"}
{"project": "FFmpeg", "commit_id": "964f07f68e1cc4e2d585615e2b1a1fade269afb0", "target": 1, "func": "static av_cold int hevc_init_context(AVCodecContext *avctx)\n{\n    HEVCContext *s = avctx->priv_data;\n    int i;\n    s->avctx = avctx;\n    s->HEVClc = av_mallocz(sizeof(HEVCLocalContext));\n    if (!s->HEVClc)\n        goto fail;\n    s->HEVClcList[0] = s->HEVClc;\n    s->sList[0] = s;\n    s->cabac_state = av_malloc(HEVC_CONTEXTS);\n    if (!s->cabac_state)\n        goto fail;\n    s->output_frame = av_frame_alloc();\n    if (!s->output_frame)\n        goto fail;\n    for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n        s->DPB[i].frame = av_frame_alloc();\n        if (!s->DPB[i].frame)\n            goto fail;\n        s->DPB[i].tf.f = s->DPB[i].frame;\n    }\n    s->max_ra = INT_MAX;\n    s->md5_ctx = av_md5_alloc();\n    if (!s->md5_ctx)\n        goto fail;\n    ff_bswapdsp_init(&s->bdsp);\n    s->context_initialized = 1;\n    s->eos = 0;\n    return 0;\nfail:\n    hevc_decode_free(avctx);\n    return AVERROR(ENOMEM);\n}", "idx": 262, "_split": "test", "_hash": "ca563250e5bba356e67d8e0fb10d5b9a"}
{"project": "FFmpeg", "commit_id": "478f1c3d5e5463a284ea7efecfc62d47ba3be11a", "target": 1, "func": "static int decode_plte_chunk(AVCodecContext *avctx, PNGDecContext *s,\n\n                             uint32_t length)\n\n{\n\n    int n, i, r, g, b;\n\n\n\n    if ((length % 3) != 0 || length > 256 * 3)\n\n        return AVERROR_INVALIDDATA;\n\n    /* read the palette */\n\n    n = length / 3;\n\n    for (i = 0; i < n; i++) {\n\n        r = bytestream2_get_byte(&s->gb);\n\n        g = bytestream2_get_byte(&s->gb);\n\n        b = bytestream2_get_byte(&s->gb);\n\n        s->palette[i] = (0xFFU << 24) | (r << 16) | (g << 8) | b;\n\n    }\n\n    for (; i < 256; i++)\n\n        s->palette[i] = (0xFFU << 24);\n\n    s->state |= PNG_PLTE;\n\n    bytestream2_skip(&s->gb, 4);     /* crc */\n\n\n\n    return 0;\n\n}\n", "idx": 265, "_split": "test", "_hash": "1ed713c129df2ac939952b48518893f9"}
{"project": "FFmpeg", "commit_id": "5c720657c23afd798ae0db7c7362eb859a89ab3d", "target": 1, "func": "static int mov_read_strf(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    if (atom.size <= 40)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n\n\n    if ((uint64_t)atom.size > (1<<30))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    av_free(st->codec->extradata);\n\n    st->codec->extradata = av_mallocz(atom.size - 40 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!st->codec->extradata)\n\n        return AVERROR(ENOMEM);\n\n    st->codec->extradata_size = atom.size - 40;\n\n    avio_skip(pb, 40);\n\n    avio_read(pb, st->codec->extradata, atom.size - 40);\n\n    return 0;\n\n}\n", "idx": 305, "_split": "test", "_hash": "a604bf2cbbac44d0cebd333be7885ac9"}
{"project": "FFmpeg", "commit_id": "1bc64c2814d409d3cc129c27c493ee915bebdc4a", "target": 1, "func": "int attribute_align_arg avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,\n                                              int *got_picture_ptr,\n                                              AVPacket *avpkt)\n{\n    int ret;\n    *got_picture_ptr = 0;\n    if ((avctx->coded_width || avctx->coded_height) && av_image_check_size(avctx->coded_width, avctx->coded_height, 0, avctx))\n        return -1;\n    avctx->pkt = avpkt;\n    apply_param_change(avctx, avpkt);\n    if ((avctx->codec->capabilities & CODEC_CAP_DELAY) || avpkt->size || (avctx->active_thread_type & FF_THREAD_FRAME)) {\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n            ret = ff_thread_decode_frame(avctx, picture, got_picture_ptr,\n                                         avpkt);\n        else {\n            ret = avctx->codec->decode(avctx, picture, got_picture_ptr,\n                                       avpkt);\n            picture->pkt_dts             = avpkt->dts;\n            picture->sample_aspect_ratio = avctx->sample_aspect_ratio;\n            picture->width               = avctx->width;\n            picture->height              = avctx->height;\n            picture->format              = avctx->pix_fmt;\n        }\n        emms_c(); //needed to avoid an emms_c() call before every return;\n        if (*got_picture_ptr)\n            avctx->frame_number++;\n    } else\n        ret = 0;\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n     * make sure it's set correctly */\n    picture->extended_data = picture->data;\n    return ret;\n}", "idx": 372, "_split": "test", "_hash": "f8ca9a94f8d9f1b585dedbcf9438efe2"}
{"project": "FFmpeg", "commit_id": "c8d0d8bc767309d5e8d9ee64addc11117190338e", "target": 1, "func": "static int crypto_open(URLContext *h, const char *uri, int flags)\n\n{\n\n    const char *nested_url;\n\n    int ret;\n\n    CryptoContext *c = h->priv_data;\n\n\n\n    if (!av_strstart(uri, \"crypto+\", &nested_url) &&\n\n        !av_strstart(uri, \"crypto:\", &nested_url)) {\n\n        av_log(h, AV_LOG_ERROR, \"Unsupported url %s\\n\", uri);\n\n        ret = AVERROR(EINVAL);\n\n        goto err;\n\n    }\n\n\n\n    if (c->keylen < BLOCKSIZE || c->ivlen < BLOCKSIZE) {\n\n        av_log(h, AV_LOG_ERROR, \"Key or IV not set\\n\");\n\n        ret = AVERROR(EINVAL);\n\n        goto err;\n\n    }\n\n    if (flags & AVIO_FLAG_WRITE) {\n\n        av_log(h, AV_LOG_ERROR, \"Only decryption is supported currently\\n\");\n\n        ret = AVERROR(ENOSYS);\n\n        goto err;\n\n    }\n\n    if ((ret = ffurl_open(&c->hd, nested_url, AVIO_FLAG_READ)) < 0) {\n\n        av_log(h, AV_LOG_ERROR, \"Unable to open input\\n\");\n\n        goto err;\n\n    }\n\n    c->aes = av_mallocz(av_aes_size);\n\n    if (!c->aes) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto err;\n\n    }\n\n\n\n    av_aes_init(c->aes, c->key, 128, 1);\n\n\n\n    h->is_streamed = 1;\n\n\n\n    return 0;\n\nerr:\n\n    av_free(c->key);\n\n    av_free(c->iv);\n\n    return ret;\n\n}\n", "idx": 436, "_split": "test", "_hash": "8f07426568ea31dd9c87700d8251d574"}
{"project": "FFmpeg", "commit_id": "72555f4a382744dd7f02edcb7fe6f8ed91f4dc3c", "target": 1, "func": "int ff_alloc_entries(AVCodecContext *avctx, int count)\n\n{\n\n    int i;\n\n\n\n    if (avctx->active_thread_type & FF_THREAD_SLICE)  {\n\n        SliceThreadContext *p = avctx->internal->thread_ctx;\n\n        p->thread_count  = avctx->thread_count;\n\n        p->entries       = av_mallocz_array(count, sizeof(int));\n\n\n\n        if (!p->entries) {\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        p->entries_count  = count;\n\n        p->progress_mutex = av_malloc_array(p->thread_count, sizeof(pthread_mutex_t));\n\n        p->progress_cond  = av_malloc_array(p->thread_count, sizeof(pthread_cond_t));\n\n\n\n        for (i = 0; i < p->thread_count; i++) {\n\n            pthread_mutex_init(&p->progress_mutex[i], NULL);\n\n            pthread_cond_init(&p->progress_cond[i], NULL);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 439, "_split": "test", "_hash": "00b6b0fe1ef8eeabdf6d31639508b605"}
{"project": "FFmpeg", "commit_id": "ccc27e2139336b66cdec3bb73a2cc7e60ef7e599", "target": 1, "func": "static int bfi_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data, *buf_end = avpkt->data + avpkt->size;\n\n    int buf_size = avpkt->size;\n\n    BFIContext *bfi = avctx->priv_data;\n\n    uint8_t *dst = bfi->dst;\n\n    uint8_t *src, *dst_offset, colour1, colour2;\n\n    uint8_t *frame_end = bfi->dst + avctx->width * avctx->height;\n\n    uint32_t *pal;\n\n    int i, j, height = avctx->height;\n\n\n\n    if (bfi->frame.data[0])\n\n        avctx->release_buffer(avctx, &bfi->frame);\n\n\n\n    bfi->frame.reference = 1;\n\n\n\n    if (avctx->get_buffer(avctx, &bfi->frame) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* Set frame parameters and palette, if necessary */\n\n    if (!avctx->frame_number) {\n\n        bfi->frame.pict_type = AV_PICTURE_TYPE_I;\n\n        bfi->frame.key_frame = 1;\n\n        /* Setting the palette */\n\n        if (avctx->extradata_size > 768) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Palette is too large.\\n\");\n\n            return -1;\n\n        }\n\n        pal = (uint32_t *)bfi->frame.data[1];\n\n        for (i = 0; i < avctx->extradata_size / 3; i++) {\n\n            int shift = 16;\n\n            *pal = 0;\n\n            for (j = 0; j < 3; j++, shift -= 8)\n\n                *pal +=\n\n                    ((avctx->extradata[i * 3 + j] << 2) |\n\n                    (avctx->extradata[i * 3 + j] >> 4)) << shift;\n\n            pal++;\n\n        }\n\n        bfi->frame.palette_has_changed = 1;\n\n    } else {\n\n        bfi->frame.pict_type = AV_PICTURE_TYPE_P;\n\n        bfi->frame.key_frame = 0;\n\n    }\n\n\n\n    buf += 4; // Unpacked size, not required.\n\n\n\n    while (dst != frame_end) {\n\n        static const uint8_t lentab[4] = { 0, 2, 0, 1 };\n\n        unsigned int byte   = *buf++, av_uninit(offset);\n\n        unsigned int code   = byte >> 6;\n\n        unsigned int length = byte & ~0xC0;\n\n\n\n        if (buf >= buf_end) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Input resolution larger than actual frame.\\n\");\n\n            return -1;\n\n        }\n\n\n\n        /* Get length and offset(if required) */\n\n        if (length == 0) {\n\n            if (code == 1) {\n\n                length = bytestream_get_byte(&buf);\n\n                offset = bytestream_get_le16(&buf);\n\n            } else {\n\n                length = bytestream_get_le16(&buf);\n\n                if (code == 2 && length == 0)\n\n                    break;\n\n            }\n\n        } else {\n\n            if (code == 1)\n\n                offset = bytestream_get_byte(&buf);\n\n        }\n\n\n\n        /* Do boundary check */\n\n        if (dst + (length << lentab[code]) > frame_end)\n\n            break;\n\n\n\n        switch (code) {\n\n\n\n        case 0:                //Normal Chain\n\n            if (length >= buf_end - buf) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Frame larger than buffer.\\n\");\n\n                return -1;\n\n            }\n\n            bytestream_get_buffer(&buf, dst, length);\n\n            dst += length;\n\n            break;\n\n\n\n        case 1:                //Back Chain\n\n            dst_offset = dst - offset;\n\n            length *= 4;        //Convert dwords to bytes.\n\n            if (dst_offset < bfi->dst)\n\n                break;\n\n            while (length--)\n\n                *dst++ = *dst_offset++;\n\n            break;\n\n\n\n        case 2:                //Skip Chain\n\n            dst += length;\n\n            break;\n\n\n\n        case 3:                //Fill Chain\n\n            colour1 = bytestream_get_byte(&buf);\n\n            colour2 = bytestream_get_byte(&buf);\n\n            while (length--) {\n\n                *dst++ = colour1;\n\n                *dst++ = colour2;\n\n            }\n\n            break;\n\n\n\n        }\n\n    }\n\n\n\n    src = bfi->dst;\n\n    dst = bfi->frame.data[0];\n\n    while (height--) {\n\n        memcpy(dst, src, avctx->width);\n\n        src += avctx->width;\n\n        dst += bfi->frame.linesize[0];\n\n    }\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame *)data = bfi->frame;\n\n    return buf_size;\n\n}\n", "idx": 490, "_split": "test", "_hash": "1bb6690abb54d70492f3393d792b543f"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int process_input_packet(InputStream *ist, const AVPacket *pkt)\n\n{\n\n    int i;\n\n    int got_output;\n\n    AVPacket avpkt;\n\n\n\n    if (ist->next_dts == AV_NOPTS_VALUE)\n\n        ist->next_dts = ist->last_dts;\n\n\n\n    if (pkt == NULL) {\n\n        /* EOF handling */\n\n        av_init_packet(&avpkt);\n\n        avpkt.data = NULL;\n\n        avpkt.size = 0;\n\n        goto handle_eof;\n\n    } else {\n\n        avpkt = *pkt;\n\n    }\n\n\n\n    if (pkt->dts != AV_NOPTS_VALUE)\n\n        ist->next_dts = ist->last_dts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n\n\n    // while we have more to decode or while the decoder did output something on EOF\n\n    while (ist->decoding_needed && (avpkt.size > 0 || (!pkt && got_output))) {\n\n        int ret = 0;\n\n    handle_eof:\n\n\n\n        ist->last_dts = ist->next_dts;\n\n\n\n        if (avpkt.size && avpkt.size != pkt->size &&\n\n            !(ist->dec->capabilities & CODEC_CAP_SUBFRAMES)) {\n\n            av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING,\n\n                   \"Multiple frames in a packet from stream %d\\n\", pkt->stream_index);\n\n            ist->showed_multi_packet_warning = 1;\n\n        }\n\n\n\n        switch (ist->dec_ctx->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ret = decode_audio    (ist, &avpkt, &got_output);\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            ret = decode_video    (ist, &avpkt, &got_output);\n\n            if (avpkt.duration)\n\n                ist->next_dts += av_rescale_q(avpkt.duration, ist->st->time_base, AV_TIME_BASE_Q);\n\n            else if (ist->st->avg_frame_rate.num)\n\n                ist->next_dts += av_rescale_q(1, av_inv_q(ist->st->avg_frame_rate),\n\n                                              AV_TIME_BASE_Q);\n\n            else if (ist->dec_ctx->time_base.num != 0) {\n\n                int ticks      = ist->st->parser ? ist->st->parser->repeat_pict + 1 :\n\n                                                   ist->dec_ctx->ticks_per_frame;\n\n                ist->next_dts += av_rescale_q(ticks, ist->dec_ctx->time_base, AV_TIME_BASE_Q);\n\n            }\n\n            break;\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            ret = transcode_subtitles(ist, &avpkt, &got_output);\n\n            break;\n\n        default:\n\n            return -1;\n\n        }\n\n\n\n        if (ret < 0)\n\n            return ret;\n\n        // touch data and size only if not EOF\n\n        if (pkt) {\n\n            avpkt.data += ret;\n\n            avpkt.size -= ret;\n\n        }\n\n        if (!got_output) {\n\n            continue;\n\n        }\n\n    }\n\n\n\n    /* handle stream copy */\n\n    if (!ist->decoding_needed) {\n\n        ist->last_dts = ist->next_dts;\n\n        switch (ist->dec_ctx->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ist->next_dts += ((int64_t)AV_TIME_BASE * ist->dec_ctx->frame_size) /\n\n                             ist->dec_ctx->sample_rate;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if (ist->dec_ctx->time_base.num != 0) {\n\n                int ticks = ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->dec_ctx->ticks_per_frame;\n\n                ist->next_dts += ((int64_t)AV_TIME_BASE *\n\n                                  ist->dec_ctx->time_base.num * ticks) /\n\n                                  ist->dec_ctx->time_base.den;\n\n            }\n\n            break;\n\n        }\n\n    }\n\n    for (i = 0; pkt && i < nb_output_streams; i++) {\n\n        OutputStream *ost = output_streams[i];\n\n\n\n        if (!check_output_constraints(ist, ost) || ost->encoding_needed)\n\n            continue;\n\n\n\n        do_streamcopy(ist, ost, pkt);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 566, "_split": "test", "_hash": "80d41d24083d6b528b2dd3930cd5b59a"}
{"project": "FFmpeg", "commit_id": "ca488ad480360dfafcb5766f7bfbb567a0638979", "target": 1, "func": "static int decode_blocks(ALSDecContext *ctx, unsigned int ra_frame,\n\n                         unsigned int c, const unsigned int *div_blocks,\n\n                         unsigned int *js_blocks)\n\n{\n\n    ALSSpecificConfig *sconf = &ctx->sconf;\n\n    unsigned int offset = 0;\n\n    unsigned int b;\n\n    ALSBlockData bd[2] = { { 0 } };\n\n\n\n    bd[0].ra_block         = ra_frame;\n\n    bd[0].const_block      = ctx->const_block;\n\n    bd[0].shift_lsbs       = ctx->shift_lsbs;\n\n    bd[0].opt_order        = ctx->opt_order;\n\n    bd[0].store_prev_samples = ctx->store_prev_samples;\n\n    bd[0].use_ltp          = ctx->use_ltp;\n\n    bd[0].ltp_lag          = ctx->ltp_lag;\n\n    bd[0].ltp_gain         = ctx->ltp_gain[0];\n\n    bd[0].quant_cof        = ctx->quant_cof[0];\n\n    bd[0].lpc_cof          = ctx->lpc_cof[0];\n\n    bd[0].prev_raw_samples = ctx->prev_raw_samples;\n\n    bd[0].js_blocks        = *js_blocks;\n\n\n\n    bd[1].ra_block         = ra_frame;\n\n    bd[1].const_block      = ctx->const_block;\n\n    bd[1].shift_lsbs       = ctx->shift_lsbs;\n\n    bd[1].opt_order        = ctx->opt_order;\n\n    bd[1].store_prev_samples = ctx->store_prev_samples;\n\n    bd[1].use_ltp          = ctx->use_ltp;\n\n    bd[1].ltp_lag          = ctx->ltp_lag;\n\n    bd[1].ltp_gain         = ctx->ltp_gain[0];\n\n    bd[1].quant_cof        = ctx->quant_cof[0];\n\n    bd[1].lpc_cof          = ctx->lpc_cof[0];\n\n    bd[1].prev_raw_samples = ctx->prev_raw_samples;\n\n    bd[1].js_blocks        = *(js_blocks + 1);\n\n\n\n    // decode all blocks\n\n    for (b = 0; b < ctx->num_blocks; b++) {\n\n        unsigned int s;\n\n\n\n        bd[0].block_length = div_blocks[b];\n\n        bd[1].block_length = div_blocks[b];\n\n\n\n        bd[0].raw_samples  = ctx->raw_samples[c    ] + offset;\n\n        bd[1].raw_samples  = ctx->raw_samples[c + 1] + offset;\n\n\n\n        bd[0].raw_other    = bd[1].raw_samples;\n\n        bd[1].raw_other    = bd[0].raw_samples;\n\n\n\n        if(read_decode_block(ctx, &bd[0]) || read_decode_block(ctx, &bd[1])) {\n\n            // damaged block, write zero for the rest of the frame\n\n            zero_remaining(b, ctx->num_blocks, div_blocks, bd[0].raw_samples);\n\n            zero_remaining(b, ctx->num_blocks, div_blocks, bd[1].raw_samples);\n\n            return -1;\n\n        }\n\n\n\n        // reconstruct joint-stereo blocks\n\n        if (bd[0].js_blocks) {\n\n            if (bd[1].js_blocks)\n\n                av_log(ctx->avctx, AV_LOG_WARNING, \"Invalid channel pair!\\n\");\n\n\n\n            for (s = 0; s < div_blocks[b]; s++)\n\n                bd[0].raw_samples[s] = bd[1].raw_samples[s] - bd[0].raw_samples[s];\n\n        } else if (bd[1].js_blocks) {\n\n            for (s = 0; s < div_blocks[b]; s++)\n\n                bd[1].raw_samples[s] = bd[1].raw_samples[s] + bd[0].raw_samples[s];\n\n        }\n\n\n\n        offset  += div_blocks[b];\n\n        bd[0].ra_block = 0;\n\n        bd[1].ra_block = 0;\n\n    }\n\n\n\n    // store carryover raw samples,\n\n    // the others channel raw samples are stored by the calling function.\n\n    memmove(ctx->raw_samples[c] - sconf->max_order,\n\n            ctx->raw_samples[c] - sconf->max_order + sconf->frame_length,\n\n            sizeof(*ctx->raw_samples[c]) * sconf->max_order);\n\n\n\n    return 0;\n\n}\n", "idx": 585, "_split": "test", "_hash": "8ee17fa160ad203ce3692e30d9883a3a"}
{"project": "FFmpeg", "commit_id": "56706ac0d5723cb549fec2602e798ab1bf6004cd", "target": 1, "func": "static int libopenjpeg_copy_packed12(AVCodecContext *avctx, const AVFrame *frame, opj_image_t *image)\n\n{\n\n    int compno;\n\n    int x, y;\n\n    int *image_line;\n\n    int frame_index;\n\n    const int numcomps  = image->numcomps;\n\n    uint16_t *frame_ptr = (uint16_t *)frame->data[0];\n\n\n\n    for (compno = 0; compno < numcomps; ++compno) {\n\n        if (image->comps[compno].w > frame->linesize[0] / numcomps) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error: frame's linesize is too small for the image\\n\");\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    for (compno = 0; compno < numcomps; ++compno) {\n\n        for (y = 0; y < avctx->height; ++y) {\n\n            image_line = image->comps[compno].data + y * image->comps[compno].w;\n\n            frame_index = y * (frame->linesize[0] / 2) + compno;\n\n            for (x = 0; x < avctx->width; ++x) {\n\n                image_line[x] = frame_ptr[frame_index] >> 4;\n\n                frame_index += numcomps;\n\n            }\n\n            for (; x < image->comps[compno].w; ++x) {\n\n                image_line[x] = image_line[x - 1];\n\n            }\n\n        }\n\n        for (; y < image->comps[compno].h; ++y) {\n\n            image_line = image->comps[compno].data + y * image->comps[compno].w;\n\n            for (x = 0; x < image->comps[compno].w; ++x) {\n\n                image_line[x] = image_line[x - image->comps[compno].w];\n\n            }\n\n        }\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 657, "_split": "test", "_hash": "aa0ec542627cb8c83f7ab4eb6d0c5423"}
{"project": "FFmpeg", "commit_id": "55815edca038997ec283569a192a3eca7f2143bc", "target": 0, "func": "static void build_feed_streams(void)\n\n{\n\n    FFStream *stream, *feed;\n\n    int i;\n\n\n\n    /* gather all streams */\n\n    for(stream = first_stream; stream != NULL; stream = stream->next) {\n\n        feed = stream->feed;\n\n        if (feed) {\n\n            if (!stream->is_feed) {\n\n                /* we handle a stream coming from a feed */\n\n                for(i=0;i<stream->nb_streams;i++)\n\n                    stream->feed_streams[i] = add_av_stream(feed, stream->streams[i]);\n\n            }\n\n        }\n\n    }\n\n\n\n    /* gather all streams */\n\n    for(stream = first_stream; stream != NULL; stream = stream->next) {\n\n        feed = stream->feed;\n\n        if (feed) {\n\n            if (stream->is_feed) {\n\n                for(i=0;i<stream->nb_streams;i++)\n\n                    stream->feed_streams[i] = i;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* create feed files if needed */\n\n    for(feed = first_feed; feed != NULL; feed = feed->next_feed) {\n\n        int fd;\n\n\n\n        if (url_exist(feed->feed_filename)) {\n\n            /* See if it matches */\n\n            AVFormatContext *s;\n\n            int matches = 0;\n\n\n\n            if (av_open_input_file(&s, feed->feed_filename, NULL, FFM_PACKET_SIZE, NULL) >= 0) {\n\n                /* Now see if it matches */\n\n                if (s->nb_streams == feed->nb_streams) {\n\n                    matches = 1;\n\n                    for(i=0;i<s->nb_streams;i++) {\n\n                        AVStream *sf, *ss;\n\n                        sf = feed->streams[i];\n\n                        ss = s->streams[i];\n\n\n\n                        if (sf->index != ss->index ||\n\n                            sf->id != ss->id) {\n\n                            http_log(\"Index & Id do not match for stream %d (%s)\\n\",\n\n                                   i, feed->feed_filename);\n\n                            matches = 0;\n\n                        } else {\n\n                            AVCodecContext *ccf, *ccs;\n\n\n\n                            ccf = sf->codec;\n\n                            ccs = ss->codec;\n\n#define CHECK_CODEC(x)  (ccf->x != ccs->x)\n\n\n\n                            if (CHECK_CODEC(codec_id) || CHECK_CODEC(codec_type)) {\n\n                                http_log(\"Codecs do not match for stream %d\\n\", i);\n\n                                matches = 0;\n\n                            } else if (CHECK_CODEC(bit_rate) || CHECK_CODEC(flags)) {\n\n                                http_log(\"Codec bitrates do not match for stream %d\\n\", i);\n\n                                matches = 0;\n\n                            } else if (ccf->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n                                if (CHECK_CODEC(time_base.den) ||\n\n                                    CHECK_CODEC(time_base.num) ||\n\n                                    CHECK_CODEC(width) ||\n\n                                    CHECK_CODEC(height)) {\n\n                                    http_log(\"Codec width, height and framerate do not match for stream %d\\n\", i);\n\n                                    matches = 0;\n\n                                }\n\n                            } else if (ccf->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n                                if (CHECK_CODEC(sample_rate) ||\n\n                                    CHECK_CODEC(channels) ||\n\n                                    CHECK_CODEC(frame_size)) {\n\n                                    http_log(\"Codec sample_rate, channels, frame_size do not match for stream %d\\n\", i);\n\n                                    matches = 0;\n\n                                }\n\n                            } else {\n\n                                http_log(\"Unknown codec type\\n\");\n\n                                matches = 0;\n\n                            }\n\n                        }\n\n                        if (!matches)\n\n                            break;\n\n                    }\n\n                } else\n\n                    http_log(\"Deleting feed file '%s' as stream counts differ (%d != %d)\\n\",\n\n                        feed->feed_filename, s->nb_streams, feed->nb_streams);\n\n\n\n                av_close_input_file(s);\n\n            } else\n\n                http_log(\"Deleting feed file '%s' as it appears to be corrupt\\n\",\n\n                        feed->feed_filename);\n\n\n\n            if (!matches) {\n\n                if (feed->readonly) {\n\n                    http_log(\"Unable to delete feed file '%s' as it is marked readonly\\n\",\n\n                        feed->feed_filename);\n\n                    exit(1);\n\n                }\n\n                unlink(feed->feed_filename);\n\n            }\n\n        }\n\n        if (!url_exist(feed->feed_filename)) {\n\n            AVFormatContext s1 = {0}, *s = &s1;\n\n\n\n            if (feed->readonly) {\n\n                http_log(\"Unable to create feed file '%s' as it is marked readonly\\n\",\n\n                    feed->feed_filename);\n\n                exit(1);\n\n            }\n\n\n\n            /* only write the header of the ffm file */\n\n            if (avio_open(&s->pb, feed->feed_filename, AVIO_FLAG_WRITE) < 0) {\n\n                http_log(\"Could not open output feed file '%s'\\n\",\n\n                         feed->feed_filename);\n\n                exit(1);\n\n            }\n\n            s->oformat = feed->fmt;\n\n            s->nb_streams = feed->nb_streams;\n\n            for(i=0;i<s->nb_streams;i++) {\n\n                AVStream *st;\n\n                st = feed->streams[i];\n\n                s->streams[i] = st;\n\n            }\n\n            av_set_parameters(s, NULL);\n\n            if (av_write_header(s) < 0) {\n\n                http_log(\"Container doesn't supports the required parameters\\n\");\n\n                exit(1);\n\n            }\n\n            /* XXX: need better api */\n\n            av_freep(&s->priv_data);\n\n            avio_close(s->pb);\n\n        }\n\n        /* get feed size and write index */\n\n        fd = open(feed->feed_filename, O_RDONLY);\n\n        if (fd < 0) {\n\n            http_log(\"Could not open output feed file '%s'\\n\",\n\n                    feed->feed_filename);\n\n            exit(1);\n\n        }\n\n\n\n        feed->feed_write_index = FFMAX(ffm_read_write_index(fd), FFM_PACKET_SIZE);\n\n        feed->feed_size = lseek(fd, 0, SEEK_END);\n\n        /* ensure that we do not wrap before the end of file */\n\n        if (feed->feed_max_size && feed->feed_max_size < feed->feed_size)\n\n            feed->feed_max_size = feed->feed_size;\n\n\n\n        close(fd);\n\n    }\n\n}\n", "idx": 666, "_split": "test", "_hash": "8e11b2401ad58efec5cac1ebed720f12"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void palette8tobgr24(const uint8_t *src, uint8_t *dst, long num_pixels, const uint8_t *palette)\n\n{\n\n\tlong i;\n\n/*\n\n\twrites 1 byte o much and might cause alignment issues on some architectures?\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t\t((unsigned *)(&dst[i*3])) = ((unsigned *)palette)[ src[i] ];\n\n*/\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t\t//FIXME slow?\n\n\t\tdst[0]= palette[ src[i]*4+0 ];\n\n\t\tdst[1]= palette[ src[i]*4+1 ];\n\n\t\tdst[2]= palette[ src[i]*4+2 ];\n\n\t\tdst+= 3;\n\n\t}\n\n}\n", "idx": 674, "_split": "test", "_hash": "f1a20e45cd3c2d3ee193e67240478695"}
{"project": "FFmpeg", "commit_id": "5cd8afee99c83b62e1474f122d947de7e4ad9ff5", "target": 0, "func": "static inline void codeblock(DiracContext *s, SubBand *b,\n\n                             GetBitContext *gb, DiracArith *c,\n\n                             int left, int right, int top, int bottom,\n\n                             int blockcnt_one, int is_arith)\n\n{\n\n    int x, y, zero_block;\n\n    int qoffset, qfactor;\n\n    IDWTELEM *buf;\n\n\n\n    /* check for any coded coefficients in this codeblock */\n\n    if (!blockcnt_one) {\n\n        if (is_arith)\n\n            zero_block = dirac_get_arith_bit(c, CTX_ZERO_BLOCK);\n\n        else\n\n            zero_block = get_bits1(gb);\n\n\n\n        if (zero_block)\n\n            return;\n\n    }\n\n\n\n    if (s->codeblock_mode && !(s->old_delta_quant && blockcnt_one)) {\n\n        if (is_arith)\n\n            b->quant += dirac_get_arith_int(c, CTX_DELTA_Q_F, CTX_DELTA_Q_DATA);\n\n        else\n\n            b->quant += dirac_get_se_golomb(gb);\n\n    }\n\n\n\n    b->quant = FFMIN(b->quant, MAX_QUANT);\n\n\n\n    qfactor = qscale_tab[b->quant];\n\n    /* TODO: context pointer? */\n\n    if (!s->num_refs)\n\n        qoffset = qoffset_intra_tab[b->quant];\n\n    else\n\n        qoffset = qoffset_inter_tab[b->quant];\n\n\n\n    buf = b->ibuf + top * b->stride;\n\n    for (y = top; y < bottom; y++) {\n\n        for (x = left; x < right; x++) {\n\n            /* [DIRAC_STD] 13.4.4 Subband coefficients. coeff_unpack() */\n\n            if (is_arith)\n\n                coeff_unpack_arith(c, qfactor, qoffset, b, buf+x, x, y);\n\n            else\n\n                buf[x] = coeff_unpack_golomb(gb, qfactor, qoffset);\n\n        }\n\n        buf += b->stride;\n\n    }\n\n}\n", "idx": 677, "_split": "test", "_hash": "d72a1f97251ffb9e97b8995b4b754737"}
{"project": "FFmpeg", "commit_id": "d58a6d8537a6f34941973c5c3be93d484a4d62ed", "target": 1, "func": "static int encode_frame(AVCodecContext *avctx, unsigned char *buf, int buf_size, void *data){\n\n    FFV1Context *f = avctx->priv_data;\n\n    CABACContext * const c= &f->c;\n\n    AVFrame *pict = data;\n\n    const int width= f->width;\n\n    const int height= f->height;\n\n    AVFrame * const p= &f->picture;\n\n    int used_count= 0;\n\n\n\n    if(avctx->strict_std_compliance >= 0){\n\n        av_log(avctx, AV_LOG_ERROR, \"this codec is under development, files encoded with it wont be decodeable with future versions!!!\\n\"\n\n               \"use vstrict=-1 to use it anyway\\n\");\n\n        return -1;\n\n    }\n\n        \n\n    ff_init_cabac_encoder(c, buf, buf_size);\n\n    ff_init_cabac_states(c, ff_h264_lps_range, ff_h264_mps_state, ff_h264_lps_state, 64);\n\n    c->lps_state[2] = 1;\n\n    c->lps_state[3] = 0;\n\n    \n\n    *p = *pict;\n\n    p->pict_type= FF_I_TYPE;\n\n    \n\n    if(avctx->gop_size==0 || f->picture_number % avctx->gop_size == 0){\n\n        put_cabac_bypass(c, 1);\n\n        p->key_frame= 1;\n\n        write_header(f);\n\n        clear_state(f);\n\n    }else{\n\n        put_cabac_bypass(c, 0);\n\n        p->key_frame= 0;\n\n    }\n\n\n\n    if(!f->ac){\n\n        used_count += put_cabac_terminate(c, 1);\n\n//printf(\"pos=%d\\n\", used_count);\n\n        init_put_bits(&f->pb, buf + used_count, buf_size - used_count);\n\n    }\n\n    \n\n    if(f->colorspace==0){\n\n        const int chroma_width = -((-width )>>f->chroma_h_shift);\n\n        const int chroma_height= -((-height)>>f->chroma_v_shift);\n\n\n\n        encode_plane(f, p->data[0], width, height, p->linesize[0], 0);\n\n\n\n        encode_plane(f, p->data[1], chroma_width, chroma_height, p->linesize[1], 1);\n\n        encode_plane(f, p->data[2], chroma_width, chroma_height, p->linesize[2], 1);\n\n    }else{\n\n        encode_rgb_frame(f, (uint32_t*)(p->data[0]), width, height, p->linesize[0]/4);\n\n    }\n\n    emms_c();\n\n    \n\n    f->picture_number++;\n\n\n\n    if(f->ac){\n\n        return put_cabac_terminate(c, 1);\n\n    }else{\n\n        flush_put_bits(&f->pb); //nicer padding FIXME\n\n        return used_count + (put_bits_count(&f->pb)+7)/8;\n\n    }\n\n}\n", "idx": 683, "_split": "test", "_hash": "98e233865319a4b66d2544cd98a9fe3c"}
{"project": "FFmpeg", "commit_id": "a8d702859b8bd17978fb5d8cb1d6acc363031e80", "target": 1, "func": "static int read_major_sync(MLPDecodeContext *m, GetBitContext *gb)\n\n{\n\n    MLPHeaderInfo mh;\n\n    int substr, ret;\n\n\n\n    if ((ret = ff_mlp_read_major_sync(m->avctx, &mh, gb)) != 0)\n\n        return ret;\n\n\n\n    if (mh.group1_bits == 0) {\n\n        av_log(m->avctx, AV_LOG_ERROR, \"invalid/unknown bits per sample\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n\n    if (mh.group2_bits > mh.group1_bits) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Channel group 2 cannot have more bits per sample than group 1.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n\n\n\n    if (mh.group2_samplerate && mh.group2_samplerate != mh.group1_samplerate) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Channel groups with differing sample rates are not currently supported.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n\n\n\n    if (mh.group1_samplerate == 0) {\n\n        av_log(m->avctx, AV_LOG_ERROR, \"invalid/unknown sampling rate\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n\n    if (mh.group1_samplerate > MAX_SAMPLERATE) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Sampling rate %d is greater than the supported maximum (%d).\\n\",\n\n               mh.group1_samplerate, MAX_SAMPLERATE);\n\n        return AVERROR_INVALIDDATA;\n\n\n    if (mh.access_unit_size > MAX_BLOCKSIZE) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Block size %d is greater than the supported maximum (%d).\\n\",\n\n               mh.access_unit_size, MAX_BLOCKSIZE);\n\n        return AVERROR_INVALIDDATA;\n\n\n    if (mh.access_unit_size_pow2 > MAX_BLOCKSIZE_POW2) {\n\n        av_log(m->avctx, AV_LOG_ERROR,\n\n               \"Block size pow2 %d is greater than the supported maximum (%d).\\n\",\n\n               mh.access_unit_size_pow2, MAX_BLOCKSIZE_POW2);\n\n        return AVERROR_INVALIDDATA;\n\n\n\n\n    if (mh.num_substreams == 0)\n\n        return AVERROR_INVALIDDATA;\n\n    if (m->avctx->codec_id == AV_CODEC_ID_MLP && mh.num_substreams > 2) {\n\n        av_log(m->avctx, AV_LOG_ERROR, \"MLP only supports up to 2 substreams.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n\n    if (mh.num_substreams > MAX_SUBSTREAMS) {\n\n\n                              \"%d substreams (more than the \"\n\n                              \"maximum supported by the decoder)\",\n\n                              mh.num_substreams);\n\n\n\n\n\n    m->access_unit_size      = mh.access_unit_size;\n\n    m->access_unit_size_pow2 = mh.access_unit_size_pow2;\n\n\n\n    m->num_substreams        = mh.num_substreams;\n\n    m->max_decoded_substream = m->num_substreams - 1;\n\n\n\n    m->avctx->sample_rate    = mh.group1_samplerate;\n\n    m->avctx->frame_size     = mh.access_unit_size;\n\n\n\n    m->avctx->bits_per_raw_sample = mh.group1_bits;\n\n    if (mh.group1_bits > 16)\n\n        m->avctx->sample_fmt = AV_SAMPLE_FMT_S32;\n\n    else\n\n        m->avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n\n\n    m->params_valid = 1;\n\n    for (substr = 0; substr < MAX_SUBSTREAMS; substr++)\n\n        m->substream[substr].restart_seen = 0;\n\n\n\n    /* Set the layout for each substream. When there's more than one, the first\n\n     * substream is Stereo. Subsequent substreams' layouts are indicated in the\n\n     * major sync. */\n\n    if (m->avctx->codec_id == AV_CODEC_ID_MLP) {\n\n\n\n\n\n\n\n        if ((substr = (mh.num_substreams > 1)))\n\n            m->substream[0].ch_layout = AV_CH_LAYOUT_STEREO;\n\n        m->substream[substr].ch_layout = mh.channel_layout_mlp;\n\n    } else {\n\n\n\n\n\n\n\n        if ((substr = (mh.num_substreams > 1)))\n\n            m->substream[0].ch_layout = AV_CH_LAYOUT_STEREO;\n\n        if (mh.num_substreams > 2)\n\n            if (mh.channel_layout_thd_stream2)\n\n                m->substream[2].ch_layout = mh.channel_layout_thd_stream2;\n\n            else\n\n                m->substream[2].ch_layout = mh.channel_layout_thd_stream1;\n\n        m->substream[substr].ch_layout = mh.channel_layout_thd_stream1;\n\n\n\n        if (m->avctx->channels<=2 && m->substream[substr].ch_layout == AV_CH_LAYOUT_MONO && m->max_decoded_substream == 1) {\n\n            av_log(m->avctx, AV_LOG_DEBUG, \"Mono stream with 2 substreams, ignoring 2nd\\n\");\n\n            m->max_decoded_substream = 0;\n\n            if (m->avctx->channels==2)\n\n                m->avctx->channel_layout = AV_CH_LAYOUT_STEREO;\n\n\n\n\n\n    m->needs_reordering = mh.channel_arrangement >= 18 && mh.channel_arrangement <= 20;\n\n\n\n    return 0;\n", "idx": 748, "_split": "test", "_hash": "993ca25d045b7cd72dce2941136bd620"}
{"project": "FFmpeg", "commit_id": "7e3e653618a59960b4c358e333ba2c0d21929e33", "target": 1, "func": "static AVStream * init_stream(AVFormatContext *s)\n\n{\n\n    BinDemuxContext *bin = s->priv_data;\n\n    AVStream *st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return NULL;\n\n    st->codec->codec_tag   = 0;\n\n    st->codec->codec_type  = AVMEDIA_TYPE_VIDEO;\n\n\n\n    if (!bin->width) {\n\n        st->codec->width  = (80<<3);\n\n        st->codec->height = (25<<4);\n\n    }\n\n\n\n    avpriv_set_pts_info(st, 60, bin->framerate.den, bin->framerate.num);\n\n\n\n    /* simulate tty display speed */\n\n    bin->chars_per_frame = FFMAX(av_q2d(st->time_base) * bin->chars_per_frame, 1);\n\n\n\n    return st;\n\n}\n", "idx": 767, "_split": "test", "_hash": "563a1b45d6bb9e2d698dbd0014255e0e"}
{"project": "FFmpeg", "commit_id": "77d2a1ca595ebe082d35c4b624ac9a9145991494", "target": 1, "func": "ff_rm_parse_packet (AVFormatContext *s, AVIOContext *pb,\n\n                    AVStream *st, RMStream *ast, int len, AVPacket *pkt,\n\n                    int *seq, int flags, int64_t timestamp)\n\n{\n\n    RMDemuxContext *rm = s->priv_data;\n\n    int ret;\n\n\n\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n        rm->current_stream= st->id;\n\n        ret = rm_assemble_video_frame(s, pb, rm, ast, pkt, len, seq, &timestamp);\n\n        if(ret)\n\n            return ret < 0 ? ret : -1; //got partial frame or error\n\n    } else if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n        if ((ast->deint_id == DEINT_ID_GENR) ||\n\n            (ast->deint_id == DEINT_ID_INT4) ||\n\n            (ast->deint_id == DEINT_ID_SIPR)) {\n\n            int x;\n\n            int sps = ast->sub_packet_size;\n\n            int cfs = ast->coded_framesize;\n\n            int h = ast->sub_packet_h;\n\n            int y = ast->sub_packet_cnt;\n\n            int w = ast->audio_framesize;\n\n\n\n            if (flags & 2)\n\n                y = ast->sub_packet_cnt = 0;\n\n            if (!y)\n\n                ast->audiotimestamp = timestamp;\n\n\n\n            switch (ast->deint_id) {\n\n                case DEINT_ID_INT4:\n\n                    for (x = 0; x < h/2; x++)\n\n                        avio_read(pb, ast->pkt.data+x*2*w+y*cfs, cfs);\n\n                    break;\n\n                case DEINT_ID_GENR:\n\n                    for (x = 0; x < w/sps; x++)\n\n                        avio_read(pb, ast->pkt.data+sps*(h*x+((h+1)/2)*(y&1)+(y>>1)), sps);\n\n                    break;\n\n                case DEINT_ID_SIPR:\n\n                    avio_read(pb, ast->pkt.data + y * w, w);\n\n                    break;\n\n            }\n\n\n\n            if (++(ast->sub_packet_cnt) < h)\n\n                return -1;\n\n            if (ast->deint_id == DEINT_ID_SIPR)\n\n                ff_rm_reorder_sipr_data(ast->pkt.data, h, w);\n\n\n\n             ast->sub_packet_cnt = 0;\n\n             rm->audio_stream_num = st->index;\n\n             rm->audio_pkt_cnt = h * w / st->codec->block_align;\n\n        } else if ((ast->deint_id == DEINT_ID_VBRF) ||\n\n                   (ast->deint_id == DEINT_ID_VBRS)) {\n\n            int x;\n\n            rm->audio_stream_num = st->index;\n\n            ast->sub_packet_cnt = (avio_rb16(pb) & 0xf0) >> 4;\n\n            if (ast->sub_packet_cnt) {\n\n                for (x = 0; x < ast->sub_packet_cnt; x++)\n\n                    ast->sub_packet_lengths[x] = avio_rb16(pb);\n\n                rm->audio_pkt_cnt = ast->sub_packet_cnt;\n\n                ast->audiotimestamp = timestamp;\n\n            } else\n\n                return -1;\n\n        } else {\n\n            av_get_packet(pb, pkt, len);\n\n            rm_ac3_swap_bytes(st, pkt);\n\n        }\n\n    } else\n\n        av_get_packet(pb, pkt, len);\n\n\n\n    pkt->stream_index = st->index;\n\n\n\n#if 0\n\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n        if(st->codec->codec_id == AV_CODEC_ID_RV20){\n\n            int seq= 128*(pkt->data[2]&0x7F) + (pkt->data[3]>>1);\n\n            av_log(s, AV_LOG_DEBUG, \"%d %\"PRId64\" %d\\n\", *timestamp, *timestamp*512LL/25, seq);\n\n\n\n            seq |= (timestamp&~0x3FFF);\n\n            if(seq - timestamp >  0x2000) seq -= 0x4000;\n\n            if(seq - timestamp < -0x2000) seq += 0x4000;\n\n        }\n\n    }\n\n#endif\n\n\n\n    pkt->pts = timestamp;\n\n    if (flags & 2)\n\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\n\n\n    return st->codec->codec_type == AVMEDIA_TYPE_AUDIO ? rm->audio_pkt_cnt : 0;\n\n}\n", "idx": 944, "_split": "test", "_hash": "e892284afc797cecb3929bd2cfa22662"}
{"project": "FFmpeg", "commit_id": "af7d13ee4a4bf8d708f9b0598abb8f6e22b76de1", "target": 1, "func": "static int null_filter_samples(AVFilterLink *link, AVFilterBufferRef *samplesref)\n\n{\n\n\n    return 0;\n\n}", "idx": 1035, "_split": "test", "_hash": "67a905e6b175c5f4752448e70c9c8bbf"}
{"project": "FFmpeg", "commit_id": "5d97d9d53ea1cc2c28411ad734565372ddeccc32", "target": 1, "func": "static int check_checksum(ByteIOContext *bc){\n\n    unsigned long checksum= get_checksum(bc);\n\n//    return checksum != get_be32(bc);\n\n\n\n    av_log(NULL, AV_LOG_ERROR, \"%08X %08X\\n\", checksum, (int)get_be32(bc));\n\n\n\n    return 0;\n\n}\n", "idx": 1059, "_split": "test", "_hash": "8c70a1feecf05dfe53d8856c497128c2"}
{"project": "FFmpeg", "commit_id": "95801b6a0727d6f7e6f1204ce812b1e81613307d", "target": 1, "func": "static int alac_decode_frame(AVCodecContext *avctx,\n\n                             void *outbuffer, int *outputsize,\n\n                             const uint8_t *inbuffer, int input_buffer_size)\n\n{\n\n    ALACContext *alac = avctx->priv_data;\n\n\n\n    int channels;\n\n    unsigned int outputsamples;\n\n    int hassize;\n\n    int readsamplesize;\n\n    int wasted_bytes;\n\n    int isnotcompressed;\n\n    uint8_t interlacing_shift;\n\n    uint8_t interlacing_leftweight;\n\n\n\n    /* short-circuit null buffers */\n\n    if (!inbuffer || !input_buffer_size)\n\n        return input_buffer_size;\n\n\n\n    /* initialize from the extradata */\n\n    if (!alac->context_initialized) {\n\n        if (alac->avctx->extradata_size != ALAC_EXTRADATA_SIZE) {\n\n            av_log(avctx, AV_LOG_ERROR, \"alac: expected %d extradata bytes\\n\",\n\n                ALAC_EXTRADATA_SIZE);\n\n            return input_buffer_size;\n\n        }\n\n        if (alac_set_info(alac)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"alac: set_info failed\\n\");\n\n            return input_buffer_size;\n\n        }\n\n        alac->context_initialized = 1;\n\n    }\n\n\n\n    init_get_bits(&alac->gb, inbuffer, input_buffer_size * 8);\n\n\n\n    channels = get_bits(&alac->gb, 3) + 1;\n\n    if (channels > MAX_CHANNELS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"channels > %d not supported\\n\",\n\n               MAX_CHANNELS);\n\n        return input_buffer_size;\n\n    }\n\n\n\n    /* 2^result = something to do with output waiting.\n\n     * perhaps matters if we read > 1 frame in a pass?\n\n     */\n\n    skip_bits(&alac->gb, 4);\n\n\n\n    skip_bits(&alac->gb, 12); /* unknown, skip 12 bits */\n\n\n\n    /* the output sample size is stored soon */\n\n    hassize = get_bits1(&alac->gb);\n\n\n\n    wasted_bytes = get_bits(&alac->gb, 2); /* unknown ? */\n\n\n\n    /* whether the frame is compressed */\n\n    isnotcompressed = get_bits1(&alac->gb);\n\n\n\n    if (hassize) {\n\n        /* now read the number of samples as a 32bit integer */\n\n        outputsamples = get_bits_long(&alac->gb, 32);\n\n        if(outputsamples > alac->setinfo_max_samples_per_frame){\n\n            av_log(avctx, AV_LOG_ERROR, \"outputsamples %d > %d\\n\", outputsamples, alac->setinfo_max_samples_per_frame);\n\n            return -1;\n\n        }\n\n    } else\n\n        outputsamples = alac->setinfo_max_samples_per_frame;\n\n\n\n    if(outputsamples > *outputsize / alac->bytespersample){\n\n        av_log(avctx, AV_LOG_ERROR, \"sample buffer too small\\n\");\n\n        return -1;\n\n    }\n\n\n\n    *outputsize = outputsamples * alac->bytespersample;\n\n    readsamplesize = alac->setinfo_sample_size - (wasted_bytes * 8) + channels - 1;\n\n\n\n    if (!isnotcompressed) {\n\n        /* so it is compressed */\n\n        int16_t predictor_coef_table[channels][32];\n\n        int predictor_coef_num[channels];\n\n        int prediction_type[channels];\n\n        int prediction_quantitization[channels];\n\n        int ricemodifier[channels];\n\n        int i, chan;\n\n\n\n        interlacing_shift = get_bits(&alac->gb, 8);\n\n        interlacing_leftweight = get_bits(&alac->gb, 8);\n\n\n\n        for (chan = 0; chan < channels; chan++) {\n\n            prediction_type[chan] = get_bits(&alac->gb, 4);\n\n            prediction_quantitization[chan] = get_bits(&alac->gb, 4);\n\n\n\n            ricemodifier[chan] = get_bits(&alac->gb, 3);\n\n            predictor_coef_num[chan] = get_bits(&alac->gb, 5);\n\n\n\n            /* read the predictor table */\n\n            for (i = 0; i < predictor_coef_num[chan]; i++)\n\n                predictor_coef_table[chan][i] = (int16_t)get_bits(&alac->gb, 16);\n\n        }\n\n\n\n        if (wasted_bytes)\n\n            av_log(avctx, AV_LOG_ERROR, \"FIXME: unimplemented, unhandling of wasted_bytes\\n\");\n\n\n\n        for (chan = 0; chan < channels; chan++) {\n\n            bastardized_rice_decompress(alac,\n\n                                        alac->predicterror_buffer[chan],\n\n                                        outputsamples,\n\n                                        readsamplesize,\n\n                                        alac->setinfo_rice_initialhistory,\n\n                                        alac->setinfo_rice_kmodifier,\n\n                                        ricemodifier[chan] * alac->setinfo_rice_historymult / 4,\n\n                                        (1 << alac->setinfo_rice_kmodifier) - 1);\n\n\n\n            if (prediction_type[chan] == 0) {\n\n                /* adaptive fir */\n\n                predictor_decompress_fir_adapt(alac->predicterror_buffer[chan],\n\n                                               alac->outputsamples_buffer[chan],\n\n                                               outputsamples,\n\n                                               readsamplesize,\n\n                                               predictor_coef_table[chan],\n\n                                               predictor_coef_num[chan],\n\n                                               prediction_quantitization[chan]);\n\n            } else {\n\n                av_log(avctx, AV_LOG_ERROR, \"FIXME: unhandled prediction type: %i\\n\", prediction_type[chan]);\n\n                /* I think the only other prediction type (or perhaps this is\n\n                 * just a boolean?) runs adaptive fir twice.. like:\n\n                 * predictor_decompress_fir_adapt(predictor_error, tempout, ...)\n\n                 * predictor_decompress_fir_adapt(predictor_error, outputsamples ...)\n\n                 * little strange..\n\n                 */\n\n            }\n\n        }\n\n    } else {\n\n        /* not compressed, easy case */\n\n        int i, chan;\n\n        for (i = 0; i < outputsamples; i++)\n\n            for (chan = 0; chan < channels; chan++) {\n\n                int32_t audiobits;\n\n\n\n                audiobits = get_bits_long(&alac->gb, alac->setinfo_sample_size);\n\n                audiobits = extend_sign32(audiobits, alac->setinfo_sample_size);\n\n\n\n                alac->outputsamples_buffer[chan][i] = audiobits;\n\n            }\n\n        /* wasted_bytes = 0; */\n\n        interlacing_shift = 0;\n\n        interlacing_leftweight = 0;\n\n    }\n\n    if (get_bits(&alac->gb, 3) != 7)\n\n        av_log(avctx, AV_LOG_ERROR, \"Error : Wrong End Of Frame\\n\");\n\n\n\n    switch(alac->setinfo_sample_size) {\n\n    case 16:\n\n        if (channels == 2) {\n\n            reconstruct_stereo_16(alac->outputsamples_buffer,\n\n                                  (int16_t*)outbuffer,\n\n                                  alac->numchannels,\n\n                                  outputsamples,\n\n                                  interlacing_shift,\n\n                                  interlacing_leftweight);\n\n        } else {\n\n            int i;\n\n            for (i = 0; i < outputsamples; i++) {\n\n                int16_t sample = alac->outputsamples_buffer[0][i];\n\n                ((int16_t*)outbuffer)[i * alac->numchannels] = sample;\n\n            }\n\n        }\n\n        break;\n\n    case 20:\n\n    case 24:\n\n        // It is not clear if there exist any encoder that creates 24 bit ALAC\n\n        // files. iTunes convert 24 bit raw files to 16 bit before encoding.\n\n    case 32:\n\n        av_log(avctx, AV_LOG_ERROR, \"FIXME: unimplemented sample size %i\\n\", alac->setinfo_sample_size);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n\n\n    if (input_buffer_size * 8 - get_bits_count(&alac->gb) > 8)\n\n        av_log(avctx, AV_LOG_ERROR, \"Error : %d bits left\\n\", input_buffer_size * 8 - get_bits_count(&alac->gb));\n\n\n\n    return input_buffer_size;\n\n}\n", "idx": 1137, "_split": "test", "_hash": "084254b08913955688c79f81665aac80"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int getopt(int argc, char *argv[], char *opts)\n\n{\n\n    static int sp = 1;\n\n    int c;\n\n    char *cp;\n\n\n\n    if (sp == 1)\n\n        if (optind >= argc ||\n\n            argv[optind][0] != '-' || argv[optind][1] == '\\0')\n\n            return EOF;\n\n        else if (!strcmp(argv[optind], \"--\")) {\n\n            optind++;\n\n            return EOF;\n\n        }\n\n    optopt = c = argv[optind][sp];\n\n    if (c == ':' || (cp = strchr(opts, c)) == NULL) {\n\n        fprintf(stderr, \": illegal option -- %c\\n\", c);\n\n        if (argv[optind][++sp] == '\\0') {\n\n            optind++;\n\n            sp = 1;\n\n        }\n\n        return '?';\n\n    }\n\n    if (*++cp == ':') {\n\n        if (argv[optind][sp+1] != '\\0')\n\n            optarg = &argv[optind++][sp+1];\n\n        else if(++optind >= argc) {\n\n            fprintf(stderr, \": option requires an argument -- %c\\n\", c);\n\n            sp = 1;\n\n            return '?';\n\n        } else\n\n            optarg = argv[optind++];\n\n        sp = 1;\n\n    } else {\n\n        if (argv[optind][++sp] == '\\0') {\n\n            sp = 1;\n\n            optind++;\n\n        }\n\n        optarg = NULL;\n\n    }\n\n\n\n    return c;\n\n}\n", "idx": 1145, "_split": "test", "_hash": "1d451111369a4d6743b4d22b23b48ca0"}
{"project": "FFmpeg", "commit_id": "04dcdc464087eece349f30db42bab903cd077778", "target": 1, "func": "FFTContext *av_fft_init(int nbits, int inverse)\n\n{\n\n    FFTContext *s = av_malloc(sizeof(*s));\n\n\n\n    if (s && ff_fft_init(s, nbits, inverse))\n\n        av_freep(&s);\n\n\n\n    return s;\n\n}\n", "idx": 1307, "_split": "test", "_hash": "2024391496fff5d69c3e968e86f7af44"}
{"project": "FFmpeg", "commit_id": "89325417e7b33f4b08171d9d609c48662d96b2d3", "target": 1, "func": "static int get_siz(Jpeg2000DecoderContext *s)\n{\n    int i;\n    int ncomponents;\n    uint32_t log2_chroma_wh = 0;\n    const enum AVPixelFormat *possible_fmts = NULL;\n    int possible_fmts_nb = 0;\n    if (bytestream2_get_bytes_left(&s->g) < 36) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Insufficient space for SIZ\\n\");\n    s->avctx->profile = bytestream2_get_be16u(&s->g); // Rsiz\n    s->width          = bytestream2_get_be32u(&s->g); // Width\n    s->height         = bytestream2_get_be32u(&s->g); // Height\n    s->image_offset_x = bytestream2_get_be32u(&s->g); // X0Siz\n    s->image_offset_y = bytestream2_get_be32u(&s->g); // Y0Siz\n    s->tile_width     = bytestream2_get_be32u(&s->g); // XTSiz\n    s->tile_height    = bytestream2_get_be32u(&s->g); // YTSiz\n    s->tile_offset_x  = bytestream2_get_be32u(&s->g); // XT0Siz\n    s->tile_offset_y  = bytestream2_get_be32u(&s->g); // YT0Siz\n    ncomponents       = bytestream2_get_be16u(&s->g); // CSiz\n    if (s->image_offset_x || s->image_offset_y) {\n        avpriv_request_sample(s->avctx, \"Support for image offsets\");\n        return AVERROR_PATCHWELCOME;\n    if (av_image_check_size(s->width, s->height, 0, s->avctx)) {\n        avpriv_request_sample(s->avctx, \"Large Dimensions\");\n        return AVERROR_PATCHWELCOME;\n    if (ncomponents <= 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid number of components: %d\\n\",\n    if (ncomponents > 4) {\n        avpriv_request_sample(s->avctx, \"Support for %d components\",\n                              ncomponents);\n        return AVERROR_PATCHWELCOME;\n    s->ncomponents = ncomponents;\n    if (s->tile_width <= 0 || s->tile_height <= 0) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid tile dimension %dx%d.\\n\",\n               s->tile_width, s->tile_height);\n    if (bytestream2_get_bytes_left(&s->g) < 3 * s->ncomponents) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Insufficient space for %d components in SIZ\\n\", s->ncomponents);\n    for (i = 0; i < s->ncomponents; i++) { // Ssiz_i XRsiz_i, YRsiz_i\n        uint8_t x    = bytestream2_get_byteu(&s->g);\n        s->cbps[i]   = (x & 0x7f) + 1;\n        s->precision = FFMAX(s->cbps[i], s->precision);\n        s->sgnd[i]   = !!(x & 0x80);\n        s->cdx[i]    = bytestream2_get_byteu(&s->g);\n        s->cdy[i]    = bytestream2_get_byteu(&s->g);\n        if (   !s->cdx[i] || s->cdx[i] == 3 || s->cdx[i] > 4\n            || !s->cdy[i] || s->cdy[i] == 3 || s->cdy[i] > 4) {\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid sample separation %d/%d\\n\", s->cdx[i], s->cdy[i]);\n        log2_chroma_wh |= s->cdy[i] >> 1 << i * 4 | s->cdx[i] >> 1 << i * 4 + 2;\n    s->numXtiles = ff_jpeg2000_ceildiv(s->width  - s->tile_offset_x, s->tile_width);\n    s->numYtiles = ff_jpeg2000_ceildiv(s->height - s->tile_offset_y, s->tile_height);\n    if (s->numXtiles * (uint64_t)s->numYtiles > INT_MAX/sizeof(*s->tile)) {\n        s->numXtiles = s->numYtiles = 0;\n        return AVERROR(EINVAL);\n    s->tile = av_mallocz_array(s->numXtiles * s->numYtiles, sizeof(*s->tile));\n    if (!s->tile) {\n        s->numXtiles = s->numYtiles = 0;\n        return AVERROR(ENOMEM);\n    for (i = 0; i < s->numXtiles * s->numYtiles; i++) {\n        Jpeg2000Tile *tile = s->tile + i;\n        tile->comp = av_mallocz(s->ncomponents * sizeof(*tile->comp));\n        if (!tile->comp)\n            return AVERROR(ENOMEM);\n    /* compute image size with reduction factor */\n    s->avctx->width  = ff_jpeg2000_ceildivpow2(s->width  - s->image_offset_x,\n                                               s->reduction_factor);\n    s->avctx->height = ff_jpeg2000_ceildivpow2(s->height - s->image_offset_y,\n                                               s->reduction_factor);\n    if (s->avctx->profile == FF_PROFILE_JPEG2000_DCINEMA_2K ||\n        s->avctx->profile == FF_PROFILE_JPEG2000_DCINEMA_4K) {\n        possible_fmts = xyz_pix_fmts;\n        possible_fmts_nb = FF_ARRAY_ELEMS(xyz_pix_fmts);\n    } else {\n        switch (s->colour_space) {\n        case 16:\n            possible_fmts = rgb_pix_fmts;\n            possible_fmts_nb = FF_ARRAY_ELEMS(rgb_pix_fmts);\n            break;\n        case 17:\n            possible_fmts = gray_pix_fmts;\n            possible_fmts_nb = FF_ARRAY_ELEMS(gray_pix_fmts);\n            break;\n        case 18:\n            possible_fmts = yuv_pix_fmts;\n            possible_fmts_nb = FF_ARRAY_ELEMS(yuv_pix_fmts);\n            break;\n        default:\n            possible_fmts = all_pix_fmts;\n            possible_fmts_nb = FF_ARRAY_ELEMS(all_pix_fmts);\n            break;\n    for (i = 0; i < possible_fmts_nb; ++i) {\n        if (pix_fmt_match(possible_fmts[i], ncomponents, s->precision, log2_chroma_wh, s->pal8)) {\n            s->avctx->pix_fmt = possible_fmts[i];\n            break;\n    if (i == possible_fmts_nb) {\n        if (ncomponents == 4 &&\n            s->cdy[0] == 1 && s->cdx[0] == 1 &&\n            s->cdy[1] == 1 && s->cdx[1] == 1 &&\n            s->cdy[2] == s->cdy[3] && s->cdx[2] == s->cdx[3]) {\n            if (s->precision == 8 && s->cdy[2] == 2 && s->cdx[2] == 2 && !s->pal8) {\n                s->avctx->pix_fmt = AV_PIX_FMT_YUVA420P;\n                s->cdef[0] = 0;\n                s->cdef[1] = 1;\n                s->cdef[2] = 2;\n                s->cdef[3] = 3;\n                i = 0;\n    if (i == possible_fmts_nb) {\n        av_log(s->avctx, AV_LOG_ERROR,\n               \"Unknown pix_fmt, profile: %d, colour_space: %d, \"\n               \"components: %d, precision: %d\\n\"\n               \"cdx[0]: %d, cdy[0]: %d\\n\"\n               \"cdx[1]: %d, cdy[1]: %d\\n\"\n               \"cdx[2]: %d, cdy[2]: %d\\n\"\n               \"cdx[3]: %d, cdy[3]: %d\\n\",\n               s->avctx->profile, s->colour_space, ncomponents, s->precision,\n               s->cdx[0],\n               s->cdy[0],\n               ncomponents > 1 ? s->cdx[1] : 0,\n               ncomponents > 1 ? s->cdy[1] : 0,\n               ncomponents > 2 ? s->cdx[2] : 0,\n               ncomponents > 2 ? s->cdy[2] : 0,\n               ncomponents > 3 ? s->cdx[3] : 0,\n               ncomponents > 3 ? s->cdy[3] : 0);\n        return AVERROR_PATCHWELCOME;\n    s->avctx->bits_per_raw_sample = s->precision;\n    return 0;", "idx": 1318, "_split": "test", "_hash": "fdbad151f17ef26baf803cd9e0d0285b"}
{"project": "FFmpeg", "commit_id": "1c495b0bf690995c45f79f4f19500921e14ec78a", "target": 1, "func": "static void sd_1d97_int(int *p, int i0, int i1)\n\n{\n\n    int i;\n\n\n\n    if (i1 <= i0 + 1) {\n\n        if (i0 == 1)\n\n            p[1] = (p[1] * I_LFTG_X + (1<<15)) >> 16;\n\n        else\n\n            p[0] = (p[0] * I_LFTG_K + (1<<15)) >> 16;\n\n        return;\n\n    }\n\n\n\n    extend97_int(p, i0, i1);\n\n    i0++; i1++;\n\n\n\n    for (i = i0/2 - 2; i < i1/2 + 1; i++)\n\n        p[2 * i + 1] -= (I_LFTG_ALPHA * (p[2 * i]     + p[2 * i + 2]) + (1 << 15)) >> 16;\n\n    for (i = i0/2 - 1; i < i1/2 + 1; i++)\n\n        p[2 * i]     -= (I_LFTG_BETA  * (p[2 * i - 1] + p[2 * i + 1]) + (1 << 15)) >> 16;\n\n    for (i = i0/2 - 1; i < i1/2; i++)\n\n        p[2 * i + 1] += (I_LFTG_GAMMA * (p[2 * i]     + p[2 * i + 2]) + (1 << 15)) >> 16;\n\n    for (i = i0/2; i < i1/2; i++)\n\n        p[2 * i]     += (I_LFTG_DELTA * (p[2 * i - 1] + p[2 * i + 1]) + (1 << 15)) >> 16;\n\n}\n", "idx": 1338, "_split": "test", "_hash": "6eb7f8fc52dfe29f4aeef1840745a4c9"}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(rgb32ToY)(uint8_t *dst, uint8_t *src, int width)\n\n{\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tint r=  ((uint32_t*)src)[i]&0xFF;\n\n\t\tint g= (((uint32_t*)src)[i]>>8)&0xFF;\n\n\t\tint b= (((uint32_t*)src)[i]>>16)&0xFF;\n\n\n\n\t\tdst[i]= ((RY*r + GY*g + BY*b + (33<<(RGB2YUV_SHIFT-1)) )>>RGB2YUV_SHIFT);\n\n\t}\n\n}\n", "idx": 1341, "_split": "test", "_hash": "e2cedb70d5e4b8a27161e9ad5cf5b237"}
{"project": "FFmpeg", "commit_id": "49c8132b17ec26666d71ee94a50f421b84feeb35", "target": 1, "func": "static int ipmovie_read_packet(AVFormatContext *s,\n\n                               AVPacket *pkt)\n\n{\n\n    IPMVEContext *ipmovie = (IPMVEContext *)s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    int ret;\n\n\n\n    ret = process_ipmovie_chunk(ipmovie, pb, pkt);\n\n    if (ret == CHUNK_BAD)\n\n        ret = AVERROR_INVALIDDATA;\n\n    else if (ret == CHUNK_EOF)\n\n        ret = AVERROR_IO;\n\n    else if (ret == CHUNK_NOMEM)\n\n        ret = AVERROR_NOMEM;\n\n    else\n\n        ret = 0;\n\n\n\n    return ret;\n\n}\n", "idx": 1373, "_split": "test", "_hash": "81a2546ac588b4194d762dbe0d4ca6d6"}
{"project": "FFmpeg", "commit_id": "46e3883519b7592e946258c68d072abd89e583c8", "target": 1, "func": "static int opus_decode_frame(OpusStreamContext *s, const uint8_t *data, int size)\n\n{\n\n    int samples    = s->packet.frame_duration;\n\n    int redundancy = 0;\n\n    int redundancy_size, redundancy_pos;\n\n    int ret, i, consumed;\n\n    int delayed_samples = s->delayed_samples;\n\n\n\n    ret = opus_rc_init(&s->rc, data, size);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* decode the silk frame */\n\n    if (s->packet.mode == OPUS_MODE_SILK || s->packet.mode == OPUS_MODE_HYBRID) {\n\n        if (!swr_is_initialized(s->swr)) {\n\n            ret = opus_init_resample(s);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n\n\n        samples = ff_silk_decode_superframe(s->silk, &s->rc, s->silk_output,\n\n                                            FFMIN(s->packet.bandwidth, OPUS_BANDWIDTH_WIDEBAND),\n\n                                            s->packet.stereo + 1,\n\n                                            silk_frame_duration_ms[s->packet.config]);\n\n        if (samples < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error decoding a SILK frame.\\n\");\n\n            return samples;\n\n        }\n\n        samples = swr_convert(s->swr,\n\n                              (uint8_t**)s->out, s->packet.frame_duration,\n\n                              (const uint8_t**)s->silk_output, samples);\n\n        if (samples < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Error resampling SILK data.\\n\");\n\n            return samples;\n\n        }\n\n\n        s->delayed_samples += s->packet.frame_duration - samples;\n\n    } else\n\n        ff_silk_flush(s->silk);\n\n\n\n    // decode redundancy information\n\n    consumed = opus_rc_tell(&s->rc);\n\n    if (s->packet.mode == OPUS_MODE_HYBRID && consumed + 37 <= size * 8)\n\n        redundancy = opus_rc_p2model(&s->rc, 12);\n\n    else if (s->packet.mode == OPUS_MODE_SILK && consumed + 17 <= size * 8)\n\n        redundancy = 1;\n\n\n\n    if (redundancy) {\n\n        redundancy_pos = opus_rc_p2model(&s->rc, 1);\n\n\n\n        if (s->packet.mode == OPUS_MODE_HYBRID)\n\n            redundancy_size = opus_rc_unimodel(&s->rc, 256) + 2;\n\n        else\n\n            redundancy_size = size - (consumed + 7) / 8;\n\n        size -= redundancy_size;\n\n        if (size < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Invalid redundancy frame size.\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (redundancy_pos) {\n\n            ret = opus_decode_redundancy(s, data + size, redundancy_size);\n\n            if (ret < 0)\n\n                return ret;\n\n            ff_celt_flush(s->celt);\n\n        }\n\n    }\n\n\n\n    /* decode the CELT frame */\n\n    if (s->packet.mode == OPUS_MODE_CELT || s->packet.mode == OPUS_MODE_HYBRID) {\n\n        float *out_tmp[2] = { s->out[0], s->out[1] };\n\n        float **dst = (s->packet.mode == OPUS_MODE_CELT) ?\n\n                      out_tmp : s->celt_output;\n\n        int celt_output_samples = samples;\n\n        int delay_samples = av_audio_fifo_size(s->celt_delay);\n\n\n\n        if (delay_samples) {\n\n            if (s->packet.mode == OPUS_MODE_HYBRID) {\n\n                av_audio_fifo_read(s->celt_delay, (void**)s->celt_output, delay_samples);\n\n\n\n                for (i = 0; i < s->output_channels; i++) {\n\n                    s->fdsp->vector_fmac_scalar(out_tmp[i], s->celt_output[i], 1.0,\n\n                                                delay_samples);\n\n                    out_tmp[i] += delay_samples;\n\n                }\n\n                celt_output_samples -= delay_samples;\n\n            } else {\n\n                av_log(s->avctx, AV_LOG_WARNING,\n\n                       \"Spurious CELT delay samples present.\\n\");\n\n                av_audio_fifo_drain(s->celt_delay, delay_samples);\n\n                if (s->avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return AVERROR_BUG;\n\n            }\n\n        }\n\n\n\n        opus_raw_init(&s->rc, data + size, size);\n\n\n\n        ret = ff_celt_decode_frame(s->celt, &s->rc, dst,\n\n                                   s->packet.stereo + 1,\n\n                                   s->packet.frame_duration,\n\n                                   (s->packet.mode == OPUS_MODE_HYBRID) ? 17 : 0,\n\n                                   celt_band_end[s->packet.bandwidth]);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        if (s->packet.mode == OPUS_MODE_HYBRID) {\n\n            int celt_delay = s->packet.frame_duration - celt_output_samples;\n\n            void *delaybuf[2] = { s->celt_output[0] + celt_output_samples,\n\n                                  s->celt_output[1] + celt_output_samples };\n\n\n\n            for (i = 0; i < s->output_channels; i++) {\n\n                s->fdsp->vector_fmac_scalar(out_tmp[i],\n\n                                            s->celt_output[i], 1.0,\n\n                                            celt_output_samples);\n\n            }\n\n\n\n            ret = av_audio_fifo_write(s->celt_delay, delaybuf, celt_delay);\n\n            if (ret < 0)\n\n                return ret;\n\n        }\n\n    } else\n\n        ff_celt_flush(s->celt);\n\n\n\n    if (s->redundancy_idx) {\n\n        for (i = 0; i < s->output_channels; i++)\n\n            opus_fade(s->out[i], s->out[i],\n\n                      s->redundancy_output[i] + 120 + s->redundancy_idx,\n\n                      ff_celt_window2 + s->redundancy_idx, 120 - s->redundancy_idx);\n\n        s->redundancy_idx = 0;\n\n    }\n\n    if (redundancy) {\n\n        if (!redundancy_pos) {\n\n            ff_celt_flush(s->celt);\n\n            ret = opus_decode_redundancy(s, data + size, redundancy_size);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            for (i = 0; i < s->output_channels; i++) {\n\n                opus_fade(s->out[i] + samples - 120 + delayed_samples,\n\n                          s->out[i] + samples - 120 + delayed_samples,\n\n                          s->redundancy_output[i] + 120,\n\n                          ff_celt_window2, 120 - delayed_samples);\n\n                if (delayed_samples)\n\n                    s->redundancy_idx = 120 - delayed_samples;\n\n            }\n\n        } else {\n\n            for (i = 0; i < s->output_channels; i++) {\n\n                memcpy(s->out[i] + delayed_samples, s->redundancy_output[i], 120 * sizeof(float));\n\n                opus_fade(s->out[i] + 120 + delayed_samples,\n\n                          s->redundancy_output[i] + 120,\n\n                          s->out[i] + 120 + delayed_samples,\n\n                          ff_celt_window2, 120);\n\n            }\n\n        }\n\n    }\n\n\n\n    return samples;\n\n}", "idx": 1377, "_split": "test", "_hash": "25b973e95cab0d5643f5f19657cce1cb"}
{"project": "FFmpeg", "commit_id": "a28cccf6d62dc770757491510c248ed632a836ce", "target": 1, "func": "static int decodeChannelSoundUnit (ATRAC3Context *q, GetBitContext *gb, channel_unit *pSnd, float *pOut, int channelNum, int codingMode)\n\n{\n\n    int   band, result=0, numSubbands, lastTonal, numBands;\n\n\n\n    if (codingMode == JOINT_STEREO && channelNum == 1) {\n\n        if (get_bits(gb,2) != 3) {\n\n            av_log(NULL,AV_LOG_ERROR,\"JS mono Sound Unit id != 3.\\n\");\n\n            return -1;\n\n        }\n\n    } else {\n\n        if (get_bits(gb,6) != 0x28) {\n\n            av_log(NULL,AV_LOG_ERROR,\"Sound Unit id != 0x28.\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    /* number of coded QMF bands */\n\n    pSnd->bandsCoded = get_bits(gb,2);\n\n\n\n    result = decodeGainControl (gb, &(pSnd->gainBlock[pSnd->gcBlkSwitch]), pSnd->bandsCoded);\n\n    if (result) return result;\n\n\n\n    pSnd->numComponents = decodeTonalComponents (gb, pSnd->components, pSnd->bandsCoded);\n\n    if (pSnd->numComponents == -1) return -1;\n\n\n\n    numSubbands = decodeSpectrum (gb, pSnd->spectrum);\n\n\n\n    /* Merge the decoded spectrum and tonal components. */\n\n    lastTonal = addTonalComponents (pSnd->spectrum, pSnd->numComponents, pSnd->components);\n\n\n\n\n\n    /* calculate number of used MLT/QMF bands according to the amount of coded spectral lines */\n\n    numBands = (subbandTab[numSubbands] - 1) >> 8;\n\n    if (lastTonal >= 0)\n\n        numBands = FFMAX((lastTonal + 256) >> 8, numBands);\n\n\n\n\n\n    /* Reconstruct time domain samples. */\n\n    for (band=0; band<4; band++) {\n\n        /* Perform the IMDCT step without overlapping. */\n\n        if (band <= numBands) {\n\n            IMLT(&(pSnd->spectrum[band*256]), pSnd->IMDCT_buf, band&1);\n\n        } else\n\n            memset(pSnd->IMDCT_buf, 0, 512 * sizeof(float));\n\n\n\n        /* gain compensation and overlapping */\n\n        gainCompensateAndOverlap (pSnd->IMDCT_buf, &(pSnd->prevFrame[band*256]), &(pOut[band*256]),\n\n                                    &((pSnd->gainBlock[1 - (pSnd->gcBlkSwitch)]).gBlock[band]),\n\n                                    &((pSnd->gainBlock[pSnd->gcBlkSwitch]).gBlock[band]));\n\n    }\n\n\n\n    /* Swap the gain control buffers for the next frame. */\n\n    pSnd->gcBlkSwitch ^= 1;\n\n\n\n    return 0;\n\n}\n", "idx": 1404, "_split": "test", "_hash": "7ab87034e6c5f5d135fc9483b64ba26e"}
{"project": "FFmpeg", "commit_id": "b8664c929437d6d079e16979c496a2db40cf2324", "target": 0, "func": "static void vp8_idct_dc_add4uv_c(uint8_t *dst, int16_t block[4][16], ptrdiff_t stride)\n\n{\n\n    vp8_idct_dc_add_c(dst+stride*0+0, block[0], stride);\n\n    vp8_idct_dc_add_c(dst+stride*0+4, block[1], stride);\n\n    vp8_idct_dc_add_c(dst+stride*4+0, block[2], stride);\n\n    vp8_idct_dc_add_c(dst+stride*4+4, block[3], stride);\n\n}\n", "idx": 1426, "_split": "test", "_hash": "55753ff319f3806dbebedc3ca83c87ea"}
{"project": "FFmpeg", "commit_id": "16c429166ddf1736972b6ccce84bd3509ec16a34", "target": 1, "func": "static av_cold int png_dec_end(AVCodecContext *avctx)\n\n{\n\n    PNGDecContext *s = avctx->priv_data;\n\n\n\n    ff_thread_release_buffer(avctx, &s->previous_picture);\n\n    av_frame_free(&s->previous_picture.f);\n\n    ff_thread_release_buffer(avctx, &s->last_picture);\n\n    av_frame_free(&s->last_picture.f);\n\n    ff_thread_release_buffer(avctx, &s->picture);\n\n    av_frame_free(&s->picture.f);\n\n    av_freep(&s->buffer);\n\n    s->buffer_size = 0;\n\n    av_freep(&s->last_row);\n\n    s->last_row_size = 0;\n\n    av_freep(&s->tmp_row);\n\n    s->tmp_row_size = 0;\n\n    av_freep(&s->extra_data);\n\n    s->extra_data_size = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 1439, "_split": "test", "_hash": "8e9253657bd71d04d1c587f47c2476c4"}
{"project": "FFmpeg", "commit_id": "73a60633143b7c51333a0772b45a47282ac445b6", "target": 1, "func": "static int probe_file(WriterContext *wctx, const char *filename)\n\n{\n\n    AVFormatContext *fmt_ctx;\n\n    int ret, i;\n\n    int section_id;\n\n\n\n    do_read_frames = do_show_frames || do_count_frames;\n\n    do_read_packets = do_show_packets || do_count_packets;\n\n\n\n    ret = open_input_file(&fmt_ctx, filename);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n#define CHECK_END if (ret < 0) goto end\n\n\n\n    nb_streams_frames  = av_calloc(fmt_ctx->nb_streams, sizeof(*nb_streams_frames));\n\n    nb_streams_packets = av_calloc(fmt_ctx->nb_streams, sizeof(*nb_streams_packets));\n\n    selected_streams   = av_calloc(fmt_ctx->nb_streams, sizeof(*selected_streams));\n\n\n\n    for (i = 0; i < fmt_ctx->nb_streams; i++) {\n\n        if (stream_specifier) {\n\n            ret = avformat_match_stream_specifier(fmt_ctx,\n\n                                                  fmt_ctx->streams[i],\n\n                                                  stream_specifier);\n\n            CHECK_END;\n\n            else\n\n                selected_streams[i] = ret;\n\n            ret = 0;\n\n        } else {\n\n            selected_streams[i] = 1;\n\n        }\n\n    }\n\n\n\n    if (do_read_frames || do_read_packets) {\n\n        if (do_show_frames && do_show_packets &&\n\n            wctx->writer->flags & WRITER_FLAG_PUT_PACKETS_AND_FRAMES_IN_SAME_CHAPTER)\n\n            section_id = SECTION_ID_PACKETS_AND_FRAMES;\n\n        else if (do_show_packets && !do_show_frames)\n\n            section_id = SECTION_ID_PACKETS;\n\n        else // (!do_show_packets && do_show_frames)\n\n            section_id = SECTION_ID_FRAMES;\n\n        if (do_show_frames || do_show_packets)\n\n            writer_print_section_header(wctx, section_id);\n\n        ret = read_packets(wctx, fmt_ctx);\n\n        if (do_show_frames || do_show_packets)\n\n            writer_print_section_footer(wctx);\n\n        CHECK_END;\n\n    }\n\n\n\n    if (do_show_programs) {\n\n        ret = show_programs(wctx, fmt_ctx);\n\n        CHECK_END;\n\n    }\n\n\n\n    if (do_show_streams) {\n\n        ret = show_streams(wctx, fmt_ctx);\n\n        CHECK_END;\n\n    }\n\n    if (do_show_chapters) {\n\n        ret = show_chapters(wctx, fmt_ctx);\n\n        CHECK_END;\n\n    }\n\n    if (do_show_format) {\n\n        ret = show_format(wctx, fmt_ctx);\n\n        CHECK_END;\n\n    }\n\n\n\nend:\n\n    close_input_file(&fmt_ctx);\n\n    av_freep(&nb_streams_frames);\n\n    av_freep(&nb_streams_packets);\n\n    av_freep(&selected_streams);\n\n\n\n    return ret;\n\n}\n", "idx": 1469, "_split": "test", "_hash": "97a4f89663d6d03446c1111fd63ca6da"}
{"project": "FFmpeg", "commit_id": "eb465b8c56d455fddf0f4f9f2625e2fe3ff7ea06", "target": 1, "func": "static void filter(USPPContext *p, uint8_t *dst[3], uint8_t *src[3],\n\n                   int dst_stride[3], int src_stride[3], int width,\n\n                   int height, uint8_t *qp_store, int qp_stride)\n\n{\n\n    int x, y, i, j;\n\n    const int count = 1<<p->log2_count;\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        int is_chroma = !!i;\n\n        int w = width  >> (is_chroma ? p->hsub : 0);\n\n        int h = height >> (is_chroma ? p->vsub : 0);\n\n        int stride = p->temp_stride[i];\n\n        int block = BLOCK >> (is_chroma ? p->hsub : 0);\n\n\n\n        if (!src[i] || !dst[i])\n\n            continue;\n\n        for (y = 0; y < h; y++) {\n\n            int index = block + block * stride + y * stride;\n\n\n\n            memcpy(p->src[i] + index, src[i] + y * src_stride[i], w );\n\n            for (x = 0; x < block; x++) {\n\n                p->src[i][index     - x - 1] = p->src[i][index +     x    ];\n\n                p->src[i][index + w + x    ] = p->src[i][index + w - x - 1];\n\n            }\n\n        }\n\n        for (y = 0; y < block; y++) {\n\n            memcpy(p->src[i] + (  block-1-y) * stride, p->src[i] + (  y+block  ) * stride, stride);\n\n            memcpy(p->src[i] + (h+block  +y) * stride, p->src[i] + (h-y+block-1) * stride, stride);\n\n        }\n\n\n\n        p->frame->linesize[i] = stride;\n\n        memset(p->temp[i], 0, (h + 2 * block) * stride * sizeof(int16_t));\n\n    }\n\n\n\n    if (p->qp)\n\n        p->frame->quality = p->qp * FF_QP2LAMBDA;\n\n    else {\n\n        int qpsum=0;\n\n        int qpcount = (height>>4) * (height>>4);\n\n\n\n        for (y = 0; y < (height>>4); y++) {\n\n            for (x = 0; x < (width>>4); x++)\n\n                qpsum += qp_store[x + y * qp_stride];\n\n        }\n\n        p->frame->quality = norm_qscale((qpsum + qpcount/2) / qpcount, p->qscale_type) * FF_QP2LAMBDA;\n\n    }\n\n//    init per MB qscale stuff FIXME\n\n    p->frame->height = height;\n\n    p->frame->width  = width;\n\n\n\n    for (i = 0; i < count; i++) {\n\n        const int x1 = offset[i+count-1][0];\n\n        const int y1 = offset[i+count-1][1];\n\n        const int x1c = x1 >> p->hsub;\n\n        const int y1c = y1 >> p->vsub;\n\n        const int BLOCKc = BLOCK >> p->hsub;\n\n        int offset;\n\n        AVPacket pkt;\n\n        int got_pkt_ptr;\n\n\n\n        av_init_packet(&pkt);\n\n        pkt.data = p->outbuf;\n\n        pkt.size = p->outbuf_size;\n\n\n\n        p->frame->data[0] = p->src[0] + x1   + y1   * p->frame->linesize[0];\n\n        p->frame->data[1] = p->src[1] + x1c  + y1c  * p->frame->linesize[1];\n\n        p->frame->data[2] = p->src[2] + x1c  + y1c  * p->frame->linesize[2];\n\n        p->frame->format  = p->avctx_enc[i]->pix_fmt;\n\n\n\n        avcodec_encode_video2(p->avctx_enc[i], &pkt, p->frame, &got_pkt_ptr);\n\n        p->frame_dec = p->avctx_enc[i]->coded_frame;\n\n\n\n        offset = (BLOCK-x1) + (BLOCK-y1) * p->frame_dec->linesize[0];\n\n\n\n        for (y = 0; y < height; y++)\n\n            for (x = 0; x < width; x++)\n\n                p->temp[0][x + y * p->temp_stride[0]] += p->frame_dec->data[0][x + y * p->frame_dec->linesize[0] + offset];\n\n\n\n        if (!src[2] || !dst[2])\n\n            continue;\n\n\n\n        offset = (BLOCKc-x1c) + (BLOCKc-y1c) * p->frame_dec->linesize[1];\n\n\n\n        for (y = 0; y < height>>p->vsub; y++) {\n\n            for (x = 0; x < width>>p->hsub; x++) {\n\n                p->temp[1][x + y * p->temp_stride[1]] += p->frame_dec->data[1][x + y * p->frame_dec->linesize[1] + offset];\n\n                p->temp[2][x + y * p->temp_stride[2]] += p->frame_dec->data[2][x + y * p->frame_dec->linesize[2] + offset];\n\n            }\n\n        }\n\n    }\n\n\n\n    for (j = 0; j < 3; j++) {\n\n        int is_chroma = !!j;\n\n        if (!dst[j])\n\n            continue;\n\n        store_slice_c(dst[j], p->temp[j], dst_stride[j], p->temp_stride[j],\n\n                      width  >> (is_chroma ? p->hsub : 0),\n\n                      height >> (is_chroma ? p->vsub : 0),\n\n                      8-p->log2_count);\n\n    }\n\n}\n", "idx": 1476, "_split": "test", "_hash": "d1061d05407925e04d4d65de56d82f44"}
{"project": "FFmpeg", "commit_id": "90540c2d5ace46a1e9789c75fde0b1f7dbb12a9b", "target": 1, "func": "static inline void RENAME(rgb15tobgr24)(const uint8_t *src, uint8_t *dst, int src_size)\n\n{\n\n    const uint16_t *end;\n\n    const uint16_t *mm_end;\n\n    uint8_t *d = dst;\n\n    const uint16_t *s = (const uint16_t*)src;\n\n    end = s + src_size/2;\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s):\"memory\");\n\n    mm_end = end - 7;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movq          %1, %%mm0    \\n\\t\"\n\n            \"movq          %1, %%mm1    \\n\\t\"\n\n            \"movq          %1, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %3, %%mm1    \\n\\t\"\n\n            \"pand          %4, %%mm2    \\n\\t\"\n\n            \"psllq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $2, %%mm1    \\n\\t\"\n\n            \"psrlq         $7, %%mm2    \\n\\t\"\n\n            \"movq       %%mm0, %%mm3    \\n\\t\"\n\n            \"movq       %%mm1, %%mm4    \\n\\t\"\n\n            \"movq       %%mm2, %%mm5    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm0    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm1    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm2    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm3    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm4    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm1    \\n\\t\"\n\n            \"psllq        $16, %%mm2    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm4    \\n\\t\"\n\n            \"psllq        $16, %%mm5    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n\n\n            \"movq       %%mm0, %%mm6    \\n\\t\"\n\n            \"movq       %%mm3, %%mm7    \\n\\t\"\n\n\n\n            \"movq         8%1, %%mm0    \\n\\t\"\n\n            \"movq         8%1, %%mm1    \\n\\t\"\n\n            \"movq         8%1, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %3, %%mm1    \\n\\t\"\n\n            \"pand          %4, %%mm2    \\n\\t\"\n\n            \"psllq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $2, %%mm1    \\n\\t\"\n\n            \"psrlq         $7, %%mm2    \\n\\t\"\n\n            \"movq       %%mm0, %%mm3    \\n\\t\"\n\n            \"movq       %%mm1, %%mm4    \\n\\t\"\n\n            \"movq       %%mm2, %%mm5    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm0    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm1    \\n\\t\"\n\n            \"punpcklwd     %5, %%mm2    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm3    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm4    \\n\\t\"\n\n            \"punpckhwd     %5, %%mm5    \\n\\t\"\n\n            \"psllq         $8, %%mm1    \\n\\t\"\n\n            \"psllq        $16, %%mm2    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"psllq         $8, %%mm4    \\n\\t\"\n\n            \"psllq        $16, %%mm5    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s),\"m\"(mask15b),\"m\"(mask15g),\"m\"(mask15r), \"m\"(mmx_null)\n\n            :\"memory\");\n\n        /* borrowed 32 to 24 */\n\n        __asm__ volatile(\n\n            \"movq       %%mm0, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"movq       %%mm6, %%mm0    \\n\\t\"\n\n            \"movq       %%mm7, %%mm1    \\n\\t\"\n\n\n\n            \"movq       %%mm4, %%mm6    \\n\\t\"\n\n            \"movq       %%mm5, %%mm7    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm1, %%mm3    \\n\\t\"\n\n\n\n            STORE_BGR24_MMX\n\n\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s)\n\n            :\"memory\");\n\n        d += 24;\n\n        s += 8;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n    while (s < end) {\n\n        register uint16_t bgr;\n\n        bgr = *s++;\n\n        *d++ = (bgr&0x1F)<<3;\n\n        *d++ = (bgr&0x3E0)>>2;\n\n        *d++ = (bgr&0x7C00)>>7;\n\n    }\n\n}\n", "idx": 1508, "_split": "test", "_hash": "b9fbe71f8c29b7a641bd82f1480b6090"}
{"project": "FFmpeg", "commit_id": "ddbcc48b646737c8bff7f8e28e0a69dca65509cf", "target": 0, "func": "static int ftp_file_size(FTPContext *s)\n\n{\n\n    char command[CONTROL_BUFFER_SIZE];\n\n    char *res = NULL;\n\n    const int size_codes[] = {213, 0};\n\n\n\n    snprintf(command, sizeof(command), \"SIZE %s\\r\\n\", s->path);\n\n    if (ftp_send_command(s, command, size_codes, &res)) {\n\n        s->filesize = strtoll(&res[4], NULL, 10);\n\n    } else {\n\n        s->filesize = -1;\n\n        av_free(res);\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    av_free(res);\n\n    return 0;\n\n}\n", "idx": 1525, "_split": "test", "_hash": "59ab25de9741363e9ddddbe16264eecd"}
{"project": "FFmpeg", "commit_id": "5c2fb561d94fc51d76ab21d6f7cc5b6cc3aa599c", "target": 0, "func": "int ff_h264_decode_ref_pic_marking(const H264Context *h, H264SliceContext *sl,\n\n                                   GetBitContext *gb)\n\n{\n\n    int i;\n\n    MMCO *mmco = sl->mmco;\n\n    int nb_mmco = 0;\n\n\n\n    if (h->nal_unit_type == NAL_IDR_SLICE) { // FIXME fields\n\n        skip_bits1(gb); // broken_link\n\n        if (get_bits1(gb)) {\n\n            mmco[0].opcode   = MMCO_LONG;\n\n            mmco[0].long_arg = 0;\n\n            nb_mmco          = 1;\n\n        }\n\n        sl->explicit_ref_marking = 1;\n\n    } else {\n\n        sl->explicit_ref_marking = get_bits1(gb);\n\n        if (sl->explicit_ref_marking) {\n\n            for (i = 0; i < MAX_MMCO_COUNT; i++) {\n\n                MMCOOpcode opcode = get_ue_golomb_31(gb);\n\n\n\n                mmco[i].opcode = opcode;\n\n                if (opcode == MMCO_SHORT2UNUSED || opcode == MMCO_SHORT2LONG) {\n\n                    mmco[i].short_pic_num =\n\n                        (sl->curr_pic_num - get_ue_golomb(gb) - 1) &\n\n                            (sl->max_pic_num - 1);\n\n#if 0\n\n                    if (mmco[i].short_pic_num >= h->short_ref_count ||\n\n                        !h->short_ref[mmco[i].short_pic_num]) {\n\n                        av_log(s->avctx, AV_LOG_ERROR,\n\n                               \"illegal short ref in memory management control \"\n\n                               \"operation %d\\n\", mmco);\n\n                        return -1;\n\n                    }\n\n#endif\n\n                }\n\n                if (opcode == MMCO_SHORT2LONG || opcode == MMCO_LONG2UNUSED ||\n\n                    opcode == MMCO_LONG || opcode == MMCO_SET_MAX_LONG) {\n\n                    unsigned int long_arg = get_ue_golomb_31(gb);\n\n                    if (long_arg >= 32 ||\n\n                        (long_arg >= 16 && !(opcode == MMCO_SET_MAX_LONG &&\n\n                                             long_arg == 16) &&\n\n                         !(opcode == MMCO_LONG2UNUSED && FIELD_PICTURE(h)))) {\n\n                        av_log(h->avctx, AV_LOG_ERROR,\n\n                               \"illegal long ref in memory management control \"\n\n                               \"operation %d\\n\", opcode);\n\n                        return -1;\n\n                    }\n\n                    mmco[i].long_arg = long_arg;\n\n                }\n\n\n\n                if (opcode > (unsigned) MMCO_LONG) {\n\n                    av_log(h->avctx, AV_LOG_ERROR,\n\n                           \"illegal memory management control operation %d\\n\",\n\n                           opcode);\n\n                    return -1;\n\n                }\n\n                if (opcode == MMCO_END)\n\n                    break;\n\n            }\n\n            nb_mmco = i;\n\n        }\n\n    }\n\n\n\n    sl->nb_mmco = nb_mmco;\n\n\n\n    return 0;\n\n}\n", "idx": 1540, "_split": "test", "_hash": "de60114f1e7fc31cc3258c07473edbc0"}
{"project": "FFmpeg", "commit_id": "89f464e9c229006e16f6bb5403c5529fdd0a9edd", "target": 0, "func": "static int decode_frame(AVCodecContext *avctx,\n\n                        void *data, int *got_frame, AVPacket *avpkt)\n\n{\n\n    TiffContext *const s = avctx->priv_data;\n\n    AVFrame *const p = data;\n\n    ThreadFrame frame = { .f = data };\n\n    unsigned off;\n\n    int le, ret, plane, planes;\n\n    int i, j, entries, stride;\n\n    unsigned soff, ssize;\n\n    uint8_t *dst;\n\n    GetByteContext stripsizes;\n\n    GetByteContext stripdata;\n\n\n\n    bytestream2_init(&s->gb, avpkt->data, avpkt->size);\n\n\n\n    // parse image header\n\n    if ((ret = ff_tdecode_header(&s->gb, &le, &off))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid TIFF header\\n\");\n\n        return ret;\n\n    } else if (off >= UINT_MAX - 14 || avpkt->size < off + 14) {\n\n        av_log(avctx, AV_LOG_ERROR, \"IFD offset is greater than image size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    s->le          = le;\n\n    // TIFF_BPP is not a required tag and defaults to 1\n\n    s->bppcount    = s->bpp = 1;\n\n    s->photometric = TIFF_PHOTOMETRIC_NONE;\n\n    s->compr       = TIFF_RAW;\n\n    s->fill_order  = 0;\n\n    free_geotags(s);\n\n\n\n    // Reset these offsets so we can tell if they were set this frame\n\n    s->stripsizesoff = s->strippos = 0;\n\n    /* parse image file directory */\n\n    bytestream2_seek(&s->gb, off, SEEK_SET);\n\n    entries = ff_tget_short(&s->gb, le);\n\n    if (bytestream2_get_bytes_left(&s->gb) < entries * 12)\n\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < entries; i++) {\n\n        if ((ret = tiff_decode_tag(s, p)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    for (i = 0; i<s->geotag_count; i++) {\n\n        const char *keyname = get_geokey_name(s->geotags[i].key);\n\n        if (!keyname) {\n\n            av_log(avctx, AV_LOG_WARNING, \"Unknown or unsupported GeoTIFF key %d\\n\", s->geotags[i].key);\n\n            continue;\n\n        }\n\n        if (get_geokey_type(s->geotags[i].key) != s->geotags[i].type) {\n\n            av_log(avctx, AV_LOG_WARNING, \"Type of GeoTIFF key %d is wrong\\n\", s->geotags[i].key);\n\n            continue;\n\n        }\n\n        ret = av_dict_set(avpriv_frame_get_metadatap(p), keyname, s->geotags[i].val, 0);\n\n        if (ret<0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Writing metadata with key '%s' failed\\n\", keyname);\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    if (!s->strippos && !s->stripoff) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Image data is missing\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    /* now we have the data and may start decoding */\n\n    if ((ret = init_image(s, &frame)) < 0)\n\n        return ret;\n\n\n\n    if (s->strips == 1 && !s->stripsize) {\n\n        av_log(avctx, AV_LOG_WARNING, \"Image data size missing\\n\");\n\n        s->stripsize = avpkt->size - s->stripoff;\n\n    }\n\n\n\n    if (s->stripsizesoff) {\n\n        if (s->stripsizesoff >= (unsigned)avpkt->size)\n\n            return AVERROR_INVALIDDATA;\n\n        bytestream2_init(&stripsizes, avpkt->data + s->stripsizesoff,\n\n                         avpkt->size - s->stripsizesoff);\n\n    }\n\n    if (s->strippos) {\n\n        if (s->strippos >= (unsigned)avpkt->size)\n\n            return AVERROR_INVALIDDATA;\n\n        bytestream2_init(&stripdata, avpkt->data + s->strippos,\n\n                         avpkt->size - s->strippos);\n\n    }\n\n\n\n    if (s->rps <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"rps %d invalid\\n\", s->rps);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    planes = s->planar ? s->bppcount : 1;\n\n    for (plane = 0; plane < planes; plane++) {\n\n        stride = p->linesize[plane];\n\n        dst = p->data[plane];\n\n        for (i = 0; i < s->height; i += s->rps) {\n\n            if (s->stripsizesoff)\n\n                ssize = ff_tget(&stripsizes, s->sstype, le);\n\n            else\n\n                ssize = s->stripsize;\n\n\n\n            if (s->strippos)\n\n                soff = ff_tget(&stripdata, s->sot, le);\n\n            else\n\n                soff = s->stripoff;\n\n\n\n            if (soff > avpkt->size || ssize > avpkt->size - soff) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid strip size/offset\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if ((ret = tiff_unpack_strip(s, p, dst, stride, avpkt->data + soff, ssize, i,\n\n                                         FFMIN(s->rps, s->height - i))) < 0) {\n\n                if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                    return ret;\n\n                break;\n\n            }\n\n            dst += s->rps * stride;\n\n        }\n\n        if (s->predictor == 2) {\n\n            if (s->photometric == TIFF_PHOTOMETRIC_YCBCR) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"predictor == 2 with YUV is unsupported\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n            dst   = p->data[plane];\n\n            soff  = s->bpp >> 3;\n\n            if (s->planar)\n\n                soff  = FFMAX(soff / s->bppcount, 1);\n\n            ssize = s->width * soff;\n\n            if (s->avctx->pix_fmt == AV_PIX_FMT_RGB48LE ||\n\n                s->avctx->pix_fmt == AV_PIX_FMT_RGBA64LE ||\n\n                s->avctx->pix_fmt == AV_PIX_FMT_GRAY16LE ||\n\n                s->avctx->pix_fmt == AV_PIX_FMT_YA16LE ||\n\n                s->avctx->pix_fmt == AV_PIX_FMT_GBRP16LE ||\n\n                s->avctx->pix_fmt == AV_PIX_FMT_GBRAP16LE) {\n\n                for (i = 0; i < s->height; i++) {\n\n                    for (j = soff; j < ssize; j += 2)\n\n                        AV_WL16(dst + j, AV_RL16(dst + j) + AV_RL16(dst + j - soff));\n\n                    dst += stride;\n\n                }\n\n            } else if (s->avctx->pix_fmt == AV_PIX_FMT_RGB48BE ||\n\n                       s->avctx->pix_fmt == AV_PIX_FMT_RGBA64BE ||\n\n                       s->avctx->pix_fmt == AV_PIX_FMT_GRAY16BE ||\n\n                       s->avctx->pix_fmt == AV_PIX_FMT_YA16BE ||\n\n                       s->avctx->pix_fmt == AV_PIX_FMT_GBRP16BE ||\n\n                       s->avctx->pix_fmt == AV_PIX_FMT_GBRAP16BE) {\n\n                for (i = 0; i < s->height; i++) {\n\n                    for (j = soff; j < ssize; j += 2)\n\n                        AV_WB16(dst + j, AV_RB16(dst + j) + AV_RB16(dst + j - soff));\n\n                    dst += stride;\n\n                }\n\n            } else {\n\n                for (i = 0; i < s->height; i++) {\n\n                    for (j = soff; j < ssize; j++)\n\n                        dst[j] += dst[j - soff];\n\n                    dst += stride;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (s->photometric == TIFF_PHOTOMETRIC_WHITE_IS_ZERO) {\n\n            dst = p->data[plane];\n\n            for (i = 0; i < s->height; i++) {\n\n                for (j = 0; j < stride; j++)\n\n                    dst[j] = (s->avctx->pix_fmt == AV_PIX_FMT_PAL8 ? (1<<s->bpp) - 1 : 255) - dst[j];\n\n                dst += stride;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->planar && s->bppcount > 2) {\n\n        FFSWAP(uint8_t*, p->data[0],     p->data[2]);\n\n        FFSWAP(int,      p->linesize[0], p->linesize[2]);\n\n        FFSWAP(uint8_t*, p->data[0],     p->data[1]);\n\n        FFSWAP(int,      p->linesize[0], p->linesize[1]);\n\n    }\n\n\n\n    *got_frame = 1;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 1628, "_split": "test", "_hash": "f2ca7c30b25abc35ad7d39be0cec5086"}
{"project": "FFmpeg", "commit_id": "bd255f9feb4deea4c990e582f0ba3b90d7b64b4c", "target": 0, "func": "int attribute_align_arg avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,\n\n                                              int *got_picture_ptr,\n\n                                              AVPacket *avpkt)\n\n{\n\n    int ret;\n\n\n\n    *got_picture_ptr = 0;\n\n    if ((avctx->coded_width || avctx->coded_height) && av_image_check_size(avctx->coded_width, avctx->coded_height, 0, avctx))\n\n        return -1;\n\n\n\n    avctx->pkt = avpkt;\n\n    apply_param_change(avctx, avpkt);\n\n\n\n    avcodec_get_frame_defaults(picture);\n\n\n\n    if ((avctx->codec->capabilities & CODEC_CAP_DELAY) || avpkt->size || (avctx->active_thread_type & FF_THREAD_FRAME)) {\n\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n\n            ret = ff_thread_decode_frame(avctx, picture, got_picture_ptr,\n\n                                         avpkt);\n\n        else {\n\n            ret = avctx->codec->decode(avctx, picture, got_picture_ptr,\n\n                                       avpkt);\n\n            picture->pkt_dts             = avpkt->dts;\n\n            picture->sample_aspect_ratio = avctx->sample_aspect_ratio;\n\n            picture->width               = avctx->width;\n\n            picture->height              = avctx->height;\n\n            picture->format              = avctx->pix_fmt;\n\n        }\n\n\n\n        emms_c(); //needed to avoid an emms_c() call before every return;\n\n\n\n        if (*got_picture_ptr)\n\n            avctx->frame_number++;\n\n    } else\n\n        ret = 0;\n\n\n\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n\n     * make sure it's set correctly */\n\n    picture->extended_data = picture->data;\n\n\n\n    return ret;\n\n}\n", "idx": 1657, "_split": "test", "_hash": "3cb594e12a54903d02ab41689ab51881"}
{"project": "FFmpeg", "commit_id": "a70a3f0b4dc488ad04f81c16479c74f57b17e06f", "target": 0, "func": "static int adpcm_decode_init(AVCodecContext * avctx)\n\n{\n\n    ADPCMContext *c = avctx->priv_data;\n\n\n\n    if(avctx->channels > 2U){\n\n        return -1;\n\n    }\n\n\n\n    c->channel = 0;\n\n    c->status[0].predictor = c->status[1].predictor = 0;\n\n    c->status[0].step_index = c->status[1].step_index = 0;\n\n    c->status[0].step = c->status[1].step = 0;\n\n\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_ADPCM_CT:\n\n        c->status[0].step = c->status[1].step = 511;\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_WS:\n\n        if (avctx->extradata && avctx->extradata_size == 2 * 4) {\n\n            c->status[0].predictor = AV_RL32(avctx->extradata);\n\n            c->status[1].predictor = AV_RL32(avctx->extradata + 4);\n\n        }\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 1713, "_split": "test", "_hash": "77a5b39b8aeff71dcdcf331204d74513"}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "int ff_schro_queue_push_back(FFSchroQueue *queue, void *p_data)\n\n{\n\n    FFSchroQueueElement *p_new = av_mallocz(sizeof(FFSchroQueueElement));\n\n\n\n    if (!p_new)\n\n        return -1;\n\n\n\n    p_new->data = p_data;\n\n\n\n    if (!queue->p_head)\n\n        queue->p_head = p_new;\n\n    else\n\n        queue->p_tail->next = p_new;\n\n    queue->p_tail = p_new;\n\n\n\n    ++queue->size;\n\n    return 0;\n\n}\n", "idx": 1791, "_split": "test", "_hash": "675a87fe5ce2a869860c975f41ef4200"}
{"project": "FFmpeg", "commit_id": "dc64f203a62083c3d5f81e8201018279c29581af", "target": 1, "func": "static int ptx_decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt) {\n\n    const uint8_t *buf = avpkt->data;\n\n\n    PTXContext * const s = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    AVFrame * const p = &s->picture;\n\n    unsigned int offset, w, h, y, stride, bytes_per_pixel;\n\n    uint8_t *ptr;\n\n\n\n\n\n    offset          = AV_RL16(buf);\n\n    w               = AV_RL16(buf+8);\n\n    h               = AV_RL16(buf+10);\n\n    bytes_per_pixel = AV_RL16(buf+12) >> 3;\n\n\n\n    if (bytes_per_pixel != 2) {\n\n        av_log_ask_for_sample(avctx, \"Image format is not RGB15.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    avctx->pix_fmt = PIX_FMT_RGB555;\n\n\n\n    if (buf_end - buf < offset)\n\n\n    if (offset != 0x2c)\n\n        av_log_ask_for_sample(avctx, \"offset != 0x2c\\n\");\n\n\n\n    buf += offset;\n\n\n\n    if (p->data[0])\n\n        avctx->release_buffer(avctx, p);\n\n\n\n    if (av_image_check_size(w, h, 0, avctx))\n\n        return -1;\n\n    if (w != avctx->width || h != avctx->height)\n\n        avcodec_set_dimensions(avctx, w, h);\n\n    if (avctx->get_buffer(avctx, p) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    ptr    = p->data[0];\n\n    stride = p->linesize[0];\n\n\n\n    for (y=0; y<h; y++) {\n\n        if (buf_end - buf < w * bytes_per_pixel)\n\n            break;\n\n#if HAVE_BIGENDIAN\n\n        unsigned int x;\n\n        for (x=0; x<w*bytes_per_pixel; x+=bytes_per_pixel)\n\n            AV_WN16(ptr+x, AV_RL16(buf+x));\n\n#else\n\n        memcpy(ptr, buf, w*bytes_per_pixel);\n\n#endif\n\n        ptr += stride;\n\n        buf += w*bytes_per_pixel;\n\n    }\n\n\n\n    *picture = s->picture;\n\n    *data_size = sizeof(AVPicture);\n\n\n\n    return offset + w*h*bytes_per_pixel;\n\n}", "idx": 1804, "_split": "test", "_hash": "9c4523ce8950598117dd8bf23220a11a"}
{"project": "FFmpeg", "commit_id": "f028d4d1c393a13c66e828d45ba8412c0b4df6da", "target": 1, "func": "static int mxf_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    KLVPacket klv;\n\n    int64_t essence_offset = 0;\n\n\n\n    mxf->last_forward_tell = INT64_MAX;\n\n\n\n    if (!mxf_read_sync(s->pb, mxf_header_partition_pack_key, 14)) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find header partition pack key\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, -14, SEEK_CUR);\n\n    mxf->fc = s;\n\n    mxf->run_in = avio_tell(s->pb);\n\n\n\n    while (!s->pb->eof_reached) {\n\n        const MXFMetadataReadTableEntry *metadata;\n\n\n\n        if (klv_read_packet(&klv, s->pb) < 0) {\n\n            /* EOF - seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        PRINT_KEY(s, \"read header\", klv.key);\n\n        av_dlog(s, \"size %\"PRIu64\" offset %#\"PRIx64\"\\n\", klv.length, klv.offset);\n\n        if (IS_KLV_KEY(klv.key, mxf_encrypted_triplet_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_avid_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_system_item_key)) {\n\n            if (!mxf->current_partition->essence_offset) {\n\n                compute_partition_essence_offset(s, mxf, &klv);\n\n            }\n\n\n\n            if (!essence_offset)\n\n                essence_offset = klv.offset;\n\n\n\n            /* seek to footer, previous partition or stop */\n\n            if (mxf_parse_handle_essence(mxf) <= 0)\n\n                break;\n\n            continue;\n\n        } else if (!memcmp(klv.key, mxf_header_partition_pack_key, 13) &&\n\n                   klv.key[13] >= 2 && klv.key[13] <= 4 && mxf->current_partition) {\n\n            /* next partition pack - keep going, seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n        }\n\n\n\n        for (metadata = mxf_metadata_read_table; metadata->read; metadata++) {\n\n            if (IS_KLV_KEY(klv.key, metadata->key)) {\n\n                int res;\n\n                if (klv.key[5] == 0x53) {\n\n                    res = mxf_read_local_tags(mxf, &klv, metadata->read, metadata->ctx_size, metadata->type);\n\n                } else {\n\n                    uint64_t next = avio_tell(s->pb) + klv.length;\n\n                    res = metadata->read(mxf, s->pb, 0, klv.length, klv.key, klv.offset);\n\n                    avio_seek(s->pb, next, SEEK_SET);\n\n                }\n\n                if (res < 0) {\n\n                    av_log(s, AV_LOG_ERROR, \"error reading header metadata\\n\");\n\n                    return res;\n\n                }\n\n                break;\n\n            }\n\n        }\n\n        if (!metadata->read)\n\n            avio_skip(s->pb, klv.length);\n\n    }\n\n    /* FIXME avoid seek */\n\n    if (!essence_offset)  {\n\n        av_log(s, AV_LOG_ERROR, \"no essence\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, essence_offset, SEEK_SET);\n\n\n\n    mxf_compute_essence_containers(mxf);\n\n\n\n    return mxf_parse_structural_metadata(mxf);\n\n}\n", "idx": 1878, "_split": "test", "_hash": "4b7ed4a139b8dbb561fe8c29f8994c67"}
{"project": "FFmpeg", "commit_id": "1577526b47439f33a999339efdec5d624b70e1da", "target": 1, "func": "static opj_image_t *mj2_create_image(AVCodecContext *avctx, opj_cparameters_t *parameters)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n    opj_image_cmptparm_t cmptparm[4] = {{0}};\n    opj_image_t *img;\n    int i;\n    int sub_dx[4];\n    int sub_dy[4];\n    int numcomps;\n    OPJ_COLOR_SPACE color_space = CLRSPC_UNKNOWN;\n    sub_dx[0] = sub_dx[3] = 1;\n    sub_dy[0] = sub_dy[3] = 1;\n    sub_dx[1] = sub_dx[2] = 1 << desc->log2_chroma_w;\n    sub_dy[1] = sub_dy[2] = 1 << desc->log2_chroma_h;\n    numcomps = desc->nb_components;\n    switch (avctx->pix_fmt) {\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_YA8:\n    case AV_PIX_FMT_GRAY16:\n    case AV_PIX_FMT_YA16:\n        color_space = CLRSPC_GRAY;\n        break;\n    case AV_PIX_FMT_RGB24:\n    case AV_PIX_FMT_RGBA:\n    case AV_PIX_FMT_RGB48:\n    case AV_PIX_FMT_RGBA64:\n    case AV_PIX_FMT_GBR24P:\n    case AV_PIX_FMT_GBRP9:\n    case AV_PIX_FMT_GBRP10:\n    case AV_PIX_FMT_GBRP12:\n    case AV_PIX_FMT_GBRP14:\n    case AV_PIX_FMT_GBRP16:\n    case AV_PIX_FMT_XYZ12:\n        color_space = CLRSPC_SRGB;\n        break;\n    case AV_PIX_FMT_YUV410P:\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9:\n    case AV_PIX_FMT_YUV422P9:\n    case AV_PIX_FMT_YUV444P9:\n    case AV_PIX_FMT_YUVA420P9:\n    case AV_PIX_FMT_YUVA422P9:\n    case AV_PIX_FMT_YUVA444P9:\n    case AV_PIX_FMT_YUV420P10:\n    case AV_PIX_FMT_YUV422P10:\n    case AV_PIX_FMT_YUV444P10:\n    case AV_PIX_FMT_YUVA420P10:\n    case AV_PIX_FMT_YUVA422P10:\n    case AV_PIX_FMT_YUVA444P10:\n    case AV_PIX_FMT_YUV420P12:\n    case AV_PIX_FMT_YUV422P12:\n    case AV_PIX_FMT_YUV444P12:\n    case AV_PIX_FMT_YUV420P14:\n    case AV_PIX_FMT_YUV422P14:\n    case AV_PIX_FMT_YUV444P14:\n    case AV_PIX_FMT_YUV420P16:\n    case AV_PIX_FMT_YUV422P16:\n    case AV_PIX_FMT_YUV444P16:\n    case AV_PIX_FMT_YUVA420P16:\n    case AV_PIX_FMT_YUVA422P16:\n    case AV_PIX_FMT_YUVA444P16:\n        color_space = CLRSPC_SYCC;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR,\n               \"The requested pixel format '%s' is not supported\\n\",\n               av_get_pix_fmt_name(avctx->pix_fmt));\n    }\n    for (i = 0; i < numcomps; i++) {\n        cmptparm[i].prec = desc->comp[i].depth_minus1 + 1;\n        cmptparm[i].bpp  = desc->comp[i].depth_minus1 + 1;\n        cmptparm[i].sgnd = 0;\n        cmptparm[i].dx = sub_dx[i];\n        cmptparm[i].dy = sub_dy[i];\n        cmptparm[i].w = (avctx->width + sub_dx[i] - 1) / sub_dx[i];\n        cmptparm[i].h = (avctx->height + sub_dy[i] - 1) / sub_dy[i];\n    }\n    img = opj_image_create(numcomps, cmptparm, color_space);\n    // x0, y0 is the top left corner of the image\n    // x1, y1 is the width, height of the reference grid\n    img->x0 = 0;\n    img->y0 = 0;\n    img->x1 = (avctx->width  - 1) * parameters->subsampling_dx + 1;\n    img->y1 = (avctx->height - 1) * parameters->subsampling_dy + 1;\n    return img;\n}", "idx": 1883, "_split": "test", "_hash": "e5ae5df6e3b047b2bf62f15709ee5f8d"}
{"project": "FFmpeg", "commit_id": "ec4c48397641dbaf4ae8df36c32aaa5a311a11bf", "target": 1, "func": "static int rtsp_listen(AVFormatContext *s)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    char proto[128], host[128], path[512], auth[128];\n\n    char uri[500];\n\n    int port;\n\n    int default_port = RTSP_DEFAULT_PORT;\n\n    char tcpname[500];\n\n    const char *lower_proto = \"tcp\";\n\n    unsigned char rbuf[4096];\n\n    unsigned char method[10];\n\n    int rbuflen = 0;\n\n    int ret;\n\n    enum RTSPMethod methodcode;\n\n\n\n    if (!rt->protocols) {\n\n        rt->protocols = ffurl_get_protocols(NULL, NULL);\n\n        if (!rt->protocols)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    /* extract hostname and port */\n\n    av_url_split(proto, sizeof(proto), auth, sizeof(auth), host, sizeof(host),\n\n                 &port, path, sizeof(path), s->filename);\n\n\n\n    /* ff_url_join. No authorization by now (NULL) */\n\n    ff_url_join(rt->control_uri, sizeof(rt->control_uri), proto, NULL, host,\n\n                port, \"%s\", path);\n\n\n\n    if (!strcmp(proto, \"rtsps\")) {\n\n        lower_proto  = \"tls\";\n\n        default_port = RTSPS_DEFAULT_PORT;\n\n    }\n\n\n\n    if (port < 0)\n\n        port = default_port;\n\n\n\n    /* Create TCP connection */\n\n    ff_url_join(tcpname, sizeof(tcpname), lower_proto, NULL, host, port,\n\n                \"?listen&listen_timeout=%d\", rt->initial_timeout * 1000);\n\n\n\n    if (ret = ffurl_open(&rt->rtsp_hd, tcpname, AVIO_FLAG_READ_WRITE,\n\n                         &s->interrupt_callback, NULL, rt->protocols)) {\n\n        av_log(s, AV_LOG_ERROR, \"Unable to open RTSP for listening\\n\");\n\n        return ret;\n\n    }\n\n    rt->state       = RTSP_STATE_IDLE;\n\n    rt->rtsp_hd_out = rt->rtsp_hd;\n\n    for (;;) { /* Wait for incoming RTSP messages */\n\n        ret = read_line(s, rbuf, sizeof(rbuf), &rbuflen);\n\n        if (ret < 0)\n\n            return ret;\n\n        ret = parse_command_line(s, rbuf, rbuflen, uri, sizeof(uri), method,\n\n                                 sizeof(method), &methodcode);\n\n        if (ret) {\n\n            av_log(s, AV_LOG_ERROR, \"RTSP: Unexpected Command\\n\");\n\n            return ret;\n\n        }\n\n\n\n        if (methodcode == ANNOUNCE) {\n\n            ret       = rtsp_read_announce(s);\n\n            rt->state = RTSP_STATE_PAUSED;\n\n        } else if (methodcode == OPTIONS) {\n\n            ret = rtsp_read_options(s);\n\n        } else if (methodcode == RECORD) {\n\n            ret = rtsp_read_record(s);\n\n            if (!ret)\n\n                return 0; // We are ready for streaming\n\n        } else if (methodcode == SETUP)\n\n            ret = rtsp_read_setup(s, host, uri);\n\n        if (ret) {\n\n            ffurl_close(rt->rtsp_hd);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 1937, "_split": "test", "_hash": "5ff031e34e0c0647d0b0d173c94d42cb"}
{"project": "FFmpeg", "commit_id": "365ef88d5df4756942324b633cc439154e468276", "target": 1, "func": "int ff_wma_run_level_decode(AVCodecContext *avctx, GetBitContext *gb,\n\n                            VLC *vlc, const float *level_table,\n\n                            const uint16_t *run_table, int version,\n\n                            WMACoef *ptr, int offset, int num_coefs,\n\n                            int block_len, int frame_len_bits,\n\n                            int coef_nb_bits)\n\n{\n\n    int code, level, sign;\n\n    const uint32_t *ilvl = (const uint32_t *) level_table;\n\n    uint32_t *iptr = (uint32_t *) ptr;\n\n    const unsigned int coef_mask = block_len - 1;\n\n    for (; offset < num_coefs; offset++) {\n\n        code = get_vlc2(gb, vlc->table, VLCBITS, VLCMAX);\n\n        if (code > 1) {\n\n            /** normal code */\n\n            offset                  += run_table[code];\n\n            sign                     = get_bits1(gb) - 1;\n\n            iptr[offset & coef_mask] = ilvl[code] ^ sign << 31;\n\n        } else if (code == 1) {\n\n            /** EOB */\n\n            break;\n\n        } else {\n\n            /** escape */\n\n            if (!version) {\n\n                level = get_bits(gb, coef_nb_bits);\n\n                /** NOTE: this is rather suboptimal. reading\n\n                 *  block_len_bits would be better */\n\n                offset += get_bits(gb, frame_len_bits);\n\n            } else {\n\n                level = ff_wma_get_large_val(gb);\n\n                /** escape decode */\n\n                if (get_bits1(gb)) {\n\n                    if (get_bits1(gb)) {\n\n                        if (get_bits1(gb)) {\n\n                            av_log(avctx, AV_LOG_ERROR,\n\n                                   \"broken escape sequence\\n\");\n\n                            return -1;\n\n                        } else\n\n                            offset += get_bits(gb, frame_len_bits) + 4;\n\n                    } else\n\n                        offset += get_bits(gb, 2) + 1;\n\n                }\n\n            }\n\n            sign                    = get_bits1(gb) - 1;\n\n            ptr[offset & coef_mask] = (level ^ sign) - sign;\n\n        }\n\n    }\n\n    /** NOTE: EOB can be omitted */\n\n    if (offset > num_coefs) {\n\n        av_log(avctx, AV_LOG_ERROR, \"overflow in spectral RLE, ignoring\\n\");\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 1945, "_split": "test", "_hash": "da2b8815beaa05cfa51ff2fa0d330b2f"}
{"project": "FFmpeg", "commit_id": "9241cd2095fe8395e02be5556d657d06f65ba91f", "target": 0, "func": "int avfilter_graph_parse(AVFilterGraph *graph, const char *filters,\n\n                         AVFilterInOut *open_inputs,\n\n                         AVFilterInOut *open_outputs, AVClass *log_ctx)\n\n{\n\n    int index = 0, ret;\n\n    char chr = 0;\n\n\n\n    AVFilterInOut *curr_inputs = NULL;\n\n\n\n    do {\n\n        AVFilterContext *filter;\n\n        filters += strspn(filters, WHITESPACES);\n\n\n\n        if ((ret = parse_inputs(&filters, &curr_inputs, &open_outputs, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if ((ret = parse_filter(&filter, &filters, graph, index, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if (filter->input_count == 1 && !curr_inputs && !index) {\n\n            /* First input can be omitted if it is \"[in]\" */\n\n            const char *tmp = \"[in]\";\n\n            if ((ret = parse_inputs(&tmp, &curr_inputs, &open_outputs, log_ctx)) < 0)\n\n                goto fail;\n\n        }\n\n\n\n        if ((ret = link_filter_inouts(filter, &curr_inputs, &open_inputs, log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        if ((ret = parse_outputs(&filters, &curr_inputs, &open_inputs, &open_outputs,\n\n                                 log_ctx)) < 0)\n\n            goto fail;\n\n\n\n        filters += strspn(filters, WHITESPACES);\n\n        chr = *filters++;\n\n\n\n        if (chr == ';' && curr_inputs) {\n\n            av_log(log_ctx, AV_LOG_ERROR,\n\n                   \"Could not find a output to link when parsing \\\"%s\\\"\\n\",\n\n                   filters - 1);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        index++;\n\n    } while (chr == ',' || chr == ';');\n\n\n\n    if (chr) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Unable to parse graph description substring: \\\"%s\\\"\\n\",\n\n               filters - 1);\n\n        ret = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    if (open_inputs && !strcmp(open_inputs->name, \"out\") && curr_inputs) {\n\n        /* Last output can be omitted if it is \"[out]\" */\n\n        const char *tmp = \"[out]\";\n\n        if ((ret = parse_outputs(&tmp, &curr_inputs, &open_inputs, &open_outputs,\n\n                                 log_ctx)) < 0)\n\n            goto fail;\n\n    }\n\n\n\n    return 0;\n\n\n\n fail:\n\n    avfilter_graph_free(graph);\n\n    free_inout(open_inputs);\n\n    free_inout(open_outputs);\n\n    free_inout(curr_inputs);\n\n    return ret;\n\n}\n", "idx": 1946, "_split": "test", "_hash": "cf514ad396dc50cd64383bc1f45d27e0"}
{"project": "FFmpeg", "commit_id": "2f76157eb05bf63725f96167feda6b2e07501c7e", "target": 1, "func": "av_cold int swri_rematrix_init(SwrContext *s){\n\n    int i, j;\n\n    int nb_in  = av_get_channel_layout_nb_channels(s->in_ch_layout);\n\n    int nb_out = av_get_channel_layout_nb_channels(s->out_ch_layout);\n\n\n\n    s->mix_any_f = NULL;\n\n\n\n    if (!s->rematrix_custom) {\n\n        int r = auto_matrix(s);\n\n        if (r)\n\n            return r;\n\n    }\n\n    if (s->midbuf.fmt == AV_SAMPLE_FMT_S16P){\n\n        s->native_matrix = av_calloc(nb_in * nb_out, sizeof(int));\n\n        s->native_one    = av_mallocz(sizeof(int));\n\n        if (!s->native_matrix || !s->native_one)\n\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < nb_out; i++) {\n\n            double rem = 0;\n\n\n\n            for (j = 0; j < nb_in; j++) {\n\n                double target = s->matrix[i][j] * 32768 + rem;\n\n                ((int*)s->native_matrix)[i * nb_in + j] = lrintf(target);\n\n                rem += target - ((int*)s->native_matrix)[i * nb_in + j];\n\n            }\n\n        }\n\n        *((int*)s->native_one) = 32768;\n\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_s16;\n\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_s16;\n\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_s16(s);\n\n    }else if(s->midbuf.fmt == AV_SAMPLE_FMT_FLTP){\n\n        s->native_matrix = av_calloc(nb_in * nb_out, sizeof(float));\n\n        s->native_one    = av_mallocz(sizeof(float));\n\n        if (!s->native_matrix || !s->native_one)\n\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < nb_out; i++)\n\n            for (j = 0; j < nb_in; j++)\n\n                ((float*)s->native_matrix)[i * nb_in + j] = s->matrix[i][j];\n\n        *((float*)s->native_one) = 1.0;\n\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_float;\n\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_float;\n\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_float(s);\n\n    }else if(s->midbuf.fmt == AV_SAMPLE_FMT_DBLP){\n\n        s->native_matrix = av_calloc(nb_in * nb_out, sizeof(double));\n\n        s->native_one    = av_mallocz(sizeof(double));\n\n        if (!s->native_matrix || !s->native_one)\n\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < nb_out; i++)\n\n            for (j = 0; j < nb_in; j++)\n\n                ((double*)s->native_matrix)[i * nb_in + j] = s->matrix[i][j];\n\n        *((double*)s->native_one) = 1.0;\n\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_double;\n\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_double;\n\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_double(s);\n\n    }else if(s->midbuf.fmt == AV_SAMPLE_FMT_S32P){\n\n        // Only for dithering currently\n\n//         s->native_matrix = av_calloc(nb_in * nb_out, sizeof(double));\n\n        s->native_one    = av_mallocz(sizeof(int));\n\n        if (!s->native_one)\n\n            return AVERROR(ENOMEM);\n\n//         for (i = 0; i < nb_out; i++)\n\n//             for (j = 0; j < nb_in; j++)\n\n//                 ((double*)s->native_matrix)[i * nb_in + j] = s->matrix[i][j];\n\n        *((int*)s->native_one) = 32768;\n\n        s->mix_1_1_f = (mix_1_1_func_type*)copy_s32;\n\n        s->mix_2_1_f = (mix_2_1_func_type*)sum2_s32;\n\n        s->mix_any_f = (mix_any_func_type*)get_mix_any_func_s32(s);\n\n    }else\n\n        av_assert0(0);\n\n    //FIXME quantize for integeres\n\n    for (i = 0; i < SWR_CH_MAX; i++) {\n\n        int ch_in=0;\n\n        for (j = 0; j < SWR_CH_MAX; j++) {\n\n            s->matrix32[i][j]= lrintf(s->matrix[i][j] * 32768);\n\n            if(s->matrix[i][j])\n\n                s->matrix_ch[i][++ch_in]= j;\n\n        }\n\n        s->matrix_ch[i][0]= ch_in;\n\n    }\n\n\n\n    if(HAVE_YASM && HAVE_MMX)\n\n        return swri_rematrix_init_x86(s);\n\n\n\n    return 0;\n\n}\n", "idx": 1998, "_split": "test", "_hash": "7a5b4d194bbdb521454580abb565a9b9"}
{"project": "FFmpeg", "commit_id": "73f863d751df84db7a0ca1bd83cdff1b95dc94dd", "target": 1, "func": "static int fic_decode_block(FICContext *ctx, GetBitContext *gb,\n\n                            uint8_t *dst, int stride, int16_t *block)\n\n{\n\n    int i, num_coeff;\n\n\n\n    /* Is it a skip block? */\n\n    if (get_bits1(gb)) {\n\n        /* This is a P-frame. */\n\n        ctx->frame->key_frame = 0;\n\n        ctx->frame->pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        return 0;\n\n    }\n\n\n\n    memset(block, 0, sizeof(*block) * 64);\n\n\n\n    num_coeff = get_bits(gb, 7);\n\n    if (num_coeff > 64)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    for (i = 0; i < num_coeff; i++)\n\n        block[ff_zigzag_direct[i]] = get_se_golomb(gb) *\n\n                                     ctx->qmat[ff_zigzag_direct[i]];\n\n\n\n    fic_idct_put(dst, stride, block);\n\n\n\n    return 0;\n\n}\n", "idx": 2010, "_split": "test", "_hash": "c066c9e052b463e248aba33f71d2ef57"}
{"project": "FFmpeg", "commit_id": "604c9b1196c70d79bbbc1f23e75f6a8253a74da3", "target": 1, "func": "void ff_rtsp_undo_setup(AVFormatContext *s, int send_packets)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    int i;\n\n\n\n    for (i = 0; i < rt->nb_rtsp_streams; i++) {\n\n        RTSPStream *rtsp_st = rt->rtsp_streams[i];\n\n        if (!rtsp_st)\n\n            continue;\n\n        if (rtsp_st->transport_priv) {\n\n            if (s->oformat) {\n\n                AVFormatContext *rtpctx = rtsp_st->transport_priv;\n\n                av_write_trailer(rtpctx);\n\n                if (rt->lower_transport == RTSP_LOWER_TRANSPORT_TCP) {\n\n                    uint8_t *ptr;\n\n                    if (CONFIG_RTSP_MUXER && rtpctx->pb && send_packets)\n\n                        ff_rtsp_tcp_write_packet(s, rtsp_st);\n\n                    avio_close_dyn_buf(rtpctx->pb, &ptr);\n\n                    av_free(ptr);\n\n                } else {\n\n                    avio_close(rtpctx->pb);\n\n                }\n\n                avformat_free_context(rtpctx);\n\n            } else if (rt->transport == RTSP_TRANSPORT_RDT && CONFIG_RTPDEC)\n\n                ff_rdt_parse_close(rtsp_st->transport_priv);\n\n            else if (rt->transport == RTSP_TRANSPORT_RTP && CONFIG_RTPDEC)\n\n                ff_rtp_parse_close(rtsp_st->transport_priv);\n\n        }\n\n        rtsp_st->transport_priv = NULL;\n\n        if (rtsp_st->rtp_handle)\n\n            ffurl_close(rtsp_st->rtp_handle);\n\n        rtsp_st->rtp_handle = NULL;\n\n    }\n\n}\n", "idx": 2027, "_split": "test", "_hash": "9243574e8b5b22145cdc5d0d09b5d1fc"}
{"project": "FFmpeg", "commit_id": "f566ac48ce450b013ffd5547ace48df8c47981c6", "target": 0, "func": "static int get_video_buffer(AVFrame *frame, int align)\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n\n    int ret, i;\n\n\n\n    if (!desc)\n\n        return AVERROR(EINVAL);\n\n\n\n    if ((ret = av_image_check_size(frame->width, frame->height, 0, NULL)) < 0)\n\n        return ret;\n\n\n\n    if (!frame->linesize[0]) {\n\n        ret = av_image_fill_linesizes(frame->linesize, frame->format,\n\n                                      frame->width);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        for (i = 0; i < 4 && frame->linesize[i]; i++)\n\n            frame->linesize[i] = FFALIGN(frame->linesize[i], align);\n\n    }\n\n\n\n    for (i = 0; i < 4 && frame->linesize[i]; i++) {\n\n        int h = FFALIGN(frame->height, 32);\n\n        if (i == 1 || i == 2)\n\n            h = -((-h) >> desc->log2_chroma_h);\n\n\n\n        frame->buf[i] = av_buffer_alloc(frame->linesize[i] * h);\n\n        if (!frame->buf[i])\n\n            goto fail;\n\n\n\n        frame->data[i] = frame->buf[i]->data;\n\n    }\n\n    if (desc->flags & PIX_FMT_PAL || desc->flags & PIX_FMT_PSEUDOPAL) {\n\n        av_buffer_unref(&frame->buf[1]);\n\n        frame->buf[1] = av_buffer_alloc(1024);\n\n        if (!frame->buf[1])\n\n            goto fail;\n\n        frame->data[1] = frame->buf[1]->data;\n\n    }\n\n\n\n    frame->extended_data = frame->data;\n\n\n\n    return 0;\n\nfail:\n\n    av_frame_unref(frame);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 2049, "_split": "test", "_hash": "34a3e9bc77d9a9f5cb99d7394f8be512"}
{"project": "FFmpeg", "commit_id": "73dacabfc9b9ef1fd2c08105fdab6238ee29c2fc", "target": 0, "func": "av_cold int ffv1_init_slice_contexts(FFV1Context *f)\n\n{\n\n    int i;\n\n\n\n    f->slice_count = f->num_h_slices * f->num_v_slices;\n\n    if (f->slice_count <= 0) {\n\n        av_log(f->avctx, AV_LOG_ERROR, \"Invalid number of slices\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    for (i = 0; i < f->slice_count; i++) {\n\n        FFV1Context *fs = av_mallocz(sizeof(*fs));\n\n        int sx          = i % f->num_h_slices;\n\n        int sy          = i / f->num_h_slices;\n\n        int sxs         = f->avctx->width  *  sx      / f->num_h_slices;\n\n        int sxe         = f->avctx->width  * (sx + 1) / f->num_h_slices;\n\n        int sys         = f->avctx->height *  sy      / f->num_v_slices;\n\n        int sye         = f->avctx->height * (sy + 1) / f->num_v_slices;\n\n        f->slice_context[i] = fs;\n\n        memcpy(fs, f, sizeof(*fs));\n\n        memset(fs->rc_stat2, 0, sizeof(fs->rc_stat2));\n\n\n\n        fs->slice_width  = sxe - sxs;\n\n        fs->slice_height = sye - sys;\n\n        fs->slice_x      = sxs;\n\n        fs->slice_y      = sys;\n\n\n\n        fs->sample_buffer = av_malloc(3 * MAX_PLANES * (fs->width + 6) *\n\n                                      sizeof(*fs->sample_buffer));\n\n        if (!fs->sample_buffer)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n    return 0;\n\n}\n", "idx": 2083, "_split": "test", "_hash": "70310f28f602038c1e11ef07d92e2d0d"}
{"project": "FFmpeg", "commit_id": "b164d66e35d349de414e2f0d7365a147aba8a620", "target": 0, "func": "static void predictor_decode_mono(APEContext *ctx, int count)\n\n{\n\n    APEPredictor *p = &ctx->predictor;\n\n    int32_t *decoded0 = ctx->decoded[0];\n\n    int32_t predictionA, currentA, A, sign;\n\n\n\n    currentA = p->lastA[0];\n\n\n\n    while (count--) {\n\n        A = *decoded0;\n\n\n\n        p->buf[YDELAYA] = currentA;\n\n        p->buf[YDELAYA - 1] = p->buf[YDELAYA] - p->buf[YDELAYA - 1];\n\n\n\n        predictionA = p->buf[YDELAYA    ] * p->coeffsA[0][0] +\n\n                      p->buf[YDELAYA - 1] * p->coeffsA[0][1] +\n\n                      p->buf[YDELAYA - 2] * p->coeffsA[0][2] +\n\n                      p->buf[YDELAYA - 3] * p->coeffsA[0][3];\n\n\n\n        currentA = A + (predictionA >> 10);\n\n\n\n        p->buf[YADAPTCOEFFSA]     = APESIGN(p->buf[YDELAYA    ]);\n\n        p->buf[YADAPTCOEFFSA - 1] = APESIGN(p->buf[YDELAYA - 1]);\n\n\n\n        sign = APESIGN(A);\n\n        p->coeffsA[0][0] += p->buf[YADAPTCOEFFSA    ] * sign;\n\n        p->coeffsA[0][1] += p->buf[YADAPTCOEFFSA - 1] * sign;\n\n        p->coeffsA[0][2] += p->buf[YADAPTCOEFFSA - 2] * sign;\n\n        p->coeffsA[0][3] += p->buf[YADAPTCOEFFSA - 3] * sign;\n\n\n\n        p->buf++;\n\n\n\n        /* Have we filled the history buffer? */\n\n        if (p->buf == p->historybuffer + HISTORY_SIZE) {\n\n            memmove(p->historybuffer, p->buf,\n\n                    PREDICTOR_SIZE * sizeof(*p->historybuffer));\n\n            p->buf = p->historybuffer;\n\n        }\n\n\n\n        p->filterA[0] = currentA + ((p->filterA[0] * 31) >> 5);\n\n        *(decoded0++) = p->filterA[0];\n\n    }\n\n\n\n    p->lastA[0] = currentA;\n\n}\n", "idx": 2093, "_split": "test", "_hash": "0db9d34a307fd4f6b8e8729085b180d4"}
{"project": "FFmpeg", "commit_id": "17ee7b5515cd1006a1f7ba4a9cced14f6526c1b0", "target": 0, "func": "static void print_report(AVFormatContext **output_files,\n\n                         AVOutputStream **ost_table, int nb_ostreams,\n\n                         int is_last_report)\n\n{\n\n    char buf[1024];\n\n    AVOutputStream *ost;\n\n    AVFormatContext *oc;\n\n    int64_t total_size;\n\n    AVCodecContext *enc;\n\n    int frame_number, vid, i;\n\n    double bitrate, ti1, pts;\n\n    static int64_t last_time = -1;\n\n    static int qp_histogram[52];\n\n\n\n    if (!is_last_report) {\n\n        int64_t cur_time;\n\n        /* display the report every 0.5 seconds */\n\n        cur_time = av_gettime();\n\n        if (last_time == -1) {\n\n            last_time = cur_time;\n\n            return;\n\n        }\n\n        if ((cur_time - last_time) < 500000)\n\n            return;\n\n        last_time = cur_time;\n\n    }\n\n\n\n\n\n    oc = output_files[0];\n\n\n\n    total_size = avio_size(oc->pb);\n\n    if(total_size<0) // FIXME improve avio_size() so it works with non seekable output too\n\n        total_size= avio_tell(oc->pb);\n\n\n\n    buf[0] = '\\0';\n\n    ti1 = 1e10;\n\n    vid = 0;\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        float q= -1;\n\n        ost = ost_table[i];\n\n        enc = ost->st->codec;\n\n        if(!ost->st->stream_copy && enc->coded_frame)\n\n            q= enc->coded_frame->quality/(float)FF_QP2LAMBDA;\n\n        if (vid && enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"q=%2.1f \", q);\n\n        }\n\n        if (!vid && enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            float t = (av_gettime()-timer_start) / 1000000.0;\n\n\n\n            frame_number = ost->frame_number;\n\n            snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"frame=%5d fps=%3d q=%3.1f \",\n\n                     frame_number, (t>1)?(int)(frame_number/t+0.5) : 0, q);\n\n            if(is_last_report)\n\n                snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"L\");\n\n            if(qp_hist){\n\n                int j;\n\n                int qp= lrintf(q);\n\n                if(qp>=0 && qp<FF_ARRAY_ELEMS(qp_histogram))\n\n                    qp_histogram[qp]++;\n\n                for(j=0; j<32; j++)\n\n                    snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"%X\", (int)lrintf(log(qp_histogram[j]+1)/log(2)));\n\n            }\n\n            if (enc->flags&CODEC_FLAG_PSNR){\n\n                int j;\n\n                double error, error_sum=0;\n\n                double scale, scale_sum=0;\n\n                char type[3]= {'Y','U','V'};\n\n                snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"PSNR=\");\n\n                for(j=0; j<3; j++){\n\n                    if(is_last_report){\n\n                        error= enc->error[j];\n\n                        scale= enc->width*enc->height*255.0*255.0*frame_number;\n\n                    }else{\n\n                        error= enc->coded_frame->error[j];\n\n                        scale= enc->width*enc->height*255.0*255.0;\n\n                    }\n\n                    if(j) scale/=4;\n\n                    error_sum += error;\n\n                    scale_sum += scale;\n\n                    snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"%c:%2.2f \", type[j], psnr(error/scale));\n\n                }\n\n                snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \"*:%2.2f \", psnr(error_sum/scale_sum));\n\n            }\n\n            vid = 1;\n\n        }\n\n        /* compute min output value */\n\n        pts = (double)ost->st->pts.val * av_q2d(ost->st->time_base);\n\n        if ((pts < ti1) && (pts > 0))\n\n            ti1 = pts;\n\n    }\n\n    if (ti1 < 0.01)\n\n        ti1 = 0.01;\n\n\n\n    if (verbose || is_last_report) {\n\n        bitrate = (double)(total_size * 8) / ti1 / 1000.0;\n\n\n\n        snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf),\n\n            \"size=%8.0fkB time=%0.2f bitrate=%6.1fkbits/s\",\n\n            (double)total_size / 1024, ti1, bitrate);\n\n\n\n        if (nb_frames_dup || nb_frames_drop)\n\n          snprintf(buf + strlen(buf), sizeof(buf) - strlen(buf), \" dup=%d drop=%d\",\n\n                  nb_frames_dup, nb_frames_drop);\n\n\n\n        if (verbose >= 0)\n\n            fprintf(stderr, \"%s    \\r\", buf);\n\n\n\n        fflush(stderr);\n\n    }\n\n\n\n    if (is_last_report && verbose >= 0){\n\n        int64_t raw= audio_size + video_size + extra_size;\n\n        fprintf(stderr, \"\\n\");\n\n        fprintf(stderr, \"video:%1.0fkB audio:%1.0fkB global headers:%1.0fkB muxing overhead %f%%\\n\",\n\n                video_size/1024.0,\n\n                audio_size/1024.0,\n\n                extra_size/1024.0,\n\n                100.0*(total_size - raw)/raw\n\n        );\n\n    }\n\n}\n", "idx": 2110, "_split": "test", "_hash": "9667de48c347386bc4e654e3a81c6ccc"}
{"project": "FFmpeg", "commit_id": "3ab9a2a5577d445252724af4067d2a7c8a378efa", "target": 1, "func": "static av_always_inline void rv40_strong_loop_filter(uint8_t *src,\n\n                                                     const int step,\n\n                                                     const int stride,\n\n                                                     const int alpha,\n\n                                                     const int lims,\n\n                                                     const int dmode,\n\n                                                     const int chroma)\n\n{\n\n    int i;\n\n\n\n    for(i = 0; i < 4; i++, src += stride){\n\n        int sflag, p0, q0, p1, q1;\n\n        int t = src[0*step] - src[-1*step];\n\n\n\n        if (!t)\n\n            continue;\n\n\n\n        sflag = (alpha * FFABS(t)) >> 7;\n\n        if (sflag > 1)\n\n            continue;\n\n\n\n        p0 = (25*src[-3*step] + 26*src[-2*step] + 26*src[-1*step] +\n\n              26*src[ 0*step] + 25*src[ 1*step] +\n\n              rv40_dither_l[dmode + i]) >> 7;\n\n\n\n        q0 = (25*src[-2*step] + 26*src[-1*step] + 26*src[ 0*step] +\n\n              26*src[ 1*step] + 25*src[ 2*step] +\n\n              rv40_dither_r[dmode + i]) >> 7;\n\n\n\n        if (sflag) {\n\n            p0 = av_clip(p0, src[-1*step] - lims, src[-1*step] + lims);\n\n            q0 = av_clip(q0, src[ 0*step] - lims, src[ 0*step] + lims);\n\n        }\n\n\n\n        p1 = (25*src[-4*step] + 26*src[-3*step] + 26*src[-2*step] + 26*p0 +\n\n              25*src[ 0*step] + rv40_dither_l[dmode + i]) >> 7;\n\n        q1 = (25*src[-1*step] + 26*q0 + 26*src[ 1*step] + 26*src[ 2*step] +\n\n              25*src[ 3*step] + rv40_dither_r[dmode + i]) >> 7;\n\n\n\n        if (sflag) {\n\n            p1 = av_clip(p1, src[-2*step] - lims, src[-2*step] + lims);\n\n            q1 = av_clip(q1, src[ 1*step] - lims, src[ 1*step] + lims);\n\n        }\n\n\n\n        src[-2*step] = p1;\n\n        src[-1*step] = p0;\n\n        src[ 0*step] = q0;\n\n        src[ 1*step] = q1;\n\n\n\n        if(!chroma){\n\n            src[-3*step] = (25*src[-1*step] + 26*src[-2*step] +\n\n                            51*src[-3*step] + 26*src[-4*step] + 64) >> 7;\n\n            src[ 2*step] = (25*src[ 0*step] + 26*src[ 1*step] +\n\n                            51*src[ 2*step] + 26*src[ 3*step] + 64) >> 7;\n\n        }\n\n    }\n\n}\n", "idx": 2115, "_split": "test", "_hash": "7e55b3fd12489438a38292ad7a067be9"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int rv10_decode_packet(AVCodecContext *avctx, const uint8_t *buf,\n\n                              int buf_size, int buf_size2)\n\n{\n\n    RVDecContext *rv = avctx->priv_data;\n\n    MpegEncContext *s = &rv->m;\n\n    int mb_count, mb_pos, left, start_mb_x, active_bits_size, ret;\n\n\n\n    active_bits_size = buf_size * 8;\n\n    init_get_bits(&s->gb, buf, FFMAX(buf_size, buf_size2) * 8);\n\n    if (s->codec_id == AV_CODEC_ID_RV10)\n\n        mb_count = rv10_decode_picture_header(s);\n\n    else\n\n        mb_count = rv20_decode_picture_header(rv);\n\n    if (mb_count < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"HEADER ERROR\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->mb_x >= s->mb_width ||\n\n        s->mb_y >= s->mb_height) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"POS ERROR %d %d\\n\", s->mb_x, s->mb_y);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    mb_pos = s->mb_y * s->mb_width + s->mb_x;\n\n    left   = s->mb_width * s->mb_height - mb_pos;\n\n    if (mb_count > left) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"COUNT ERROR\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((s->mb_x == 0 && s->mb_y == 0) || s->current_picture_ptr == NULL) {\n\n        // FIXME write parser so we always have complete frames?\n\n        if (s->current_picture_ptr) {\n\n            ff_er_frame_end(&s->er);\n\n            ff_MPV_frame_end(s);\n\n            s->mb_x = s->mb_y = s->resync_mb_x = s->resync_mb_y = 0;\n\n        }\n\n        if ((ret = ff_MPV_frame_start(s, avctx)) < 0)\n\n            return ret;\n\n        ff_mpeg_er_frame_start(s);\n\n    } else {\n\n        if (s->current_picture_ptr->f.pict_type != s->pict_type) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Slice type mismatch\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    av_dlog(avctx, \"qscale=%d\\n\", s->qscale);\n\n\n\n    /* default quantization values */\n\n    if (s->codec_id == AV_CODEC_ID_RV10) {\n\n        if (s->mb_y == 0)\n\n            s->first_slice_line = 1;\n\n    } else {\n\n        s->first_slice_line = 1;\n\n        s->resync_mb_x      = s->mb_x;\n\n    }\n\n    start_mb_x     = s->mb_x;\n\n    s->resync_mb_y = s->mb_y;\n\n    if (s->h263_aic) {\n\n        s->y_dc_scale_table =\n\n        s->c_dc_scale_table = ff_aic_dc_scale_table;\n\n    } else {\n\n        s->y_dc_scale_table =\n\n        s->c_dc_scale_table = ff_mpeg1_dc_scale_table;\n\n    }\n\n\n\n    if (s->modified_quant)\n\n        s->chroma_qscale_table = ff_h263_chroma_qscale_table;\n\n\n\n    ff_set_qscale(s, s->qscale);\n\n\n\n    s->rv10_first_dc_coded[0] = 0;\n\n    s->rv10_first_dc_coded[1] = 0;\n\n    s->rv10_first_dc_coded[2] = 0;\n\n    s->block_wrap[0] =\n\n    s->block_wrap[1] =\n\n    s->block_wrap[2] =\n\n    s->block_wrap[3] = s->b8_stride;\n\n    s->block_wrap[4] =\n\n    s->block_wrap[5] = s->mb_stride;\n\n    ff_init_block_index(s);\n\n\n\n    /* decode each macroblock */\n\n    for (s->mb_num_left = mb_count; s->mb_num_left > 0; s->mb_num_left--) {\n\n        int ret;\n\n        ff_update_block_index(s);\n\n        av_dlog(avctx, \"**mb x=%d y=%d\\n\", s->mb_x, s->mb_y);\n\n\n\n        s->mv_dir  = MV_DIR_FORWARD;\n\n        s->mv_type = MV_TYPE_16X16;\n\n        ret = ff_h263_decode_mb(s, s->block);\n\n\n\n        // Repeat the slice end check from ff_h263_decode_mb with our active\n\n        // bitstream size\n\n        if (ret != SLICE_ERROR) {\n\n            int v = show_bits(&s->gb, 16);\n\n\n\n            if (get_bits_count(&s->gb) + 16 > active_bits_size)\n\n                v >>= get_bits_count(&s->gb) + 16 - active_bits_size;\n\n\n\n            if (!v)\n\n                ret = SLICE_END;\n\n        }\n\n        if (ret != SLICE_ERROR && active_bits_size < get_bits_count(&s->gb) &&\n\n            8 * buf_size2 >= get_bits_count(&s->gb)) {\n\n            active_bits_size = buf_size2 * 8;\n\n            av_log(avctx, AV_LOG_DEBUG, \"update size from %d to %d\\n\",\n\n                   8 * buf_size, active_bits_size);\n\n            ret = SLICE_OK;\n\n        }\n\n\n\n        if (ret == SLICE_ERROR || active_bits_size < get_bits_count(&s->gb)) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"ERROR at MB %d %d\\n\", s->mb_x,\n\n                   s->mb_y);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n\n            ff_h263_update_motion_val(s);\n\n        ff_MPV_decode_mb(s, s->block);\n\n        if (s->loop_filter)\n\n            ff_h263_loop_filter(s);\n\n\n\n        if (++s->mb_x == s->mb_width) {\n\n            s->mb_x = 0;\n\n            s->mb_y++;\n\n            ff_init_block_index(s);\n\n        }\n\n        if (s->mb_x == s->resync_mb_x)\n\n            s->first_slice_line = 0;\n\n        if (ret == SLICE_END)\n\n            break;\n\n    }\n\n\n\n    ff_er_add_slice(&s->er, start_mb_x, s->resync_mb_y, s->mb_x - 1, s->mb_y,\n\n                    ER_MB_END);\n\n\n\n    return active_bits_size;\n\n}\n", "idx": 2130, "_split": "test", "_hash": "a3b4a3bbb3e0ebc26e6c5f63a474eaec"}
{"project": "FFmpeg", "commit_id": "26227d91865ddfbfe35c9ff84853cc469e1c7daf", "target": 1, "func": "static inline int *DEC_UQUAD(int *dst, unsigned idx, unsigned sign)\n\n{\n\n    unsigned nz = idx >> 12;\n\n\n\n    dst[0] = (idx & 3) * (1 + (((int)sign >> 31) << 1));\n\n    sign <<= nz & 1;\n\n    nz >>= 1;\n\n    dst[1] = (idx >> 2 & 3) * (1 + (((int)sign >> 31) << 1));\n\n    sign <<= nz & 1;\n\n    nz >>= 1;\n\n    dst[2] = (idx >> 4 & 3) * (1 + (((int)sign >> 31) << 1));\n\n    sign <<= nz & 1;\n\n    nz >>= 1;\n\n    dst[3] = (idx >> 6 & 3) * (1 + (((int)sign >> 31) << 1));\n\n\n\n    return dst + 4;\n\n}\n", "idx": 2142, "_split": "test", "_hash": "c44674a8bffb45bbb91f9cb1dc6ac703"}
{"project": "FFmpeg", "commit_id": "ed1c83508ec920bfef773e3aa3ac1764a65826ec", "target": 0, "func": "static int atrim_filter_frame(AVFilterLink *inlink, AVFrame *frame)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    TrimContext       *s = ctx->priv;\n\n    int64_t start_sample, end_sample = frame->nb_samples;\n\n    int64_t pts;\n\n    int drop;\n\n\n\n    /* drop everything if EOF has already been returned */\n\n    if (s->eof) {\n\n        av_frame_free(&frame);\n\n        return 0;\n\n    }\n\n\n\n    if (frame->pts != AV_NOPTS_VALUE)\n\n        pts = av_rescale_q(frame->pts, inlink->time_base,\n\n                           (AVRational){ 1, inlink->sample_rate });\n\n    else\n\n        pts = s->next_pts;\n\n    s->next_pts = pts + frame->nb_samples;\n\n\n\n    /* check if at least a part of the frame is after the start time */\n\n    if (s->start_sample < 0 && s->start_pts == AV_NOPTS_VALUE) {\n\n        start_sample = 0;\n\n    } else {\n\n        drop = 1;\n\n        start_sample = frame->nb_samples;\n\n\n\n        if (s->start_sample >= 0 &&\n\n            s->nb_samples + frame->nb_samples > s->start_sample) {\n\n            drop         = 0;\n\n            start_sample = FFMIN(start_sample, s->start_sample - s->nb_samples);\n\n        }\n\n\n\n        if (s->start_pts != AV_NOPTS_VALUE && pts != AV_NOPTS_VALUE &&\n\n            pts + frame->nb_samples > s->start_pts) {\n\n            drop = 0;\n\n            start_sample = FFMIN(start_sample, s->start_pts - pts);\n\n        }\n\n\n\n        if (drop)\n\n            goto drop;\n\n    }\n\n\n\n    if (s->first_pts == AV_NOPTS_VALUE)\n\n        s->first_pts = pts + start_sample;\n\n\n\n    /* check if at least a part of the frame is before the end time */\n\n    if (s->end_sample == INT64_MAX && s->end_pts == AV_NOPTS_VALUE && !s->duration_tb) {\n\n        end_sample = frame->nb_samples;\n\n    } else {\n\n        drop       = 1;\n\n        end_sample = 0;\n\n\n\n        if (s->end_sample != INT64_MAX &&\n\n            s->nb_samples < s->end_sample) {\n\n            drop       = 0;\n\n            end_sample = FFMAX(end_sample, s->end_sample - s->nb_samples);\n\n        }\n\n\n\n        if (s->end_pts != AV_NOPTS_VALUE && pts != AV_NOPTS_VALUE &&\n\n            pts < s->end_pts) {\n\n            drop       = 0;\n\n            end_sample = FFMAX(end_sample, s->end_pts - pts);\n\n        }\n\n\n\n        if (s->duration_tb && pts - s->first_pts < s->duration_tb) {\n\n            drop       = 0;\n\n            end_sample = FFMAX(end_sample, s->first_pts + s->duration_tb - pts);\n\n        }\n\n\n\n        if (drop) {\n\n            s->eof = 1;\n\n            goto drop;\n\n        }\n\n    }\n\n\n\n    s->nb_samples += frame->nb_samples;\n\n    start_sample   = FFMAX(0, start_sample);\n\n    end_sample     = FFMIN(frame->nb_samples, end_sample);\n\n    av_assert0(start_sample < end_sample);\n\n\n\n    if (start_sample) {\n\n        AVFrame *out = ff_get_audio_buffer(ctx->outputs[0], end_sample - start_sample);\n\n        if (!out) {\n\n            av_frame_free(&frame);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n\n\n        av_frame_copy_props(out, frame);\n\n        av_samples_copy(out->extended_data, frame->extended_data, 0, start_sample,\n\n                        out->nb_samples, av_get_channel_layout_nb_channels(frame->channel_layout),\n\n                        frame->format);\n\n        if (out->pts != AV_NOPTS_VALUE)\n\n            out->pts += av_rescale_q(start_sample, (AVRational){ 1, out->sample_rate },\n\n                                     inlink->time_base);\n\n\n\n        av_frame_free(&frame);\n\n        frame = out;\n\n    } else\n\n        frame->nb_samples = end_sample;\n\n\n\n    s->got_output = 1;\n\n    return ff_filter_frame(ctx->outputs[0], frame);\n\n\n\ndrop:\n\n    s->nb_samples += frame->nb_samples;\n\n    av_frame_free(&frame);\n\n    return 0;\n\n}\n", "idx": 2157, "_split": "test", "_hash": "f02fe2df7b06cfbba912009521b873d9"}
{"project": "FFmpeg", "commit_id": "f95cfff07765912676cc613b55e2234b5d70f1bd", "target": 0, "func": "static int ffserver_save_avoption(const char *opt, const char *arg, int type, FFServerConfig *config)\n\n{\n\n    static int hinted = 0;\n\n    int ret = 0;\n\n    AVDictionaryEntry *e;\n\n    const AVOption *o = NULL;\n\n    const char *option = NULL;\n\n    const char *codec_name = NULL;\n\n    char buff[1024];\n\n    AVCodecContext *ctx;\n\n    AVDictionary **dict;\n\n    enum AVCodecID guessed_codec_id;\n\n\n\n    switch (type) {\n\n    case AV_OPT_FLAG_VIDEO_PARAM:\n\n        ctx = config->dummy_vctx;\n\n        dict = &config->video_opts;\n\n        guessed_codec_id = config->guessed_video_codec_id != AV_CODEC_ID_NONE ?\n\n                           config->guessed_video_codec_id : AV_CODEC_ID_H264;\n\n        break;\n\n    case AV_OPT_FLAG_AUDIO_PARAM:\n\n        ctx = config->dummy_actx;\n\n        dict = &config->audio_opts;\n\n        guessed_codec_id = config->guessed_audio_codec_id != AV_CODEC_ID_NONE ?\n\n                           config->guessed_audio_codec_id : AV_CODEC_ID_AAC;\n\n        break;\n\n    default:\n\n        av_assert0(0);\n\n    }\n\n\n\n    if (strchr(opt, ':')) {\n\n        //explicit private option\n\n        snprintf(buff, sizeof(buff), \"%s\", opt);\n\n        codec_name = buff;\n\n        option = strchr(buff, ':');\n\n        buff[option - buff] = '\\0';\n\n        option++;\n\n        if ((ret = ffserver_set_codec(ctx, codec_name, config)) < 0)\n\n            return ret;\n\n        if (!ctx->codec || !ctx->priv_data)\n\n            return -1;\n\n    } else {\n\n        option = opt;\n\n    }\n\n\n\n    o = av_opt_find(ctx, option, NULL, type | AV_OPT_FLAG_ENCODING_PARAM, AV_OPT_SEARCH_CHILDREN);\n\n    if (!o && (!strcmp(option, \"time_base\")  || !strcmp(option, \"pixel_format\") ||\n\n               !strcmp(option, \"video_size\") || !strcmp(option, \"codec_tag\")))\n\n        o = av_opt_find(ctx, option, NULL, 0, 0);\n\n    if (!o) {\n\n        report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n\n                            &config->errors, \"Option not found: %s\\n\", opt);\n\n        if (!hinted && ctx->codec_id == AV_CODEC_ID_NONE) {\n\n            hinted = 1;\n\n            report_config_error(config->filename, config->line_num, AV_LOG_ERROR, NULL,\n\n                                \"If '%s' is a codec private option, then prefix it with codec name, \"\n\n                                \"for example '%s:%s %s' or define codec earlier.\\n\",\n\n                                opt, avcodec_get_name(guessed_codec_id) ,opt, arg);\n\n        }\n\n    } else if ((ret = av_opt_set(ctx, option, arg, AV_OPT_SEARCH_CHILDREN)) < 0) {\n\n        report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n\n                &config->errors, \"Invalid value for option %s (%s): %s\\n\", opt,\n\n                arg, av_err2str(ret));\n\n    } else if ((e = av_dict_get(*dict, option, NULL, 0))) {\n\n        if ((o->type == AV_OPT_TYPE_FLAGS) && arg && (arg[0] == '+' || arg[0] == '-'))\n\n            return av_dict_set(dict, option, arg, AV_DICT_APPEND);\n\n        report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n\n                &config->errors,\n\n                \"Redeclaring value of the option %s, previous value: %s\\n\",\n\n                opt, e->value);\n\n    } else if (av_dict_set(dict, option, arg, 0) < 0) {\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    return 0;\n\n}\n", "idx": 2188, "_split": "test", "_hash": "f59d4ba5a0d1a02f3abac8f509b1c881"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuv422ptouyvy)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n                                         long width, long height,\n\n                                         long lumStride, long chromStride, long dstStride)\n\n{\n\n    RENAME(yuvPlanartouyvy)(ysrc, usrc, vsrc, dst, width, height, lumStride, chromStride, dstStride, 1);\n\n}\n", "idx": 2246, "_split": "test", "_hash": "e81072521c3fa34303907fe66635a3fb"}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "yuv2422_2_c_template(SwsContext *c, const uint16_t *buf0,\n\n                     const uint16_t *buf1, const uint16_t *ubuf0,\n\n                     const uint16_t *ubuf1, const uint16_t *vbuf0,\n\n                     const uint16_t *vbuf1, const uint16_t *abuf0,\n\n                     const uint16_t *abuf1, uint8_t *dest, int dstW,\n\n                     int yalpha, int uvalpha, int y,\n\n                     enum PixelFormat target)\n\n{\n\n    int  yalpha1 = 4095 - yalpha;\n\n    int uvalpha1 = 4095 - uvalpha;\n\n    int i;\n\n\n\n    for (i = 0; i < (dstW >> 1); i++) {\n\n        int Y1 = (buf0[i * 2]     * yalpha1  + buf1[i * 2]     * yalpha)  >> 19;\n\n        int Y2 = (buf0[i * 2 + 1] * yalpha1  + buf1[i * 2 + 1] * yalpha)  >> 19;\n\n        int U  = (ubuf0[i]        * uvalpha1 + ubuf1[i]        * uvalpha) >> 19;\n\n        int V  = (vbuf0[i]        * uvalpha1 + vbuf1[i]        * uvalpha) >> 19;\n\n\n\n        output_pixels(i * 4, Y1, U, Y2, V);\n\n    }\n\n}\n", "idx": 2298, "_split": "test", "_hash": "b599cb7529adabfbbcd588bfd076e1ed"}
{"project": "FFmpeg", "commit_id": "2207ea44fb4fad4d47646a789bc244e3e84c1726", "target": 0, "func": "static av_always_inline void emulated_edge_mc(uint8_t *buf, const uint8_t *src,\n\n                                              int linesize,\n\n                                              int block_w, int block_h,\n\n                                              int src_x, int src_y,\n\n                                              int w, int h,\n\n                                              emu_edge_core_func *core_fn)\n\n{\n\n    int start_y, start_x, end_y, end_x, src_y_add = 0;\n\n\n\n    if (src_y >= h) {\n\n        src_y_add = h - 1 - src_y;\n\n        src_y     = h - 1;\n\n    } else if (src_y <= -block_h) {\n\n        src_y_add = 1 - block_h - src_y;\n\n        src_y     = 1 - block_h;\n\n    }\n\n    if (src_x >= w) {\n\n        src   += w - 1 - src_x;\n\n        src_x  = w - 1;\n\n    } else if (src_x <= -block_w) {\n\n        src   += 1 - block_w - src_x;\n\n        src_x  = 1 - block_w;\n\n    }\n\n\n\n    start_y = FFMAX(0, -src_y);\n\n    start_x = FFMAX(0, -src_x);\n\n    end_y   = FFMIN(block_h, h-src_y);\n\n    end_x   = FFMIN(block_w, w-src_x);\n\n    av_assert2(start_x < end_x && block_w > 0);\n\n    av_assert2(start_y < end_y && block_h > 0);\n\n\n\n    // fill in the to-be-copied part plus all above/below\n\n    src += (src_y_add + start_y) * linesize + start_x;\n\n    buf += start_x;\n\n    core_fn(buf, src, linesize, start_y, end_y,\n\n            block_h, start_x, end_x, block_w);\n\n}\n", "idx": 2300, "_split": "test", "_hash": "297421bedbbefa0af6fea60a7f2dfee0"}
{"project": "FFmpeg", "commit_id": "e838c9852e6f0a471a6917083e70e6fe238ba26a", "target": 1, "func": "static av_cold int init_bundles(BinkContext *c)\n\n{\n\n    int bw, bh, blocks;\n\n    int i;\n\n\n\n    bw = (c->avctx->width  + 7) >> 3;\n\n    bh = (c->avctx->height + 7) >> 3;\n\n    blocks = bw * bh;\n\n\n\n    for (i = 0; i < BINKB_NB_SRC; i++) {\n\n        c->bundle[i].data = av_malloc(blocks * 64);\n\n        if (!c->bundle[i].data)\n\n            return AVERROR(ENOMEM);\n\n        c->bundle[i].data_end = c->bundle[i].data + blocks * 64;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 2325, "_split": "test", "_hash": "5b77d4e88cfca2ddccffc1a0533a4f68"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(yuv422ptoyuy2)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n\tlong width, long height,\n\n\tlong lumStride, long chromStride, long dstStride)\n\n{\n\n\tRENAME(yuvPlanartoyuy2)(ysrc, usrc, vsrc, dst, width, height, lumStride, chromStride, dstStride, 1);\n\n}\n", "idx": 2348, "_split": "test", "_hash": "975721f9e7a9707b5bb46bbc9839beb5"}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static int vqa_decode_init(AVCodecContext *avctx)\n\n{\n\n    VqaContext *s = (VqaContext *)avctx->priv_data;\n\n    unsigned char *vqa_header;\n\n    int i, j, codebook_index;;\n\n\n\n    s->avctx = avctx;\n\n    avctx->pix_fmt = PIX_FMT_PAL8;\n\n    avctx->has_b_frames = 0;\n\n    dsputil_init(&s->dsp, avctx);\n\n\n\n    /* make sure the extradata made it */\n\n    if (s->avctx->extradata_size != VQA_HEADER_SIZE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: expected extradata size of %d\\n\", VQA_HEADER_SIZE);\n\n\n\n\n\n    /* load up the VQA parameters from the header */\n\n    vqa_header = (unsigned char *)s->avctx->extradata;\n\n    s->vqa_version = vqa_header[0];\n\n    s->width = LE_16(&vqa_header[6]);\n\n    s->height = LE_16(&vqa_header[8]);\n\n\n\n\n\n    s->vector_width = vqa_header[10];\n\n    s->vector_height = vqa_header[11];\n\n    s->partial_count = s->partial_countdown = vqa_header[13];\n\n\n\n    /* the vector dimensions have to meet very stringent requirements */\n\n    if ((s->vector_width != 4) ||\n\n        ((s->vector_height != 2) && (s->vector_height != 4))) {\n\n        /* return without further initialization */\n\n\n\n\n\n    /* allocate codebooks */\n\n    s->codebook_size = MAX_CODEBOOK_SIZE;\n\n    s->codebook = av_malloc(s->codebook_size);\n\n    s->next_codebook_buffer = av_malloc(s->codebook_size);\n\n\n\n    /* initialize the solid-color vectors */\n\n    if (s->vector_height == 4) {\n\n        codebook_index = 0xFF00 * 16;\n\n        for (i = 0; i < 256; i++)\n\n            for (j = 0; j < 16; j++)\n\n                s->codebook[codebook_index++] = i;\n\n    } else {\n\n        codebook_index = 0xF00 * 8;\n\n        for (i = 0; i < 256; i++)\n\n            for (j = 0; j < 8; j++)\n\n                s->codebook[codebook_index++] = i;\n\n\n    s->next_codebook_buffer_index = 0;\n\n\n\n    /* allocate decode buffer */\n\n    s->decode_buffer_size = (s->width / s->vector_width) *\n\n        (s->height / s->vector_height) * 2;\n\n    s->decode_buffer = av_malloc(s->decode_buffer_size);\n\n\n\n    s->frame.data[0] = NULL;\n\n\n\n    return 0;\n", "idx": 2358, "_split": "test", "_hash": "84c13c275d824d17913e130d77f7722c"}
{"project": "FFmpeg", "commit_id": "25bcf24d4d0faf0191923be8afac8f67ca98b500", "target": 0, "func": "static int open_output_file(OptionsContext *o, const char *filename)\n\n{\n\n    AVFormatContext *oc;\n\n    int i, j, err;\n\n    AVOutputFormat *file_oformat;\n\n    OutputFile *of;\n\n    OutputStream *ost;\n\n    InputStream  *ist;\n\n    AVDictionary *unused_opts = NULL;\n\n    AVDictionaryEntry *e = NULL;\n\n\n\n    if (configure_complex_filters() < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Error configuring filters.\\n\");\n\n        exit_program(1);\n\n    }\n\n\n\n    if (o->stop_time != INT64_MAX && o->recording_time != INT64_MAX) {\n\n        o->stop_time = INT64_MAX;\n\n        av_log(NULL, AV_LOG_WARNING, \"-t and -to cannot be used together; using -t.\\n\");\n\n    }\n\n\n\n    if (o->stop_time != INT64_MAX && o->recording_time == INT64_MAX) {\n\n        int64_t start_time = o->start_time == AV_NOPTS_VALUE ? 0 : o->start_time;\n\n        if (o->stop_time <= start_time) {\n\n            av_log(NULL, AV_LOG_WARNING, \"-to value smaller than -ss; ignoring -to.\\n\");\n\n            o->stop_time = INT64_MAX;\n\n        } else {\n\n            o->recording_time = o->stop_time - start_time;\n\n        }\n\n    }\n\n\n\n    GROW_ARRAY(output_files, nb_output_files);\n\n    of = av_mallocz(sizeof(*of));\n\n    if (!of)\n\n        exit_program(1);\n\n    output_files[nb_output_files - 1] = of;\n\n\n\n    of->ost_index      = nb_output_streams;\n\n    of->recording_time = o->recording_time;\n\n    of->start_time     = o->start_time;\n\n    of->limit_filesize = o->limit_filesize;\n\n    of->shortest       = o->shortest;\n\n    av_dict_copy(&of->opts, o->g->format_opts, 0);\n\n\n\n    if (!strcmp(filename, \"-\"))\n\n        filename = \"pipe:\";\n\n\n\n    err = avformat_alloc_output_context2(&oc, NULL, o->format, filename);\n\n    if (!oc) {\n\n        print_error(filename, err);\n\n        exit_program(1);\n\n    }\n\n\n\n    of->ctx = oc;\n\n    if (o->recording_time != INT64_MAX)\n\n        oc->duration = o->recording_time;\n\n\n\n    file_oformat= oc->oformat;\n\n    oc->interrupt_callback = int_cb;\n\n\n\n    /* create streams for all unlabeled output pads */\n\n    for (i = 0; i < nb_filtergraphs; i++) {\n\n        FilterGraph *fg = filtergraphs[i];\n\n        for (j = 0; j < fg->nb_outputs; j++) {\n\n            OutputFilter *ofilter = fg->outputs[j];\n\n\n\n            if (!ofilter->out_tmp || ofilter->out_tmp->name)\n\n                continue;\n\n\n\n            switch (avfilter_pad_get_type(ofilter->out_tmp->filter_ctx->output_pads,\n\n                                          ofilter->out_tmp->pad_idx)) {\n\n            case AVMEDIA_TYPE_VIDEO:    o->video_disable    = 1; break;\n\n            case AVMEDIA_TYPE_AUDIO:    o->audio_disable    = 1; break;\n\n            case AVMEDIA_TYPE_SUBTITLE: o->subtitle_disable = 1; break;\n\n            }\n\n            init_output_filter(ofilter, o, oc);\n\n        }\n\n    }\n\n\n\n    /* ffserver seeking with date=... needs a date reference */\n\n    if (!strcmp(file_oformat->name, \"ffm\") &&\n\n        av_strstart(filename, \"http:\", NULL)) {\n\n        int err = parse_option(o, \"metadata\", \"creation_time=now\", options);\n\n        if (err < 0) {\n\n            print_error(filename, err);\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    if (!strcmp(file_oformat->name, \"ffm\") && !override_ffserver &&\n\n        av_strstart(filename, \"http:\", NULL)) {\n\n        int j;\n\n        /* special case for files sent to ffserver: we get the stream\n\n           parameters from ffserver */\n\n        int err = read_ffserver_streams(o, oc, filename);\n\n        if (err < 0) {\n\n            print_error(filename, err);\n\n            exit_program(1);\n\n        }\n\n        for(j = nb_output_streams - oc->nb_streams; j < nb_output_streams; j++) {\n\n            ost = output_streams[j];\n\n            for (i = 0; i < nb_input_streams; i++) {\n\n                ist = input_streams[i];\n\n                if(ist->st->codec->codec_type == ost->st->codec->codec_type){\n\n                    ost->sync_ist= ist;\n\n                    ost->source_index= i;\n\n                    if(ost->st->codec->codec_type == AVMEDIA_TYPE_AUDIO) ost->avfilter = av_strdup(\"anull\");\n\n                    if(ost->st->codec->codec_type == AVMEDIA_TYPE_VIDEO) ost->avfilter = av_strdup(\"null\");\n\n                    ist->discard = 0;\n\n                    ist->st->discard = AVDISCARD_NONE;\n\n                    break;\n\n                }\n\n            }\n\n            if(!ost->sync_ist){\n\n                av_log(NULL, AV_LOG_FATAL, \"Missing %s stream which is required by this ffm\\n\", av_get_media_type_string(ost->st->codec->codec_type));\n\n                exit_program(1);\n\n            }\n\n        }\n\n    } else if (!o->nb_stream_maps) {\n\n        char *subtitle_codec_name = NULL;\n\n        /* pick the \"best\" stream of each type */\n\n\n\n        /* video: highest resolution */\n\n        if (!o->video_disable && oc->oformat->video_codec != AV_CODEC_ID_NONE) {\n\n            int area = 0, idx = -1;\n\n            int qcr = avformat_query_codec(oc->oformat, oc->oformat->video_codec, 0);\n\n            for (i = 0; i < nb_input_streams; i++) {\n\n                int new_area;\n\n                ist = input_streams[i];\n\n                new_area = ist->st->codec->width * ist->st->codec->height;\n\n                if((qcr!=MKTAG('A', 'P', 'I', 'C')) && (ist->st->disposition & AV_DISPOSITION_ATTACHED_PIC))\n\n                    new_area = 1;\n\n                if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n                    new_area > area) {\n\n                    if((qcr==MKTAG('A', 'P', 'I', 'C')) && !(ist->st->disposition & AV_DISPOSITION_ATTACHED_PIC))\n\n                        continue;\n\n                    area = new_area;\n\n                    idx = i;\n\n                }\n\n            }\n\n            if (idx >= 0)\n\n                new_video_stream(o, oc, idx);\n\n        }\n\n\n\n        /* audio: most channels */\n\n        if (!o->audio_disable && oc->oformat->audio_codec != AV_CODEC_ID_NONE) {\n\n            int channels = 0, idx = -1;\n\n            for (i = 0; i < nb_input_streams; i++) {\n\n                ist = input_streams[i];\n\n                if (ist->st->codec->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n                    ist->st->codec->channels > channels) {\n\n                    channels = ist->st->codec->channels;\n\n                    idx = i;\n\n                }\n\n            }\n\n            if (idx >= 0)\n\n                new_audio_stream(o, oc, idx);\n\n        }\n\n\n\n        /* subtitles: pick first */\n\n        MATCH_PER_TYPE_OPT(codec_names, str, subtitle_codec_name, oc, \"s\");\n\n        if (!o->subtitle_disable && (oc->oformat->subtitle_codec != AV_CODEC_ID_NONE || subtitle_codec_name)) {\n\n            for (i = 0; i < nb_input_streams; i++)\n\n                if (input_streams[i]->st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n\n                    new_subtitle_stream(o, oc, i);\n\n                    break;\n\n                }\n\n        }\n\n        /* do something with data? */\n\n    } else {\n\n        for (i = 0; i < o->nb_stream_maps; i++) {\n\n            StreamMap *map = &o->stream_maps[i];\n\n\n\n            if (map->disabled)\n\n                continue;\n\n\n\n            if (map->linklabel) {\n\n                FilterGraph *fg;\n\n                OutputFilter *ofilter = NULL;\n\n                int j, k;\n\n\n\n                for (j = 0; j < nb_filtergraphs; j++) {\n\n                    fg = filtergraphs[j];\n\n                    for (k = 0; k < fg->nb_outputs; k++) {\n\n                        AVFilterInOut *out = fg->outputs[k]->out_tmp;\n\n                        if (out && !strcmp(out->name, map->linklabel)) {\n\n                            ofilter = fg->outputs[k];\n\n                            goto loop_end;\n\n                        }\n\n                    }\n\n                }\n\nloop_end:\n\n                if (!ofilter) {\n\n                    av_log(NULL, AV_LOG_FATAL, \"Output with label '%s' does not exist \"\n\n                           \"in any defined filter graph, or was already used elsewhere.\\n\", map->linklabel);\n\n                    exit_program(1);\n\n                }\n\n                init_output_filter(ofilter, o, oc);\n\n            } else {\n\n                int src_idx = input_files[map->file_index]->ist_index + map->stream_index;\n\n\n\n                ist = input_streams[input_files[map->file_index]->ist_index + map->stream_index];\n\n                if(o->subtitle_disable && ist->st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE)\n\n                    continue;\n\n                if(o->   audio_disable && ist->st->codec->codec_type == AVMEDIA_TYPE_AUDIO)\n\n                    continue;\n\n                if(o->   video_disable && ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n                    continue;\n\n                if(o->    data_disable && ist->st->codec->codec_type == AVMEDIA_TYPE_DATA)\n\n                    continue;\n\n\n\n                switch (ist->st->codec->codec_type) {\n\n                case AVMEDIA_TYPE_VIDEO:      ost = new_video_stream     (o, oc, src_idx); break;\n\n                case AVMEDIA_TYPE_AUDIO:      ost = new_audio_stream     (o, oc, src_idx); break;\n\n                case AVMEDIA_TYPE_SUBTITLE:   ost = new_subtitle_stream  (o, oc, src_idx); break;\n\n                case AVMEDIA_TYPE_DATA:       ost = new_data_stream      (o, oc, src_idx); break;\n\n                case AVMEDIA_TYPE_ATTACHMENT: ost = new_attachment_stream(o, oc, src_idx); break;\n\n                default:\n\n                    av_log(NULL, AV_LOG_FATAL, \"Cannot map stream #%d:%d - unsupported type.\\n\",\n\n                           map->file_index, map->stream_index);\n\n                    exit_program(1);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    /* handle attached files */\n\n    for (i = 0; i < o->nb_attachments; i++) {\n\n        AVIOContext *pb;\n\n        uint8_t *attachment;\n\n        const char *p;\n\n        int64_t len;\n\n\n\n        if ((err = avio_open2(&pb, o->attachments[i], AVIO_FLAG_READ, &int_cb, NULL)) < 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Could not open attachment file %s.\\n\",\n\n                   o->attachments[i]);\n\n            exit_program(1);\n\n        }\n\n        if ((len = avio_size(pb)) <= 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Could not get size of the attachment %s.\\n\",\n\n                   o->attachments[i]);\n\n            exit_program(1);\n\n        }\n\n        if (!(attachment = av_malloc(len))) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Attachment %s too large to fit into memory.\\n\",\n\n                   o->attachments[i]);\n\n            exit_program(1);\n\n        }\n\n        avio_read(pb, attachment, len);\n\n\n\n        ost = new_attachment_stream(o, oc, -1);\n\n        ost->stream_copy               = 0;\n\n        ost->attachment_filename       = o->attachments[i];\n\n        ost->finished                  = 1;\n\n        ost->st->codec->extradata      = attachment;\n\n        ost->st->codec->extradata_size = len;\n\n\n\n        p = strrchr(o->attachments[i], '/');\n\n        av_dict_set(&ost->st->metadata, \"filename\", (p && *p) ? p + 1 : o->attachments[i], AV_DICT_DONT_OVERWRITE);\n\n        avio_close(pb);\n\n    }\n\n\n\n    for (i = nb_output_streams - oc->nb_streams; i < nb_output_streams; i++) { //for all streams of this output file\n\n        AVDictionaryEntry *e;\n\n        ost = output_streams[i];\n\n\n\n        if ((ost->stream_copy || ost->attachment_filename)\n\n            && (e = av_dict_get(o->g->codec_opts, \"flags\", NULL, AV_DICT_IGNORE_SUFFIX))\n\n            && (!e->key[5] || check_stream_specifier(oc, ost->st, e->key+6)))\n\n            if (av_opt_set(ost->st->codec, \"flags\", e->value, 0) < 0)\n\n                exit_program(1);\n\n    }\n\n\n\n    /* check if all codec options have been used */\n\n    unused_opts = strip_specifiers(o->g->codec_opts);\n\n    for (i = of->ost_index; i < nb_output_streams; i++) {\n\n        e = NULL;\n\n        while ((e = av_dict_get(output_streams[i]->opts, \"\", e,\n\n                                AV_DICT_IGNORE_SUFFIX)))\n\n            av_dict_set(&unused_opts, e->key, NULL, 0);\n\n    }\n\n\n\n    e = NULL;\n\n    while ((e = av_dict_get(unused_opts, \"\", e, AV_DICT_IGNORE_SUFFIX))) {\n\n        const AVClass *class = avcodec_get_class();\n\n        const AVOption *option = av_opt_find(&class, e->key, NULL, 0,\n\n                                             AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ);\n\n        if (!option)\n\n            continue;\n\n        if (!(option->flags & AV_OPT_FLAG_ENCODING_PARAM)) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Codec AVOption %s (%s) specified for \"\n\n                   \"output file #%d (%s) is not an encoding option.\\n\", e->key,\n\n                   option->help ? option->help : \"\", nb_output_files - 1,\n\n                   filename);\n\n            exit_program(1);\n\n        }\n\n\n\n        // gop_timecode is injected by generic code but not always used\n\n        if (!strcmp(e->key, \"gop_timecode\"))\n\n            continue;\n\n\n\n        av_log(NULL, AV_LOG_WARNING, \"Codec AVOption %s (%s) specified for \"\n\n               \"output file #%d (%s) has not been used for any stream. The most \"\n\n               \"likely reason is either wrong type (e.g. a video option with \"\n\n               \"no video streams) or that it is a private option of some encoder \"\n\n               \"which was not actually used for any stream.\\n\", e->key,\n\n               option->help ? option->help : \"\", nb_output_files - 1, filename);\n\n    }\n\n    av_dict_free(&unused_opts);\n\n\n\n    /* check filename in case of an image number is expected */\n\n    if (oc->oformat->flags & AVFMT_NEEDNUMBER) {\n\n        if (!av_filename_number_test(oc->filename)) {\n\n            print_error(oc->filename, AVERROR(EINVAL));\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    if (!(oc->oformat->flags & AVFMT_NOFILE)) {\n\n        /* test if it already exists to avoid losing precious files */\n\n        assert_file_overwrite(filename);\n\n\n\n        /* open the file */\n\n        if ((err = avio_open2(&oc->pb, filename, AVIO_FLAG_WRITE,\n\n                              &oc->interrupt_callback,\n\n                              &of->opts)) < 0) {\n\n            print_error(filename, err);\n\n            exit_program(1);\n\n        }\n\n    } else if (strcmp(oc->oformat->name, \"image2\")==0 && !av_filename_number_test(filename))\n\n        assert_file_overwrite(filename);\n\n\n\n    if (o->mux_preload) {\n\n        uint8_t buf[64];\n\n        snprintf(buf, sizeof(buf), \"%d\", (int)(o->mux_preload*AV_TIME_BASE));\n\n        av_dict_set(&of->opts, \"preload\", buf, 0);\n\n    }\n\n    oc->max_delay = (int)(o->mux_max_delay * AV_TIME_BASE);\n\n\n\n    /* copy metadata */\n\n    for (i = 0; i < o->nb_metadata_map; i++) {\n\n        char *p;\n\n        int in_file_index = strtol(o->metadata_map[i].u.str, &p, 0);\n\n\n\n        if (in_file_index >= nb_input_files) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Invalid input file index %d while processing metadata maps\\n\", in_file_index);\n\n            exit_program(1);\n\n        }\n\n        copy_metadata(o->metadata_map[i].specifier, *p ? p + 1 : p, oc,\n\n                      in_file_index >= 0 ?\n\n                      input_files[in_file_index]->ctx : NULL, o);\n\n    }\n\n\n\n    /* copy chapters */\n\n    if (o->chapters_input_file >= nb_input_files) {\n\n        if (o->chapters_input_file == INT_MAX) {\n\n            /* copy chapters from the first input file that has them*/\n\n            o->chapters_input_file = -1;\n\n            for (i = 0; i < nb_input_files; i++)\n\n                if (input_files[i]->ctx->nb_chapters) {\n\n                    o->chapters_input_file = i;\n\n                    break;\n\n                }\n\n        } else {\n\n            av_log(NULL, AV_LOG_FATAL, \"Invalid input file index %d in chapter mapping.\\n\",\n\n                   o->chapters_input_file);\n\n            exit_program(1);\n\n        }\n\n    }\n\n    if (o->chapters_input_file >= 0)\n\n        copy_chapters(input_files[o->chapters_input_file], of,\n\n                      !o->metadata_chapters_manual);\n\n\n\n    /* copy global metadata by default */\n\n    if (!o->metadata_global_manual && nb_input_files){\n\n        av_dict_copy(&oc->metadata, input_files[0]->ctx->metadata,\n\n                     AV_DICT_DONT_OVERWRITE);\n\n        if(o->recording_time != INT64_MAX)\n\n            av_dict_set(&oc->metadata, \"duration\", NULL, 0);\n\n        av_dict_set(&oc->metadata, \"creation_time\", NULL, 0);\n\n    }\n\n    if (!o->metadata_streams_manual)\n\n        for (i = of->ost_index; i < nb_output_streams; i++) {\n\n            InputStream *ist;\n\n            if (output_streams[i]->source_index < 0)         /* this is true e.g. for attached files */\n\n                continue;\n\n            ist = input_streams[output_streams[i]->source_index];\n\n            av_dict_copy(&output_streams[i]->st->metadata, ist->st->metadata, AV_DICT_DONT_OVERWRITE);\n\n        }\n\n\n\n    /* process manually set metadata */\n\n    for (i = 0; i < o->nb_metadata; i++) {\n\n        AVDictionary **m;\n\n        char type, *val;\n\n        const char *stream_spec;\n\n        int index = 0, j, ret = 0;\n\n\n\n        val = strchr(o->metadata[i].u.str, '=');\n\n        if (!val) {\n\n            av_log(NULL, AV_LOG_FATAL, \"No '=' character in metadata string %s.\\n\",\n\n                   o->metadata[i].u.str);\n\n            exit_program(1);\n\n        }\n\n        *val++ = 0;\n\n\n\n        parse_meta_type(o->metadata[i].specifier, &type, &index, &stream_spec);\n\n        if (type == 's') {\n\n            for (j = 0; j < oc->nb_streams; j++) {\n\n                if ((ret = check_stream_specifier(oc, oc->streams[j], stream_spec)) > 0) {\n\n                    av_dict_set(&oc->streams[j]->metadata, o->metadata[i].u.str, *val ? val : NULL, 0);\n\n                } else if (ret < 0)\n\n                    exit_program(1);\n\n            }\n\n        }\n\n        else {\n\n            switch (type) {\n\n            case 'g':\n\n                m = &oc->metadata;\n\n                break;\n\n            case 'c':\n\n                if (index < 0 || index >= oc->nb_chapters) {\n\n                    av_log(NULL, AV_LOG_FATAL, \"Invalid chapter index %d in metadata specifier.\\n\", index);\n\n                    exit_program(1);\n\n                }\n\n                m = &oc->chapters[index]->metadata;\n\n                break;\n\n            default:\n\n                av_log(NULL, AV_LOG_FATAL, \"Invalid metadata specifier %s.\\n\", o->metadata[i].specifier);\n\n                exit_program(1);\n\n            }\n\n            av_dict_set(m, o->metadata[i].u.str, *val ? val : NULL, 0);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 2365, "_split": "test", "_hash": "43c9bc6feea027673e8de5e9760b179e"}
{"project": "FFmpeg", "commit_id": "1cb4ef526dd1e5f547d0354efb0831d07e967919", "target": 1, "func": "static int add_candidate_ref(HEVCContext *s, RefPicList *list,\n\n                             int poc, int ref_flag)\n\n{\n\n    HEVCFrame *ref = find_ref_idx(s, poc);\n\n\n\n    if (ref == s->ref)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (!ref) {\n\n        ref = generate_missing_ref(s, poc);\n\n        if (!ref)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    list->list[list->nb_refs] = ref->poc;\n\n    list->ref[list->nb_refs]  = ref;\n\n    list->nb_refs++;\n\n\n\n    mark_ref(ref, ref_flag);\n\n    return 0;\n\n}\n", "idx": 2400, "_split": "test", "_hash": "f7f28d814946d33a8121d9e3bd675324"}
{"project": "FFmpeg", "commit_id": "b9fa32082c71013e90eab9e9997967d2939cf4a6", "target": 1, "func": "static int vorbis_parse_id_hdr(vorbis_context *vc){\n\n    GetBitContext *gb=&vc->gb;\n\n    uint_fast8_t bl0, bl1;\n\n\n\n    if ((get_bits(gb, 8)!='v') || (get_bits(gb, 8)!='o') ||\n\n    (get_bits(gb, 8)!='r') || (get_bits(gb, 8)!='b') ||\n\n    (get_bits(gb, 8)!='i') || (get_bits(gb, 8)!='s')) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \" Vorbis id header packet corrupt (no vorbis signature). \\n\");\n\n        return 1;\n\n    }\n\n\n\n    vc->version=get_bits_long(gb, 32);    //FIXME check 0\n\n    vc->audio_channels=get_bits(gb, 8);   //FIXME check >0\n\n    vc->audio_samplerate=get_bits_long(gb, 32);   //FIXME check >0\n\n    vc->bitrate_maximum=get_bits_long(gb, 32);\n\n    vc->bitrate_nominal=get_bits_long(gb, 32);\n\n    vc->bitrate_minimum=get_bits_long(gb, 32);\n\n    bl0=get_bits(gb, 4);\n\n    bl1=get_bits(gb, 4);\n\n    vc->blocksize[0]=(1<<bl0);\n\n    vc->blocksize[1]=(1<<bl1);\n\n    if (bl0>13 || bl0<6 || bl1>13 || bl1<6 || bl1<bl0) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \" Vorbis id header packet corrupt (illegal blocksize). \\n\");\n\n        return 3;\n\n    }\n\n    // output format int16\n\n    if (vc->blocksize[1]/2 * vc->audio_channels * 2 >\n\n                                             AVCODEC_MAX_AUDIO_FRAME_SIZE) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \"Vorbis channel count makes \"\n\n               \"output packets too large.\\n\");\n\n        return 4;\n\n    }\n\n    vc->win[0]=ff_vorbis_vwin[bl0-6];\n\n    vc->win[1]=ff_vorbis_vwin[bl1-6];\n\n\n\n    if(vc->exp_bias){\n\n        int i, j;\n\n        for(j=0; j<2; j++){\n\n            float *win = av_malloc(vc->blocksize[j]/2 * sizeof(float));\n\n            for(i=0; i<vc->blocksize[j]/2; i++)\n\n                win[i] = vc->win[j][i] * (1<<15);\n\n            vc->win[j] = win;\n\n        }\n\n    }\n\n\n\n    if ((get_bits1(gb)) == 0) {\n\n        av_log(vc->avccontext, AV_LOG_ERROR, \" Vorbis id header packet corrupt (framing flag not set). \\n\");\n\n        return 2;\n\n    }\n\n\n\n    vc->channel_residues= av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->channel_floors  = av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->saved           = av_mallocz((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->ret             = av_malloc((vc->blocksize[1]/2)*vc->audio_channels * sizeof(float));\n\n    vc->buf             = av_malloc( vc->blocksize[1]                       * sizeof(float));\n\n    vc->buf_tmp         = av_malloc( vc->blocksize[1]                       * sizeof(float));\n\n    vc->previous_window=0;\n\n\n\n    ff_mdct_init(&vc->mdct[0], bl0, 1);\n\n    ff_mdct_init(&vc->mdct[1], bl1, 1);\n\n\n\n    AV_DEBUG(\" vorbis version %d \\n audio_channels %d \\n audio_samplerate %d \\n bitrate_max %d \\n bitrate_nom %d \\n bitrate_min %d \\n blk_0 %d blk_1 %d \\n \",\n\n            vc->version, vc->audio_channels, vc->audio_samplerate, vc->bitrate_maximum, vc->bitrate_nominal, vc->bitrate_minimum, vc->blocksize[0], vc->blocksize[1]);\n\n\n\n/*\n\n    BLK=vc->blocksize[0];\n\n    for(i=0;i<BLK/2;++i) {\n\n        vc->win[0][i]=sin(0.5*3.14159265358*(sin(((float)i+0.5)/(float)BLK*3.14159265358))*(sin(((float)i+0.5)/(float)BLK*3.14159265358)));\n\n    }\n\n*/\n\n\n\n    return 0;\n\n}\n", "idx": 2424, "_split": "test", "_hash": "507ad9da9375434e674d7e3c891f5b5b"}
{"project": "FFmpeg", "commit_id": "1181d93231e9b807965724587d363c1cfd5a1d0d", "target": 0, "func": "void ff_avg_h264_qpel4_mc31_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_and_aver_dst_4x4_msa(src - 2,\n\n                                         src - (stride * 2) +\n\n                                         sizeof(uint8_t), stride, dst, stride);\n\n}\n", "idx": 2429, "_split": "test", "_hash": "aee52beb629a7c5c65b88d7748e32401"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int flv_probe(AVProbeData *p)\n\n{\n\n    const uint8_t *d;\n\n\n\n    if (p->buf_size < 6)\n\n        return 0;\n\n    d = p->buf;\n\n    if (d[0] == 'F' && d[1] == 'L' && d[2] == 'V' && d[3] < 5 && d[5]==0) {\n\n        return AVPROBE_SCORE_MAX;\n\n    }\n\n    return 0;\n\n}\n", "idx": 2466, "_split": "test", "_hash": "ffc1a56fc2e1712f67501148491f88db"}
{"project": "FFmpeg", "commit_id": "13ccba50d45662a15777b549b2fcd9b4621b0e01", "target": 0, "func": "static void opt_output_file(void *optctx, const char *filename)\n\n{\n\n    OptionsContext *o = optctx;\n\n    AVFormatContext *oc;\n\n    int i, err;\n\n    AVOutputFormat *file_oformat;\n\n    OutputStream *ost;\n\n    InputStream  *ist;\n\n\n\n    if (!strcmp(filename, \"-\"))\n\n        filename = \"pipe:\";\n\n\n\n    oc = avformat_alloc_context();\n\n    if (!oc) {\n\n        print_error(filename, AVERROR(ENOMEM));\n\n        exit_program(1);\n\n    }\n\n\n\n    if (last_asked_format) {\n\n        file_oformat = av_guess_format(last_asked_format, NULL, NULL);\n\n        if (!file_oformat) {\n\n            fprintf(stderr, \"Requested output format '%s' is not a suitable output format\\n\", last_asked_format);\n\n            exit_program(1);\n\n        }\n\n        last_asked_format = NULL;\n\n    } else {\n\n        file_oformat = av_guess_format(NULL, filename, NULL);\n\n        if (!file_oformat) {\n\n            fprintf(stderr, \"Unable to find a suitable output format for '%s'\\n\",\n\n                    filename);\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    oc->oformat = file_oformat;\n\n    av_strlcpy(oc->filename, filename, sizeof(oc->filename));\n\n\n\n    if (!strcmp(file_oformat->name, \"ffm\") &&\n\n        av_strstart(filename, \"http:\", NULL)) {\n\n        /* special case for files sent to avserver: we get the stream\n\n           parameters from avserver */\n\n        int err = read_avserver_streams(oc, filename);\n\n        if (err < 0) {\n\n            print_error(filename, err);\n\n            exit_program(1);\n\n        }\n\n    } else if (!o->nb_stream_maps) {\n\n        /* pick the \"best\" stream of each type */\n\n#define NEW_STREAM(type, index)\\\n\n        if (index >= 0) {\\\n\n            ost = new_ ## type ## _stream(oc);\\\n\n            ost->source_index = index;\\\n\n            ost->sync_ist     = &input_streams[index];\\\n\n            input_streams[index].discard = 0;\\\n\n        }\n\n\n\n        /* video: highest resolution */\n\n        if (!video_disable && oc->oformat->video_codec != CODEC_ID_NONE) {\n\n            int area = 0, idx = -1;\n\n            for (i = 0; i < nb_input_streams; i++) {\n\n                ist = &input_streams[i];\n\n                if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n                    ist->st->codec->width * ist->st->codec->height > area) {\n\n                    area = ist->st->codec->width * ist->st->codec->height;\n\n                    idx = i;\n\n                }\n\n            }\n\n            NEW_STREAM(video, idx);\n\n        }\n\n\n\n        /* audio: most channels */\n\n        if (!audio_disable && oc->oformat->audio_codec != CODEC_ID_NONE) {\n\n            int channels = 0, idx = -1;\n\n            for (i = 0; i < nb_input_streams; i++) {\n\n                ist = &input_streams[i];\n\n                if (ist->st->codec->codec_type == AVMEDIA_TYPE_AUDIO &&\n\n                    ist->st->codec->channels > channels) {\n\n                    channels = ist->st->codec->channels;\n\n                    idx = i;\n\n                }\n\n            }\n\n            NEW_STREAM(audio, idx);\n\n        }\n\n\n\n        /* subtitles: pick first */\n\n        if (!subtitle_disable && oc->oformat->subtitle_codec != CODEC_ID_NONE) {\n\n            for (i = 0; i < nb_input_streams; i++)\n\n                if (input_streams[i].st->codec->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n\n                    NEW_STREAM(subtitle, i);\n\n                    break;\n\n                }\n\n        }\n\n        /* do something with data? */\n\n    } else {\n\n        for (i = 0; i < o->nb_stream_maps; i++) {\n\n            StreamMap *map = &o->stream_maps[i];\n\n\n\n            if (map->disabled)\n\n                continue;\n\n\n\n            ist = &input_streams[input_files[map->file_index].ist_index + map->stream_index];\n\n            switch (ist->st->codec->codec_type) {\n\n            case AVMEDIA_TYPE_VIDEO:    ost = new_video_stream(oc);    break;\n\n            case AVMEDIA_TYPE_AUDIO:    ost = new_audio_stream(oc);    break;\n\n            case AVMEDIA_TYPE_SUBTITLE: ost = new_subtitle_stream(oc); break;\n\n            case AVMEDIA_TYPE_DATA:     ost = new_data_stream(oc);     break;\n\n            default:\n\n                av_log(NULL, AV_LOG_ERROR, \"Cannot map stream #%d.%d - unsupported type.\\n\",\n\n                       map->file_index, map->stream_index);\n\n                exit_program(1);\n\n            }\n\n\n\n            ost->source_index = input_files[map->file_index].ist_index + map->stream_index;\n\n            ost->sync_ist = &input_streams[input_files[map->sync_file_index].ist_index +\n\n                                           map->sync_stream_index];\n\n            ist->discard = 0;\n\n        }\n\n    }\n\n\n\n    av_dict_copy(&oc->metadata, metadata, 0);\n\n    av_dict_free(&metadata);\n\n\n\n\n\n    output_files = grow_array(output_files, sizeof(*output_files), &nb_output_files, nb_output_files + 1);\n\n    output_files[nb_output_files - 1].ctx       = oc;\n\n    output_files[nb_output_files - 1].ost_index = nb_output_streams - oc->nb_streams;\n\n    output_files[nb_output_files - 1].recording_time = o->recording_time;\n\n    output_files[nb_output_files - 1].start_time     = o->start_time;\n\n    output_files[nb_output_files - 1].limit_filesize = limit_filesize;\n\n    av_dict_copy(&output_files[nb_output_files - 1].opts, format_opts, 0);\n\n\n\n    /* check filename in case of an image number is expected */\n\n    if (oc->oformat->flags & AVFMT_NEEDNUMBER) {\n\n        if (!av_filename_number_test(oc->filename)) {\n\n            print_error(oc->filename, AVERROR(EINVAL));\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    if (!(oc->oformat->flags & AVFMT_NOFILE)) {\n\n        /* test if it already exists to avoid loosing precious files */\n\n        if (!file_overwrite &&\n\n            (strchr(filename, ':') == NULL ||\n\n             filename[1] == ':' ||\n\n             av_strstart(filename, \"file:\", NULL))) {\n\n            if (avio_check(filename, 0) == 0) {\n\n                if (!using_stdin) {\n\n                    fprintf(stderr,\"File '%s' already exists. Overwrite ? [y/N] \", filename);\n\n                    fflush(stderr);\n\n                    if (!read_yesno()) {\n\n                        fprintf(stderr, \"Not overwriting - exiting\\n\");\n\n                        exit_program(1);\n\n                    }\n\n                }\n\n                else {\n\n                    fprintf(stderr,\"File '%s' already exists. Exiting.\\n\", filename);\n\n                    exit_program(1);\n\n                }\n\n            }\n\n        }\n\n\n\n        /* open the file */\n\n        if ((err = avio_open(&oc->pb, filename, AVIO_FLAG_WRITE)) < 0) {\n\n            print_error(filename, err);\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    oc->preload= (int)(mux_preload*AV_TIME_BASE);\n\n    oc->max_delay= (int)(mux_max_delay*AV_TIME_BASE);\n\n    oc->flags |= AVFMT_FLAG_NONBLOCK;\n\n\n\n    /* copy chapters */\n\n    if (chapters_input_file >= nb_input_files) {\n\n        if (chapters_input_file == INT_MAX) {\n\n            /* copy chapters from the first input file that has them*/\n\n            chapters_input_file = -1;\n\n            for (i = 0; i < nb_input_files; i++)\n\n                if (input_files[i].ctx->nb_chapters) {\n\n                    chapters_input_file = i;\n\n                    break;\n\n                }\n\n        } else {\n\n            av_log(NULL, AV_LOG_ERROR, \"Invalid input file index %d in chapter mapping.\\n\",\n\n                   chapters_input_file);\n\n            exit_program(1);\n\n        }\n\n    }\n\n    if (chapters_input_file >= 0)\n\n        copy_chapters(&input_files[chapters_input_file], &output_files[nb_output_files - 1]);\n\n\n\n    /* copy metadata */\n\n    for (i = 0; i < nb_meta_data_maps; i++) {\n\n        AVFormatContext *files[2];\n\n        AVDictionary    **meta[2];\n\n        int j;\n\n\n\n#define METADATA_CHECK_INDEX(index, nb_elems, desc)\\\n\n        if ((index) < 0 || (index) >= (nb_elems)) {\\\n\n            av_log(NULL, AV_LOG_ERROR, \"Invalid %s index %d while processing metadata maps\\n\",\\\n\n                     (desc), (index));\\\n\n            exit_program(1);\\\n\n        }\n\n\n\n        int in_file_index = meta_data_maps[i][1].file;\n\n        if (in_file_index < 0)\n\n            continue;\n\n        METADATA_CHECK_INDEX(in_file_index, nb_input_files, \"input file\")\n\n\n\n        files[0] = oc;\n\n        files[1] = input_files[in_file_index].ctx;\n\n\n\n        for (j = 0; j < 2; j++) {\n\n            MetadataMap *map = &meta_data_maps[i][j];\n\n\n\n            switch (map->type) {\n\n            case 'g':\n\n                meta[j] = &files[j]->metadata;\n\n                break;\n\n            case 's':\n\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_streams, \"stream\")\n\n                meta[j] = &files[j]->streams[map->index]->metadata;\n\n                break;\n\n            case 'c':\n\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_chapters, \"chapter\")\n\n                meta[j] = &files[j]->chapters[map->index]->metadata;\n\n                break;\n\n            case 'p':\n\n                METADATA_CHECK_INDEX(map->index, files[j]->nb_programs, \"program\")\n\n                meta[j] = &files[j]->programs[map->index]->metadata;\n\n                break;\n\n            }\n\n        }\n\n\n\n        av_dict_copy(meta[0], *meta[1], AV_DICT_DONT_OVERWRITE);\n\n    }\n\n\n\n    /* copy global metadata by default */\n\n    if (metadata_global_autocopy && nb_input_files)\n\n        av_dict_copy(&oc->metadata, input_files[0].ctx->metadata,\n\n                     AV_DICT_DONT_OVERWRITE);\n\n    if (metadata_streams_autocopy)\n\n        for (i = output_files[nb_output_files - 1].ost_index; i < nb_output_streams; i++) {\n\n            InputStream *ist = &input_streams[output_streams[i].source_index];\n\n            av_dict_copy(&output_streams[i].st->metadata, ist->st->metadata, AV_DICT_DONT_OVERWRITE);\n\n        }\n\n\n\n    frame_rate    = (AVRational){0, 0};\n\n    frame_width   = 0;\n\n    frame_height  = 0;\n\n    audio_sample_rate = 0;\n\n    audio_channels    = 0;\n\n    audio_sample_fmt  = AV_SAMPLE_FMT_NONE;\n\n    chapters_input_file = INT_MAX;\n\n    limit_filesize = UINT64_MAX;\n\n\n\n    av_freep(&meta_data_maps);\n\n    nb_meta_data_maps = 0;\n\n    metadata_global_autocopy   = 1;\n\n    metadata_streams_autocopy  = 1;\n\n    metadata_chapters_autocopy = 1;\n\n    av_freep(&streamid_map);\n\n    nb_streamid_map = 0;\n\n\n\n    av_dict_free(&codec_names);\n\n\n\n    av_freep(&forced_key_frames);\n\n    reset_options(o);\n\n}\n", "idx": 2502, "_split": "test", "_hash": "3c23036d080923a0dc5119f0c619136c"}
{"project": "FFmpeg", "commit_id": "52a213865670ae69c1852d4d04cf41f8929abbd0", "target": 0, "func": "static int read_gab2_sub(AVStream *st, AVPacket *pkt)\n\n{\n\n    if (pkt->size >= 7 &&\n\n        !strcmp(pkt->data, \"GAB2\") && AV_RL16(pkt->data + 5) == 2) {\n\n        uint8_t desc[256];\n\n        int score      = AVPROBE_SCORE_EXTENSION, ret;\n\n        AVIStream *ast = st->priv_data;\n\n        AVInputFormat *sub_demuxer;\n\n        AVRational time_base;\n\n        AVIOContext *pb = avio_alloc_context(pkt->data + 7,\n\n                                             pkt->size - 7,\n\n                                             0, NULL, NULL, NULL, NULL);\n\n        AVProbeData pd;\n\n        unsigned int desc_len = avio_rl32(pb);\n\n\n\n        if (desc_len > pb->buf_end - pb->buf_ptr)\n\n            goto error;\n\n\n\n        ret = avio_get_str16le(pb, desc_len, desc, sizeof(desc));\n\n        avio_skip(pb, desc_len - ret);\n\n        if (*desc)\n\n            av_dict_set(&st->metadata, \"title\", desc, 0);\n\n\n\n        avio_rl16(pb);   /* flags? */\n\n        avio_rl32(pb);   /* data size */\n\n\n\n        pd = (AVProbeData) { .buf      = pb->buf_ptr,\n\n                             .buf_size = pb->buf_end - pb->buf_ptr };\n\n        if (!(sub_demuxer = av_probe_input_format2(&pd, 1, &score)))\n\n            goto error;\n\n\n\n        if (!(ast->sub_ctx = avformat_alloc_context()))\n\n            goto error;\n\n\n\n        ast->sub_ctx->pb = pb;\n\n        if (!avformat_open_input(&ast->sub_ctx, \"\", sub_demuxer, NULL)) {\n\n            ff_read_packet(ast->sub_ctx, &ast->sub_pkt);\n\n            *st->codec = *ast->sub_ctx->streams[0]->codec;\n\n            ast->sub_ctx->streams[0]->codec->extradata = NULL;\n\n            time_base = ast->sub_ctx->streams[0]->time_base;\n\n            avpriv_set_pts_info(st, 64, time_base.num, time_base.den);\n\n        }\n\n        ast->sub_buffer = pkt->data;\n\n        memset(pkt, 0, sizeof(*pkt));\n\n        return 1;\n\n\n\nerror:\n\n        av_freep(&pb);\n\n    }\n\n    return 0;\n\n}\n", "idx": 2534, "_split": "test", "_hash": "69d8eef8a1573872cb4098148657bf46"}
{"project": "FFmpeg", "commit_id": "0b42631641d998e509cde6fa344edc6ab5cb4ac8", "target": 0, "func": "static int get_coc(Jpeg2000DecoderContext *s, Jpeg2000CodingStyle *c,\n\n                   uint8_t *properties)\n\n{\n\n    int compno;\n\n\n\n    if (s->buf_end - s->buf < 2)\n\n        return AVERROR(EINVAL);\n\n\n\n    compno = bytestream_get_byte(&s->buf);\n\n\n\n    c      += compno;\n\n    c->csty = bytestream_get_byte(&s->buf);\n\n    get_cox(s, c);\n\n\n\n    properties[compno] |= HAD_COC;\n\n    return 0;\n\n}\n", "idx": 2665, "_split": "test", "_hash": "44316d046959c1812551a94f511ef98c"}
{"project": "FFmpeg", "commit_id": "28bf81c90d36a55cf76e2be913c5215ebebf61f2", "target": 1, "func": "static inline void RENAME(hyscale)(uint16_t *dst, int dstWidth, uint8_t *src, int srcW, int xInc)\n\n{\n\n#ifdef HAVE_MMX\n\n\t// use the new MMX scaler if th mmx2 cant be used (its faster than the x86asm one)\n\n    if(sws_flags != SWS_FAST_BILINEAR || (!canMMX2BeUsed))\n\n#else\n\n    if(sws_flags != SWS_FAST_BILINEAR)\n\n#endif\n\n    {\n\n    \tRENAME(hScale)(dst, dstWidth, src, srcW, xInc, hLumFilter, hLumFilterPos, hLumFilterSize);\n\n    }\n\n    else // Fast Bilinear upscale / crap downscale\n\n    {\n\n#ifdef ARCH_X86\n\n#ifdef HAVE_MMX2\n\n\tint i;\n\n\tif(canMMX2BeUsed)\n\n\t{\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"pxor %%mm2, %%mm2\t\t\\n\\t\" // 2*xalpha\n\n\t\t\t\"movd %5, %%mm6\t\t\t\\n\\t\" // xInc&0xFFFF\n\n\t\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"psllq $16, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"psllq $16, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"paddw %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"psllq $16, %%mm2\t\t\\n\\t\" //0,t,2t,3t\t\tt=xInc&0xFF\n\n\t\t\t\"movq %%mm2, \"MANGLE(temp0)\"\t\\n\\t\"\n\n\t\t\t\"movd %4, %%mm6\t\t\t\\n\\t\" //(xInc*4)&0xFFFF\n\n\t\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\t\"punpcklwd %%mm6, %%mm6\t\t\\n\\t\"\n\n\t\t\t\"xorl %%eax, %%eax\t\t\\n\\t\" // i\n\n\t\t\t\"movl %0, %%esi\t\t\t\\n\\t\" // src\n\n\t\t\t\"movl %1, %%edi\t\t\t\\n\\t\" // buf1\n\n\t\t\t\"movl %3, %%edx\t\t\t\\n\\t\" // (xInc*4)>>16\n\n\t\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\"\n\n\t\t\t\"xorl %%ebx, %%ebx\t\t\\n\\t\"\n\n\t\t\t\"movw %4, %%bx\t\t\t\\n\\t\" // (xInc*4)&0xFFFF\n\n\n\n#define FUNNY_Y_CODE \\\n\n\t\t\tPREFETCH\" 1024(%%esi)\t\t\\n\\t\"\\\n\n\t\t\tPREFETCH\" 1056(%%esi)\t\t\\n\\t\"\\\n\n\t\t\tPREFETCH\" 1088(%%esi)\t\t\\n\\t\"\\\n\n\t\t\t\"call \"MANGLE(funnyYCode)\"\t\\n\\t\"\\\n\n\t\t\t\"movq \"MANGLE(temp0)\", %%mm2\t\\n\\t\"\\\n\n\t\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\"\n\n\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\nFUNNY_Y_CODE\n\n\n\n\t\t\t:: \"m\" (src), \"m\" (dst), \"m\" (dstWidth), \"m\" ((xInc*4)>>16),\n\n\t\t\t\"m\" ((xInc*4)&0xFFFF), \"m\" (xInc&0xFFFF)\n\n\t\t\t: \"%eax\", \"%ebx\", \"%ecx\", \"%edx\", \"%esi\", \"%edi\"\n\n\t\t);\n\n\t\tfor(i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) dst[i] = src[srcW-1]*128;\n\n\t}\n\n\telse\n\n\t{\n\n#endif\n\n\t//NO MMX just normal asm ...\n\n\tasm volatile(\n\n\t\t\"xorl %%eax, %%eax\t\t\\n\\t\" // i\n\n\t\t\"xorl %%ebx, %%ebx\t\t\\n\\t\" // xx\n\n\t\t\"xorl %%ecx, %%ecx\t\t\\n\\t\" // 2*xalpha\n\n\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"movzbl  (%0, %%ebx), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%0, %%ebx), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"movl %1, %%edi\t\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, (%%edi, %%eax, 2)\t\\n\\t\"\n\n\t\t\"addw %4, %%cx\t\t\t\\n\\t\" //2*xalpha += xInc&0xFF\n\n\t\t\"adcl %3, %%ebx\t\t\t\\n\\t\" //xx+= xInc>>8 + carry\n\n\n\n\t\t\"movzbl (%0, %%ebx), %%edi\t\\n\\t\" //src[xx]\n\n\t\t\"movzbl 1(%0, %%ebx), %%esi\t\\n\\t\" //src[xx+1]\n\n\t\t\"subl %%edi, %%esi\t\t\\n\\t\" //src[xx+1] - src[xx]\n\n\t\t\"imull %%ecx, %%esi\t\t\\n\\t\" //(src[xx+1] - src[xx])*2*xalpha\n\n\t\t\"shll $16, %%edi\t\t\\n\\t\"\n\n\t\t\"addl %%edi, %%esi\t\t\\n\\t\" //src[xx+1]*2*xalpha + src[xx]*(1-2*xalpha)\n\n\t\t\"movl %1, %%edi\t\t\t\\n\\t\"\n\n\t\t\"shrl $9, %%esi\t\t\t\\n\\t\"\n\n\t\t\"movw %%si, 2(%%edi, %%eax, 2)\t\\n\\t\"\n\n\t\t\"addw %4, %%cx\t\t\t\\n\\t\" //2*xalpha += xInc&0xFF\n\n\t\t\"adcl %3, %%ebx\t\t\t\\n\\t\" //xx+= xInc>>8 + carry\n\n\n\n\n\n\t\t\"addl $2, %%eax\t\t\t\\n\\t\"\n\n\t\t\"cmpl %2, %%eax\t\t\t\\n\\t\"\n\n\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n\n\n\t\t:: \"r\" (src), \"m\" (dst), \"m\" (dstWidth), \"m\" (xInc>>16), \"m\" (xInc&0xFFFF)\n\n\t\t: \"%eax\", \"%ebx\", \"%ecx\", \"%edi\", \"%esi\"\n\n\t\t);\n\n#ifdef HAVE_MMX2\n\n\t} //if MMX2 cant be used\n\n#endif\n\n#else\n\n\tint i;\n\n\tunsigned int xpos=0;\n\n\tfor(i=0;i<dstWidth;i++)\n\n\t{\n\n\t\tregister unsigned int xx=xpos>>16;\n\n\t\tregister unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n\t\tdst[i]= (src[xx]<<7) + (src[xx+1] - src[xx])*xalpha;\n\n\t\txpos+=xInc;\n\n\t}\n\n#endif\n\n    }\n\n}\n", "idx": 2677, "_split": "test", "_hash": "f8071fd98a9d2889f79e7e961c7e9a48"}
{"project": "FFmpeg", "commit_id": "c5f15f40b9b25f033fd9e8dd1e12763913098c11", "target": 1, "func": "static int h264_handle_packet(AVFormatContext *ctx, PayloadContext *data,\n\n                              AVStream *st, AVPacket *pkt, uint32_t *timestamp,\n\n                              const uint8_t *buf, int len, uint16_t seq,\n\n                              int flags)\n\n{\n\n    uint8_t nal;\n\n    uint8_t type;\n\n    int result = 0;\n\n\n\n    if (!len) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Empty H264 RTP packet\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    nal  = buf[0];\n\n    type = nal & 0x1f;\n\n\n\n    assert(data);\n\n    assert(buf);\n\n\n\n    /* Simplify the case (these are all the nal types used internally by\n\n     * the h264 codec). */\n\n    if (type >= 1 && type <= 23)\n\n        type = 1;\n\n    switch (type) {\n\n    case 0:                    // undefined, but pass them through\n\n    case 1:\n\n        av_new_packet(pkt, len + sizeof(start_sequence));\n\n        memcpy(pkt->data, start_sequence, sizeof(start_sequence));\n\n        memcpy(pkt->data + sizeof(start_sequence), buf, len);\n\n        COUNT_NAL_TYPE(data, nal);\n\n        break;\n\n\n\n    case 24:                   // STAP-A (one packet, multiple nals)\n\n        // consume the STAP-A NAL\n\n        buf++;\n\n        len--;\n\n        // first we are going to figure out the total size\n\n        {\n\n            int pass         = 0;\n\n            int total_length = 0;\n\n            uint8_t *dst     = NULL;\n\n\n\n            for (pass = 0; pass < 2; pass++) {\n\n                const uint8_t *src = buf;\n\n                int src_len        = len;\n\n\n\n                while (src_len > 2) {\n\n                    uint16_t nal_size = AV_RB16(src);\n\n\n\n                    // consume the length of the aggregate\n\n                    src     += 2;\n\n                    src_len -= 2;\n\n\n\n                    if (nal_size <= src_len) {\n\n                        if (pass == 0) {\n\n                            // counting\n\n                            total_length += sizeof(start_sequence) + nal_size;\n\n                        } else {\n\n                            // copying\n\n                            assert(dst);\n\n                            memcpy(dst, start_sequence, sizeof(start_sequence));\n\n                            dst += sizeof(start_sequence);\n\n                            memcpy(dst, src, nal_size);\n\n                            COUNT_NAL_TYPE(data, *src);\n\n                            dst += nal_size;\n\n                        }\n\n                    } else {\n\n                        av_log(ctx, AV_LOG_ERROR,\n\n                               \"nal size exceeds length: %d %d\\n\", nal_size, src_len);\n\n                    }\n\n\n\n                    // eat what we handled\n\n                    src     += nal_size;\n\n                    src_len -= nal_size;\n\n\n\n                    if (src_len < 0)\n\n                        av_log(ctx, AV_LOG_ERROR,\n\n                               \"Consumed more bytes than we got! (%d)\\n\", src_len);\n\n                }\n\n\n\n                if (pass == 0) {\n\n                    /* now we know the total size of the packet (with the\n\n                     * start sequences added) */\n\n                    av_new_packet(pkt, total_length);\n\n                    dst = pkt->data;\n\n                } else {\n\n                    assert(dst - pkt->data == total_length);\n\n                }\n\n            }\n\n        }\n\n        break;\n\n\n\n    case 25:                   // STAP-B\n\n    case 26:                   // MTAP-16\n\n    case 27:                   // MTAP-24\n\n    case 29:                   // FU-B\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Unhandled type (%d) (See RFC for implementation details\\n\",\n\n               type);\n\n        result = AVERROR(ENOSYS);\n\n        break;\n\n\n\n    case 28:                   // FU-A (fragmented nal)\n\n        buf++;\n\n        len--;                 // skip the fu_indicator\n\n        if (len > 1) {\n\n            // these are the same as above, we just redo them here for clarity\n\n            uint8_t fu_indicator      = nal;\n\n            uint8_t fu_header         = *buf;\n\n            uint8_t start_bit         = fu_header >> 7;\n\n            uint8_t av_unused end_bit = (fu_header & 0x40) >> 6;\n\n            uint8_t nal_type          = fu_header & 0x1f;\n\n            uint8_t reconstructed_nal;\n\n\n\n            // Reconstruct this packet's true nal; only the data follows.\n\n            /* The original nal forbidden bit and NRI are stored in this\n\n             * packet's nal. */\n\n            reconstructed_nal  = fu_indicator & 0xe0;\n\n            reconstructed_nal |= nal_type;\n\n\n\n            // skip the fu_header\n\n            buf++;\n\n            len--;\n\n\n\n            if (start_bit)\n\n                COUNT_NAL_TYPE(data, nal_type);\n\n            if (start_bit) {\n\n                /* copy in the start sequence, and the reconstructed nal */\n\n                av_new_packet(pkt, sizeof(start_sequence) + sizeof(nal) + len);\n\n                memcpy(pkt->data, start_sequence, sizeof(start_sequence));\n\n                pkt->data[sizeof(start_sequence)] = reconstructed_nal;\n\n                memcpy(pkt->data + sizeof(start_sequence) + sizeof(nal), buf, len);\n\n            } else {\n\n                av_new_packet(pkt, len);\n\n                memcpy(pkt->data, buf, len);\n\n            }\n\n        } else {\n\n            av_log(ctx, AV_LOG_ERROR, \"Too short data for FU-A H264 RTP packet\\n\");\n\n            result = AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n\n\n    case 30:                   // undefined\n\n    case 31:                   // undefined\n\n    default:\n\n        av_log(ctx, AV_LOG_ERROR, \"Undefined type (%d)\\n\", type);\n\n        result = AVERROR_INVALIDDATA;\n\n        break;\n\n    }\n\n\n\n    pkt->stream_index = st->index;\n\n\n\n    return result;\n\n}\n", "idx": 2704, "_split": "test", "_hash": "86b2725991d3551e02fb5eb1bba2676a"}
{"project": "FFmpeg", "commit_id": "1169f0d0afc0454633cfcfad73643f0458521c67", "target": 0, "func": "void ff_dnxhdenc_init_x86(DNXHDEncContext *ctx)\n\n{\n\n#if HAVE_INLINE_ASM\n\n    if (av_get_cpu_flags() & AV_CPU_FLAG_SSE2) {\n\n        if (ctx->cid_table->bit_depth == 8)\n\n            ctx->get_pixels_8x4_sym = get_pixels_8x4_sym_sse2;\n\n    }\n\n#endif /* HAVE_INLINE_ASM */\n\n}\n", "idx": 2793, "_split": "test", "_hash": "8c34b33e69f1c393eb7762f9e3211cae"}
{"project": "FFmpeg", "commit_id": "8bdba1092f50d52e0af90f425811302ec91152f8", "target": 1, "func": "int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n\n    const uint64_t fuzz_tag = FUZZ_TAG;\n\n    FuzzDataBuffer buffer;\n\n    const uint8_t *last = data;\n\n    const uint8_t *end = data + size;\n\n    uint32_t it = 0;\n\n\n\n    if (!c)\n\n        c = AVCodecInitialize(FFMPEG_CODEC);  // Done once.\n\n\n\n    AVCodecContext* ctx = avcodec_alloc_context3(NULL);\n\n    if (!ctx)\n\n        error(\"Failed memory allocation\");\n\n\n\n    ctx->max_pixels = 4096 * 4096; //To reduce false positive OOM and hangs\n\n\n\n    int res = avcodec_open2(ctx, c, NULL);\n\n    if (res < 0)\n\n        return res;\n\n\n\n    FDBCreate(&buffer);\n\n    int got_frame;\n\n    AVFrame *frame = av_frame_alloc();\n\n    if (!frame)\n\n        error(\"Failed memory allocation\");\n\n\n\n    // Read very simple container\n\n    AVPacket avpkt;\n\n    while (data < end && it < maxiteration) {\n\n        // Search for the TAG\n\n        while (data + sizeof(fuzz_tag) < end) {\n\n            if (data[0] == (fuzz_tag & 0xFF) && *(const uint64_t *)(data) == fuzz_tag)\n\n                break;\n\n            data++;\n\n        }\n\n        if (data + sizeof(fuzz_tag) > end)\n\n            data = end;\n\n\n\n        FDBPrepare(&buffer, &avpkt, last, data - last);\n\n        data += sizeof(fuzz_tag);\n\n        last = data;\n\n\n\n        // Iterate through all data\n\n        while (avpkt.size > 0 && it++ < maxiteration) {\n\n            av_frame_unref(frame);\n\n            int ret = decode_handler(ctx, frame, &got_frame, &avpkt);\n\n\n\n            if (it > 20)\n\n                ctx->error_concealment = 0;\n\n\n\n            if (ret <= 0 || ret > avpkt.size)\n\n               break;\n\n\n\n            avpkt.data += ret;\n\n            avpkt.size -= ret;\n\n        }\n\n    }\n\n\n\n    av_init_packet(&avpkt);\n\n    avpkt.data = NULL;\n\n    avpkt.size = 0;\n\n\n\n    do {\n\n        got_frame = 0;\n\n        decode_handler(ctx, frame, &got_frame, &avpkt);\n\n    } while (got_frame == 1 && it++ < maxiteration);\n\n\n\n    av_frame_free(&frame);\n\n    avcodec_free_context(&ctx);\n\n    av_freep(&ctx);\n\n    FDBDesroy(&buffer);\n\n    return 0;\n\n}", "idx": 2857, "_split": "test", "_hash": "73601faa6f020a067a24e7dcd4d4f917"}
{"project": "FFmpeg", "commit_id": "37013fd018ae02679f177f42245f3e0e3c12d587", "target": 0, "func": "static void audiogen(void *data, enum AVSampleFormat sample_fmt,\n\n                     int channels, int sample_rate, int nb_samples)\n\n{\n\n    int i, ch, k;\n\n    double v, f, a, ampa;\n\n    double tabf1[SWR_CH_MAX];\n\n    double tabf2[SWR_CH_MAX];\n\n    double taba[SWR_CH_MAX];\n\n    unsigned static rnd;\n\n\n\n#define PUT_SAMPLE set(data, ch, k, channels, sample_fmt, v);\n\n#define uint_rand(x) (x = x * 1664525 + 1013904223)\n\n#define dbl_rand(x) (uint_rand(x)*2.0 / (double)UINT_MAX - 1)\n\n    k = 0;\n\n\n\n    /* 1 second of single freq sinus at 1000 Hz */\n\n    a = 0;\n\n    for (i = 0; i < 1 * sample_rate && k < nb_samples; i++, k++) {\n\n        v = sin(a) * 0.30;\n\n        for (ch = 0; ch < channels; ch++)\n\n            PUT_SAMPLE\n\n        a += M_PI * 1000.0 * 2.0 / sample_rate;\n\n    }\n\n\n\n    /* 1 second of varying frequency between 100 and 10000 Hz */\n\n    a = 0;\n\n    for (i = 0; i < 1 * sample_rate && k < nb_samples; i++, k++) {\n\n        v = sin(a) * 0.30;\n\n        for (ch = 0; ch < channels; ch++)\n\n            PUT_SAMPLE\n\n        f  = 100.0 + (((10000.0 - 100.0) * i) / sample_rate);\n\n        a += M_PI * f * 2.0 / sample_rate;\n\n    }\n\n\n\n    /* 0.5 second of low amplitude white noise */\n\n    for (i = 0; i < sample_rate / 2 && k < nb_samples; i++, k++) {\n\n        v = dbl_rand(rnd) * 0.30;\n\n        for (ch = 0; ch < channels; ch++)\n\n            PUT_SAMPLE\n\n    }\n\n\n\n    /* 0.5 second of high amplitude white noise */\n\n    for (i = 0; i < sample_rate / 2 && k < nb_samples; i++, k++) {\n\n        v = dbl_rand(rnd);\n\n        for (ch = 0; ch < channels; ch++)\n\n            PUT_SAMPLE\n\n    }\n\n\n\n    /* 1 second of unrelated ramps for each channel */\n\n    for (ch = 0; ch < channels; ch++) {\n\n        taba[ch]  = 0;\n\n        tabf1[ch] = 100 + uint_rand(rnd) % 5000;\n\n        tabf2[ch] = 100 + uint_rand(rnd) % 5000;\n\n    }\n\n    for (i = 0; i < 1 * sample_rate && k < nb_samples; i++, k++) {\n\n        for (ch = 0; ch < channels; ch++) {\n\n            v = sin(taba[ch]) * 0.30;\n\n            PUT_SAMPLE\n\n            f = tabf1[ch] + (((tabf2[ch] - tabf1[ch]) * i) / sample_rate);\n\n            taba[ch] += M_PI * f * 2.0 / sample_rate;\n\n        }\n\n    }\n\n\n\n    /* 2 seconds of 500 Hz with varying volume */\n\n    a    = 0;\n\n    ampa = 0;\n\n    for (i = 0; i < 2 * sample_rate && k < nb_samples; i++, k++) {\n\n        for (ch = 0; ch < channels; ch++) {\n\n            double amp = (1.0 + sin(ampa)) * 0.15;\n\n            if (ch & 1)\n\n                amp = 0.30 - amp;\n\n            v = sin(a) * amp;\n\n            PUT_SAMPLE\n\n            a    += M_PI * 500.0 * 2.0 / sample_rate;\n\n            ampa += M_PI *  2.0 / sample_rate;\n\n        }\n\n    }\n\n}\n", "idx": 2929, "_split": "test", "_hash": "5a92744c0de96c0da643cb3ec4bf6d92"}
{"project": "FFmpeg", "commit_id": "ea97859c8c218b83ab747a7eabcb88ca446f6751", "target": 1, "func": "static void paint_mouse_pointer(AVFormatContext *s1, struct gdigrab *gdigrab)\n\n{\n\n    CURSORINFO ci = {0};\n\n\n\n#define CURSOR_ERROR(str)                 \\\n\n    if (!gdigrab->cursor_error_printed) {       \\\n\n        WIN32_API_ERROR(str);             \\\n\n        gdigrab->cursor_error_printed = 1;      \\\n\n    }\n\n\n\n    ci.cbSize = sizeof(ci);\n\n\n\n    if (GetCursorInfo(&ci)) {\n\n        HCURSOR icon = CopyCursor(ci.hCursor);\n\n        ICONINFO info;\n\n        POINT pos;\n\n        RECT clip_rect = gdigrab->clip_rect;\n\n        HWND hwnd = gdigrab->hwnd;\n\n        info.hbmMask = NULL;\n\n        info.hbmColor = NULL;\n\n\n\n        if (ci.flags != CURSOR_SHOWING)\n\n            return;\n\n\n\n        if (!icon) {\n\n            /* Use the standard arrow cursor as a fallback.\n\n             * You'll probably only hit this in Wine, which can't fetch\n\n             * the current system cursor. */\n\n            icon = CopyCursor(LoadCursor(NULL, IDC_ARROW));\n\n        }\n\n\n\n        if (!GetIconInfo(icon, &info)) {\n\n            CURSOR_ERROR(\"Could not get icon info\");\n\n            goto icon_error;\n\n        }\n\n\n\n        pos.x = ci.ptScreenPos.x - clip_rect.left - info.xHotspot;\n\n        pos.y = ci.ptScreenPos.y - clip_rect.top - info.yHotspot;\n\n\n\n        if (hwnd) {\n\n            RECT rect;\n\n\n\n            if (GetWindowRect(hwnd, &rect)) {\n\n                pos.x -= rect.left;\n\n                pos.y -= rect.top;\n\n            } else {\n\n                CURSOR_ERROR(\"Couldn't get window rectangle\");\n\n                goto icon_error;\n\n            }\n\n        }\n\n\n\n        av_log(s1, AV_LOG_DEBUG, \"Cursor pos (%li,%li) -> (%li,%li)\\n\",\n\n                ci.ptScreenPos.x, ci.ptScreenPos.y, pos.x, pos.y);\n\n\n\n        if (pos.x >= 0 && pos.x <= clip_rect.right - clip_rect.left &&\n\n                pos.y >= 0 && pos.y <= clip_rect.bottom - clip_rect.top) {\n\n            if (!DrawIcon(gdigrab->dest_hdc, pos.x, pos.y, icon))\n\n                CURSOR_ERROR(\"Couldn't draw icon\");\n\n        }\n\n\n\nicon_error:\n\n\n\n\n\n        if (icon)\n\n            DestroyCursor(icon);\n\n    } else {\n\n        CURSOR_ERROR(\"Couldn't get cursor info\");\n\n    }\n\n}", "idx": 2946, "_split": "test", "_hash": "6178daad8f00e562f7482c945926a4d7"}
{"project": "FFmpeg", "commit_id": "f43a16049ef07585789d311f314f236a314f91f7", "target": 0, "func": "int opt_cpuflags(const char *opt, const char *arg)\n\n{\n\n#define CPUFLAG_MMX2     (AV_CPU_FLAG_MMX      | AV_CPU_FLAG_MMX2)\n\n#define CPUFLAG_3DNOW    (AV_CPU_FLAG_3DNOW    | AV_CPU_FLAG_MMX)\n\n#define CPUFLAG_3DNOWEXT (AV_CPU_FLAG_3DNOWEXT | CPUFLAG_3DNOW)\n\n#define CPUFLAG_SSE      (AV_CPU_FLAG_SSE      | CPUFLAG_MMX2)\n\n#define CPUFLAG_SSE2     (AV_CPU_FLAG_SSE2     | CPUFLAG_SSE)\n\n#define CPUFLAG_SSE2SLOW (AV_CPU_FLAG_SSE2SLOW | CPUFLAG_SSE2)\n\n#define CPUFLAG_SSE3     (AV_CPU_FLAG_SSE3     | CPUFLAG_SSE2)\n\n#define CPUFLAG_SSE3SLOW (AV_CPU_FLAG_SSE3SLOW | CPUFLAG_SSE3)\n\n#define CPUFLAG_SSSE3    (AV_CPU_FLAG_SSSE3    | CPUFLAG_SSE3)\n\n#define CPUFLAG_SSE4     (AV_CPU_FLAG_SSE4     | CPUFLAG_SSSE3)\n\n#define CPUFLAG_SSE42    (AV_CPU_FLAG_SSE42    | CPUFLAG_SSE4)\n\n#define CPUFLAG_AVX      (AV_CPU_FLAG_AVX      | CPUFLAG_SSE42)\n\n#define CPUFLAG_XOP      (AV_CPU_FLAG_XOP      | CPUFLAG_AVX)\n\n#define CPUFLAG_FMA4     (AV_CPU_FLAG_FMA4     | CPUFLAG_AVX)\n\n    static const AVOption cpuflags_opts[] = {\n\n        { \"flags\"   , NULL, 0, AV_OPT_TYPE_FLAGS, { 0 }, INT64_MIN, INT64_MAX, .unit = \"flags\" },\n\n        { \"altivec\" , NULL, 0, AV_OPT_TYPE_CONST, { AV_CPU_FLAG_ALTIVEC  },    .unit = \"flags\" },\n\n        { \"mmx\"     , NULL, 0, AV_OPT_TYPE_CONST, { AV_CPU_FLAG_MMX      },    .unit = \"flags\" },\n\n        { \"mmx2\"    , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_MMX2         },    .unit = \"flags\" },\n\n        { \"sse\"     , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSE          },    .unit = \"flags\" },\n\n        { \"sse2\"    , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSE2         },    .unit = \"flags\" },\n\n        { \"sse2slow\", NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSE2SLOW     },    .unit = \"flags\" },\n\n        { \"sse3\"    , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSE3         },    .unit = \"flags\" },\n\n        { \"sse3slow\", NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSE3SLOW     },    .unit = \"flags\" },\n\n        { \"ssse3\"   , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSSE3        },    .unit = \"flags\" },\n\n        { \"atom\"    , NULL, 0, AV_OPT_TYPE_CONST, { AV_CPU_FLAG_ATOM     },    .unit = \"flags\" },\n\n        { \"sse4.1\"  , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSE4         },    .unit = \"flags\" },\n\n        { \"sse4.2\"  , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_SSE42        },    .unit = \"flags\" },\n\n        { \"avx\"     , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_AVX          },    .unit = \"flags\" },\n\n        { \"xop\"     , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_XOP          },    .unit = \"flags\" },\n\n        { \"fma4\"    , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_FMA4         },    .unit = \"flags\" },\n\n        { \"3dnow\"   , NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_3DNOW        },    .unit = \"flags\" },\n\n        { \"3dnowext\", NULL, 0, AV_OPT_TYPE_CONST, { CPUFLAG_3DNOWEXT     },    .unit = \"flags\" },\n\n        { NULL },\n\n    };\n\n    static const AVClass class = {\n\n        .class_name = \"cpuflags\",\n\n        .item_name  = av_default_item_name,\n\n        .option     = cpuflags_opts,\n\n        .version    = LIBAVUTIL_VERSION_INT,\n\n    };\n\n    int flags = av_get_cpu_flags();\n\n    int ret;\n\n    const AVClass *pclass = &class;\n\n\n\n    if ((ret = av_opt_eval_flags(&pclass, &cpuflags_opts[0], arg, &flags)) < 0)\n\n        return ret;\n\n\n\n    av_force_cpu_flags(flags);\n\n    return 0;\n\n}\n", "idx": 3054, "_split": "test", "_hash": "bb91512a23a17610e5549dc36661dfcf"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "void ff_put_h264_qpel8_mc21_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midv_qrt_8w_msa(src - (2 * stride) - 2, stride, dst, stride, 8, 0);\n\n}\n", "idx": 3065, "_split": "test", "_hash": "1f445482b4d30da96b6f602121a70809"}
{"project": "FFmpeg", "commit_id": "9924f1bc34242bb9315c355108f3ce744c1f33c5", "target": 0, "func": "static int mkv_write_header(AVFormatContext *s)\n\n{\n\n    MatroskaMuxContext *mkv = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    ebml_master ebml_header;\n\n    AVDictionaryEntry *tag;\n\n    int ret, i, version = 2;\n\n    int64_t creation_time;\n\n\n\n    if (!strcmp(s->oformat->name, \"webm\"))\n\n        mkv->mode = MODE_WEBM;\n\n    else\n\n        mkv->mode = MODE_MATROSKAv2;\n\n\n\n    if (mkv->mode != MODE_WEBM ||\n\n        av_dict_get(s->metadata, \"stereo_mode\", NULL, 0) ||\n\n        av_dict_get(s->metadata, \"alpha_mode\", NULL, 0))\n\n        version = 4;\n\n\n\n    if (s->nb_streams > MAX_TRACKS) {\n\n        av_log(s, AV_LOG_ERROR,\n\n               \"At most %d streams are supported for muxing in Matroska\\n\",\n\n               MAX_TRACKS);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        if (s->streams[i]->codecpar->codec_id == AV_CODEC_ID_ATRAC3 ||\n\n            s->streams[i]->codecpar->codec_id == AV_CODEC_ID_COOK ||\n\n            s->streams[i]->codecpar->codec_id == AV_CODEC_ID_RA_288 ||\n\n            s->streams[i]->codecpar->codec_id == AV_CODEC_ID_SIPR ||\n\n            s->streams[i]->codecpar->codec_id == AV_CODEC_ID_RV10 ||\n\n            s->streams[i]->codecpar->codec_id == AV_CODEC_ID_RV20) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"The Matroska muxer does not yet support muxing %s\\n\",\n\n                   avcodec_get_name(s->streams[i]->codecpar->codec_id));\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        if (s->streams[i]->codecpar->codec_id == AV_CODEC_ID_OPUS ||\n\n            av_dict_get(s->streams[i]->metadata, \"stereo_mode\", NULL, 0) ||\n\n            av_dict_get(s->streams[i]->metadata, \"alpha_mode\", NULL, 0))\n\n            version = 4;\n\n    }\n\n\n\n    mkv->tracks = av_mallocz_array(s->nb_streams, sizeof(*mkv->tracks));\n\n    if (!mkv->tracks) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    ebml_header = start_ebml_master(pb, EBML_ID_HEADER, 0);\n\n    put_ebml_uint   (pb, EBML_ID_EBMLVERSION        ,           1);\n\n    put_ebml_uint   (pb, EBML_ID_EBMLREADVERSION    ,           1);\n\n    put_ebml_uint   (pb, EBML_ID_EBMLMAXIDLENGTH    ,           4);\n\n    put_ebml_uint   (pb, EBML_ID_EBMLMAXSIZELENGTH  ,           8);\n\n    put_ebml_string (pb, EBML_ID_DOCTYPE            , s->oformat->name);\n\n    put_ebml_uint   (pb, EBML_ID_DOCTYPEVERSION     ,     version);\n\n    put_ebml_uint   (pb, EBML_ID_DOCTYPEREADVERSION ,           2);\n\n    end_ebml_master(pb, ebml_header);\n\n\n\n    mkv->segment = start_ebml_master(pb, MATROSKA_ID_SEGMENT, 0);\n\n    mkv->segment_offset = avio_tell(pb);\n\n\n\n    // we write 2 seek heads - one at the end of the file to point to each\n\n    // cluster, and one at the beginning to point to all other level one\n\n    // elements (including the seek head at the end of the file), which\n\n    // isn't more than 10 elements if we only write one of each other\n\n    // currently defined level 1 element\n\n    mkv->main_seekhead    = mkv_start_seekhead(pb, mkv->segment_offset, 10);\n\n    if (!mkv->main_seekhead) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    ret = mkv_add_seekhead_entry(mkv->main_seekhead, MATROSKA_ID_INFO, avio_tell(pb));\n\n    if (ret < 0) goto fail;\n\n\n\n    ret = start_ebml_master_crc32(pb, &mkv->info_bc, mkv, &mkv->info, MATROSKA_ID_INFO, 0);\n\n    if (ret < 0)\n\n        return ret;\n\n    pb = mkv->info_bc;\n\n\n\n    put_ebml_uint(pb, MATROSKA_ID_TIMECODESCALE, 1000000);\n\n    if ((tag = av_dict_get(s->metadata, \"title\", NULL, 0)))\n\n        put_ebml_string(pb, MATROSKA_ID_TITLE, tag->value);\n\n    if (!(s->flags & AVFMT_FLAG_BITEXACT)) {\n\n        put_ebml_string(pb, MATROSKA_ID_MUXINGAPP, LIBAVFORMAT_IDENT);\n\n        if ((tag = av_dict_get(s->metadata, \"encoding_tool\", NULL, 0)))\n\n            put_ebml_string(pb, MATROSKA_ID_WRITINGAPP, tag->value);\n\n        else\n\n            put_ebml_string(pb, MATROSKA_ID_WRITINGAPP, LIBAVFORMAT_IDENT);\n\n\n\n        if (mkv->mode != MODE_WEBM) {\n\n            uint32_t segment_uid[4];\n\n            AVLFG lfg;\n\n\n\n            av_lfg_init(&lfg, av_get_random_seed());\n\n\n\n            for (i = 0; i < 4; i++)\n\n                segment_uid[i] = av_lfg_get(&lfg);\n\n\n\n            put_ebml_binary(pb, MATROSKA_ID_SEGMENTUID, segment_uid, 16);\n\n        }\n\n    } else {\n\n        const char *ident = \"Lavf\";\n\n        put_ebml_string(pb, MATROSKA_ID_MUXINGAPP , ident);\n\n        put_ebml_string(pb, MATROSKA_ID_WRITINGAPP, ident);\n\n    }\n\n\n\n    if (ff_parse_creation_time_metadata(s, &creation_time, 0) > 0) {\n\n        // Adjust time so it's relative to 2001-01-01 and convert to nanoseconds.\n\n        int64_t date_utc = (creation_time - 978307200000000LL) * 1000;\n\n        uint8_t date_utc_buf[8];\n\n        AV_WB64(date_utc_buf, date_utc);\n\n        put_ebml_binary(pb, MATROSKA_ID_DATEUTC, date_utc_buf, 8);\n\n    }\n\n\n\n    // reserve space for the duration\n\n    mkv->duration = 0;\n\n    mkv->duration_offset = avio_tell(pb);\n\n    if (!mkv->is_live) {\n\n        int64_t metadata_duration = get_metadata_duration(s);\n\n\n\n        if (s->duration > 0) {\n\n            int64_t scaledDuration = av_rescale(s->duration, 1000, AV_TIME_BASE);\n\n            put_ebml_float(pb, MATROSKA_ID_DURATION, scaledDuration);\n\n            av_log(s, AV_LOG_DEBUG, \"Write early duration from recording time = %\" PRIu64 \"\\n\", scaledDuration);\n\n        } else if (metadata_duration > 0) {\n\n            int64_t scaledDuration = av_rescale(metadata_duration, 1000, AV_TIME_BASE);\n\n            put_ebml_float(pb, MATROSKA_ID_DURATION, scaledDuration);\n\n            av_log(s, AV_LOG_DEBUG, \"Write early duration from metadata = %\" PRIu64 \"\\n\", scaledDuration);\n\n        } else {\n\n            put_ebml_void(pb, 11);              // assumes double-precision float to be written\n\n        }\n\n    }\n\n    if ((s->pb->seekable & AVIO_SEEKABLE_NORMAL) && !mkv->is_live)\n\n        end_ebml_master_crc32_preliminary(s->pb, &mkv->info_bc, mkv, mkv->info);\n\n    else\n\n        end_ebml_master_crc32(s->pb, &mkv->info_bc, mkv, mkv->info);\n\n    pb = s->pb;\n\n\n\n    // initialize stream_duration fields\n\n    mkv->stream_durations = av_mallocz(s->nb_streams * sizeof(int64_t));\n\n    mkv->stream_duration_offsets = av_mallocz(s->nb_streams * sizeof(int64_t));\n\n\n\n    ret = mkv_write_tracks(s);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    for (i = 0; i < s->nb_chapters; i++)\n\n        mkv->chapter_id_offset = FFMAX(mkv->chapter_id_offset, 1LL - s->chapters[i]->id);\n\n\n\n    ret = mkv_write_chapters(s);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    if (mkv->mode != MODE_WEBM) {\n\n        ret = mkv_write_attachments(s);\n\n        if (ret < 0)\n\n            goto fail;\n\n    }\n\n\n\n    ret = mkv_write_tags(s);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    if (!(s->pb->seekable & AVIO_SEEKABLE_NORMAL) && !mkv->is_live)\n\n        mkv_write_seekhead(pb, mkv);\n\n\n\n    mkv->cues = mkv_start_cues(mkv->segment_offset);\n\n    if (!mkv->cues) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    if ((pb->seekable & AVIO_SEEKABLE_NORMAL) && mkv->reserve_cues_space) {\n\n        mkv->cues_pos = avio_tell(pb);\n\n        put_ebml_void(pb, mkv->reserve_cues_space);\n\n    }\n\n\n\n    av_init_packet(&mkv->cur_audio_pkt);\n\n    mkv->cur_audio_pkt.size = 0;\n\n    mkv->cluster_pos = -1;\n\n\n\n    avio_flush(pb);\n\n\n\n    // start a new cluster every 5 MB or 5 sec, or 32k / 1 sec for streaming or\n\n    // after 4k and on a keyframe\n\n    if (pb->seekable & AVIO_SEEKABLE_NORMAL) {\n\n        if (mkv->cluster_time_limit < 0)\n\n            mkv->cluster_time_limit = 5000;\n\n        if (mkv->cluster_size_limit < 0)\n\n            mkv->cluster_size_limit = 5 * 1024 * 1024;\n\n    } else {\n\n        if (mkv->cluster_time_limit < 0)\n\n            mkv->cluster_time_limit = 1000;\n\n        if (mkv->cluster_size_limit < 0)\n\n            mkv->cluster_size_limit = 32 * 1024;\n\n    }\n\n\n\n    return 0;\n\nfail:\n\n    mkv_free(mkv);\n\n    return ret;\n\n}\n", "idx": 3117, "_split": "test", "_hash": "2b696279e0eecc619a9a0e0feb007c01"}
{"project": "FFmpeg", "commit_id": "e0c6cce44729d94e2a5507a4b6d031f23e8bd7b6", "target": 0, "func": "av_cold void ff_sws_init_swScale_mmx(SwsContext *c)\n\n{\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n#if HAVE_INLINE_ASM\n\n    if (cpu_flags & AV_CPU_FLAG_MMX)\n\n        sws_init_swScale_MMX(c);\n\n#if HAVE_MMXEXT_INLINE\n\n    if (cpu_flags & AV_CPU_FLAG_MMXEXT)\n\n        sws_init_swScale_MMX2(c);\n\n#endif\n\n#endif /* HAVE_INLINE_ASM */\n\n\n\n#if HAVE_YASM\n\n#define ASSIGN_SCALE_FUNC2(hscalefn, filtersize, opt1, opt2) do { \\\n\n    if (c->srcBpc == 8) { \\\n\n        hscalefn = c->dstBpc <= 10 ? ff_hscale8to15_ ## filtersize ## _ ## opt2 : \\\n\n                                     ff_hscale8to19_ ## filtersize ## _ ## opt1; \\\n\n    } else if (c->srcBpc == 9) { \\\n\n        hscalefn = c->dstBpc <= 10 ? ff_hscale9to15_ ## filtersize ## _ ## opt2 : \\\n\n                                     ff_hscale9to19_ ## filtersize ## _ ## opt1; \\\n\n    } else if (c->srcBpc == 10) { \\\n\n        hscalefn = c->dstBpc <= 10 ? ff_hscale10to15_ ## filtersize ## _ ## opt2 : \\\n\n                                     ff_hscale10to19_ ## filtersize ## _ ## opt1; \\\n\n    } else /* c->srcBpc == 16 */ { \\\n\n        hscalefn = c->dstBpc <= 10 ? ff_hscale16to15_ ## filtersize ## _ ## opt2 : \\\n\n                                     ff_hscale16to19_ ## filtersize ## _ ## opt1; \\\n\n    } \\\n\n} while (0)\n\n#define ASSIGN_MMX_SCALE_FUNC(hscalefn, filtersize, opt1, opt2) \\\n\n    switch (filtersize) { \\\n\n    case 4:  ASSIGN_SCALE_FUNC2(hscalefn, 4, opt1, opt2); break; \\\n\n    case 8:  ASSIGN_SCALE_FUNC2(hscalefn, 8, opt1, opt2); break; \\\n\n    default: ASSIGN_SCALE_FUNC2(hscalefn, X, opt1, opt2); break; \\\n\n    }\n\n#define ASSIGN_VSCALEX_FUNC(vscalefn, opt, do_16_case, condition_8bit) \\\n\nswitch(c->dstBpc){ \\\n\n    case 16:                          do_16_case;                          break; \\\n\n    case 10: if (!isBE(c->dstFormat)) vscalefn = ff_yuv2planeX_10_ ## opt; break; \\\n\n    case 9:  if (!isBE(c->dstFormat)) vscalefn = ff_yuv2planeX_9_  ## opt; break; \\\n\n    default: if (condition_8bit)      vscalefn = ff_yuv2planeX_8_  ## opt; break; \\\n\n    }\n\n#define ASSIGN_VSCALE_FUNC(vscalefn, opt1, opt2, opt2chk) \\\n\n    switch(c->dstBpc){ \\\n\n    case 16: if (!isBE(c->dstFormat))            vscalefn = ff_yuv2plane1_16_ ## opt1; break; \\\n\n    case 10: if (!isBE(c->dstFormat) && opt2chk) vscalefn = ff_yuv2plane1_10_ ## opt2; break; \\\n\n    case 9:  if (!isBE(c->dstFormat) && opt2chk) vscalefn = ff_yuv2plane1_9_  ## opt2;  break; \\\n\n    default:                                     vscalefn = ff_yuv2plane1_8_  ## opt1;  break; \\\n\n    }\n\n#define case_rgb(x, X, opt) \\\n\n        case PIX_FMT_ ## X: \\\n\n            c->lumToYV12 = ff_ ## x ## ToY_ ## opt; \\\n\n            if (!c->chrSrcHSubSample) \\\n\n                c->chrToYV12 = ff_ ## x ## ToUV_ ## opt; \\\n\n            break\n\n#if ARCH_X86_32\n\n    if (cpu_flags & AV_CPU_FLAG_MMX) {\n\n        ASSIGN_MMX_SCALE_FUNC(c->hyScale, c->hLumFilterSize, mmx, mmx);\n\n        ASSIGN_MMX_SCALE_FUNC(c->hcScale, c->hChrFilterSize, mmx, mmx);\n\n        ASSIGN_VSCALE_FUNC(c->yuv2plane1, mmx, mmx2, cpu_flags & AV_CPU_FLAG_MMXEXT);\n\n\n\n        switch (c->srcFormat) {\n\n        case PIX_FMT_Y400A:\n\n            c->lumToYV12 = ff_yuyvToY_mmx;\n\n            if (c->alpPixBuf)\n\n                c->alpToYV12 = ff_uyvyToY_mmx;\n\n            break;\n\n        case PIX_FMT_YUYV422:\n\n            c->lumToYV12 = ff_yuyvToY_mmx;\n\n            c->chrToYV12 = ff_yuyvToUV_mmx;\n\n            break;\n\n        case PIX_FMT_UYVY422:\n\n            c->lumToYV12 = ff_uyvyToY_mmx;\n\n            c->chrToYV12 = ff_uyvyToUV_mmx;\n\n            break;\n\n        case PIX_FMT_NV12:\n\n            c->chrToYV12 = ff_nv12ToUV_mmx;\n\n            break;\n\n        case PIX_FMT_NV21:\n\n            c->chrToYV12 = ff_nv21ToUV_mmx;\n\n            break;\n\n        case_rgb(rgb24, RGB24, mmx);\n\n        case_rgb(bgr24, BGR24, mmx);\n\n        case_rgb(bgra,  BGRA,  mmx);\n\n        case_rgb(rgba,  RGBA,  mmx);\n\n        case_rgb(abgr,  ABGR,  mmx);\n\n        case_rgb(argb,  ARGB,  mmx);\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n    if (cpu_flags & AV_CPU_FLAG_MMXEXT) {\n\n        ASSIGN_VSCALEX_FUNC(c->yuv2planeX, mmx2, , 1);\n\n    }\n\n#endif /* ARCH_X86_32 */\n\n#define ASSIGN_SSE_SCALE_FUNC(hscalefn, filtersize, opt1, opt2) \\\n\n    switch (filtersize) { \\\n\n    case 4:  ASSIGN_SCALE_FUNC2(hscalefn, 4, opt1, opt2); break; \\\n\n    case 8:  ASSIGN_SCALE_FUNC2(hscalefn, 8, opt1, opt2); break; \\\n\n    default: if (filtersize & 4) ASSIGN_SCALE_FUNC2(hscalefn, X4, opt1, opt2); \\\n\n             else                ASSIGN_SCALE_FUNC2(hscalefn, X8, opt1, opt2); \\\n\n             break; \\\n\n    }\n\n    if (cpu_flags & AV_CPU_FLAG_SSE2) {\n\n        ASSIGN_SSE_SCALE_FUNC(c->hyScale, c->hLumFilterSize, sse2, sse2);\n\n        ASSIGN_SSE_SCALE_FUNC(c->hcScale, c->hChrFilterSize, sse2, sse2);\n\n        ASSIGN_VSCALEX_FUNC(c->yuv2planeX, sse2, ,\n\n                            HAVE_ALIGNED_STACK || ARCH_X86_64);\n\n        ASSIGN_VSCALE_FUNC(c->yuv2plane1, sse2, sse2, 1);\n\n\n\n        switch (c->srcFormat) {\n\n        case PIX_FMT_Y400A:\n\n            c->lumToYV12 = ff_yuyvToY_sse2;\n\n            if (c->alpPixBuf)\n\n                c->alpToYV12 = ff_uyvyToY_sse2;\n\n            break;\n\n        case PIX_FMT_YUYV422:\n\n            c->lumToYV12 = ff_yuyvToY_sse2;\n\n            c->chrToYV12 = ff_yuyvToUV_sse2;\n\n            break;\n\n        case PIX_FMT_UYVY422:\n\n            c->lumToYV12 = ff_uyvyToY_sse2;\n\n            c->chrToYV12 = ff_uyvyToUV_sse2;\n\n            break;\n\n        case PIX_FMT_NV12:\n\n            c->chrToYV12 = ff_nv12ToUV_sse2;\n\n            break;\n\n        case PIX_FMT_NV21:\n\n            c->chrToYV12 = ff_nv21ToUV_sse2;\n\n            break;\n\n        case_rgb(rgb24, RGB24, sse2);\n\n        case_rgb(bgr24, BGR24, sse2);\n\n        case_rgb(bgra,  BGRA,  sse2);\n\n        case_rgb(rgba,  RGBA,  sse2);\n\n        case_rgb(abgr,  ABGR,  sse2);\n\n        case_rgb(argb,  ARGB,  sse2);\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n    if (cpu_flags & AV_CPU_FLAG_SSSE3) {\n\n        ASSIGN_SSE_SCALE_FUNC(c->hyScale, c->hLumFilterSize, ssse3, ssse3);\n\n        ASSIGN_SSE_SCALE_FUNC(c->hcScale, c->hChrFilterSize, ssse3, ssse3);\n\n        switch (c->srcFormat) {\n\n        case_rgb(rgb24, RGB24, ssse3);\n\n        case_rgb(bgr24, BGR24, ssse3);\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n    if (cpu_flags & AV_CPU_FLAG_SSE4) {\n\n        /* Xto15 don't need special sse4 functions */\n\n        ASSIGN_SSE_SCALE_FUNC(c->hyScale, c->hLumFilterSize, sse4, ssse3);\n\n        ASSIGN_SSE_SCALE_FUNC(c->hcScale, c->hChrFilterSize, sse4, ssse3);\n\n        ASSIGN_VSCALEX_FUNC(c->yuv2planeX, sse4,\n\n                            if (!isBE(c->dstFormat)) c->yuv2planeX = ff_yuv2planeX_16_sse4,\n\n                            HAVE_ALIGNED_STACK || ARCH_X86_64);\n\n        if (c->dstBpc == 16 && !isBE(c->dstFormat))\n\n            c->yuv2plane1 = ff_yuv2plane1_16_sse4;\n\n    }\n\n\n\n    if (cpu_flags & AV_CPU_FLAG_AVX) {\n\n        ASSIGN_VSCALEX_FUNC(c->yuv2planeX, avx, ,\n\n                            HAVE_ALIGNED_STACK || ARCH_X86_64);\n\n        ASSIGN_VSCALE_FUNC(c->yuv2plane1, avx, avx, 1);\n\n\n\n        switch (c->srcFormat) {\n\n        case PIX_FMT_YUYV422:\n\n            c->chrToYV12 = ff_yuyvToUV_avx;\n\n            break;\n\n        case PIX_FMT_UYVY422:\n\n            c->chrToYV12 = ff_uyvyToUV_avx;\n\n            break;\n\n        case PIX_FMT_NV12:\n\n            c->chrToYV12 = ff_nv12ToUV_avx;\n\n            break;\n\n        case PIX_FMT_NV21:\n\n            c->chrToYV12 = ff_nv21ToUV_avx;\n\n            break;\n\n        case_rgb(rgb24, RGB24, avx);\n\n        case_rgb(bgr24, BGR24, avx);\n\n        case_rgb(bgra,  BGRA,  avx);\n\n        case_rgb(rgba,  RGBA,  avx);\n\n        case_rgb(abgr,  ABGR,  avx);\n\n        case_rgb(argb,  ARGB,  avx);\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n#endif\n\n}\n", "idx": 3153, "_split": "test", "_hash": "715f56096d6d709a8ca57c266140b5f1"}
{"project": "FFmpeg", "commit_id": "0a467a9b594dd67aa96bad687d05f8845b009f18", "target": 1, "func": "static unsigned tget(const uint8_t **p, int type, int le)\n\n{\n\n    switch (type) {\n\n    case TIFF_BYTE:\n\n        return *(*p)++;\n\n    case TIFF_SHORT:\n\n        return tget_short(p, le);\n\n    case TIFF_LONG:\n\n        return tget_long(p, le);\n\n    default:\n\n        return UINT_MAX;\n\n    }\n\n}\n", "idx": 3158, "_split": "test", "_hash": "bd1cee01f346e8a9bcf4f619c39c2665"}
{"project": "FFmpeg", "commit_id": "c43485f70765cb488bfdf95dc783bb9b14eb1179", "target": 1, "func": "static int decode_hq_slice(AVCodecContext *avctx, void *arg)\n\n{\n\n    int i, quant, level, orientation, quant_idx;\n\n    uint8_t quants[MAX_DWT_LEVELS][4];\n\n    DiracContext *s = avctx->priv_data;\n\n    DiracSlice *slice = arg;\n\n    GetBitContext *gb = &slice->gb;\n\n\n\n    skip_bits_long(gb, 8*s->highquality.prefix_bytes);\n\n    quant_idx = get_bits(gb, 8);\n\n\n\n    /* Slice quantization (slice_quantizers() in the specs) */\n\n    for (level = 0; level < s->wavelet_depth; level++) {\n\n        for (orientation = !!level; orientation < 4; orientation++) {\n\n            quant = FFMAX(quant_idx - s->lowdelay.quant[level][orientation], 0);\n\n            quants[level][orientation] = quant;\n\n        }\n\n    }\n\n\n\n    /* Luma + 2 Chroma planes */\n\n    for (i = 0; i < 3; i++) {\n\n        int64_t length = s->highquality.size_scaler * get_bits(gb, 8);\n\n        int64_t bits_left = 8 * length;\n\n        int64_t bits_end = get_bits_count(gb) + bits_left;\n\n\n\n        if (bits_end >= INT_MAX) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"end too far away\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        for (level = 0; level < s->wavelet_depth; level++) {\n\n            for (orientation = !!level; orientation < 4; orientation++) {\n\n                decode_subband(s, gb, quants[level][orientation], slice->slice_x, slice->slice_y, bits_end,\n\n                               &s->plane[i].band[level][orientation], NULL);\n\n            }\n\n        }\n\n        skip_bits_long(gb, bits_end - get_bits_count(gb));\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 3160, "_split": "test", "_hash": "7d28c3994d9bd345581a35b0e297a1a1"}
{"project": "FFmpeg", "commit_id": "a8bdf2405c6027f45a899eaaa6ba74e97c1c2701", "target": 1, "func": "static av_cold int amr_wb_encode_init(AVCodecContext *avctx)\n\n{\n\n    AMRWBContext *s = avctx->priv_data;\n\n\n\n    if (avctx->sample_rate != 16000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only 16000Hz sample rate supported\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    if (avctx->channels != 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono supported\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    s->mode            = get_wb_bitrate_mode(avctx->bit_rate, avctx);\n\n    s->last_bitrate    = avctx->bit_rate;\n\n\n\n    avctx->frame_size  = 320;\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n\n\n\n\n    s->state     = E_IF_init();\n\n\n\n    return 0;\n\n}", "idx": 3161, "_split": "test", "_hash": "998ed25ddd89b924106c3c52236a227c"}
{"project": "FFmpeg", "commit_id": "69ee915e1c628fdf8b270de8c19ff357333e354a", "target": 1, "func": "void ff_fetch_timestamp(AVCodecParserContext *s, int off, int remove)\n\n{\n\n    int i;\n\n\n\n    s->dts    =\n\n    s->pts    = AV_NOPTS_VALUE;\n\n    s->pos    = -1;\n\n    s->offset = 0;\n\n    for (i = 0; i < AV_PARSER_PTS_NB; i++) {\n\n        if (s->cur_offset + off >= s->cur_frame_offset[i] &&\n\n            (s->frame_offset < s->cur_frame_offset[i] ||\n\n             (!s->frame_offset && !s->next_frame_offset)) && // first field/frame\n\n            // check disabled since MPEG-TS does not send complete PES packets\n\n            /*s->next_frame_offset + off <*/  s->cur_frame_end[i]){\n\n\n\n            s->dts    = s->cur_frame_dts[i];\n\n            s->pts    = s->cur_frame_pts[i];\n\n            s->pos    = s->cur_frame_pos[i];\n\n            s->offset = s->next_frame_offset - s->cur_frame_offset[i];\n\n            if (remove)\n\n                s->cur_frame_offset[i] = INT64_MAX;\n\n            if (s->cur_offset + off < s->cur_frame_end[i])\n\n                break;\n\n        }\n\n    }\n\n}\n", "idx": 3176, "_split": "test", "_hash": "eec796765f80deda0c061f557b1b1ef2"}
{"project": "FFmpeg", "commit_id": "c61b28e0421f0f9502dfb21495a03cda191def15", "target": 0, "func": "static int decode_frame(AVCodecContext *avctx, const uint8_t *databuf,\n\n                        float **out_samples)\n\n{\n\n    ATRAC3Context *q = avctx->priv_data;\n\n    int ret, i;\n\n    uint8_t *ptr1;\n\n\n\n    if (q->coding_mode == JOINT_STEREO) {\n\n        /* channel coupling mode */\n\n        /* decode Sound Unit 1 */\n\n        init_get_bits(&q->gb, databuf, avctx->block_align * 8);\n\n\n\n        ret = decode_channel_sound_unit(q, &q->gb, q->units, out_samples[0], 0,\n\n                                        JOINT_STEREO);\n\n        if (ret != 0)\n\n            return ret;\n\n\n\n        /* Framedata of the su2 in the joint-stereo mode is encoded in\n\n         * reverse byte order so we need to swap it first. */\n\n        if (databuf == q->decoded_bytes_buffer) {\n\n            uint8_t *ptr2 = q->decoded_bytes_buffer + avctx->block_align - 1;\n\n            ptr1          = q->decoded_bytes_buffer;\n\n            for (i = 0; i < avctx->block_align / 2; i++, ptr1++, ptr2--)\n\n                FFSWAP(uint8_t, *ptr1, *ptr2);\n\n        } else {\n\n            const uint8_t *ptr2 = databuf + avctx->block_align - 1;\n\n            for (i = 0; i < avctx->block_align; i++)\n\n                q->decoded_bytes_buffer[i] = *ptr2--;\n\n        }\n\n\n\n        /* Skip the sync codes (0xF8). */\n\n        ptr1 = q->decoded_bytes_buffer;\n\n        for (i = 4; *ptr1 == 0xF8; i++, ptr1++) {\n\n            if (i >= avctx->block_align)\n\n                return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n\n\n        /* set the bitstream reader at the start of the second Sound Unit*/\n\n        init_get_bits8(&q->gb, ptr1, q->decoded_bytes_buffer + avctx->block_align - ptr1);\n\n\n\n        /* Fill the Weighting coeffs delay buffer */\n\n        memmove(q->weighting_delay, &q->weighting_delay[2],\n\n                4 * sizeof(*q->weighting_delay));\n\n        q->weighting_delay[4] = get_bits1(&q->gb);\n\n        q->weighting_delay[5] = get_bits(&q->gb, 3);\n\n\n\n        for (i = 0; i < 4; i++) {\n\n            q->matrix_coeff_index_prev[i] = q->matrix_coeff_index_now[i];\n\n            q->matrix_coeff_index_now[i]  = q->matrix_coeff_index_next[i];\n\n            q->matrix_coeff_index_next[i] = get_bits(&q->gb, 2);\n\n        }\n\n\n\n        /* Decode Sound Unit 2. */\n\n        ret = decode_channel_sound_unit(q, &q->gb, &q->units[1],\n\n                                        out_samples[1], 1, JOINT_STEREO);\n\n        if (ret != 0)\n\n            return ret;\n\n\n\n        /* Reconstruct the channel coefficients. */\n\n        reverse_matrixing(out_samples[0], out_samples[1],\n\n                          q->matrix_coeff_index_prev,\n\n                          q->matrix_coeff_index_now);\n\n\n\n        channel_weighting(out_samples[0], out_samples[1], q->weighting_delay);\n\n    } else {\n\n        /* single channels */\n\n        /* Decode the channel sound units. */\n\n        for (i = 0; i < avctx->channels; i++) {\n\n            /* Set the bitstream reader at the start of a channel sound unit. */\n\n            init_get_bits(&q->gb,\n\n                          databuf + i * avctx->block_align / avctx->channels,\n\n                          avctx->block_align * 8 / avctx->channels);\n\n\n\n            ret = decode_channel_sound_unit(q, &q->gb, &q->units[i],\n\n                                            out_samples[i], i, q->coding_mode);\n\n            if (ret != 0)\n\n                return ret;\n\n        }\n\n    }\n\n\n\n    /* Apply the iQMF synthesis filter. */\n\n    for (i = 0; i < avctx->channels; i++) {\n\n        float *p1 = out_samples[i];\n\n        float *p2 = p1 + 256;\n\n        float *p3 = p2 + 256;\n\n        float *p4 = p3 + 256;\n\n        ff_atrac_iqmf(p1, p2, 256, p1, q->units[i].delay_buf1, q->temp_buf);\n\n        ff_atrac_iqmf(p4, p3, 256, p3, q->units[i].delay_buf2, q->temp_buf);\n\n        ff_atrac_iqmf(p1, p3, 512, p1, q->units[i].delay_buf3, q->temp_buf);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 3183, "_split": "test", "_hash": "67be43bec92b036ad624baa305fb387a"}
{"project": "FFmpeg", "commit_id": "3d2c3ef4b46d96023d6f0d358e4d7d65568da67c", "target": 0, "func": "static int decode_cabac_mb_cbp_luma( H264Context *h) {\n\n    int cbp_b, cbp_a, ctx, cbp = 0;\n\n\n\n    cbp_a = h->slice_table[h->left_mb_xy[0]] == h->slice_num ? h->left_cbp : -1;\n\n    cbp_b = h->slice_table[h->top_mb_xy]     == h->slice_num ? h->top_cbp  : -1;\n\n\n\n    ctx = !(cbp_a & 0x02) + 2 * !(cbp_b & 0x04);\n\n    cbp |= get_cabac_noinline(&h->cabac, &h->cabac_state[73 + ctx]);\n\n    ctx = !(cbp   & 0x01) + 2 * !(cbp_b & 0x08);\n\n    cbp |= get_cabac_noinline(&h->cabac, &h->cabac_state[73 + ctx]) << 1;\n\n    ctx = !(cbp_a & 0x08) + 2 * !(cbp   & 0x01);\n\n    cbp |= get_cabac_noinline(&h->cabac, &h->cabac_state[73 + ctx]) << 2;\n\n    ctx = !(cbp   & 0x04) + 2 * !(cbp   & 0x02);\n\n    cbp |= get_cabac_noinline(&h->cabac, &h->cabac_state[73 + ctx]) << 3;\n\n    return cbp;\n\n}\n", "idx": 3211, "_split": "test", "_hash": "0517fa7fbfbef983567e05e4ee11affe"}
{"project": "FFmpeg", "commit_id": "f0adb99d068e659178c00271a46cd469dfc01a6e", "target": 1, "func": "void ff_qsv_decode_reset(AVCodecContext *avctx, QSVContext *q)\n\n{\n\n    QSVFrame *cur;\n\n    AVPacket pkt;\n\n    int ret = 0;\n\n    mfxVideoParam param = { { 0 } };\n\n\n\n    if (q->reinit_pending) {\n\n        close_decoder(q);\n\n    } else if (q->engine_ready) {\n\n        ret = MFXVideoDECODE_GetVideoParam(q->session, &param);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"MFX decode get param error %d\\n\", ret);\n\n        }\n\n\n\n        ret = MFXVideoDECODE_Reset(q->session, &param);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"MFX decode reset error %d\\n\", ret);\n\n        }\n\n\n\n        /* Free all frames*/\n\n        cur = q->work_frames;\n\n        while (cur) {\n\n            q->work_frames = cur->next;\n\n            av_frame_free(&cur->frame);\n\n            av_freep(&cur);\n\n            cur = q->work_frames;\n\n        }\n\n    }\n\n\n\n    /* Reset output surfaces */\n\n    av_fifo_reset(q->async_fifo);\n\n\n\n    /* Reset input packets fifo */\n\n    while (av_fifo_size(q->pkt_fifo)) {\n\n        av_fifo_generic_read(q->pkt_fifo, &pkt, sizeof(pkt), NULL);\n\n        av_packet_unref(&pkt);\n\n    }\n\n\n\n    /* Reset input bitstream fifo */\n\n    av_fifo_reset(q->input_fifo);\n\n}\n", "idx": 3227, "_split": "test", "_hash": "6e28002b07e33db5577415dfe5d1c679"}
{"project": "FFmpeg", "commit_id": "03931ecf71710452fc9e89d4f18354f0b5e05395", "target": 0, "func": "static float ssim_plane(uint8_t *main, int main_stride,\n\n                        uint8_t *ref, int ref_stride,\n\n                        int width, int height, void *temp)\n\n{\n\n    int z = 0;\n\n    int x, y;\n\n    float ssim = 0.0;\n\n    int (*sum0)[4] = temp;\n\n    int (*sum1)[4] = sum0 + (width >> 2) + 3;\n\n\n\n    width >>= 2;\n\n    height >>= 2;\n\n\n\n    for (y = 1; y < height; y++) {\n\n        for (; z <= y; z++) {\n\n            FFSWAP(void*, sum0, sum1);\n\n            for (x = 0; x < width; x+=2)\n\n                ssim_4x4x2_core(&main[4 * (x + z * main_stride)], main_stride,\n\n                                &ref[4 * (x + z * ref_stride)], ref_stride,\n\n                                &sum0[x]);\n\n        }\n\n\n\n        ssim += ssim_endn(sum0, sum1, width - 1);\n\n    }\n\n\n\n    return ssim / ((height - 1) * (width - 1));\n\n}\n", "idx": 3274, "_split": "test", "_hash": "681f4d62ec8a392163e89cb1a405ea0c"}
{"project": "FFmpeg", "commit_id": "4b1f5e5090abed6c618c8ba380cd7d28d140f867", "target": 0, "func": "static void qdm2_decode_super_block(QDM2Context *q)\n\n{\n\n    GetBitContext gb;\n\n    QDM2SubPacket header, *packet;\n\n    int i, packet_bytes, sub_packet_size, sub_packets_D;\n\n    unsigned int next_index = 0;\n\n\n\n    memset(q->tone_level_idx_hi1, 0, sizeof(q->tone_level_idx_hi1));\n\n    memset(q->tone_level_idx_mid, 0, sizeof(q->tone_level_idx_mid));\n\n    memset(q->tone_level_idx_hi2, 0, sizeof(q->tone_level_idx_hi2));\n\n\n\n    q->sub_packets_B = 0;\n\n    sub_packets_D    = 0;\n\n\n\n    average_quantized_coeffs(q); // average elements in quantized_coeffs[max_ch][10][8]\n\n\n\n    init_get_bits(&gb, q->compressed_data, q->compressed_size * 8);\n\n    qdm2_decode_sub_packet_header(&gb, &header);\n\n\n\n    if (header.type < 2 || header.type >= 8) {\n\n        q->has_errors = 1;\n\n        av_log(NULL, AV_LOG_ERROR, \"bad superblock type\\n\");\n\n        return;\n\n    }\n\n\n\n    q->superblocktype_2_3 = (header.type == 2 || header.type == 3);\n\n    packet_bytes          = (q->compressed_size - get_bits_count(&gb) / 8);\n\n\n\n    init_get_bits(&gb, header.data, header.size * 8);\n\n\n\n    if (header.type == 2 || header.type == 4 || header.type == 5) {\n\n        int csum = 257 * get_bits(&gb, 8);\n\n        csum += 2 * get_bits(&gb, 8);\n\n\n\n        csum = qdm2_packet_checksum(q->compressed_data, q->checksum_size, csum);\n\n\n\n        if (csum != 0) {\n\n            q->has_errors = 1;\n\n            av_log(NULL, AV_LOG_ERROR, \"bad packet checksum\\n\");\n\n            return;\n\n        }\n\n    }\n\n\n\n    q->sub_packet_list_B[0].packet = NULL;\n\n    q->sub_packet_list_D[0].packet = NULL;\n\n\n\n    for (i = 0; i < 6; i++)\n\n        if (--q->fft_level_exp[i] < 0)\n\n            q->fft_level_exp[i] = 0;\n\n\n\n    for (i = 0; packet_bytes > 0; i++) {\n\n        int j;\n\n\n\n        if (i >= FF_ARRAY_ELEMS(q->sub_packet_list_A)) {\n\n            SAMPLES_NEEDED_2(\"too many packet bytes\");\n\n            return;\n\n        }\n\n\n\n        q->sub_packet_list_A[i].next = NULL;\n\n\n\n        if (i > 0) {\n\n            q->sub_packet_list_A[i - 1].next = &q->sub_packet_list_A[i];\n\n\n\n            /* seek to next block */\n\n            init_get_bits(&gb, header.data, header.size * 8);\n\n            skip_bits(&gb, next_index * 8);\n\n\n\n            if (next_index >= header.size)\n\n                break;\n\n        }\n\n\n\n        /* decode subpacket */\n\n        packet = &q->sub_packets[i];\n\n        qdm2_decode_sub_packet_header(&gb, packet);\n\n        next_index      = packet->size + get_bits_count(&gb) / 8;\n\n        sub_packet_size = ((packet->size > 0xff) ? 1 : 0) + packet->size + 2;\n\n\n\n        if (packet->type == 0)\n\n            break;\n\n\n\n        if (sub_packet_size > packet_bytes) {\n\n            if (packet->type != 10 && packet->type != 11 && packet->type != 12)\n\n                break;\n\n            packet->size += packet_bytes - sub_packet_size;\n\n        }\n\n\n\n        packet_bytes -= sub_packet_size;\n\n\n\n        /* add subpacket to 'all subpackets' list */\n\n        q->sub_packet_list_A[i].packet = packet;\n\n\n\n        /* add subpacket to related list */\n\n        if (packet->type == 8) {\n\n            SAMPLES_NEEDED_2(\"packet type 8\");\n\n            return;\n\n        } else if (packet->type >= 9 && packet->type <= 12) {\n\n            /* packets for MPEG Audio like Synthesis Filter */\n\n            QDM2_LIST_ADD(q->sub_packet_list_D, sub_packets_D, packet);\n\n        } else if (packet->type == 13) {\n\n            for (j = 0; j < 6; j++)\n\n                q->fft_level_exp[j] = get_bits(&gb, 6);\n\n        } else if (packet->type == 14) {\n\n            for (j = 0; j < 6; j++)\n\n                q->fft_level_exp[j] = qdm2_get_vlc(&gb, &fft_level_exp_vlc, 0, 2);\n\n        } else if (packet->type == 15) {\n\n            SAMPLES_NEEDED_2(\"packet type 15\")\n\n            return;\n\n        } else if (packet->type >= 16 && packet->type < 48 &&\n\n                   !fft_subpackets[packet->type - 16]) {\n\n            /* packets for FFT */\n\n            QDM2_LIST_ADD(q->sub_packet_list_B, q->sub_packets_B, packet);\n\n        }\n\n    } // Packet bytes loop\n\n\n\n    if (q->sub_packet_list_D[0].packet != NULL) {\n\n        process_synthesis_subpackets(q, q->sub_packet_list_D);\n\n        q->do_synth_filter = 1;\n\n    } else if (q->do_synth_filter) {\n\n        process_subpacket_10(q, NULL);\n\n        process_subpacket_11(q, NULL);\n\n        process_subpacket_12(q, NULL);\n\n    }\n\n}\n", "idx": 3290, "_split": "test", "_hash": "557725aadec63abbe7edaeec3c30964f"}
{"project": "FFmpeg", "commit_id": "2254b559cbcfc0418135f09add37c0a5866b1981", "target": 1, "func": "static void hScale8To15_c(SwsContext *c, int16_t *dst, int dstW, const uint8_t *src,\n\n                          const int16_t *filter, const int16_t *filterPos,\n\n                          int filterSize)\n\n{\n\n    int i;\n\n    for (i=0; i<dstW; i++) {\n\n        int j;\n\n        int srcPos= filterPos[i];\n\n        int val=0;\n\n        for (j=0; j<filterSize; j++) {\n\n            val += ((int)src[srcPos + j])*filter[filterSize*i + j];\n\n        }\n\n        //filter += hFilterSize;\n\n        dst[i] = FFMIN(val>>7, (1<<15)-1); // the cubic equation does overflow ...\n\n        //dst[i] = val>>7;\n\n    }\n\n}\n", "idx": 3293, "_split": "test", "_hash": "d33feb7a89345e0909d381b86fa5ca72"}
{"project": "FFmpeg", "commit_id": "a4f6be86d67ae30d494fbe8a470bc32b715d75a9", "target": 0, "func": "static void av_always_inline filter_mb_edgech( uint8_t *pix, int stride, const int16_t bS[4], unsigned int qp, H264Context *h ) {\n\n    const int qp_bd_offset = 6 * (h->sps.bit_depth_luma - 8);\n\n    const unsigned int index_a = qp - qp_bd_offset + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = beta_table[qp - qp_bd_offset + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]]+1;\n\n        tc[1] = tc0_table[index_a][bS[1]]+1;\n\n        tc[2] = tc0_table[index_a][bS[2]]+1;\n\n        tc[3] = tc0_table[index_a][bS[3]]+1;\n\n        h->h264dsp.h264_v_loop_filter_chroma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->h264dsp.h264_v_loop_filter_chroma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 3330, "_split": "test", "_hash": "5ddc8ca8ec31ab41077868e6609e1728"}
{"project": "FFmpeg", "commit_id": "90540c2d5ace46a1e9789c75fde0b1f7dbb12a9b", "target": 1, "func": "static inline void RENAME(rgb15to32)(const uint8_t *src, uint8_t *dst, int src_size)\n\n{\n\n    const uint16_t *end;\n\n    const uint16_t *mm_end;\n\n    uint8_t *d = dst;\n\n    const uint16_t *s = (const uint16_t *)src;\n\n    end = s + src_size/2;\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*s):\"memory\");\n\n    __asm__ volatile(\"pxor    %%mm7,%%mm7    \\n\\t\":::\"memory\");\n\n    __asm__ volatile(\"pcmpeqd %%mm6,%%mm6    \\n\\t\":::\"memory\");\n\n    mm_end = end - 3;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movq          %1, %%mm0    \\n\\t\"\n\n            \"movq          %1, %%mm1    \\n\\t\"\n\n            \"movq          %1, %%mm2    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %3, %%mm1    \\n\\t\"\n\n            \"pand          %4, %%mm2    \\n\\t\"\n\n            \"psllq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $2, %%mm1    \\n\\t\"\n\n            \"psrlq         $7, %%mm2    \\n\\t\"\n\n            PACK_RGB32\n\n            :\"=m\"(*d)\n\n            :\"m\"(*s),\"m\"(mask15b),\"m\"(mask15g),\"m\"(mask15r)\n\n            :\"memory\");\n\n        d += 16;\n\n        s += 4;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n    while (s < end) {\n\n        register uint16_t bgr;\n\n        bgr = *s++;\n\n        *d++ = (bgr&0x1F)<<3;\n\n        *d++ = (bgr&0x3E0)>>2;\n\n        *d++ = (bgr&0x7C00)>>7;\n\n        *d++ = 255;\n\n    }\n\n}\n", "idx": 3375, "_split": "test", "_hash": "a3dee53d9d1625dda4004b7ef4bfed51"}
{"project": "FFmpeg", "commit_id": "2254b559cbcfc0418135f09add37c0a5866b1981", "target": 1, "func": "static av_always_inline void hcscale(SwsContext *c, int16_t *dst1, int16_t *dst2, int dstWidth,\n\n                                     const uint8_t *src_in[4],\n\n                                     int srcW, int xInc, const int16_t *hChrFilter,\n\n                                     const int16_t *hChrFilterPos, int hChrFilterSize,\n\n                                     uint8_t *formatConvBuffer, uint32_t *pal)\n\n{\n\n    const uint8_t *src1 = src_in[1], *src2 = src_in[2];\n\n    if (c->chrToYV12) {\n\n        uint8_t *buf2 = formatConvBuffer + FFALIGN(srcW * FFALIGN(c->srcBpc, 8) >> 3, 16);\n\n        c->chrToYV12(formatConvBuffer, buf2, src1, src2, srcW, pal);\n\n        src1= formatConvBuffer;\n\n        src2= buf2;\n\n    } else if (c->readChrPlanar) {\n\n        uint8_t *buf2 = formatConvBuffer + FFALIGN(srcW * FFALIGN(c->srcBpc, 8) >> 3, 16);\n\n        c->readChrPlanar(formatConvBuffer, buf2, src_in, srcW);\n\n        src1= formatConvBuffer;\n\n        src2= buf2;\n\n    }\n\n\n\n    if (!c->hcscale_fast) {\n\n        c->hcScale(c, dst1, dstWidth, src1, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n        c->hcScale(c, dst2, dstWidth, src2, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    } else { // fast bilinear upscale / crap downscale\n\n        c->hcscale_fast(c, dst1, dst2, dstWidth, src1, src2, srcW, xInc);\n\n    }\n\n\n\n    if (c->chrConvertRange)\n\n        c->chrConvertRange(dst1, dst2, dstWidth);\n\n}\n", "idx": 3397, "_split": "test", "_hash": "f924d34cff521a345d83fd7ad403393c"}
{"project": "FFmpeg", "commit_id": "1181d93231e9b807965724587d363c1cfd5a1d0d", "target": 0, "func": "static void avc_luma_hv_qrt_and_aver_dst_4x4_msa(const uint8_t *src_x,\n\n                                                 const uint8_t *src_y,\n\n                                                 int32_t src_stride,\n\n                                                 uint8_t *dst,\n\n                                                 int32_t dst_stride)\n\n{\n\n    v16i8 src_hz0, src_hz1, src_hz2, src_hz3;\n\n    v16u8 dst0, dst1, dst2, dst3;\n\n    v16i8 src_vt0, src_vt1, src_vt2, src_vt3, src_vt4;\n\n    v16i8 src_vt5, src_vt6, src_vt7, src_vt8;\n\n    v16i8 mask0, mask1, mask2;\n\n    v8i16 hz_out0, hz_out1, vert_out0, vert_out1;\n\n    v8i16 res0, res1;\n\n    v16u8 res;\n\n\n\n    LD_SB3(&luma_mask_arr[48], 16, mask0, mask1, mask2);\n\n    LD_SB5(src_y, src_stride, src_vt0, src_vt1, src_vt2, src_vt3, src_vt4);\n\n    src_y += (5 * src_stride);\n\n\n\n    src_vt0 = (v16i8) __msa_insve_w((v4i32) src_vt0, 1, (v4i32) src_vt1);\n\n    src_vt1 = (v16i8) __msa_insve_w((v4i32) src_vt1, 1, (v4i32) src_vt2);\n\n    src_vt2 = (v16i8) __msa_insve_w((v4i32) src_vt2, 1, (v4i32) src_vt3);\n\n    src_vt3 = (v16i8) __msa_insve_w((v4i32) src_vt3, 1, (v4i32) src_vt4);\n\n\n\n    XORI_B4_128_SB(src_vt0, src_vt1, src_vt2, src_vt3);\n\n    LD_SB4(src_x, src_stride, src_hz0, src_hz1, src_hz2, src_hz3);\n\n    LD_UB4(dst, dst_stride, dst0, dst1, dst2, dst3);\n\n    XORI_B4_128_SB(src_hz0, src_hz1, src_hz2, src_hz3);\n\n    hz_out0 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src_hz0, src_hz1,\n\n                                                          mask0, mask1, mask2);\n\n    hz_out1 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src_hz2, src_hz3,\n\n                                                          mask0, mask1, mask2);\n\n    SRARI_H2_SH(hz_out0, hz_out1, 5);\n\n    SAT_SH2_SH(hz_out0, hz_out1, 7);\n\n    LD_SB4(src_y, src_stride, src_vt5, src_vt6, src_vt7, src_vt8);\n\n\n\n    src_vt4 = (v16i8) __msa_insve_w((v4i32) src_vt4, 1, (v4i32) src_vt5);\n\n    src_vt5 = (v16i8) __msa_insve_w((v4i32) src_vt5, 1, (v4i32) src_vt6);\n\n    src_vt6 = (v16i8) __msa_insve_w((v4i32) src_vt6, 1, (v4i32) src_vt7);\n\n    src_vt7 = (v16i8) __msa_insve_w((v4i32) src_vt7, 1, (v4i32) src_vt8);\n\n\n\n    XORI_B4_128_SB(src_vt4, src_vt5, src_vt6, src_vt7);\n\n\n\n    /* filter calc */\n\n    vert_out0 = AVC_CALC_DPADD_B_6PIX_2COEFF_R_SH(src_vt0, src_vt1, src_vt2,\n\n                                                  src_vt3, src_vt4, src_vt5);\n\n    vert_out1 = AVC_CALC_DPADD_B_6PIX_2COEFF_R_SH(src_vt2, src_vt3, src_vt4,\n\n                                                  src_vt5, src_vt6, src_vt7);\n\n    SRARI_H2_SH(vert_out0, vert_out1, 5);\n\n    SAT_SH2_SH(vert_out0, vert_out1, 7);\n\n\n\n    res1 = __msa_srari_h((hz_out1 + vert_out1), 1);\n\n    res0 = __msa_srari_h((hz_out0 + vert_out0), 1);\n\n\n\n    SAT_SH2_SH(res0, res1, 7);\n\n    res = PCKEV_XORI128_UB(res0, res1);\n\n\n\n    dst0 = (v16u8) __msa_insve_w((v4i32) dst0, 1, (v4i32) dst1);\n\n    dst1 = (v16u8) __msa_insve_w((v4i32) dst2, 1, (v4i32) dst3);\n\n    dst0 = (v16u8) __msa_insve_d((v2i64) dst0, 1, (v2i64) dst1);\n\n    dst0 = __msa_aver_u_b(res, dst0);\n\n\n\n    ST4x4_UB(dst0, dst0, 0, 1, 2, 3, dst, dst_stride);\n\n}\n", "idx": 3416, "_split": "test", "_hash": "2673a3fe36829e39e9c171ab59f51a2b"}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_loopfilter_cb_or_cr_intra_edge_ver_msa(uint8_t *data_cb_or_cr,\n\n                                                       uint8_t alpha_in,\n\n                                                       uint8_t beta_in,\n\n                                                       uint32_t img_width)\n\n{\n\n    uint16_t out0, out1, out2, out3;\n\n    v8i16 tmp1;\n\n    v16u8 alpha, beta, is_less_than;\n\n    v8i16 p0_or_q0, q0_or_p0;\n\n    v16u8 p1_or_q1_org, p0_or_q0_org, q0_or_p0_org, q1_or_p1_org;\n\n    v16i8 zero = { 0 };\n\n    v16u8 p0_asub_q0, p1_asub_p0, q1_asub_q0;\n\n    v16u8 is_less_than_alpha, is_less_than_beta;\n\n    v8i16 p1_org_r, p0_org_r, q0_org_r, q1_org_r;\n\n\n\n    {\n\n        v16u8 row0, row1, row2, row3, row4, row5, row6, row7;\n\n\n\n        LOAD_8VECS_UB((data_cb_or_cr - 2), img_width,\n\n                      row0, row1, row2, row3, row4, row5, row6, row7);\n\n\n\n        TRANSPOSE8x4_B_UB(row0, row1, row2, row3, row4, row5, row6, row7,\n\n                          p1_or_q1_org, p0_or_q0_org,\n\n                          q0_or_p0_org, q1_or_p1_org);\n\n    }\n\n\n\n    alpha = (v16u8) __msa_fill_b(alpha_in);\n\n    beta = (v16u8) __msa_fill_b(beta_in);\n\n\n\n    p0_asub_q0 = __msa_asub_u_b(p0_or_q0_org, q0_or_p0_org);\n\n    p1_asub_p0 = __msa_asub_u_b(p1_or_q1_org, p0_or_q0_org);\n\n    q1_asub_q0 = __msa_asub_u_b(q1_or_p1_org, q0_or_p0_org);\n\n\n\n    is_less_than_alpha = (p0_asub_q0 < alpha);\n\n    is_less_than_beta = (p1_asub_p0 < beta);\n\n    is_less_than = is_less_than_beta & is_less_than_alpha;\n\n    is_less_than_beta = (q1_asub_q0 < beta);\n\n    is_less_than = is_less_than_beta & is_less_than;\n\n\n\n    is_less_than = (v16u8) __msa_ilvr_d((v2i64) zero, (v2i64) is_less_than);\n\n\n\n    if (!__msa_test_bz_v(is_less_than)) {\n\n        p1_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) p1_or_q1_org);\n\n        p0_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) p0_or_q0_org);\n\n        q0_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) q0_or_p0_org);\n\n        q1_org_r = (v8i16) __msa_ilvr_b(zero, (v16i8) q1_or_p1_org);\n\n\n\n        AVC_LOOP_FILTER_P0_OR_Q0(p0_org_r, q1_org_r, p1_org_r, p0_or_q0);\n\n        AVC_LOOP_FILTER_P0_OR_Q0(q0_org_r, p1_org_r, q1_org_r, q0_or_p0);\n\n\n\n        /* convert 16 bit output into 8 bit output */\n\n        p0_or_q0 = (v8i16) __msa_pckev_b(zero, (v16i8) p0_or_q0);\n\n        q0_or_p0 = (v8i16) __msa_pckev_b(zero, (v16i8) q0_or_p0);\n\n\n\n        p0_or_q0_org =\n\n            __msa_bmnz_v(p0_or_q0_org, (v16u8) p0_or_q0, is_less_than);\n\n        q0_or_p0_org =\n\n            __msa_bmnz_v(q0_or_p0_org, (v16u8) q0_or_p0, is_less_than);\n\n\n\n        tmp1 = (v8i16) __msa_ilvr_b((v16i8) q0_or_p0_org, (v16i8) p0_or_q0_org);\n\n\n\n        data_cb_or_cr -= 1;\n\n\n\n        out0 = __msa_copy_u_h(tmp1, 0);\n\n        out1 = __msa_copy_u_h(tmp1, 1);\n\n        out2 = __msa_copy_u_h(tmp1, 2);\n\n        out3 = __msa_copy_u_h(tmp1, 3);\n\n\n\n        STORE_HWORD(data_cb_or_cr, out0);\n\n        data_cb_or_cr += img_width;\n\n        STORE_HWORD(data_cb_or_cr, out1);\n\n        data_cb_or_cr += img_width;\n\n        STORE_HWORD(data_cb_or_cr, out2);\n\n        data_cb_or_cr += img_width;\n\n        STORE_HWORD(data_cb_or_cr, out3);\n\n        data_cb_or_cr += img_width;\n\n\n\n        out0 = __msa_copy_u_h(tmp1, 4);\n\n        out1 = __msa_copy_u_h(tmp1, 5);\n\n        out2 = __msa_copy_u_h(tmp1, 6);\n\n        out3 = __msa_copy_u_h(tmp1, 7);\n\n\n\n        STORE_HWORD(data_cb_or_cr, out0);\n\n        data_cb_or_cr += img_width;\n\n        STORE_HWORD(data_cb_or_cr, out1);\n\n        data_cb_or_cr += img_width;\n\n        STORE_HWORD(data_cb_or_cr, out2);\n\n        data_cb_or_cr += img_width;\n\n        STORE_HWORD(data_cb_or_cr, out3);\n\n    }\n\n}\n", "idx": 3452, "_split": "test", "_hash": "b714bee23381ae5b07fd0ff8d9724333"}
{"project": "FFmpeg", "commit_id": "e15824e75b5549e53eb5c1ffb79766321ac8d122", "target": 1, "func": "int ff_h261_handle_packet(AVFormatContext *ctx, PayloadContext *data,\n\n                          AVStream *st, AVPacket *pkt, uint32_t *timestamp,\n\n                          const uint8_t *buf, int len, uint16_t seq, int flags)\n\n{\n\n    int sbit, ebit, gobn, mbap, quant;\n\n    int res;\n\n\n\n    //av_log(ctx, AV_LOG_DEBUG, \"got h261 RTP packet with time: %u\\n\", timestamp);\n\n\n\n    /* drop data of previous packets in case of non-continuous (loss) packet stream */\n\n    if (data->buf && data->timestamp != *timestamp) {\n\n        h261_free_dyn_buffer(&data->buf);\n\n    }\n\n\n\n    /* sanity check for size of input packet */\n\n    if (len < 5 /* 4 bytes header and 1 byte payload at least */) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Too short H.261 RTP packet\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /*\n\n      decode the H.261 payload header according to section 4.1 of RFC 4587:\n\n      (uses 4 bytes between RTP header and H.261 stream per packet)\n\n\n\n         0                   1                   2                   3\n\n         0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n\n        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n        |SBIT |EBIT |I|V| GOBN  |   MBAP  |  QUANT  |  HMVD   |  VMVD   |\n\n        +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n\n\n           Start bit position (SBIT): 3 bits\n\n           End bit position (EBIT): 3 bits\n\n           INTRA-frame encoded data (I): 1 bit\n\n           Motion Vector flag (V): 1 bit\n\n           GOB number (GOBN): 4 bits\n\n           Macroblock address predictor (MBAP): 5 bits\n\n           Quantizer (QUANT): 5 bits\n\n           Horizontal motion vector data (HMVD): 5 bits\n\n           Vertical motion vector data (VMVD): 5 bits\n\n\n\n    */\n\n    sbit  =  (buf[0] >> 5) & 0x07;\n\n    ebit  =  (buf[0] >> 2) & 0x07;\n\n    gobn  =  (buf[1] >> 4) & 0x0f;\n\n    mbap  = ((buf[1] << 1) & 0x1e) | ((buf[1] >> 7) & 0x01);\n\n    quant =  (buf[1] >> 4) & 0x0f;\n\n\n\n    /* pass the H.261 payload header and continue with the actual payload */\n\n    buf += RTP_H261_PAYLOAD_HEADER_SIZE;\n\n    len -= RTP_H261_PAYLOAD_HEADER_SIZE;\n\n\n\n    /* start frame buffering with new dynamic buffer */\n\n    if (!data->buf) {\n\n        /* sanity check: a new frame starts with gobn=0, sbit=0, mbap=0, uqnat=0 */\n\n        if (!gobn  && !sbit && !mbap && !quant){\n\n            res = avio_open_dyn_buf(&data->buf);\n\n            if (res < 0)\n\n                return res;\n\n            /* update the timestamp in the frame packet with the one from the RTP packet */\n\n            data->timestamp = *timestamp;\n\n        } else {\n\n            /* frame not started yet, need more packets */\n\n            return AVERROR(EAGAIN);\n\n        }\n\n    }\n\n\n\n    /* do the \"byte merging\" at the boundaries of two consecutive frame fragments */\n\n    if (data->endbyte_bits || sbit) {\n\n        if (data->endbyte_bits == sbit) {\n\n            data->endbyte |= buf[0] & (0xff >> sbit);\n\n            data->endbyte_bits = 0;\n\n            buf++;\n\n            len--;\n\n            avio_w8(data->buf, data->endbyte);\n\n        } else {\n\n            /* ebit/sbit values inconsistent, assuming packet loss */\n\n            GetBitContext gb;\n\n            init_get_bits(&gb, buf, len*8 - ebit);\n\n            skip_bits(&gb, sbit);\n\n            if (data->endbyte_bits) {\n\n                data->endbyte |= get_bits(&gb, 8 - data->endbyte_bits);\n\n                avio_w8(data->buf, data->endbyte);\n\n            }\n\n            while (get_bits_left(&gb) >= 8)\n\n                avio_w8(data->buf, get_bits(&gb, 8));\n\n            data->endbyte_bits = get_bits_left(&gb);\n\n            if (data->endbyte_bits)\n\n                data->endbyte = get_bits(&gb, data->endbyte_bits) <<\n\n                                (8 - data->endbyte_bits);\n\n            ebit = 0;\n\n            len = 0;\n\n        }\n\n    }\n\n    if (ebit) {\n\n        if (len > 0)\n\n            avio_write(data->buf, buf, len - 1);\n\n        data->endbyte_bits = 8 - ebit;\n\n        data->endbyte = buf[len - 1] & (0xff << ebit);\n\n    } else {\n\n        avio_write(data->buf, buf, len);\n\n    }\n\n\n\n    /* RTP marker bit means: last fragment of current frame was received;\n\n       otherwise, an additional fragment is needed for the current frame */\n\n    if (!(flags & RTP_FLAG_MARKER))\n\n        return AVERROR(EAGAIN);\n\n\n\n    /* write the completed last byte from the \"byte merging\" */\n\n    if (data->endbyte_bits)\n\n        avio_w8(data->buf, data->endbyte);\n\n    data->endbyte_bits = 0;\n\n\n\n    /* close frame buffering and create resulting A/V packet */\n\n    res = ff_rtp_finalize_packet(pkt, &data->buf, st->index);\n\n    if (res < 0)\n\n        return res;\n\n\n\n    return 0;\n\n}\n", "idx": 3456, "_split": "test", "_hash": "9103394aa2b03c69b3bc6c7bd9aa226b"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int vdpau_mpeg_start_frame(AVCodecContext *avctx,\n\n                                  const uint8_t *buffer, uint32_t size)\n\n{\n\n    MpegEncContext * const s = avctx->priv_data;\n\n    Picture *pic             = s->current_picture_ptr;\n\n    struct vdpau_picture_context *pic_ctx = pic->hwaccel_picture_private;\n\n    VdpPictureInfoMPEG1Or2 *info = &pic_ctx->info.mpeg;\n\n    VdpVideoSurface ref;\n\n    int i;\n\n\n\n    /* fill VdpPictureInfoMPEG1Or2 struct */\n\n    info->forward_reference  = VDP_INVALID_HANDLE;\n\n    info->backward_reference = VDP_INVALID_HANDLE;\n\n\n\n    switch (s->pict_type) {\n\n    case AV_PICTURE_TYPE_B:\n\n        ref = ff_vdpau_get_surface_id(&s->next_picture.f);\n\n        assert(ref != VDP_INVALID_HANDLE);\n\n        info->backward_reference = ref;\n\n        /* fall through to forward prediction */\n\n    case AV_PICTURE_TYPE_P:\n\n        ref = ff_vdpau_get_surface_id(&s->last_picture.f);\n\n        info->forward_reference  = ref;\n\n    }\n\n\n\n    info->slice_count                = 0;\n\n    info->picture_structure          = s->picture_structure;\n\n    info->picture_coding_type        = s->pict_type;\n\n    info->intra_dc_precision         = s->intra_dc_precision;\n\n    info->frame_pred_frame_dct       = s->frame_pred_frame_dct;\n\n    info->concealment_motion_vectors = s->concealment_motion_vectors;\n\n    info->intra_vlc_format           = s->intra_vlc_format;\n\n    info->alternate_scan             = s->alternate_scan;\n\n    info->q_scale_type               = s->q_scale_type;\n\n    info->top_field_first            = s->top_field_first;\n\n    // Both for MPEG-1 only, zero for MPEG-2:\n\n    info->full_pel_forward_vector    = s->full_pel[0];\n\n    info->full_pel_backward_vector   = s->full_pel[1];\n\n    // For MPEG-1 fill both horizontal & vertical:\n\n    info->f_code[0][0]               = s->mpeg_f_code[0][0];\n\n    info->f_code[0][1]               = s->mpeg_f_code[0][1];\n\n    info->f_code[1][0]               = s->mpeg_f_code[1][0];\n\n    info->f_code[1][1]               = s->mpeg_f_code[1][1];\n\n    for (i = 0; i < 64; ++i) {\n\n        info->intra_quantizer_matrix[i]     = s->intra_matrix[i];\n\n        info->non_intra_quantizer_matrix[i] = s->inter_matrix[i];\n\n    }\n\n\n\n    return ff_vdpau_common_start_frame(pic_ctx, buffer, size);\n\n}\n", "idx": 3460, "_split": "test", "_hash": "b6a1037fd607e2a19c4d84698603cba7"}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "void h263_decode_init_vlc(MpegEncContext *s)\n\n{\n\n    static int done = 0;\n\n\n\n    if (!done) {\n\n        done = 1;\n\n\n\n        init_vlc(&intra_MCBPC_vlc, INTRA_MCBPC_VLC_BITS, 9, \n\n                 intra_MCBPC_bits, 1, 1,\n\n                 intra_MCBPC_code, 1, 1);\n\n        init_vlc(&inter_MCBPC_vlc, INTER_MCBPC_VLC_BITS, 28, \n\n                 inter_MCBPC_bits, 1, 1,\n\n                 inter_MCBPC_code, 1, 1);\n\n        init_vlc(&cbpy_vlc, CBPY_VLC_BITS, 16,\n\n                 &cbpy_tab[0][1], 2, 1,\n\n                 &cbpy_tab[0][0], 2, 1);\n\n        init_vlc(&mv_vlc, MV_VLC_BITS, 33,\n\n                 &mvtab[0][1], 2, 1,\n\n                 &mvtab[0][0], 2, 1);\n\n        init_rl(&rl_inter);\n\n        init_rl(&rl_intra);\n\n        init_rl(&rvlc_rl_inter);\n\n        init_rl(&rvlc_rl_intra);\n\n        init_rl(&rl_intra_aic);\n\n        init_vlc_rl(&rl_inter);\n\n        init_vlc_rl(&rl_intra);\n\n        init_vlc_rl(&rvlc_rl_inter);\n\n        init_vlc_rl(&rvlc_rl_intra);\n\n        init_vlc_rl(&rl_intra_aic);\n\n        init_vlc(&dc_lum, DC_VLC_BITS, 10 /* 13 */,\n\n                 &DCtab_lum[0][1], 2, 1,\n\n                 &DCtab_lum[0][0], 2, 1);\n\n        init_vlc(&dc_chrom, DC_VLC_BITS, 10 /* 13 */,\n\n                 &DCtab_chrom[0][1], 2, 1,\n\n                 &DCtab_chrom[0][0], 2, 1);\n\n        init_vlc(&sprite_trajectory, SPRITE_TRAJ_VLC_BITS, 15,\n\n                 &sprite_trajectory_tab[0][1], 4, 2,\n\n                 &sprite_trajectory_tab[0][0], 4, 2);\n\n        init_vlc(&mb_type_b_vlc, MB_TYPE_B_VLC_BITS, 4,\n\n                 &mb_type_b_tab[0][1], 2, 1,\n\n                 &mb_type_b_tab[0][0], 2, 1);\n\n        init_vlc(&h263_mbtype_b_vlc, H263_MBTYPE_B_VLC_BITS, 15,\n\n                 &h263_mbtype_b_tab[0][1], 2, 1,\n\n                 &h263_mbtype_b_tab[0][0], 2, 1);\n\n        init_vlc(&cbpc_b_vlc, CBPC_B_VLC_BITS, 4,\n\n                 &cbpc_b_tab[0][1], 2, 1,\n\n                 &cbpc_b_tab[0][0], 2, 1);\n\n    }\n\n}\n", "idx": 3476, "_split": "test", "_hash": "40e265f14502b63a2dd23a475ea04722"}
{"project": "FFmpeg", "commit_id": "d7e9533aa06f4073a27812349b35ba5fede11ca1", "target": 1, "func": "static int mpeg1_decode_sequence(AVCodecContext *avctx, \n\n                                 UINT8 *buf, int buf_size)\n\n{\n\n    Mpeg1Context *s1 = avctx->priv_data;\n\n    MpegEncContext *s = &s1->mpeg_enc_ctx;\n\n    int width, height, i, v, j;\n\n    \n\n    init_get_bits(&s->gb, buf, buf_size);\n\n\n\n    width = get_bits(&s->gb, 12);\n\n    height = get_bits(&s->gb, 12);\n\n    skip_bits(&s->gb, 4);\n\n    s->frame_rate_index = get_bits(&s->gb, 4);\n\n    if (s->frame_rate_index == 0)\n\n        return -1;\n\n    s->bit_rate = get_bits(&s->gb, 18) * 400;\n\n    if (get_bits1(&s->gb) == 0) /* marker */\n\n        return -1;\n\n    if (width <= 0 || height <= 0 ||\n\n        (width % 2) != 0 || (height % 2) != 0)\n\n        return -1;\n\n    if (width != s->width ||\n\n        height != s->height) {\n\n        /* start new mpeg1 context decoding */\n\n        s->out_format = FMT_MPEG1;\n\n        if (s1->mpeg_enc_ctx_allocated) {\n\n            MPV_common_end(s);\n\n        }\n\n        s->width = width;\n\n        s->height = height;\n\n        s->has_b_frames = 1;\n\n        s->avctx = avctx;\n\n        avctx->width = width;\n\n        avctx->height = height;\n\n        avctx->frame_rate = frame_rate_tab[s->frame_rate_index];\n\n        s->frame_rate = avctx->frame_rate;\n\n        avctx->bit_rate = s->bit_rate;\n\n        \n\n        if (MPV_common_init(s) < 0)\n\n            return -1;\n\n        mpeg1_init_vlc(s);\n\n        s1->mpeg_enc_ctx_allocated = 1;\n\n    }\n\n\n\n    skip_bits(&s->gb, 10); /* vbv_buffer_size */\n\n    skip_bits(&s->gb, 1);\n\n\n\n    /* get matrix */\n\n    if (get_bits1(&s->gb)) {\n\n        for(i=0;i<64;i++) {\n\n            v = get_bits(&s->gb, 8);\n\n            j = zigzag_direct[i];\n\n            s->intra_matrix[j] = v;\n\n            s->chroma_intra_matrix[j] = v;\n\n        }\n\n#ifdef DEBUG\n\n        dprintf(\"intra matrix present\\n\");\n\n        for(i=0;i<64;i++)\n\n            dprintf(\" %d\", s->intra_matrix[zigzag_direct[i]]);\n\n        printf(\"\\n\");\n\n#endif\n\n    } else {\n\n        for(i=0;i<64;i++) {\n\n            v = default_intra_matrix[i];\n\n            s->intra_matrix[i] = v;\n\n            s->chroma_intra_matrix[i] = v;\n\n        }\n\n    }\n\n    if (get_bits1(&s->gb)) {\n\n        for(i=0;i<64;i++) {\n\n            v = get_bits(&s->gb, 8);\n\n            j = zigzag_direct[i];\n\n            s->non_intra_matrix[j] = v;\n\n            s->chroma_non_intra_matrix[j] = v;\n\n        }\n\n#ifdef DEBUG\n\n        dprintf(\"non intra matrix present\\n\");\n\n        for(i=0;i<64;i++)\n\n            dprintf(\" %d\", s->non_intra_matrix[zigzag_direct[i]]);\n\n        printf(\"\\n\");\n\n#endif\n\n    } else {\n\n        for(i=0;i<64;i++) {\n\n            v = default_non_intra_matrix[i];\n\n            s->non_intra_matrix[i] = v;\n\n            s->chroma_non_intra_matrix[i] = v;\n\n        }\n\n    }\n\n\n\n    /* we set mpeg2 parameters so that it emulates mpeg1 */\n\n    s->progressive_sequence = 1;\n\n    s->progressive_frame = 1;\n\n    s->picture_structure = PICT_FRAME;\n\n    s->frame_pred_frame_dct = 1;\n\n    s->mpeg2 = 0;\n\n    return 0;\n\n}\n", "idx": 3499, "_split": "test", "_hash": "e18c3f7b780be206fb29877ba4fd94f6"}
{"project": "FFmpeg", "commit_id": "d600b18f224e02f8bfc6660bfa442e7ff3fb057c", "target": 1, "func": "void ff_rfps_calculate(AVFormatContext *ic)\n{\n    int i, j;\n    for (i = 0; i<ic->nb_streams; i++) {\n        AVStream *st = ic->streams[i];\n        if (st->codec->codec_type != AVMEDIA_TYPE_VIDEO)\n        // the check for tb_unreliable() is not completely correct, since this is not about handling\n        // a unreliable/inexact time base, but a time base that is finer than necessary, as e.g.\n        // ipmovie.c produces.\n        if (tb_unreliable(st->codec) && st->info->duration_count > 15 && st->info->duration_gcd > FFMAX(1, st->time_base.den/(500LL*st->time_base.num)) && !st->r_frame_rate.num)\n            av_reduce(&st->r_frame_rate.num, &st->r_frame_rate.den, st->time_base.den, st->time_base.num * st->info->duration_gcd, INT_MAX);\n        if (st->info->duration_count>1 && !st->r_frame_rate.num\n            && tb_unreliable(st->codec)) {\n            int num = 0;\n            double best_error= 0.01;\n            for (j=0; j<MAX_STD_TIMEBASES; j++) {\n                int k;\n                if(st->info->codec_info_duration && st->info->codec_info_duration*av_q2d(st->time_base) < (1001*12.0)/get_std_framerate(j))\n                if(!st->info->codec_info_duration && 1.0 < (1001*12.0)/get_std_framerate(j))\n                for(k=0; k<2; k++){\n                    int n= st->info->duration_count;\n                    double a= st->info->duration_error[k][0][j] / n;\n                    double error= st->info->duration_error[k][1][j]/n - a*a;\n                    if(error < best_error && best_error> 0.000000001){\n                        best_error= error;\n                        num = get_std_framerate(j);\n                    }\n                    if(error < 0.02)\n                        av_log(NULL, AV_LOG_DEBUG, \"rfps: %f %f\\n\", get_std_framerate(j) / 12.0/1001, error);\n                }\n            }\n            // do not increase frame rate by more than 1 % in order to match a standard rate.\n            if (num && (!st->r_frame_rate.num || (double)num/(12*1001) < 1.01 * av_q2d(st->r_frame_rate)))\n                av_reduce(&st->r_frame_rate.num, &st->r_frame_rate.den, num, 12*1001, INT_MAX);\n        }\n        av_freep(&st->info->duration_error);\n        st->info->last_dts = AV_NOPTS_VALUE;\n        st->info->duration_count = 0;\n        st->info->rfps_duration_sum = 0;\n    }\n}", "idx": 3502, "_split": "test", "_hash": "b5bf061fb52a3858bac04e23113cf007"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static void pred_spatial_direct_motion(const H264Context *const h, H264SliceContext *sl,\n\n                                       int *mb_type)\n\n{\n\n    int b8_stride = 2;\n\n    int b4_stride = h->b_stride;\n\n    int mb_xy = sl->mb_xy, mb_y = sl->mb_y;\n\n    int mb_type_col[2];\n\n    const int16_t (*l1mv0)[2], (*l1mv1)[2];\n\n    const int8_t *l1ref0, *l1ref1;\n\n    const int is_b8x8 = IS_8X8(*mb_type);\n\n    unsigned int sub_mb_type = MB_TYPE_L0L1;\n\n    int i8, i4;\n\n    int ref[2];\n\n    int mv[2];\n\n    int list;\n\n\n\n    assert(sl->ref_list[1][0].reference & 3);\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent,\n\n                           sl->mb_y + !!IS_INTERLACED(*mb_type));\n\n\n\n#define MB_TYPE_16x16_OR_INTRA (MB_TYPE_16x16 | MB_TYPE_INTRA4x4 | \\\n\n                                MB_TYPE_INTRA16x16 | MB_TYPE_INTRA_PCM)\n\n\n\n    /* ref = min(neighbors) */\n\n    for (list = 0; list < 2; list++) {\n\n        int left_ref     = sl->ref_cache[list][scan8[0] - 1];\n\n        int top_ref      = sl->ref_cache[list][scan8[0] - 8];\n\n        int refc         = sl->ref_cache[list][scan8[0] - 8 + 4];\n\n        const int16_t *C = sl->mv_cache[list][scan8[0]  - 8 + 4];\n\n        if (refc == PART_NOT_AVAILABLE) {\n\n            refc = sl->ref_cache[list][scan8[0] - 8 - 1];\n\n            C    = sl->mv_cache[list][scan8[0]  - 8 - 1];\n\n        }\n\n        ref[list] = FFMIN3((unsigned)left_ref,\n\n                           (unsigned)top_ref,\n\n                           (unsigned)refc);\n\n        if (ref[list] >= 0) {\n\n            /* This is just pred_motion() but with the cases removed that\n\n             * cannot happen for direct blocks. */\n\n            const int16_t *const A = sl->mv_cache[list][scan8[0] - 1];\n\n            const int16_t *const B = sl->mv_cache[list][scan8[0] - 8];\n\n\n\n            int match_count = (left_ref == ref[list]) +\n\n                              (top_ref  == ref[list]) +\n\n                              (refc     == ref[list]);\n\n\n\n            if (match_count > 1) { // most common\n\n                mv[list] = pack16to32(mid_pred(A[0], B[0], C[0]),\n\n                                      mid_pred(A[1], B[1], C[1]));\n\n            } else {\n\n                assert(match_count == 1);\n\n                if (left_ref == ref[list])\n\n                    mv[list] = AV_RN32A(A);\n\n                else if (top_ref == ref[list])\n\n                    mv[list] = AV_RN32A(B);\n\n                else\n\n                    mv[list] = AV_RN32A(C);\n\n            }\n\n        } else {\n\n            int mask = ~(MB_TYPE_L0 << (2 * list));\n\n            mv[list]  = 0;\n\n            ref[list] = -1;\n\n            if (!is_b8x8)\n\n                *mb_type &= mask;\n\n            sub_mb_type &= mask;\n\n        }\n\n    }\n\n    if (ref[0] < 0 && ref[1] < 0) {\n\n        ref[0] = ref[1] = 0;\n\n        if (!is_b8x8)\n\n            *mb_type |= MB_TYPE_L0L1;\n\n        sub_mb_type |= MB_TYPE_L0L1;\n\n    }\n\n\n\n    if (!(is_b8x8 | mv[0] | mv[1])) {\n\n        fill_rectangle(&sl->ref_cache[0][scan8[0]], 4, 4, 8, (uint8_t)ref[0], 1);\n\n        fill_rectangle(&sl->ref_cache[1][scan8[0]], 4, 4, 8, (uint8_t)ref[1], 1);\n\n        fill_rectangle(&sl->mv_cache[0][scan8[0]], 4, 4, 8, 0, 4);\n\n        fill_rectangle(&sl->mv_cache[1][scan8[0]], 4, 4, 8, 0, 4);\n\n        *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                 MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                   MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n        return;\n\n    }\n\n\n\n    if (IS_INTERLACED(sl->ref_list[1][0].parent->mb_type[mb_xy])) { // AFL/AFR/FR/FL -> AFL/FL\n\n        if (!IS_INTERLACED(*mb_type)) {                    //     AFR/FR    -> AFL/FL\n\n            mb_y  = (sl->mb_y & ~1) + sl->col_parity;\n\n            mb_xy = sl->mb_x +\n\n                    ((sl->mb_y & ~1) + sl->col_parity) * h->mb_stride;\n\n            b8_stride = 0;\n\n        } else {\n\n            mb_y  += sl->col_fieldoff;\n\n            mb_xy += h->mb_stride * sl->col_fieldoff; // non-zero for FL -> FL & differ parity\n\n        }\n\n        goto single_col;\n\n    } else {                                             // AFL/AFR/FR/FL -> AFR/FR\n\n        if (IS_INTERLACED(*mb_type)) {                   // AFL       /FL -> AFR/FR\n\n            mb_y           =  sl->mb_y & ~1;\n\n            mb_xy          = (sl->mb_y & ~1) * h->mb_stride + sl->mb_x;\n\n            mb_type_col[0] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n            mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy + h->mb_stride];\n\n            b8_stride      = 2 + 4 * h->mb_stride;\n\n            b4_stride     *= 6;\n\n            if (IS_INTERLACED(mb_type_col[0]) !=\n\n                IS_INTERLACED(mb_type_col[1])) {\n\n                mb_type_col[0] &= ~MB_TYPE_INTERLACED;\n\n                mb_type_col[1] &= ~MB_TYPE_INTERLACED;\n\n            }\n\n\n\n            sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n            if ((mb_type_col[0] & MB_TYPE_16x16_OR_INTRA) &&\n\n                (mb_type_col[1] & MB_TYPE_16x16_OR_INTRA) &&\n\n                !is_b8x8) {\n\n                *mb_type |= MB_TYPE_16x8 | MB_TYPE_DIRECT2;  /* B_16x8 */\n\n            } else {\n\n                *mb_type |= MB_TYPE_8x8;\n\n            }\n\n        } else {                                         //     AFR/FR    -> AFR/FR\n\nsingle_col:\n\n            mb_type_col[0] =\n\n            mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n\n\n            sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n            if (!is_b8x8 && (mb_type_col[0] & MB_TYPE_16x16_OR_INTRA)) {\n\n                *mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_16x16 */\n\n            } else if (!is_b8x8 &&\n\n                       (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16))) {\n\n                *mb_type |= MB_TYPE_DIRECT2 |\n\n                            (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16));\n\n            } else {\n\n                if (!h->sps.direct_8x8_inference_flag) {\n\n                    /* FIXME: Save sub mb types from previous frames (or derive\n\n                     * from MVs) so we know exactly what block size to use. */\n\n                    sub_mb_type += (MB_TYPE_8x8 - MB_TYPE_16x16); /* B_SUB_4x4 */\n\n                }\n\n                *mb_type |= MB_TYPE_8x8;\n\n            }\n\n        }\n\n    }\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent, mb_y);\n\n\n\n    l1mv0  = &sl->ref_list[1][0].parent->motion_val[0][h->mb2b_xy[mb_xy]];\n\n    l1mv1  = &sl->ref_list[1][0].parent->motion_val[1][h->mb2b_xy[mb_xy]];\n\n    l1ref0 = &sl->ref_list[1][0].parent->ref_index[0][4 * mb_xy];\n\n    l1ref1 = &sl->ref_list[1][0].parent->ref_index[1][4 * mb_xy];\n\n    if (!b8_stride) {\n\n        if (sl->mb_y & 1) {\n\n            l1ref0 += 2;\n\n            l1ref1 += 2;\n\n            l1mv0  += 2 * b4_stride;\n\n            l1mv1  += 2 * b4_stride;\n\n        }\n\n    }\n\n\n\n    if (IS_INTERLACED(*mb_type) != IS_INTERLACED(mb_type_col[0])) {\n\n        int n = 0;\n\n        for (i8 = 0; i8 < 4; i8++) {\n\n            int x8  = i8 & 1;\n\n            int y8  = i8 >> 1;\n\n            int xy8 = x8     + y8 * b8_stride;\n\n            int xy4 = x8 * 3 + y8 * b4_stride;\n\n            int a, b;\n\n\n\n            if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                continue;\n\n            sl->sub_mb_type[i8] = sub_mb_type;\n\n\n\n            fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[0], 1);\n\n            fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[1], 1);\n\n            if (!IS_INTRA(mb_type_col[y8]) && !sl->ref_list[1][0].parent->long_ref &&\n\n                ((l1ref0[xy8] == 0 &&\n\n                  FFABS(l1mv0[xy4][0]) <= 1 &&\n\n                  FFABS(l1mv0[xy4][1]) <= 1) ||\n\n                 (l1ref0[xy8] < 0 &&\n\n                  l1ref1[xy8] == 0 &&\n\n                  FFABS(l1mv1[xy4][0]) <= 1 &&\n\n                  FFABS(l1mv1[xy4][1]) <= 1))) {\n\n                a =\n\n                b = 0;\n\n                if (ref[0] > 0)\n\n                    a = mv[0];\n\n                if (ref[1] > 0)\n\n                    b = mv[1];\n\n                n++;\n\n            } else {\n\n                a = mv[0];\n\n                b = mv[1];\n\n            }\n\n            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, a, 4);\n\n            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, b, 4);\n\n        }\n\n        if (!is_b8x8 && !(n & 3))\n\n            *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                     MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                       MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n    } else if (IS_16X16(*mb_type)) {\n\n        int a, b;\n\n\n\n        fill_rectangle(&sl->ref_cache[0][scan8[0]], 4, 4, 8, (uint8_t)ref[0], 1);\n\n        fill_rectangle(&sl->ref_cache[1][scan8[0]], 4, 4, 8, (uint8_t)ref[1], 1);\n\n        if (!IS_INTRA(mb_type_col[0]) && !sl->ref_list[1][0].parent->long_ref &&\n\n            ((l1ref0[0] == 0 &&\n\n              FFABS(l1mv0[0][0]) <= 1 &&\n\n              FFABS(l1mv0[0][1]) <= 1) ||\n\n             (l1ref0[0] < 0 && !l1ref1[0] &&\n\n              FFABS(l1mv1[0][0]) <= 1 &&\n\n              FFABS(l1mv1[0][1]) <= 1 &&\n\n              h->x264_build > 33U))) {\n\n            a = b = 0;\n\n            if (ref[0] > 0)\n\n                a = mv[0];\n\n            if (ref[1] > 0)\n\n                b = mv[1];\n\n        } else {\n\n            a = mv[0];\n\n            b = mv[1];\n\n        }\n\n        fill_rectangle(&sl->mv_cache[0][scan8[0]], 4, 4, 8, a, 4);\n\n        fill_rectangle(&sl->mv_cache[1][scan8[0]], 4, 4, 8, b, 4);\n\n    } else {\n\n        int n = 0;\n\n        for (i8 = 0; i8 < 4; i8++) {\n\n            const int x8 = i8 & 1;\n\n            const int y8 = i8 >> 1;\n\n\n\n            if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                continue;\n\n            sl->sub_mb_type[i8] = sub_mb_type;\n\n\n\n            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, mv[0], 4);\n\n            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, mv[1], 4);\n\n            fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[0], 1);\n\n            fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[1], 1);\n\n\n\n            assert(b8_stride == 2);\n\n            /* col_zero_flag */\n\n            if (!IS_INTRA(mb_type_col[0]) && !sl->ref_list[1][0].parent->long_ref &&\n\n                (l1ref0[i8] == 0 ||\n\n                 (l1ref0[i8] < 0 &&\n\n                  l1ref1[i8] == 0 &&\n\n                  h->x264_build > 33U))) {\n\n                const int16_t (*l1mv)[2] = l1ref0[i8] == 0 ? l1mv0 : l1mv1;\n\n                if (IS_SUB_8X8(sub_mb_type)) {\n\n                    const int16_t *mv_col = l1mv[x8 * 3 + y8 * 3 * b4_stride];\n\n                    if (FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1) {\n\n                        if (ref[0] == 0)\n\n                            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2,\n\n                                           8, 0, 4);\n\n                        if (ref[1] == 0)\n\n                            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2,\n\n                                           8, 0, 4);\n\n                        n += 4;\n\n                    }\n\n                } else {\n\n                    int m = 0;\n\n                    for (i4 = 0; i4 < 4; i4++) {\n\n                        const int16_t *mv_col = l1mv[x8 * 2 + (i4 & 1) +\n\n                                                     (y8 * 2 + (i4 >> 1)) * b4_stride];\n\n                        if (FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1) {\n\n                            if (ref[0] == 0)\n\n                                AV_ZERO32(sl->mv_cache[0][scan8[i8 * 4 + i4]]);\n\n                            if (ref[1] == 0)\n\n                                AV_ZERO32(sl->mv_cache[1][scan8[i8 * 4 + i4]]);\n\n                            m++;\n\n                        }\n\n                    }\n\n                    if (!(m & 3))\n\n                        sl->sub_mb_type[i8] += MB_TYPE_16x16 - MB_TYPE_8x8;\n\n                    n += m;\n\n                }\n\n            }\n\n        }\n\n        if (!is_b8x8 && !(n & 15))\n\n            *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                     MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                       MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n    }\n\n}\n", "idx": 3517, "_split": "test", "_hash": "fc3a82161c1fdea25df9c68c47ec5b73"}
{"project": "FFmpeg", "commit_id": "066ad0926a53ea6ee9d5cb3e348160a881145e73", "target": 1, "func": "static int tmv_read_seek(AVFormatContext *s, int stream_index,\n\n                         int64_t timestamp, int flags)\n\n{\n\n    TMVContext *tmv = s->priv_data;\n\n    int64_t pos;\n\n\n\n    if (stream_index)\n\n        return -1;\n\n\n\n    pos = timestamp *\n\n          (tmv->audio_chunk_size + tmv->video_chunk_size + tmv->padding);\n\n\n\n    avio_seek(s->pb, pos + TMV_HEADER_SIZE, SEEK_SET);\n\n    tmv->stream_index = 0;\n\n    return 0;\n\n}\n", "idx": 3551, "_split": "test", "_hash": "a577886de9d805f1d4e45525606aae3d"}
{"project": "FFmpeg", "commit_id": "3d5822d9cf07d08bce82903e4715658f46b01b5c", "target": 1, "func": "static int jpeg2000_decode_packet(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile, int *tp_index,\n\n                                  Jpeg2000CodingStyle *codsty,\n\n                                  Jpeg2000ResLevel *rlevel, int precno,\n\n                                  int layno, uint8_t *expn, int numgbits)\n\n{\n\n    int bandno, cblkno, ret, nb_code_blocks;\n\n    int cwsno;\n\n\n\n    if (layno < rlevel->band[0].prec[precno].decoded_layers)\n\n        return 0;\n\n    rlevel->band[0].prec[precno].decoded_layers = layno + 1;\n\n\n\n    if (bytestream2_get_bytes_left(&s->g) == 0 && s->bit_index == 8) {\n\n        if (*tp_index < FF_ARRAY_ELEMS(tile->tile_part) - 1) {\n\n            s->g = tile->tile_part[++(*tp_index)].tpg;\n\n        }\n\n    }\n\n\n\n    if (bytestream2_peek_be32(&s->g) == JPEG2000_SOP_FIXED_BYTES)\n\n        bytestream2_skip(&s->g, JPEG2000_SOP_BYTE_LENGTH);\n\n\n\n    if (!(ret = get_bits(s, 1))) {\n\n        jpeg2000_flush(s);\n\n        return 0;\n\n    } else if (ret < 0)\n\n        return ret;\n\n\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++) {\n\n        Jpeg2000Band *band = rlevel->band + bandno;\n\n        Jpeg2000Prec *prec = band->prec + precno;\n\n\n\n        if (band->coord[0][0] == band->coord[0][1] ||\n\n            band->coord[1][0] == band->coord[1][1])\n\n            continue;\n\n        nb_code_blocks =  prec->nb_codeblocks_height *\n\n                          prec->nb_codeblocks_width;\n\n        for (cblkno = 0; cblkno < nb_code_blocks; cblkno++) {\n\n            Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n\n            int incl, newpasses, llen;\n\n\n\n            if (cblk->npasses)\n\n                incl = get_bits(s, 1);\n\n            else\n\n                incl = tag_tree_decode(s, prec->cblkincl + cblkno, layno + 1) == layno;\n\n            if (!incl)\n\n                continue;\n\n            else if (incl < 0)\n\n                return incl;\n\n\n\n            if (!cblk->npasses) {\n\n                int v = expn[bandno] + numgbits - 1 -\n\n                        tag_tree_decode(s, prec->zerobits + cblkno, 100);\n\n                if (v < 0 || v > 30) {\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                           \"nonzerobits %d invalid or unsupported\\n\", v);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                cblk->nonzerobits = v;\n\n            }\n\n            if ((newpasses = getnpasses(s)) < 0)\n\n                return newpasses;\n\n            av_assert2(newpasses > 0);\n\n            if (cblk->npasses + newpasses >= JPEG2000_MAX_PASSES) {\n\n                avpriv_request_sample(s->avctx, \"Too many passes\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n            if ((llen = getlblockinc(s)) < 0)\n\n                return llen;\n\n            if (cblk->lblock + llen + av_log2(newpasses) > 16) {\n\n                avpriv_request_sample(s->avctx,\n\n                                      \"Block with length beyond 16 bits\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n            cblk->lblock += llen;\n\n\n\n            cblk->nb_lengthinc = 0;\n\n            cblk->nb_terminationsinc = 0;\n\n            do {\n\n                int newpasses1 = 0;\n\n\n\n                while (newpasses1 < newpasses) {\n\n                    newpasses1 ++;\n\n                    if (needs_termination(codsty->cblk_style, cblk->npasses + newpasses1 - 1)) {\n\n                        cblk->nb_terminationsinc ++;\n\n                        break;\n\n                    }\n\n                }\n\n\n\n                if ((ret = get_bits(s, av_log2(newpasses1) + cblk->lblock)) < 0)\n\n                    return ret;\n\n                if (ret > sizeof(cblk->data)) {\n\n                    avpriv_request_sample(s->avctx,\n\n                                        \"Block with lengthinc greater than %\"SIZE_SPECIFIER\"\",\n\n                                        sizeof(cblk->data));\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n                cblk->lengthinc[cblk->nb_lengthinc++] = ret;\n\n                cblk->npasses  += newpasses1;\n\n                newpasses -= newpasses1;\n\n            } while(newpasses);\n\n        }\n\n    }\n\n    jpeg2000_flush(s);\n\n\n\n    if (codsty->csty & JPEG2000_CSTY_EPH) {\n\n        if (bytestream2_peek_be16(&s->g) == JPEG2000_EPH)\n\n            bytestream2_skip(&s->g, 2);\n\n        else\n\n            av_log(s->avctx, AV_LOG_ERROR, \"EPH marker not found. instead %X\\n\", bytestream2_peek_be32(&s->g));\n\n    }\n\n\n\n    for (bandno = 0; bandno < rlevel->nbands; bandno++) {\n\n        Jpeg2000Band *band = rlevel->band + bandno;\n\n        Jpeg2000Prec *prec = band->prec + precno;\n\n\n\n        nb_code_blocks = prec->nb_codeblocks_height * prec->nb_codeblocks_width;\n\n        for (cblkno = 0; cblkno < nb_code_blocks; cblkno++) {\n\n            Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n\n            for (cwsno = 0; cwsno < cblk->nb_lengthinc; cwsno ++) {\n\n                if (   bytestream2_get_bytes_left(&s->g) < cblk->lengthinc[cwsno]\n\n                    || sizeof(cblk->data) < cblk->length + cblk->lengthinc[cwsno] + 4\n\n                ) {\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                        \"Block length %\"PRIu16\" or lengthinc %d is too large, left %d\\n\",\n\n                        cblk->length, cblk->lengthinc[cwsno], bytestream2_get_bytes_left(&s->g));\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                bytestream2_get_bufferu(&s->g, cblk->data + cblk->length, cblk->lengthinc[cwsno]);\n\n                cblk->length   += cblk->lengthinc[cwsno];\n\n                cblk->lengthinc[cwsno] = 0;\n\n                if (cblk->nb_terminationsinc) {\n\n                    cblk->nb_terminationsinc--;\n\n                    cblk->nb_terminations++;\n\n                    cblk->data[cblk->length++] = 0xFF;\n\n                    cblk->data[cblk->length++] = 0xFF;\n\n                    cblk->data_start[cblk->nb_terminations] = cblk->length;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 3561, "_split": "test", "_hash": "5f9eb89f00c4de7a99c17899bac6a2a8"}
{"project": "FFmpeg", "commit_id": "b84a7330af41cec93384bf59ed68c67b09d105cd", "target": 1, "func": "static int64_t read_ts(char **line, int *duration)\n\n{\n\n    int64_t start, end;\n\n\n\n    if (sscanf(*line, \"%\"SCNd64\",%\"SCNd64, &start, &end) == 2) {\n\n        *line += strcspn(*line, \"\\\"\") + 1;\n\n        *duration = end - start;\n\n        return start;\n\n    }\n\n    return AV_NOPTS_VALUE;\n\n}\n", "idx": 3596, "_split": "test", "_hash": "724d84821c383a9980db0693349054da"}
{"project": "FFmpeg", "commit_id": "21bffa93a6fc73e1f1859f8bc224409eaaf27658", "target": 1, "func": "static void mov_write_uuidprof_tag(AVIOContext *pb, AVFormatContext *s)\n\n{\n\n    AVStream       *video_st    = s->streams[0];\n\n    AVCodecParameters *video_par = s->streams[0]->codecpar;\n\n    AVCodecParameters *audio_par = s->streams[1]->codecpar;\n\n    int audio_rate = audio_par->sample_rate;\n\n    // TODO: should be avg_frame_rate\n\n    int frame_rate = ((video_st->time_base.den) * (0x10000)) / (video_st->time_base.num);\n\n    int audio_kbitrate = audio_par->bit_rate / 1000;\n\n    int video_kbitrate = FFMIN(video_par->bit_rate / 1000, 800 - audio_kbitrate);\n\n\n\n    avio_wb32(pb, 0x94); /* size */\n\n    ffio_wfourcc(pb, \"uuid\");\n\n    ffio_wfourcc(pb, \"PROF\");\n\n\n\n    avio_wb32(pb, 0x21d24fce); /* 96 bit UUID */\n\n    avio_wb32(pb, 0xbb88695c);\n\n    avio_wb32(pb, 0xfac9c740);\n\n\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n    avio_wb32(pb, 0x3);  /* 3 sections ? */\n\n\n\n    avio_wb32(pb, 0x14); /* size */\n\n    ffio_wfourcc(pb, \"FPRF\");\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n    avio_wb32(pb, 0x0);  /* ? */\n\n\n\n    avio_wb32(pb, 0x2c);  /* size */\n\n    ffio_wfourcc(pb, \"APRF\"); /* audio */\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, 0x2);   /* TrackID */\n\n    ffio_wfourcc(pb, \"mp4a\");\n\n    avio_wb32(pb, 0x20f);\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, audio_kbitrate);\n\n    avio_wb32(pb, audio_kbitrate);\n\n    avio_wb32(pb, audio_rate);\n\n    avio_wb32(pb, audio_par->channels);\n\n\n\n    avio_wb32(pb, 0x34);  /* size */\n\n    ffio_wfourcc(pb, \"VPRF\");   /* video */\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, 0x1);    /* TrackID */\n\n    if (video_par->codec_id == AV_CODEC_ID_H264) {\n\n        ffio_wfourcc(pb, \"avc1\");\n\n        avio_wb16(pb, 0x014D);\n\n        avio_wb16(pb, 0x0015);\n\n    } else {\n\n        ffio_wfourcc(pb, \"mp4v\");\n\n        avio_wb16(pb, 0x0000);\n\n        avio_wb16(pb, 0x0103);\n\n    }\n\n    avio_wb32(pb, 0x0);\n\n    avio_wb32(pb, video_kbitrate);\n\n    avio_wb32(pb, video_kbitrate);\n\n    avio_wb32(pb, frame_rate);\n\n    avio_wb32(pb, frame_rate);\n\n    avio_wb16(pb, video_par->width);\n\n    avio_wb16(pb, video_par->height);\n\n    avio_wb32(pb, 0x010001); /* ? */\n\n}\n", "idx": 3610, "_split": "test", "_hash": "de4f721502080791c338278f9d26af2b"}
{"project": "FFmpeg", "commit_id": "8b2fce0d3f5a56c40c28899c9237210ca8f9cf75", "target": 1, "func": "static inline void yuv2nv12XinC(int16_t *lumFilter, int16_t **lumSrc, int lumFilterSize,\n\n                                int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,\n\n                                uint8_t *dest, uint8_t *uDest, int dstW, int chrDstW, int dstFormat)\n\n{\n\n    //FIXME Optimize (just quickly writen not opti..)\n\n    int i;\n\n    for (i=0; i<dstW; i++)\n\n    {\n\n        int val=1<<18;\n\n        int j;\n\n        for (j=0; j<lumFilterSize; j++)\n\n            val += lumSrc[j][i] * lumFilter[j];\n\n\n\n        dest[i]= av_clip_uint8(val>>19);\n\n    }\n\n\n\n    if (!uDest)\n\n        return;\n\n\n\n    if (dstFormat == PIX_FMT_NV12)\n\n        for (i=0; i<chrDstW; i++)\n\n        {\n\n            int u=1<<18;\n\n            int v=1<<18;\n\n            int j;\n\n            for (j=0; j<chrFilterSize; j++)\n\n            {\n\n                u += chrSrc[j][i] * chrFilter[j];\n\n                v += chrSrc[j][i + 2048] * chrFilter[j];\n\n            }\n\n\n\n            uDest[2*i]= av_clip_uint8(u>>19);\n\n            uDest[2*i+1]= av_clip_uint8(v>>19);\n\n        }\n\n    else\n\n        for (i=0; i<chrDstW; i++)\n\n        {\n\n            int u=1<<18;\n\n            int v=1<<18;\n\n            int j;\n\n            for (j=0; j<chrFilterSize; j++)\n\n            {\n\n                u += chrSrc[j][i] * chrFilter[j];\n\n                v += chrSrc[j][i + 2048] * chrFilter[j];\n\n            }\n\n\n\n            uDest[2*i]= av_clip_uint8(v>>19);\n\n            uDest[2*i+1]= av_clip_uint8(u>>19);\n\n        }\n\n}\n", "idx": 3621, "_split": "test", "_hash": "e345742e37ecae89243860190f07bcca"}
{"project": "FFmpeg", "commit_id": "8b27f76bf8790536afccb96780b5feb9c65636be", "target": 0, "func": "static av_cold void build_modpred(Indeo3DecodeContext *s)\n\n{\n\n  int i, j;\n\n\n\n  s->ModPred = av_malloc(8 * 128);\n\n\n\n  for (i=0; i < 128; ++i) {\n\n    s->ModPred[i+0*128] = i >  126 ? 254 : 2*(i + 1 - ((i + 1) % 2));\n\n    s->ModPred[i+1*128] = i ==   7 ?  20 :\n\n                          i == 119 ||\n\n                          i == 120 ? 236 : 2*(i + 2 - ((i + 1) % 3));\n\n    s->ModPred[i+2*128] = i >  125 ? 248 : 2*(i + 2 - ((i + 2) % 4));\n\n    s->ModPred[i+3*128] =                  2*(i + 1 - ((i - 3) % 5));\n\n    s->ModPred[i+4*128] = i ==   8 ?  20 : 2*(i + 1 - ((i - 3) % 6));\n\n    s->ModPred[i+5*128] =                  2*(i + 4 - ((i + 3) % 7));\n\n    s->ModPred[i+6*128] = i >  123 ? 240 : 2*(i + 4 - ((i + 4) % 8));\n\n    s->ModPred[i+7*128] =                  2*(i + 5 - ((i + 4) % 9));\n\n  }\n\n\n\n  s->corrector_type = av_malloc(24 * 256);\n\n\n\n  for (i=0; i < 24; ++i) {\n\n    for (j=0; j < 256; ++j) {\n\n      s->corrector_type[i*256+j] = j < corrector_type_0[i]          ? 1 :\n\n                                   j < 248 || (i == 16 && j == 248) ? 0 :\n\n                                   corrector_type_2[j - 248];\n\n    }\n\n  }\n\n}\n", "idx": 3658, "_split": "test", "_hash": "7f3819ea2fe6e1297c9f59658ee64ced"}
{"project": "FFmpeg", "commit_id": "29c2fcb6776f80a0a5551bb82b43bc14c8202331", "target": 1, "func": "static void lms_update(WmallDecodeCtx *s, int ich, int ilms, int16_t input, int16_t pred)\n\n{\n\n    int16_t icoef;\n\n    int recent = s->cdlms[ich][ilms].recent;\n\n    int16_t range = 1 << (s->bits_per_sample - 1);\n\n    int bps = s->bits_per_sample > 16 ? 4 : 2; // bytes per sample\n\n\n\n    if (input > pred) {\n\n        for (icoef = 0; icoef < s->cdlms[ich][ilms].order; icoef++)\n\n            s->cdlms[ich][ilms].coefs[icoef] +=\n\n                s->cdlms[ich][ilms].lms_updates[icoef + recent];\n\n    } else {\n\n        for (icoef = 0; icoef < s->cdlms[ich][ilms].order; icoef++)\n\n            s->cdlms[ich][ilms].coefs[icoef] -=\n\n                s->cdlms[ich][ilms].lms_updates[icoef];     // XXX: [icoef + recent] ?\n\n    }\n\n    s->cdlms[ich][ilms].recent--;\n\n    s->cdlms[ich][ilms].lms_prevvalues[recent] = av_clip(input, -range, range - 1);\n\n\n\n    if (input > pred)\n\n        s->cdlms[ich][ilms].lms_updates[recent] = s->update_speed[ich];\n\n    else if (input < pred)\n\n        s->cdlms[ich][ilms].lms_updates[recent] = -s->update_speed[ich];\n\n\n\n    /* XXX: spec says:\n\n    cdlms[iCh][ilms].updates[iRecent + cdlms[iCh][ilms].order >> 4] >>= 2;\n\n    lms_updates[iCh][ilms][iRecent + cdlms[iCh][ilms].order >> 3] >>= 1;\n\n\n\n        Questions is - are cdlms[iCh][ilms].updates[] and lms_updates[][][] two\n\n        seperate buffers? Here I've assumed that the two are same which makes\n\n        more sense to me.\n\n    */\n\n    s->cdlms[ich][ilms].lms_updates[recent + s->cdlms[ich][ilms].order >> 4] >>= 2;\n\n    s->cdlms[ich][ilms].lms_updates[recent + s->cdlms[ich][ilms].order >> 3] >>= 1;\n\n    /* XXX: recent + (s->cdlms[ich][ilms].order >> 4) ? */\n\n\n\n    if (s->cdlms[ich][ilms].recent == 0) {\n\n        /* XXX: This memcpy()s will probably fail if a fixed 32-bit buffer is used.\n\n                follow kshishkov's suggestion of using a union. */\n\n        memcpy(s->cdlms[ich][ilms].lms_prevvalues + s->cdlms[ich][ilms].order,\n\n               s->cdlms[ich][ilms].lms_prevvalues,\n\n               bps * s->cdlms[ich][ilms].order);\n\n        memcpy(s->cdlms[ich][ilms].lms_updates + s->cdlms[ich][ilms].order,\n\n               s->cdlms[ich][ilms].lms_updates,\n\n               bps * s->cdlms[ich][ilms].order);\n\n        s->cdlms[ich][ilms].recent = s->cdlms[ich][ilms].order;\n\n    }\n\n}\n", "idx": 3714, "_split": "test", "_hash": "a81115b4b9b08da574a541bd7d1ea049"}
{"project": "FFmpeg", "commit_id": "2f86e7bd12d8023da3349f10490b1e5b64531e23", "target": 1, "func": "static int create_filter(AVFilterContext **filt_ctx, AVFilterGraph *ctx, int index,\n\n                         const char *filt_name, const char *args, AVClass *log_ctx)\n\n{\n\n    AVFilter *filt;\n\n    char inst_name[30];\n\n    char tmp_args[256];\n\n    int ret;\n\n\n\n    snprintf(inst_name, sizeof(inst_name), \"Parsed filter %d %s\", index, filt_name);\n\n\n\n    filt = avfilter_get_by_name(filt_name);\n\n\n\n    if (!filt) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"No such filter: '%s'\\n\", filt_name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    ret = avfilter_open(filt_ctx, filt, inst_name);\n\n    if (!*filt_ctx) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Error creating filter '%s'\\n\", filt_name);\n\n        return ret;\n\n    }\n\n\n\n    if ((ret = avfilter_graph_add_filter(ctx, *filt_ctx)) < 0) {\n\n        avfilter_free(*filt_ctx);\n\n        return ret;\n\n    }\n\n\n\n    if (!strcmp(filt_name, \"scale\") && !strstr(args, \"flags\")) {\n\n        snprintf(tmp_args, sizeof(tmp_args), \"%s:%s\",\n\n                 args, ctx->scale_sws_opts);\n\n        args = tmp_args;\n\n    }\n\n\n\n    if ((ret = avfilter_init_filter(*filt_ctx, args, NULL)) < 0) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Error initializing filter '%s' with args '%s'\\n\", filt_name, args);\n\n        return ret;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 3721, "_split": "test", "_hash": "58f8019ec13df93f223c6e0dff2c0c9c"}
{"project": "FFmpeg", "commit_id": "dae7ff04160901a30a35af05f2f149b289c4f0b1", "target": 1, "func": "static void decode_mclms(WmallDecodeCtx *s)\n\n{\n\n    s->mclms_order = (get_bits(&s->gb, 4) + 1) * 2;\n\n    s->mclms_scaling = get_bits(&s->gb, 4);\n\n    if(get_bits1(&s->gb)) {\n\n\t// mclms_send_coef\n\n\tint i;\n\n\tint send_coef_bits;\n\n\tint cbits = av_log2(s->mclms_scaling + 1);\n\n\tassert(cbits == my_log2(s->mclms_scaling + 1));\n\n\tif(1 << cbits < s->mclms_scaling + 1)\n\n\t    cbits++;\n\n\n\n\tsend_coef_bits = (cbits ? get_bits(&s->gb, cbits) : 0) + 2;\n\n\n\n\tfor(i = 0; i < s->mclms_order * s->num_channels * s->num_channels; i++) {\n\n\t    s->mclms_coeffs[i] = get_bits(&s->gb, send_coef_bits);\n\n\t}\n\n\n\n\tfor(i = 0; i < s->num_channels; i++) {\n\n\t    int c;\n\n\t    for(c = 0; c < i; c++) {\n\n\t\ts->mclms_coeffs_cur[i * s->num_channels + c] = get_bits(&s->gb, send_coef_bits);\n\n\t    }\n\n\t}\n\n    }\n\n}\n", "idx": 3722, "_split": "test", "_hash": "b7a7a4281289d4435807f51858001b5d"}
{"project": "FFmpeg", "commit_id": "69d0a2922f76e4e121c9f434bdf29f55b26c0c66", "target": 0, "func": "static av_cold int sonic_encode_init(AVCodecContext *avctx)\n\n{\n\n    SonicContext *s = avctx->priv_data;\n\n    PutBitContext pb;\n\n    int i, version = 0;\n\n\n\n    if (avctx->channels > MAX_CHANNELS)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono and stereo streams are supported by now\\n\");\n\n        return AVERROR(EINVAL); /* only stereo or mono for now */\n\n    }\n\n\n\n    if (avctx->channels == 2)\n\n        s->decorrelation = MID_SIDE;\n\n    else\n\n        s->decorrelation = 3;\n\n\n\n    if (avctx->codec->id == AV_CODEC_ID_SONIC_LS)\n\n    {\n\n        s->lossless = 1;\n\n        s->num_taps = 32;\n\n        s->downsampling = 1;\n\n        s->quantization = 0.0;\n\n    }\n\n    else\n\n    {\n\n        s->num_taps = 128;\n\n        s->downsampling = 2;\n\n        s->quantization = 1.0;\n\n    }\n\n\n\n    // max tap 2048\n\n    if ((s->num_taps < 32) || (s->num_taps > 1024) ||\n\n        ((s->num_taps>>5)<<5 != s->num_taps))\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid number of taps\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    // generate taps\n\n    s->tap_quant = av_calloc(s->num_taps, sizeof(*s->tap_quant));\n\n    for (i = 0; i < s->num_taps; i++)\n\n        s->tap_quant[i] = ff_sqrt(i+1);\n\n\n\n    s->channels = avctx->channels;\n\n    s->samplerate = avctx->sample_rate;\n\n\n\n    s->block_align = 2048LL*s->samplerate/(44100*s->downsampling);\n\n    s->frame_size = s->channels*s->block_align*s->downsampling;\n\n\n\n    s->tail_size = s->num_taps*s->channels;\n\n    s->tail = av_calloc(s->tail_size, sizeof(*s->tail));\n\n    if (!s->tail)\n\n        return AVERROR(ENOMEM);\n\n\n\n    s->predictor_k = av_calloc(s->num_taps, sizeof(*s->predictor_k) );\n\n    if (!s->predictor_k)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < s->channels; i++)\n\n    {\n\n        s->coded_samples[i] = av_calloc(s->block_align, sizeof(**s->coded_samples));\n\n        if (!s->coded_samples[i])\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    s->int_samples = av_calloc(s->frame_size, sizeof(*s->int_samples));\n\n\n\n    s->window_size = ((2*s->tail_size)+s->frame_size);\n\n    s->window = av_calloc(s->window_size, sizeof(*s->window));\n\n    if (!s->window)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->extradata = av_mallocz(16);\n\n    if (!avctx->extradata)\n\n        return AVERROR(ENOMEM);\n\n    init_put_bits(&pb, avctx->extradata, 16*8);\n\n\n\n    put_bits(&pb, 2, version); // version\n\n    if (version == 1)\n\n    {\n\n        put_bits(&pb, 2, s->channels);\n\n        put_bits(&pb, 4, code_samplerate(s->samplerate));\n\n    }\n\n    put_bits(&pb, 1, s->lossless);\n\n    if (!s->lossless)\n\n        put_bits(&pb, 3, SAMPLE_SHIFT); // XXX FIXME: sample precision\n\n    put_bits(&pb, 2, s->decorrelation);\n\n    put_bits(&pb, 2, s->downsampling);\n\n    put_bits(&pb, 5, (s->num_taps >> 5)-1); // 32..1024\n\n    put_bits(&pb, 1, 0); // XXX FIXME: no custom tap quant table\n\n\n\n    flush_put_bits(&pb);\n\n    avctx->extradata_size = put_bits_count(&pb)/8;\n\n\n\n    av_log(avctx, AV_LOG_INFO, \"Sonic: ver: %d ls: %d dr: %d taps: %d block: %d frame: %d downsamp: %d\\n\",\n\n        version, s->lossless, s->decorrelation, s->num_taps, s->block_align, s->frame_size, s->downsampling);\n\n\n\n    avctx->frame_size = s->block_align*s->downsampling;\n\n\n\n    return 0;\n\n}\n", "idx": 3743, "_split": "test", "_hash": "48af5886467d3b7a6ae298c5f7ac0497"}
{"project": "FFmpeg", "commit_id": "2005fddcbb4e18e8f7c34326e40609e4a2d83c31", "target": 0, "func": "int ff_h264_check_intra_pred_mode(H264Context *h, int mode, int is_chroma)\n\n{\n\n    static const int8_t top[7]  = { LEFT_DC_PRED8x8, 1, -1, -1 };\n\n    static const int8_t left[7] = { TOP_DC_PRED8x8, -1, 2, -1, DC_128_PRED8x8 };\n\n\n\n    if (mode > 6U) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"out of range intra chroma pred mode at %d %d\\n\",\n\n               h->mb_x, h->mb_y);\n\n        return -1;\n\n    }\n\n\n\n    if (!(h->top_samples_available & 0x8000)) {\n\n        mode = top[mode];\n\n        if (mode < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"top block unavailable for requested intra mode at %d %d\\n\",\n\n                   h->mb_x, h->mb_y);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if ((h->left_samples_available & 0x8080) != 0x8080) {\n\n        mode = left[mode];\n\n        if (is_chroma && (h->left_samples_available & 0x8080)) {\n\n            // mad cow disease mode, aka MBAFF + constrained_intra_pred\n\n            mode = ALZHEIMER_DC_L0T_PRED8x8 +\n\n                   (!(h->left_samples_available & 0x8000)) +\n\n                   2 * (mode == DC_128_PRED8x8);\n\n        }\n\n        if (mode < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"left block unavailable for requested intra mode at %d %d\\n\",\n\n                   h->mb_x, h->mb_y);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    return mode;\n\n}\n", "idx": 3748, "_split": "test", "_hash": "060764e0619c80ae26f5e1988e1cd663"}
{"project": "FFmpeg", "commit_id": "4a023d5b53132ced3643d0e8397baa80cf75f656", "target": 0, "func": "static av_cold int check_format(AVCodecContext *avctx)\n\n{\n\n    AVCodecParserContext *parser;\n\n    uint8_t *pout;\n\n    int psize;\n\n    int index;\n\n    H264Context *h;\n\n    int ret = -1;\n\n\n\n    /* init parser & parse file */\n\n    parser = av_parser_init(avctx->codec->id);\n\n    if (!parser) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to open H.264 parser.\\n\");\n\n        goto final;\n\n    }\n\n    parser->flags = PARSER_FLAG_COMPLETE_FRAMES;\n\n    index = av_parser_parse2(parser, avctx, &pout, &psize, NULL, 0, 0, 0, 0);\n\n    if (index < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to parse this file.\\n\");\n\n        goto release_parser;\n\n    }\n\n\n\n    /* check if support */\n\n    h = parser->priv_data;\n\n    switch (h->sps.bit_depth_luma) {\n\n    case 8:\n\n        if (!CHROMA444(h) && !CHROMA422(h)) {\n\n            // only this will H.264 decoder switch to hwaccel\n\n            ret = 0;\n\n            break;\n\n        }\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported file.\\n\");\n\n    }\n\n\n\nrelease_parser:\n\n    av_parser_close(parser);\n\n\n\nfinal:\n\n    return ret;\n\n}\n", "idx": 3832, "_split": "test", "_hash": "ab362e4c5404ae50b1e8073754145643"}
{"project": "FFmpeg", "commit_id": "3f8148911c6e6e1f2a042bd4ca3ad8516a92130c", "target": 0, "func": "static int read_packet(AVFormatContext *s1, AVPacket *pkt)\n\n{\n\n    VideoDemuxData *s = s1->priv_data;\n\n    char filename_bytes[1024];\n\n    char *filename = filename_bytes;\n\n    int i;\n\n    int size[3]={0}, ret[3]={0};\n\n    AVIOContext *f[3] = {NULL};\n\n    AVCodecContext *codec= s1->streams[0]->codec;\n\n\n\n    if (!s->is_pipe) {\n\n        /* loop over input */\n\n        if (s->loop && s->img_number > s->img_last) {\n\n            s->img_number = s->img_first;\n\n        }\n\n        if (s->img_number > s->img_last)\n\n            return AVERROR_EOF;\n\n        if (s->use_glob) {\n\n#if HAVE_GLOB\n\n            filename = s->globstate.gl_pathv[s->img_number];\n\n#endif\n\n        } else {\n\n        if (av_get_frame_filename(filename_bytes, sizeof(filename_bytes),\n\n                                  s->path, s->img_number)<0 && s->img_number > 1)\n\n            return AVERROR(EIO);\n\n        }\n\n        for(i=0; i<3; i++){\n\n            if (avio_open2(&f[i], filename, AVIO_FLAG_READ,\n\n                           &s1->interrupt_callback, NULL) < 0) {\n\n                if(i>=1)\n\n                    break;\n\n                av_log(s1, AV_LOG_ERROR, \"Could not open file : %s\\n\",filename);\n\n                return AVERROR(EIO);\n\n            }\n\n            size[i]= avio_size(f[i]);\n\n\n\n            if(!s->split_planes)\n\n                break;\n\n            filename[ strlen(filename) - 1 ]= 'U' + i;\n\n        }\n\n\n\n        if(codec->codec_id == AV_CODEC_ID_RAWVIDEO && !codec->width)\n\n            infer_size(&codec->width, &codec->height, size[0]);\n\n    } else {\n\n        f[0] = s1->pb;\n\n        if (url_feof(f[0]))\n\n            return AVERROR(EIO);\n\n        size[0]= 4096;\n\n    }\n\n\n\n    av_new_packet(pkt, size[0] + size[1] + size[2]);\n\n    pkt->stream_index = 0;\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n\n\n    pkt->size= 0;\n\n    for(i=0; i<3; i++){\n\n        if(f[i]){\n\n            ret[i]= avio_read(f[i], pkt->data + pkt->size, size[i]);\n\n            if (!s->is_pipe)\n\n                avio_close(f[i]);\n\n            if(ret[i]>0)\n\n                pkt->size += ret[i];\n\n        }\n\n    }\n\n\n\n    if (ret[0] <= 0 || ret[1]<0 || ret[2]<0) {\n\n        av_free_packet(pkt);\n\n        return AVERROR(EIO); /* signal EOF */\n\n    } else {\n\n        s->img_count++;\n\n        s->img_number++;\n\n        return 0;\n\n    }\n\n}\n", "idx": 3901, "_split": "test", "_hash": "05338177ee21ac30d58ca0ac80ba2abb"}
{"project": "FFmpeg", "commit_id": "7ed47e97297fd5ef473d0cc93f0455adbadaac83", "target": 1, "func": "static int smacker_read_header(AVFormatContext *s)\n{\n    AVIOContext *pb = s->pb;\n    SmackerContext *smk = s->priv_data;\n    AVStream *st, *ast[7];\n    int i, ret;\n    int tbase;\n    /* read and check header */\n    smk->magic = avio_rl32(pb);\n    if (smk->magic != MKTAG('S', 'M', 'K', '2') && smk->magic != MKTAG('S', 'M', 'K', '4'))\n    smk->width = avio_rl32(pb);\n    smk->height = avio_rl32(pb);\n    smk->frames = avio_rl32(pb);\n    smk->pts_inc = (int32_t)avio_rl32(pb);\n    smk->flags = avio_rl32(pb);\n    if(smk->flags & SMACKER_FLAG_RING_FRAME)\n        smk->frames++;\n    for(i = 0; i < 7; i++)\n        smk->audio[i] = avio_rl32(pb);\n    smk->treesize = avio_rl32(pb);\n    if(smk->treesize >= UINT_MAX/4){ // smk->treesize + 16 must not overflow (this check is probably redundant)\n        av_log(s, AV_LOG_ERROR, \"treesize too large\\n\");\n//FIXME remove extradata \"rebuilding\"\n    smk->mmap_size = avio_rl32(pb);\n    smk->mclr_size = avio_rl32(pb);\n    smk->full_size = avio_rl32(pb);\n    smk->type_size = avio_rl32(pb);\n    for(i = 0; i < 7; i++) {\n        smk->rates[i]  = avio_rl24(pb);\n        smk->aflags[i] = avio_r8(pb);\n    smk->pad = avio_rl32(pb);\n    /* setup data */\n    if(smk->frames > 0xFFFFFF) {\n        av_log(s, AV_LOG_ERROR, \"Too many frames: %\"PRIu32\"\\n\", smk->frames);\n    smk->frm_size = av_malloc_array(smk->frames, sizeof(*smk->frm_size));\n    smk->frm_flags = av_malloc(smk->frames);\n    if (!smk->frm_size || !smk->frm_flags) {\n        av_freep(&smk->frm_size);\n        av_freep(&smk->frm_flags);\n        return AVERROR(ENOMEM);\n    smk->is_ver4 = (smk->magic != MKTAG('S', 'M', 'K', '2'));\n    /* read frame info */\n    for(i = 0; i < smk->frames; i++) {\n        smk->frm_size[i] = avio_rl32(pb);\n    for(i = 0; i < smk->frames; i++) {\n        smk->frm_flags[i] = avio_r8(pb);\n    /* init video codec */\n    st = avformat_new_stream(s, NULL);\n    if (!st)\n        return AVERROR(ENOMEM);\n    smk->videoindex = st->index;\n    st->codec->width = smk->width;\n    st->codec->height = smk->height;\n    st->codec->pix_fmt = AV_PIX_FMT_PAL8;\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n    st->codec->codec_id = AV_CODEC_ID_SMACKVIDEO;\n    st->codec->codec_tag = smk->magic;\n    /* Smacker uses 100000 as internal timebase */\n    if(smk->pts_inc < 0)\n        smk->pts_inc = -smk->pts_inc;\n    else\n        smk->pts_inc *= 100;\n    tbase = 100000;\n    av_reduce(&tbase, &smk->pts_inc, tbase, smk->pts_inc, (1UL<<31)-1);\n    avpriv_set_pts_info(st, 33, smk->pts_inc, tbase);\n    st->duration = smk->frames;\n    /* handle possible audio streams */\n    for(i = 0; i < 7; i++) {\n        smk->indexes[i] = -1;\n        if (smk->rates[i]) {\n            ast[i] = avformat_new_stream(s, NULL);\n            if (!ast[i])\n                return AVERROR(ENOMEM);\n            smk->indexes[i] = ast[i]->index;\n            ast[i]->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n            if (smk->aflags[i] & SMK_AUD_BINKAUD) {\n                ast[i]->codec->codec_id = AV_CODEC_ID_BINKAUDIO_RDFT;\n            } else if (smk->aflags[i] & SMK_AUD_USEDCT) {\n                ast[i]->codec->codec_id = AV_CODEC_ID_BINKAUDIO_DCT;\n            } else if (smk->aflags[i] & SMK_AUD_PACKED){\n                ast[i]->codec->codec_id = AV_CODEC_ID_SMACKAUDIO;\n                ast[i]->codec->codec_tag = MKTAG('S', 'M', 'K', 'A');\n            } else {\n                ast[i]->codec->codec_id = AV_CODEC_ID_PCM_U8;\n            if (smk->aflags[i] & SMK_AUD_STEREO) {\n                ast[i]->codec->channels       = 2;\n                ast[i]->codec->channel_layout = AV_CH_LAYOUT_STEREO;\n            } else {\n                ast[i]->codec->channels       = 1;\n                ast[i]->codec->channel_layout = AV_CH_LAYOUT_MONO;\n            ast[i]->codec->sample_rate = smk->rates[i];\n            ast[i]->codec->bits_per_coded_sample = (smk->aflags[i] & SMK_AUD_16BITS) ? 16 : 8;\n            if(ast[i]->codec->bits_per_coded_sample == 16 && ast[i]->codec->codec_id == AV_CODEC_ID_PCM_U8)\n                ast[i]->codec->codec_id = AV_CODEC_ID_PCM_S16LE;\n            avpriv_set_pts_info(ast[i], 64, 1, ast[i]->codec->sample_rate\n                    * ast[i]->codec->channels * ast[i]->codec->bits_per_coded_sample / 8);\n    /* load trees to extradata, they will be unpacked by decoder */\n    if(ff_alloc_extradata(st->codec, smk->treesize + 16)){\n        av_log(s, AV_LOG_ERROR,\n               \"Cannot allocate %\"PRIu32\" bytes of extradata\\n\",\n               smk->treesize + 16);\n        av_freep(&smk->frm_size);\n        av_freep(&smk->frm_flags);\n        return AVERROR(ENOMEM);\n    ret = avio_read(pb, st->codec->extradata + 16, st->codec->extradata_size - 16);\n    if(ret != st->codec->extradata_size - 16){\n        av_freep(&smk->frm_size);\n        av_freep(&smk->frm_flags);\n        return AVERROR(EIO);\n    ((int32_t*)st->codec->extradata)[0] = av_le2ne32(smk->mmap_size);\n    ((int32_t*)st->codec->extradata)[1] = av_le2ne32(smk->mclr_size);\n    ((int32_t*)st->codec->extradata)[2] = av_le2ne32(smk->full_size);\n    ((int32_t*)st->codec->extradata)[3] = av_le2ne32(smk->type_size);\n    smk->curstream = -1;\n    smk->nextpos = avio_tell(pb);\n    return 0;", "idx": 3913, "_split": "test", "_hash": "cc3d7a9dc47dd0db404b5b8cb07d77b3"}
{"project": "FFmpeg", "commit_id": "e8c4df40e399fc87c6167c5557c11e0d904ca720", "target": 1, "func": "static int mov_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    MOVContext *mov = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    MOVTrack *trk = &mov->tracks[pkt->stream_index];\n\n    AVCodecContext *enc = trk->enc;\n\n    unsigned int samplesInChunk = 0;\n\n    int size= pkt->size;\n\n\n\n    if (url_is_streamed(s->pb)) return 0; /* Can't handle that */\n\n    if (!size) return 0; /* Discard 0 sized packets */\n\n\n\n    if (enc->codec_id == CODEC_ID_AMR_NB) {\n\n        /* We must find out how many AMR blocks there are in one packet */\n\n        static uint16_t packed_size[16] =\n\n            {13, 14, 16, 18, 20, 21, 27, 32, 6, 0, 0, 0, 0, 0, 0, 0};\n\n        int len = 0;\n\n\n\n        while (len < size && samplesInChunk < 100) {\n\n            len += packed_size[(pkt->data[len] >> 3) & 0x0F];\n\n            samplesInChunk++;\n\n        }\n\n        if(samplesInChunk > 1){\n\n            av_log(s, AV_LOG_ERROR, \"fatal error, input is not a single packet, implement a AVParser for it\\n\");\n\n            return -1;\n\n        }\n\n    } else if (trk->sampleSize)\n\n        samplesInChunk = size/trk->sampleSize;\n\n    else\n\n        samplesInChunk = 1;\n\n\n\n    /* copy extradata if it exists */\n\n    if (trk->vosLen == 0 && enc->extradata_size > 0) {\n\n        trk->vosLen = enc->extradata_size;\n\n        trk->vosData = av_malloc(trk->vosLen);\n\n        memcpy(trk->vosData, enc->extradata, trk->vosLen);\n\n    }\n\n\n\n    if (enc->codec_id == CODEC_ID_H264 && trk->vosLen > 0 && *(uint8_t *)trk->vosData != 1) {\n\n        /* from x264 or from bytestream h264 */\n\n        /* nal reformating needed */\n\n        int ret = ff_avc_parse_nal_units(pkt->data, &pkt->data, &pkt->size);\n\n        if (ret < 0)\n\n            return ret;\n\n        assert(pkt->size);\n\n        size = pkt->size;\n\n    } else if (enc->codec_id == CODEC_ID_DNXHD && !trk->vosLen) {\n\n        /* copy frame to create needed atoms */\n\n        trk->vosLen = size;\n\n        trk->vosData = av_malloc(size);\n\n\n\n        memcpy(trk->vosData, pkt->data, size);\n\n    }\n\n\n\n    if (!(trk->entry % MOV_INDEX_CLUSTER_SIZE)) {\n\n        trk->cluster = av_realloc(trk->cluster, (trk->entry + MOV_INDEX_CLUSTER_SIZE) * sizeof(*trk->cluster));\n\n        if (!trk->cluster)\n\n            return -1;\n\n    }\n\n\n\n    trk->cluster[trk->entry].pos = url_ftell(pb);\n\n    trk->cluster[trk->entry].samplesInChunk = samplesInChunk;\n\n    trk->cluster[trk->entry].size = size;\n\n    trk->cluster[trk->entry].entries = samplesInChunk;\n\n    trk->cluster[trk->entry].dts = pkt->dts;\n\n    trk->trackDuration = pkt->dts - trk->cluster[0].dts + pkt->duration;\n\n\n\n    if (pkt->pts == AV_NOPTS_VALUE) {\n\n        av_log(s, AV_LOG_WARNING, \"pts has no value\\n\");\n\n        pkt->pts = pkt->dts;\n\n    }\n\n    if (pkt->dts != pkt->pts)\n\n        trk->hasBframes = 1;\n\n    trk->cluster[trk->entry].cts = pkt->pts - pkt->dts;\n\n    trk->cluster[trk->entry].key_frame = !!(pkt->flags & PKT_FLAG_KEY);\n\n    if(trk->cluster[trk->entry].key_frame)\n\n        trk->hasKeyframes++;\n\n    trk->entry++;\n\n    trk->sampleCount += samplesInChunk;\n\n    mov->mdat_size += size;\n\n\n\n    put_buffer(pb, pkt->data, size);\n\n\n\n    put_flush_packet(pb);\n\n    return 0;\n\n}", "idx": 3956, "_split": "test", "_hash": "cbeed5e5ce5ea86503a701df7c3b64d4"}
{"project": "FFmpeg", "commit_id": "5a2ad7ede33b5d63c1f1b1313a218da62e1c0d48", "target": 0, "func": "static int apply_window_and_mdct(vorbis_enc_context *venc,\n\n                                 float *audio, int samples)\n\n{\n\n    int channel;\n\n    const float * win = venc->win[0];\n\n    int window_len = 1 << (venc->log2_blocksize[0] - 1);\n\n    float n = (float)(1 << venc->log2_blocksize[0]) / 4.0;\n\n    AVFloatDSPContext *fdsp = venc->fdsp;\n\n\n\n    if (!venc->have_saved && !samples)\n\n        return 0;\n\n\n\n    if (venc->have_saved) {\n\n        for (channel = 0; channel < venc->channels; channel++)\n\n            memcpy(venc->samples + channel * window_len * 2,\n\n                   venc->saved + channel * window_len, sizeof(float) * window_len);\n\n    } else {\n\n        for (channel = 0; channel < venc->channels; channel++)\n\n            memset(venc->samples + channel * window_len * 2, 0,\n\n                   sizeof(float) * window_len);\n\n    }\n\n\n\n    if (samples) {\n\n        for (channel = 0; channel < venc->channels; channel++) {\n\n            float *offset = venc->samples + channel * window_len * 2 + window_len;\n\n\n\n            fdsp->vector_fmul_reverse(offset, audio + channel * window_len, win, samples);\n\n            fdsp->vector_fmul_scalar(offset, offset, 1/n, samples);\n\n        }\n\n    } else {\n\n        for (channel = 0; channel < venc->channels; channel++)\n\n            memset(venc->samples + channel * window_len * 2 + window_len,\n\n                   0, sizeof(float) * window_len);\n\n    }\n\n\n\n    for (channel = 0; channel < venc->channels; channel++)\n\n        venc->mdct[0].mdct_calc(&venc->mdct[0], venc->coeffs + channel * window_len,\n\n                     venc->samples + channel * window_len * 2);\n\n\n\n    if (samples) {\n\n        for (channel = 0; channel < venc->channels; channel++) {\n\n            float *offset = venc->saved + channel * window_len;\n\n\n\n            fdsp->vector_fmul(offset, audio + channel * window_len, win, samples);\n\n            fdsp->vector_fmul_scalar(offset, offset, 1/n, samples);\n\n        }\n\n        venc->have_saved = 1;\n\n    } else {\n\n        venc->have_saved = 0;\n\n    }\n\n    return 1;\n\n}\n", "idx": 3971, "_split": "test", "_hash": "a3ef3ba3f216aff8dbdcef588203cc2f"}
{"project": "FFmpeg", "commit_id": "8542f9c4f17125d483c40c0c5723842f1c982f81", "target": 1, "func": "static int32_t parse_gain(const char *gain)\n\n{\n\n    char *fraction;\n\n    int  scale = 10000;\n\n    int32_t mb = 0;\n\n    int sign   = 1;\n\n    int db;\n\n\n\n    if (!gain)\n\n        return INT32_MIN;\n\n\n\n    gain += strspn(gain, \" \\t\");\n\n\n\n    if (*gain == '-')\n\n        sign = -1;\n\n\n\n    db = strtol(gain, &fraction, 0);\n\n    if (*fraction++ == '.') {\n\n        while (av_isdigit(*fraction) && scale) {\n\n            mb += scale * (*fraction - '0');\n\n            scale /= 10;\n\n            fraction++;\n\n        }\n\n    }\n\n\n\n    if (abs(db) > (INT32_MAX - mb) / 100000)\n\n        return INT32_MIN;\n\n\n\n    return db * 100000 + sign * mb;\n\n}\n", "idx": 3984, "_split": "test", "_hash": "a427be0fa82c2179928669f9570e7f23"}
{"project": "FFmpeg", "commit_id": "6f1b2967712e25e4c39c506862982b3011e06532", "target": 1, "func": "static int lag_decode_zero_run_line(LagarithContext *l, uint8_t *dst,\n\n                                    const uint8_t *src, const uint8_t *src_end,\n\n                                    int width, int esc_count)\n\n{\n\n    int i = 0;\n\n    int count;\n\n    uint8_t zero_run = 0;\n\n    const uint8_t *src_start = src;\n\n    uint8_t mask1 = -(esc_count < 2);\n\n    uint8_t mask2 = -(esc_count < 3);\n\n    uint8_t *end = dst + (width - 2);\n\n\n\n    avpriv_request_sample(l->avctx, \"zero_run_line\");\n\n    return AVERROR_PATCHWELCOME;\n\n\n\noutput_zeros:\n\n    if (l->zeros_rem) {\n\n        count = FFMIN(l->zeros_rem, width - i);\n\n        if (end - dst < count) {\n\n            av_log(l->avctx, AV_LOG_ERROR, \"Too many zeros remaining.\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        memset(dst, 0, count);\n\n        l->zeros_rem -= count;\n\n        dst += count;\n\n    }\n\n\n\n    while (dst < end) {\n\n        i = 0;\n\n        while (!zero_run && dst + i < end) {\n\n            i++;\n\n            if (i+2 >= src_end - src)\n\n                return AVERROR_INVALIDDATA;\n\n            zero_run =\n\n                !(src[i] | (src[i + 1] & mask1) | (src[i + 2] & mask2));\n\n        }\n\n        if (zero_run) {\n\n            zero_run = 0;\n\n            i += esc_count;\n\n            memcpy(dst, src, i);\n\n            dst += i;\n\n            l->zeros_rem = lag_calc_zero_run(src[i]);\n\n\n\n            src += i + 1;\n\n            goto output_zeros;\n\n        } else {\n\n            memcpy(dst, src, i);\n\n            src += i;\n\n            dst += i;\n\n        }\n\n    }\n\n    return  src - src_start;\n\n}\n", "idx": 4009, "_split": "test", "_hash": "593a62637c0b12f6a89290e1cb62baff"}
{"project": "FFmpeg", "commit_id": "86b0d9cd58137fc499f263267c3219ac6186b98e", "target": 0, "func": "static void av_always_inline filter_mb_edgecv( uint8_t *pix, int stride, int16_t bS[4], unsigned int qp, H264Context *h ) {\n\n    const unsigned int index_a = qp + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = beta_table[qp + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]]+1;\n\n        tc[1] = tc0_table[index_a][bS[1]]+1;\n\n        tc[2] = tc0_table[index_a][bS[2]]+1;\n\n        tc[3] = tc0_table[index_a][bS[3]]+1;\n\n        h->h264dsp.h264_h_loop_filter_chroma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->h264dsp.h264_h_loop_filter_chroma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 4025, "_split": "test", "_hash": "8a5e9370963d7db7415f21c0c66a329e"}
{"project": "FFmpeg", "commit_id": "8c5cd1c9d33b4b287f85d42efb1aecfaee31de6c", "target": 1, "func": "static int decode_entropy_coded_image(WebPContext *s, enum ImageRole role,\n\n                                      int w, int h)\n\n{\n\n    ImageContext *img;\n\n    HuffReader *hg;\n\n    int i, j, ret, x, y, width;\n\n\n\n    img       = &s->image[role];\n\n    img->role = role;\n\n\n\n    if (!img->frame) {\n\n        img->frame = av_frame_alloc();\n\n        if (!img->frame)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    img->frame->format = AV_PIX_FMT_ARGB;\n\n    img->frame->width  = w;\n\n    img->frame->height = h;\n\n\n\n    if (role == IMAGE_ROLE_ARGB && !img->is_alpha_primary) {\n\n        ThreadFrame pt = { .f = img->frame };\n\n        ret = ff_thread_get_buffer(s->avctx, &pt, 0);\n\n    } else\n\n        ret = av_frame_get_buffer(img->frame, 1);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (get_bits1(&s->gb)) {\n\n        img->color_cache_bits = get_bits(&s->gb, 4);\n\n        if (img->color_cache_bits < 1 || img->color_cache_bits > 11) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"invalid color cache bits: %d\\n\",\n\n                   img->color_cache_bits);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        img->color_cache = av_mallocz_array(1 << img->color_cache_bits,\n\n                                            sizeof(*img->color_cache));\n\n        if (!img->color_cache)\n\n            return AVERROR(ENOMEM);\n\n    } else {\n\n        img->color_cache_bits = 0;\n\n    }\n\n\n\n    img->nb_huffman_groups = 1;\n\n    if (role == IMAGE_ROLE_ARGB && get_bits1(&s->gb)) {\n\n        ret = decode_entropy_image(s);\n\n        if (ret < 0)\n\n            return ret;\n\n        img->nb_huffman_groups = s->nb_huffman_groups;\n\n    }\n\n    img->huffman_groups = av_mallocz_array(img->nb_huffman_groups *\n\n                                           HUFFMAN_CODES_PER_META_CODE,\n\n                                           sizeof(*img->huffman_groups));\n\n    if (!img->huffman_groups)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < img->nb_huffman_groups; i++) {\n\n        hg = &img->huffman_groups[i * HUFFMAN_CODES_PER_META_CODE];\n\n        for (j = 0; j < HUFFMAN_CODES_PER_META_CODE; j++) {\n\n            int alphabet_size = alphabet_sizes[j];\n\n            if (!j && img->color_cache_bits > 0)\n\n                alphabet_size += 1 << img->color_cache_bits;\n\n\n\n            if (get_bits1(&s->gb)) {\n\n                read_huffman_code_simple(s, &hg[j]);\n\n            } else {\n\n                ret = read_huffman_code_normal(s, &hg[j], alphabet_size);\n\n                if (ret < 0)\n\n                    return ret;\n\n            }\n\n        }\n\n    }\n\n\n\n    width = img->frame->width;\n\n    if (role == IMAGE_ROLE_ARGB && s->reduced_width > 0)\n\n        width = s->reduced_width;\n\n\n\n    x = 0; y = 0;\n\n    while (y < img->frame->height) {\n\n        int v;\n\n\n\n        hg = get_huffman_group(s, img, x, y);\n\n        v = huff_reader_get_symbol(&hg[HUFF_IDX_GREEN], &s->gb);\n\n        if (v < NUM_LITERAL_CODES) {\n\n            /* literal pixel values */\n\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n\n            p[2] = v;\n\n            p[1] = huff_reader_get_symbol(&hg[HUFF_IDX_RED],   &s->gb);\n\n            p[3] = huff_reader_get_symbol(&hg[HUFF_IDX_BLUE],  &s->gb);\n\n            p[0] = huff_reader_get_symbol(&hg[HUFF_IDX_ALPHA], &s->gb);\n\n            if (img->color_cache_bits)\n\n                color_cache_put(img, AV_RB32(p));\n\n            x++;\n\n            if (x == width) {\n\n                x = 0;\n\n                y++;\n\n            }\n\n        } else if (v < NUM_LITERAL_CODES + NUM_LENGTH_CODES) {\n\n            /* LZ77 backwards mapping */\n\n            int prefix_code, length, distance, ref_x, ref_y;\n\n\n\n            /* parse length and distance */\n\n            prefix_code = v - NUM_LITERAL_CODES;\n\n            if (prefix_code < 4) {\n\n                length = prefix_code + 1;\n\n            } else {\n\n                int extra_bits = (prefix_code - 2) >> 1;\n\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n\n                length = offset + get_bits(&s->gb, extra_bits) + 1;\n\n            }\n\n            prefix_code = huff_reader_get_symbol(&hg[HUFF_IDX_DIST], &s->gb);\n\n            if (prefix_code > 39) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"distance prefix code too large: %d\\n\", prefix_code);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (prefix_code < 4) {\n\n                distance = prefix_code + 1;\n\n            } else {\n\n                int extra_bits = prefix_code - 2 >> 1;\n\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n\n                distance = offset + get_bits(&s->gb, extra_bits) + 1;\n\n            }\n\n\n\n            /* find reference location */\n\n            if (distance <= NUM_SHORT_DISTANCES) {\n\n                int xi = lz77_distance_offsets[distance - 1][0];\n\n                int yi = lz77_distance_offsets[distance - 1][1];\n\n                distance = FFMAX(1, xi + yi * width);\n\n            } else {\n\n                distance -= NUM_SHORT_DISTANCES;\n\n            }\n\n            ref_x = x;\n\n            ref_y = y;\n\n            if (distance <= x) {\n\n                ref_x -= distance;\n\n                distance = 0;\n\n            } else {\n\n                ref_x = 0;\n\n                distance -= x;\n\n            }\n\n            while (distance >= width) {\n\n                ref_y--;\n\n                distance -= width;\n\n            }\n\n            if (distance > 0) {\n\n                ref_x = width - distance;\n\n                ref_y--;\n\n            }\n\n            ref_x = FFMAX(0, ref_x);\n\n            ref_y = FFMAX(0, ref_y);\n\n\n\n            /* copy pixels\n\n             * source and dest regions can overlap and wrap lines, so just\n\n             * copy per-pixel */\n\n            for (i = 0; i < length; i++) {\n\n                uint8_t *p_ref = GET_PIXEL(img->frame, ref_x, ref_y);\n\n                uint8_t *p     = GET_PIXEL(img->frame,     x,     y);\n\n\n\n                AV_COPY32(p, p_ref);\n\n                if (img->color_cache_bits)\n\n                    color_cache_put(img, AV_RB32(p));\n\n                x++;\n\n                ref_x++;\n\n                if (x == width) {\n\n                    x = 0;\n\n                    y++;\n\n                }\n\n                if (ref_x == width) {\n\n                    ref_x = 0;\n\n                    ref_y++;\n\n                }\n\n                if (y == img->frame->height || ref_y == img->frame->height)\n\n                    break;\n\n            }\n\n        } else {\n\n            /* read from color cache */\n\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n\n            int cache_idx = v - (NUM_LITERAL_CODES + NUM_LENGTH_CODES);\n\n\n\n            if (!img->color_cache_bits) {\n\n                av_log(s->avctx, AV_LOG_ERROR, \"color cache not found\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (cache_idx >= 1 << img->color_cache_bits) {\n\n                av_log(s->avctx, AV_LOG_ERROR,\n\n                       \"color cache index out-of-bounds\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            AV_WB32(p, img->color_cache[cache_idx]);\n\n            x++;\n\n            if (x == width) {\n\n                x = 0;\n\n                y++;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 4029, "_split": "test", "_hash": "943183780262df8fbd356d882ee2e72c"}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "void ff_mspel_motion(MpegEncContext *s,\n\n                               uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                               uint8_t **ref_picture, op_pixels_func (*pix_op)[4],\n\n                               int motion_x, int motion_y, int h)\n\n{\n\n    Wmv2Context * const w= (Wmv2Context*)s;\n\n    uint8_t *ptr;\n\n    int dxy, offset, mx, my, src_x, src_y, v_edge_pos, linesize, uvlinesize;\n\n    int emu=0;\n\n\n\n    dxy = ((motion_y & 1) << 1) | (motion_x & 1);\n\n    dxy = 2*dxy + w->hshift;\n\n    src_x = s->mb_x * 16 + (motion_x >> 1);\n\n    src_y = s->mb_y * 16 + (motion_y >> 1);\n\n\n\n    /* WARNING: do no forget half pels */\n\n    v_edge_pos = s->v_edge_pos;\n\n    src_x = av_clip(src_x, -16, s->width);\n\n    src_y = av_clip(src_y, -16, s->height);\n\n\n\n    if(src_x<=-16 || src_x >= s->width)\n\n        dxy &= ~3;\n\n    if(src_y<=-16 || src_y >= s->height)\n\n        dxy &= ~4;\n\n\n\n    linesize   = s->linesize;\n\n    uvlinesize = s->uvlinesize;\n\n    ptr = ref_picture[0] + (src_y * linesize) + src_x;\n\n\n\n        if(src_x<1 || src_y<1 || src_x + 17  >= s->h_edge_pos\n\n                              || src_y + h+1 >= v_edge_pos){\n\n            s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr - 1 - s->linesize, s->linesize, 19, 19,\n\n                             src_x-1, src_y-1, s->h_edge_pos, s->v_edge_pos);\n\n            ptr= s->edge_emu_buffer + 1 + s->linesize;\n\n            emu=1;\n\n        }\n\n\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y             , ptr             , linesize);\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y+8           , ptr+8           , linesize);\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y  +8*linesize, ptr  +8*linesize, linesize);\n\n    s->dsp.put_mspel_pixels_tab[dxy](dest_y+8+8*linesize, ptr+8+8*linesize, linesize);\n\n\n\n    if(s->flags&CODEC_FLAG_GRAY) return;\n\n\n\n    if (s->out_format == FMT_H263) {\n\n        dxy = 0;\n\n        if ((motion_x & 3) != 0)\n\n            dxy |= 1;\n\n        if ((motion_y & 3) != 0)\n\n            dxy |= 2;\n\n        mx = motion_x >> 2;\n\n        my = motion_y >> 2;\n\n    } else {\n\n        mx = motion_x / 2;\n\n        my = motion_y / 2;\n\n        dxy = ((my & 1) << 1) | (mx & 1);\n\n        mx >>= 1;\n\n        my >>= 1;\n\n    }\n\n\n\n    src_x = s->mb_x * 8 + mx;\n\n    src_y = s->mb_y * 8 + my;\n\n    src_x = av_clip(src_x, -8, s->width >> 1);\n\n    if (src_x == (s->width >> 1))\n\n        dxy &= ~1;\n\n    src_y = av_clip(src_y, -8, s->height >> 1);\n\n    if (src_y == (s->height >> 1))\n\n        dxy &= ~2;\n\n    offset = (src_y * uvlinesize) + src_x;\n\n    ptr = ref_picture[1] + offset;\n\n    if(emu){\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr, s->uvlinesize, 9, 9,\n\n                         src_x, src_y, s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n        ptr= s->edge_emu_buffer;\n\n    }\n\n    pix_op[1][dxy](dest_cb, ptr, uvlinesize, h >> 1);\n\n\n\n    ptr = ref_picture[2] + offset;\n\n    if(emu){\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr, s->uvlinesize, 9, 9,\n\n                         src_x, src_y, s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n        ptr= s->edge_emu_buffer;\n\n    }\n\n    pix_op[1][dxy](dest_cr, ptr, uvlinesize, h >> 1);\n\n}\n", "idx": 4041, "_split": "test", "_hash": "78940787ae0776f24e0003f39ca91421"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int svq1_encode_plane(SVQ1Context *s, int plane,\n\n                             unsigned char *src_plane,\n\n                             unsigned char *ref_plane,\n\n                             unsigned char *decoded_plane,\n\n                             int width, int height, int src_stride, int stride)\n\n{\n\n    const AVFrame *f = s->avctx->coded_frame;\n\n    int x, y;\n\n    int i;\n\n    int block_width, block_height;\n\n    int level;\n\n    int threshold[6];\n\n    uint8_t *src     = s->scratchbuf + stride * 16;\n\n    const int lambda = (f->quality * f->quality) >>\n\n                       (2 * FF_LAMBDA_SHIFT);\n\n\n\n    /* figure out the acceptable level thresholds in advance */\n\n    threshold[5] = QUALITY_THRESHOLD;\n\n    for (level = 4; level >= 0; level--)\n\n        threshold[level] = threshold[level + 1] * THRESHOLD_MULTIPLIER;\n\n\n\n    block_width  = (width  + 15) / 16;\n\n    block_height = (height + 15) / 16;\n\n\n\n    if (f->pict_type == AV_PICTURE_TYPE_P) {\n\n        s->m.avctx                         = s->avctx;\n\n        s->m.current_picture_ptr           = &s->m.current_picture;\n\n        s->m.last_picture_ptr              = &s->m.last_picture;\n\n        s->m.last_picture.f.data[0]        = ref_plane;\n\n        s->m.linesize                      =\n\n        s->m.last_picture.f.linesize[0]    =\n\n        s->m.new_picture.f.linesize[0]     =\n\n        s->m.current_picture.f.linesize[0] = stride;\n\n        s->m.width                         = width;\n\n        s->m.height                        = height;\n\n        s->m.mb_width                      = block_width;\n\n        s->m.mb_height                     = block_height;\n\n        s->m.mb_stride                     = s->m.mb_width + 1;\n\n        s->m.b8_stride                     = 2 * s->m.mb_width + 1;\n\n        s->m.f_code                        = 1;\n\n        s->m.pict_type                     = f->pict_type;\n\n        s->m.me_method                     = s->avctx->me_method;\n\n        s->m.me.scene_change_score         = 0;\n\n        s->m.flags                         = s->avctx->flags;\n\n        // s->m.out_format                    = FMT_H263;\n\n        // s->m.unrestricted_mv               = 1;\n\n        s->m.lambda                        = f->quality;\n\n        s->m.qscale                        = s->m.lambda * 139 +\n\n                                             FF_LAMBDA_SCALE * 64 >>\n\n                                             FF_LAMBDA_SHIFT + 7;\n\n        s->m.lambda2                       = s->m.lambda * s->m.lambda +\n\n                                             FF_LAMBDA_SCALE / 2 >>\n\n                                             FF_LAMBDA_SHIFT;\n\n\n\n        if (!s->motion_val8[plane]) {\n\n            s->motion_val8[plane]  = av_mallocz((s->m.b8_stride *\n\n                                                 block_height * 2 + 2) *\n\n                                                2 * sizeof(int16_t));\n\n            s->motion_val16[plane] = av_mallocz((s->m.mb_stride *\n\n                                                 (block_height + 2) + 1) *\n\n                                                2 * sizeof(int16_t));\n\n        }\n\n\n\n        s->m.mb_type = s->mb_type;\n\n\n\n        // dummies, to avoid segfaults\n\n        s->m.current_picture.mb_mean   = (uint8_t *)s->dummy;\n\n        s->m.current_picture.mb_var    = (uint16_t *)s->dummy;\n\n        s->m.current_picture.mc_mb_var = (uint16_t *)s->dummy;\n\n        s->m.current_picture.mb_type = s->dummy;\n\n\n\n        s->m.current_picture.motion_val[0]   = s->motion_val8[plane] + 2;\n\n        s->m.p_mv_table                      = s->motion_val16[plane] +\n\n                                               s->m.mb_stride + 1;\n\n        s->m.dsp                             = s->dsp; // move\n\n        ff_init_me(&s->m);\n\n\n\n        s->m.me.dia_size      = s->avctx->dia_size;\n\n        s->m.first_slice_line = 1;\n\n        for (y = 0; y < block_height; y++) {\n\n            s->m.new_picture.f.data[0] = src - y * 16 * stride; // ugly\n\n            s->m.mb_y                  = y;\n\n\n\n            for (i = 0; i < 16 && i + 16 * y < height; i++) {\n\n                memcpy(&src[i * stride], &src_plane[(i + 16 * y) * src_stride],\n\n                       width);\n\n                for (x = width; x < 16 * block_width; x++)\n\n                    src[i * stride + x] = src[i * stride + x - 1];\n\n            }\n\n            for (; i < 16 && i + 16 * y < 16 * block_height; i++)\n\n                memcpy(&src[i * stride], &src[(i - 1) * stride],\n\n                       16 * block_width);\n\n\n\n            for (x = 0; x < block_width; x++) {\n\n                s->m.mb_x = x;\n\n                ff_init_block_index(&s->m);\n\n                ff_update_block_index(&s->m);\n\n\n\n                ff_estimate_p_frame_motion(&s->m, x, y);\n\n            }\n\n            s->m.first_slice_line = 0;\n\n        }\n\n\n\n        ff_fix_long_p_mvs(&s->m);\n\n        ff_fix_long_mvs(&s->m, NULL, 0, s->m.p_mv_table, s->m.f_code,\n\n                        CANDIDATE_MB_TYPE_INTER, 0);\n\n    }\n\n\n\n    s->m.first_slice_line = 1;\n\n    for (y = 0; y < block_height; y++) {\n\n        for (i = 0; i < 16 && i + 16 * y < height; i++) {\n\n            memcpy(&src[i * stride], &src_plane[(i + 16 * y) * src_stride],\n\n                   width);\n\n            for (x = width; x < 16 * block_width; x++)\n\n                src[i * stride + x] = src[i * stride + x - 1];\n\n        }\n\n        for (; i < 16 && i + 16 * y < 16 * block_height; i++)\n\n            memcpy(&src[i * stride], &src[(i - 1) * stride], 16 * block_width);\n\n\n\n        s->m.mb_y = y;\n\n        for (x = 0; x < block_width; x++) {\n\n            uint8_t reorder_buffer[3][6][7 * 32];\n\n            int count[3][6];\n\n            int offset       = y * 16 * stride + x * 16;\n\n            uint8_t *decoded = decoded_plane + offset;\n\n            uint8_t *ref     = ref_plane + offset;\n\n            int score[4]     = { 0, 0, 0, 0 }, best;\n\n            uint8_t *temp    = s->scratchbuf;\n\n\n\n            if (s->pb.buf_end - s->pb.buf -\n\n                (put_bits_count(&s->pb) >> 3) < 3000) { // FIXME: check size\n\n                av_log(s->avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n                return -1;\n\n            }\n\n\n\n            s->m.mb_x = x;\n\n            ff_init_block_index(&s->m);\n\n            ff_update_block_index(&s->m);\n\n\n\n            if (f->pict_type == AV_PICTURE_TYPE_I ||\n\n                (s->m.mb_type[x + y * s->m.mb_stride] &\n\n                 CANDIDATE_MB_TYPE_INTRA)) {\n\n                for (i = 0; i < 6; i++)\n\n                    init_put_bits(&s->reorder_pb[i], reorder_buffer[0][i],\n\n                                  7 * 32);\n\n                if (f->pict_type == AV_PICTURE_TYPE_P) {\n\n                    const uint8_t *vlc = ff_svq1_block_type_vlc[SVQ1_BLOCK_INTRA];\n\n                    put_bits(&s->reorder_pb[5], vlc[1], vlc[0]);\n\n                    score[0] = vlc[1] * lambda;\n\n                }\n\n                score[0] += encode_block(s, src + 16 * x, NULL, temp, stride,\n\n                                         5, 64, lambda, 1);\n\n                for (i = 0; i < 6; i++) {\n\n                    count[0][i] = put_bits_count(&s->reorder_pb[i]);\n\n                    flush_put_bits(&s->reorder_pb[i]);\n\n                }\n\n            } else\n\n                score[0] = INT_MAX;\n\n\n\n            best = 0;\n\n\n\n            if (f->pict_type == AV_PICTURE_TYPE_P) {\n\n                const uint8_t *vlc = ff_svq1_block_type_vlc[SVQ1_BLOCK_INTER];\n\n                int mx, my, pred_x, pred_y, dxy;\n\n                int16_t *motion_ptr;\n\n\n\n                motion_ptr = ff_h263_pred_motion(&s->m, 0, 0, &pred_x, &pred_y);\n\n                if (s->m.mb_type[x + y * s->m.mb_stride] &\n\n                    CANDIDATE_MB_TYPE_INTER) {\n\n                    for (i = 0; i < 6; i++)\n\n                        init_put_bits(&s->reorder_pb[i], reorder_buffer[1][i],\n\n                                      7 * 32);\n\n\n\n                    put_bits(&s->reorder_pb[5], vlc[1], vlc[0]);\n\n\n\n                    s->m.pb = s->reorder_pb[5];\n\n                    mx      = motion_ptr[0];\n\n                    my      = motion_ptr[1];\n\n                    assert(mx     >= -32 && mx     <= 31);\n\n                    assert(my     >= -32 && my     <= 31);\n\n                    assert(pred_x >= -32 && pred_x <= 31);\n\n                    assert(pred_y >= -32 && pred_y <= 31);\n\n                    ff_h263_encode_motion(&s->m, mx - pred_x, 1);\n\n                    ff_h263_encode_motion(&s->m, my - pred_y, 1);\n\n                    s->reorder_pb[5] = s->m.pb;\n\n                    score[1]        += lambda * put_bits_count(&s->reorder_pb[5]);\n\n\n\n                    dxy = (mx & 1) + 2 * (my & 1);\n\n\n\n                    s->hdsp.put_pixels_tab[0][dxy](temp + 16,\n\n                                                   ref + (mx >> 1) +\n\n                                                   stride * (my >> 1),\n\n                                                   stride, 16);\n\n\n\n                    score[1] += encode_block(s, src + 16 * x, temp + 16,\n\n                                             decoded, stride, 5, 64, lambda, 0);\n\n                    best      = score[1] <= score[0];\n\n\n\n                    vlc       = ff_svq1_block_type_vlc[SVQ1_BLOCK_SKIP];\n\n                    score[2]  = s->dsp.sse[0](NULL, src + 16 * x, ref,\n\n                                              stride, 16);\n\n                    score[2] += vlc[1] * lambda;\n\n                    if (score[2] < score[best] && mx == 0 && my == 0) {\n\n                        best = 2;\n\n                        s->hdsp.put_pixels_tab[0][0](decoded, ref, stride, 16);\n\n                        for (i = 0; i < 6; i++)\n\n                            count[2][i] = 0;\n\n                        put_bits(&s->pb, vlc[1], vlc[0]);\n\n                    }\n\n                }\n\n\n\n                if (best == 1) {\n\n                    for (i = 0; i < 6; i++) {\n\n                        count[1][i] = put_bits_count(&s->reorder_pb[i]);\n\n                        flush_put_bits(&s->reorder_pb[i]);\n\n                    }\n\n                } else {\n\n                    motion_ptr[0]                      =\n\n                    motion_ptr[1]                      =\n\n                    motion_ptr[2]                      =\n\n                    motion_ptr[3]                      =\n\n                    motion_ptr[0 + 2 * s->m.b8_stride] =\n\n                    motion_ptr[1 + 2 * s->m.b8_stride] =\n\n                    motion_ptr[2 + 2 * s->m.b8_stride] =\n\n                    motion_ptr[3 + 2 * s->m.b8_stride] = 0;\n\n                }\n\n            }\n\n\n\n            s->rd_total += score[best];\n\n\n\n            for (i = 5; i >= 0; i--)\n\n                avpriv_copy_bits(&s->pb, reorder_buffer[best][i],\n\n                                 count[best][i]);\n\n            if (best == 0)\n\n                s->hdsp.put_pixels_tab[0][0](decoded, temp, stride, 16);\n\n        }\n\n        s->m.first_slice_line = 0;\n\n    }\n\n    return 0;\n\n}\n", "idx": 4062, "_split": "test", "_hash": "058ab00502595de87e3bfa07c904c8a7"}
{"project": "FFmpeg", "commit_id": "39f01e346cab464ef6c0d4ec58cc13b7123e60d8", "target": 1, "func": "static int ffmmal_add_packet(AVCodecContext *avctx, AVPacket *avpkt,\n\n                             int is_extradata)\n\n{\n\n    MMALDecodeContext *ctx = avctx->priv_data;\n\n    AVBufferRef *buf = NULL;\n\n    int size = 0;\n\n    uint8_t *data = (uint8_t *)\"\";\n\n    uint8_t *start;\n\n    int ret = 0;\n\n\n\n    if (avpkt->size) {\n\n        if (avpkt->buf) {\n\n            buf = av_buffer_ref(avpkt->buf);\n\n            size = avpkt->size;\n\n            data = avpkt->data;\n\n        } else {\n\n            buf = av_buffer_alloc(avpkt->size);\n\n            if (buf) {\n\n                memcpy(buf->data, avpkt->data, avpkt->size);\n\n                size = buf->size;\n\n                data = buf->data;\n\n            }\n\n        }\n\n        if (!buf) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto done;\n\n        }\n\n        if (!is_extradata)\n\n            ctx->packets_sent++;\n\n    } else {\n\n        if (!ctx->packets_sent) {\n\n            // Short-cut the flush logic to avoid upsetting MMAL.\n\n            ctx->eos_sent = 1;\n\n            ctx->eos_received = 1;\n\n            goto done;\n\n        }\n\n    }\n\n\n\n    start = data;\n\n\n\n    do {\n\n        FFBufferEntry *buffer = av_mallocz(sizeof(*buffer));\n\n        if (!buffer) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto done;\n\n        }\n\n\n\n        buffer->data = data;\n\n        buffer->length = FFMIN(size, ctx->decoder->input[0]->buffer_size);\n\n\n\n        if (is_extradata)\n\n            buffer->flags |= MMAL_BUFFER_HEADER_FLAG_CONFIG;\n\n\n\n        if (data == start)\n\n            buffer->flags |= MMAL_BUFFER_HEADER_FLAG_FRAME_START;\n\n\n\n        data += buffer->length;\n\n        size -= buffer->length;\n\n\n\n        buffer->pts = avpkt->pts == AV_NOPTS_VALUE ? MMAL_TIME_UNKNOWN : avpkt->pts;\n\n        buffer->dts = avpkt->dts == AV_NOPTS_VALUE ? MMAL_TIME_UNKNOWN : avpkt->dts;\n\n\n\n        if (!size)\n\n            buffer->flags |= MMAL_BUFFER_HEADER_FLAG_FRAME_END;\n\n\n\n        if (!buffer->length) {\n\n            buffer->flags |= MMAL_BUFFER_HEADER_FLAG_EOS;\n\n            ctx->eos_sent = 1;\n\n        }\n\n\n\n        if (buf) {\n\n            buffer->ref = av_buffer_ref(buf);\n\n            if (!buffer->ref) {\n\n                av_free(buffer);\n\n                ret = AVERROR(ENOMEM);\n\n                goto done;\n\n            }\n\n        }\n\n\n\n        // Insert at end of the list\n\n        if (!ctx->waiting_buffers)\n\n            ctx->waiting_buffers = buffer;\n\n        if (ctx->waiting_buffers_tail)\n\n            ctx->waiting_buffers_tail->next = buffer;\n\n        ctx->waiting_buffers_tail = buffer;\n\n    } while (size);\n\n\n\ndone:\n\n    av_buffer_unref(&buf);\n\n    return ret;\n\n}\n", "idx": 4064, "_split": "test", "_hash": "117c3d718c5978e7a73304041e11be3a"}
{"project": "FFmpeg", "commit_id": "969267482de97b08503d27d2fe090ec820273e40", "target": 1, "func": "static void write_frame(AVFormatContext *s, AVPacket *pkt, OutputStream *ost)\n\n{\n\n    AVBitStreamFilterContext *bsfc = ost->bitstream_filters;\n\n    AVCodecContext          *avctx = ost->st->codec;\n\n    int ret;\n\n\n\n    if ((avctx->codec_type == AVMEDIA_TYPE_VIDEO && video_sync_method == VSYNC_DROP) ||\n\n        (avctx->codec_type == AVMEDIA_TYPE_AUDIO && audio_sync_method < 0))\n\n        pkt->pts = pkt->dts = AV_NOPTS_VALUE;\n\n\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO && pkt->dts != AV_NOPTS_VALUE) {\n\n        int64_t max = ost->st->cur_dts + !(s->oformat->flags & AVFMT_TS_NONSTRICT);\n\n        if (ost->st->cur_dts && ost->st->cur_dts != AV_NOPTS_VALUE &&  max > pkt->dts) {\n\n            av_log(s, max - pkt->dts > 2 ? AV_LOG_WARNING : AV_LOG_DEBUG, \"Audio timestamp %\"PRId64\" < %\"PRId64\" invalid, cliping\\n\", pkt->dts, max);\n\n            pkt->pts = pkt->dts = max;\n\n\n\n\n\n    /*\n\n     * Audio encoders may split the packets --  #frames in != #packets out.\n\n     * But there is no reordering, so we can limit the number of output packets\n\n     * by simply dropping them here.\n\n     * Counting encoded video frames needs to be done separately because of\n\n     * reordering, see do_video_out()\n\n     */\n\n    if (!(avctx->codec_type == AVMEDIA_TYPE_VIDEO && avctx->codec)) {\n\n        if (ost->frame_number >= ost->max_frames) {\n\n            av_free_packet(pkt);\n\n            return;\n\n\n        ost->frame_number++;\n\n\n\n\n    while (bsfc) {\n\n        AVPacket new_pkt = *pkt;\n\n        int a = av_bitstream_filter_filter(bsfc, avctx, NULL,\n\n                                           &new_pkt.data, &new_pkt.size,\n\n                                           pkt->data, pkt->size,\n\n                                           pkt->flags & AV_PKT_FLAG_KEY);\n\n\n\n\n\n\n\n\n\n\n\n        if (a > 0) {\n\n            av_free_packet(pkt);\n\n            new_pkt.destruct = av_destruct_packet;\n\n        } else if (a < 0) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Failed to open bitstream filter %s for stream %d with codec %s\",\n\n                   bsfc->filter->name, pkt->stream_index,\n\n                   avctx->codec ? avctx->codec->name : \"copy\");\n\n            print_error(\"\", a);\n\n            if (exit_on_error)\n\n                exit_program(1);\n\n\n        *pkt = new_pkt;\n\n\n\n        bsfc = bsfc->next;\n\n\n\n\n    pkt->stream_index = ost->index;\n\n    ret = av_interleaved_write_frame(s, pkt);\n\n    if (ret < 0) {\n\n        print_error(\"av_interleaved_write_frame()\", ret);\n\n        exit_program(1);\n\n", "idx": 4070, "_split": "test", "_hash": "efe6b9f876ad200e8b90246c366f411e"}
{"project": "FFmpeg", "commit_id": "bc488ec28aec4bc91ba47283c49c9f7f25696eaa", "target": 1, "func": "av_cold void ff_pixblockdsp_init_x86(PixblockDSPContext *c,\n\n                                     AVCodecContext *avctx,\n\n                                     unsigned high_bit_depth)\n\n{\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (EXTERNAL_MMX(cpu_flags)) {\n\n        if (!high_bit_depth)\n\n            c->get_pixels = ff_get_pixels_mmx;\n\n\n        c->diff_pixels = ff_diff_pixels_mmx;\n\n    }\n\n\n\n    if (EXTERNAL_SSE2(cpu_flags)) {\n\n        if (!high_bit_depth)\n\n            c->get_pixels = ff_get_pixels_sse2;\n\n\n        c->diff_pixels = ff_diff_pixels_sse2;\n\n    }\n\n}", "idx": 4091, "_split": "test", "_hash": "83672800d7d5f1cb3a530a3a49d8ef0d"}
{"project": "FFmpeg", "commit_id": "238ddd6482d7aea2e917760a9bef291030a11e61", "target": 1, "func": "static void pkt_dump_internal(void *avcl, FILE *f, int level, const AVPacket *pkt,\n\n                              int dump_payload, AVRational time_base)\n\n{\n\n    HEXDUMP_PRINT(\"stream #%d:\\n\", pkt->stream_index);\n\n    HEXDUMP_PRINT(\"  keyframe=%d\\n\", (pkt->flags & AV_PKT_FLAG_KEY) != 0);\n\n    HEXDUMP_PRINT(\"  duration=%0.3f\\n\", pkt->duration * av_q2d(time_base));\n\n    /* DTS is _always_ valid after av_read_frame() */\n\n    HEXDUMP_PRINT(\"  dts=\");\n\n    if (pkt->dts == AV_NOPTS_VALUE)\n\n        HEXDUMP_PRINT(\"N/A\");\n\n    else\n\n        HEXDUMP_PRINT(\"%0.3f\", pkt->dts * av_q2d(time_base));\n\n    /* PTS may not be known if B-frames are present. */\n\n    HEXDUMP_PRINT(\"  pts=\");\n\n    if (pkt->pts == AV_NOPTS_VALUE)\n\n        HEXDUMP_PRINT(\"N/A\");\n\n    else\n\n        HEXDUMP_PRINT(\"%0.3f\", pkt->pts * av_q2d(time_base));\n\n    HEXDUMP_PRINT(\"\\n\");\n\n    HEXDUMP_PRINT(\"  size=%d\\n\", pkt->size);\n\n    if (dump_payload)\n\n        av_hex_dump(f, pkt->data, pkt->size);\n\n}\n", "idx": 4095, "_split": "test", "_hash": "0014d9bf14ea4cd8490f4d64f3082968"}
{"project": "FFmpeg", "commit_id": "9f36ea57ae6eefb42432220feab0350494f4144c", "target": 1, "func": "int av_packet_split_side_data(AVPacket *pkt){\n\n    if (!pkt->side_data_elems && pkt->size >12 && AV_RB64(pkt->data + pkt->size - 8) == FF_MERGE_MARKER){\n\n        int i;\n\n        unsigned int size;\n\n        uint8_t *p;\n\n\n\n        p = pkt->data + pkt->size - 8 - 5;\n\n        for (i=1; ; i++){\n\n            size = AV_RB32(p);\n\n            if (size>INT_MAX || p - pkt->data < size)\n\n                return 0;\n\n            if (p[4]&128)\n\n                break;\n\n            p-= size+5;\n\n        }\n\n\n\n        pkt->side_data = av_malloc_array(i, sizeof(*pkt->side_data));\n\n        if (!pkt->side_data)\n\n            return AVERROR(ENOMEM);\n\n\n\n        p= pkt->data + pkt->size - 8 - 5;\n\n        for (i=0; ; i++){\n\n            size= AV_RB32(p);\n\n            av_assert0(size<=INT_MAX && p - pkt->data >= size);\n\n            pkt->side_data[i].data = av_mallocz(size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n            pkt->side_data[i].size = size;\n\n            pkt->side_data[i].type = p[4]&127;\n\n            if (!pkt->side_data[i].data)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(pkt->side_data[i].data, p-size, size);\n\n            pkt->size -= size + 5;\n\n            if(p[4]&128)\n\n                break;\n\n            p-= size+5;\n\n        }\n\n        pkt->size -= 8;\n\n        pkt->side_data_elems = i+1;\n\n        return 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 4159, "_split": "test", "_hash": "b7b4a052f802c27bb0127261780aad68"}
{"project": "FFmpeg", "commit_id": "9c3a8693a20da3ad89a327bf778e13c2cd74c81c", "target": 0, "func": "dshow_cycle_devices(AVFormatContext *avctx, ICreateDevEnum *devenum,\n\n                    enum dshowDeviceType devtype, IBaseFilter **pfilter)\n\n{\n\n    struct dshow_ctx *ctx = avctx->priv_data;\n\n    IBaseFilter *device_filter = NULL;\n\n    IEnumMoniker *classenum = NULL;\n\n    IMoniker *m = NULL;\n\n    const char *device_name = ctx->device_name[devtype];\n\n    int skip = (devtype == VideoDevice) ? ctx->video_device_number\n\n                                        : ctx->audio_device_number;\n\n    int r;\n\n\n\n    const GUID *device_guid[2] = { &CLSID_VideoInputDeviceCategory,\n\n                                   &CLSID_AudioInputDeviceCategory };\n\n    const char *devtypename = (devtype == VideoDevice) ? \"video\" : \"audio\";\n\n\n\n    r = ICreateDevEnum_CreateClassEnumerator(devenum, device_guid[devtype],\n\n                                             (IEnumMoniker **) &classenum, 0);\n\n    if (r != S_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not enumerate %s devices.\\n\",\n\n               devtypename);\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    while (!device_filter && IEnumMoniker_Next(classenum, 1, &m, NULL) == S_OK) {\n\n        IPropertyBag *bag = NULL;\n\n        char *buf = NULL;\n\n        VARIANT var;\n\n\n\n        r = IMoniker_BindToStorage(m, 0, 0, &IID_IPropertyBag, (void *) &bag);\n\n        if (r != S_OK)\n\n            goto fail1;\n\n\n\n        var.vt = VT_BSTR;\n\n        r = IPropertyBag_Read(bag, L\"FriendlyName\", &var, NULL);\n\n        if (r != S_OK)\n\n            goto fail1;\n\n\n\n        buf = dup_wchar_to_utf8(var.bstrVal);\n\n\n\n        if (pfilter) {\n\n            if (strcmp(device_name, buf))\n\n                goto fail1;\n\n\n\n            if (!skip--)\n\n                IMoniker_BindToObject(m, 0, 0, &IID_IBaseFilter, (void *) &device_filter);\n\n        } else {\n\n            av_log(avctx, AV_LOG_INFO, \" \\\"%s\\\"\\n\", buf);\n\n        }\n\n\n\nfail1:\n\n        if (buf)\n\n            av_free(buf);\n\n        if (bag)\n\n            IPropertyBag_Release(bag);\n\n        IMoniker_Release(m);\n\n    }\n\n\n\n    IEnumMoniker_Release(classenum);\n\n\n\n    if (pfilter) {\n\n        if (!device_filter) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Could not find %s device.\\n\",\n\n                   devtypename);\n\n            return AVERROR(EIO);\n\n        }\n\n        *pfilter = device_filter;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 4196, "_split": "test", "_hash": "00164ebe74cde9eced4ffe563cf7f27a"}
{"project": "FFmpeg", "commit_id": "a755b725ec1d657609c8bd726ce37e7cf193d03f", "target": 0, "func": "static int do_decode(AVCodecContext *avctx, AVPacket *pkt)\n\n{\n\n    int got_frame;\n\n    int ret;\n\n\n\n    av_assert0(!avctx->internal->buffer_frame->buf[0]);\n\n\n\n    if (!pkt)\n\n        pkt = avctx->internal->buffer_pkt;\n\n\n\n    // This is the lesser evil. The field is for compatibility with legacy users\n\n    // of the legacy API, and users using the new API should not be forced to\n\n    // even know about this field.\n\n    avctx->refcounted_frames = 1;\n\n\n\n    // Some codecs (at least wma lossless) will crash when feeding drain packets\n\n    // after EOF was signaled.\n\n    if (avctx->internal->draining_done)\n\n        return AVERROR_EOF;\n\n\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n        ret = avcodec_decode_video2(avctx, avctx->internal->buffer_frame,\n\n                                    &got_frame, pkt);\n\n        if (ret >= 0 && !(avctx->flags & AV_CODEC_FLAG_TRUNCATED))\n\n            ret = pkt->size;\n\n    } else if (avctx->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n        ret = avcodec_decode_audio4(avctx, avctx->internal->buffer_frame,\n\n                                    &got_frame, pkt);\n\n    } else {\n\n        ret = AVERROR(EINVAL);\n\n    }\n\n\n\n    if (ret == AVERROR(EAGAIN))\n\n        ret = pkt->size;\n\n\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (avctx->internal->draining && !got_frame)\n\n        avctx->internal->draining_done = 1;\n\n\n\n    if (ret >= pkt->size) {\n\n        av_packet_unref(avctx->internal->buffer_pkt);\n\n    } else {\n\n        int consumed = ret;\n\n\n\n        if (pkt != avctx->internal->buffer_pkt) {\n\n            av_packet_unref(avctx->internal->buffer_pkt);\n\n            if ((ret = av_packet_ref(avctx->internal->buffer_pkt, pkt)) < 0)\n\n                return ret;\n\n        }\n\n\n\n        avctx->internal->buffer_pkt->data += consumed;\n\n        avctx->internal->buffer_pkt->size -= consumed;\n\n        avctx->internal->buffer_pkt->pts   = AV_NOPTS_VALUE;\n\n        avctx->internal->buffer_pkt->dts   = AV_NOPTS_VALUE;\n\n    }\n\n\n\n    if (got_frame)\n\n        av_assert0(avctx->internal->buffer_frame->buf[0]);\n\n\n\n    return 0;\n\n}\n", "idx": 4198, "_split": "test", "_hash": "ad9698d8294abf0afb1fd2ec57c0f1a9"}
{"project": "FFmpeg", "commit_id": "ec07efa70012845e8642df67a4a773f510a17088", "target": 1, "func": "static int parse_adaptation_sets(AVFormatContext *s)\n\n{\n\n    WebMDashMuxContext *w = s->priv_data;\n\n    char *p = w->adaptation_sets;\n\n    char *q;\n\n    enum { new_set, parsed_id, parsing_streams } state;\n\n    if (!w->adaptation_sets) {\n\n        av_log(s, AV_LOG_ERROR, \"The 'adaptation_sets' option must be set.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    // syntax id=0,streams=0,1,2 id=1,streams=3,4 and so on\n\n    state = new_set;\n\n    while (p < w->adaptation_sets + strlen(w->adaptation_sets)) {\n\n        if (*p == ' ')\n\n            continue;\n\n        else if (state == new_set && !strncmp(p, \"id=\", 3)) {\n\n            void *mem = av_realloc(w->as, sizeof(*w->as) * (w->nb_as + 1));\n\n            if (mem == NULL)\n\n                return AVERROR(ENOMEM);\n\n            w->as = mem;\n\n            ++w->nb_as;\n\n            w->as[w->nb_as - 1].nb_streams = 0;\n\n            w->as[w->nb_as - 1].streams = NULL;\n\n            p += 3; // consume \"id=\"\n\n            q = w->as[w->nb_as - 1].id;\n\n            while (*p != ',') *q++ = *p++;\n\n            *q = 0;\n\n            p++;\n\n            state = parsed_id;\n\n        } else if (state == parsed_id && !strncmp(p, \"streams=\", 8)) {\n\n            p += 8; // consume \"streams=\"\n\n            state = parsing_streams;\n\n        } else if (state == parsing_streams) {\n\n            struct AdaptationSet *as = &w->as[w->nb_as - 1];\n\n            q = p;\n\n            while (*q != '\\0' && *q != ',' && *q != ' ') q++;\n\n            as->streams = av_realloc(as->streams, sizeof(*as->streams) * ++as->nb_streams);\n\n            if (as->streams == NULL)\n\n                return AVERROR(ENOMEM);\n\n            as->streams[as->nb_streams - 1] = to_integer(p, q - p + 1);\n\n            if (as->streams[as->nb_streams - 1] < 0) return -1;\n\n            if (*q == '\\0') break;\n\n            if (*q == ' ') state = new_set;\n\n            p = ++q;\n\n        } else {\n\n            return -1;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 4255, "_split": "test", "_hash": "34914aad5509b8edeaa2efc5afb20619"}
{"project": "FFmpeg", "commit_id": "5b29af624fe8be5379fd649019a04ff44bfde04f", "target": 0, "func": "static int aac_encode_frame(AVCodecContext *avctx,\n\n                            uint8_t *frame, int buf_size, void *data)\n\n{\n\n    AACEncContext *s = avctx->priv_data;\n\n    int16_t *samples = s->samples, *samples2, *la;\n\n    ChannelElement *cpe;\n\n    int i, j, chans, tag, start_ch;\n\n    const uint8_t *chan_map = aac_chan_configs[avctx->channels-1];\n\n    int chan_el_counter[4];\n\n    FFPsyWindowInfo windows[AAC_MAX_CHANNELS];\n\n\n\n    if (s->last_frame)\n\n        return 0;\n\n    if (data) {\n\n        if (!s->psypp) {\n\n            memcpy(s->samples + 1024 * avctx->channels, data,\n\n                   1024 * avctx->channels * sizeof(s->samples[0]));\n\n        } else {\n\n            start_ch = 0;\n\n            samples2 = s->samples + 1024 * avctx->channels;\n\n            for (i = 0; i < chan_map[0]; i++) {\n\n                tag = chan_map[i+1];\n\n                chans = tag == TYPE_CPE ? 2 : 1;\n\n                ff_psy_preprocess(s->psypp, (uint16_t*)data + start_ch,\n\n                                  samples2 + start_ch, start_ch, chans);\n\n                start_ch += chans;\n\n            }\n\n        }\n\n    }\n\n    if (!avctx->frame_number) {\n\n        memcpy(s->samples, s->samples + 1024 * avctx->channels,\n\n               1024 * avctx->channels * sizeof(s->samples[0]));\n\n        return 0;\n\n    }\n\n\n\n    start_ch = 0;\n\n    for (i = 0; i < chan_map[0]; i++) {\n\n        FFPsyWindowInfo* wi = windows + start_ch;\n\n        tag      = chan_map[i+1];\n\n        chans    = tag == TYPE_CPE ? 2 : 1;\n\n        cpe      = &s->cpe[i];\n\n        for (j = 0; j < chans; j++) {\n\n            IndividualChannelStream *ics = &cpe->ch[j].ics;\n\n            int k;\n\n            int cur_channel = start_ch + j;\n\n            samples2 = samples + cur_channel;\n\n            la       = samples2 + (448+64) * avctx->channels;\n\n            if (!data)\n\n                la = NULL;\n\n            if (tag == TYPE_LFE) {\n\n                wi[j].window_type[0] = ONLY_LONG_SEQUENCE;\n\n                wi[j].window_shape   = 0;\n\n                wi[j].num_windows    = 1;\n\n                wi[j].grouping[0]    = 1;\n\n            } else {\n\n                wi[j] = ff_psy_suggest_window(&s->psy, samples2, la, cur_channel,\n\n                                              ics->window_sequence[0]);\n\n            }\n\n            ics->window_sequence[1] = ics->window_sequence[0];\n\n            ics->window_sequence[0] = wi[j].window_type[0];\n\n            ics->use_kb_window[1]   = ics->use_kb_window[0];\n\n            ics->use_kb_window[0]   = wi[j].window_shape;\n\n            ics->num_windows        = wi[j].num_windows;\n\n            ics->swb_sizes          = s->psy.bands    [ics->num_windows == 8];\n\n            ics->num_swb            = tag == TYPE_LFE ? 12 : s->psy.num_bands[ics->num_windows == 8];\n\n            for (k = 0; k < ics->num_windows; k++)\n\n                ics->group_len[k] = wi[j].grouping[k];\n\n\n\n            apply_window_and_mdct(avctx, s, &cpe->ch[j], samples2);\n\n        }\n\n        start_ch += chans;\n\n    }\n\n    do {\n\n        int frame_bits;\n\n        init_put_bits(&s->pb, frame, buf_size*8);\n\n        if ((avctx->frame_number & 0xFF)==1 && !(avctx->flags & CODEC_FLAG_BITEXACT))\n\n            put_bitstream_info(avctx, s, LIBAVCODEC_IDENT);\n\n        start_ch = 0;\n\n        memset(chan_el_counter, 0, sizeof(chan_el_counter));\n\n        for (i = 0; i < chan_map[0]; i++) {\n\n            FFPsyWindowInfo* wi = windows + start_ch;\n\n            tag      = chan_map[i+1];\n\n            chans    = tag == TYPE_CPE ? 2 : 1;\n\n            cpe      = &s->cpe[i];\n\n            put_bits(&s->pb, 3, tag);\n\n            put_bits(&s->pb, 4, chan_el_counter[tag]++);\n\n            for (j = 0; j < chans; j++) {\n\n                s->cur_channel = start_ch + j;\n\n                ff_psy_set_band_info(&s->psy, s->cur_channel, cpe->ch[j].coeffs, &wi[j]);\n\n                s->coder->search_for_quantizers(avctx, s, &cpe->ch[j], s->lambda);\n\n            }\n\n            cpe->common_window = 0;\n\n            if (chans > 1\n\n                && wi[0].window_type[0] == wi[1].window_type[0]\n\n                && wi[0].window_shape   == wi[1].window_shape) {\n\n\n\n                cpe->common_window = 1;\n\n                for (j = 0; j < wi[0].num_windows; j++) {\n\n                    if (wi[0].grouping[j] != wi[1].grouping[j]) {\n\n                        cpe->common_window = 0;\n\n                        break;\n\n                    }\n\n                }\n\n            }\n\n            s->cur_channel = start_ch;\n\n            if (cpe->common_window && s->coder->search_for_ms)\n\n                s->coder->search_for_ms(s, cpe, s->lambda);\n\n            adjust_frame_information(s, cpe, chans);\n\n            if (chans == 2) {\n\n                put_bits(&s->pb, 1, cpe->common_window);\n\n                if (cpe->common_window) {\n\n                    put_ics_info(s, &cpe->ch[0].ics);\n\n                    encode_ms_info(&s->pb, cpe);\n\n                }\n\n            }\n\n            for (j = 0; j < chans; j++) {\n\n                s->cur_channel = start_ch + j;\n\n                encode_individual_channel(avctx, s, &cpe->ch[j], cpe->common_window);\n\n            }\n\n            start_ch += chans;\n\n        }\n\n\n\n        frame_bits = put_bits_count(&s->pb);\n\n        if (frame_bits <= 6144 * avctx->channels - 3) {\n\n            s->psy.bitres.bits = frame_bits / avctx->channels;\n\n            break;\n\n        }\n\n\n\n        s->lambda *= avctx->bit_rate * 1024.0f / avctx->sample_rate / frame_bits;\n\n\n\n    } while (1);\n\n\n\n    put_bits(&s->pb, 3, TYPE_END);\n\n    flush_put_bits(&s->pb);\n\n    avctx->frame_bits = put_bits_count(&s->pb);\n\n\n\n    // rate control stuff\n\n    if (!(avctx->flags & CODEC_FLAG_QSCALE)) {\n\n        float ratio = avctx->bit_rate * 1024.0f / avctx->sample_rate / avctx->frame_bits;\n\n        s->lambda *= ratio;\n\n        s->lambda = FFMIN(s->lambda, 65536.f);\n\n    }\n\n\n\n    if (!data)\n\n        s->last_frame = 1;\n\n    memcpy(s->samples, s->samples + 1024 * avctx->channels,\n\n           1024 * avctx->channels * sizeof(s->samples[0]));\n\n    return put_bits_count(&s->pb)>>3;\n\n}\n", "idx": 4260, "_split": "test", "_hash": "0c5d5f8f409819c08208d6e1b2a5d190"}
{"project": "FFmpeg", "commit_id": "6a6bc43f5f79587b8936334cc0b3a6616f4807ac", "target": 0, "func": "static int dxtory_decode_v2_420(AVCodecContext *avctx, AVFrame *pic,\n\n                                const uint8_t *src, int src_size)\n\n{\n\n    GetByteContext gb;\n\n    GetBitContext  gb2;\n\n    int nslices, slice, slice_height, ref_slice_height;\n\n    int cur_y, next_y;\n\n    uint32_t off, slice_size;\n\n    uint8_t *Y, *U, *V;\n\n    int ret;\n\n\n\n    bytestream2_init(&gb, src, src_size);\n\n    nslices = bytestream2_get_le16(&gb);\n\n    off = FFALIGN(nslices * 4 + 2, 16);\n\n    if (src_size < off) {\n\n        av_log(avctx, AV_LOG_ERROR, \"no slice data\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (!nslices || avctx->height % nslices) {\n\n        avpriv_request_sample(avctx, \"%d slices for %dx%d\", nslices,\n\n                              avctx->width, avctx->height);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    ref_slice_height = avctx->height / nslices;\n\n    if ((avctx->width & 1) || (avctx->height & 1)) {\n\n        avpriv_request_sample(avctx, \"Frame dimensions %dx%d\",\n\n                              avctx->width, avctx->height);\n\n    }\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n\n    if ((ret = ff_get_buffer(avctx, pic, 0)) < 0)\n\n        return ret;\n\n\n\n    Y = pic->data[0];\n\n    U = pic->data[1];\n\n    V = pic->data[2];\n\n\n\n    cur_y  = 0;\n\n    next_y = ref_slice_height;\n\n    for (slice = 0; slice < nslices; slice++) {\n\n        slice_size   = bytestream2_get_le32(&gb);\n\n        slice_height = (next_y & ~1) - (cur_y & ~1);\n\n        if (slice_size > src_size - off) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"invalid slice size %\"PRIu32\" (only %\"PRIu32\" bytes left)\\n\",\n\n                   slice_size, src_size - off);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if (slice_size <= 16) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid slice size %\"PRIu32\"\\n\", slice_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (AV_RL32(src + off) != slice_size - 16) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Slice sizes mismatch: got %\"PRIu32\" instead of %\"PRIu32\"\\n\",\n\n                   AV_RL32(src + off), slice_size - 16);\n\n        }\n\n        init_get_bits(&gb2, src + off + 16, (slice_size - 16) * 8);\n\n        dx2_decode_slice_420(&gb2, avctx->width, slice_height, Y, U, V,\n\n                             pic->linesize[0], pic->linesize[1],\n\n                             pic->linesize[2]);\n\n\n\n        Y += pic->linesize[0] *  slice_height;\n\n        U += pic->linesize[1] * (slice_height >> 1);\n\n        V += pic->linesize[2] * (slice_height >> 1);\n\n        off += slice_size;\n\n        cur_y   = next_y;\n\n        next_y += ref_slice_height;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 4306, "_split": "test", "_hash": "b788600f8de2a244ae481ed24546c6cb"}
{"project": "FFmpeg", "commit_id": "6ebc7240606e8f1fccd2edbe4ffac150053a16cc", "target": 0, "func": "static int read_sbr_grid(AACContext *ac, SpectralBandReplication *sbr,\n\n                         GetBitContext *gb, SBRData *ch_data)\n\n{\n\n    int i;\n\n    unsigned bs_pointer = 0;\n\n    // frameLengthFlag ? 15 : 16; 960 sample length frames unsupported; this value is numTimeSlots\n\n    int abs_bord_trail = 16;\n\n    int num_rel_lead, num_rel_trail;\n\n    unsigned bs_num_env_old = ch_data->bs_num_env;\n\n\n\n    ch_data->bs_freq_res[0] = ch_data->bs_freq_res[ch_data->bs_num_env];\n\n    ch_data->bs_amp_res = sbr->bs_amp_res_header;\n\n    ch_data->t_env_num_env_old = ch_data->t_env[bs_num_env_old];\n\n\n\n    switch (ch_data->bs_frame_class = get_bits(gb, 2)) {\n\n    case FIXFIX:\n\n        ch_data->bs_num_env                 = 1 << get_bits(gb, 2);\n\n        num_rel_lead                        = ch_data->bs_num_env - 1;\n\n        if (ch_data->bs_num_env == 1)\n\n            ch_data->bs_amp_res = 0;\n\n\n\n        if (ch_data->bs_num_env > 4) {\n\n            av_log(ac->avccontext, AV_LOG_ERROR,\n\n                   \"Invalid bitstream, too many SBR envelopes in FIXFIX type SBR frame: %d\\n\",\n\n                   ch_data->bs_num_env);\n\n            return -1;\n\n        }\n\n\n\n        ch_data->t_env[0]                   = 0;\n\n        ch_data->t_env[ch_data->bs_num_env] = abs_bord_trail;\n\n\n\n        abs_bord_trail = (abs_bord_trail + (ch_data->bs_num_env >> 1)) /\n\n                   ch_data->bs_num_env;\n\n        for (i = 0; i < num_rel_lead; i++)\n\n            ch_data->t_env[i + 1] = ch_data->t_env[i] + abs_bord_trail;\n\n\n\n        ch_data->bs_freq_res[1] = get_bits1(gb);\n\n        for (i = 1; i < ch_data->bs_num_env; i++)\n\n            ch_data->bs_freq_res[i + 1] = ch_data->bs_freq_res[1];\n\n        break;\n\n    case FIXVAR:\n\n        abs_bord_trail                     += get_bits(gb, 2);\n\n        num_rel_trail                       = get_bits(gb, 2);\n\n        ch_data->bs_num_env                 = num_rel_trail + 1;\n\n        ch_data->t_env[0]                   = 0;\n\n        ch_data->t_env[ch_data->bs_num_env] = abs_bord_trail;\n\n\n\n        for (i = 0; i < num_rel_trail; i++)\n\n            ch_data->t_env[ch_data->bs_num_env - 1 - i] =\n\n                ch_data->t_env[ch_data->bs_num_env - i] - 2 * get_bits(gb, 2) - 2;\n\n\n\n        bs_pointer = get_bits(gb, ceil_log2[ch_data->bs_num_env]);\n\n\n\n        for (i = 0; i < ch_data->bs_num_env; i++)\n\n            ch_data->bs_freq_res[ch_data->bs_num_env - i] = get_bits1(gb);\n\n        break;\n\n    case VARFIX:\n\n        ch_data->t_env[0]                   = get_bits(gb, 2);\n\n        num_rel_lead                        = get_bits(gb, 2);\n\n        ch_data->bs_num_env                 = num_rel_lead + 1;\n\n        ch_data->t_env[ch_data->bs_num_env] = abs_bord_trail;\n\n\n\n        for (i = 0; i < num_rel_lead; i++)\n\n            ch_data->t_env[i + 1] = ch_data->t_env[i] + 2 * get_bits(gb, 2) + 2;\n\n\n\n        bs_pointer = get_bits(gb, ceil_log2[ch_data->bs_num_env]);\n\n\n\n        get_bits1_vector(gb, ch_data->bs_freq_res + 1, ch_data->bs_num_env);\n\n        break;\n\n    case VARVAR:\n\n        ch_data->t_env[0]                   = get_bits(gb, 2);\n\n        abs_bord_trail                     += get_bits(gb, 2);\n\n        num_rel_lead                        = get_bits(gb, 2);\n\n        num_rel_trail                       = get_bits(gb, 2);\n\n        ch_data->bs_num_env                 = num_rel_lead + num_rel_trail + 1;\n\n        ch_data->t_env[ch_data->bs_num_env] = abs_bord_trail;\n\n\n\n        if (ch_data->bs_num_env > 5) {\n\n            av_log(ac->avccontext, AV_LOG_ERROR,\n\n                   \"Invalid bitstream, too many SBR envelopes in VARVAR type SBR frame: %d\\n\",\n\n                   ch_data->bs_num_env);\n\n            return -1;\n\n        }\n\n\n\n        for (i = 0; i < num_rel_lead; i++)\n\n            ch_data->t_env[i + 1] = ch_data->t_env[i] + 2 * get_bits(gb, 2) + 2;\n\n        for (i = 0; i < num_rel_trail; i++)\n\n            ch_data->t_env[ch_data->bs_num_env - 1 - i] =\n\n                ch_data->t_env[ch_data->bs_num_env - i] - 2 * get_bits(gb, 2) - 2;\n\n\n\n        bs_pointer = get_bits(gb, ceil_log2[ch_data->bs_num_env]);\n\n\n\n        get_bits1_vector(gb, ch_data->bs_freq_res + 1, ch_data->bs_num_env);\n\n        break;\n\n    }\n\n\n\n    if (bs_pointer > ch_data->bs_num_env + 1) {\n\n        av_log(ac->avccontext, AV_LOG_ERROR,\n\n               \"Invalid bitstream, bs_pointer points to a middle noise border outside the time borders table: %d\\n\",\n\n               bs_pointer);\n\n        return -1;\n\n    }\n\n\n\n    ch_data->bs_num_noise = (ch_data->bs_num_env > 1) + 1;\n\n\n\n    ch_data->t_q[0]                     = ch_data->t_env[0];\n\n    ch_data->t_q[ch_data->bs_num_noise] = ch_data->t_env[ch_data->bs_num_env];\n\n    if (ch_data->bs_num_noise > 1) {\n\n        unsigned int idx;\n\n        if (ch_data->bs_frame_class == FIXFIX) {\n\n            idx = ch_data->bs_num_env >> 1;\n\n        } else if (ch_data->bs_frame_class & 1) { // FIXVAR or VARVAR\n\n            idx = ch_data->bs_num_env - FFMAX(bs_pointer - 1, 1);\n\n        } else { // VARFIX\n\n            if (!bs_pointer)\n\n                idx = 1;\n\n            else if (bs_pointer == 1)\n\n                idx = ch_data->bs_num_env - 1;\n\n            else // bs_pointer > 1\n\n                idx = bs_pointer - 1;\n\n        }\n\n        ch_data->t_q[1] = ch_data->t_env[idx];\n\n    }\n\n\n\n    ch_data->e_a[0] = -(ch_data->e_a[1] != bs_num_env_old); // l_APrev\n\n    ch_data->e_a[1] = -1;\n\n    if ((ch_data->bs_frame_class & 1) && bs_pointer) { // FIXVAR or VARVAR and bs_pointer != 0\n\n        ch_data->e_a[1] = ch_data->bs_num_env + 1 - bs_pointer;\n\n    } else if ((ch_data->bs_frame_class == 2) && (bs_pointer > 1)) // VARFIX and bs_pointer > 1\n\n        ch_data->e_a[1] = bs_pointer - 1;\n\n\n\n    return 0;\n\n}\n", "idx": 4307, "_split": "test", "_hash": "0139145335a33b3815b7204b54b5966a"}
{"project": "FFmpeg", "commit_id": "612ecfbbbb3f4238d44cca5f250ffc6147d03ec2", "target": 0, "func": "static int gif_read_image(GifState *s)\n\n{\n\n    int left, top, width, height, bits_per_pixel, code_size, flags;\n\n    int is_interleaved, has_local_palette, y, pass, y1, linesize, n, i;\n\n    uint8_t *ptr, *spal, *palette, *ptr1;\n\n\n\n    left = bytestream_get_le16(&s->bytestream);\n\n    top = bytestream_get_le16(&s->bytestream);\n\n    width = bytestream_get_le16(&s->bytestream);\n\n    height = bytestream_get_le16(&s->bytestream);\n\n    flags = bytestream_get_byte(&s->bytestream);\n\n    is_interleaved = flags & 0x40;\n\n    has_local_palette = flags & 0x80;\n\n    bits_per_pixel = (flags & 0x07) + 1;\n\n\n\n    av_dlog(s->avctx, \"image x=%d y=%d w=%d h=%d\\n\", left, top, width, height);\n\n\n\n    if (has_local_palette) {\n\n        bytestream_get_buffer(&s->bytestream, s->local_palette, 3 * (1 << bits_per_pixel));\n\n        palette = s->local_palette;\n\n    } else {\n\n        palette = s->global_palette;\n\n        bits_per_pixel = s->bits_per_pixel;\n\n    }\n\n\n\n    /* verify that all the image is inside the screen dimensions */\n\n    if (left + width > s->screen_width ||\n\n        top + height > s->screen_height)\n\n        return AVERROR(EINVAL);\n\n\n\n    /* build the palette */\n\n    n = (1 << bits_per_pixel);\n\n    spal = palette;\n\n    for(i = 0; i < n; i++) {\n\n        s->image_palette[i] = (0xffu << 24) | AV_RB24(spal);\n\n        spal += 3;\n\n    }\n\n    for(; i < 256; i++)\n\n        s->image_palette[i] = (0xffu << 24);\n\n    /* handle transparency */\n\n    if (s->transparent_color_index >= 0)\n\n        s->image_palette[s->transparent_color_index] = 0;\n\n\n\n    /* now get the image data */\n\n    code_size = bytestream_get_byte(&s->bytestream);\n\n    ff_lzw_decode_init(s->lzw, code_size, s->bytestream,\n\n                       s->bytestream_end - s->bytestream, FF_LZW_GIF);\n\n\n\n    /* read all the image */\n\n    linesize = s->picture.linesize[0];\n\n    ptr1 = s->picture.data[0] + top * linesize + left;\n\n    ptr = ptr1;\n\n    pass = 0;\n\n    y1 = 0;\n\n    for (y = 0; y < height; y++) {\n\n        ff_lzw_decode(s->lzw, ptr, width);\n\n        if (is_interleaved) {\n\n            switch(pass) {\n\n            default:\n\n            case 0:\n\n            case 1:\n\n                y1 += 8;\n\n                ptr += linesize * 8;\n\n                if (y1 >= height) {\n\n                    y1 = pass ? 2 : 4;\n\n                    ptr = ptr1 + linesize * y1;\n\n                    pass++;\n\n                }\n\n                break;\n\n            case 2:\n\n                y1 += 4;\n\n                ptr += linesize * 4;\n\n                if (y1 >= height) {\n\n                    y1 = 1;\n\n                    ptr = ptr1 + linesize;\n\n                    pass++;\n\n                }\n\n                break;\n\n            case 3:\n\n                y1 += 2;\n\n                ptr += linesize * 2;\n\n                break;\n\n            }\n\n        } else {\n\n            ptr += linesize;\n\n        }\n\n    }\n\n    /* read the garbage data until end marker is found */\n\n    ff_lzw_decode_tail(s->lzw);\n\n    s->bytestream = ff_lzw_cur_ptr(s->lzw);\n\n    return 0;\n\n}\n", "idx": 4341, "_split": "test", "_hash": "468473468d0af9046b31bb30d02219b3"}
{"project": "FFmpeg", "commit_id": "43a4cb070bf7588c53fd192e8fbc71a52fa14a4c", "target": 0, "func": "static int alac_encode_frame(AVCodecContext *avctx, uint8_t *frame,\n\n                             int buf_size, void *data)\n\n{\n\n    AlacEncodeContext *s = avctx->priv_data;\n\n    PutBitContext *pb = &s->pbctx;\n\n    int i, out_bytes, verbatim_flag = 0;\n\n\n\n    if (avctx->frame_size > DEFAULT_FRAME_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"input frame size exceeded\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (buf_size < 2 * s->max_coded_frame_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"buffer size is too small\\n\");\n\n        return -1;\n\n    }\n\n\n\nverbatim:\n\n    init_put_bits(pb, frame, buf_size);\n\n\n\n    if (s->compression_level == 0 || verbatim_flag) {\n\n        // Verbatim mode\n\n        const int16_t *samples = data;\n\n        write_frame_header(s, 1);\n\n        for (i = 0; i < avctx->frame_size * avctx->channels; i++) {\n\n            put_sbits(pb, 16, *samples++);\n\n        }\n\n    } else {\n\n        init_sample_buffers(s, data);\n\n        write_frame_header(s, 0);\n\n        write_compressed_frame(s);\n\n    }\n\n\n\n    put_bits(pb, 3, 7);\n\n    flush_put_bits(pb);\n\n    out_bytes = put_bits_count(pb) >> 3;\n\n\n\n    if (out_bytes > s->max_coded_frame_size) {\n\n        /* frame too large. use verbatim mode */\n\n        if (verbatim_flag || s->compression_level == 0) {\n\n            /* still too large. must be an error. */\n\n            av_log(avctx, AV_LOG_ERROR, \"error encoding frame\\n\");\n\n            return -1;\n\n        }\n\n        verbatim_flag = 1;\n\n        goto verbatim;\n\n    }\n\n\n\n    return out_bytes;\n\n}\n", "idx": 4344, "_split": "test", "_hash": "acc2a75c7fbc9683164201eb677f406a"}
{"project": "FFmpeg", "commit_id": "56ee3f9de7b9f6090d599a27d33a392890a2f7b8", "target": 0, "func": "static int poll_filter(OutputStream *ost)\n\n{\n\n    OutputFile    *of = output_files[ost->file_index];\n\n    AVFrame *filtered_frame = NULL;\n\n    int frame_size, ret;\n\n\n\n    if (!ost->filtered_frame && !(ost->filtered_frame = avcodec_alloc_frame())) {\n\n        return AVERROR(ENOMEM);\n\n    } else\n\n        avcodec_get_frame_defaults(ost->filtered_frame);\n\n    filtered_frame = ost->filtered_frame;\n\n\n\n    if (ost->enc->type == AVMEDIA_TYPE_AUDIO &&\n\n        !(ost->enc->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE))\n\n        ret = av_buffersink_get_samples(ost->filter->filter, filtered_frame,\n\n                                         ost->st->codec->frame_size);\n\n    else\n\n        ret = av_buffersink_get_frame(ost->filter->filter, filtered_frame);\n\n\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (filtered_frame->pts != AV_NOPTS_VALUE) {\n\n        filtered_frame->pts = av_rescale_q(filtered_frame->pts,\n\n                                           ost->filter->filter->inputs[0]->time_base,\n\n                                           ost->st->codec->time_base) -\n\n                              av_rescale_q(of->start_time,\n\n                                           AV_TIME_BASE_Q,\n\n                                           ost->st->codec->time_base);\n\n    }\n\n\n\n    switch (ost->filter->filter->inputs[0]->type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        if (!ost->frame_aspect_ratio)\n\n            ost->st->codec->sample_aspect_ratio = filtered_frame->sample_aspect_ratio;\n\n\n\n        do_video_out(of->ctx, ost, filtered_frame, &frame_size);\n\n        if (vstats_filename && frame_size)\n\n            do_video_stats(ost, frame_size);\n\n        break;\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        do_audio_out(of->ctx, ost, filtered_frame);\n\n        break;\n\n    default:\n\n        // TODO support subtitle filters\n\n        av_assert0(0);\n\n    }\n\n\n\n    av_frame_unref(filtered_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 4411, "_split": "test", "_hash": "d022ee4e5ab4deb580dd636486eef8e9"}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "void ff_af_queue_init(AVCodecContext *avctx, AudioFrameQueue *afq)\n\n{\n\n    afq->avctx             = avctx;\n\n    afq->next_pts          = AV_NOPTS_VALUE;\n\n    afq->remaining_delay   = avctx->delay;\n\n    afq->remaining_samples = avctx->delay;\n\n    afq->frame_queue       = NULL;\n\n}\n", "idx": 4479, "_split": "test", "_hash": "32faefb4d9c719173e216a994bc2da75"}
{"project": "FFmpeg", "commit_id": "90540c2d5ace46a1e9789c75fde0b1f7dbb12a9b", "target": 1, "func": "static inline void RENAME(rgb24tobgr15)(const uint8_t *src, uint8_t *dst, int src_size)\n\n{\n\n    const uint8_t *s = src;\n\n    const uint8_t *end;\n\n    const uint8_t *mm_end;\n\n    uint16_t *d = (uint16_t *)dst;\n\n    end = s + src_size;\n\n    __asm__ volatile(PREFETCH\"    %0\"::\"m\"(*src):\"memory\");\n\n    __asm__ volatile(\n\n        \"movq          %0, %%mm7    \\n\\t\"\n\n        \"movq          %1, %%mm6    \\n\\t\"\n\n        ::\"m\"(red_15mask),\"m\"(green_15mask));\n\n    mm_end = end - 11;\n\n    while (s < mm_end) {\n\n        __asm__ volatile(\n\n            PREFETCH\"    32%1           \\n\\t\"\n\n            \"movd          %1, %%mm0    \\n\\t\"\n\n            \"movd         3%1, %%mm3    \\n\\t\"\n\n            \"punpckldq    6%1, %%mm0    \\n\\t\"\n\n            \"punpckldq    9%1, %%mm3    \\n\\t\"\n\n            \"movq       %%mm0, %%mm1    \\n\\t\"\n\n            \"movq       %%mm0, %%mm2    \\n\\t\"\n\n            \"movq       %%mm3, %%mm4    \\n\\t\"\n\n            \"movq       %%mm3, %%mm5    \\n\\t\"\n\n            \"psrlq         $3, %%mm0    \\n\\t\"\n\n            \"psrlq         $3, %%mm3    \\n\\t\"\n\n            \"pand          %2, %%mm0    \\n\\t\"\n\n            \"pand          %2, %%mm3    \\n\\t\"\n\n            \"psrlq         $6, %%mm1    \\n\\t\"\n\n            \"psrlq         $6, %%mm4    \\n\\t\"\n\n            \"pand       %%mm6, %%mm1    \\n\\t\"\n\n            \"pand       %%mm6, %%mm4    \\n\\t\"\n\n            \"psrlq         $9, %%mm2    \\n\\t\"\n\n            \"psrlq         $9, %%mm5    \\n\\t\"\n\n            \"pand       %%mm7, %%mm2    \\n\\t\"\n\n            \"pand       %%mm7, %%mm5    \\n\\t\"\n\n            \"por        %%mm1, %%mm0    \\n\\t\"\n\n            \"por        %%mm4, %%mm3    \\n\\t\"\n\n            \"por        %%mm2, %%mm0    \\n\\t\"\n\n            \"por        %%mm5, %%mm3    \\n\\t\"\n\n            \"psllq        $16, %%mm3    \\n\\t\"\n\n            \"por        %%mm3, %%mm0    \\n\\t\"\n\n            MOVNTQ\"     %%mm0, %0       \\n\\t\"\n\n            :\"=m\"(*d):\"m\"(*s),\"m\"(blue_15mask):\"memory\");\n\n        d += 4;\n\n        s += 12;\n\n    }\n\n    __asm__ volatile(SFENCE:::\"memory\");\n\n    __asm__ volatile(EMMS:::\"memory\");\n\n    while (s < end) {\n\n        const int b = *s++;\n\n        const int g = *s++;\n\n        const int r = *s++;\n\n        *d++ = (b>>3) | ((g&0xF8)<<2) | ((r&0xF8)<<7);\n\n    }\n\n}\n", "idx": 4519, "_split": "test", "_hash": "7ef989bfd7c80f87e3490225ee77c860"}
{"project": "FFmpeg", "commit_id": "b46a77f19ddc4b2b5fa3187835ceb602a5244e24", "target": 0, "func": "int ff_vdpau_common_init(AVCodecContext *avctx, VdpDecoderProfile profile,\n\n                         int level)\n\n{\n\n    VDPAUHWContext *hwctx = avctx->hwaccel_context;\n\n    VDPAUContext *vdctx = avctx->internal->hwaccel_priv_data;\n\n    VdpVideoSurfaceQueryCapabilities *surface_query_caps;\n\n    VdpDecoderQueryCapabilities *decoder_query_caps;\n\n    VdpDecoderCreate *create;\n\n    void *func;\n\n    VdpStatus status;\n\n    VdpBool supported;\n\n    uint32_t max_level, max_mb, max_width, max_height;\n\n    VdpChromaType type;\n\n    uint32_t width;\n\n    uint32_t height;\n\n\n\n    vdctx->width            = UINT32_MAX;\n\n    vdctx->height           = UINT32_MAX;\n\n\n\n    if (av_vdpau_get_surface_parameters(avctx, &type, &width, &height))\n\n        return AVERROR(ENOSYS);\n\n\n\n    if (hwctx) {\n\n        hwctx->reset            = 0;\n\n\n\n        if (hwctx->context.decoder != VDP_INVALID_HANDLE) {\n\n            vdctx->decoder = hwctx->context.decoder;\n\n            vdctx->render  = hwctx->context.render;\n\n            vdctx->device  = VDP_INVALID_HANDLE;\n\n            return 0; /* Decoder created by user */\n\n        }\n\n\n\n        vdctx->device           = hwctx->device;\n\n        vdctx->get_proc_address = hwctx->get_proc_address;\n\n\n\n        if (hwctx->flags & AV_HWACCEL_FLAG_IGNORE_LEVEL)\n\n            level = 0;\n\n\n\n        if (!(hwctx->flags & AV_HWACCEL_FLAG_ALLOW_HIGH_DEPTH) &&\n\n            type != VDP_CHROMA_TYPE_420)\n\n            return AVERROR(ENOSYS);\n\n    } else {\n\n        AVHWFramesContext *frames_ctx = NULL;\n\n        AVVDPAUDeviceContext *dev_ctx;\n\n\n\n        // We assume the hw_frames_ctx always survives until ff_vdpau_common_uninit\n\n        // is called. This holds true as the user is not allowed to touch\n\n        // hw_device_ctx, or hw_frames_ctx after get_format (and ff_get_format\n\n        // itself also uninits before unreffing hw_frames_ctx).\n\n        if (avctx->hw_frames_ctx) {\n\n            frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n        } else if (avctx->hw_device_ctx) {\n\n            int ret;\n\n\n\n            avctx->hw_frames_ctx = av_hwframe_ctx_alloc(avctx->hw_device_ctx);\n\n            if (!avctx->hw_frames_ctx)\n\n                return AVERROR(ENOMEM);\n\n\n\n            frames_ctx            = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n            frames_ctx->format    = AV_PIX_FMT_VDPAU;\n\n            frames_ctx->sw_format = avctx->sw_pix_fmt;\n\n            frames_ctx->width     = avctx->coded_width;\n\n            frames_ctx->height    = avctx->coded_height;\n\n\n\n            ret = av_hwframe_ctx_init(avctx->hw_frames_ctx);\n\n            if (ret < 0) {\n\n                av_buffer_unref(&avctx->hw_frames_ctx);\n\n                return ret;\n\n            }\n\n        }\n\n\n\n        if (!frames_ctx) {\n\n            av_log(avctx, AV_LOG_ERROR, \"A hardware frames context is \"\n\n                   \"required for VDPAU decoding.\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        dev_ctx = frames_ctx->device_ctx->hwctx;\n\n\n\n        vdctx->device           = dev_ctx->device;\n\n        vdctx->get_proc_address = dev_ctx->get_proc_address;\n\n\n\n        if (avctx->hwaccel_flags & AV_HWACCEL_FLAG_IGNORE_LEVEL)\n\n            level = 0;\n\n    }\n\n\n\n    if (level < 0)\n\n        return AVERROR(ENOTSUP);\n\n\n\n    status = vdctx->get_proc_address(vdctx->device,\n\n                                     VDP_FUNC_ID_VIDEO_SURFACE_QUERY_CAPABILITIES,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        surface_query_caps = func;\n\n\n\n    status = surface_query_caps(vdctx->device, type, &supported,\n\n                                &max_width, &max_height);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    if (supported != VDP_TRUE ||\n\n        max_width < width || max_height < height)\n\n        return AVERROR(ENOTSUP);\n\n\n\n    status = vdctx->get_proc_address(vdctx->device,\n\n                                     VDP_FUNC_ID_DECODER_QUERY_CAPABILITIES,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        decoder_query_caps = func;\n\n\n\n    status = decoder_query_caps(vdctx->device, profile, &supported, &max_level,\n\n                                &max_mb, &max_width, &max_height);\n\n#ifdef VDP_DECODER_PROFILE_H264_CONSTRAINED_BASELINE\n\n    if ((status != VDP_STATUS_OK || supported != VDP_TRUE) && profile == VDP_DECODER_PROFILE_H264_CONSTRAINED_BASELINE) {\n\n        profile = VDP_DECODER_PROFILE_H264_MAIN;\n\n        status = decoder_query_caps(vdctx->device, profile, &supported,\n\n                                    &max_level, &max_mb,\n\n                                    &max_width, &max_height);\n\n    }\n\n#endif\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n\n\n    if (supported != VDP_TRUE || max_level < level ||\n\n        max_width < width || max_height < height)\n\n        return AVERROR(ENOTSUP);\n\n\n\n    status = vdctx->get_proc_address(vdctx->device, VDP_FUNC_ID_DECODER_CREATE,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        create = func;\n\n\n\n    status = vdctx->get_proc_address(vdctx->device, VDP_FUNC_ID_DECODER_RENDER,\n\n                                     &func);\n\n    if (status != VDP_STATUS_OK)\n\n        return vdpau_error(status);\n\n    else\n\n        vdctx->render = func;\n\n\n\n    status = create(vdctx->device, profile, width, height, avctx->refs,\n\n                    &vdctx->decoder);\n\n    if (status == VDP_STATUS_OK) {\n\n        vdctx->width  = avctx->coded_width;\n\n        vdctx->height = avctx->coded_height;\n\n    }\n\n\n\n    return vdpau_error(status);\n\n}\n", "idx": 4524, "_split": "test", "_hash": "c9197f7eb69c56d0d168a77abed5fb66"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int estimate_qp(MpegEncContext *s, int dry_run){\n\n    if (s->next_lambda){\n\n        s->current_picture_ptr->f.quality =\n\n        s->current_picture.f.quality = s->next_lambda;\n\n        if(!dry_run) s->next_lambda= 0;\n\n    } else if (!s->fixed_qscale) {\n\n        s->current_picture_ptr->f.quality =\n\n        s->current_picture.f.quality = ff_rate_estimate_qscale(s, dry_run);\n\n        if (s->current_picture.f.quality < 0)\n\n            return -1;\n\n    }\n\n\n\n    if(s->adaptive_quant){\n\n        switch(s->codec_id){\n\n        case AV_CODEC_ID_MPEG4:\n\n            if (CONFIG_MPEG4_ENCODER)\n\n                ff_clean_mpeg4_qscales(s);\n\n            break;\n\n        case AV_CODEC_ID_H263:\n\n        case AV_CODEC_ID_H263P:\n\n        case AV_CODEC_ID_FLV1:\n\n            if (CONFIG_H263_ENCODER)\n\n                ff_clean_h263_qscales(s);\n\n            break;\n\n        default:\n\n            ff_init_qscale_tab(s);\n\n        }\n\n\n\n        s->lambda= s->lambda_table[0];\n\n        //FIXME broken\n\n    }else\n\n        s->lambda = s->current_picture.f.quality;\n\n    update_qscale(s);\n\n    return 0;\n\n}\n", "idx": 4539, "_split": "test", "_hash": "889f98ffbc5fed3166cee963a20ff44c"}
{"project": "FFmpeg", "commit_id": "6c77805fc84a63b74e5025b4d7eeea24c8138cf3", "target": 0, "func": "enum CodecID av_codec_get_id(const AVCodecTag *tags[4], unsigned int tag)\n\n{\n\n    int i;\n\n    for(i=0; i<4 && tags[i]; i++){\n\n        enum CodecID id= codec_get_id(tags[i], tag);\n\n        if(id!=CODEC_ID_NONE) return id;\n\n    }\n\n    return CODEC_ID_NONE;\n\n}\n", "idx": 4610, "_split": "test", "_hash": "7932f8bddbc3eb154c703fc930a6d7e5"}
{"project": "FFmpeg", "commit_id": "57d04d3f11290d1848efa3b47031762f936d4cb3", "target": 1, "func": "static inline void blockCopy(uint8_t dst[], int dstStride, uint8_t src[], int srcStride,\n\n\tint numLines, int levelFix)\n\n{\n\n\tint i;\n\n\tif(levelFix)\n\n\t{\n\n#ifdef HAVE_MMX\n\n\t\t\t\t\tasm volatile(\n\n\t\t\t\t\t\t\"movl %4, %%eax \\n\\t\"\n\n\t\t\t\t\t\t\"movl %%eax, temp0\\n\\t\"\n\n\t\t\t\t\t\t\"pushl %0 \\n\\t\"\n\n\t\t\t\t\t\t\"pushl %1 \\n\\t\"\n\n\t\t\t\t\t\t\"leal (%2,%2), %%eax\t\\n\\t\"\n\n\t\t\t\t\t\t\"leal (%3,%3), %%ebx\t\\n\\t\"\n\n\t\t\t\t\t\t\"movq packedYOffset, %%mm2\t\\n\\t\"\n\n\t\t\t\t\t\t\"movq packedYScale, %%mm3\t\\n\\t\"\n\n\t\t\t\t\t\t\"pxor %%mm4, %%mm4\t\\n\\t\"\n\n\n\n#define SCALED_CPY\t\t\t\t\t\\\n\n\t\t\t\t\t\t\"movq (%0), %%mm0\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq (%0,%2), %%mm1\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"psubusb %%mm2, %%mm0\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"psubusb %%mm2, %%mm1\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq %%mm0, %%mm5\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"punpcklbw %%mm4, %%mm0 \\n\\t\"\\\n\n\t\t\t\t\t\t\"punpckhbw %%mm4, %%mm5 \\n\\t\"\\\n\n\t\t\t\t\t\t\"psllw $7, %%mm0\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"psllw $7, %%mm5\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"pmulhw %%mm3, %%mm0\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"pmulhw %%mm3, %%mm5\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"packuswb %%mm5, %%mm0\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq %%mm0, (%1)\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq %%mm1, %%mm5\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"punpcklbw %%mm4, %%mm1 \\n\\t\"\\\n\n\t\t\t\t\t\t\"punpckhbw %%mm4, %%mm5 \\n\\t\"\\\n\n\t\t\t\t\t\t\"psllw $7, %%mm1\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"psllw $7, %%mm5\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"pmulhw %%mm3, %%mm1\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"pmulhw %%mm3, %%mm5\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"packuswb %%mm5, %%mm1\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq %%mm1, (%1, %3)\t\\n\\t\"\\\n\n\n\n\t\t\t\t\t\t\"1:\t\t\t\\n\\t\"\n\nSCALED_CPY\n\n\t\t\t\t\t\t\"addl %%eax, %0\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"addl %%ebx, %1\t\t\\n\\t\"\n\nSCALED_CPY\n\n\t\t\t\t\t\t\"addl %%eax, %0\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"addl %%ebx, %1\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"decl temp0\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"jnz 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t\t\t\t\"popl %1 \\n\\t\"\n\n\t\t\t\t\t\t\"popl %0 \\n\\t\"\n\n\t\t\t\t\t\t: : \"r\" (src),\n\n\t\t\t\t\t\t\"r\" (dst),\n\n\t\t\t\t\t\t\"r\" (srcStride),\n\n\t\t\t\t\t\t\"r\" (dstStride),\n\n\t\t\t\t\t\t\"m\" (numLines>>2)\n\n\t\t\t\t\t\t: \"%eax\", \"%ebx\"\n\n\t\t\t\t\t);\n\n#else\n\n\t\t\t\tfor(i=0; i<numLines; i++)\n\n\t\t\t\t\tmemcpy(\t&(dst[dstStride*i]),\n\n\t\t\t\t\t\t&(src[srcStride*i]), BLOCK_SIZE);\n\n#endif\n\n\t}\n\n\telse\n\n\t{\n\n#ifdef HAVE_MMX\n\n\t\t\t\t\tasm volatile(\n\n\t\t\t\t\t\t\"movl %4, %%eax \\n\\t\"\n\n\t\t\t\t\t\t\"movl %%eax, temp0\\n\\t\"\n\n\t\t\t\t\t\t\"pushl %0 \\n\\t\"\n\n\t\t\t\t\t\t\"pushl %1 \\n\\t\"\n\n\t\t\t\t\t\t\"leal (%2,%2), %%eax\t\\n\\t\"\n\n\t\t\t\t\t\t\"leal (%3,%3), %%ebx\t\\n\\t\"\n\n\t\t\t\t\t\t\"movq packedYOffset, %%mm2\t\\n\\t\"\n\n\t\t\t\t\t\t\"movq packedYScale, %%mm3\t\\n\\t\"\n\n\n\n#define SIMPLE_CPY\t\t\t\t\t\\\n\n\t\t\t\t\t\t\"movq (%0), %%mm0\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq (%0,%2), %%mm1\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq %%mm0, (%1)\t\\n\\t\"\\\n\n\t\t\t\t\t\t\"movq %%mm1, (%1, %3)\t\\n\\t\"\\\n\n\n\n\t\t\t\t\t\t\"1:\t\t\t\\n\\t\"\n\nSIMPLE_CPY\n\n\t\t\t\t\t\t\"addl %%eax, %0\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"addl %%ebx, %1\t\t\\n\\t\"\n\nSIMPLE_CPY\n\n\t\t\t\t\t\t\"addl %%eax, %0\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"addl %%ebx, %1\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"decl temp0\t\t\\n\\t\"\n\n\t\t\t\t\t\t\"jnz 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t\t\t\t\"popl %1 \\n\\t\"\n\n\t\t\t\t\t\t\"popl %0 \\n\\t\"\n\n\t\t\t\t\t\t: : \"r\" (src),\n\n\t\t\t\t\t\t\"r\" (dst),\n\n\t\t\t\t\t\t\"r\" (srcStride),\n\n\t\t\t\t\t\t\"r\" (dstStride),\n\n\t\t\t\t\t\t\"m\" (numLines>>2)\n\n\t\t\t\t\t\t: \"%eax\", \"%ebx\"\n\n\t\t\t\t\t);\n\n#else\n\n\t\t\t\tfor(i=0; i<numLines; i++)\n\n\t\t\t\t\tmemcpy(\t&(dst[dstStride*i]),\n\n\t\t\t\t\t\t&(src[srcStride*i]), BLOCK_SIZE);\n\n#endif\n\n\t}\n\n}\n", "idx": 4639, "_split": "test", "_hash": "ecfcbff48a469d445e05958da26b34e1"}
{"project": "FFmpeg", "commit_id": "ae93965359e71c1f88ba170f8efd6a198344c235", "target": 1, "func": "int ff_hevc_output_frame(HEVCContext *s, AVFrame *out, int flush)\n\n{\n\n    do {\n\n        int nb_output = 0;\n\n        int min_poc   = INT_MAX;\n\n        int i, min_idx, ret;\n\n\n\n        if (s->sh.no_output_of_prior_pics_flag == 1) {\n\n            for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n\n                HEVCFrame *frame = &s->DPB[i];\n\n                if (!(frame->flags & HEVC_FRAME_FLAG_BUMPING) && frame->poc != s->poc &&\n\n                        frame->sequence == s->seq_output) {\n\n                    ff_hevc_unref_frame(s, frame, HEVC_FRAME_FLAG_OUTPUT);\n\n                }\n\n            }\n\n        }\n\n\n\n        for (i = 0; i < FF_ARRAY_ELEMS(s->DPB); i++) {\n\n            HEVCFrame *frame = &s->DPB[i];\n\n            if ((frame->flags & HEVC_FRAME_FLAG_OUTPUT) &&\n\n                frame->sequence == s->seq_output) {\n\n                nb_output++;\n\n                if (frame->poc < min_poc) {\n\n                    min_poc = frame->poc;\n\n                    min_idx = i;\n\n                }\n\n            }\n\n        }\n\n\n\n        /* wait for more frames before output */\n\n        if (!flush && s->seq_output == s->seq_decode && s->sps &&\n\n            nb_output <= s->sps->temporal_layer[s->sps->max_sub_layers - 1].num_reorder_pics)\n\n            return 0;\n\n\n\n        if (nb_output) {\n\n            HEVCFrame *frame = &s->DPB[min_idx];\n\n            AVFrame *dst = out;\n\n            AVFrame *src = frame->frame;\n\n            const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(src->format);\n\n            int pixel_shift = !!(desc->comp[0].depth_minus1 > 7);\n\n\n\n            ret = av_frame_ref(out, src);\n\n            if (frame->flags & HEVC_FRAME_FLAG_BUMPING)\n\n                ff_hevc_unref_frame(s, frame, HEVC_FRAME_FLAG_OUTPUT | HEVC_FRAME_FLAG_BUMPING);\n\n            else\n\n                ff_hevc_unref_frame(s, frame, HEVC_FRAME_FLAG_OUTPUT);\n\n            if (ret < 0)\n\n                return ret;\n\n\n\n            for (i = 0; i < 3; i++) {\n\n                int hshift = (i > 0) ? desc->log2_chroma_w : 0;\n\n                int vshift = (i > 0) ? desc->log2_chroma_h : 0;\n\n                int off = ((frame->window.left_offset >> hshift) << pixel_shift) +\n\n                          (frame->window.top_offset   >> vshift) * dst->linesize[i];\n\n                dst->data[i] += off;\n\n            }\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"Output frame with POC %d.\\n\", frame->poc);\n\n            return 1;\n\n        }\n\n\n\n        if (s->seq_output != s->seq_decode)\n\n            s->seq_output = (s->seq_output + 1) & 0xff;\n\n        else\n\n            break;\n\n    } while (1);\n\n\n\n    return 0;\n\n}\n", "idx": 4668, "_split": "test", "_hash": "03840422e4b049f9d49e79599e768314"}
{"project": "FFmpeg", "commit_id": "4b9ac0b5f070f35eff671d83cee436db40631112", "target": 0, "func": "static int mpegaudio_parse(AVCodecParserContext *s1,\n\n                           AVCodecContext *avctx,\n\n                           uint8_t **poutbuf, int *poutbuf_size, \n\n                           const uint8_t *buf, int buf_size)\n\n{\n\n    MpegAudioParseContext *s = s1->priv_data;\n\n    int len, ret;\n\n    uint32_t header;\n\n    const uint8_t *buf_ptr;\n\n\n\n    *poutbuf = NULL;\n\n    *poutbuf_size = 0;\n\n    buf_ptr = buf;\n\n    while (buf_size > 0) {\n\n\tlen = s->inbuf_ptr - s->inbuf;\n\n\tif (s->frame_size == 0) {\n\n            /* special case for next header for first frame in free\n\n               format case (XXX: find a simpler method) */\n\n            if (s->free_format_next_header != 0) {\n\n                s->inbuf[0] = s->free_format_next_header >> 24;\n\n                s->inbuf[1] = s->free_format_next_header >> 16;\n\n                s->inbuf[2] = s->free_format_next_header >> 8;\n\n                s->inbuf[3] = s->free_format_next_header;\n\n                s->inbuf_ptr = s->inbuf + 4;\n\n                s->free_format_next_header = 0;\n\n                goto got_header;\n\n            }\n\n\t    /* no header seen : find one. We need at least MPA_HEADER_SIZE\n\n               bytes to parse it */\n\n\t    len = MPA_HEADER_SIZE - len;\n\n\t    if (len > buf_size)\n\n\t\tlen = buf_size;\n\n\t    if (len > 0) {\n\n\t\tmemcpy(s->inbuf_ptr, buf_ptr, len);\n\n\t\tbuf_ptr += len;\n\n\t\tbuf_size -= len;\n\n\t\ts->inbuf_ptr += len;\n\n\t    }\n\n\t    if ((s->inbuf_ptr - s->inbuf) >= MPA_HEADER_SIZE) {\n\n            got_header:\n\n\t\theader = (s->inbuf[0] << 24) | (s->inbuf[1] << 16) |\n\n\t\t    (s->inbuf[2] << 8) | s->inbuf[3];\n\n\n\n                ret = mpa_decode_header(avctx, header);\n\n                if (ret < 0) {\n\n\t\t    /* no sync found : move by one byte (inefficient, but simple!) */\n\n\t\t    memmove(s->inbuf, s->inbuf + 1, s->inbuf_ptr - s->inbuf - 1);\n\n\t\t    s->inbuf_ptr--;\n\n                    dprintf(\"skip %x\\n\", header);\n\n                    /* reset free format frame size to give a chance\n\n                       to get a new bitrate */\n\n                    s->free_format_frame_size = 0;\n\n\t\t} else {\n\n                    s->frame_size = ret;\n\n#if 0\n\n                    /* free format: prepare to compute frame size */\n\n\t\t    if (decode_header(s, header) == 1) {\n\n\t\t\ts->frame_size = -1;\n\n                    }\n\n#endif\n\n\t\t}\n\n\t    }\n\n        } else \n\n#if 0\n\n        if (s->frame_size == -1) {\n\n            /* free format : find next sync to compute frame size */\n\n\t    len = MPA_MAX_CODED_FRAME_SIZE - len;\n\n\t    if (len > buf_size)\n\n\t\tlen = buf_size;\n\n            if (len == 0) {\n\n\t\t/* frame too long: resync */\n\n                s->frame_size = 0;\n\n\t\tmemmove(s->inbuf, s->inbuf + 1, s->inbuf_ptr - s->inbuf - 1);\n\n\t\ts->inbuf_ptr--;\n\n            } else {\n\n                uint8_t *p, *pend;\n\n                uint32_t header1;\n\n                int padding;\n\n\n\n                memcpy(s->inbuf_ptr, buf_ptr, len);\n\n                /* check for header */\n\n                p = s->inbuf_ptr - 3;\n\n                pend = s->inbuf_ptr + len - 4;\n\n                while (p <= pend) {\n\n                    header = (p[0] << 24) | (p[1] << 16) |\n\n                        (p[2] << 8) | p[3];\n\n                    header1 = (s->inbuf[0] << 24) | (s->inbuf[1] << 16) |\n\n                        (s->inbuf[2] << 8) | s->inbuf[3];\n\n                    /* check with high probability that we have a\n\n                       valid header */\n\n                    if ((header & SAME_HEADER_MASK) ==\n\n                        (header1 & SAME_HEADER_MASK)) {\n\n                        /* header found: update pointers */\n\n                        len = (p + 4) - s->inbuf_ptr;\n\n                        buf_ptr += len;\n\n                        buf_size -= len;\n\n                        s->inbuf_ptr = p;\n\n                        /* compute frame size */\n\n                        s->free_format_next_header = header;\n\n                        s->free_format_frame_size = s->inbuf_ptr - s->inbuf;\n\n                        padding = (header1 >> 9) & 1;\n\n                        if (s->layer == 1)\n\n                            s->free_format_frame_size -= padding * 4;\n\n                        else\n\n                            s->free_format_frame_size -= padding;\n\n                        dprintf(\"free frame size=%d padding=%d\\n\", \n\n                                s->free_format_frame_size, padding);\n\n                        decode_header(s, header1);\n\n                        goto next_data;\n\n                    }\n\n                    p++;\n\n                }\n\n                /* not found: simply increase pointers */\n\n                buf_ptr += len;\n\n                s->inbuf_ptr += len;\n\n                buf_size -= len;\n\n            }\n\n\t} else \n\n#endif\n\n        if (len < s->frame_size) {\n\n            if (s->frame_size > MPA_MAX_CODED_FRAME_SIZE)\n\n                s->frame_size = MPA_MAX_CODED_FRAME_SIZE;\n\n\t    len = s->frame_size - len;\n\n\t    if (len > buf_size)\n\n\t\tlen = buf_size;\n\n\t    memcpy(s->inbuf_ptr, buf_ptr, len);\n\n\t    buf_ptr += len;\n\n\t    s->inbuf_ptr += len;\n\n\t    buf_size -= len;\n\n\t}\n\n        //    next_data:\n\n        if (s->frame_size > 0 && \n\n            (s->inbuf_ptr - s->inbuf) >= s->frame_size) {\n\n            *poutbuf = s->inbuf;\n\n            *poutbuf_size = s->inbuf_ptr - s->inbuf;\n\n\t    s->inbuf_ptr = s->inbuf;\n\n\t    s->frame_size = 0;\n\n\t    break;\n\n\t}\n\n    }\n\n    return buf_ptr - buf;\n\n}\n", "idx": 4681, "_split": "test", "_hash": "1790696c9d0f5af565a8378132484762"}
{"project": "FFmpeg", "commit_id": "33d69a90085d30af8a292d9364b835a26565d6b9", "target": 0, "func": "JNIEnv *ff_jni_attach_env(int *attached, void *log_ctx)\n\n{\n\n    int ret = 0;\n\n    JNIEnv *env = NULL;\n\n\n\n    *attached = 0;\n\n\n\n    pthread_mutex_lock(&lock);\n\n    if (java_vm == NULL && (java_vm = av_jni_get_java_vm(log_ctx)) == NULL) {\n\n\n\n        av_log(log_ctx, AV_LOG_INFO, \"Retrieving current Java virtual machine using Android JniInvocation wrapper\\n\");\n\n        if (check_jni_invocation(log_ctx) == 0) {\n\n            if ((java_vm = get_java_vm(NULL, log_ctx)) != NULL ||\n\n                (java_vm = get_java_vm(\"libdvm.so\", log_ctx)) != NULL ||\n\n                (java_vm = get_java_vm(\"libart.so\", log_ctx)) != NULL) {\n\n                av_log(log_ctx, AV_LOG_INFO, \"Found Java virtual machine using Android JniInvocation wrapper\\n\");\n\n            }\n\n        }\n\n    }\n\n    pthread_mutex_unlock(&lock);\n\n\n\n    if (!java_vm) {\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Could not retrieve a Java virtual machine\\n\");\n\n        return NULL;\n\n    }\n\n\n\n    ret = (*java_vm)->GetEnv(java_vm, (void **)&env, JNI_VERSION_1_6);\n\n    switch(ret) {\n\n    case JNI_EDETACHED:\n\n        if ((*java_vm)->AttachCurrentThread(java_vm, &env, NULL) != 0) {\n\n            av_log(log_ctx, AV_LOG_ERROR, \"Failed to attach the JNI environment to the current thread\\n\");\n\n            env = NULL;\n\n        } else {\n\n            *attached = 1;\n\n        }\n\n        break;\n\n    case JNI_OK:\n\n        break;\n\n    case JNI_EVERSION:\n\n        av_log(log_ctx, AV_LOG_ERROR, \"The specified JNI version is not supported\\n\");\n\n        break;\n\n    default:\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Failed to get the JNI environment attached to this thread\");\n\n        break;\n\n    }\n\n\n\n    return env;\n\n}\n", "idx": 4685, "_split": "test", "_hash": "2b0a976cb34acf4c23761c8920a96aa0"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "void sws_rgb2rgb_init(int flags)\n\n{\n\n#if HAVE_SSE2 || HAVE_MMX2 || HAVE_AMD3DNOW || HAVE_MMX\n\n    if (flags & SWS_CPU_CAPS_SSE2)\n\n        rgb2rgb_init_SSE2();\n\n    else if (flags & SWS_CPU_CAPS_MMX2)\n\n        rgb2rgb_init_MMX2();\n\n    else if (flags & SWS_CPU_CAPS_3DNOW)\n\n        rgb2rgb_init_3DNOW();\n\n    else if (flags & SWS_CPU_CAPS_MMX)\n\n        rgb2rgb_init_MMX();\n\n    else\n\n#endif /* HAVE_MMX2 || HAVE_AMD3DNOW || HAVE_MMX */\n\n        rgb2rgb_init_C();\n\n}\n", "idx": 4698, "_split": "test", "_hash": "9d8357100acd2379f0ad44f3659858f3"}
{"project": "FFmpeg", "commit_id": "292850b634240045805e3c2001aed6f046034e93", "target": 0, "func": "static double tget_double(GetByteContext *gb, int le)\n\n{\n\n    av_alias64 i = { .u64 = le ? bytestream2_get_le64(gb) : bytestream2_get_be64(gb)};\n\n    return i.f64;\n\n}\n", "idx": 4718, "_split": "test", "_hash": "a487c0533e16837516274f90716a20b5"}
{"project": "FFmpeg", "commit_id": "15d14ce47cb39b93a80a2c6b8396db81c16934e6", "target": 1, "func": "static int64_t get_bit_rate(AVCodecContext *ctx)\n\n{\n\n    int64_t bit_rate;\n\n    int bits_per_sample;\n\n\n\n    switch (ctx->codec_type) {\n\n    case AVMEDIA_TYPE_VIDEO:\n\n    case AVMEDIA_TYPE_DATA:\n\n    case AVMEDIA_TYPE_SUBTITLE:\n\n    case AVMEDIA_TYPE_ATTACHMENT:\n\n        bit_rate = ctx->bit_rate;\n\n        break;\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        bits_per_sample = av_get_bits_per_sample(ctx->codec_id);\n\n        bit_rate = bits_per_sample ? ctx->sample_rate * ctx->channels * bits_per_sample : ctx->bit_rate;\n\n        break;\n\n    default:\n\n        bit_rate = 0;\n\n        break;\n\n    }\n\n    return bit_rate;\n\n}\n", "idx": 4761, "_split": "test", "_hash": "3b55d2b4b25492d1020f3fb9b2f79308"}
{"project": "FFmpeg", "commit_id": "7631f14bb35e8467d4ffaaa2b34e60614eb37c71", "target": 0, "func": "static int mkv_write_codecprivate(AVFormatContext *s, AVIOContext *pb,\n\n                                  AVCodecParameters *par,\n\n                                  int native_id, int qt_id)\n\n{\n\n    AVIOContext *dyn_cp;\n\n    uint8_t *codecpriv;\n\n    int ret, codecpriv_size;\n\n\n\n    ret = avio_open_dyn_buf(&dyn_cp);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (native_id) {\n\n        ret = mkv_write_native_codecprivate(s, par, dyn_cp);\n\n    } else if (par->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n        if (qt_id) {\n\n            if (!par->codec_tag)\n\n                par->codec_tag = ff_codec_get_tag(ff_codec_movvideo_tags,\n\n                                                    par->codec_id);\n\n            if (   ff_codec_get_id(ff_codec_movvideo_tags, par->codec_tag) == par->codec_id\n\n                && (!par->extradata_size || ff_codec_get_id(ff_codec_movvideo_tags, AV_RL32(par->extradata + 4)) != par->codec_id)\n\n            ) {\n\n                int i;\n\n                avio_wb32(dyn_cp, 0x5a + par->extradata_size);\n\n                avio_wl32(dyn_cp, par->codec_tag);\n\n                for(i = 0; i < 0x5a - 8; i++)\n\n                    avio_w8(dyn_cp, 0);\n\n            }\n\n            avio_write(dyn_cp, par->extradata, par->extradata_size);\n\n        } else {\n\n            if (!ff_codec_get_tag(ff_codec_bmp_tags, par->codec_id))\n\n                av_log(s, AV_LOG_WARNING, \"codec %s is not supported by this format\\n\",\n\n                       avcodec_get_name(par->codec_id));\n\n\n\n            if (!par->codec_tag)\n\n                par->codec_tag = ff_codec_get_tag(ff_codec_bmp_tags,\n\n                                                  par->codec_id);\n\n            if (!par->codec_tag && par->codec_id != AV_CODEC_ID_RAWVIDEO) {\n\n                av_log(s, AV_LOG_ERROR, \"No bmp codec tag found for codec %s\\n\",\n\n                       avcodec_get_name(par->codec_id));\n\n                ret = AVERROR(EINVAL);\n\n            }\n\n\n\n            ff_put_bmp_header(dyn_cp, par, ff_codec_bmp_tags, 0, 0);\n\n        }\n\n    } else if (par->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n        unsigned int tag;\n\n        tag = ff_codec_get_tag(ff_codec_wav_tags, par->codec_id);\n\n        if (!tag) {\n\n            av_log(s, AV_LOG_ERROR, \"No wav codec tag found for codec %s\\n\",\n\n                   avcodec_get_name(par->codec_id));\n\n            ret = AVERROR(EINVAL);\n\n        }\n\n        if (!par->codec_tag)\n\n            par->codec_tag = tag;\n\n\n\n        ff_put_wav_header(s, dyn_cp, par, FF_PUT_WAV_HEADER_FORCE_WAVEFORMATEX);\n\n    }\n\n\n\n    codecpriv_size = avio_close_dyn_buf(dyn_cp, &codecpriv);\n\n    if (codecpriv_size)\n\n        put_ebml_binary(pb, MATROSKA_ID_CODECPRIVATE, codecpriv,\n\n                        codecpriv_size);\n\n    av_free(codecpriv);\n\n    return ret;\n\n}\n", "idx": 4762, "_split": "test", "_hash": "c8681e2710db726cb6b1540626e6de61"}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "void ff_vp3_idct_dc_add_c(uint8_t *dest/*align 8*/, int line_size, const DCTELEM *block/*align 16*/){\n\n    int i, dc = (block[0] + 15) >> 5;\n\n    const uint8_t *cm = ff_cropTbl + MAX_NEG_CROP + dc;\n\n\n\n    for(i = 0; i < 8; i++){\n\n        dest[0] = cm[dest[0]];\n\n        dest[1] = cm[dest[1]];\n\n        dest[2] = cm[dest[2]];\n\n        dest[3] = cm[dest[3]];\n\n        dest[4] = cm[dest[4]];\n\n        dest[5] = cm[dest[5]];\n\n        dest[6] = cm[dest[6]];\n\n        dest[7] = cm[dest[7]];\n\n        dest += line_size;\n\n    }\n\n}\n", "idx": 4766, "_split": "test", "_hash": "7ea1617c07724b4f9e50a792950f862c"}
{"project": "FFmpeg", "commit_id": "13705b69ebe9e375fdb52469760a0fbb5f593cc1", "target": 1, "func": "static inline int mirror(int v, int m){\n\n    if     (v<0) return -v;\n\n    else if(v>m) return 2*m-v;\n\n    else         return v;\n\n}\n", "idx": 4769, "_split": "test", "_hash": "c18f36b8fe3560bf7431e0dad8df6404"}
{"project": "FFmpeg", "commit_id": "ddef3d902f0e4cbd6be6b3e5df7ec158ce51488b", "target": 1, "func": "static int mov_write_tkhd_tag(AVIOContext *pb, MOVMuxContext *mov,\n\n                              MOVTrack *track, AVStream *st)\n\n{\n\n    int64_t duration = av_rescale_rnd(track->track_duration, MOV_TIMESCALE,\n\n                                      track->timescale, AV_ROUND_UP);\n\n    int version = duration < INT32_MAX ? 0 : 1;\n\n    int flags   = MOV_TKHD_FLAG_IN_MOVIE;\n\n    int rotation = 0;\n\n    int group   = 0;\n\n\n\n    uint32_t *display_matrix = NULL;\n\n    int      display_matrix_size, i;\n\n\n\n    if (st) {\n\n        if (mov->per_stream_grouping)\n\n            group = st->index;\n\n        else\n\n            group = st->codecpar->codec_type;\n\n\n\n        display_matrix = (uint32_t*)av_stream_get_side_data(st, AV_PKT_DATA_DISPLAYMATRIX,\n\n                                                            &display_matrix_size);\n\n        if (display_matrix && display_matrix_size < 9 * sizeof(*display_matrix))\n\n            display_matrix = NULL;\n\n    }\n\n\n\n    if (track->flags & MOV_TRACK_ENABLED)\n\n        flags |= MOV_TKHD_FLAG_ENABLED;\n\n\n\n    if (track->mode == MODE_ISM)\n\n        version = 1;\n\n\n\n    (version == 1) ? avio_wb32(pb, 104) : avio_wb32(pb, 92); /* size */\n\n    ffio_wfourcc(pb, \"tkhd\");\n\n    avio_w8(pb, version);\n\n    avio_wb24(pb, flags);\n\n    if (version == 1) {\n\n        avio_wb64(pb, track->time);\n\n        avio_wb64(pb, track->time);\n\n    } else {\n\n        avio_wb32(pb, track->time); /* creation time */\n\n        avio_wb32(pb, track->time); /* modification time */\n\n    }\n\n    avio_wb32(pb, track->track_id); /* track-id */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    if (!track->entry && mov->mode == MODE_ISM)\n\n        (version == 1) ? avio_wb64(pb, UINT64_C(0xffffffffffffffff)) : avio_wb32(pb, 0xffffffff);\n\n    else if (!track->entry)\n\n        (version == 1) ? avio_wb64(pb, 0) : avio_wb32(pb, 0);\n\n    else\n\n        (version == 1) ? avio_wb64(pb, duration) : avio_wb32(pb, duration);\n\n\n\n    avio_wb32(pb, 0); /* reserved */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    avio_wb16(pb, 0); /* layer */\n\n    avio_wb16(pb, group); /* alternate group) */\n\n    /* Volume, only for audio */\n\n    if (track->par->codec_type == AVMEDIA_TYPE_AUDIO)\n\n        avio_wb16(pb, 0x0100);\n\n    else\n\n        avio_wb16(pb, 0);\n\n    avio_wb16(pb, 0); /* reserved */\n\n\n\n    /* Matrix structure */\n\n\n    if (st && st->metadata) {\n\n        AVDictionaryEntry *rot = av_dict_get(st->metadata, \"rotate\", NULL, 0);\n\n        rotation = (rot && rot->value) ? atoi(rot->value) : 0;\n\n    }\n\n\n    if (display_matrix) {\n\n        for (i = 0; i < 9; i++)\n\n            avio_wb32(pb, display_matrix[i]);\n\n\n    } else if (rotation == 90) {\n\n        write_matrix(pb,  0,  1, -1,  0, track->par->height, 0);\n\n    } else if (rotation == 180) {\n\n        write_matrix(pb, -1,  0,  0, -1, track->par->width, track->par->height);\n\n    } else if (rotation == 270) {\n\n        write_matrix(pb,  0, -1,  1,  0, 0, track->par->width);\n\n\n    } else {\n\n        write_matrix(pb,  1,  0,  0,  1, 0, 0);\n\n    }\n\n    /* Track width and height, for visual only */\n\n    if (st && (track->par->codec_type == AVMEDIA_TYPE_VIDEO ||\n\n               track->par->codec_type == AVMEDIA_TYPE_SUBTITLE)) {\n\n        int64_t track_width_1616;\n\n        if (track->mode == MODE_MOV) {\n\n            track_width_1616 = track->par->width * 0x10000ULL;\n\n        } else {\n\n            track_width_1616 = av_rescale(st->sample_aspect_ratio.num,\n\n                                                  track->par->width * 0x10000LL,\n\n                                                  st->sample_aspect_ratio.den);\n\n            if (!track_width_1616 ||\n\n                track->height != track->par->height ||\n\n                track_width_1616 > UINT32_MAX)\n\n                track_width_1616 = track->par->width * 0x10000ULL;\n\n        }\n\n        if (track_width_1616 > UINT32_MAX) {\n\n            av_log(mov->fc, AV_LOG_WARNING, \"track width is too large\\n\");\n\n            track_width_1616 = 0;\n\n        }\n\n        avio_wb32(pb, track_width_1616);\n\n        if (track->height > 0xFFFF) {\n\n            av_log(mov->fc, AV_LOG_WARNING, \"track height is too large\\n\");\n\n            avio_wb32(pb, 0);\n\n        } else\n\n            avio_wb32(pb, track->height * 0x10000U);\n\n    } else {\n\n        avio_wb32(pb, 0);\n\n        avio_wb32(pb, 0);\n\n    }\n\n    return 0x5c;\n\n}", "idx": 4781, "_split": "test", "_hash": "36de87d4550027b30d8320acc6c7fbde"}
{"project": "FFmpeg", "commit_id": "4189fe11ffcbdcd311eb9a3437586a94492c4cde", "target": 1, "func": "static int vobsub_read_seek(AVFormatContext *s, int stream_index,\n\n                            int64_t min_ts, int64_t ts, int64_t max_ts, int flags)\n\n{\n\n    MpegDemuxContext *vobsub = s->priv_data;\n\n\n\n    /* Rescale requested timestamps based on the first stream (timebase is the\n\n     * same for all subtitles stream within a .idx/.sub). Rescaling is done just\n\n     * like in avformat_seek_file(). */\n\n    if (stream_index == -1 && s->nb_streams != 1) {\n\n        int i, ret = 0;\n\n        AVRational time_base = s->streams[0]->time_base;\n\n        ts = av_rescale_q(ts, AV_TIME_BASE_Q, time_base);\n\n        min_ts = av_rescale_rnd(min_ts, time_base.den,\n\n                                time_base.num * (int64_t)AV_TIME_BASE,\n\n                                AV_ROUND_UP   | AV_ROUND_PASS_MINMAX);\n\n        max_ts = av_rescale_rnd(max_ts, time_base.den,\n\n                                time_base.num * (int64_t)AV_TIME_BASE,\n\n                                AV_ROUND_DOWN | AV_ROUND_PASS_MINMAX);\n\n        for (i = 0; i < s->nb_streams; i++) {\n\n            int r = ff_subtitles_queue_seek(&vobsub->q[i], s, stream_index,\n\n                                            min_ts, ts, max_ts, flags);\n\n            if (r < 0)\n\n                ret = r;\n\n        }\n\n        return ret;\n\n    }\n\n\n\n\n\n    return ff_subtitles_queue_seek(&vobsub->q[stream_index], s, stream_index,\n\n                                   min_ts, ts, max_ts, flags);\n\n}", "idx": 4798, "_split": "test", "_hash": "3136dcbbfa85d4237c62a1da04c76c58"}
{"project": "FFmpeg", "commit_id": "c177f2ec4a21d62fdefd925ad69c24a2f9dad303", "target": 0, "func": "static av_cold int aac_encode_init(AVCodecContext *avctx)\n\n{\n\n    AACContext *s = avctx->priv_data;\n\n    int ret = AVERROR(EINVAL);\n\n    AACENC_InfoStruct info = { 0 };\n\n    CHANNEL_MODE mode;\n\n    AACENC_ERROR err;\n\n    int aot = FF_PROFILE_AAC_LOW + 1;\n\n    int sce = 0, cpe = 0;\n\n\n\n    if ((err = aacEncOpen(&s->handle, 0, avctx->channels)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to open the encoder: %s\\n\",\n\n               aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    if (avctx->profile != FF_PROFILE_UNKNOWN)\n\n        aot = avctx->profile + 1;\n\n\n\n    if ((err = aacEncoder_SetParam(s->handle, AACENC_AOT, aot)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to set the AOT %d: %s\\n\",\n\n               aot, aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    if (aot == FF_PROFILE_AAC_ELD + 1 && s->eld_sbr) {\n\n        if ((err = aacEncoder_SetParam(s->handle, AACENC_SBR_MODE,\n\n                                       1)) != AACENC_OK) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unable to enable SBR for ELD: %s\\n\",\n\n                   aac_get_error(err));\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    if ((err = aacEncoder_SetParam(s->handle, AACENC_SAMPLERATE,\n\n                                   avctx->sample_rate)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to set the sample rate %d: %s\\n\",\n\n               avctx->sample_rate, aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    switch (avctx->channels) {\n\n    case 1: mode = MODE_1;       sce = 1; cpe = 0; break;\n\n    case 2: mode = MODE_2;       sce = 0; cpe = 1; break;\n\n    case 3: mode = MODE_1_2;     sce = 1; cpe = 1; break;\n\n    case 4: mode = MODE_1_2_1;   sce = 2; cpe = 1; break;\n\n    case 5: mode = MODE_1_2_2;   sce = 1; cpe = 2; break;\n\n    case 6: mode = MODE_1_2_2_1; sce = 2; cpe = 2; break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Unsupported number of channels %d\\n\", avctx->channels);\n\n        goto error;\n\n    }\n\n\n\n    if ((err = aacEncoder_SetParam(s->handle, AACENC_CHANNELMODE,\n\n                                   mode)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Unable to set channel mode %d: %s\\n\", mode, aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    if ((err = aacEncoder_SetParam(s->handle, AACENC_CHANNELORDER,\n\n                                   1)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Unable to set wav channel order %d: %s\\n\",\n\n               mode, aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    if (avctx->flags & CODEC_FLAG_QSCALE || s->vbr) {\n\n        int mode = s->vbr ? s->vbr : avctx->global_quality;\n\n        if (mode <  1 || mode > 5) {\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"VBR quality %d out of range, should be 1-5\\n\", mode);\n\n            mode = av_clip(mode, 1, 5);\n\n        }\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Note, the VBR setting is unsupported and only works with \"\n\n               \"some parameter combinations\\n\");\n\n        if ((err = aacEncoder_SetParam(s->handle, AACENC_BITRATEMODE,\n\n                                       mode)) != AACENC_OK) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unable to set the VBR bitrate mode %d: %s\\n\",\n\n                   mode, aac_get_error(err));\n\n            goto error;\n\n        }\n\n    } else {\n\n        if (avctx->bit_rate <= 0) {\n\n            if (avctx->profile == FF_PROFILE_AAC_HE_V2) {\n\n                sce = 1;\n\n                cpe = 0;\n\n            }\n\n            avctx->bit_rate = (96*sce + 128*cpe) * avctx->sample_rate / 44;\n\n            if (avctx->profile == FF_PROFILE_AAC_HE ||\n\n                avctx->profile == FF_PROFILE_AAC_HE_V2 ||\n\n                s->eld_sbr)\n\n                avctx->bit_rate /= 2;\n\n        }\n\n        if ((err = aacEncoder_SetParam(s->handle, AACENC_BITRATE,\n\n                                       avctx->bit_rate)) != AACENC_OK) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unable to set the bitrate %d: %s\\n\",\n\n                   avctx->bit_rate, aac_get_error(err));\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    /* Choose bitstream format - if global header is requested, use\n\n     * raw access units, otherwise use ADTS. */\n\n    if ((err = aacEncoder_SetParam(s->handle, AACENC_TRANSMUX,\n\n                                   avctx->flags & CODEC_FLAG_GLOBAL_HEADER ? 0 : s->latm ? 10 : 2)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to set the transmux format: %s\\n\",\n\n               aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    if (s->latm && s->header_period) {\n\n        if ((err = aacEncoder_SetParam(s->handle, AACENC_HEADER_PERIOD,\n\n                                       s->header_period)) != AACENC_OK) {\n\n             av_log(avctx, AV_LOG_ERROR, \"Unable to set header period: %s\\n\",\n\n                    aac_get_error(err));\n\n             goto error;\n\n        }\n\n    }\n\n\n\n    /* If no signaling mode is chosen, use explicit hierarchical signaling\n\n     * if using mp4 mode (raw access units, with global header) and\n\n     * implicit signaling if using ADTS. */\n\n    if (s->signaling < 0)\n\n        s->signaling = avctx->flags & CODEC_FLAG_GLOBAL_HEADER ? 2 : 0;\n\n\n\n    if ((err = aacEncoder_SetParam(s->handle, AACENC_SIGNALING_MODE,\n\n                                   s->signaling)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to set signaling mode %d: %s\\n\",\n\n               s->signaling, aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    if ((err = aacEncoder_SetParam(s->handle, AACENC_AFTERBURNER,\n\n                                   s->afterburner)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to set afterburner to %d: %s\\n\",\n\n               s->afterburner, aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n    if (avctx->cutoff > 0) {\n\n        if (avctx->cutoff < (avctx->sample_rate + 255) >> 8) {\n\n            av_log(avctx, AV_LOG_ERROR, \"cutoff valid range is %d-20000\\n\",\n\n                   (avctx->sample_rate + 255) >> 8);\n\n            goto error;\n\n        }\n\n        if ((err = aacEncoder_SetParam(s->handle, AACENC_BANDWIDTH,\n\n                                       avctx->cutoff)) != AACENC_OK) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unable to set the encoder bandwidth to %d: %s\\n\",\n\n                   avctx->cutoff, aac_get_error(err));\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    if ((err = aacEncEncode(s->handle, NULL, NULL, NULL, NULL)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to initialize the encoder: %s\\n\",\n\n               aac_get_error(err));\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if ((err = aacEncInfo(s->handle, &info)) != AACENC_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to get encoder info: %s\\n\",\n\n               aac_get_error(err));\n\n        goto error;\n\n    }\n\n\n\n#if FF_API_OLD_ENCODE_AUDIO\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n    if (!avctx->coded_frame) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto error;\n\n    }\n\n#endif\n\n    avctx->frame_size = info.frameLength;\n\n    avctx->delay      = info.encoderDelay;\n\n    ff_af_queue_init(avctx, &s->afq);\n\n\n\n    if (avctx->flags & CODEC_FLAG_GLOBAL_HEADER) {\n\n        avctx->extradata_size = info.confSize;\n\n        avctx->extradata      = av_mallocz(avctx->extradata_size +\n\n                                           FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!avctx->extradata) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto error;\n\n        }\n\n\n\n        memcpy(avctx->extradata, info.confBuf, info.confSize);\n\n    }\n\n    return 0;\n\nerror:\n\n    aac_encode_close(avctx);\n\n    return ret;\n\n}\n", "idx": 4800, "_split": "test", "_hash": "79663e703b3f532f13e447509d1a3f4a"}
{"project": "FFmpeg", "commit_id": "24947d4988012f1f0fd467c83418615adc11c3e8", "target": 1, "func": "static int vorbis_floor1_decode(vorbis_context *vc,\n\n                                vorbis_floor_data *vfu, float *vec)\n\n{\n\n    vorbis_floor1 *vf = &vfu->t1;\n\n    GetBitContext *gb = &vc->gb;\n\n    uint16_t range_v[4] = { 256, 128, 86, 64 };\n\n    unsigned range = range_v[vf->multiplier - 1];\n\n    uint16_t floor1_Y[258];\n\n    uint16_t floor1_Y_final[258];\n\n    int floor1_flag[258];\n\n    unsigned class, cdim, cbits, csub, cval, offset, i, j;\n\n    int book, adx, ady, dy, off, predicted, err;\n\n\n\n\n\n    if (!get_bits1(gb)) // silence\n\n        return 1;\n\n\n\n// Read values (or differences) for the floor's points\n\n\n\n    floor1_Y[0] = get_bits(gb, ilog(range - 1));\n\n    floor1_Y[1] = get_bits(gb, ilog(range - 1));\n\n\n\n    av_dlog(NULL, \"floor 0 Y %d floor 1 Y %d \\n\", floor1_Y[0], floor1_Y[1]);\n\n\n\n    offset = 2;\n\n    for (i = 0; i < vf->partitions; ++i) {\n\n        class = vf->partition_class[i];\n\n        cdim   = vf->class_dimensions[class];\n\n        cbits  = vf->class_subclasses[class];\n\n        csub = (1 << cbits) - 1;\n\n        cval = 0;\n\n\n\n        av_dlog(NULL, \"Cbits %u\\n\", cbits);\n\n\n\n        if (cbits) // this reads all subclasses for this partition's class\n\n            cval = get_vlc2(gb, vc->codebooks[vf->class_masterbook[class]].vlc.table,\n\n                            vc->codebooks[vf->class_masterbook[class]].nb_bits, 3);\n\n\n\n        for (j = 0; j < cdim; ++j) {\n\n            book = vf->subclass_books[class][cval & csub];\n\n\n\n            av_dlog(NULL, \"book %d Cbits %u cval %u  bits:%d\\n\",\n\n                    book, cbits, cval, get_bits_count(gb));\n\n\n\n            cval = cval >> cbits;\n\n            if (book > -1) {\n\n                floor1_Y[offset+j] = get_vlc2(gb, vc->codebooks[book].vlc.table,\n\n                vc->codebooks[book].nb_bits, 3);\n\n            } else {\n\n                floor1_Y[offset+j] = 0;\n\n            }\n\n\n\n            av_dlog(NULL, \" floor(%d) = %d \\n\",\n\n                    vf->list[offset+j].x, floor1_Y[offset+j]);\n\n        }\n\n        offset+=cdim;\n\n    }\n\n\n\n// Amplitude calculation from the differences\n\n\n\n    floor1_flag[0] = 1;\n\n    floor1_flag[1] = 1;\n\n    floor1_Y_final[0] = floor1_Y[0];\n\n    floor1_Y_final[1] = floor1_Y[1];\n\n\n\n    for (i = 2; i < vf->x_list_dim; ++i) {\n\n        unsigned val, highroom, lowroom, room, high_neigh_offs, low_neigh_offs;\n\n\n\n        low_neigh_offs  = vf->list[i].low;\n\n        high_neigh_offs = vf->list[i].high;\n\n        dy  = floor1_Y_final[high_neigh_offs] - floor1_Y_final[low_neigh_offs];  // render_point begin\n\n        adx = vf->list[high_neigh_offs].x - vf->list[low_neigh_offs].x;\n\n        ady = FFABS(dy);\n\n        err = ady * (vf->list[i].x - vf->list[low_neigh_offs].x);\n\n        off = err / adx;\n\n        if (dy < 0) {\n\n            predicted = floor1_Y_final[low_neigh_offs] - off;\n\n        } else {\n\n            predicted = floor1_Y_final[low_neigh_offs] + off;\n\n        } // render_point end\n\n\n\n        val = floor1_Y[i];\n\n        highroom = range-predicted;\n\n        lowroom  = predicted;\n\n        if (highroom < lowroom) {\n\n            room = highroom * 2;\n\n        } else {\n\n            room = lowroom * 2;   // SPEC mispelling\n\n        }\n\n        if (val) {\n\n            floor1_flag[low_neigh_offs]  = 1;\n\n            floor1_flag[high_neigh_offs] = 1;\n\n            floor1_flag[i]               = 1;\n\n            if (val >= room) {\n\n                if (highroom > lowroom) {\n\n                    floor1_Y_final[i] = val - lowroom + predicted;\n\n                } else {\n\n                    floor1_Y_final[i] = predicted - val + highroom - 1;\n\n                }\n\n            } else {\n\n                if (val & 1) {\n\n                    floor1_Y_final[i] = predicted - (val + 1) / 2;\n\n                } else {\n\n                    floor1_Y_final[i] = predicted + val / 2;\n\n                }\n\n            }\n\n        } else {\n\n            floor1_flag[i]    = 0;\n\n            floor1_Y_final[i] = predicted;\n\n        }\n\n\n\n        av_dlog(NULL, \" Decoded floor(%d) = %u / val %u\\n\",\n\n                vf->list[i].x, floor1_Y_final[i], val);\n\n    }\n\n\n\n// Curve synth - connect the calculated dots and convert from dB scale FIXME optimize ?\n\n\n\n    ff_vorbis_floor1_render_list(vf->list, vf->x_list_dim, floor1_Y_final, floor1_flag, vf->multiplier, vec, vf->list[1].x);\n\n\n\n    av_dlog(NULL, \" Floor decoded\\n\");\n\n\n\n    return 0;\n\n}\n", "idx": 4801, "_split": "test", "_hash": "0815fca4e9b05ea568115218a8013aa3"}
{"project": "FFmpeg", "commit_id": "11de006babf735aafa3462d43dd2c02bb6ac6e2f", "target": 0, "func": "static int v4l2_read_packet(AVFormatContext *s1, AVPacket *pkt)\n\n{\n\n#if FF_API_CODED_FRAME\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    struct video_data *s = s1->priv_data;\n\n    AVFrame *frame = s1->streams[0]->codec->coded_frame;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n    int res;\n\n\n\n    av_init_packet(pkt);\n\n    if ((res = mmap_read_frame(s1, pkt)) < 0) {\n\n        return res;\n\n    }\n\n\n\n#if FF_API_CODED_FRAME\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    if (frame && s->interlaced) {\n\n        frame->interlaced_frame = 1;\n\n        frame->top_field_first = s->top_field_first;\n\n    }\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    return pkt->size;\n\n}\n", "idx": 4873, "_split": "test", "_hash": "9de25d057871fa748c7a351ef7729f01"}
{"project": "FFmpeg", "commit_id": "955aec3c7c7be39b659197e1ec379a09f2b7c41c", "target": 0, "func": "static int mp3_parse_vbr_tags(AVFormatContext *s, AVStream *st, int64_t base)\n\n{\n\n    uint32_t v, spf;\n\n    MPADecodeHeader c;\n\n    int vbrtag_size = 0;\n\n    MP3DecContext *mp3 = s->priv_data;\n\n\n\n    ffio_init_checksum(s->pb, ff_crcA001_update, 0);\n\n\n\n    v = avio_rb32(s->pb);\n\n    if(ff_mpa_check_header(v) < 0)\n\n      return -1;\n\n\n\n    if (avpriv_mpegaudio_decode_header(&c, v) == 0)\n\n        vbrtag_size = c.frame_size;\n\n    if(c.layer != 3)\n\n        return -1;\n\n\n\n    spf = c.lsf ? 576 : 1152; /* Samples per frame, layer 3 */\n\n\n\n    mp3->frames = 0;\n\n    mp3->size   = 0;\n\n\n\n    mp3_parse_info_tag(s, st, &c, spf);\n\n    mp3_parse_vbri_tag(s, st, base);\n\n\n\n    if (!mp3->frames && !mp3->size)\n\n        return -1;\n\n\n\n    /* Skip the vbr tag frame */\n\n    avio_seek(s->pb, base + vbrtag_size, SEEK_SET);\n\n\n\n    if (mp3->frames)\n\n        st->duration = av_rescale_q(mp3->frames, (AVRational){spf, c.sample_rate},\n\n                                    st->time_base);\n\n    if (mp3->size && mp3->frames && !mp3->is_cbr)\n\n        st->codec->bit_rate = av_rescale(mp3->size, 8 * c.sample_rate, mp3->frames * (int64_t)spf);\n\n\n\n    return 0;\n\n}\n", "idx": 4879, "_split": "test", "_hash": "227ef8878bba0819b76de9d4534d4f72"}
{"project": "FFmpeg", "commit_id": "842b6c14bcfc1c5da1a2d288fd65386eb8c158ad", "target": 0, "func": "static void mpegts_write_pmt(AVFormatContext *s, MpegTSService *service)\n\n{\n\n    MpegTSWrite *ts = s->priv_data;\n\n    uint8_t data[1012], *q, *desc_length_ptr, *program_info_length_ptr;\n\n    int val, stream_type, i;\n\n\n\n    q = data;\n\n    put16(&q, 0xe000 | service->pcr_pid);\n\n\n\n    program_info_length_ptr = q;\n\n    q += 2; /* patched after */\n\n\n\n    /* put program info here */\n\n\n\n    val = 0xf000 | (q - program_info_length_ptr - 2);\n\n    program_info_length_ptr[0] = val >> 8;\n\n    program_info_length_ptr[1] = val;\n\n\n\n    for(i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        MpegTSWriteStream *ts_st = st->priv_data;\n\n        AVDictionaryEntry *lang = av_dict_get(st->metadata, \"language\", NULL,0);\n\n        switch(st->codec->codec_id) {\n\n        case AV_CODEC_ID_MPEG1VIDEO:\n\n        case AV_CODEC_ID_MPEG2VIDEO:\n\n            stream_type = STREAM_TYPE_VIDEO_MPEG2;\n\n            break;\n\n        case AV_CODEC_ID_MPEG4:\n\n            stream_type = STREAM_TYPE_VIDEO_MPEG4;\n\n            break;\n\n        case AV_CODEC_ID_H264:\n\n            stream_type = STREAM_TYPE_VIDEO_H264;\n\n            break;\n\n        case AV_CODEC_ID_CAVS:\n\n            stream_type = STREAM_TYPE_VIDEO_CAVS;\n\n            break;\n\n        case AV_CODEC_ID_DIRAC:\n\n            stream_type = STREAM_TYPE_VIDEO_DIRAC;\n\n            break;\n\n        case AV_CODEC_ID_MP2:\n\n        case AV_CODEC_ID_MP3:\n\n            stream_type = STREAM_TYPE_AUDIO_MPEG1;\n\n            break;\n\n        case AV_CODEC_ID_AAC:\n\n            stream_type = (ts->flags & MPEGTS_FLAG_AAC_LATM) ? STREAM_TYPE_AUDIO_AAC_LATM : STREAM_TYPE_AUDIO_AAC;\n\n            break;\n\n        case AV_CODEC_ID_AAC_LATM:\n\n            stream_type = STREAM_TYPE_AUDIO_AAC_LATM;\n\n            break;\n\n        case AV_CODEC_ID_AC3:\n\n            stream_type = STREAM_TYPE_AUDIO_AC3;\n\n            break;\n\n        default:\n\n            stream_type = STREAM_TYPE_PRIVATE_DATA;\n\n            break;\n\n        }\n\n        *q++ = stream_type;\n\n        put16(&q, 0xe000 | ts_st->pid);\n\n        desc_length_ptr = q;\n\n        q += 2; /* patched after */\n\n\n\n        /* write optional descriptors here */\n\n        switch(st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            if(st->codec->codec_id==AV_CODEC_ID_EAC3){\n\n                *q++=0x7a; // EAC3 descriptor see A038 DVB SI\n\n                *q++=1; // 1 byte, all flags sets to 0\n\n                *q++=0; // omit all fields...\n\n            }\n\n            if(st->codec->codec_id==AV_CODEC_ID_S302M){\n\n                *q++ = 0x05; /* MPEG-2 registration descriptor*/\n\n                *q++ = 4;\n\n                *q++ = 'B';\n\n                *q++ = 'S';\n\n                *q++ = 'S';\n\n                *q++ = 'D';\n\n            }\n\n\n\n            if (lang) {\n\n                char *p;\n\n                char *next = lang->value;\n\n                uint8_t *len_ptr;\n\n\n\n                *q++ = 0x0a; /* ISO 639 language descriptor */\n\n                len_ptr = q++;\n\n                *len_ptr = 0;\n\n\n\n                for (p = lang->value; next && *len_ptr < 255 / 4 * 4; p = next + 1) {\n\n                    next = strchr(p, ',');\n\n                    if (strlen(p) != 3 && (!next || next != p + 3))\n\n                        continue; /* not a 3-letter code */\n\n\n\n                    *q++ = *p++;\n\n                    *q++ = *p++;\n\n                    *q++ = *p++;\n\n\n\n                if (st->disposition & AV_DISPOSITION_CLEAN_EFFECTS)\n\n                    *q++ = 0x01;\n\n                else if (st->disposition & AV_DISPOSITION_HEARING_IMPAIRED)\n\n                    *q++ = 0x02;\n\n                else if (st->disposition & AV_DISPOSITION_VISUAL_IMPAIRED)\n\n                    *q++ = 0x03;\n\n                else\n\n                    *q++ = 0; /* undefined type */\n\n\n\n                    *len_ptr += 4;\n\n                }\n\n\n\n                if (*len_ptr == 0)\n\n                    q -= 2; /* no language codes were written */\n\n            }\n\n            break;\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            {\n\n                const char default_language[] = \"und\";\n\n                const char *language = lang && strlen(lang->value) >= 3 ? lang->value : default_language;\n\n\n\n                if (st->codec->codec_id == AV_CODEC_ID_DVB_SUBTITLE) {\n\n                    uint8_t *len_ptr;\n\n                    int extradata_copied = 0;\n\n\n\n                    *q++ = 0x59; /* subtitling_descriptor */\n\n                    len_ptr = q++;\n\n\n\n                    while (strlen(language) >= 3 && (sizeof(data) - (q - data)) >= 8) { /* 8 bytes per DVB subtitle substream data */\n\n                        *q++ = *language++;\n\n                        *q++ = *language++;\n\n                        *q++ = *language++;\n\n                        /* Skip comma */\n\n                        if (*language != '\\0')\n\n                            language++;\n\n\n\n                        if (st->codec->extradata_size - extradata_copied >= 5) {\n\n                            *q++ = st->codec->extradata[extradata_copied + 4]; /* subtitling_type */\n\n                            memcpy(q, st->codec->extradata + extradata_copied, 4); /* composition_page_id and ancillary_page_id */\n\n                            extradata_copied += 5;\n\n                            q += 4;\n\n                        } else {\n\n                            /* subtitling_type:\n\n                             * 0x10 - normal with no monitor aspect ratio criticality\n\n                             * 0x20 - for the hard of hearing with no monitor aspect ratio criticality */\n\n                            *q++ = (st->disposition & AV_DISPOSITION_HEARING_IMPAIRED) ? 0x20 : 0x10;\n\n                            if ((st->codec->extradata_size == 4) && (extradata_copied == 0)) {\n\n                                /* support of old 4-byte extradata format */\n\n                                memcpy(q, st->codec->extradata, 4); /* composition_page_id and ancillary_page_id */\n\n                                extradata_copied += 4;\n\n                                q += 4;\n\n                            } else {\n\n                                put16(&q, 1); /* composition_page_id */\n\n                                put16(&q, 1); /* ancillary_page_id */\n\n                            }\n\n                        }\n\n                    }\n\n\n\n                    *len_ptr = q - len_ptr - 1;\n\n                } else if (st->codec->codec_id == AV_CODEC_ID_DVB_TELETEXT) {\n\n                    uint8_t *len_ptr = NULL;\n\n                    int extradata_copied = 0;\n\n\n\n                    /* The descriptor tag. teletext_descriptor */\n\n                    *q++ = 0x56;\n\n                    len_ptr = q++;\n\n\n\n                    while (strlen(language) >= 3) {\n\n                        *q++ = *language++;\n\n                        *q++ = *language++;\n\n                        *q++ = *language++;\n\n                        /* Skip comma */\n\n                        if (*language != '\\0')\n\n                            language++;\n\n\n\n                        if (st->codec->extradata_size - 1 > extradata_copied) {\n\n                            memcpy(q, st->codec->extradata + extradata_copied, 2);\n\n                            extradata_copied += 2;\n\n                            q += 2;\n\n                        } else {\n\n                            /* The Teletext descriptor:\n\n                             * teletext_type: This 5-bit field indicates the type of Teletext page indicated. (0x01 Initial Teletext page)\n\n                             * teletext_magazine_number: This is a 3-bit field which identifies the magazine number.\n\n                             * teletext_page_number: This is an 8-bit field giving two 4-bit hex digits identifying the page number. */\n\n                            *q++ = 0x08;\n\n                            *q++ = 0x00;\n\n                        }\n\n                    }\n\n\n\n                    *len_ptr = q - len_ptr - 1;\n\n                 }\n\n            }\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if (stream_type == STREAM_TYPE_VIDEO_DIRAC) {\n\n                *q++ = 0x05; /*MPEG-2 registration descriptor*/\n\n                *q++ = 4;\n\n                *q++ = 'd';\n\n                *q++ = 'r';\n\n                *q++ = 'a';\n\n                *q++ = 'c';\n\n            }\n\n            break;\n\n        case AVMEDIA_TYPE_DATA:\n\n            if (st->codec->codec_id == AV_CODEC_ID_SMPTE_KLV) {\n\n                *q++ = 0x05; /* MPEG-2 registration descriptor */\n\n                *q++ = 4;\n\n                *q++ = 'K';\n\n                *q++ = 'L';\n\n                *q++ = 'V';\n\n                *q++ = 'A';\n\n            }\n\n            break;\n\n        }\n\n\n\n        val = 0xf000 | (q - desc_length_ptr - 2);\n\n        desc_length_ptr[0] = val >> 8;\n\n        desc_length_ptr[1] = val;\n\n    }\n\n    mpegts_write_section1(&service->pmt, PMT_TID, service->sid, ts->tables_version, 0, 0,\n\n                          data, q - data);\n\n}\n", "idx": 4896, "_split": "test", "_hash": "077b1bb649560b355c320528ff2171a9"}
{"project": "FFmpeg", "commit_id": "8eb76217d0137b7adad438f6c923310fbc1fc4c1", "target": 1, "func": "static int ipvideo_decode_block_opcode_0xD(IpvideoContext *s, AVFrame *frame)\n{\n    int y;\n    unsigned char P[2];\n    /* 4-color block encoding: each 4x4 block is a different color */\n    for (y = 0; y < 8; y++) {\n        if (!(y & 3)) {\n            P[0] = bytestream2_get_byte(&s->stream_ptr);\n            P[1] = bytestream2_get_byte(&s->stream_ptr);\n        memset(s->pixel_ptr,     P[0], 4);\n        memset(s->pixel_ptr + 4, P[1], 4);\n        s->pixel_ptr += s->stride;\n    /* report success */\n    return 0;", "idx": 4995, "_split": "test", "_hash": "6932ebb328019cdb145c455d7e431ff7"}
{"project": "FFmpeg", "commit_id": "aefdb735c3df9480c1ca9bcf4a3835bd66271bd1", "target": 0, "func": "static void reverse_matrixing(float *su1, float *su2, int *prev_code,\n\n                              int *curr_code)\n\n{\n\n    int i, nsample, band;\n\n    float mc1_l, mc1_r, mc2_l, mc2_r;\n\n\n\n    for (i = 0, band = 0; band < 4 * 256; band += 256, i++) {\n\n        int s1 = prev_code[i];\n\n        int s2 = curr_code[i];\n\n        nsample = 0;\n\n\n\n        if (s1 != s2) {\n\n            /* Selector value changed, interpolation needed. */\n\n            mc1_l = matrix_coeffs[s1 * 2    ];\n\n            mc1_r = matrix_coeffs[s1 * 2 + 1];\n\n            mc2_l = matrix_coeffs[s2 * 2    ];\n\n            mc2_r = matrix_coeffs[s2 * 2 + 1];\n\n\n\n            /* Interpolation is done over the first eight samples. */\n\n            for (; nsample < 8; nsample++) {\n\n                float c1 = su1[band + nsample];\n\n                float c2 = su2[band + nsample];\n\n                c2 = c1 * INTERPOLATE(mc1_l, mc2_l, nsample) +\n\n                     c2 * INTERPOLATE(mc1_r, mc2_r, nsample);\n\n                su1[band + nsample] = c2;\n\n                su2[band + nsample] = c1 * 2.0 - c2;\n\n            }\n\n        }\n\n\n\n        /* Apply the matrix without interpolation. */\n\n        switch (s2) {\n\n        case 0:     /* M/S decoding */\n\n            for (; nsample < 256; nsample++) {\n\n                float c1 = su1[band + nsample];\n\n                float c2 = su2[band + nsample];\n\n                su1[band + nsample] =  c2       * 2.0;\n\n                su2[band + nsample] = (c1 - c2) * 2.0;\n\n            }\n\n            break;\n\n        case 1:\n\n            for (; nsample < 256; nsample++) {\n\n                float c1 = su1[band + nsample];\n\n                float c2 = su2[band + nsample];\n\n                su1[band + nsample] = (c1 + c2) *  2.0;\n\n                su2[band + nsample] =  c2       * -2.0;\n\n            }\n\n            break;\n\n        case 2:\n\n        case 3:\n\n            for (; nsample < 256; nsample++) {\n\n                float c1 = su1[band + nsample];\n\n                float c2 = su2[band + nsample];\n\n                su1[band + nsample] = c1 + c2;\n\n                su2[band + nsample] = c1 - c2;\n\n            }\n\n            break;\n\n        default:\n\n            assert(0);\n\n        }\n\n    }\n\n}\n", "idx": 5044, "_split": "test", "_hash": "bf24461f3fe090ad4b54ff45d818e634"}
{"project": "FFmpeg", "commit_id": "eedd9148733ff4467c62092ad1c1a26d6125b249", "target": 1, "func": "static int read_part_of_packet(AVFormatContext *s, int64_t *pts,\n\n                               int *len, int *strid, int read_packet) {\n\n    AVIOContext *pb = s->pb;\n\n    PVAContext *pvactx = s->priv_data;\n\n    int syncword, streamid, reserved, flags, length, pts_flag;\n\n    int64_t pva_pts = AV_NOPTS_VALUE, startpos;\n\n    int ret;\n\n\n\nrecover:\n\n    startpos = avio_tell(pb);\n\n\n\n    syncword = avio_rb16(pb);\n\n    streamid = avio_r8(pb);\n\n    avio_r8(pb);               /* counter not used */\n\n    reserved = avio_r8(pb);\n\n    flags    = avio_r8(pb);\n\n    length   = avio_rb16(pb);\n\n\n\n    pts_flag = flags & 0x10;\n\n\n\n    if (syncword != PVA_MAGIC) {\n\n        pva_log(s, AV_LOG_ERROR, \"invalid syncword\\n\");\n\n        return AVERROR(EIO);\n\n    }\n\n    if (streamid != PVA_VIDEO_PAYLOAD && streamid != PVA_AUDIO_PAYLOAD) {\n\n        pva_log(s, AV_LOG_ERROR, \"invalid streamid\\n\");\n\n        return AVERROR(EIO);\n\n    }\n\n    if (reserved != 0x55) {\n\n        pva_log(s, AV_LOG_WARNING, \"expected reserved byte to be 0x55\\n\");\n\n    }\n\n    if (length > PVA_MAX_PAYLOAD_LENGTH) {\n\n        pva_log(s, AV_LOG_ERROR, \"invalid payload length %u\\n\", length);\n\n        return AVERROR(EIO);\n\n    }\n\n\n\n    if (streamid == PVA_VIDEO_PAYLOAD && pts_flag) {\n\n        pva_pts = avio_rb32(pb);\n\n        length -= 4;\n\n    } else if (streamid == PVA_AUDIO_PAYLOAD) {\n\n        /* PVA Audio Packets either start with a signaled PES packet or\n\n         * are a continuation of the previous PES packet. New PES packets\n\n         * always start at the beginning of a PVA Packet, never somewhere in\n\n         * the middle. */\n\n        if (!pvactx->continue_pes) {\n\n            int pes_signal, pes_header_data_length, pes_packet_length,\n\n                pes_flags;\n\n            unsigned char pes_header_data[256];\n\n\n\n            pes_signal             = avio_rb24(pb);\n\n            avio_r8(pb);\n\n            pes_packet_length      = avio_rb16(pb);\n\n            pes_flags              = avio_rb16(pb);\n\n            pes_header_data_length = avio_r8(pb);\n\n\n\n            if (pes_signal != 1 || pes_header_data_length == 0) {\n\n                pva_log(s, AV_LOG_WARNING, \"expected non empty signaled PES packet, \"\n\n                                          \"trying to recover\\n\");\n\n                avio_skip(pb, length - 9);\n\n                if (!read_packet)\n\n                    return AVERROR(EIO);\n\n                goto recover;\n\n            }\n\n\n\n            ret = avio_read(pb, pes_header_data, pes_header_data_length);\n\n            if (ret != pes_header_data_length)\n\n                return ret < 0 ? ret : AVERROR_INVALIDDATA;\n\n            length -= 9 + pes_header_data_length;\n\n\n\n            pes_packet_length -= 3 + pes_header_data_length;\n\n\n\n            pvactx->continue_pes = pes_packet_length;\n\n\n\n            if (pes_flags & 0x80 && (pes_header_data[0] & 0xf0) == 0x20)\n\n                pva_pts = ff_parse_pes_pts(pes_header_data);\n\n        }\n\n\n\n        pvactx->continue_pes -= length;\n\n\n\n        if (pvactx->continue_pes < 0) {\n\n            pva_log(s, AV_LOG_WARNING, \"audio data corruption\\n\");\n\n            pvactx->continue_pes = 0;\n\n        }\n\n    }\n\n\n\n    if (pva_pts != AV_NOPTS_VALUE)\n\n        av_add_index_entry(s->streams[streamid-1], startpos, pva_pts, 0, 0, AVINDEX_KEYFRAME);\n\n\n\n    *pts   = pva_pts;\n\n    *len   = length;\n\n    *strid = streamid;\n\n    return 0;\n\n}\n", "idx": 5060, "_split": "test", "_hash": "ce809bf8efdee40232a440b711fc0acb"}
{"project": "FFmpeg", "commit_id": "60f10e0ad37418cc697765d85b0bc22db70f726a", "target": 1, "func": "static void pred8x8_top_dc_rv40_c(uint8_t *src, int stride){\n\n    int i;\n\n    int dc0;\n\n\n\n    dc0=0;\n\n    for(i=0;i<8; i++)\n\n        dc0+= src[i-stride];\n\n    dc0= 0x01010101*((dc0 + 4)>>3);\n\n\n\n    for(i=0; i<8; i++){\n\n        ((uint32_t*)(src+i*stride))[0]=\n\n        ((uint32_t*)(src+i*stride))[1]= dc0;\n\n    }\n\n}\n", "idx": 5071, "_split": "test", "_hash": "e893ab25289a01d7fc0609c2e74b5ddf"}
{"project": "FFmpeg", "commit_id": "f7cf12b209c3a1ac2d6b797c585b593a5e9a461d", "target": 1, "func": "static int vc1_init_common(VC1Context *v)\n\n{\n\n    static int done = 0;\n\n    int i = 0;\n\n\n\n    v->hrd_rate = v->hrd_buffer = NULL;\n\n\n\n    /* VLC tables */\n\n    if(!done)\n\n    {\n\n        done = 1;\n\n        init_vlc(&ff_vc1_bfraction_vlc, VC1_BFRACTION_VLC_BITS, 23,\n\n                 ff_vc1_bfraction_bits, 1, 1,\n\n                 ff_vc1_bfraction_codes, 1, 1, INIT_VLC_USE_STATIC);\n\n        init_vlc(&ff_vc1_norm2_vlc, VC1_NORM2_VLC_BITS, 4,\n\n                 ff_vc1_norm2_bits, 1, 1,\n\n                 ff_vc1_norm2_codes, 1, 1, INIT_VLC_USE_STATIC);\n\n        init_vlc(&ff_vc1_norm6_vlc, VC1_NORM6_VLC_BITS, 64,\n\n                 ff_vc1_norm6_bits, 1, 1,\n\n                 ff_vc1_norm6_codes, 2, 2, INIT_VLC_USE_STATIC);\n\n        init_vlc(&ff_vc1_imode_vlc, VC1_IMODE_VLC_BITS, 7,\n\n                 ff_vc1_imode_bits, 1, 1,\n\n                 ff_vc1_imode_codes, 1, 1, INIT_VLC_USE_STATIC);\n\n        for (i=0; i<3; i++)\n\n        {\n\n            init_vlc(&ff_vc1_ttmb_vlc[i], VC1_TTMB_VLC_BITS, 16,\n\n                     ff_vc1_ttmb_bits[i], 1, 1,\n\n                     ff_vc1_ttmb_codes[i], 2, 2, INIT_VLC_USE_STATIC);\n\n            init_vlc(&ff_vc1_ttblk_vlc[i], VC1_TTBLK_VLC_BITS, 8,\n\n                     ff_vc1_ttblk_bits[i], 1, 1,\n\n                     ff_vc1_ttblk_codes[i], 1, 1, INIT_VLC_USE_STATIC);\n\n            init_vlc(&ff_vc1_subblkpat_vlc[i], VC1_SUBBLKPAT_VLC_BITS, 15,\n\n                     ff_vc1_subblkpat_bits[i], 1, 1,\n\n                     ff_vc1_subblkpat_codes[i], 1, 1, INIT_VLC_USE_STATIC);\n\n        }\n\n        for(i=0; i<4; i++)\n\n        {\n\n            init_vlc(&ff_vc1_4mv_block_pattern_vlc[i], VC1_4MV_BLOCK_PATTERN_VLC_BITS, 16,\n\n                     ff_vc1_4mv_block_pattern_bits[i], 1, 1,\n\n                     ff_vc1_4mv_block_pattern_codes[i], 1, 1, INIT_VLC_USE_STATIC);\n\n            init_vlc(&ff_vc1_cbpcy_p_vlc[i], VC1_CBPCY_P_VLC_BITS, 64,\n\n                     ff_vc1_cbpcy_p_bits[i], 1, 1,\n\n                     ff_vc1_cbpcy_p_codes[i], 2, 2, INIT_VLC_USE_STATIC);\n\n            init_vlc(&ff_vc1_mv_diff_vlc[i], VC1_MV_DIFF_VLC_BITS, 73,\n\n                     ff_vc1_mv_diff_bits[i], 1, 1,\n\n                     ff_vc1_mv_diff_codes[i], 2, 2, INIT_VLC_USE_STATIC);\n\n        }\n\n        for(i=0; i<8; i++)\n\n            init_vlc(&ff_vc1_ac_coeff_table[i], AC_VLC_BITS, vc1_ac_sizes[i],\n\n                     &vc1_ac_tables[i][0][1], 8, 4,\n\n                     &vc1_ac_tables[i][0][0], 8, 4, INIT_VLC_USE_STATIC);\n\n        init_vlc(&ff_msmp4_mb_i_vlc, MB_INTRA_VLC_BITS, 64,\n\n                 &ff_msmp4_mb_i_table[0][1], 4, 2,\n\n                 &ff_msmp4_mb_i_table[0][0], 4, 2, INIT_VLC_USE_STATIC);\n\n    }\n\n\n\n    /* Other defaults */\n\n    v->pq = -1;\n\n    v->mvrange = 0; /* 7.1.1.18, p80 */\n\n\n\n    return 0;\n\n}\n", "idx": 5138, "_split": "test", "_hash": "b9bbb1fe92ac7b3189d083aab393914e"}
{"project": "FFmpeg", "commit_id": "73e8e8dbf969b9a0bc1591abcfeba474a42e47bc", "target": 1, "func": "int av_read_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    int ret, i;\n    AVStream *st;\n    for(;;){\n        AVPacketList *pktl = s->raw_packet_buffer;\n        if (pktl) {\n            *pkt = pktl->pkt;\n            if(s->streams[pkt->stream_index]->codec->codec_id != CODEC_ID_PROBE ||\n               !s->streams[pkt->stream_index]->probe_packets ||\n               s->raw_packet_buffer_remaining_size < pkt->size){\n                AVProbeData *pd = &s->streams[pkt->stream_index]->probe_data;\n                av_freep(&pd->buf);\n                pd->buf_size = 0;\n                s->raw_packet_buffer = pktl->next;\n                s->raw_packet_buffer_remaining_size += pkt->size;\n                av_free(pktl);\n                return 0;\n        av_init_packet(pkt);\n        ret= s->iformat->read_packet(s, pkt);\n        if (ret < 0) {\n            if (!pktl || ret == AVERROR(EAGAIN))\n                return ret;\n            for (i = 0; i < s->nb_streams; i++)\n                s->streams[i]->probe_packets = 0;\n        st= s->streams[pkt->stream_index];\n        switch(st->codec->codec_type){\n        case AVMEDIA_TYPE_VIDEO:\n            if(s->video_codec_id)   st->codec->codec_id= s->video_codec_id;\n            break;\n        case AVMEDIA_TYPE_AUDIO:\n            if(s->audio_codec_id)   st->codec->codec_id= s->audio_codec_id;\n            break;\n        case AVMEDIA_TYPE_SUBTITLE:\n            if(s->subtitle_codec_id)st->codec->codec_id= s->subtitle_codec_id;\n            break;\n        if(!pktl && (st->codec->codec_id != CODEC_ID_PROBE ||\n                     !st->probe_packets))\n            return ret;\n        add_to_pktbuf(&s->raw_packet_buffer, pkt, &s->raw_packet_buffer_end);\n        s->raw_packet_buffer_remaining_size -= pkt->size;\n        if(st->codec->codec_id == CODEC_ID_PROBE){\n            AVProbeData *pd = &st->probe_data;\n            av_log(s, AV_LOG_DEBUG, \"probing stream %d\\n\", st->index);\n            --st->probe_packets;\n            pd->buf = av_realloc(pd->buf, pd->buf_size+pkt->size+AVPROBE_PADDING_SIZE);\n            memcpy(pd->buf+pd->buf_size, pkt->data, pkt->size);\n            pd->buf_size += pkt->size;\n            memset(pd->buf+pd->buf_size, 0, AVPROBE_PADDING_SIZE);\n            if(av_log2(pd->buf_size) != av_log2(pd->buf_size - pkt->size)){\n                //FIXME we dont reduce score to 0 for the case of running out of buffer space in bytes\n                set_codec_from_probe_data(s, st, pd, st->probe_packets > 0 ? AVPROBE_SCORE_MAX/4 : 0);\n                if(st->codec->codec_id != CODEC_ID_PROBE){\n                    pd->buf_size=0;\n                    av_freep(&pd->buf);\n                    av_log(s, AV_LOG_DEBUG, \"probed stream %d\\n\", st->index);", "idx": 5146, "_split": "test", "_hash": "c2e591130752373505853804cbc374ba"}
{"project": "FFmpeg", "commit_id": "9af6abdc17deb95c9b1f1d9242ba49b8b5e0b016", "target": 1, "func": "static int decodeTonalComponents (GetBitContext *gb, tonal_component *pComponent, int numBands)\n\n{\n\n    int i,j,k,cnt;\n\n    int   components, coding_mode_selector, coding_mode, coded_values_per_component;\n\n    int   sfIndx, coded_values, max_coded_values, quant_step_index, coded_components;\n\n    int   band_flags[4], mantissa[8];\n\n    float  *pCoef;\n\n    float  scalefactor;\n\n    int   component_count = 0;\n\n\n\n    components = get_bits(gb,5);\n\n\n\n    /* no tonal components */\n\n    if (components == 0)\n\n        return 0;\n\n\n\n    coding_mode_selector = get_bits(gb,2);\n\n    if (coding_mode_selector == 2)\n\n\n\n\n    coding_mode = coding_mode_selector & 1;\n\n\n\n    for (i = 0; i < components; i++) {\n\n        for (cnt = 0; cnt <= numBands; cnt++)\n\n            band_flags[cnt] = get_bits1(gb);\n\n\n\n        coded_values_per_component = get_bits(gb,3);\n\n\n\n        quant_step_index = get_bits(gb,3);\n\n        if (quant_step_index <= 1)\n\n\n\n\n        if (coding_mode_selector == 3)\n\n            coding_mode = get_bits1(gb);\n\n\n\n        for (j = 0; j < (numBands + 1) * 4; j++) {\n\n            if (band_flags[j >> 2] == 0)\n\n                continue;\n\n\n\n            coded_components = get_bits(gb,3);\n\n\n\n            for (k=0; k<coded_components; k++) {\n\n                sfIndx = get_bits(gb,6);\n\n\n\n                pComponent[component_count].pos = j * 64 + (get_bits(gb,6));\n\n                max_coded_values = SAMPLES_PER_FRAME - pComponent[component_count].pos;\n\n                coded_values = coded_values_per_component + 1;\n\n                coded_values = FFMIN(max_coded_values,coded_values);\n\n\n\n                scalefactor = ff_atrac_sf_table[sfIndx] * iMaxQuant[quant_step_index];\n\n\n\n                readQuantSpectralCoeffs(gb, quant_step_index, coding_mode, mantissa, coded_values);\n\n\n\n                pComponent[component_count].numCoefs = coded_values;\n\n\n\n                /* inverse quant */\n\n                pCoef = pComponent[component_count].coef;\n\n                for (cnt = 0; cnt < coded_values; cnt++)\n\n                    pCoef[cnt] = mantissa[cnt] * scalefactor;\n\n\n\n                component_count++;\n\n            }\n\n        }\n\n    }\n\n\n\n    return component_count;\n\n}", "idx": 5190, "_split": "test", "_hash": "13164ce4eb9a09d9b1fadfaf4f66de16"}
{"project": "FFmpeg", "commit_id": "77d2ef13a8fa630e5081f14bde3fd20f84c90aec", "target": 1, "func": "static int matroska_decode_buffer(uint8_t** buf, int* buf_size,\n\n                                  MatroskaTrack *track)\n\n{\n\n    MatroskaTrackEncoding *encodings = track->encodings.elem;\n\n    uint8_t* data = *buf;\n\n    int isize = *buf_size;\n\n    uint8_t* pkt_data = NULL;\n\n    int pkt_size = isize;\n\n    int result = 0;\n\n    int olen;\n\n\n\n    if (pkt_size >= 10000000)\n\n        return -1;\n\n\n\n    switch (encodings[0].compression.algo) {\n\n    case MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP:\n\n        return encodings[0].compression.settings.size;\n\n    case MATROSKA_TRACK_ENCODING_COMP_LZO:\n\n        do {\n\n            olen = pkt_size *= 3;\n\n            pkt_data = av_realloc(pkt_data, pkt_size+AV_LZO_OUTPUT_PADDING);\n\n            result = av_lzo1x_decode(pkt_data, &olen, data, &isize);\n\n        } while (result==AV_LZO_OUTPUT_FULL && pkt_size<10000000);\n\n        if (result)\n\n            goto failed;\n\n        pkt_size -= olen;\n\n        break;\n\n#if CONFIG_ZLIB\n\n    case MATROSKA_TRACK_ENCODING_COMP_ZLIB: {\n\n        z_stream zstream = {0};\n\n        if (inflateInit(&zstream) != Z_OK)\n\n            return -1;\n\n        zstream.next_in = data;\n\n        zstream.avail_in = isize;\n\n        do {\n\n            pkt_size *= 3;\n\n            pkt_data = av_realloc(pkt_data, pkt_size);\n\n            zstream.avail_out = pkt_size - zstream.total_out;\n\n            zstream.next_out = pkt_data + zstream.total_out;\n\n            result = inflate(&zstream, Z_NO_FLUSH);\n\n        } while (result==Z_OK && pkt_size<10000000);\n\n        pkt_size = zstream.total_out;\n\n        inflateEnd(&zstream);\n\n        if (result != Z_STREAM_END)\n\n            goto failed;\n\n        break;\n\n    }\n\n#endif\n\n#if CONFIG_BZLIB\n\n    case MATROSKA_TRACK_ENCODING_COMP_BZLIB: {\n\n        bz_stream bzstream = {0};\n\n        if (BZ2_bzDecompressInit(&bzstream, 0, 0) != BZ_OK)\n\n            return -1;\n\n        bzstream.next_in = data;\n\n        bzstream.avail_in = isize;\n\n        do {\n\n            pkt_size *= 3;\n\n            pkt_data = av_realloc(pkt_data, pkt_size);\n\n            bzstream.avail_out = pkt_size - bzstream.total_out_lo32;\n\n            bzstream.next_out = pkt_data + bzstream.total_out_lo32;\n\n            result = BZ2_bzDecompress(&bzstream);\n\n        } while (result==BZ_OK && pkt_size<10000000);\n\n        pkt_size = bzstream.total_out_lo32;\n\n        BZ2_bzDecompressEnd(&bzstream);\n\n        if (result != BZ_STREAM_END)\n\n            goto failed;\n\n        break;\n\n    }\n\n#endif\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    *buf = pkt_data;\n\n    *buf_size = pkt_size;\n\n    return 0;\n\n failed:\n\n    av_free(pkt_data);\n\n    return -1;\n\n}\n", "idx": 5277, "_split": "test", "_hash": "b9d03f7cf9cb3dc59e0c7ac73e68b164"}
{"project": "FFmpeg", "commit_id": "63b1866ae1e19ff0d694746a84e2eac859cda462", "target": 0, "func": "static void ac3_extract_exponents_c(uint8_t *exp, int32_t *coef, int nb_coefs)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < nb_coefs; i++) {\n\n        int e;\n\n        int v = abs(coef[i]);\n\n        if (v == 0)\n\n            e = 24;\n\n        else {\n\n            e = 23 - av_log2(v);\n\n            if (e >= 24) {\n\n                e = 24;\n\n                coef[i] = 0;\n\n            }\n\n            av_assert2(e >= 0);\n\n        }\n\n        exp[i] = e;\n\n    }\n\n}\n", "idx": 5281, "_split": "test", "_hash": "82d92d9ebe3b1ceaef2618bc55bc273c"}
{"project": "FFmpeg", "commit_id": "428098165de4c3edfe42c1b7f00627d287015863", "target": 1, "func": "SwsFunc yuv2rgb_get_func_ptr (SwsContext *c)\n\n{\n\n#if defined(HAVE_MMX2) || defined(HAVE_MMX)\n\n    if(c->flags & SWS_CPU_CAPS_MMX2){\n\n\tswitch(c->dstFormat){\n\n\tcase PIX_FMT_RGB32: return yuv420_rgb32_MMX2;\n\n\tcase PIX_FMT_BGR24: return yuv420_rgb24_MMX2;\n\n\tcase PIX_FMT_BGR565: return yuv420_rgb16_MMX2;\n\n\tcase PIX_FMT_BGR555: return yuv420_rgb15_MMX2;\n\n\t}\n\n    }\n\n    if(c->flags & SWS_CPU_CAPS_MMX){\n\n\tswitch(c->dstFormat){\n\n\tcase PIX_FMT_RGB32: return yuv420_rgb32_MMX;\n\n\tcase PIX_FMT_BGR24: return yuv420_rgb24_MMX;\n\n\tcase PIX_FMT_BGR565: return yuv420_rgb16_MMX;\n\n\tcase PIX_FMT_BGR555: return yuv420_rgb15_MMX;\n\n\t}\n\n    }\n\n#endif\n\n#ifdef HAVE_MLIB\n\n    {\n\n\tSwsFunc t= yuv2rgb_init_mlib(c);\n\n\tif(t) return t;\n\n    }\n\n#endif\n\n#ifdef HAVE_ALTIVEC\n\n    if (c->flags & SWS_CPU_CAPS_ALTIVEC)\n\n    {\n\n\tSwsFunc t = yuv2rgb_init_altivec(c);\n\n\tif(t) return t;\n\n    }\n\n#endif\n\n\n\n    av_log(c, AV_LOG_WARNING, \"No accelerated colorspace conversion found\\n\");\n\n\n\n    switch(c->dstFormat){\n\n    case PIX_FMT_BGR32:\n\n    case PIX_FMT_RGB32: return yuv2rgb_c_32;\n\n    case PIX_FMT_RGB24: return yuv2rgb_c_24_rgb;\n\n    case PIX_FMT_BGR24: return yuv2rgb_c_24_bgr;\n\n    case PIX_FMT_RGB565:\n\n    case PIX_FMT_BGR565:\n\n    case PIX_FMT_RGB555:\n\n    case PIX_FMT_BGR555: return yuv2rgb_c_16;\n\n    case PIX_FMT_RGB8:\n\n    case PIX_FMT_BGR8:  return yuv2rgb_c_8_ordered_dither;\n\n    case PIX_FMT_RGB4:\n\n    case PIX_FMT_BGR4:  return yuv2rgb_c_4_ordered_dither;\n\n    case PIX_FMT_RGB4_BYTE:\n\n    case PIX_FMT_BGR4_BYTE:  return yuv2rgb_c_4b_ordered_dither;\n\n    case PIX_FMT_MONOBLACK:  return yuv2rgb_c_1_ordered_dither;\n\n    default:\n\n    \tassert(0);\n\n    }\n\n    return NULL;\n\n}\n", "idx": 5308, "_split": "test", "_hash": "4b14d73df51b06819413839d59e8c185"}
{"project": "FFmpeg", "commit_id": "7cc8d616aab68ba5534e5a74214786ad08aac5ce", "target": 1, "func": "uint8_t ff_mlp_calculate_parity(const uint8_t *buf, unsigned int buf_size)\n\n{\n\n    uint32_t scratch = 0;\n\n    const uint8_t *buf_end = buf + buf_size;\n\n\n\n\n\n    for (; buf < buf_end - 3; buf += 4)\n\n        scratch ^= *((const uint32_t*)buf);\n\n\n\n    scratch = xor_32_to_8(scratch);\n\n\n\n    for (; buf < buf_end; buf++)\n\n\n\n\n    return scratch;\n\n}", "idx": 5327, "_split": "test", "_hash": "2a18d2f3221f5e41e46710d1f00b7beb"}
{"project": "FFmpeg", "commit_id": "f354f30836a3148275ce60d19bbc581310249ad2", "target": 0, "func": "void ff_er_frame_start(ERContext *s)\n\n{\n\n    if (!s->avctx->err_recognition)\n\n        return;\n\n\n\n    memset(s->error_status_table, ER_MB_ERROR | VP_START | ER_MB_END,\n\n           s->mb_stride * s->mb_height * sizeof(uint8_t));\n\n    s->error_count    = 3 * s->mb_num;\n\n    s->error_occurred = 0;\n\n}\n", "idx": 5353, "_split": "test", "_hash": "a4bd58e6bf57496bb32a777e1cb3d0d0"}
{"project": "FFmpeg", "commit_id": "f98c9fb27de84dc4f6123537b754eb2fe1a80c02", "target": 0, "func": "av_cold int MPV_common_init(MpegEncContext *s)\n\n{\n\n    int y_size, c_size, yc_size, i, mb_array_size, mv_table_size, x, y, threads;\n\n\n\n    if(s->codec_id == CODEC_ID_MPEG2VIDEO && !s->progressive_sequence)\n\n        s->mb_height = (s->height + 31) / 32 * 2;\n\n    else if (s->codec_id != CODEC_ID_H264)\n\n        s->mb_height = (s->height + 15) / 16;\n\n\n\n    if(s->avctx->pix_fmt == PIX_FMT_NONE){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"decoding to PIX_FMT_NONE is not supported.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if((s->encoding || (s->avctx->active_thread_type & FF_THREAD_SLICE)) &&\n\n       (s->avctx->thread_count > MAX_THREADS || (s->avctx->thread_count > s->mb_height && s->mb_height))){\n\n        av_log(s->avctx, AV_LOG_ERROR, \"too many threads\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if((s->width || s->height) && av_image_check_size(s->width, s->height, 0, s->avctx))\n\n        return -1;\n\n\n\n    dsputil_init(&s->dsp, s->avctx);\n\n    ff_dct_common_init(s);\n\n\n\n    s->flags= s->avctx->flags;\n\n    s->flags2= s->avctx->flags2;\n\n\n\n    if (s->width && s->height) {\n\n        s->mb_width  = (s->width  + 15) / 16;\n\n        s->mb_stride = s->mb_width + 1;\n\n        s->b8_stride = s->mb_width*2 + 1;\n\n        s->b4_stride = s->mb_width*4 + 1;\n\n        mb_array_size= s->mb_height * s->mb_stride;\n\n        mv_table_size= (s->mb_height+2) * s->mb_stride + 1;\n\n\n\n        /* set chroma shifts */\n\n        avcodec_get_chroma_sub_sample(s->avctx->pix_fmt,&(s->chroma_x_shift),\n\n                                      &(s->chroma_y_shift) );\n\n\n\n        /* set default edge pos, will be overriden in decode_header if needed */\n\n        s->h_edge_pos= s->mb_width*16;\n\n        s->v_edge_pos= s->mb_height*16;\n\n\n\n        s->mb_num = s->mb_width * s->mb_height;\n\n\n\n        s->block_wrap[0]=\n\n        s->block_wrap[1]=\n\n        s->block_wrap[2]=\n\n        s->block_wrap[3]= s->b8_stride;\n\n        s->block_wrap[4]=\n\n        s->block_wrap[5]= s->mb_stride;\n\n\n\n        y_size = s->b8_stride * (2 * s->mb_height + 1);\n\n        c_size = s->mb_stride * (s->mb_height + 1);\n\n        yc_size = y_size + 2 * c_size;\n\n\n\n        /* convert fourcc to upper case */\n\n        s->codec_tag = ff_toupper4(s->avctx->codec_tag);\n\n\n\n        s->stream_codec_tag = ff_toupper4(s->avctx->stream_codec_tag);\n\n\n\n        s->avctx->coded_frame= (AVFrame*)&s->current_picture;\n\n\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->mb_index2xy, (s->mb_num+1)*sizeof(int), fail) //error ressilience code looks cleaner with this\n\n        for(y=0; y<s->mb_height; y++){\n\n            for(x=0; x<s->mb_width; x++){\n\n                s->mb_index2xy[ x + y*s->mb_width ] = x + y*s->mb_stride;\n\n            }\n\n        }\n\n        s->mb_index2xy[ s->mb_height*s->mb_width ] = (s->mb_height-1)*s->mb_stride + s->mb_width; //FIXME really needed?\n\n\n\n        if (s->encoding) {\n\n            /* Allocate MV tables */\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->p_mv_table_base            , mv_table_size * 2 * sizeof(int16_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->b_forw_mv_table_base       , mv_table_size * 2 * sizeof(int16_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->b_back_mv_table_base       , mv_table_size * 2 * sizeof(int16_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->b_bidir_forw_mv_table_base , mv_table_size * 2 * sizeof(int16_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->b_bidir_back_mv_table_base , mv_table_size * 2 * sizeof(int16_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->b_direct_mv_table_base     , mv_table_size * 2 * sizeof(int16_t), fail)\n\n            s->p_mv_table           = s->p_mv_table_base            + s->mb_stride + 1;\n\n            s->b_forw_mv_table      = s->b_forw_mv_table_base       + s->mb_stride + 1;\n\n            s->b_back_mv_table      = s->b_back_mv_table_base       + s->mb_stride + 1;\n\n            s->b_bidir_forw_mv_table= s->b_bidir_forw_mv_table_base + s->mb_stride + 1;\n\n            s->b_bidir_back_mv_table= s->b_bidir_back_mv_table_base + s->mb_stride + 1;\n\n            s->b_direct_mv_table    = s->b_direct_mv_table_base     + s->mb_stride + 1;\n\n\n\n            if(s->msmpeg4_version){\n\n                FF_ALLOCZ_OR_GOTO(s->avctx, s->ac_stats, 2*2*(MAX_LEVEL+1)*(MAX_RUN+1)*2*sizeof(int), fail);\n\n            }\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->avctx->stats_out, 256, fail);\n\n\n\n            /* Allocate MB type table */\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->mb_type  , mb_array_size * sizeof(uint16_t), fail) //needed for encoding\n\n\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->lambda_table, mb_array_size * sizeof(int), fail)\n\n\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->q_intra_matrix  , 64*32   * sizeof(int), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->q_inter_matrix  , 64*32   * sizeof(int), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->q_intra_matrix16, 64*32*2 * sizeof(uint16_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->q_inter_matrix16, 64*32*2 * sizeof(uint16_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->input_picture, MAX_PICTURE_COUNT * sizeof(Picture*), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->reordered_input_picture, MAX_PICTURE_COUNT * sizeof(Picture*), fail)\n\n\n\n            if(s->avctx->noise_reduction){\n\n                FF_ALLOCZ_OR_GOTO(s->avctx, s->dct_offset, 2 * 64 * sizeof(uint16_t), fail)\n\n            }\n\n        }\n\n    }\n\n\n\n    s->picture_count = MAX_PICTURE_COUNT * FFMAX(1, s->avctx->thread_count);\n\n    FF_ALLOCZ_OR_GOTO(s->avctx, s->picture, s->picture_count * sizeof(Picture), fail)\n\n    for(i = 0; i < s->picture_count; i++) {\n\n        avcodec_get_frame_defaults((AVFrame *)&s->picture[i]);\n\n    }\n\n\n\n    if (s->width && s->height) {\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->error_status_table, mb_array_size*sizeof(uint8_t), fail)\n\n\n\n        if(s->codec_id==CODEC_ID_MPEG4 || (s->flags & CODEC_FLAG_INTERLACED_ME)){\n\n            /* interlaced direct mode decoding tables */\n\n            for(i=0; i<2; i++){\n\n                int j, k;\n\n                for(j=0; j<2; j++){\n\n                    for(k=0; k<2; k++){\n\n                        FF_ALLOCZ_OR_GOTO(s->avctx,    s->b_field_mv_table_base[i][j][k], mv_table_size * 2 * sizeof(int16_t), fail)\n\n                        s->b_field_mv_table[i][j][k] = s->b_field_mv_table_base[i][j][k] + s->mb_stride + 1;\n\n                    }\n\n                    FF_ALLOCZ_OR_GOTO(s->avctx, s->b_field_select_table [i][j], mb_array_size * 2 * sizeof(uint8_t), fail)\n\n                    FF_ALLOCZ_OR_GOTO(s->avctx, s->p_field_mv_table_base[i][j], mv_table_size * 2 * sizeof(int16_t), fail)\n\n                    s->p_field_mv_table[i][j] = s->p_field_mv_table_base[i][j]+ s->mb_stride + 1;\n\n                }\n\n                FF_ALLOCZ_OR_GOTO(s->avctx, s->p_field_select_table[i], mb_array_size * 2 * sizeof(uint8_t), fail)\n\n            }\n\n        }\n\n        if (s->out_format == FMT_H263) {\n\n            /* cbp values */\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->coded_block_base, y_size, fail);\n\n            s->coded_block= s->coded_block_base + s->b8_stride + 1;\n\n\n\n            /* cbp, ac_pred, pred_dir */\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->cbp_table     , mb_array_size * sizeof(uint8_t), fail)\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->pred_dir_table, mb_array_size * sizeof(uint8_t), fail)\n\n        }\n\n\n\n        if (s->h263_pred || s->h263_plus || !s->encoding) {\n\n            /* dc values */\n\n            //MN: we need these for error resilience of intra-frames\n\n            FF_ALLOCZ_OR_GOTO(s->avctx, s->dc_val_base, yc_size * sizeof(int16_t), fail);\n\n            s->dc_val[0] = s->dc_val_base + s->b8_stride + 1;\n\n            s->dc_val[1] = s->dc_val_base + y_size + s->mb_stride + 1;\n\n            s->dc_val[2] = s->dc_val[1] + c_size;\n\n            for(i=0;i<yc_size;i++)\n\n                s->dc_val_base[i] = 1024;\n\n        }\n\n\n\n        /* which mb is a intra block */\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->mbintra_table, mb_array_size, fail);\n\n        memset(s->mbintra_table, 1, mb_array_size);\n\n\n\n        /* init macroblock skip table */\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->mbskip_table, mb_array_size+2, fail);\n\n        //Note the +1 is for a quicker mpeg4 slice_end detection\n\n        FF_ALLOCZ_OR_GOTO(s->avctx, s->prev_pict_types, PREV_PICT_TYPES_BUFFER_SIZE, fail);\n\n\n\n        s->parse_context.state= -1;\n\n        if((s->avctx->debug&(FF_DEBUG_VIS_QP|FF_DEBUG_VIS_MB_TYPE)) || (s->avctx->debug_mv)){\n\n            s->visualization_buffer[0] = av_malloc((s->mb_width*16 + 2*EDGE_WIDTH) * s->mb_height*16 + 2*EDGE_WIDTH);\n\n            s->visualization_buffer[1] = av_malloc((s->mb_width*16 + 2*EDGE_WIDTH) * s->mb_height*16 + 2*EDGE_WIDTH);\n\n            s->visualization_buffer[2] = av_malloc((s->mb_width*16 + 2*EDGE_WIDTH) * s->mb_height*16 + 2*EDGE_WIDTH);\n\n        }\n\n    }\n\n\n\n    s->context_initialized = 1;\n\n    s->thread_context[0]= s;\n\n\n\n    if (s->width && s->height) {\n\n    if (s->encoding || (HAVE_THREADS && s->avctx->active_thread_type&FF_THREAD_SLICE)) {\n\n        threads = s->avctx->thread_count;\n\n\n\n        for(i=1; i<threads; i++){\n\n            s->thread_context[i]= av_malloc(sizeof(MpegEncContext));\n\n            memcpy(s->thread_context[i], s, sizeof(MpegEncContext));\n\n        }\n\n\n\n        for(i=0; i<threads; i++){\n\n            if(init_duplicate_context(s->thread_context[i], s) < 0)\n\n                goto fail;\n\n            s->thread_context[i]->start_mb_y= (s->mb_height*(i  ) + s->avctx->thread_count/2) / s->avctx->thread_count;\n\n            s->thread_context[i]->end_mb_y  = (s->mb_height*(i+1) + s->avctx->thread_count/2) / s->avctx->thread_count;\n\n        }\n\n    } else {\n\n        if(init_duplicate_context(s, s) < 0) goto fail;\n\n        s->start_mb_y = 0;\n\n        s->end_mb_y   = s->mb_height;\n\n    }\n\n    }\n\n\n\n    return 0;\n\n fail:\n\n    MPV_common_end(s);\n\n    return -1;\n\n}\n", "idx": 5356, "_split": "test", "_hash": "10c99a818a2eb7e8a51175d1bdce4c70"}
{"project": "FFmpeg", "commit_id": "03847eb8259291b4ff1bd840bd779d0699d71f96", "target": 0, "func": "int av_probe_input_buffer(AVIOContext *pb, AVInputFormat **fmt,\n\n                          const char *filename, void *logctx,\n\n                          unsigned int offset, unsigned int max_probe_size)\n\n{\n\n    AVProbeData pd = { filename ? filename : \"\", NULL, -offset };\n\n    unsigned char *buf = NULL;\n\n    int ret = 0, probe_size;\n\n\n\n    if (!max_probe_size) {\n\n        max_probe_size = PROBE_BUF_MAX;\n\n    } else if (max_probe_size > PROBE_BUF_MAX) {\n\n        max_probe_size = PROBE_BUF_MAX;\n\n    } else if (max_probe_size < PROBE_BUF_MIN) {\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (offset >= max_probe_size) {\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    for(probe_size= PROBE_BUF_MIN; probe_size<=max_probe_size && !*fmt;\n\n        probe_size = FFMIN(probe_size<<1, FFMAX(max_probe_size, probe_size+1))) {\n\n        int score = probe_size < max_probe_size ? AVPROBE_SCORE_RETRY : 0;\n\n        int buf_offset = (probe_size == PROBE_BUF_MIN) ? 0 : probe_size>>1;\n\n        void *buftmp;\n\n\n\n        if (probe_size < offset) {\n\n            continue;\n\n        }\n\n\n\n        /* read probe data */\n\n        buftmp = av_realloc(buf, probe_size + AVPROBE_PADDING_SIZE);\n\n        if(!buftmp){\n\n            av_free(buf);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        buf=buftmp;\n\n        if ((ret = avio_read(pb, buf + buf_offset, probe_size - buf_offset)) < 0) {\n\n            /* fail if error was not end of file, otherwise, lower score */\n\n            if (ret != AVERROR_EOF) {\n\n                av_free(buf);\n\n                return ret;\n\n            }\n\n            score = 0;\n\n            ret = 0;            /* error was end of file, nothing read */\n\n        }\n\n        pd.buf_size += ret;\n\n        pd.buf = &buf[offset];\n\n\n\n        memset(pd.buf + pd.buf_size, 0, AVPROBE_PADDING_SIZE);\n\n\n\n        /* guess file format */\n\n        *fmt = av_probe_input_format2(&pd, 1, &score);\n\n        if(*fmt){\n\n            if(score <= AVPROBE_SCORE_RETRY){ //this can only be true in the last iteration\n\n                av_log(logctx, AV_LOG_WARNING, \"Format %s detected only with low score of %d, misdetection possible!\\n\", (*fmt)->name, score);\n\n            }else\n\n                av_log(logctx, AV_LOG_DEBUG, \"Format %s probed with size=%d and score=%d\\n\", (*fmt)->name, probe_size, score);\n\n        }\n\n    }\n\n\n\n    if (!*fmt) {\n\n        av_free(buf);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* rewind. reuse probe buffer to avoid seeking */\n\n    ret = ffio_rewind_with_probe_data(pb, &buf, pd.buf_size);\n\n\n\n    return ret;\n\n}\n", "idx": 5357, "_split": "test", "_hash": "31526c8926a02a519e6070abc2057f11"}
{"project": "FFmpeg", "commit_id": "fc5a905a6d0c76d9fb8d838ac83f6219a7a5e20f", "target": 0, "func": "static void start_children(FFStream *feed)\n\n{\n\n    if (no_launch)\n\n        return;\n\n\n\n    for (; feed; feed = feed->next) {\n\n        if (feed->child_argv && !feed->pid) {\n\n            feed->pid_start = time(0);\n\n\n\n            feed->pid = fork();\n\n\n\n            if (feed->pid < 0) {\n\n                http_log(\"Unable to create children\\n\");\n\n                exit(1);\n\n            }\n\n            if (!feed->pid) {\n\n                /* In child */\n\n                char pathname[1024];\n\n                char *slash;\n\n                int i;\n\n\n\n                av_strlcpy(pathname, my_program_name, sizeof(pathname));\n\n\n\n                slash = strrchr(pathname, '/');\n\n                if (!slash)\n\n                    slash = pathname;\n\n                else\n\n                    slash++;\n\n                strcpy(slash, \"ffmpeg\");\n\n\n\n                http_log(\"Launch command line: \");\n\n                http_log(\"%s \", pathname);\n\n                for (i = 1; feed->child_argv[i] && feed->child_argv[i][0]; i++)\n\n                    http_log(\"%s \", feed->child_argv[i]);\n\n                http_log(\"\\n\");\n\n\n\n                for (i = 3; i < 256; i++)\n\n                    close(i);\n\n\n\n                if (!ffserver_debug) {\n\n                    i = open(\"/dev/null\", O_RDWR);\n\n                    if (i != -1) {\n\n                        dup2(i, 0);\n\n                        dup2(i, 1);\n\n                        dup2(i, 2);\n\n                        close(i);\n\n                    }\n\n                }\n\n\n\n                /* This is needed to make relative pathnames work */\n\n                chdir(my_program_dir);\n\n\n\n                signal(SIGPIPE, SIG_DFL);\n\n\n\n                execvp(pathname, feed->child_argv);\n\n\n\n                _exit(1);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 5416, "_split": "test", "_hash": "b2f89d1014b9e8eda4b138ede5e429f3"}
{"project": "FFmpeg", "commit_id": "8adff79b6d30d1ae2cb9cf906e1d7fcd759cd638", "target": 1, "func": "static int mov_seek_fragment(AVFormatContext *s, AVStream *st, int64_t timestamp)\n\n{\n\n    MOVContext *mov = s->priv_data;\n\n    int i, j;\n\n\n\n    if (!mov->fragment_index_complete)\n\n        return 0;\n\n\n\n    for (i = 0; i < mov->fragment_index_count; i++) {\n\n        if (mov->fragment_index_data[i]->track_id == st->id) {\n\n            MOVFragmentIndex *index = index = mov->fragment_index_data[i];\n\n            for (j = index->item_count - 1; j >= 0; j--) {\n\n                if (index->items[j].time <= timestamp) {\n\n                    if (index->items[j].headers_read)\n\n                        return 0;\n\n\n\n                    return mov_switch_root(s, index->items[j].moof_offset);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 5429, "_split": "test", "_hash": "6fecb28694ef7d556810f431d5d604ee"}
{"project": "FFmpeg", "commit_id": "39bb30f6640fe1faf4bbc779a79786028febc95d", "target": 1, "func": "static int mxf_read_track(MXFTrack *track, ByteIOContext *pb, int tag)\n\n{\n\n    switch(tag) {\n\n    case 0x4801:\n\n        track->track_id = get_be32(pb);\n\n        break;\n\n    case 0x4804:\n\n        get_buffer(pb, track->track_number, 4);\n\n        break;\n\n    case 0x4B01:\n\n        track->edit_rate.den = get_be32(pb);\n\n        track->edit_rate.num = get_be32(pb);\n\n        break;\n\n    case 0x4803:\n\n        get_buffer(pb, track->sequence_ref, 16);\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 5430, "_split": "test", "_hash": "65d8666f03a78a323ff5ec58c14e7bf4"}
{"project": "FFmpeg", "commit_id": "e947b75b1c76ef6793209c2c445b8c224a28717a", "target": 1, "func": "int ff_wms_parse_sdp_a_line(AVFormatContext *s, const char *p)\n\n{\n\n    int ret = 0;\n\n    if (av_strstart(p, \"pgmpu:data:application/vnd.ms.wms-hdr.asfv1;base64,\", &p)) {\n\n        AVIOContext pb;\n\n        RTSPState *rt = s->priv_data;\n\n        AVDictionary *opts = NULL;\n\n        int len = strlen(p) * 6 / 8;\n\n        char *buf = av_mallocz(len);\n\n        AVInputFormat *iformat;\n\n\n\n        if (!buf)\n\n            return AVERROR(ENOMEM);\n\n        av_base64_decode(buf, p, len);\n\n\n\n        if (rtp_asf_fix_header(buf, len) < 0)\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"Failed to fix invalid RTSP-MS/ASF min_pktsize\\n\");\n\n        init_packetizer(&pb, buf, len);\n\n        if (rt->asf_ctx) {\n\n            avformat_close_input(&rt->asf_ctx);\n\n        }\n\n\n\n        if (!(iformat = av_find_input_format(\"asf\")))\n\n            return AVERROR_DEMUXER_NOT_FOUND;\n\n\n\n        rt->asf_ctx = avformat_alloc_context();\n\n        if (!rt->asf_ctx) {\n\n            av_free(buf);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        rt->asf_ctx->pb      = &pb;\n\n        av_dict_set(&opts, \"no_resync_search\", \"1\", 0);\n\n\n\n        if ((ret = ff_copy_whiteblacklists(rt->asf_ctx, s)) < 0) {\n\n            av_dict_free(&opts);\n\n            return ret;\n\n        }\n\n\n\n        ret = avformat_open_input(&rt->asf_ctx, \"\", iformat, &opts);\n\n        av_dict_free(&opts);\n\n        if (ret < 0) {\n\n            av_free(buf);\n\n            return ret;\n\n        }\n\n        av_dict_copy(&s->metadata, rt->asf_ctx->metadata, 0);\n\n        rt->asf_pb_pos = avio_tell(&pb);\n\n        av_free(buf);\n\n        rt->asf_ctx->pb = NULL;\n\n    }\n\n    return ret;\n\n}\n", "idx": 5437, "_split": "test", "_hash": "783bb79335ff281ef8156ac4130a8a7f"}
{"project": "FFmpeg", "commit_id": "9a3f10695a011861dcf5a649e3e72580b1a4eed4", "target": 1, "func": "static int ra144_encode_frame(AVCodecContext *avctx, uint8_t *frame,\n\n                              int buf_size, void *data)\n\n{\n\n    static const uint8_t sizes[LPC_ORDER] = {64, 32, 32, 16, 16, 8, 8, 8, 8, 4};\n\n    static const uint8_t bit_sizes[LPC_ORDER] = {6, 5, 5, 4, 4, 3, 3, 3, 3, 2};\n\n    RA144Context *ractx;\n\n    PutBitContext pb;\n\n    int32_t lpc_data[NBLOCKS * BLOCKSIZE];\n\n    int32_t lpc_coefs[LPC_ORDER][MAX_LPC_ORDER];\n\n    int shift[LPC_ORDER];\n\n    int16_t block_coefs[NBLOCKS][LPC_ORDER];\n\n    int lpc_refl[LPC_ORDER];    /**< reflection coefficients of the frame */\n\n    unsigned int refl_rms[NBLOCKS]; /**< RMS of the reflection coefficients */\n\n    int energy = 0;\n\n    int i, idx;\n\n\n\n    if (buf_size < FRAMESIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"output buffer too small\\n\");\n\n        return 0;\n\n    }\n\n    ractx = avctx->priv_data;\n\n\n\n    /**\n\n     * Since the LPC coefficients are calculated on a frame centered over the\n\n     * fourth subframe, to encode a given frame, data from the next frame is\n\n     * needed. In each call to this function, the previous frame (whose data are\n\n     * saved in the encoder context) is encoded, and data from the current frame\n\n     * are saved in the encoder context to be used in the next function call.\n\n     */\n\n    for (i = 0; i < (2 * BLOCKSIZE + BLOCKSIZE / 2); i++) {\n\n        lpc_data[i] = ractx->curr_block[BLOCKSIZE + BLOCKSIZE / 2 + i];\n\n        energy += (lpc_data[i] * lpc_data[i]) >> 4;\n\n    }\n\n    for (i = 2 * BLOCKSIZE + BLOCKSIZE / 2; i < NBLOCKS * BLOCKSIZE; i++) {\n\n        lpc_data[i] = *((int16_t *)data + i - 2 * BLOCKSIZE - BLOCKSIZE / 2) >>\n\n                      2;\n\n        energy += (lpc_data[i] * lpc_data[i]) >> 4;\n\n    }\n\n    energy = ff_energy_tab[quantize(ff_t_sqrt(energy >> 5) >> 10, ff_energy_tab,\n\n                                    32)];\n\n\n\n    ff_lpc_calc_coefs(&ractx->lpc_ctx, lpc_data, NBLOCKS * BLOCKSIZE, LPC_ORDER,\n\n                      LPC_ORDER, 16, lpc_coefs, shift, FF_LPC_TYPE_LEVINSON,\n\n                      0, ORDER_METHOD_EST, 12, 0);\n\n    for (i = 0; i < LPC_ORDER; i++)\n\n        block_coefs[NBLOCKS - 1][i] = -(lpc_coefs[LPC_ORDER - 1][i] <<\n\n                                        (12 - shift[LPC_ORDER - 1]));\n\n\n\n    /**\n\n     * TODO: apply perceptual weighting of the input speech through bandwidth\n\n     * expansion of the LPC filter.\n\n     */\n\n\n\n    if (ff_eval_refl(lpc_refl, block_coefs[NBLOCKS - 1], avctx)) {\n\n        /**\n\n         * The filter is unstable: use the coefficients of the previous frame.\n\n         */\n\n        ff_int_to_int16(block_coefs[NBLOCKS - 1], ractx->lpc_coef[1]);\n\n        ff_eval_refl(lpc_refl, block_coefs[NBLOCKS - 1], avctx);\n\n    }\n\n    init_put_bits(&pb, frame, buf_size);\n\n    for (i = 0; i < LPC_ORDER; i++) {\n\n        idx = quantize(lpc_refl[i], ff_lpc_refl_cb[i], sizes[i]);\n\n        put_bits(&pb, bit_sizes[i], idx);\n\n        lpc_refl[i] = ff_lpc_refl_cb[i][idx];\n\n    }\n\n    ractx->lpc_refl_rms[0] = ff_rms(lpc_refl);\n\n    ff_eval_coefs(ractx->lpc_coef[0], lpc_refl);\n\n    refl_rms[0] = ff_interp(ractx, block_coefs[0], 1, 1, ractx->old_energy);\n\n    refl_rms[1] = ff_interp(ractx, block_coefs[1], 2,\n\n                            energy <= ractx->old_energy,\n\n                            ff_t_sqrt(energy * ractx->old_energy) >> 12);\n\n    refl_rms[2] = ff_interp(ractx, block_coefs[2], 3, 0, energy);\n\n    refl_rms[3] = ff_rescale_rms(ractx->lpc_refl_rms[0], energy);\n\n    ff_int_to_int16(block_coefs[NBLOCKS - 1], ractx->lpc_coef[0]);\n\n    put_bits(&pb, 5, quantize(energy, ff_energy_tab, 32));\n\n    for (i = 0; i < NBLOCKS; i++)\n\n        ra144_encode_subblock(ractx, ractx->curr_block + i * BLOCKSIZE,\n\n                              block_coefs[i], refl_rms[i], &pb);\n\n    flush_put_bits(&pb);\n\n    ractx->old_energy = energy;\n\n    ractx->lpc_refl_rms[1] = ractx->lpc_refl_rms[0];\n\n    FFSWAP(unsigned int *, ractx->lpc_coef[0], ractx->lpc_coef[1]);\n\n    for (i = 0; i < NBLOCKS * BLOCKSIZE; i++)\n\n        ractx->curr_block[i] = *((int16_t *)data + i) >> 2;\n\n    return FRAMESIZE;\n\n}\n", "idx": 5452, "_split": "test", "_hash": "69395790dfb6c6ab6ac33aad7e3c16ac"}
{"project": "FFmpeg", "commit_id": "86ab6b6e08e2982fb5785e0691c0a7e289339ffb", "target": 0, "func": "static void decode0(GetByteContext *gb, RangeCoder *rc, unsigned cumFreq, unsigned freq, unsigned total_freq)\n\n{\n\n    int t = rc->range * (uint64_t)cumFreq / total_freq;\n\n\n\n    rc->code1 += t + 1;\n\n    rc->range = rc->range * (uint64_t)(freq + cumFreq) / total_freq - (t + 1);\n\n\n\n    while (rc->range < TOP && bytestream2_get_bytes_left(gb) > 0) {\n\n        unsigned byte = bytestream2_get_byte(gb);\n\n        rc->code = (rc->code << 8) | byte;\n\n        rc->code1 <<= 8;\n\n        rc->range <<= 8;\n\n    }\n\n}\n", "idx": 5457, "_split": "test", "_hash": "65e06a0812f135d7349a9a709c1f2fb8"}
{"project": "FFmpeg", "commit_id": "cf7d2f2d2134c0854edf2db91e7436ac2bc9874f", "target": 0, "func": "static av_cold int dnxhd_encode_init(AVCodecContext *avctx)\n\n{\n\n    DNXHDEncContext *ctx = avctx->priv_data;\n\n    int i, index, bit_depth, ret;\n\n\n\n    switch (avctx->pix_fmt) {\n\n    case AV_PIX_FMT_YUV422P:\n\n        bit_depth = 8;\n\n        break;\n\n    case AV_PIX_FMT_YUV422P10:\n\n        bit_depth = 10;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"pixel format is incompatible with DNxHD\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    ctx->cid = ff_dnxhd_find_cid(avctx, bit_depth);\n\n    if (!ctx->cid) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"video parameters incompatible with DNxHD\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    av_log(avctx, AV_LOG_DEBUG, \"cid %d\\n\", ctx->cid);\n\n\n\n    index = ff_dnxhd_get_cid_table(ctx->cid);\n\n    if (index < 0)\n\n        return index;\n\n    ctx->cid_table = &ff_dnxhd_cid_table[index];\n\n\n\n    ctx->m.avctx    = avctx;\n\n    ctx->m.mb_intra = 1;\n\n    ctx->m.h263_aic = 1;\n\n\n\n    avctx->bits_per_raw_sample = ctx->cid_table->bit_depth;\n\n\n\n    ff_blockdsp_init(&ctx->bdsp, avctx);\n\n    ff_fdctdsp_init(&ctx->m.fdsp, avctx);\n\n    ff_mpv_idct_init(&ctx->m);\n\n    ff_mpegvideoencdsp_init(&ctx->m.mpvencdsp, avctx);\n\n    ff_pixblockdsp_init(&ctx->m.pdsp, avctx);\n\n    if (!ctx->m.dct_quantize)\n\n        ctx->m.dct_quantize = ff_dct_quantize_c;\n\n\n\n    if (ctx->cid_table->bit_depth == 10) {\n\n        ctx->m.dct_quantize     = dnxhd_10bit_dct_quantize;\n\n        ctx->get_pixels_8x4_sym = dnxhd_10bit_get_pixels_8x4_sym;\n\n        ctx->block_width_l2     = 4;\n\n    } else {\n\n        ctx->get_pixels_8x4_sym = dnxhd_8bit_get_pixels_8x4_sym;\n\n        ctx->block_width_l2     = 3;\n\n    }\n\n\n\n    if (ARCH_X86)\n\n        ff_dnxhdenc_init_x86(ctx);\n\n\n\n    ctx->m.mb_height = (avctx->height + 15) / 16;\n\n    ctx->m.mb_width  = (avctx->width  + 15) / 16;\n\n\n\n    if (avctx->flags & AV_CODEC_FLAG_INTERLACED_DCT) {\n\n        ctx->interlaced   = 1;\n\n        ctx->m.mb_height /= 2;\n\n    }\n\n\n\n    ctx->m.mb_num = ctx->m.mb_height * ctx->m.mb_width;\n\n\n\n#if FF_API_QUANT_BIAS\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    if (ctx->intra_quant_bias == FF_DEFAULT_QUANT_BIAS &&\n\n        avctx->intra_quant_bias != FF_DEFAULT_QUANT_BIAS)\n\n        ctx->intra_quant_bias = avctx->intra_quant_bias;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n    // XXX tune lbias/cbias\n\n    if ((ret = dnxhd_init_qmat(ctx, ctx->intra_quant_bias, 0)) < 0)\n\n        return ret;\n\n\n\n    /* Avid Nitris hardware decoder requires a minimum amount of padding\n\n     * in the coding unit payload */\n\n    if (ctx->nitris_compat)\n\n        ctx->min_padding = 1600;\n\n\n\n    if ((ret = dnxhd_init_vlc(ctx)) < 0)\n\n        return ret;\n\n    if ((ret = dnxhd_init_rc(ctx)) < 0)\n\n        return ret;\n\n\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->slice_size,\n\n                      ctx->m.mb_height * sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->slice_offs,\n\n                      ctx->m.mb_height * sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_bits,\n\n                      ctx->m.mb_num * sizeof(uint16_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(ctx->m.avctx, ctx->mb_qscale,\n\n                      ctx->m.mb_num * sizeof(uint8_t), fail);\n\n\n\n#if FF_API_CODED_FRAME\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    avctx->coded_frame->key_frame = 1;\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    if (avctx->thread_count > MAX_THREADS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"too many threads\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    ctx->thread[0] = ctx;\n\n    for (i = 1; i < avctx->thread_count; i++) {\n\n        ctx->thread[i] = av_malloc(sizeof(DNXHDEncContext));\n\n        memcpy(ctx->thread[i], ctx, sizeof(DNXHDEncContext));\n\n    }\n\n\n\n    return 0;\n\nfail:  // for FF_ALLOCZ_OR_GOTO\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 5539, "_split": "test", "_hash": "d819e5f51f3fff0506c5bb37276e5431"}
{"project": "FFmpeg", "commit_id": "ccce723c6d0ea1ea89ea6c47160a07d37cdeeba2", "target": 0, "func": "static int vc1_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size, n_slices = 0, i;\n\n    VC1Context *v = avctx->priv_data;\n\n    MpegEncContext *s = &v->s;\n\n    AVFrame *pict = data;\n\n    uint8_t *buf2 = NULL;\n\n    const uint8_t *buf_start = buf, *buf_start_second_field = NULL;\n\n    int mb_height, n_slices1=-1;\n\n    struct {\n\n        uint8_t *buf;\n\n        GetBitContext gb;\n\n        int mby_start;\n\n    } *slices = NULL, *tmp;\n\n\n\n    v->second_field = 0;\n\n\n\n    if(s->flags & CODEC_FLAG_LOW_DELAY)\n\n        s->low_delay = 1;\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == VC1_CODE_ENDOFSEQ)) {\n\n        /* special case for last picture */\n\n        if (s->low_delay == 0 && s->next_picture_ptr) {\n\n            *pict = s->next_picture_ptr->f;\n\n            s->next_picture_ptr = NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n\n\n        return buf_size;\n\n    }\n\n\n\n    if (s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU) {\n\n        if (v->profile < PROFILE_ADVANCED)\n\n            avctx->pix_fmt = AV_PIX_FMT_VDPAU_WMV3;\n\n        else\n\n            avctx->pix_fmt = AV_PIX_FMT_VDPAU_VC1;\n\n    }\n\n\n\n    //for advanced profile we may need to parse and unescape data\n\n    if (avctx->codec_id == AV_CODEC_ID_VC1 || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\n        int buf_size2 = 0;\n\n        buf2 = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n        if (IS_MARKER(AV_RB32(buf))) { /* frame starts with marker and needs to be parsed */\n\n            const uint8_t *start, *end, *next;\n\n            int size;\n\n\n\n            next = buf;\n\n            for (start = buf, end = buf + buf_size; next < end; start = next) {\n\n                next = find_next_marker(start + 4, end);\n\n                size = next - start - 4;\n\n                if (size <= 0) continue;\n\n                switch (AV_RB32(start)) {\n\n                case VC1_CODE_FRAME:\n\n                    if (avctx->hwaccel ||\n\n                        s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)\n\n                        buf_start = start;\n\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n\n                    break;\n\n                case VC1_CODE_FIELD: {\n\n                    int buf_size3;\n\n                    if (avctx->hwaccel ||\n\n                        s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)\n\n                        buf_start_second_field = start;\n\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                    if (!tmp)\n\n                        goto err;\n\n                    slices = tmp;\n\n                    slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!slices[n_slices].buf)\n\n                        goto err;\n\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n\n                                                    slices[n_slices].buf);\n\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                                  buf_size3 << 3);\n\n                    /* assuming that the field marker is at the exact middle,\n\n                       hope it's correct */\n\n                    slices[n_slices].mby_start = s->mb_height >> 1;\n\n                    n_slices1 = n_slices - 1; // index of the last slice of the first field\n\n                    n_slices++;\n\n                    break;\n\n                }\n\n                case VC1_CODE_ENTRYPOINT: /* it should be before frame data */\n\n                    buf_size2 = vc1_unescape_buffer(start + 4, size, buf2);\n\n                    init_get_bits(&s->gb, buf2, buf_size2 * 8);\n\n                    ff_vc1_decode_entry_point(avctx, v, &s->gb);\n\n                    break;\n\n                case VC1_CODE_SLICE: {\n\n                    int buf_size3;\n\n                    tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                    if (!tmp)\n\n                        goto err;\n\n                    slices = tmp;\n\n                    slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                    if (!slices[n_slices].buf)\n\n                        goto err;\n\n                    buf_size3 = vc1_unescape_buffer(start + 4, size,\n\n                                                    slices[n_slices].buf);\n\n                    init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                                  buf_size3 << 3);\n\n                    slices[n_slices].mby_start = get_bits(&slices[n_slices].gb, 9);\n\n                    n_slices++;\n\n                    break;\n\n                }\n\n                }\n\n            }\n\n        } else if (v->interlace && ((buf[0] & 0xC0) == 0xC0)) { /* WVC1 interlaced stores both fields divided by marker */\n\n            const uint8_t *divider;\n\n            int buf_size3;\n\n\n\n            divider = find_next_marker(buf, buf + buf_size);\n\n            if ((divider == (buf + buf_size)) || AV_RB32(divider) != VC1_CODE_FIELD) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Error in WVC1 interlaced frame\\n\");\n\n                goto err;\n\n            } else { // found field marker, unescape second field\n\n                if (avctx->hwaccel ||\n\n                    s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)\n\n                    buf_start_second_field = divider;\n\n                tmp = av_realloc(slices, sizeof(*slices) * (n_slices+1));\n\n                if (!tmp)\n\n                    goto err;\n\n                slices = tmp;\n\n                slices[n_slices].buf = av_mallocz(buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!slices[n_slices].buf)\n\n                    goto err;\n\n                buf_size3 = vc1_unescape_buffer(divider + 4, buf + buf_size - divider - 4, slices[n_slices].buf);\n\n                init_get_bits(&slices[n_slices].gb, slices[n_slices].buf,\n\n                              buf_size3 << 3);\n\n                slices[n_slices].mby_start = s->mb_height >> 1;\n\n                n_slices1 = n_slices - 1;\n\n                n_slices++;\n\n            }\n\n            buf_size2 = vc1_unescape_buffer(buf, divider - buf, buf2);\n\n        } else {\n\n            buf_size2 = vc1_unescape_buffer(buf, buf_size, buf2);\n\n        }\n\n        init_get_bits(&s->gb, buf2, buf_size2*8);\n\n    } else\n\n        init_get_bits(&s->gb, buf, buf_size*8);\n\n\n\n    if (v->res_sprite) {\n\n        v->new_sprite  = !get_bits1(&s->gb);\n\n        v->two_sprites =  get_bits1(&s->gb);\n\n        /* res_sprite means a Windows Media Image stream, AV_CODEC_ID_*IMAGE means\n\n           we're using the sprite compositor. These are intentionally kept separate\n\n           so you can get the raw sprites by using the wmv3 decoder for WMVP or\n\n           the vc1 one for WVP2 */\n\n        if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\n            if (v->new_sprite) {\n\n                // switch AVCodecContext parameters to those of the sprites\n\n                avctx->width  = avctx->coded_width  = v->sprite_width;\n\n                avctx->height = avctx->coded_height = v->sprite_height;\n\n            } else {\n\n                goto image;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (s->context_initialized &&\n\n        (s->width  != avctx->coded_width ||\n\n         s->height != avctx->coded_height)) {\n\n        ff_vc1_decode_end(avctx);\n\n    }\n\n\n\n    if (!s->context_initialized) {\n\n        if (ff_msmpeg4_decode_init(avctx) < 0 || ff_vc1_decode_init_alloc_tables(v) < 0)\n\n            goto err;\n\n\n\n        s->low_delay = !avctx->has_b_frames || v->res_sprite;\n\n\n\n        if (v->profile == PROFILE_ADVANCED) {\n\n            s->h_edge_pos = avctx->coded_width;\n\n            s->v_edge_pos = avctx->coded_height;\n\n        }\n\n    }\n\n\n\n    /* We need to set current_picture_ptr before reading the header,\n\n     * otherwise we cannot store anything in there. */\n\n    if (s->current_picture_ptr == NULL || s->current_picture_ptr->f.data[0]) {\n\n        int i = ff_find_unused_picture(s, 0);\n\n        if (i < 0)\n\n            goto err;\n\n        s->current_picture_ptr = &s->picture[i];\n\n    }\n\n\n\n    // do parse frame header\n\n    v->pic_header_flag = 0;\n\n    if (v->profile < PROFILE_ADVANCED) {\n\n        if (ff_vc1_parse_frame_header(v, &s->gb) < 0) {\n\n            goto err;\n\n        }\n\n    } else {\n\n        if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n\n            goto err;\n\n        }\n\n    }\n\n\n\n    if (avctx->debug & FF_DEBUG_PICT_INFO)\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"pict_type: %c\\n\", av_get_picture_type_char(s->pict_type));\n\n\n\n    if ((avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE)\n\n        && s->pict_type != AV_PICTURE_TYPE_I) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Sprite decoder: expected I-frame\\n\");\n\n        goto err;\n\n    }\n\n\n\n    if ((s->mb_height >> v->field_mode) == 0) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"image too short\\n\");\n\n        goto err;\n\n    }\n\n\n\n    // process pulldown flags\n\n    s->current_picture_ptr->f.repeat_pict = 0;\n\n    // Pulldown flags are only valid when 'broadcast' has been set.\n\n    // So ticks_per_frame will be 2\n\n    if (v->rff) {\n\n        // repeat field\n\n        s->current_picture_ptr->f.repeat_pict = 1;\n\n    } else if (v->rptfrm) {\n\n        // repeat frames\n\n        s->current_picture_ptr->f.repeat_pict = v->rptfrm * 2;\n\n    }\n\n\n\n    // for skipping the frame\n\n    s->current_picture.f.pict_type = s->pict_type;\n\n    s->current_picture.f.key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    /* skip B-frames if we don't have reference frames */\n\n    if (s->last_picture_ptr == NULL && (s->pict_type == AV_PICTURE_TYPE_B || s->dropable)) {\n\n        goto err;\n\n    }\n\n    if ((avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == AV_PICTURE_TYPE_B) ||\n\n        (avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != AV_PICTURE_TYPE_I) ||\n\n         avctx->skip_frame >= AVDISCARD_ALL) {\n\n        goto end;\n\n    }\n\n\n\n    if (s->next_p_frame_damaged) {\n\n        if (s->pict_type == AV_PICTURE_TYPE_B)\n\n            goto end;\n\n        else\n\n            s->next_p_frame_damaged = 0;\n\n    }\n\n\n\n    if (ff_MPV_frame_start(s, avctx) < 0) {\n\n        goto err;\n\n    }\n\n\n\n    v->s.current_picture_ptr->f.interlaced_frame = (v->fcm != PROGRESSIVE);\n\n    v->s.current_picture_ptr->f.top_field_first  = v->tff;\n\n\n\n    s->me.qpel_put = s->dsp.put_qpel_pixels_tab;\n\n    s->me.qpel_avg = s->dsp.avg_qpel_pixels_tab;\n\n\n\n    if ((CONFIG_VC1_VDPAU_DECODER)\n\n        &&s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)\n\n        ff_vdpau_vc1_decode_picture(s, buf_start, (buf + buf_size) - buf_start);\n\n    else if (avctx->hwaccel) {\n\n        if (v->field_mode && buf_start_second_field) {\n\n            // decode first field\n\n            s->picture_structure = PICT_BOTTOM_FIELD - v->tff;\n\n            if (avctx->hwaccel->start_frame(avctx, buf_start, buf_start_second_field - buf_start) < 0)\n\n                goto err;\n\n            if (avctx->hwaccel->decode_slice(avctx, buf_start, buf_start_second_field - buf_start) < 0)\n\n                goto err;\n\n            if (avctx->hwaccel->end_frame(avctx) < 0)\n\n                goto err;\n\n\n\n            // decode second field\n\n            s->gb = slices[n_slices1 + 1].gb;\n\n            s->picture_structure = PICT_TOP_FIELD + v->tff;\n\n            v->second_field = 1;\n\n            v->pic_header_flag = 0;\n\n            if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"parsing header for second field failed\");\n\n                goto err;\n\n            }\n\n            v->s.current_picture_ptr->f.pict_type = v->s.pict_type;\n\n\n\n            if (avctx->hwaccel->start_frame(avctx, buf_start_second_field, (buf + buf_size) - buf_start_second_field) < 0)\n\n                goto err;\n\n            if (avctx->hwaccel->decode_slice(avctx, buf_start_second_field, (buf + buf_size) - buf_start_second_field) < 0)\n\n                goto err;\n\n            if (avctx->hwaccel->end_frame(avctx) < 0)\n\n                goto err;\n\n        } else {\n\n            s->picture_structure = PICT_FRAME;\n\n            if (avctx->hwaccel->start_frame(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n\n                goto err;\n\n            if (avctx->hwaccel->decode_slice(avctx, buf_start, (buf + buf_size) - buf_start) < 0)\n\n                goto err;\n\n            if (avctx->hwaccel->end_frame(avctx) < 0)\n\n                goto err;\n\n        }\n\n    } else {\n\n        if (v->fcm == ILACE_FRAME && s->pict_type == AV_PICTURE_TYPE_B)\n\n            goto err; // This codepath is still incomplete thus it is disabled\n\n\n\n        ff_er_frame_start(s);\n\n\n\n        v->bits = buf_size * 8;\n\n        v->end_mb_x = s->mb_width;\n\n        if (v->field_mode) {\n\n            uint8_t *tmp[2];\n\n            s->current_picture.f.linesize[0] <<= 1;\n\n            s->current_picture.f.linesize[1] <<= 1;\n\n            s->current_picture.f.linesize[2] <<= 1;\n\n            s->linesize                      <<= 1;\n\n            s->uvlinesize                    <<= 1;\n\n            tmp[0]          = v->mv_f_last[0];\n\n            tmp[1]          = v->mv_f_last[1];\n\n            v->mv_f_last[0] = v->mv_f_next[0];\n\n            v->mv_f_last[1] = v->mv_f_next[1];\n\n            v->mv_f_next[0] = v->mv_f[0];\n\n            v->mv_f_next[1] = v->mv_f[1];\n\n            v->mv_f[0] = tmp[0];\n\n            v->mv_f[1] = tmp[1];\n\n        }\n\n        mb_height = s->mb_height >> v->field_mode;\n\n        for (i = 0; i <= n_slices; i++) {\n\n            if (i > 0 &&  slices[i - 1].mby_start >= mb_height) {\n\n                if (v->field_mode <= 0) {\n\n                    av_log(v->s.avctx, AV_LOG_ERROR, \"Slice %d starts beyond \"\n\n                           \"picture boundary (%d >= %d)\\n\", i,\n\n                           slices[i - 1].mby_start, mb_height);\n\n                    continue;\n\n                }\n\n                v->second_field = 1;\n\n                v->blocks_off   = s->mb_width  * s->mb_height << 1;\n\n                v->mb_off       = s->mb_stride * s->mb_height >> 1;\n\n            } else {\n\n                v->second_field = 0;\n\n                v->blocks_off   = 0;\n\n                v->mb_off       = 0;\n\n            }\n\n            if (i) {\n\n                v->pic_header_flag = 0;\n\n                if (v->field_mode && i == n_slices1 + 2) {\n\n                    if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Field header damaged\\n\");\n\n                        continue;\n\n                    }\n\n                } else if (get_bits1(&s->gb)) {\n\n                    v->pic_header_flag = 1;\n\n                    if (ff_vc1_parse_frame_header_adv(v, &s->gb) < 0) {\n\n                        av_log(v->s.avctx, AV_LOG_ERROR, \"Slice header damaged\\n\");\n\n                        continue;\n\n                    }\n\n                }\n\n            }\n\n            s->start_mb_y = (i == 0) ? 0 : FFMAX(0, slices[i-1].mby_start % mb_height);\n\n            if (!v->field_mode || v->second_field)\n\n                s->end_mb_y = (i == n_slices     ) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            else\n\n                s->end_mb_y = (i <= n_slices1 + 1) ? mb_height : FFMIN(mb_height, slices[i].mby_start % mb_height);\n\n            if (s->end_mb_y <= s->start_mb_y) {\n\n                av_log(v->s.avctx, AV_LOG_ERROR, \"end mb y %d %d invalid\\n\", s->end_mb_y, s->start_mb_y);\n\n                continue;\n\n            }\n\n            ff_vc1_decode_blocks(v);\n\n            if (i != n_slices)\n\n                s->gb = slices[i].gb;\n\n        }\n\n        if (v->field_mode) {\n\n            v->second_field = 0;\n\n            if (s->pict_type == AV_PICTURE_TYPE_B) {\n\n                memcpy(v->mv_f_base, v->mv_f_next_base,\n\n                       2 * (s->b8_stride * (s->mb_height * 2 + 1) + s->mb_stride * (s->mb_height + 1) * 2));\n\n            }\n\n            s->current_picture.f.linesize[0] >>= 1;\n\n            s->current_picture.f.linesize[1] >>= 1;\n\n            s->current_picture.f.linesize[2] >>= 1;\n\n            s->linesize                      >>= 1;\n\n            s->uvlinesize                    >>= 1;\n\n        }\n\n        av_dlog(s->avctx, \"Consumed %i/%i bits\\n\",\n\n                get_bits_count(&s->gb), s->gb.size_in_bits);\n\n//  if (get_bits_count(&s->gb) > buf_size * 8)\n\n//      return -1;\n\n        if(s->error_occurred && s->pict_type == AV_PICTURE_TYPE_B)\n\n            goto err;\n\n        if(!v->field_mode)\n\n            ff_er_frame_end(s);\n\n    }\n\n\n\n    ff_MPV_frame_end(s);\n\n\n\n    if (avctx->codec_id == AV_CODEC_ID_WMV3IMAGE || avctx->codec_id == AV_CODEC_ID_VC1IMAGE) {\n\nimage:\n\n        avctx->width  = avctx->coded_width  = v->output_width;\n\n        avctx->height = avctx->coded_height = v->output_height;\n\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n\n            goto end;\n\n#if CONFIG_WMV3IMAGE_DECODER || CONFIG_VC1IMAGE_DECODER\n\n        if (vc1_decode_sprites(v, &s->gb))\n\n            goto err;\n\n#endif\n\n        *pict      = v->sprite_output_frame;\n\n        *data_size = sizeof(AVFrame);\n\n    } else {\n\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n            *pict = s->current_picture_ptr->f;\n\n        } else if (s->last_picture_ptr != NULL) {\n\n            *pict = s->last_picture_ptr->f;\n\n        }\n\n        if (s->last_picture_ptr || s->low_delay) {\n\n            *data_size = sizeof(AVFrame);\n\n            ff_print_debug_info(s, pict);\n\n        }\n\n    }\n\n\n\nend:\n\n    av_free(buf2);\n\n    for (i = 0; i < n_slices; i++)\n\n        av_free(slices[i].buf);\n\n    av_free(slices);\n\n    return buf_size;\n\n\n\nerr:\n\n    av_free(buf2);\n\n    for (i = 0; i < n_slices; i++)\n\n        av_free(slices[i].buf);\n\n    av_free(slices);\n\n    return -1;\n\n}\n", "idx": 5567, "_split": "test", "_hash": "b8213e701807e0341904a0211989cab1"}
{"project": "FFmpeg", "commit_id": "fc9b22dd2e5de851a89245b5357e710b93587278", "target": 0, "func": "static int rtp_open(URLContext *h, const char *uri, int flags)\n\n{\n\n    RTPContext *s;\n\n    int port, is_output, ttl, local_port;\n\n    char hostname[256];\n\n    char buf[1024];\n\n    char path[1024];\n\n    const char *p;\n\n\n\n    is_output = (flags & URL_WRONLY);\n\n\n\n    s = av_mallocz(sizeof(RTPContext));\n\n    if (!s)\n\n        return AVERROR(ENOMEM);\n\n    h->priv_data = s;\n\n\n\n    url_split(NULL, 0, NULL, 0, hostname, sizeof(hostname), &port,\n\n              path, sizeof(path), uri);\n\n    /* extract parameters */\n\n    ttl = -1;\n\n    local_port = -1;\n\n    p = strchr(uri, '?');\n\n    if (p) {\n\n        if (find_info_tag(buf, sizeof(buf), \"ttl\", p)) {\n\n            ttl = strtol(buf, NULL, 10);\n\n        }\n\n        if (find_info_tag(buf, sizeof(buf), \"localport\", p)) {\n\n            local_port = strtol(buf, NULL, 10);\n\n        }\n\n    }\n\n\n\n    build_udp_url(buf, sizeof(buf),\n\n                  hostname, port, local_port, ttl);\n\n    if (url_open(&s->rtp_hd, buf, flags) < 0)\n\n        goto fail;\n\n    local_port = udp_get_local_port(s->rtp_hd);\n\n    /* XXX: need to open another connection if the port is not even */\n\n\n\n    /* well, should suppress localport in path */\n\n\n\n    build_udp_url(buf, sizeof(buf),\n\n                  hostname, port + 1, local_port + 1, ttl);\n\n    if (url_open(&s->rtcp_hd, buf, flags) < 0)\n\n        goto fail;\n\n\n\n    /* just to ease handle access. XXX: need to suppress direct handle\n\n       access */\n\n    s->rtp_fd = udp_get_file_handle(s->rtp_hd);\n\n    s->rtcp_fd = udp_get_file_handle(s->rtcp_hd);\n\n\n\n    h->max_packet_size = url_get_max_packet_size(s->rtp_hd);\n\n    h->is_streamed = 1;\n\n    return 0;\n\n\n\n fail:\n\n    if (s->rtp_hd)\n\n        url_close(s->rtp_hd);\n\n    if (s->rtcp_hd)\n\n        url_close(s->rtcp_hd);\n\n    av_free(s);\n\n    return AVERROR(EIO);\n\n}\n", "idx": 5617, "_split": "test", "_hash": "709b6762b6f44fbf8af65ea8a8fea3a5"}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static float get_band_cost_UPAIR7_mips(struct AACEncContext *s,\n\n                                       PutBitContext *pb, const float *in,\n\n                                       const float *scaled, int size, int scale_idx,\n\n                                       int cb, const float lambda, const float uplim,\n\n                                       int *bits)\n\n{\n\n    const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    int i;\n\n    float cost = 0;\n\n    int qc1, qc2, qc3, qc4;\n\n    int curbits = 0;\n\n\n\n    uint8_t *p_bits  = (uint8_t *)ff_aac_spectral_bits[cb-1];\n\n    float   *p_codes = (float   *)ff_aac_codebook_vectors[cb-1];\n\n\n\n    for (i = 0; i < size; i += 4) {\n\n        const float *vec, *vec2;\n\n        int curidx, curidx2, sign1, count1, sign2, count2;\n\n        int   *in_int = (int   *)&in[i];\n\n        float *in_pos = (float *)&in[i];\n\n        float di0, di1, di2, di3;\n\n        int t0, t1, t2, t3, t4;\n\n\n\n        qc1 = scaled[i  ] * Q34 + ROUND_STANDARD;\n\n        qc2 = scaled[i+1] * Q34 + ROUND_STANDARD;\n\n        qc3 = scaled[i+2] * Q34 + ROUND_STANDARD;\n\n        qc4 = scaled[i+3] * Q34 + ROUND_STANDARD;\n\n\n\n        __asm__ volatile (\n\n            \".set push                                          \\n\\t\"\n\n            \".set noreorder                                     \\n\\t\"\n\n\n\n            \"ori        %[t4],      $zero,      7               \\n\\t\"\n\n            \"ori        %[sign1],   $zero,      0               \\n\\t\"\n\n            \"ori        %[sign2],   $zero,      0               \\n\\t\"\n\n            \"slt        %[t0],      %[t4],      %[qc1]          \\n\\t\"\n\n            \"slt        %[t1],      %[t4],      %[qc2]          \\n\\t\"\n\n            \"slt        %[t2],      %[t4],      %[qc3]          \\n\\t\"\n\n            \"slt        %[t3],      %[t4],      %[qc4]          \\n\\t\"\n\n            \"movn       %[qc1],     %[t4],      %[t0]           \\n\\t\"\n\n            \"movn       %[qc2],     %[t4],      %[t1]           \\n\\t\"\n\n            \"movn       %[qc3],     %[t4],      %[t2]           \\n\\t\"\n\n            \"movn       %[qc4],     %[t4],      %[t3]           \\n\\t\"\n\n            \"lw         %[t0],      0(%[in_int])                \\n\\t\"\n\n            \"lw         %[t1],      4(%[in_int])                \\n\\t\"\n\n            \"lw         %[t2],      8(%[in_int])                \\n\\t\"\n\n            \"lw         %[t3],      12(%[in_int])               \\n\\t\"\n\n            \"slt        %[t0],      %[t0],      $zero           \\n\\t\"\n\n            \"movn       %[sign1],   %[t0],      %[qc1]          \\n\\t\"\n\n            \"slt        %[t2],      %[t2],      $zero           \\n\\t\"\n\n            \"movn       %[sign2],   %[t2],      %[qc3]          \\n\\t\"\n\n            \"slt        %[t1],      %[t1],      $zero           \\n\\t\"\n\n            \"sll        %[t0],      %[sign1],   1               \\n\\t\"\n\n            \"or         %[t0],      %[t0],      %[t1]           \\n\\t\"\n\n            \"movn       %[sign1],   %[t0],      %[qc2]          \\n\\t\"\n\n            \"slt        %[t3],      %[t3],      $zero           \\n\\t\"\n\n            \"sll        %[t0],      %[sign2],   1               \\n\\t\"\n\n            \"or         %[t0],      %[t0],      %[t3]           \\n\\t\"\n\n            \"movn       %[sign2],   %[t0],      %[qc4]          \\n\\t\"\n\n            \"slt        %[count1],  $zero,      %[qc1]          \\n\\t\"\n\n            \"slt        %[t1],      $zero,      %[qc2]          \\n\\t\"\n\n            \"slt        %[count2],  $zero,      %[qc3]          \\n\\t\"\n\n            \"slt        %[t2],      $zero,      %[qc4]          \\n\\t\"\n\n            \"addu       %[count1],  %[count1],  %[t1]           \\n\\t\"\n\n            \"addu       %[count2],  %[count2],  %[t2]           \\n\\t\"\n\n\n\n            \".set pop                                           \\n\\t\"\n\n\n\n            : [qc1]\"+r\"(qc1), [qc2]\"+r\"(qc2),\n\n              [qc3]\"+r\"(qc3), [qc4]\"+r\"(qc4),\n\n              [sign1]\"=&r\"(sign1), [count1]\"=&r\"(count1),\n\n              [sign2]\"=&r\"(sign2), [count2]\"=&r\"(count2),\n\n              [t0]\"=&r\"(t0), [t1]\"=&r\"(t1), [t2]\"=&r\"(t2), [t3]\"=&r\"(t3),\n\n              [t4]\"=&r\"(t4)\n\n            : [in_int]\"r\"(in_int)\n\n            : \"memory\"\n\n        );\n\n\n\n        curidx = 8 * qc1;\n\n        curidx += qc2;\n\n\n\n        curidx2 = 8 * qc3;\n\n        curidx2 += qc4;\n\n\n\n        curbits += p_bits[curidx];\n\n        curbits += upair7_sign_bits[curidx];\n\n        vec     = &p_codes[curidx*2];\n\n\n\n        curbits += p_bits[curidx2];\n\n        curbits += upair7_sign_bits[curidx2];\n\n        vec2    = &p_codes[curidx2*2];\n\n\n\n        __asm__ volatile (\n\n            \".set push                                          \\n\\t\"\n\n            \".set noreorder                                     \\n\\t\"\n\n\n\n            \"lwc1       %[di0],     0(%[in_pos])                \\n\\t\"\n\n            \"lwc1       %[di1],     4(%[in_pos])                \\n\\t\"\n\n            \"lwc1       %[di2],     8(%[in_pos])                \\n\\t\"\n\n            \"lwc1       %[di3],     12(%[in_pos])               \\n\\t\"\n\n            \"abs.s      %[di0],     %[di0]                      \\n\\t\"\n\n            \"abs.s      %[di1],     %[di1]                      \\n\\t\"\n\n            \"abs.s      %[di2],     %[di2]                      \\n\\t\"\n\n            \"abs.s      %[di3],     %[di3]                      \\n\\t\"\n\n            \"lwc1       $f0,        0(%[vec])                   \\n\\t\"\n\n            \"lwc1       $f1,        4(%[vec])                   \\n\\t\"\n\n            \"lwc1       $f2,        0(%[vec2])                  \\n\\t\"\n\n            \"lwc1       $f3,        4(%[vec2])                  \\n\\t\"\n\n            \"nmsub.s    %[di0],     %[di0],     $f0,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di1],     %[di1],     $f1,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di2],     %[di2],     $f2,    %[IQ]   \\n\\t\"\n\n            \"nmsub.s    %[di3],     %[di3],     $f3,    %[IQ]   \\n\\t\"\n\n\n\n            \".set pop                                           \\n\\t\"\n\n\n\n            : [di0]\"=&f\"(di0), [di1]\"=&f\"(di1),\n\n              [di2]\"=&f\"(di2), [di3]\"=&f\"(di3)\n\n            : [in_pos]\"r\"(in_pos), [vec]\"r\"(vec),\n\n              [vec2]\"r\"(vec2), [IQ]\"f\"(IQ)\n\n            : \"$f0\", \"$f1\", \"$f2\", \"$f3\",\n\n              \"memory\"\n\n        );\n\n\n\n        cost += di0 * di0 + di1 * di1\n\n                + di2 * di2 + di3 * di3;\n\n    }\n\n\n\n    if (bits)\n\n        *bits = curbits;\n\n    return cost * lambda + curbits;\n\n}\n", "idx": 5621, "_split": "test", "_hash": "768cb1290178d1a2254b5093dc5ab087"}
{"project": "FFmpeg", "commit_id": "d2ee495fb241fa4ef5b8b56161328c4379d1c79a", "target": 1, "func": "void ff_mlp_init_x86(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n#if HAVE_7REGS && HAVE_TEN_OPERANDS\n\n    c->mlp_filter_channel = mlp_filter_channel_x86;\n\n#endif\n\n}\n", "idx": 5731, "_split": "test", "_hash": "570b0f4ef76b532b038d6e359656508b"}
{"project": "FFmpeg", "commit_id": "295b79b5d8c0cf0a9691f8d6b512aa1e289d528d", "target": 1, "func": "static av_cold int roq_encode_init(AVCodecContext *avctx)\n{\n    RoqContext *enc = avctx->priv_data;\n    av_lfg_init(&enc->randctx, 1);\n    enc->framesSinceKeyframe = 0;\n    if ((avctx->width & 0xf) || (avctx->height & 0xf)) {\n        av_log(avctx, AV_LOG_ERROR, \"Dimensions must be divisible by 16\\n\");\n        return AVERROR(EINVAL);\n    if (avctx->width > 65535 || avctx->height > 65535) {\n        av_log(avctx, AV_LOG_ERROR, \"Dimensions are max %d\\n\", enc->quake3_compat ? 32768 : 65535);\n        return AVERROR(EINVAL);\n    if (((avctx->width)&(avctx->width-1))||((avctx->height)&(avctx->height-1)))\n        av_log(avctx, AV_LOG_ERROR, \"Warning: dimensions not power of two, this is not supported by quake\\n\");\n    enc->width = avctx->width;\n    enc->height = avctx->height;\n    enc->framesSinceKeyframe = 0;\n    enc->first_frame = 1;\n    enc->last_frame    = av_frame_alloc();\n    enc->current_frame = av_frame_alloc();\n    if (!enc->last_frame || !enc->current_frame) {\n    enc->tmpData      = av_malloc(sizeof(RoqTempdata));\n    enc->this_motion4 =\n        av_mallocz_array((enc->width*enc->height/16), sizeof(motion_vect));\n    enc->last_motion4 =\n        av_malloc_array ((enc->width*enc->height/16), sizeof(motion_vect));\n    enc->this_motion8 =\n        av_mallocz_array((enc->width*enc->height/64), sizeof(motion_vect));\n    enc->last_motion8 =\n        av_malloc_array ((enc->width*enc->height/64), sizeof(motion_vect));\n    return 0;", "idx": 5754, "_split": "test", "_hash": "3854af4742e5d77d3f4abf7b15423e9d"}
{"project": "FFmpeg", "commit_id": "fd1588919d2c70288a1a3fea1aefdd3ea2c424bb", "target": 1, "func": "void ff_h264_flush_change(H264Context *h)\n\n{\n\n    int i, j;\n\n\n\n    h->next_outputed_poc = INT_MIN;\n\n    h->prev_interlaced_frame = 1;\n\n    idr(h);\n\n\n\n    h->poc.prev_frame_num = -1;\n\n    if (h->cur_pic_ptr) {\n\n        h->cur_pic_ptr->reference = 0;\n\n        for (j=i=0; h->delayed_pic[i]; i++)\n\n            if (h->delayed_pic[i] != h->cur_pic_ptr)\n\n                h->delayed_pic[j++] = h->delayed_pic[i];\n\n        h->delayed_pic[j] = NULL;\n\n    }\n\n    ff_h264_unref_picture(h, &h->last_pic_for_ec);\n\n\n\n    h->first_field = 0;\n\n    ff_h264_sei_uninit(&h->sei);\n\n    h->recovery_frame = -1;\n\n    h->frame_recovered = 0;\n\n    h->current_slice = 0;\n\n    h->mmco_reset = 1;\n\n    for (i = 0; i < h->nb_slice_ctx; i++)\n\n        h->slice_ctx[i].list_count = 0;\n\n}\n", "idx": 5755, "_split": "test", "_hash": "3048df3eb84e8658ce76605313c787f5"}
{"project": "FFmpeg", "commit_id": "4dbcdfa86d1405f7e5c0ec14a4be7d2fb5903d7b", "target": 0, "func": "static int av_set_number2(void *obj, const char *name, double num, int den, int64_t intnum, const AVOption **o_out)\n\n{\n\n    const AVOption *o = av_opt_find(obj, name, NULL, 0, 0);\n\n    void *dst;\n\n    if (o_out)\n\n        *o_out= o;\n\n    if (!o || o->offset<=0)\n\n        return AVERROR_OPTION_NOT_FOUND;\n\n\n\n    if (o->max*den < num*intnum || o->min*den > num*intnum) {\n\n        av_log(obj, AV_LOG_ERROR, \"Value %lf for parameter '%s' out of range\\n\", num, name);\n\n        return AVERROR(ERANGE);\n\n    }\n\n\n\n    dst= ((uint8_t*)obj) + o->offset;\n\n\n\n    switch (o->type) {\n\n    case FF_OPT_TYPE_FLAGS:\n\n    case FF_OPT_TYPE_INT:   *(int       *)dst= llrint(num/den)*intnum; break;\n\n    case FF_OPT_TYPE_INT64: *(int64_t   *)dst= llrint(num/den)*intnum; break;\n\n    case FF_OPT_TYPE_FLOAT: *(float     *)dst= num*intnum/den;         break;\n\n    case FF_OPT_TYPE_DOUBLE:*(double    *)dst= num*intnum/den;         break;\n\n    case FF_OPT_TYPE_RATIONAL:\n\n        if ((int)num == num) *(AVRational*)dst= (AVRational){num*intnum, den};\n\n        else                 *(AVRational*)dst= av_d2q(num*intnum/den, 1<<24);\n\n        break;\n\n    default:\n\n        return AVERROR(EINVAL);\n\n    }\n\n    return 0;\n\n}\n", "idx": 5762, "_split": "test", "_hash": "c7d388aa513ae6fb60a5e2c9c858f67e"}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "static void vc1_inv_trans_8x4_dc_c(uint8_t *dest, int linesize, DCTELEM *block)\n\n{\n\n    int i;\n\n    int dc = block[0];\n\n    const uint8_t *cm;\n\n    dc = ( 3 * dc +  1) >> 1;\n\n    dc = (17 * dc + 64) >> 7;\n\n    cm = ff_cropTbl + MAX_NEG_CROP + dc;\n\n    for(i = 0; i < 4; i++){\n\n        dest[0] = cm[dest[0]];\n\n        dest[1] = cm[dest[1]];\n\n        dest[2] = cm[dest[2]];\n\n        dest[3] = cm[dest[3]];\n\n        dest[4] = cm[dest[4]];\n\n        dest[5] = cm[dest[5]];\n\n        dest[6] = cm[dest[6]];\n\n        dest[7] = cm[dest[7]];\n\n        dest += linesize;\n\n    }\n\n}\n", "idx": 5781, "_split": "test", "_hash": "51b629100f450f21a2756f6ce0f4fc55"}
{"project": "FFmpeg", "commit_id": "a70c27e813346a11e5fff3d329ecba82fb76826a", "target": 1, "func": "static always_inline uint8_t vc1_mspel_filter(const uint8_t *src, int stride, int mode, int r)\n\n{\n\n    switch(mode){\n\n    case 0: //no shift\n\n        return src[0];\n\n    case 1: // 1/4 shift\n\n        return (-4*src[-stride] + 53*src[0] + 18*src[stride] - 3*src[stride*2] + 32 - r) >> 6;\n\n    case 2: // 1/2 shift\n\n        return (-src[-stride] + 9*src[0] + 9*src[stride] - src[stride*2] + 8 - r) >> 4;\n\n    case 3: // 3/4 shift\n\n        return (-3*src[-stride] + 18*src[0] + 53*src[stride] - 4*src[stride*2] + 32 - r) >> 6;\n\n    }\n\n    return 0; //should not occur\n\n}\n", "idx": 5789, "_split": "test", "_hash": "3f19928a017bbff3ad504cbb0ae46780"}
{"project": "FFmpeg", "commit_id": "7e4fe5162ab94a413e04caae19193c5e7a4c6478", "target": 0, "func": "static void sha1_transform(uint32_t state[5], const uint8_t buffer[64])\n\n{\n\n    uint32_t block[80];\n\n    unsigned int i, a, b, c, d, e;\n\n\n\n    a = state[0];\n\n    b = state[1];\n\n    c = state[2];\n\n    d = state[3];\n\n    e = state[4];\n\n#if CONFIG_SMALL\n\n    for (i = 0; i < 80; i++) {\n\n        int t;\n\n        if (i < 16)\n\n            t = AV_RB32(buffer + 4 * i);\n\n        else\n\n            t = rol(block[i-3] ^ block[i-8] ^ block[i-14] ^ block[i-16], 1);\n\n        block[i] = t;\n\n        t += e + rol(a, 5);\n\n        if (i < 40) {\n\n            if (i < 20)\n\n                t += ((b&(c^d))^d)     + 0x5A827999;\n\n            else\n\n                t += ( b^c     ^d)     + 0x6ED9EBA1;\n\n        } else {\n\n            if (i < 60)\n\n                t += (((b|c)&d)|(b&c)) + 0x8F1BBCDC;\n\n            else\n\n                t += ( b^c     ^d)     + 0xCA62C1D6;\n\n        }\n\n        e = d;\n\n        d = c;\n\n        c = rol(b, 30);\n\n        b = a;\n\n        a = t;\n\n    }\n\n#else\n\n    for (i = 0; i < 15; i += 5) {\n\n        R0(a, b, c, d, e, 0 + i);\n\n        R0(e, a, b, c, d, 1 + i);\n\n        R0(d, e, a, b, c, 2 + i);\n\n        R0(c, d, e, a, b, 3 + i);\n\n        R0(b, c, d, e, a, 4 + i);\n\n    }\n\n    R0(a, b, c, d, e, 15);\n\n    R1(e, a, b, c, d, 16);\n\n    R1(d, e, a, b, c, 17);\n\n    R1(c, d, e, a, b, 18);\n\n    R1(b, c, d, e, a, 19);\n\n    for (i = 20; i < 40; i += 5) {\n\n        R2(a, b, c, d, e, 0 + i);\n\n        R2(e, a, b, c, d, 1 + i);\n\n        R2(d, e, a, b, c, 2 + i);\n\n        R2(c, d, e, a, b, 3 + i);\n\n        R2(b, c, d, e, a, 4 + i);\n\n    }\n\n    for (; i < 60; i += 5) {\n\n        R3(a, b, c, d, e, 0 + i);\n\n        R3(e, a, b, c, d, 1 + i);\n\n        R3(d, e, a, b, c, 2 + i);\n\n        R3(c, d, e, a, b, 3 + i);\n\n        R3(b, c, d, e, a, 4 + i);\n\n    }\n\n    for (; i < 80; i += 5) {\n\n        R4(a, b, c, d, e, 0 + i);\n\n        R4(e, a, b, c, d, 1 + i);\n\n        R4(d, e, a, b, c, 2 + i);\n\n        R4(c, d, e, a, b, 3 + i);\n\n        R4(b, c, d, e, a, 4 + i);\n\n    }\n\n#endif\n\n    state[0] += a;\n\n    state[1] += b;\n\n    state[2] += c;\n\n    state[3] += d;\n\n    state[4] += e;\n\n}\n", "idx": 5826, "_split": "test", "_hash": "3d0ca889284b6991c3300cd2f4c03aac"}
{"project": "FFmpeg", "commit_id": "a8bdf2405c6027f45a899eaaa6ba74e97c1c2701", "target": 1, "func": "static av_cold int amr_nb_encode_init(AVCodecContext *avctx)\n\n{\n\n    AMRContext *s = avctx->priv_data;\n\n\n\n    if (avctx->sample_rate != 8000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only 8000Hz sample rate supported\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    if (avctx->channels != 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono supported\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    avctx->frame_size  = 160;\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n\n\n\n\n    s->enc_state = Encoder_Interface_init(s->enc_dtx);\n\n    if (!s->enc_state) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Encoder_Interface_init error\\n\");\n\n\n        return -1;\n\n    }\n\n\n\n    s->enc_mode    = get_bitrate_mode(avctx->bit_rate, avctx);\n\n    s->enc_bitrate = avctx->bit_rate;\n\n\n\n    return 0;\n\n}", "idx": 5845, "_split": "test", "_hash": "6bb36f7bf1091807573dbd929dfc66c1"}
{"project": "FFmpeg", "commit_id": "c6bdc90890250ce351b260eff69ce3c0d0745a62", "target": 1, "func": "void help(void)\n\n{\n\n    printf(\"dct-test [-i] [<test-number>]\\n\"\n\n           \"test-number 0 -> test with random matrixes\\n\"\n\n           \"            1 -> test with random sparse matrixes\\n\"\n\n           \"            2 -> do 3. test from mpeg4 std\\n\"\n\n           \"-i          test IDCT implementations\\n\"\n\n           \"-4          test IDCT248 implementations\\n\");\n\n    exit(1);\n\n}\n", "idx": 5846, "_split": "test", "_hash": "dc531d09bec7ff792249a474c93e6313"}
{"project": "FFmpeg", "commit_id": "e3052ce7b177164da8aecfec065650fa5733e2d1", "target": 1, "func": "static int get_num(ByteIOContext *pb, int *len)\n\n{\n\n    int n, n1;\n\n\n\n    n = get_be16(pb);\n\n    (*len)-=2;\n\n//    n &= 0x7FFF;\n\n    if (n >= 0x4000) {\n\n        return n - 0x4000;\n\n    } else {\n\n        n1 = get_be16(pb);\n\n        (*len)-=2;\n\n        return (n << 16) | n1;\n\n    }\n\n}\n", "idx": 5864, "_split": "test", "_hash": "feb4db361906ce2544f0e245377fbef6"}
{"project": "FFmpeg", "commit_id": "d6945aeee419a8417b8019c7c92227e12e45b7ad", "target": 1, "func": "static void FUNCC(ff_h264_add_pixels8)(uint8_t *_dst, int16_t *_src, int stride)\n\n{\n\n    int i;\n\n    pixel *dst = (pixel *) _dst;\n\n    dctcoef *src = (dctcoef *) _src;\n\n    stride /= sizeof(pixel);\n\n\n\n    for (i = 0; i < 8; i++) {\n\n        dst[0] += src[0];\n\n        dst[1] += src[1];\n\n        dst[2] += src[2];\n\n        dst[3] += src[3];\n\n        dst[4] += src[4];\n\n        dst[5] += src[5];\n\n        dst[6] += src[6];\n\n        dst[7] += src[7];\n\n\n\n        dst += stride;\n\n        src += 8;\n\n    }\n\n\n\n    memset(_src, 0, sizeof(dctcoef) * 64);\n\n}\n", "idx": 5905, "_split": "test", "_hash": "221a7fb8bbbcd953cb4dd9400f82d608"}
{"project": "FFmpeg", "commit_id": "fbaf75b166cd067cf383a75ffcccb1e2b370bf6d", "target": 1, "func": "static int output_frame(H264Context *h, AVFrame *dst, AVFrame *src)\n\n{\n\n    int i;\n\n    int ret = av_frame_ref(dst, src);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (!h->sps.crop)\n\n        return 0;\n\n\n\n    for (i = 0; i < 3; i++) {\n\n        int hshift = (i > 0) ? h->chroma_x_shift : 0;\n\n        int vshift = (i > 0) ? h->chroma_y_shift : 0;\n\n        int off    = ((h->sps.crop_left >> hshift) << h->pixel_shift) +\n\n            (h->sps.crop_top  >> vshift) * dst->linesize[i];\n\n        dst->data[i] += off;\n\n    }\n\n    return 0;\n\n}\n", "idx": 5908, "_split": "test", "_hash": "7e01d45b46ec9080baf0f9e7375cf635"}
{"project": "FFmpeg", "commit_id": "33f58c3616d2870d3861da68217ef9d05cc5047a", "target": 1, "func": "static int idcin_read_packet(AVFormatContext *s,\n\n                             AVPacket *pkt)\n\n{\n\n    int ret;\n\n    unsigned int command;\n\n    unsigned int chunk_size;\n\n    IdcinDemuxContext *idcin = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int i;\n\n    int palette_scale;\n\n    unsigned char r, g, b;\n\n    unsigned char palette_buffer[768];\n\n    uint32_t palette[256];\n\n\n\n    if (s->pb->eof_reached)\n\n        return AVERROR(EIO);\n\n\n\n    if (idcin->next_chunk_is_video) {\n\n        command = avio_rl32(pb);\n\n        if (command == 2) {\n\n            return AVERROR(EIO);\n\n        } else if (command == 1) {\n\n            /* trigger a palette change */\n\n            if (avio_read(pb, palette_buffer, 768) != 768)\n\n                return AVERROR(EIO);\n\n            /* scale the palette as necessary */\n\n            palette_scale = 2;\n\n            for (i = 0; i < 768; i++)\n\n                if (palette_buffer[i] > 63) {\n\n                    palette_scale = 0;\n\n                    break;\n\n\n\n\n            for (i = 0; i < 256; i++) {\n\n                r = palette_buffer[i * 3    ] << palette_scale;\n\n                g = palette_buffer[i * 3 + 1] << palette_scale;\n\n                b = palette_buffer[i * 3 + 2] << palette_scale;\n\n                palette[i] = (r << 16) | (g << 8) | (b);\n\n\n\n\n\n        chunk_size = avio_rl32(pb);\n\n\n\n\n\n        /* skip the number of decoded bytes (always equal to width * height) */\n\n        avio_skip(pb, 4);\n\n        chunk_size -= 4;\n\n        ret= av_get_packet(pb, pkt, chunk_size);\n\n        if (ret < 0)\n\n            return ret;\n\n        if (command == 1) {\n\n            uint8_t *pal;\n\n\n\n            pal = av_packet_new_side_data(pkt, AV_PKT_DATA_PALETTE,\n\n                                          AVPALETTE_SIZE);\n\n            if (ret < 0)\n\n                return ret;\n\n            memcpy(pal, palette, AVPALETTE_SIZE);\n\n            pkt->flags |= AV_PKT_FLAG_KEY;\n\n\n        pkt->stream_index = idcin->video_stream_index;\n\n        pkt->duration     = 1;\n\n    } else {\n\n        /* send out the audio chunk */\n\n        if (idcin->current_audio_chunk)\n\n            chunk_size = idcin->audio_chunk_size2;\n\n        else\n\n            chunk_size = idcin->audio_chunk_size1;\n\n        ret= av_get_packet(pb, pkt, chunk_size);\n\n        if (ret < 0)\n\n            return ret;\n\n        pkt->stream_index = idcin->audio_stream_index;\n\n        pkt->duration     = chunk_size / idcin->block_align;\n\n\n\n        idcin->current_audio_chunk ^= 1;\n\n\n\n\n    if (idcin->audio_present)\n\n        idcin->next_chunk_is_video ^= 1;\n\n\n\n    return ret;\n", "idx": 5965, "_split": "test", "_hash": "5f6b9f216fea48df9f9d958a0ce6ee48"}
{"project": "FFmpeg", "commit_id": "009f829dde811af654af7110326aea3a72c05d5e", "target": 1, "func": "static inline void RENAME(yuv2rgb555_2)(SwsContext *c, const uint16_t *buf0,\n\n                                        const uint16_t *buf1, const uint16_t *ubuf0,\n\n                                        const uint16_t *ubuf1, const uint16_t *vbuf0,\n\n                                        const uint16_t *vbuf1, const uint16_t *abuf0,\n\n                                        const uint16_t *abuf1, uint8_t *dest,\n\n                                        int dstW, int yalpha, int uvalpha, int y)\n\n{\n\n    x86_reg uv_off = c->uv_off << 1;\n\n\n\n    //Note 8280 == DSTW_OFFSET but the preprocessor can't handle that there :(\n\n    __asm__ volatile(\n\n        \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n        \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n        \"push %%\"REG_BP\"                        \\n\\t\"\n\n        YSCALEYUV2RGB(%%REGBP, %5, %6)\n\n        \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n        /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n        \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n        \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n        \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n        WRITERGB15(%%REGb, 8280(%5), %%REGBP)\n\n        \"pop %%\"REG_BP\"                         \\n\\t\"\n\n        \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n        :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n           \"a\" (&c->redDither), \"m\"(uv_off)\n\n    );\n\n}\n", "idx": 5981, "_split": "test", "_hash": "b9986b62c264dcccbb1707cab70e1d7b"}
{"project": "FFmpeg", "commit_id": "f7a02d5d694bcef993b0229c9e57f22421fed637", "target": 0, "func": "static int output_packet(InputStream *ist, const AVPacket *pkt)\n\n{\n\n    int ret = 0, i;\n\n    int got_output;\n\n\n\n    AVPacket avpkt;\n\n    if (!ist->saw_first_ts) {\n\n        ist->dts = ist->st->avg_frame_rate.num ? - ist->st->codec->has_b_frames * AV_TIME_BASE / av_q2d(ist->st->avg_frame_rate) : 0;\n\n        ist->pts = 0;\n\n        if (pkt != NULL && pkt->pts != AV_NOPTS_VALUE && !ist->decoding_needed) {\n\n            ist->dts += av_rescale_q(pkt->pts, ist->st->time_base, AV_TIME_BASE_Q);\n\n            ist->pts = ist->dts; //unused but better to set it to a value thats not totally wrong\n\n        }\n\n        ist->saw_first_ts = 1;\n\n    }\n\n\n\n    if (ist->next_dts == AV_NOPTS_VALUE)\n\n        ist->next_dts = ist->dts;\n\n    if (ist->next_pts == AV_NOPTS_VALUE)\n\n        ist->next_pts = ist->pts;\n\n\n\n    if (pkt == NULL) {\n\n        /* EOF handling */\n\n        av_init_packet(&avpkt);\n\n        avpkt.data = NULL;\n\n        avpkt.size = 0;\n\n        goto handle_eof;\n\n    } else {\n\n        avpkt = *pkt;\n\n    }\n\n\n\n    if (pkt->dts != AV_NOPTS_VALUE) {\n\n        ist->next_dts = ist->dts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n        if (ist->st->codec->codec_type != AVMEDIA_TYPE_VIDEO || !ist->decoding_needed)\n\n            ist->next_pts = ist->pts = ist->dts;\n\n    }\n\n\n\n    // while we have more to decode or while the decoder did output something on EOF\n\n    while (ist->decoding_needed && (avpkt.size > 0 || (!pkt && got_output))) {\n\n        int duration;\n\n    handle_eof:\n\n\n\n        ist->pts = ist->next_pts;\n\n        ist->dts = ist->next_dts;\n\n\n\n        if (avpkt.size && avpkt.size != pkt->size) {\n\n            av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING,\n\n                   \"Multiple frames in a packet from stream %d\\n\", pkt->stream_index);\n\n            ist->showed_multi_packet_warning = 1;\n\n        }\n\n\n\n        switch (ist->st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ret = decode_audio    (ist, &avpkt, &got_output);\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            ret = decode_video    (ist, &avpkt, &got_output);\n\n            if (avpkt.duration) {\n\n                duration = av_rescale_q(avpkt.duration, ist->st->time_base, AV_TIME_BASE_Q);\n\n            } else if(ist->st->codec->time_base.num != 0 && ist->st->codec->time_base.den != 0) {\n\n                int ticks= ist->st->parser ? ist->st->parser->repeat_pict+1 : ist->st->codec->ticks_per_frame;\n\n                duration = ((int64_t)AV_TIME_BASE *\n\n                                ist->st->codec->time_base.num * ticks) /\n\n                                ist->st->codec->time_base.den;\n\n            } else\n\n                duration = 0;\n\n\n\n            if(ist->dts != AV_NOPTS_VALUE && duration) {\n\n                ist->next_dts += duration;\n\n            }else\n\n                ist->next_dts = AV_NOPTS_VALUE;\n\n\n\n            if (got_output)\n\n                ist->next_pts += duration; //FIXME the duration is not correct in some cases\n\n            break;\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            ret = transcode_subtitles(ist, &avpkt, &got_output);\n\n            break;\n\n        default:\n\n            return -1;\n\n        }\n\n\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        avpkt.dts=\n\n        avpkt.pts= AV_NOPTS_VALUE;\n\n\n\n        // touch data and size only if not EOF\n\n        if (pkt) {\n\n            if(ist->st->codec->codec_type != AVMEDIA_TYPE_AUDIO)\n\n                ret = avpkt.size;\n\n            avpkt.data += ret;\n\n            avpkt.size -= ret;\n\n        }\n\n        if (!got_output) {\n\n            continue;\n\n        }\n\n    }\n\n\n\n    /* handle stream copy */\n\n    if (!ist->decoding_needed) {\n\n        rate_emu_sleep(ist);\n\n        ist->dts = ist->next_dts;\n\n        switch (ist->st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ist->next_dts += ((int64_t)AV_TIME_BASE * ist->st->codec->frame_size) /\n\n                             ist->st->codec->sample_rate;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if (pkt->duration) {\n\n                ist->next_dts += av_rescale_q(pkt->duration, ist->st->time_base, AV_TIME_BASE_Q);\n\n            } else if(ist->st->codec->time_base.num != 0) {\n\n                int ticks= ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->st->codec->ticks_per_frame;\n\n                ist->next_dts += ((int64_t)AV_TIME_BASE *\n\n                                  ist->st->codec->time_base.num * ticks) /\n\n                                  ist->st->codec->time_base.den;\n\n            }\n\n            break;\n\n        }\n\n        ist->pts = ist->dts;\n\n        ist->next_pts = ist->next_dts;\n\n    }\n\n    for (i = 0; pkt && i < nb_output_streams; i++) {\n\n        OutputStream *ost = output_streams[i];\n\n\n\n        if (!check_output_constraints(ist, ost) || ost->encoding_needed)\n\n            continue;\n\n\n\n        do_streamcopy(ist, ost, pkt);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 6008, "_split": "test", "_hash": "2d0c63fc2b7ef1a4a84b3a43f92cea35"}
{"project": "FFmpeg", "commit_id": "df824548d031dbfc5fa86ea9e0c652bd086b55c4", "target": 0, "func": "static int eightsvx_decode_frame(AVCodecContext *avctx, void *data,\n\n                                 int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    EightSvxContext *esc = avctx->priv_data;\n\n    int n, out_data_size;\n\n    int ch, ret;\n\n    uint8_t *src;\n\n\n\n    /* decode and interleave the first packet */\n\n    if (!esc->samples && avpkt) {\n\n        int packet_size = avpkt->size;\n\n\n\n        if (packet_size % avctx->channels) {\n\n            av_log(avctx, AV_LOG_WARNING, \"Packet with odd size, ignoring last byte\\n\");\n\n            if (packet_size < avctx->channels)\n\n                return packet_size;\n\n            packet_size -= packet_size % avctx->channels;\n\n        }\n\n        esc->samples_size = !esc->table ?\n\n            packet_size : avctx->channels + (packet_size-avctx->channels) * 2;\n\n        if (!(esc->samples = av_malloc(esc->samples_size)))\n\n            return AVERROR(ENOMEM);\n\n\n\n        /* decompress */\n\n        if (esc->table) {\n\n            const uint8_t *buf = avpkt->data;\n\n            uint8_t *dst;\n\n            int buf_size = avpkt->size;\n\n            int i, n = esc->samples_size;\n\n\n\n            if (buf_size < 2) {\n\n                av_log(avctx, AV_LOG_ERROR, \"packet size is too small\\n\");\n\n                return AVERROR(EINVAL);\n\n            }\n\n\n\n            /* the uncompressed starting value is contained in the first byte */\n\n            dst = esc->samples;\n\n            for (i = 0; i < avctx->channels; i++) {\n\n                *(dst++) = buf[0]+128;\n\n                delta_decode(dst, buf + 1, buf_size / avctx->channels - 1, (buf[0]+128)&0xFF, esc->table);\n\n                buf += buf_size / avctx->channels;\n\n                dst += n / avctx->channels - 1;\n\n            }\n\n        } else {\n\n            raw_decode(esc->samples, avpkt->data, esc->samples_size);\n\n        }\n\n    }\n\n\n\n    /* get output buffer */\n\n    av_assert1(!(esc->samples_size % avctx->channels || esc->samples_idx % avctx->channels));\n\n    esc->frame.nb_samples = FFMIN(MAX_FRAME_SIZE, esc->samples_size - esc->samples_idx)  / avctx->channels;\n\n    if ((ret = avctx->get_buffer(avctx, &esc->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = esc->frame;\n\n\n\n    out_data_size = esc->frame.nb_samples;\n\n    for (ch = 0; ch<avctx->channels; ch++) {\n\n        src = esc->samples + esc->samples_idx / avctx->channels + ch * esc->samples_size / avctx->channels;\n\n        memcpy(esc->frame.data[ch], src, out_data_size);\n\n    }\n\n    out_data_size *= avctx->channels;\n\n    esc->samples_idx += out_data_size;\n\n\n\n    return esc->table ?\n\n        (avctx->frame_number == 0)*2 + out_data_size / 2 :\n\n        out_data_size;\n\n}\n", "idx": 6063, "_split": "test", "_hash": "80bda3a4b9b96159274be21b7751cf2f"}
{"project": "FFmpeg", "commit_id": "1eaff98c8320d9ba48fbaec2a558f31f4104de98", "target": 1, "func": "static int flv_write_trailer(AVFormatContext *s)\n\n{\n\n    int64_t file_size;\n\n\n\n    AVIOContext *pb = s->pb;\n\n    FLVContext *flv = s->priv_data;\n\n    int i;\n\n\n\n    /* Add EOS tag */\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVCodecContext *enc = s->streams[i]->codec;\n\n        FLVStreamContext *sc = s->streams[i]->priv_data;\n\n        if (enc->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n            enc->codec_id == AV_CODEC_ID_H264)\n\n            put_avc_eos_tag(pb, sc->last_ts);\n\n    }\n\n\n\n    file_size = avio_tell(pb);\n\n\n\n    /* update information */\n\n    avio_seek(pb, flv->duration_offset, SEEK_SET);\n\n    put_amf_double(pb, flv->duration / (double)1000);\n\n    avio_seek(pb, flv->filesize_offset, SEEK_SET);\n\n    put_amf_double(pb, file_size);\n\n\n\n    avio_seek(pb, file_size, SEEK_SET);\n\n    return 0;\n\n}\n", "idx": 6103, "_split": "test", "_hash": "ef9a3b75fc46942a583898c4c8a3998e"}
{"project": "FFmpeg", "commit_id": "5c720657c23afd798ae0db7c7362eb859a89ab3d", "target": 1, "func": "static int mov_read_cmov(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n#if CONFIG_ZLIB\n\n    AVIOContext ctx;\n\n    uint8_t *cmov_data;\n\n    uint8_t *moov_data; /* uncompressed data */\n\n    long cmov_len, moov_len;\n\n    int ret = -1;\n\n\n\n    avio_rb32(pb); /* dcom atom */\n\n    if (avio_rl32(pb) != MKTAG('d','c','o','m'))\n\n        return AVERROR_INVALIDDATA;\n\n    if (avio_rl32(pb) != MKTAG('z','l','i','b')) {\n\n        av_log(c->fc, AV_LOG_ERROR, \"unknown compression for cmov atom !\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_rb32(pb); /* cmvd atom */\n\n    if (avio_rl32(pb) != MKTAG('c','m','v','d'))\n\n        return AVERROR_INVALIDDATA;\n\n    moov_len = avio_rb32(pb); /* uncompressed size */\n\n    cmov_len = atom.size - 6 * 4;\n\n\n\n    cmov_data = av_malloc(cmov_len);\n\n    if (!cmov_data)\n\n        return AVERROR(ENOMEM);\n\n    moov_data = av_malloc(moov_len);\n\n    if (!moov_data) {\n\n        av_free(cmov_data);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    avio_read(pb, cmov_data, cmov_len);\n\n    if (uncompress (moov_data, (uLongf *) &moov_len, (const Bytef *)cmov_data, cmov_len) != Z_OK)\n\n        goto free_and_return;\n\n    if (ffio_init_context(&ctx, moov_data, moov_len, 0, NULL, NULL, NULL, NULL) != 0)\n\n        goto free_and_return;\n\n    atom.type = MKTAG('m','o','o','v');\n\n    atom.size = moov_len;\n\n    ret = mov_read_default(c, &ctx, atom);\n\nfree_and_return:\n\n    av_free(moov_data);\n\n    av_free(cmov_data);\n\n    return ret;\n\n#else\n\n    av_log(c->fc, AV_LOG_ERROR, \"this file requires zlib support compiled in\\n\");\n\n    return AVERROR(ENOSYS);\n\n#endif\n\n}\n", "idx": 6112, "_split": "test", "_hash": "efe6bb91aa0bbd140b88661a7eac0208"}
{"project": "FFmpeg", "commit_id": "170870b77c8c71304f9eae946d49aa5e30a464bc", "target": 1, "func": "static int sdp_parse_rtpmap(AVFormatContext *s,\n\n                            AVCodecContext *codec, RTSPStream *rtsp_st,\n\n                            int payload_type, const char *p)\n\n{\n\n    char buf[256];\n\n    int i;\n\n    AVCodec *c;\n\n    const char *c_name;\n\n\n\n    /* Loop into AVRtpDynamicPayloadTypes[] and AVRtpPayloadTypes[] and\n\n     * see if we can handle this kind of payload.\n\n     * The space should normally not be there but some Real streams or\n\n     * particular servers (\"RealServer Version 6.1.3.970\", see issue 1658)\n\n     * have a trailing space. */\n\n    get_word_sep(buf, sizeof(buf), \"/ \", &p);\n\n    if (payload_type >= RTP_PT_PRIVATE) {\n\n        RTPDynamicProtocolHandler *handler;\n\n        for (handler = RTPFirstDynamicPayloadHandler;\n\n             handler; handler = handler->next) {\n\n            if (!strcasecmp(buf, handler->enc_name) &&\n\n                codec->codec_type == handler->codec_type) {\n\n                codec->codec_id          = handler->codec_id;\n\n                rtsp_st->dynamic_handler = handler;\n\n                if (handler->open)\n\n                    rtsp_st->dynamic_protocol_context = handler->open();\n\n                break;\n\n            }\n\n        }\n\n    } else {\n\n        /* We are in a standard case\n\n         * (from http://www.iana.org/assignments/rtp-parameters). */\n\n        /* search into AVRtpPayloadTypes[] */\n\n        codec->codec_id = ff_rtp_codec_id(buf, codec->codec_type);\n\n    }\n\n\n\n    c = avcodec_find_decoder(codec->codec_id);\n\n    if (c && c->name)\n\n        c_name = c->name;\n\n    else\n\n        c_name = (char *) NULL;\n\n\n\n    if (c_name) {\n\n        get_word_sep(buf, sizeof(buf), \"/\", &p);\n\n        i = atoi(buf);\n\n        switch (codec->codec_type) {\n\n        case CODEC_TYPE_AUDIO:\n\n            av_log(s, AV_LOG_DEBUG, \"audio codec set to: %s\\n\", c_name);\n\n            codec->sample_rate = RTSP_DEFAULT_AUDIO_SAMPLERATE;\n\n            codec->channels = RTSP_DEFAULT_NB_AUDIO_CHANNELS;\n\n            if (i > 0) {\n\n                codec->sample_rate = i;\n\n                get_word_sep(buf, sizeof(buf), \"/\", &p);\n\n                i = atoi(buf);\n\n                if (i > 0)\n\n                    codec->channels = i;\n\n                // TODO: there is a bug here; if it is a mono stream, and\n\n                // less than 22000Hz, faad upconverts to stereo and twice\n\n                // the frequency.  No problem, but the sample rate is being\n\n                // set here by the sdp line. Patch on its way. (rdm)\n\n            }\n\n            av_log(s, AV_LOG_DEBUG, \"audio samplerate set to: %i\\n\",\n\n                   codec->sample_rate);\n\n            av_log(s, AV_LOG_DEBUG, \"audio channels set to: %i\\n\",\n\n                   codec->channels);\n\n            break;\n\n        case CODEC_TYPE_VIDEO:\n\n            av_log(s, AV_LOG_DEBUG, \"video codec set to: %s\\n\", c_name);\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    return -1;\n\n}\n", "idx": 6125, "_split": "test", "_hash": "50e5bc11b1b5eaeab9deb89f5289d9a1"}
{"project": "FFmpeg", "commit_id": "dcc39ee10e82833ce24aa57926c00ffeb1948198", "target": 0, "func": "void ff_mpv_frame_end(MpegEncContext *s)\n\n{\n\n#if FF_API_XVMC\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    /* redraw edges for the frame if decoding didn't complete */\n\n    // just to make sure that all data is rendered.\n\n    if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration) {\n\n        ff_xvmc_field_end(s);\n\n    } else\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif /* FF_API_XVMC */\n\n\n\n    emms_c();\n\n\n\n    if (s->current_picture.reference)\n\n        ff_thread_report_progress(&s->current_picture_ptr->tf, INT_MAX, 0);\n\n}\n", "idx": 6140, "_split": "test", "_hash": "c18577097fd030a14409063315eaffa8"}
{"project": "FFmpeg", "commit_id": "b67f3d65757e9b08a797f584ee818ad7cfe7b303", "target": 1, "func": "static int read_ffserver_streams(AVFormatContext *s, const char *filename)\n\n{\n\n    int i, err;\n\n    AVFormatContext *ic;\n\n    int nopts = 0;\n\n\n\n    err = av_open_input_file(&ic, filename, NULL, FFM_PACKET_SIZE, NULL);\n\n    if (err < 0)\n\n        return err;\n\n    /* copy stream format */\n\n    s->nb_streams = ic->nb_streams;\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        AVStream *st;\n\n        AVCodec *codec;\n\n\n\n        // FIXME: a more elegant solution is needed\n\n        st = av_mallocz(sizeof(AVStream));\n\n        memcpy(st, ic->streams[i], sizeof(AVStream));\n\n        st->codec = avcodec_alloc_context();\n\n        if (!st->codec) {\n\n            print_error(filename, AVERROR(ENOMEM));\n\n            ffmpeg_exit(1);\n\n        }\n\n        avcodec_copy_context(st->codec, ic->streams[i]->codec);\n\n        s->streams[i] = st;\n\n\n\n        codec = avcodec_find_encoder(st->codec->codec_id);\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (audio_stream_copy) {\n\n                st->stream_copy = 1;\n\n            } else\n\n                choose_sample_fmt(st, codec);\n\n        } else if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            if (video_stream_copy) {\n\n                st->stream_copy = 1;\n\n            } else\n\n                choose_pixel_fmt(st, codec);\n\n        }\n\n\n\n        if(!st->codec->thread_count)\n\n            st->codec->thread_count = 1;\n\n        if(st->codec->thread_count>1)\n\n            avcodec_thread_init(st->codec, st->codec->thread_count);\n\n\n\n        if(st->codec->flags & CODEC_FLAG_BITEXACT)\n\n            nopts = 1;\n\n    }\n\n\n\n    if (!nopts)\n\n        s->timestamp = av_gettime();\n\n\n\n    av_close_input_file(ic);\n\n    return 0;\n\n}\n", "idx": 6160, "_split": "test", "_hash": "608df585f92894b69d7a7d7af469ad0c"}
{"project": "FFmpeg", "commit_id": "ff763351e74550df3b9a0465634d1ec48b15b043", "target": 1, "func": "static void uninit(AVFilterContext *ctx)\n\n{\n\n    ZScaleContext *s = ctx->priv;\n\n\n\n    zimg_filter_graph_free(s->graph);\n\n\n    av_freep(&s->tmp);\n\n    s->tmp_size = 0;\n\n}", "idx": 6165, "_split": "test", "_hash": "509bfd926265965b79e680d1a7079289"}
{"project": "FFmpeg", "commit_id": "3e1028c625e11d9d19376f5c88267de1cee8fa70", "target": 1, "func": "static void lpc_analyze_remodulate(int32_t *decoded, const int coeffs[32],\n\n                                   int order, int qlevel, int len, int bps)\n\n{\n\n    int i, j;\n\n    int ebps = 1 << (bps-1);\n\n    unsigned sigma = 0;\n\n\n\n    for (i = order; i < len; i++)\n\n        sigma |= decoded[i] + ebps;\n\n\n\n    if (sigma < 2*ebps)\n\n        return;\n\n\n\n    for (i = len - 1; i >= order; i--) {\n\n        int64_t p = 0;\n\n        for (j = 0; j < order; j++)\n\n            p += coeffs[j] * (int64_t)decoded[i-order+j];\n\n        decoded[i] -= p >> qlevel;\n\n    }\n\n    for (i = order; i < len; i++, decoded++) {\n\n        int32_t p = 0;\n\n        for (j = 0; j < order; j++)\n\n            p += coeffs[j] * (uint32_t)decoded[j];\n\n        decoded[j] += p >> qlevel;\n\n    }\n\n}\n", "idx": 6272, "_split": "test", "_hash": "309902c642c765e12a5730a660955c0a"}
{"project": "FFmpeg", "commit_id": "b853cfe7eaf13b7d4ff3ceba7098544ccc049df8", "target": 0, "func": "static int read_thread(void *arg)\n\n{\n\n    VideoState *is = arg;\n\n    AVFormatContext *ic = NULL;\n\n    int err, i, ret;\n\n    int st_index[AVMEDIA_TYPE_NB];\n\n    AVPacket pkt1, *pkt = &pkt1;\n\n    int eof = 0;\n\n    int pkt_in_play_range = 0;\n\n    AVDictionaryEntry *t;\n\n    AVDictionary **opts;\n\n    int orig_nb_streams;\n\n    SDL_mutex *wait_mutex = SDL_CreateMutex();\n\n\n\n    memset(st_index, -1, sizeof(st_index));\n\n    is->last_video_stream = is->video_stream = -1;\n\n    is->last_audio_stream = is->audio_stream = -1;\n\n    is->last_subtitle_stream = is->subtitle_stream = -1;\n\n\n\n    ic = avformat_alloc_context();\n\n    ic->interrupt_callback.callback = decode_interrupt_cb;\n\n    ic->interrupt_callback.opaque = is;\n\n    err = avformat_open_input(&ic, is->filename, is->iformat, &format_opts);\n\n    if (err < 0) {\n\n        print_error(is->filename, err);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n    if ((t = av_dict_get(format_opts, \"\", NULL, AV_DICT_IGNORE_SUFFIX))) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Option %s not found.\\n\", t->key);\n\n        ret = AVERROR_OPTION_NOT_FOUND;\n\n        goto fail;\n\n    }\n\n    is->ic = ic;\n\n\n\n    if (genpts)\n\n        ic->flags |= AVFMT_FLAG_GENPTS;\n\n\n\n    opts = setup_find_stream_info_opts(ic, codec_opts);\n\n    orig_nb_streams = ic->nb_streams;\n\n\n\n    err = avformat_find_stream_info(ic, opts);\n\n    if (err < 0) {\n\n        fprintf(stderr, \"%s: could not find codec parameters\\n\", is->filename);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n    for (i = 0; i < orig_nb_streams; i++)\n\n        av_dict_free(&opts[i]);\n\n    av_freep(&opts);\n\n\n\n    if (ic->pb)\n\n        ic->pb->eof_reached = 0; // FIXME hack, ffplay maybe should not use url_feof() to test for the end\n\n\n\n    if (seek_by_bytes < 0)\n\n        seek_by_bytes = !!(ic->iformat->flags & AVFMT_TS_DISCONT);\n\n\n\n    is->max_frame_duration = (ic->iformat->flags & AVFMT_TS_DISCONT) ? 10.0 : 3600.0;\n\n\n\n    /* if seeking requested, we execute it */\n\n    if (start_time != AV_NOPTS_VALUE) {\n\n        int64_t timestamp;\n\n\n\n        timestamp = start_time;\n\n        /* add the stream start time */\n\n        if (ic->start_time != AV_NOPTS_VALUE)\n\n            timestamp += ic->start_time;\n\n        ret = avformat_seek_file(ic, -1, INT64_MIN, timestamp, INT64_MAX, 0);\n\n        if (ret < 0) {\n\n            fprintf(stderr, \"%s: could not seek to position %0.3f\\n\",\n\n                    is->filename, (double)timestamp / AV_TIME_BASE);\n\n        }\n\n    }\n\n\n\n    is->realtime = is_realtime(ic);\n\n\n\n    for (i = 0; i < ic->nb_streams; i++)\n\n        ic->streams[i]->discard = AVDISCARD_ALL;\n\n    if (!video_disable)\n\n        st_index[AVMEDIA_TYPE_VIDEO] =\n\n            av_find_best_stream(ic, AVMEDIA_TYPE_VIDEO,\n\n                                wanted_stream[AVMEDIA_TYPE_VIDEO], -1, NULL, 0);\n\n    if (!audio_disable)\n\n        st_index[AVMEDIA_TYPE_AUDIO] =\n\n            av_find_best_stream(ic, AVMEDIA_TYPE_AUDIO,\n\n                                wanted_stream[AVMEDIA_TYPE_AUDIO],\n\n                                st_index[AVMEDIA_TYPE_VIDEO],\n\n                                NULL, 0);\n\n    if (!video_disable)\n\n        st_index[AVMEDIA_TYPE_SUBTITLE] =\n\n            av_find_best_stream(ic, AVMEDIA_TYPE_SUBTITLE,\n\n                                wanted_stream[AVMEDIA_TYPE_SUBTITLE],\n\n                                (st_index[AVMEDIA_TYPE_AUDIO] >= 0 ?\n\n                                 st_index[AVMEDIA_TYPE_AUDIO] :\n\n                                 st_index[AVMEDIA_TYPE_VIDEO]),\n\n                                NULL, 0);\n\n    if (show_status) {\n\n        av_dump_format(ic, 0, is->filename, 0);\n\n    }\n\n\n\n    is->show_mode = show_mode;\n\n\n\n    /* open the streams */\n\n    if (st_index[AVMEDIA_TYPE_AUDIO] >= 0) {\n\n        stream_component_open(is, st_index[AVMEDIA_TYPE_AUDIO]);\n\n    }\n\n\n\n    ret = -1;\n\n    if (st_index[AVMEDIA_TYPE_VIDEO] >= 0) {\n\n        ret = stream_component_open(is, st_index[AVMEDIA_TYPE_VIDEO]);\n\n    }\n\n    if (is->show_mode == SHOW_MODE_NONE)\n\n        is->show_mode = ret >= 0 ? SHOW_MODE_VIDEO : SHOW_MODE_RDFT;\n\n\n\n    is->refresh_tid = SDL_CreateThread(refresh_thread, is);\n\n\n\n    if (st_index[AVMEDIA_TYPE_SUBTITLE] >= 0) {\n\n        stream_component_open(is, st_index[AVMEDIA_TYPE_SUBTITLE]);\n\n    }\n\n\n\n    if (is->video_stream < 0 && is->audio_stream < 0) {\n\n        fprintf(stderr, \"%s: could not open codecs\\n\", is->filename);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n\n\n    if (infinite_buffer < 0 && is->realtime)\n\n        infinite_buffer = 1;\n\n\n\n    for (;;) {\n\n        if (is->abort_request)\n\n            break;\n\n        if (is->paused != is->last_paused) {\n\n            is->last_paused = is->paused;\n\n            if (is->paused)\n\n                is->read_pause_return = av_read_pause(ic);\n\n            else\n\n                av_read_play(ic);\n\n        }\n\n#if CONFIG_RTSP_DEMUXER || CONFIG_MMSH_PROTOCOL\n\n        if (is->paused &&\n\n                (!strcmp(ic->iformat->name, \"rtsp\") ||\n\n                 (ic->pb && !strncmp(input_filename, \"mmsh:\", 5)))) {\n\n            /* wait 10 ms to avoid trying to get another packet */\n\n            /* XXX: horrible */\n\n            SDL_Delay(10);\n\n            continue;\n\n        }\n\n#endif\n\n        if (is->seek_req) {\n\n            int64_t seek_target = is->seek_pos;\n\n            int64_t seek_min    = is->seek_rel > 0 ? seek_target - is->seek_rel + 2: INT64_MIN;\n\n            int64_t seek_max    = is->seek_rel < 0 ? seek_target - is->seek_rel - 2: INT64_MAX;\n\n// FIXME the +-2 is due to rounding being not done in the correct direction in generation\n\n//      of the seek_pos/seek_rel variables\n\n\n\n            ret = avformat_seek_file(is->ic, -1, seek_min, seek_target, seek_max, is->seek_flags);\n\n            if (ret < 0) {\n\n                fprintf(stderr, \"%s: error while seeking\\n\", is->ic->filename);\n\n            } else {\n\n                if (is->audio_stream >= 0) {\n\n                    packet_queue_flush(&is->audioq);\n\n                    packet_queue_put(&is->audioq, &flush_pkt);\n\n                }\n\n                if (is->subtitle_stream >= 0) {\n\n                    packet_queue_flush(&is->subtitleq);\n\n                    packet_queue_put(&is->subtitleq, &flush_pkt);\n\n                }\n\n                if (is->video_stream >= 0) {\n\n                    packet_queue_flush(&is->videoq);\n\n                    packet_queue_put(&is->videoq, &flush_pkt);\n\n                }\n\n                if (is->seek_flags & AVSEEK_FLAG_BYTE) {\n\n                   //FIXME: use a cleaner way to signal obsolete external clock...\n\n                   update_external_clock_pts(is, (double)AV_NOPTS_VALUE);\n\n                } else {\n\n                   update_external_clock_pts(is, seek_target / (double)AV_TIME_BASE);\n\n                }\n\n            }\n\n            is->seek_req = 0;\n\n            eof = 0;\n\n            if (is->paused)\n\n                step_to_next_frame(is);\n\n        }\n\n        if (is->queue_attachments_req) {\n\n            avformat_queue_attached_pictures(ic);\n\n            is->queue_attachments_req = 0;\n\n        }\n\n\n\n        /* if the queue are full, no need to read more */\n\n        if (infinite_buffer<1 &&\n\n              (is->audioq.size + is->videoq.size + is->subtitleq.size > MAX_QUEUE_SIZE\n\n            || (   (is->audioq   .nb_packets > MIN_FRAMES || is->audio_stream < 0 || is->audioq.abort_request)\n\n                && (is->videoq   .nb_packets > MIN_FRAMES || is->video_stream < 0 || is->videoq.abort_request)\n\n                && (is->subtitleq.nb_packets > MIN_FRAMES || is->subtitle_stream < 0 || is->subtitleq.abort_request)))) {\n\n            /* wait 10 ms */\n\n            SDL_LockMutex(wait_mutex);\n\n            SDL_CondWaitTimeout(is->continue_read_thread, wait_mutex, 10);\n\n            SDL_UnlockMutex(wait_mutex);\n\n            continue;\n\n        }\n\n        if (eof) {\n\n            if (is->video_stream >= 0) {\n\n                av_init_packet(pkt);\n\n                pkt->data = NULL;\n\n                pkt->size = 0;\n\n                pkt->stream_index = is->video_stream;\n\n                packet_queue_put(&is->videoq, pkt);\n\n            }\n\n            if (is->audio_stream >= 0 &&\n\n                is->audio_st->codec->codec->capabilities & CODEC_CAP_DELAY) {\n\n                av_init_packet(pkt);\n\n                pkt->data = NULL;\n\n                pkt->size = 0;\n\n                pkt->stream_index = is->audio_stream;\n\n                packet_queue_put(&is->audioq, pkt);\n\n            }\n\n            SDL_Delay(10);\n\n            if (is->audioq.size + is->videoq.size + is->subtitleq.size == 0) {\n\n                if (loop != 1 && (!loop || --loop)) {\n\n                    stream_seek(is, start_time != AV_NOPTS_VALUE ? start_time : 0, 0, 0);\n\n                } else if (autoexit) {\n\n                    ret = AVERROR_EOF;\n\n                    goto fail;\n\n                }\n\n            }\n\n            eof=0;\n\n            continue;\n\n        }\n\n        ret = av_read_frame(ic, pkt);\n\n        if (ret < 0) {\n\n            if (ret == AVERROR_EOF || url_feof(ic->pb))\n\n                eof = 1;\n\n            if (ic->pb && ic->pb->error)\n\n                break;\n\n            SDL_LockMutex(wait_mutex);\n\n            SDL_CondWaitTimeout(is->continue_read_thread, wait_mutex, 10);\n\n            SDL_UnlockMutex(wait_mutex);\n\n            continue;\n\n        }\n\n        /* check if packet is in play range specified by user, then queue, otherwise discard */\n\n        pkt_in_play_range = duration == AV_NOPTS_VALUE ||\n\n                (pkt->pts - ic->streams[pkt->stream_index]->start_time) *\n\n                av_q2d(ic->streams[pkt->stream_index]->time_base) -\n\n                (double)(start_time != AV_NOPTS_VALUE ? start_time : 0) / 1000000\n\n                <= ((double)duration / 1000000);\n\n        if (pkt->stream_index == is->audio_stream && pkt_in_play_range) {\n\n            packet_queue_put(&is->audioq, pkt);\n\n        } else if (pkt->stream_index == is->video_stream && pkt_in_play_range) {\n\n            packet_queue_put(&is->videoq, pkt);\n\n        } else if (pkt->stream_index == is->subtitle_stream && pkt_in_play_range) {\n\n            packet_queue_put(&is->subtitleq, pkt);\n\n        } else {\n\n            av_free_packet(pkt);\n\n        }\n\n    }\n\n    /* wait until the end */\n\n    while (!is->abort_request) {\n\n        SDL_Delay(100);\n\n    }\n\n\n\n    ret = 0;\n\n fail:\n\n    /* close each stream */\n\n    if (is->audio_stream >= 0)\n\n        stream_component_close(is, is->audio_stream);\n\n    if (is->video_stream >= 0)\n\n        stream_component_close(is, is->video_stream);\n\n    if (is->subtitle_stream >= 0)\n\n        stream_component_close(is, is->subtitle_stream);\n\n    if (is->ic) {\n\n        avformat_close_input(&is->ic);\n\n    }\n\n\n\n    if (ret != 0) {\n\n        SDL_Event event;\n\n\n\n        event.type = FF_QUIT_EVENT;\n\n        event.user.data1 = is;\n\n        SDL_PushEvent(&event);\n\n    }\n\n    SDL_DestroyMutex(wait_mutex);\n\n    return 0;\n\n}\n", "idx": 6277, "_split": "test", "_hash": "c05c12e4676e4b9a24d5d6b958f20809"}
{"project": "FFmpeg", "commit_id": "859bb3cfee28efff9c965d4c9320c7837b85849e", "target": 0, "func": "int ff_xvmc_field_start(MpegEncContext *s, AVCodecContext *avctx)\n\n{\n\n    struct xvmc_pix_fmt *last, *next, *render = (struct xvmc_pix_fmt*)s->current_picture.data[2];\n\n    const int mb_block_count = 4 + (1 << s->chroma_format);\n\n\n\n    assert(avctx);\n\n    if (!render || render->xvmc_id != AV_XVMC_ID ||\n\n        !render->data_blocks || !render->mv_blocks) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Render token doesn't look as expected.\\n\");\n\n        return -1; // make sure that this is a render packet\n\n    }\n\n\n\n    if (render->filled_mv_blocks_num) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Rendering surface contains %i unprocessed blocks.\\n\",\n\n               render->filled_mv_blocks_num);\n\n        return -1;\n\n    }\n\n    if (render->allocated_mv_blocks   < 1 ||\n\n        render->allocated_data_blocks <  render->allocated_mv_blocks*mb_block_count ||\n\n        render->start_mv_blocks_num   >= render->allocated_mv_blocks                ||\n\n        render->next_free_data_block_num >\n\n                        render->allocated_data_blocks -\n\n                        mb_block_count*(render->allocated_mv_blocks-render->start_mv_blocks_num)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Rendering surface doesn't provide enough block structures to work with.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    render->picture_structure = s->picture_structure;\n\n    render->flags             = s->first_field ? 0 : XVMC_SECOND_FIELD;\n\n    render->p_future_surface  = NULL;\n\n    render->p_past_surface    = NULL;\n\n\n\n    switch(s->pict_type) {\n\n        case  FF_I_TYPE:\n\n            return 0; // no prediction from other frames\n\n        case  FF_B_TYPE:\n\n            next = (struct xvmc_pix_fmt*)s->next_picture.data[2];\n\n            if (!next)\n\n                return -1;\n\n            if (next->xvmc_id != AV_XVMC_ID)\n\n                return -1;\n\n            render->p_future_surface = next->p_surface;\n\n            // no return here, going to set forward prediction\n\n        case  FF_P_TYPE:\n\n            last = (struct xvmc_pix_fmt*)s->last_picture.data[2];\n\n            if (!last)\n\n                last = render; // predict second field from the first\n\n            if (last->xvmc_id != AV_XVMC_ID)\n\n                return -1;\n\n            render->p_past_surface = last->p_surface;\n\n            return 0;\n\n    }\n\n\n\nreturn -1;\n\n}\n", "idx": 6293, "_split": "test", "_hash": "2d6a261aa9e279166a37c00642db7c9d"}
{"project": "FFmpeg", "commit_id": "0eec40b713eee84e2aec8af35ccce059817cad2a", "target": 1, "func": "static int calculate_bitrate(AVFormatContext *s)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    int i, j;\n\n    int64_t lensum = 0;\n\n    int64_t maxpos = 0;\n\n\n\n    for (i = 0; i<s->nb_streams; i++) {\n\n        int64_t len = 0;\n\n        AVStream *st = s->streams[i];\n\n\n\n        if (!st->nb_index_entries)\n\n            continue;\n\n\n\n        for (j = 0; j < st->nb_index_entries; j++)\n\n            len += st->index_entries[j].size;\n\n        maxpos = FFMAX(maxpos, st->index_entries[j-1].pos);\n\n        lensum += len;\n\n    }\n\n    if (maxpos < avi->io_fsize*9/10) // index does not cover the whole file\n\n        return 0;\n\n    if (lensum*9/10 > maxpos || lensum < maxpos*9/10) // frame sum and filesize mismatch\n\n        return 0;\n\n\n\n    for (i = 0; i<s->nb_streams; i++) {\n\n        int64_t len = 0;\n\n        AVStream *st = s->streams[i];\n\n        int64_t duration;\n\n\n\n        for (j = 0; j < st->nb_index_entries; j++)\n\n            len += st->index_entries[j].size;\n\n\n\n        if (st->nb_index_entries < 2 || st->codec->bit_rate > 0)\n\n            continue;\n\n        duration = st->index_entries[j-1].timestamp - st->index_entries[0].timestamp;\n\n        st->codec->bit_rate = av_rescale(8*len, st->time_base.den, duration * st->time_base.num);\n\n    }\n\n    return 1;\n\n}\n", "idx": 6307, "_split": "test", "_hash": "5c20619c2cd15e2ff140278fe3e93692"}
{"project": "FFmpeg", "commit_id": "2da0d70d5eebe42f9fcd27ee554419ebe2a5da06", "target": 1, "func": "static inline void RENAME(yuy2ToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1, uint8_t *src2, long width)\n\n{\n\n#ifdef HAVE_MMX\n\n\tasm volatile(\n\n\t\t\"movq \"MANGLE(bm01010101)\", %%mm4\\n\\t\"\n\n\t\t\"mov %0, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"movq (%1, %%\"REG_a\",4), %%mm0\t\\n\\t\"\n\n\t\t\"movq 8(%1, %%\"REG_a\",4), %%mm1\t\\n\\t\"\n\n\t\t\"psrlw $8, %%mm0\t\t\\n\\t\"\n\n\t\t\"psrlw $8, %%mm1\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"psrlw $8, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm1, %%mm1\t\t\\n\\t\"\n\n\t\t\"movd %%mm0, (%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"movd %%mm1, (%2, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"add $4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t: : \"g\" (-width), \"r\" (src1+width*4), \"r\" (dstU+width), \"r\" (dstV+width)\n\n\t\t: \"%\"REG_a\n\n\t);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tdstU[i]= src1[4*i + 1];\n\n\t\tdstV[i]= src1[4*i + 3];\n\n\t}\n\n#endif\n\n        assert(src1 == src2);\n\n}\n", "idx": 6432, "_split": "test", "_hash": "9dd06929f7766b9c5828c0df4e4b031f"}
{"project": "FFmpeg", "commit_id": "fdbbf2e0fc1bb91a5d735a49f39337eb172e68a7", "target": 0, "func": "static void h261_v_loop_filter_c(uint8_t *dest,uint8_t *src, int stride){\n\n    int i,j,xy,yz;\n\n    int res;\n\n    for(i=0; i<8; i++){\n\n        for(j=1; j<7; j++){\n\n            xy = j * stride + i;\n\n            yz = j * 8 + i;\n\n            res = (int)src[yz-1*8] + ((int)(src[yz+0*8]) * 2) + (int)src[yz+1*8];\n\n            res +=2;\n\n            res >>=2;\n\n            dest[xy] = (uint8_t)res;\n\n        }\n\n    }\n\n}\n", "idx": 6452, "_split": "test", "_hash": "36e29a28872fefba7980198a2ff41847"}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(uyvyToY)(uint8_t *dst, const uint8_t *src, int width, uint32_t *unused)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(\n\n        \"mov                  %0, %%\"REG_a\"         \\n\\t\"\n\n        \"1:                                         \\n\\t\"\n\n        \"movq  (%1, %%\"REG_a\",2), %%mm0             \\n\\t\"\n\n        \"movq 8(%1, %%\"REG_a\",2), %%mm1             \\n\\t\"\n\n        \"psrlw                $8, %%mm0             \\n\\t\"\n\n        \"psrlw                $8, %%mm1             \\n\\t\"\n\n        \"packuswb          %%mm1, %%mm0             \\n\\t\"\n\n        \"movq              %%mm0, (%2, %%\"REG_a\")   \\n\\t\"\n\n        \"add                  $8, %%\"REG_a\"         \\n\\t\"\n\n        \" js                  1b                    \\n\\t\"\n\n        : : \"g\" ((x86_reg)-width), \"r\" (src+width*2), \"r\" (dst+width)\n\n        : \"%\"REG_a\n\n    );\n\n#else\n\n    int i;\n\n    for (i=0; i<width; i++)\n\n        dst[i]= src[2*i+1];\n\n#endif\n\n}\n", "idx": 6455, "_split": "test", "_hash": "c0d6614a79d7307f6d112253c31b3260"}
{"project": "FFmpeg", "commit_id": "951e715cebfaffced7f13c1525771ff917fe1d38", "target": 1, "func": "static int video_thread(void *arg)\n\n{\n\n    VideoState *is = arg;\n\n    AVFrame *frame = avcodec_alloc_frame();\n\n    int64_t pts_int;\n\n    double pts;\n\n    int ret;\n\n\n\n#if CONFIG_AVFILTER\n\n    AVFilterGraph *graph = avfilter_graph_alloc();\n\n    AVFilterContext *filt_out = NULL;\n\n    int64_t pos;\n\n    int last_w = is->video_st->codec->width;\n\n    int last_h = is->video_st->codec->height;\n\n\n\n    if ((ret = configure_video_filters(graph, is, vfilters)) < 0)\n\n        goto the_end;\n\n    filt_out = is->out_video_filter;\n\n#endif\n\n\n\n    for (;;) {\n\n#if !CONFIG_AVFILTER\n\n        AVPacket pkt;\n\n#else\n\n        AVFilterBufferRef *picref;\n\n        AVRational tb;\n\n#endif\n\n        while (is->paused && !is->videoq.abort_request)\n\n            SDL_Delay(10);\n\n#if CONFIG_AVFILTER\n\n        if (   last_w != is->video_st->codec->width\n\n            || last_h != is->video_st->codec->height) {\n\n            av_dlog(NULL, \"Changing size %dx%d -> %dx%d\\n\", last_w, last_h,\n\n                    is->video_st->codec->width, is->video_st->codec->height);\n\n            avfilter_graph_free(&graph);\n\n            graph = avfilter_graph_alloc();\n\n            if ((ret = configure_video_filters(graph, is, vfilters)) < 0)\n\n                goto the_end;\n\n            filt_out = is->out_video_filter;\n\n            last_w = is->video_st->codec->width;\n\n            last_h = is->video_st->codec->height;\n\n        }\n\n        ret = get_filtered_video_frame(filt_out, frame, &picref, &tb);\n\n        if (picref) {\n\n            pts_int = picref->pts;\n\n            pos     = picref->pos;\n\n            frame->opaque = picref;\n\n        }\n\n\n\n        if (av_cmp_q(tb, is->video_st->time_base)) {\n\n            av_unused int64_t pts1 = pts_int;\n\n            pts_int = av_rescale_q(pts_int, tb, is->video_st->time_base);\n\n            av_dlog(NULL, \"video_thread(): \"\n\n                    \"tb:%d/%d pts:%\"PRId64\" -> tb:%d/%d pts:%\"PRId64\"\\n\",\n\n                    tb.num, tb.den, pts1,\n\n                    is->video_st->time_base.num, is->video_st->time_base.den, pts_int);\n\n        }\n\n#else\n\n        ret = get_video_frame(is, frame, &pts_int, &pkt);\n\n#endif\n\n\n\n        if (ret < 0)\n\n            goto the_end;\n\n\n\n        if (!ret)\n\n            continue;\n\n\n\n        pts = pts_int * av_q2d(is->video_st->time_base);\n\n\n\n#if CONFIG_AVFILTER\n\n        ret = output_picture2(is, frame, pts, pos);\n\n#else\n\n        ret = output_picture2(is, frame, pts,  pkt.pos);\n\n        av_free_packet(&pkt);\n\n#endif\n\n        if (ret < 0)\n\n            goto the_end;\n\n\n\n        if (step)\n\n            if (cur_stream)\n\n                stream_pause(cur_stream);\n\n    }\n\n the_end:\n\n#if CONFIG_AVFILTER\n\n    avfilter_graph_free(&graph);\n\n#endif\n\n    av_free(frame);\n\n    return 0;\n\n}\n", "idx": 6489, "_split": "test", "_hash": "833c0812b5d17b80adbd41d421c54851"}
{"project": "FFmpeg", "commit_id": "5d20f19be25c973fe10d0d17db9245002585710d", "target": 1, "func": "int av_aes_init(AVAES *a, const uint8_t *key, int key_bits, int decrypt)\n\n{\n\n    int i, j, t, rconpointer = 0;\n\n    uint8_t tk[8][4];\n\n    int KC = key_bits >> 5;\n\n    int rounds = KC + 6;\n\n    uint8_t log8[256];\n\n    uint8_t alog8[512];\n\n\n\n    if (!enc_multbl[FF_ARRAY_ELEMS(enc_multbl)-1][FF_ARRAY_ELEMS(enc_multbl[0])-1]) {\n\n        j = 1;\n\n        for (i = 0; i < 255; i++) {\n\n            alog8[i] = alog8[i + 255] = j;\n\n            log8[j] = i;\n\n            j ^= j + j;\n\n            if (j > 255)\n\n                j ^= 0x11B;\n\n        }\n\n        for (i = 0; i < 256; i++) {\n\n            j = i ? alog8[255 - log8[i]] : 0;\n\n            j ^= (j << 1) ^ (j << 2) ^ (j << 3) ^ (j << 4);\n\n            j = (j ^ (j >> 8) ^ 99) & 255;\n\n            inv_sbox[j] = i;\n\n            sbox[i] = j;\n\n        }\n\n        init_multbl2(dec_multbl[0], (const int[4]) { 0xe, 0x9, 0xd, 0xb },\n\n                     log8, alog8, inv_sbox);\n\n        init_multbl2(enc_multbl[0], (const int[4]) { 0x2, 0x1, 0x1, 0x3 },\n\n                     log8, alog8, sbox);\n\n    }\n\n\n\n    if (key_bits != 128 && key_bits != 192 && key_bits != 256)\n\n        return -1;\n\n\n\n    a->rounds = rounds;\n\n\n\n    memcpy(tk, key, KC * 4);\n\n\n\n    for (t = 0; t < (rounds + 1) * 16;) {\n\n        memcpy(a->round_key[0].u8 + t, tk, KC * 4);\n\n        t += KC * 4;\n\n\n\n        for (i = 0; i < 4; i++)\n\n            tk[0][i] ^= sbox[tk[KC - 1][(i + 1) & 3]];\n\n        tk[0][0] ^= rcon[rconpointer++];\n\n\n\n        for (j = 1; j < KC; j++) {\n\n            if (KC != 8 || j != KC >> 1)\n\n                for (i = 0; i < 4; i++)\n\n                    tk[j][i] ^= tk[j - 1][i];\n\n            else\n\n                for (i = 0; i < 4; i++)\n\n                    tk[j][i] ^= sbox[tk[j - 1][i]];\n\n        }\n\n    }\n\n\n\n    if (decrypt) {\n\n        for (i = 1; i < rounds; i++) {\n\n            av_aes_block tmp[3];\n\n            tmp[2] = a->round_key[i];\n\n            subshift(&tmp[1], 0, sbox);\n\n            mix(tmp, dec_multbl, 1, 3);\n\n            a->round_key[i] = tmp[0];\n\n        }\n\n    } else {\n\n        for (i = 0; i < (rounds + 1) >> 1; i++) {\n\n            FFSWAP(av_aes_block, a->round_key[i], a->round_key[rounds-i]);\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 6509, "_split": "test", "_hash": "09661c7bff93f717b384dcec0f371622"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(yv12touyvy)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n\tunsigned int width, unsigned int height,\n\n\tint lumStride, int chromStride, int dstStride)\n\n{\n\n\t//FIXME interpolate chroma\n\n\tRENAME(yuvPlanartouyvy)(ysrc, usrc, vsrc, dst, width, height, lumStride, chromStride, dstStride, 2);\n\n}\n", "idx": 6519, "_split": "test", "_hash": "410348d1748ccdcf1a4f660f1fd4476e"}
{"project": "FFmpeg", "commit_id": "b04665ac028d26747396eaf4dbf9188225a6f2a1", "target": 0, "func": "static int opt_preset(const char *opt, const char *arg)\n\n{\n\n    FILE *f=NULL;\n\n    char filename[1000], tmp[1000], tmp2[1000], line[1000];\n\n    int i;\n\n    const char *base[3]= { getenv(\"HOME\"),\n\n                           \"/usr/local/share\",\n\n                           \"/usr/share\",\n\n                         };\n\n\n\n    for(i=!base[0]; i<3 && !f; i++){\n\n        snprintf(filename, sizeof(filename), \"%s/%sffmpeg/%s.ffpreset\", base[i], i ? \"\" : \".\", arg);\n\n        f= fopen(filename, \"r\");\n\n        if(!f){\n\n            char *codec_name= *opt == 'v' ? video_codec_name :\n\n                              *opt == 'a' ? audio_codec_name :\n\n                                            subtitle_codec_name;\n\n            snprintf(filename, sizeof(filename), \"%s/%sffmpeg/%s-%s.ffpreset\", base[i],  i ? \"\" : \".\", codec_name, arg);\n\n            f= fopen(filename, \"r\");\n\n        }\n\n    }\n\n    if(!f && ((arg[0]=='.' && arg[1]=='/') || arg[0]=='/' ||\n\n              is_dos_path(arg))){\n\n        snprintf(filename, sizeof(filename), arg);\n\n        f= fopen(filename, \"r\");\n\n    }\n\n\n\n    if(!f){\n\n        fprintf(stderr, \"File for preset '%s' not found\\n\", arg);\n\n        av_exit(1);\n\n    }\n\n\n\n    while(!feof(f)){\n\n        int e= fscanf(f, \"%999[^\\n]\\n\", line) - 1;\n\n        if(line[0] == '#' && !e)\n\n            continue;\n\n        e|= sscanf(line, \"%999[^=]=%999[^\\n]\\n\", tmp, tmp2) - 2;\n\n        if(e){\n\n            fprintf(stderr, \"%s: Preset file invalid\\n\", filename);\n\n            av_exit(1);\n\n        }\n\n        if(!strcmp(tmp, \"acodec\")){\n\n            opt_audio_codec(tmp2);\n\n        }else if(!strcmp(tmp, \"vcodec\")){\n\n            opt_video_codec(tmp2);\n\n        }else if(!strcmp(tmp, \"scodec\")){\n\n            opt_subtitle_codec(tmp2);\n\n        }else if(opt_default(tmp, tmp2) < 0){\n\n            fprintf(stderr, \"%s: Invalid option or argument: %s=%s\\n\", filename, tmp, tmp2);\n\n            av_exit(1);\n\n        }\n\n    }\n\n\n\n    fclose(f);\n\n\n\n    return 0;\n\n}\n", "idx": 6535, "_split": "test", "_hash": "e71f74f294c8862cf87b9df8b5301244"}
{"project": "FFmpeg", "commit_id": "fdbc544d29176ba69d67dd879df4696f0a19052e", "target": 1, "func": "static int asf_read_ext_content(AVFormatContext *s, const GUIDParseTable *g)\n\n{\n\n    ASFContext *asf  = s->priv_data;\n\n    AVIOContext *pb  = s->pb;\n\n    uint64_t size    = avio_rl64(pb);\n\n    uint16_t nb_desc = avio_rl16(pb);\n\n    int i, ret;\n\n\n\n    for (i = 0; i < nb_desc; i++) {\n\n        uint16_t name_len, type, val_len;\n\n        uint8_t *name = NULL;\n\n\n\n        name_len = avio_rl16(pb);\n\n        if (!name_len)\n\n            return AVERROR_INVALIDDATA;\n\n        name = av_malloc(name_len);\n\n        if (!name)\n\n            return AVERROR(ENOMEM);\n\n        avio_get_str16le(pb, name_len, name,\n\n                         name_len);\n\n        type    = avio_rl16(pb);\n\n        val_len = avio_rl16(pb);\n\n\n\n        if ((ret = process_metadata(s, name, name_len, val_len, type, &s->metadata)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    align_position(pb, asf->offset, size);\n\n    return 0;\n\n}\n", "idx": 6543, "_split": "test", "_hash": "5741941aaf05728a8c36fbfa01a21da0"}
{"project": "FFmpeg", "commit_id": "ec3b22326dc07fb8300a577bd6b17c19a0f1bcf7", "target": 1, "func": "static int http_prepare_data(HTTPContext *c)\n\n{\n\n    int i;\n\n\n\n    switch(c->state) {\n\n    case HTTPSTATE_SEND_DATA_HEADER:\n\n        memset(&c->fmt_ctx, 0, sizeof(c->fmt_ctx));\n\n        if (c->stream->feed) {\n\n            /* open output stream by using specified codecs */\n\n            c->fmt_ctx.oformat = c->stream->fmt;\n\n            c->fmt_ctx.nb_streams = c->stream->nb_streams;\n\n            for(i=0;i<c->fmt_ctx.nb_streams;i++) {\n\n                AVStream *st;\n\n                st = av_mallocz(sizeof(AVStream));\n\n                c->fmt_ctx.streams[i] = st;\n\n                if (c->stream->feed == c->stream)\n\n                    memcpy(st, c->stream->streams[i], sizeof(AVStream));\n\n                else\n\n                    memcpy(st, c->stream->feed->streams[c->stream->feed_streams[i]], sizeof(AVStream));\n\n\n\n                st->codec.frame_number = 0; /* XXX: should be done in\n\n                                               AVStream, not in codec */\n\n            }\n\n            c->got_key_frame = 0;\n\n        } else {\n\n            /* open output stream by using codecs in specified file */\n\n            c->fmt_ctx.oformat = c->stream->fmt;\n\n            c->fmt_ctx.nb_streams = c->fmt_in->nb_streams;\n\n            for(i=0;i<c->fmt_ctx.nb_streams;i++) {\n\n                AVStream *st;\n\n                st = av_mallocz(sizeof(AVStream));\n\n                c->fmt_ctx.streams[i] = st;\n\n                memcpy(st, c->fmt_in->streams[i], sizeof(AVStream));\n\n                st->codec.frame_number = 0; /* XXX: should be done in\n\n                                               AVStream, not in codec */\n\n            }\n\n            c->got_key_frame = 0;\n\n        }\n\n        init_put_byte(&c->fmt_ctx.pb, c->pbuffer, PACKET_MAX_SIZE,\n\n                      1, c, NULL, http_write_packet, NULL);\n\n        c->fmt_ctx.pb.is_streamed = 1;\n\n        /* prepare header */\n\n        av_write_header(&c->fmt_ctx);\n\n        c->state = HTTPSTATE_SEND_DATA;\n\n        c->last_packet_sent = 0;\n\n        break;\n\n    case HTTPSTATE_SEND_DATA:\n\n        /* find a new packet */\n\n#if 0\n\n        fifo_total_size = http_fifo_write_count - c->last_http_fifo_write_count;\n\n        if (fifo_total_size >= ((3 * FIFO_MAX_SIZE) / 4)) {\n\n            /* overflow : resync. We suppose that wptr is at this\n\n               point a pointer to a valid packet */\n\n            c->rptr = http_fifo.wptr;\n\n            c->got_key_frame = 0;\n\n        }\n\n        \n\n        start_rptr = c->rptr;\n\n        if (fifo_read(&http_fifo, (UINT8 *)&hdr, sizeof(hdr), &c->rptr) < 0)\n\n            return 0;\n\n        payload_size = ntohs(hdr.payload_size);\n\n        payload = av_malloc(payload_size);\n\n        if (fifo_read(&http_fifo, payload, payload_size, &c->rptr) < 0) {\n\n            /* cannot read all the payload */\n\n            av_free(payload);\n\n            c->rptr = start_rptr;\n\n            return 0;\n\n        }\n\n        \n\n        c->last_http_fifo_write_count = http_fifo_write_count - \n\n            fifo_size(&http_fifo, c->rptr);\n\n        \n\n        if (c->stream->stream_type != STREAM_TYPE_MASTER) {\n\n            /* test if the packet can be handled by this format */\n\n            ret = 0;\n\n            for(i=0;i<c->fmt_ctx.nb_streams;i++) {\n\n                AVStream *st = c->fmt_ctx.streams[i];\n\n                if (test_header(&hdr, &st->codec)) {\n\n                    /* only begin sending when got a key frame */\n\n                    if (st->codec.key_frame)\n\n                        c->got_key_frame |= 1 << i;\n\n                    if (c->got_key_frame & (1 << i)) {\n\n                        ret = c->fmt_ctx.format->write_packet(&c->fmt_ctx, i,\n\n                                                                   payload, payload_size);\n\n                    }\n\n                    break;\n\n                }\n\n            }\n\n            if (ret) {\n\n                /* must send trailer now */\n\n                c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n            }\n\n        } else {\n\n            /* master case : send everything */\n\n            char *q;\n\n            q = c->buffer;\n\n            memcpy(q, &hdr, sizeof(hdr));\n\n            q += sizeof(hdr);\n\n            memcpy(q, payload, payload_size);\n\n            q += payload_size;\n\n            c->buffer_ptr = c->buffer;\n\n            c->buffer_end = q;\n\n        }\n\n        av_free(payload);\n\n#endif\n\n        {\n\n            AVPacket pkt;\n\n\n\n            /* read a packet from the input stream */\n\n            if (c->stream->feed) {\n\n                ffm_set_write_index(c->fmt_in, \n\n                                    c->stream->feed->feed_write_index,\n\n                                    c->stream->feed->feed_size);\n\n            }\n\n            \n\n            if (av_read_packet(c->fmt_in, &pkt) < 0) {\n\n                if (c->stream->feed && c->stream->feed->feed_opened) {\n\n                    /* if coming from feed, it means we reached the end of the\n\n                       ffm file, so must wait for more data */\n\n                    c->state = HTTPSTATE_WAIT_FEED;\n\n                    return 1; /* state changed */\n\n                } else {\n\n                    /* must send trailer now because eof or error */\n\n                    c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n                }\n\n            } else {\n\n                /* send it to the appropriate stream */\n\n                if (c->stream->feed) {\n\n                    /* if coming from a feed, select the right stream */\n\n                    for(i=0;i<c->stream->nb_streams;i++) {\n\n                        if (c->stream->feed_streams[i] == pkt.stream_index) {\n\n                            pkt.stream_index = i;\n\n                            if (pkt.flags & PKT_FLAG_KEY) {\n\n                                c->got_key_frame |= 1 << i;\n\n                            }\n\n                            /* See if we have all the key frames, then \n\n                             * we start to send. This logic is not quite\n\n                             * right, but it works for the case of a \n\n                             * single video stream with one or more\n\n                             * audio streams (for which every frame is \n\n                             * typically a key frame). \n\n                             */\n\n                            if (!c->stream->send_on_key || ((c->got_key_frame + 1) >> c->stream->nb_streams)) {\n\n                                goto send_it;\n\n                            }\n\n                        }\n\n                    }\n\n                } else {\n\n                    AVCodecContext *codec;\n\n                send_it:\n\n                    /* Fudge here */\n\n                    codec = &c->fmt_ctx.streams[pkt.stream_index]->codec;\n\n\n\n                    codec->key_frame = ((pkt.flags & PKT_FLAG_KEY) != 0);\n\n\n\n#ifdef PJSG\n\n                    if (codec->codec_type == CODEC_TYPE_AUDIO) {\n\n                        codec->frame_size = (codec->sample_rate * pkt.duration + 500000) / 1000000;\n\n                        /* printf(\"Calculated size %d, from sr %d, duration %d\\n\", codec->frame_size, codec->sample_rate, pkt.duration); */\n\n                    }\n\n#endif\n\n\n\n                    if (av_write_packet(&c->fmt_ctx, &pkt, 0))\n\n                        c->state = HTTPSTATE_SEND_DATA_TRAILER;\n\n\n\n                    codec->frame_number++;\n\n                }\n\n\n\n                av_free_packet(&pkt);\n\n            }\n\n        }\n\n        break;\n\n    default:\n\n    case HTTPSTATE_SEND_DATA_TRAILER:\n\n        /* last packet test ? */\n\n        if (c->last_packet_sent)\n\n            return -1;\n\n        /* prepare header */\n\n        av_write_trailer(&c->fmt_ctx);\n\n        c->last_packet_sent = 1;\n\n        break;\n\n    }\n\n    return 0;\n\n}\n", "idx": 6556, "_split": "test", "_hash": "0c500328a916737871902b0c64d60edc"}
{"project": "FFmpeg", "commit_id": "65db4899fa8790049bec3af16ecdb75dd81051fd", "target": 1, "func": "static void input_callback(MMAL_PORT_T *port, MMAL_BUFFER_HEADER_T *buffer)\n\n{\n\n    if (!buffer->cmd) {\n\n        AVBufferRef *buf = buffer->user_data;\n\n        av_buffer_unref(&buf);\n\n    }\n\n    mmal_buffer_header_release(buffer);\n\n}\n", "idx": 6575, "_split": "test", "_hash": "7d69b53867e8572715be29732f44ab27"}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "static void avc_luma_vt_and_aver_dst_16x16_msa(const uint8_t *src,\n\n                                               int32_t src_stride,\n\n                                               uint8_t *dst, int32_t dst_stride)\n\n{\n\n    int32_t loop_cnt;\n\n    int16_t filt_const0 = 0xfb01;\n\n    int16_t filt_const1 = 0x1414;\n\n    int16_t filt_const2 = 0x1fb;\n\n    v16u8 dst0, dst1, dst2, dst3;\n\n    v16i8 src0, src1, src2, src3, src4, src5, src6, src7, src8;\n\n    v16i8 src10_r, src32_r, src54_r, src76_r, src21_r, src43_r, src65_r;\n\n    v16i8 src87_r, src10_l, src32_l, src54_l, src76_l, src21_l, src43_l;\n\n    v16i8 src65_l, src87_l;\n\n    v8i16 out0_r, out1_r, out2_r, out3_r, out0_l, out1_l, out2_l, out3_l;\n\n    v16i8 filt0, filt1, filt2;\n\n    v16u8 res0, res1, res2, res3;\n\n\n\n    filt0 = (v16i8) __msa_fill_h(filt_const0);\n\n    filt1 = (v16i8) __msa_fill_h(filt_const1);\n\n    filt2 = (v16i8) __msa_fill_h(filt_const2);\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n    ILVR_B4_SB(src1, src0, src2, src1, src3, src2, src4, src3,\n\n               src10_r, src21_r, src32_r, src43_r);\n\n    ILVL_B4_SB(src1, src0, src2, src1, src3, src2, src4, src3,\n\n               src10_l, src21_l, src32_l, src43_l);\n\n\n\n    for (loop_cnt = 4; loop_cnt--;) {\n\n        LD_SB4(src, src_stride, src5, src6, src7, src8);\n\n        src += (4 * src_stride);\n\n\n\n        XORI_B4_128_SB(src5, src6, src7, src8);\n\n        ILVR_B4_SB(src5, src4, src6, src5, src7, src6, src8, src7,\n\n                   src54_r, src65_r, src76_r, src87_r);\n\n        ILVL_B4_SB(src5, src4, src6, src5, src7, src6, src8, src7,\n\n                   src54_l, src65_l, src76_l, src87_l);\n\n        out0_r = DPADD_SH3_SH(src10_r, src32_r, src54_r, filt0, filt1, filt2);\n\n        out1_r = DPADD_SH3_SH(src21_r, src43_r, src65_r, filt0, filt1, filt2);\n\n        out2_r = DPADD_SH3_SH(src32_r, src54_r, src76_r, filt0, filt1, filt2);\n\n        out3_r = DPADD_SH3_SH(src43_r, src65_r, src87_r, filt0, filt1, filt2);\n\n        out0_l = DPADD_SH3_SH(src10_l, src32_l, src54_l, filt0, filt1, filt2);\n\n        out1_l = DPADD_SH3_SH(src21_l, src43_l, src65_l, filt0, filt1, filt2);\n\n        out2_l = DPADD_SH3_SH(src32_l, src54_l, src76_l, filt0, filt1, filt2);\n\n        out3_l = DPADD_SH3_SH(src43_l, src65_l, src87_l, filt0, filt1, filt2);\n\n        SRARI_H4_SH(out0_r, out1_r, out2_r, out3_r, 5);\n\n        SRARI_H4_SH(out0_l, out1_l, out2_l, out3_l, 5);\n\n        SAT_SH4_SH(out0_r, out1_r, out2_r, out3_r, 7);\n\n        SAT_SH4_SH(out0_l, out1_l, out2_l, out3_l, 7);\n\n        LD_UB4(dst, dst_stride, dst0, dst1, dst2, dst3);\n\n        PCKEV_B4_UB(out0_l, out0_r, out1_l, out1_r, out2_l, out2_r, out3_l,\n\n                    out3_r, res0, res1, res2, res3);\n\n        XORI_B4_128_UB(res0, res1, res2, res3);\n\n        AVER_UB4_UB(res0, dst0, res1, dst1, res2, dst2, res3, dst3,\n\n                    res0, res1, res2, res3);\n\n        ST_UB4(res0, res1, res2, res3, dst, dst_stride);\n\n        dst += (4 * dst_stride);\n\n\n\n        src10_r = src54_r;\n\n        src32_r = src76_r;\n\n        src21_r = src65_r;\n\n        src43_r = src87_r;\n\n        src10_l = src54_l;\n\n        src32_l = src76_l;\n\n        src21_l = src65_l;\n\n        src43_l = src87_l;\n\n        src4 = src8;\n\n    }\n\n}\n", "idx": 6580, "_split": "test", "_hash": "9d41f5c67a3119227a8416e204d4b7d4"}
{"project": "FFmpeg", "commit_id": "15ea222778caaec0877b3f9938140b707c931d96", "target": 0, "func": "static void copy_picture_field(InterlaceContext *s,\n\n                               AVFrame *src_frame, AVFrame *dst_frame,\n\n                               AVFilterLink *inlink, enum FieldType field_type,\n\n                               int lowpass)\n\n{\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);\n\n    int hsub = desc->log2_chroma_w;\n\n    int vsub = desc->log2_chroma_h;\n\n    int plane, j;\n\n\n\n    for (plane = 0; plane < desc->nb_components; plane++) {\n\n        int cols  = (plane == 1 || plane == 2) ? -(-inlink->w) >> hsub : inlink->w;\n\n        int lines = (plane == 1 || plane == 2) ? -(-inlink->h) >> vsub : inlink->h;\n\n        uint8_t *dstp = dst_frame->data[plane];\n\n        const uint8_t *srcp = src_frame->data[plane];\n\n\n\n        av_assert0(cols >= 0 || lines >= 0);\n\n\n\n        lines = (lines + (field_type == FIELD_UPPER)) / 2;\n\n        if (field_type == FIELD_LOWER)\n\n            srcp += src_frame->linesize[plane];\n\n        if (field_type == FIELD_LOWER)\n\n            dstp += dst_frame->linesize[plane];\n\n        if (lowpass) {\n\n            int srcp_linesize = src_frame->linesize[plane] * 2;\n\n            int dstp_linesize = dst_frame->linesize[plane] * 2;\n\n            for (j = lines; j > 0; j--) {\n\n                const uint8_t *srcp_above = srcp - src_frame->linesize[plane];\n\n                const uint8_t *srcp_below = srcp + src_frame->linesize[plane];\n\n                if (j == lines)\n\n                    srcp_above = srcp; // there is no line above\n\n                if (j == 1)\n\n                    srcp_below = srcp; // there is no line below\n\n                s->lowpass_line(dstp, cols, srcp, srcp_above, srcp_below);\n\n                dstp += dstp_linesize;\n\n                srcp += srcp_linesize;\n\n            }\n\n        } else {\n\n            av_image_copy_plane(dstp, dst_frame->linesize[plane] * 2,\n\n                                srcp, src_frame->linesize[plane] * 2,\n\n                                cols, lines);\n\n        }\n\n    }\n\n}\n", "idx": 6622, "_split": "test", "_hash": "5169f0436b9b68c0c43ff09347d8ca38"}
{"project": "FFmpeg", "commit_id": "3ab9a2a5577d445252724af4067d2a7c8a378efa", "target": 1, "func": "static av_always_inline void rv40_weak_loop_filter(uint8_t *src,\n\n                                                   const int step,\n\n                                                   const int stride,\n\n                                                   const int filter_p1,\n\n                                                   const int filter_q1,\n\n                                                   const int alpha,\n\n                                                   const int beta,\n\n                                                   const int lim_p0q0,\n\n                                                   const int lim_q1,\n\n                                                   const int lim_p1)\n\n{\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n    int i, t, u, diff;\n\n\n\n    for (i = 0; i < 4; i++, src += stride) {\n\n        int diff_p1p0 = src[-2*step] - src[-1*step];\n\n        int diff_q1q0 = src[ 1*step] - src[ 0*step];\n\n        int diff_p1p2 = src[-2*step] - src[-3*step];\n\n        int diff_q1q2 = src[ 1*step] - src[ 2*step];\n\n\n\n        t = src[0*step] - src[-1*step];\n\n        if (!t)\n\n            continue;\n\n\n\n        u = (alpha * FFABS(t)) >> 7;\n\n        if (u > 3 - (filter_p1 && filter_q1))\n\n            continue;\n\n\n\n        t <<= 2;\n\n        if (filter_p1 && filter_q1)\n\n            t += src[-2*step] - src[1*step];\n\n\n\n        diff = CLIP_SYMM((t + 4) >> 3, lim_p0q0);\n\n        src[-1*step] = cm[src[-1*step] + diff];\n\n        src[ 0*step] = cm[src[ 0*step] - diff];\n\n\n\n        if (filter_p1 && FFABS(diff_p1p2) <= beta) {\n\n            t = (diff_p1p0 + diff_p1p2 - diff) >> 1;\n\n            src[-2*step] = cm[src[-2*step] - CLIP_SYMM(t, lim_p1)];\n\n        }\n\n\n\n        if (filter_q1 && FFABS(diff_q1q2) <= beta) {\n\n            t = (diff_q1q0 + diff_q1q2 + diff) >> 1;\n\n            src[ 1*step] = cm[src[ 1*step] - CLIP_SYMM(t, lim_q1)];\n\n        }\n\n    }\n\n}\n", "idx": 6646, "_split": "test", "_hash": "02e76efa051746177e8b74c54308412b"}
{"project": "FFmpeg", "commit_id": "8772d2511a4ac45f275eaef2b4b6b1ef132c993b", "target": 1, "func": "static int normalize_bits(int num, int width)\n\n{\n\n    if (!num)\n\n        return 0;\n\n    if (num == -1)\n\n        return width;\n\n    if (num < 0)\n\n        num = ~num;\n\n\n\n    return width - av_log2(num);\n\n}\n", "idx": 6670, "_split": "test", "_hash": "400984ad4a6be346bb2d373c57af58b8"}
{"project": "FFmpeg", "commit_id": "7b94df232a4b76c44e243e618573f8d331a1eb1c", "target": 0, "func": "static int srt_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *got_sub_ptr, AVPacket *avpkt)\n\n{\n\n    AVSubtitle *sub = data;\n\n    AVBPrint buffer;\n\n    int x1 = -1, y1 = -1, x2 = -1, y2 = -1;\n\n    int size, ret;\n\n    const uint8_t *p = av_packet_get_side_data(avpkt, AV_PKT_DATA_SUBTITLE_POSITION, &size);\n\n    FFASSDecoderContext *s = avctx->priv_data;\n\n\n\n    if (p && size == 16) {\n\n        x1 = AV_RL32(p     );\n\n        y1 = AV_RL32(p +  4);\n\n        x2 = AV_RL32(p +  8);\n\n        y2 = AV_RL32(p + 12);\n\n    }\n\n\n\n    if (avpkt->size <= 0)\n\n        return avpkt->size;\n\n\n\n    av_bprint_init(&buffer, 0, AV_BPRINT_SIZE_UNLIMITED);\n\n\n\n    srt_to_ass(avctx, &buffer, avpkt->data, x1, y1, x2, y2);\n\n    ret = ff_ass_add_rect(sub, buffer.str, s->readorder++, 0, NULL, NULL);\n\n    av_bprint_finalize(&buffer, NULL);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    *got_sub_ptr = sub->num_rects > 0;\n\n    return avpkt->size;\n\n}\n", "idx": 6708, "_split": "test", "_hash": "273a2aa2a133d9debd42ca4c43930224"}
{"project": "FFmpeg", "commit_id": "221f902f1dc167bdc0bfdff6b6af3214ae3cc1f4", "target": 1, "func": "static int filter_slice(AVFilterContext *ctx, void *arg, int jobnr, int nb_jobs)\n\n{\n\n    YADIFContext *s = ctx->priv;\n\n    ThreadData *td  = arg;\n\n    int refs = s->cur->linesize[td->plane];\n\n    int df = (s->csp->comp[td->plane].depth_minus1 + 8) / 8;\n\n    int pix_3 = 3 * df;\n\n    int slice_h = td->h / nb_jobs;\n\n    int slice_start = jobnr * slice_h;\n\n    int slice_end   = (jobnr == nb_jobs - 1) ? td->h : (jobnr + 1) * slice_h;\n\n    int y;\n\n\n\n    /* filtering reads 3 pixels to the left/right; to avoid invalid reads,\n\n     * we need to call the c variant which avoids this for border pixels\n\n     */\n\n    for (y = slice_start; y < slice_end; y++) {\n\n        if ((y ^ td->parity) & 1) {\n\n            uint8_t *prev = &s->prev->data[td->plane][y * refs];\n\n            uint8_t *cur  = &s->cur ->data[td->plane][y * refs];\n\n            uint8_t *next = &s->next->data[td->plane][y * refs];\n\n            uint8_t *dst  = &td->frame->data[td->plane][y * td->frame->linesize[td->plane]];\n\n            int     mode  = y == 1 || y + 2 == td->h ? 2 : s->mode;\n\n            s->filter_line(dst + pix_3, prev + pix_3, cur + pix_3,\n\n                           next + pix_3, td->w - 6,\n\n                           y + 1 < td->h ? refs : -refs,\n\n                           y ? -refs : refs,\n\n                           td->parity ^ td->tff, mode);\n\n            s->filter_edges(dst, prev, cur, next, td->w,\n\n                            y + 1 < td->h ? refs : -refs,\n\n                            y ? -refs : refs,\n\n                            td->parity ^ td->tff, mode);\n\n        } else {\n\n            memcpy(&td->frame->data[td->plane][y * td->frame->linesize[td->plane]],\n\n                   &s->cur->data[td->plane][y * refs], td->w * df);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 6727, "_split": "test", "_hash": "1d469b4436c7ba53f02c57dffde287f6"}
{"project": "FFmpeg", "commit_id": "1f361124d97cf8b8ce6d3aacb10cdc53706470de", "target": 1, "func": "int ff_img_read_packet(AVFormatContext *s1, AVPacket *pkt)\n\n{\n\n    VideoDemuxData *s = s1->priv_data;\n\n    char filename_bytes[1024];\n\n    char *filename = filename_bytes;\n\n    int i;\n\n    int size[3]           = { 0 }, ret[3] = { 0 };\n\n    AVIOContext *f[3]     = { NULL };\n\n    AVCodecContext *codec = s1->streams[0]->codec;\n\n\n\n    if (!s->is_pipe) {\n\n        /* loop over input */\n\n        if (s->loop && s->img_number > s->img_last) {\n\n            s->img_number = s->img_first;\n\n        }\n\n        if (s->img_number > s->img_last)\n\n            return AVERROR_EOF;\n\n        if (s->use_glob) {\n\n#if HAVE_GLOB\n\n            filename = s->globstate.gl_pathv[s->img_number];\n\n#endif\n\n        } else {\n\n        if (av_get_frame_filename(filename_bytes, sizeof(filename_bytes),\n\n                                  s->path,\n\n                                  s->img_number) < 0 && s->img_number > 1)\n\n            return AVERROR(EIO);\n\n        }\n\n        for (i = 0; i < 3; i++) {\n\n            if (avio_open2(&f[i], filename, AVIO_FLAG_READ,\n\n                           &s1->interrupt_callback, NULL) < 0) {\n\n                if (i >= 1)\n\n                    break;\n\n                av_log(s1, AV_LOG_ERROR, \"Could not open file : %s\\n\",\n\n                       filename);\n\n                return AVERROR(EIO);\n\n            }\n\n            size[i] = avio_size(f[i]);\n\n\n\n            if (!s->split_planes)\n\n                break;\n\n            filename[strlen(filename) - 1] = 'U' + i;\n\n        }\n\n\n\n        if (codec->codec_id == AV_CODEC_ID_NONE) {\n\n            AVProbeData pd;\n\n            AVInputFormat *ifmt;\n\n            uint8_t header[PROBE_BUF_MIN + AVPROBE_PADDING_SIZE];\n\n            int ret;\n\n            int score = 0;\n\n\n\n            ret = avio_read(f[0], header, PROBE_BUF_MIN);\n\n            if (ret < 0)\n\n                return ret;\n\n\n            avio_skip(f[0], -ret);\n\n            pd.buf = header;\n\n            pd.buf_size = ret;\n\n            pd.filename = filename;\n\n\n\n            ifmt = av_probe_input_format3(&pd, 1, &score);\n\n            if (ifmt && ifmt->read_packet == ff_img_read_packet && ifmt->raw_codec_id)\n\n                codec->codec_id = ifmt->raw_codec_id;\n\n        }\n\n\n\n        if (codec->codec_id == AV_CODEC_ID_RAWVIDEO && !codec->width)\n\n            infer_size(&codec->width, &codec->height, size[0]);\n\n    } else {\n\n        f[0] = s1->pb;\n\n        if (url_feof(f[0]))\n\n            return AVERROR(EIO);\n\n        if (s->frame_size > 0) {\n\n            size[0] = s->frame_size;\n\n        } else {\n\n            size[0] = 4096;\n\n        }\n\n    }\n\n\n\n    if (av_new_packet(pkt, size[0] + size[1] + size[2]) < 0)\n\n        return AVERROR(ENOMEM);\n\n    pkt->stream_index = 0;\n\n    pkt->flags       |= AV_PKT_FLAG_KEY;\n\n    if (s->ts_from_file) {\n\n        struct stat img_stat;\n\n        if (stat(filename, &img_stat))\n\n            return AVERROR(EIO);\n\n        pkt->pts = (int64_t)img_stat.st_mtime;\n\n        av_add_index_entry(s1->streams[0], s->img_number, pkt->pts, 0, 0, AVINDEX_KEYFRAME);\n\n    } else if (!s->is_pipe) {\n\n        pkt->pts      = s->pts;\n\n    }\n\n\n\n    pkt->size = 0;\n\n    for (i = 0; i < 3; i++) {\n\n        if (f[i]) {\n\n            ret[i] = avio_read(f[i], pkt->data + pkt->size, size[i]);\n\n            if (!s->is_pipe)\n\n                avio_close(f[i]);\n\n            if (ret[i] > 0)\n\n                pkt->size += ret[i];\n\n        }\n\n    }\n\n\n\n    if (ret[0] <= 0 || ret[1] < 0 || ret[2] < 0) {\n\n        av_free_packet(pkt);\n\n        return AVERROR(EIO); /* signal EOF */\n\n    } else {\n\n        s->img_count++;\n\n        s->img_number++;\n\n        s->pts++;\n\n        return 0;\n\n    }\n\n}", "idx": 6763, "_split": "test", "_hash": "ff85b0682634859e022f7ac1feeb5d1f"}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static void quantize_and_encode_band_cost_SPAIR_mips(struct AACEncContext *s,\n\n                                                     PutBitContext *pb, const float *in, float *out,\n\n                                                     const float *scaled, int size, int scale_idx,\n\n                                                     int cb, const float lambda, const float uplim,\n\n                                                     int *bits, const float ROUNDING)\n\n{\n\n    const float Q34 = ff_aac_pow34sf_tab[POW_SF2_ZERO - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float IQ  = ff_aac_pow2sf_tab [POW_SF2_ZERO + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    int i;\n\n    int qc1, qc2, qc3, qc4;\n\n\n\n    uint8_t  *p_bits  = (uint8_t  *)ff_aac_spectral_bits[cb-1];\n\n    uint16_t *p_codes = (uint16_t *)ff_aac_spectral_codes[cb-1];\n\n    float    *p_vec   = (float    *)ff_aac_codebook_vectors[cb-1];\n\n\n\n    abs_pow34_v(s->scoefs, in, size);\n\n    scaled = s->scoefs;\n\n    for (i = 0; i < size; i += 4) {\n\n        int curidx, curidx2;\n\n        int *in_int = (int *)&in[i];\n\n        uint8_t v_bits;\n\n        unsigned int v_codes;\n\n        int t0, t1, t2, t3, t4, t5, t6, t7;\n\n        const float *vec1, *vec2;\n\n\n\n        qc1 = scaled[i  ] * Q34 + ROUND_STANDARD;\n\n        qc2 = scaled[i+1] * Q34 + ROUND_STANDARD;\n\n        qc3 = scaled[i+2] * Q34 + ROUND_STANDARD;\n\n        qc4 = scaled[i+3] * Q34 + ROUND_STANDARD;\n\n\n\n        __asm__ volatile (\n\n            \".set push                      \\n\\t\"\n\n            \".set noreorder                 \\n\\t\"\n\n\n\n            \"ori    %[t4],  $zero,  4       \\n\\t\"\n\n            \"slt    %[t0],  %[t4],  %[qc1]  \\n\\t\"\n\n            \"slt    %[t1],  %[t4],  %[qc2]  \\n\\t\"\n\n            \"slt    %[t2],  %[t4],  %[qc3]  \\n\\t\"\n\n            \"slt    %[t3],  %[t4],  %[qc4]  \\n\\t\"\n\n            \"movn   %[qc1], %[t4],  %[t0]   \\n\\t\"\n\n            \"movn   %[qc2], %[t4],  %[t1]   \\n\\t\"\n\n            \"movn   %[qc3], %[t4],  %[t2]   \\n\\t\"\n\n            \"movn   %[qc4], %[t4],  %[t3]   \\n\\t\"\n\n            \"lw     %[t0],  0(%[in_int])    \\n\\t\"\n\n            \"lw     %[t1],  4(%[in_int])    \\n\\t\"\n\n            \"lw     %[t2],  8(%[in_int])    \\n\\t\"\n\n            \"lw     %[t3],  12(%[in_int])   \\n\\t\"\n\n            \"srl    %[t0],  %[t0],  31      \\n\\t\"\n\n            \"srl    %[t1],  %[t1],  31      \\n\\t\"\n\n            \"srl    %[t2],  %[t2],  31      \\n\\t\"\n\n            \"srl    %[t3],  %[t3],  31      \\n\\t\"\n\n            \"subu   %[t4],  $zero,  %[qc1]  \\n\\t\"\n\n            \"subu   %[t5],  $zero,  %[qc2]  \\n\\t\"\n\n            \"subu   %[t6],  $zero,  %[qc3]  \\n\\t\"\n\n            \"subu   %[t7],  $zero,  %[qc4]  \\n\\t\"\n\n            \"movn   %[qc1], %[t4],  %[t0]   \\n\\t\"\n\n            \"movn   %[qc2], %[t5],  %[t1]   \\n\\t\"\n\n            \"movn   %[qc3], %[t6],  %[t2]   \\n\\t\"\n\n            \"movn   %[qc4], %[t7],  %[t3]   \\n\\t\"\n\n\n\n            \".set pop                       \\n\\t\"\n\n\n\n            : [qc1]\"+r\"(qc1), [qc2]\"+r\"(qc2),\n\n              [qc3]\"+r\"(qc3), [qc4]\"+r\"(qc4),\n\n              [t0]\"=&r\"(t0), [t1]\"=&r\"(t1), [t2]\"=&r\"(t2), [t3]\"=&r\"(t3),\n\n              [t4]\"=&r\"(t4), [t5]\"=&r\"(t5), [t6]\"=&r\"(t6), [t7]\"=&r\"(t7)\n\n            : [in_int]\"r\"(in_int)\n\n            : \"memory\"\n\n        );\n\n\n\n        curidx = 9 * qc1;\n\n        curidx += qc2 + 40;\n\n\n\n        curidx2 = 9 * qc3;\n\n        curidx2 += qc4 + 40;\n\n\n\n        v_codes = (p_codes[curidx] << p_bits[curidx2]) | (p_codes[curidx2]);\n\n        v_bits  = p_bits[curidx] + p_bits[curidx2];\n\n        put_bits(pb, v_bits, v_codes);\n\n\n\n        if (out) {\n\n           vec1 = &p_vec[curidx*2 ];\n\n           vec2 = &p_vec[curidx2*2];\n\n           out[i+0] = vec1[0] * IQ;\n\n           out[i+1] = vec1[1] * IQ;\n\n           out[i+2] = vec2[0] * IQ;\n\n           out[i+3] = vec2[1] * IQ;\n\n        }\n\n    }\n\n}\n", "idx": 6778, "_split": "test", "_hash": "c0186253108f5720a7ca82e70f9f7ea0"}
{"project": "FFmpeg", "commit_id": "eef9f06508354d1c7d5624c1c18997e7974288f1", "target": 0, "func": "static int stream_component_open(PlayerState *is, int stream_index)\n\n{\n\n    AVFormatContext *ic = is->ic;\n\n    AVCodecContext *avctx;\n\n    AVCodec *codec;\n\n    SDL_AudioSpec wanted_spec, spec;\n\n    AVDictionary *opts;\n\n    AVDictionaryEntry *t = NULL;\n\n    int ret = 0;\n\n\n\n    if (stream_index < 0 || stream_index >= ic->nb_streams)\n\n        return -1;\n\n    avctx = ic->streams[stream_index]->codec;\n\n\n\n    opts = filter_codec_opts(codec_opts, avctx->codec_id, ic, ic->streams[stream_index], NULL);\n\n\n\n    codec = avcodec_find_decoder(avctx->codec_id);\n\n    avctx->workaround_bugs   = workaround_bugs;\n\n    avctx->idct_algo         = idct;\n\n    avctx->skip_frame        = skip_frame;\n\n    avctx->skip_idct         = skip_idct;\n\n    avctx->skip_loop_filter  = skip_loop_filter;\n\n    avctx->error_concealment = error_concealment;\n\n\n\n    if (fast)\n\n        avctx->flags2 |= AV_CODEC_FLAG2_FAST;\n\n\n\n    if (!av_dict_get(opts, \"threads\", NULL, 0))\n\n        av_dict_set(&opts, \"threads\", \"auto\", 0);\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO)\n\n        av_dict_set(&opts, \"refcounted_frames\", \"1\", 0);\n\n    if (!codec ||\n\n        (ret = avcodec_open2(avctx, codec, &opts)) < 0) {\n\n        goto fail;\n\n    }\n\n    if ((t = av_dict_get(opts, \"\", NULL, AV_DICT_IGNORE_SUFFIX))) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Option %s not found.\\n\", t->key);\n\n        ret =  AVERROR_OPTION_NOT_FOUND;\n\n        goto fail;\n\n    }\n\n\n\n    /* prepare audio output */\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n        is->sdl_sample_rate = avctx->sample_rate;\n\n\n\n        if (!avctx->channel_layout)\n\n            avctx->channel_layout = av_get_default_channel_layout(avctx->channels);\n\n        if (!avctx->channel_layout) {\n\n            fprintf(stderr, \"unable to guess channel layout\\n\");\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n        if (avctx->channels == 1)\n\n            is->sdl_channel_layout = AV_CH_LAYOUT_MONO;\n\n        else\n\n            is->sdl_channel_layout = AV_CH_LAYOUT_STEREO;\n\n        is->sdl_channels = av_get_channel_layout_nb_channels(is->sdl_channel_layout);\n\n\n\n        wanted_spec.format = AUDIO_S16SYS;\n\n        wanted_spec.freq = is->sdl_sample_rate;\n\n        wanted_spec.channels = is->sdl_channels;\n\n        wanted_spec.silence = 0;\n\n        wanted_spec.samples = SDL_AUDIO_BUFFER_SIZE;\n\n        wanted_spec.callback = sdl_audio_callback;\n\n        wanted_spec.userdata = is;\n\n        if (SDL_OpenAudio(&wanted_spec, &spec) < 0) {\n\n            fprintf(stderr, \"SDL_OpenAudio: %s\\n\", SDL_GetError());\n\n            ret = AVERROR_UNKNOWN;\n\n            goto fail;\n\n        }\n\n        is->audio_hw_buf_size = spec.size;\n\n        is->sdl_sample_fmt          = AV_SAMPLE_FMT_S16;\n\n        is->resample_sample_fmt     = is->sdl_sample_fmt;\n\n        is->resample_channel_layout = avctx->channel_layout;\n\n        is->resample_sample_rate    = avctx->sample_rate;\n\n    }\n\n\n\n    ic->streams[stream_index]->discard = AVDISCARD_DEFAULT;\n\n    switch (avctx->codec_type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        is->audio_stream = stream_index;\n\n        is->audio_st = ic->streams[stream_index];\n\n        is->audio_buf_size  = 0;\n\n        is->audio_buf_index = 0;\n\n\n\n        /* init averaging filter */\n\n        is->audio_diff_avg_coef  = exp(log(0.01) / AUDIO_DIFF_AVG_NB);\n\n        is->audio_diff_avg_count = 0;\n\n        /* since we do not have a precise anough audio fifo fullness,\n\n           we correct audio sync only if larger than this threshold */\n\n        is->audio_diff_threshold = 2.0 * SDL_AUDIO_BUFFER_SIZE / avctx->sample_rate;\n\n\n\n        memset(&is->audio_pkt, 0, sizeof(is->audio_pkt));\n\n        packet_queue_init(&is->audioq);\n\n        SDL_PauseAudio(0);\n\n        break;\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        is->video_stream = stream_index;\n\n        is->video_st = ic->streams[stream_index];\n\n\n\n        packet_queue_init(&is->videoq);\n\n        is->video_tid = SDL_CreateThread(video_thread, is);\n\n        break;\n\n    case AVMEDIA_TYPE_SUBTITLE:\n\n        is->subtitle_stream = stream_index;\n\n        is->subtitle_st = ic->streams[stream_index];\n\n        packet_queue_init(&is->subtitleq);\n\n\n\n        is->subtitle_tid = SDL_CreateThread(subtitle_thread, is);\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n\n\nfail:\n\n    av_dict_free(&opts);\n\n\n\n    return ret;\n\n}\n", "idx": 6801, "_split": "test", "_hash": "4fbf439731151131f3ff06306b733bc6"}
{"project": "FFmpeg", "commit_id": "7a206eb32f624171a35235f714d44ee9dec9abcb", "target": 0, "func": "static int alac_set_info(ALACContext *alac)\n\n{\n\n    GetByteContext gb;\n\n\n\n    bytestream2_init(&gb, alac->avctx->extradata,\n\n                     alac->avctx->extradata_size);\n\n\n\n    bytestream2_skipu(&gb, 12); // size:4, alac:4, version:4\n\n\n\n    alac->max_samples_per_frame = bytestream2_get_be32u(&gb);\n\n    if (alac->max_samples_per_frame >= UINT_MAX/4){\n\n        av_log(alac->avctx, AV_LOG_ERROR,\n\n               \"max_samples_per_frame too large\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    bytestream2_skipu(&gb, 1);  // compatible version\n\n    alac->sample_size          = bytestream2_get_byteu(&gb);\n\n    alac->rice_history_mult    = bytestream2_get_byteu(&gb);\n\n    alac->rice_initial_history = bytestream2_get_byteu(&gb);\n\n    alac->rice_limit           = bytestream2_get_byteu(&gb);\n\n    alac->channels             = bytestream2_get_byteu(&gb);\n\n    bytestream2_get_be16u(&gb); // maxRun\n\n    bytestream2_get_be32u(&gb); // max coded frame size\n\n    bytestream2_get_be32u(&gb); // average bitrate\n\n    bytestream2_get_be32u(&gb); // samplerate\n\n\n\n    return 0;\n\n}\n", "idx": 6879, "_split": "test", "_hash": "c334a18960051b55eb92cb9efa28b7b2"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int slice_end(AVCodecContext *avctx, AVFrame *pict)\n\n{\n\n    Mpeg1Context *s1  = avctx->priv_data;\n\n    MpegEncContext *s = &s1->mpeg_enc_ctx;\n\n\n\n    if (!s1->mpeg_enc_ctx_allocated || !s->current_picture_ptr)\n\n        return 0;\n\n\n\n    if (s->avctx->hwaccel) {\n\n        if (s->avctx->hwaccel->end_frame(s->avctx) < 0)\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"hardware accelerator failed to decode picture\\n\");\n\n    }\n\n\n\n#if FF_API_XVMC\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration)\n\n        ff_xvmc_field_end(s);\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif /* FF_API_XVMC */\n\n\n\n    /* end of slice reached */\n\n    if (/* s->mb_y << field_pic == s->mb_height && */ !s->first_field) {\n\n        /* end of image */\n\n\n\n        ff_er_frame_end(&s->er);\n\n\n\n        ff_MPV_frame_end(s);\n\n\n\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n            int ret = av_frame_ref(pict, &s->current_picture_ptr->f);\n\n            if (ret < 0)\n\n                return ret;\n\n            ff_print_debug_info(s, s->current_picture_ptr);\n\n        } else {\n\n            if (avctx->active_thread_type & FF_THREAD_FRAME)\n\n                s->picture_number++;\n\n            /* latency of 1 frame for I- and P-frames */\n\n            /* XXX: use another variable than picture_number */\n\n            if (s->last_picture_ptr != NULL) {\n\n                int ret = av_frame_ref(pict, &s->last_picture_ptr->f);\n\n                if (ret < 0)\n\n                    return ret;\n\n                ff_print_debug_info(s, s->last_picture_ptr);\n\n            }\n\n        }\n\n\n\n        return 1;\n\n    } else {\n\n        return 0;\n\n    }\n\n}\n", "idx": 6956, "_split": "test", "_hash": "65f7d007cb535965b698be70b5f81249"}
{"project": "FFmpeg", "commit_id": "d82eccea2bf905cd51889954658f4e7f64876df8", "target": 1, "func": "static inline int mpeg2_fast_decode_block_non_intra(MpegEncContext *s,\n\n                                                    int16_t *block, int n)\n\n{\n\n    int level, i, j, run;\n\n    RLTable *rl = &ff_rl_mpeg1;\n\n    uint8_t * const scantable = s->intra_scantable.permutated;\n\n    const int qscale          = s->qscale;\n\n    OPEN_READER(re, &s->gb);\n\n    i = -1;\n\n\n\n    // special case for first coefficient, no need to add second VLC table\n\n    UPDATE_CACHE(re, &s->gb);\n\n    if (((int32_t)GET_CACHE(re, &s->gb)) < 0) {\n\n        level = (3 * qscale) >> 1;\n\n        if (GET_CACHE(re, &s->gb) & 0x40000000)\n\n            level = -level;\n\n        block[0] = level;\n\n        i++;\n\n        SKIP_BITS(re, &s->gb, 2);\n\n        if (((int32_t)GET_CACHE(re, &s->gb)) <= (int32_t)0xBFFFFFFF)\n\n            goto end;\n\n    }\n\n\n\n    /* now quantify & encode AC coefficients */\n\n    for (;;) {\n\n        GET_RL_VLC(level, run, re, &s->gb, rl->rl_vlc[0], TEX_VLC_BITS, 2, 0);\n\n\n\n        if (level != 0) {\n\n            i += run;\n\n            j  = scantable[i];\n\n            level = ((level * 2 + 1) * qscale) >> 1;\n\n            level = (level ^ SHOW_SBITS(re, &s->gb, 1)) - SHOW_SBITS(re, &s->gb, 1);\n\n            SKIP_BITS(re, &s->gb, 1);\n\n        } else {\n\n            /* escape */\n\n            run = SHOW_UBITS(re, &s->gb, 6) + 1; LAST_SKIP_BITS(re, &s->gb, 6);\n\n            UPDATE_CACHE(re, &s->gb);\n\n            level = SHOW_SBITS(re, &s->gb, 12); SKIP_BITS(re, &s->gb, 12);\n\n\n\n            i += run;\n\n            j  = scantable[i];\n\n            if (level < 0) {\n\n                level = ((-level * 2 + 1) * qscale) >> 1;\n\n                level = -level;\n\n            } else {\n\n                level = ((level * 2 + 1) * qscale) >> 1;\n\n            }\n\n        }\n\n\n\n        block[j] = level;\n\n        if (((int32_t)GET_CACHE(re, &s->gb)) <= (int32_t)0xBFFFFFFF)\n\n            break;\n\n        UPDATE_CACHE(re, &s->gb);\n\n    }\n\nend:\n\n    LAST_SKIP_BITS(re, &s->gb, 2);\n\n    CLOSE_READER(re, &s->gb);\n\n    s->block_last_index[n] = i;\n\n    return 0;\n\n}\n", "idx": 6972, "_split": "test", "_hash": "562ac05bbf1bcf758b122fd060ab5a8b"}
{"project": "FFmpeg", "commit_id": "b853cfe7eaf13b7d4ff3ceba7098544ccc049df8", "target": 0, "func": "static void stream_close(VideoState *is)\n\n{\n\n    VideoPicture *vp;\n\n    int i;\n\n    /* XXX: use a special url_shutdown call to abort parse cleanly */\n\n    is->abort_request = 1;\n\n    SDL_WaitThread(is->read_tid, NULL);\n\n    SDL_WaitThread(is->refresh_tid, NULL);\n\n    packet_queue_destroy(&is->videoq);\n\n    packet_queue_destroy(&is->audioq);\n\n    packet_queue_destroy(&is->subtitleq);\n\n\n\n    /* free all pictures */\n\n    for (i = 0; i < VIDEO_PICTURE_QUEUE_SIZE; i++) {\n\n        vp = &is->pictq[i];\n\n#if CONFIG_AVFILTER\n\n        avfilter_unref_bufferp(&vp->picref);\n\n#endif\n\n        if (vp->bmp) {\n\n            SDL_FreeYUVOverlay(vp->bmp);\n\n            vp->bmp = NULL;\n\n        }\n\n    }\n\n    SDL_DestroyMutex(is->pictq_mutex);\n\n    SDL_DestroyCond(is->pictq_cond);\n\n    SDL_DestroyMutex(is->subpq_mutex);\n\n    SDL_DestroyCond(is->subpq_cond);\n\n    SDL_DestroyCond(is->continue_read_thread);\n\n#if !CONFIG_AVFILTER\n\n    sws_freeContext(is->img_convert_ctx);\n\n#endif\n\n    av_free(is);\n\n}\n", "idx": 6997, "_split": "test", "_hash": "223d04305d8fbd86c45a87ddab9f2940"}
{"project": "FFmpeg", "commit_id": "560b10a6c3627cccf6735170d370cf9e3d38e805", "target": 1, "func": "static void init_gain_table(COOKContext *q) {\n\n    int i;\n\n    q->gain_size_factor = q->samples_per_channel/8;\n\n    for (i=0 ; i<23 ; i++) {\n\n        q->gain_table[i] = pow((double)q->pow2tab[i+52] ,\n\n                               (1.0/(double)q->gain_size_factor));\n\n    }\n\n    memset(&q->gain_copy, 0, sizeof(COOKgain));\n\n    memset(&q->gain_current, 0, sizeof(COOKgain));\n\n    memset(&q->gain_now, 0, sizeof(COOKgain));\n\n    memset(&q->gain_previous, 0, sizeof(COOKgain));\n\n}\n", "idx": 6999, "_split": "test", "_hash": "06a3d6704d4c6c623e154f00e95f98af"}
{"project": "FFmpeg", "commit_id": "7117547298b13d6f52a20d6a62a27dc0a1c3e263", "target": 1, "func": "static int get_buffer_sao(HEVCContext *s, AVFrame *frame, const HEVCSPS *sps)\n\n{\n\n    int ret, i;\n\n\n\n    frame->width  = s->avctx->width  + 2;\n\n    frame->height = s->avctx->height + 2;\n\n    if ((ret = ff_get_buffer(s->avctx, frame, AV_GET_BUFFER_FLAG_REF)) < 0)\n\n        return ret;\n\n    for (i = 0; frame->data[i]; i++) {\n\n        int offset = frame->linesize[i] + (1 << sps->pixel_shift);\n\n        frame->data[i] += offset;\n\n    }\n\n    frame->width  = s->avctx->width;\n\n    frame->height = s->avctx->height;\n\n\n\n    return 0;\n\n}\n", "idx": 7048, "_split": "test", "_hash": "8bfd250f1456898ce3599b6572ab9385"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "static void avc_luma_vt_16w_msa(const uint8_t *src, int32_t src_stride,\n\n                                uint8_t *dst, int32_t dst_stride,\n\n                                int32_t height)\n\n{\n\n    int32_t loop_cnt;\n\n    int16_t filt_const0 = 0xfb01;\n\n    int16_t filt_const1 = 0x1414;\n\n    int16_t filt_const2 = 0x1fb;\n\n    v16i8 src0, src1, src2, src3, src4, src5, src6, src7, src8;\n\n    v16i8 src10_r, src32_r, src54_r, src76_r, src21_r, src43_r, src65_r;\n\n    v16i8 src87_r, src10_l, src32_l, src54_l, src76_l, src21_l, src43_l;\n\n    v16i8 src65_l, src87_l;\n\n    v8i16 out0_r, out1_r, out2_r, out3_r, out0_l, out1_l, out2_l, out3_l;\n\n    v16u8 res0, res1, res2, res3;\n\n    v16i8 filt0, filt1, filt2;\n\n\n\n    filt0 = (v16i8) __msa_fill_h(filt_const0);\n\n    filt1 = (v16i8) __msa_fill_h(filt_const1);\n\n    filt2 = (v16i8) __msa_fill_h(filt_const2);\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n    ILVR_B4_SB(src1, src0, src2, src1, src3, src2, src4, src3,\n\n               src10_r, src21_r, src32_r, src43_r);\n\n    ILVL_B4_SB(src1, src0, src2, src1, src3, src2, src4, src3,\n\n               src10_l, src21_l, src32_l, src43_l);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src, src_stride, src5, src6, src7, src8);\n\n        src += (4 * src_stride);\n\n\n\n        XORI_B4_128_SB(src5, src6, src7, src8);\n\n        ILVR_B4_SB(src5, src4, src6, src5, src7, src6, src8, src7,\n\n                   src54_r, src65_r, src76_r, src87_r);\n\n        ILVL_B4_SB(src5, src4, src6, src5, src7, src6, src8, src7,\n\n                   src54_l, src65_l, src76_l, src87_l);\n\n        out0_r = DPADD_SH3_SH(src10_r, src32_r, src54_r, filt0, filt1, filt2);\n\n        out1_r = DPADD_SH3_SH(src21_r, src43_r, src65_r, filt0, filt1, filt2);\n\n        out2_r = DPADD_SH3_SH(src32_r, src54_r, src76_r, filt0, filt1, filt2);\n\n        out3_r = DPADD_SH3_SH(src43_r, src65_r, src87_r, filt0, filt1, filt2);\n\n        out0_l = DPADD_SH3_SH(src10_l, src32_l, src54_l, filt0, filt1, filt2);\n\n        out1_l = DPADD_SH3_SH(src21_l, src43_l, src65_l, filt0, filt1, filt2);\n\n        out2_l = DPADD_SH3_SH(src32_l, src54_l, src76_l, filt0, filt1, filt2);\n\n        out3_l = DPADD_SH3_SH(src43_l, src65_l, src87_l, filt0, filt1, filt2);\n\n        SRARI_H4_SH(out0_r, out1_r, out2_r, out3_r, 5);\n\n        SAT_SH4_SH(out0_r, out1_r, out2_r, out3_r, 7);\n\n        SRARI_H4_SH(out0_l, out1_l, out2_l, out3_l, 5);\n\n        SAT_SH4_SH(out0_l, out1_l, out2_l, out3_l, 7);\n\n        PCKEV_B4_UB(out0_l, out0_r, out1_l, out1_r, out2_l, out2_r, out3_l,\n\n                    out3_r, res0, res1, res2, res3);\n\n        XORI_B4_128_UB(res0, res1, res2, res3);\n\n\n\n        ST_UB4(res0, res1, res2, res3, dst, dst_stride);\n\n        dst += (4 * dst_stride);\n\n\n\n        src10_r = src54_r;\n\n        src32_r = src76_r;\n\n        src21_r = src65_r;\n\n        src43_r = src87_r;\n\n        src10_l = src54_l;\n\n        src32_l = src76_l;\n\n        src21_l = src65_l;\n\n        src43_l = src87_l;\n\n        src4 = src8;\n\n    }\n\n}\n", "idx": 7066, "_split": "test", "_hash": "598bfd8ae23d379293b852318339a2d5"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static void prepare_app_arguments(int *argc_ptr, char ***argv_ptr)\n\n{\n\n    char *argstr_flat;\n\n    wchar_t **argv_w;\n\n    int i, buffsize = 0, offset = 0;\n\n\n\n    if (win32_argv_utf8) {\n\n        *argc_ptr = win32_argc;\n\n        *argv_ptr = win32_argv_utf8;\n\n        return;\n\n    }\n\n\n\n    win32_argc = 0;\n\n    argv_w = CommandLineToArgvW(GetCommandLineW(), &win32_argc);\n\n    if (win32_argc <= 0 || !argv_w)\n\n        return;\n\n\n\n    /* determine the UTF-8 buffer size (including NULL-termination symbols) */\n\n    for (i = 0; i < win32_argc; i++)\n\n        buffsize += WideCharToMultiByte(CP_UTF8, 0, argv_w[i], -1,\n\n                                        NULL, 0, NULL, NULL);\n\n\n\n    win32_argv_utf8 = av_mallocz(sizeof(char *) * (win32_argc + 1) + buffsize);\n\n    argstr_flat     = (char *)win32_argv_utf8 + sizeof(char *) * (win32_argc + 1);\n\n    if (win32_argv_utf8 == NULL) {\n\n        LocalFree(argv_w);\n\n        return;\n\n    }\n\n\n\n    for (i = 0; i < win32_argc; i++) {\n\n        win32_argv_utf8[i] = &argstr_flat[offset];\n\n        offset += WideCharToMultiByte(CP_UTF8, 0, argv_w[i], -1,\n\n                                      &argstr_flat[offset],\n\n                                      buffsize - offset, NULL, NULL);\n\n    }\n\n    win32_argv_utf8[i] = NULL;\n\n    LocalFree(argv_w);\n\n\n\n    *argc_ptr = win32_argc;\n\n    *argv_ptr = win32_argv_utf8;\n\n}\n", "idx": 7111, "_split": "test", "_hash": "920db0de5eb21ca42323bc5046760e4f"}
{"project": "FFmpeg", "commit_id": "2f996b8397ee0e646a824f3dfcbd291a114af348", "target": 0, "func": "int MP3lame_encode_frame(AVCodecContext *avctx,\n\n                     unsigned char *frame, int buf_size, void *data)\n\n{\n\n\tMp3AudioContext *s = avctx->priv_data;\n\n\tint num, i;\n\n//av_log(avctx, AV_LOG_DEBUG, \"%X %d %X\\n\", (int)frame, buf_size, (int)data);\n\n//        if(data==NULL)\n\n//            return lame_encode_flush(s->gfp, frame, buf_size);\n\n\n\n\t/* lame 3.91 dies on '1-channel interleaved' data */\n\n\tif (s->stereo) {\n\n\t\tnum = lame_encode_buffer_interleaved(s->gfp, data,\n\n\t\t\tMPA_FRAME_SIZE, frame, buf_size);\n\n\t} else {\n\n\t\tnum = lame_encode_buffer(s->gfp, data, data, MPA_FRAME_SIZE,\n\n\t\t\tframe, buf_size);\n\n\n\n/*av_log(avctx, AV_LOG_DEBUG, \"in:%d out:%d\\n\", MPA_FRAME_SIZE, num);\n\nfor(i=0; i<num; i++){\n\n    av_log(avctx, AV_LOG_DEBUG, \"%2X \", frame[i]);\n\n}*/\n\n\t}\n\n\n\n\treturn num;\n\n}\n", "idx": 7122, "_split": "test", "_hash": "73c5271537bc9ab61f42eb3c44b7a219"}
{"project": "FFmpeg", "commit_id": "bf2bc926f04dcdde0a22c137d08a0bb546e0179e", "target": 1, "func": "static int decode_b_picture_secondary_header(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    int status;\n\n\n\n    bitplane_decoding(&v->skip_mb_plane, v);\n\n    if (status < 0) return -1;\n\n#if TRACE\n\n    if (v->mv_mode == MV_PMODE_MIXED_MV)\n\n    {\n\n        status = bitplane_decoding(&v->mv_type_mb_plane, v);\n\n        if (status < 0)\n\n            return -1;\n\n#if TRACE\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"MB MV Type plane encoding: \"\n\n               \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n#endif\n\n    }\n\n\n\n    //bitplane\n\n    status = bitplane_decoding(&v->direct_mb_plane, v);\n\n    if (status < 0) return -1;\n\n#if TRACE\n\n    av_log(v->s.avctx, AV_LOG_DEBUG, \"MB Direct plane encoding: \"\n\n           \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n#endif\n\n\n\n    av_log(v->s.avctx, AV_LOG_DEBUG, \"Skip MB plane encoding: \"\n\n           \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n#endif\n\n\n\n    /* FIXME: what is actually chosen for B frames ? */\n\n    v->s.mv_table_index = get_bits(gb, 2); //but using vc9_ tables\n\n    v->cbpcy_vlc = &vc9_cbpcy_p_vlc[get_bits(gb, 2)];\n\n\n\n    if (v->dquant)\n\n    {\n\n        vop_dquant_decoding(v);\n\n    }\n\n\n\n    if (v->vstransform)\n\n    {\n\n        v->ttmbf = get_bits(gb, 1);\n\n        if (v->ttmbf)\n\n        {\n\n            v->ttfrm = get_bits(gb, 2);\n\n            av_log(v->s.avctx, AV_LOG_INFO, \"Transform used: %ix%i\\n\",\n\n                   (v->ttfrm & 2) ? 4 : 8, (v->ttfrm & 1) ? 4 : 8);\n\n        }\n\n    }\n\n    /* Epilog (AC/DC syntax) should be done in caller */\n\n    return 0;\n\n}\n", "idx": 7130, "_split": "test", "_hash": "41f3379bc80c257271b0a20ef95621e1"}
{"project": "FFmpeg", "commit_id": "0efb6106118c17308b3fdc3190f5e5bf84b01d5c", "target": 1, "func": "static int mxf_get_stream_index(AVFormatContext *s, KLVPacket *klv)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        MXFTrack *track = s->streams[i]->priv_data;\n\n        /* SMPTE 379M 7.3 */\n\n        if (!memcmp(klv->key + sizeof(mxf_essence_element_key), track->track_number, sizeof(track->track_number)))\n\n            return i;\n\n    }\n\n    /* return 0 if only one stream, for OP Atom files with 0 as track number */\n\n    return s->nb_streams == 1 ? 0 : -1;\n\n}\n", "idx": 7150, "_split": "test", "_hash": "666b8586e3aa2c878001d6707edcbbb7"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static void vc1_mc_1mv(VC1Context *v, int dir)\n\n{\n\n    MpegEncContext *s = &v->s;\n\n    H264ChromaContext *h264chroma = &v->h264chroma;\n\n    uint8_t *srcY, *srcU, *srcV;\n\n    int dxy, mx, my, uvmx, uvmy, src_x, src_y, uvsrc_x, uvsrc_y;\n\n    int v_edge_pos = s->v_edge_pos >> v->field_mode;\n\n    int i;\n\n    uint8_t (*luty)[256], (*lutuv)[256];\n\n    int use_ic;\n\n\n\n    if ((!v->field_mode ||\n\n         (v->ref_field_type[dir] == 1 && v->cur_field_type == 1)) &&\n\n        !v->s.last_picture.f.data[0])\n\n        return;\n\n\n\n    mx = s->mv[dir][0][0];\n\n    my = s->mv[dir][0][1];\n\n\n\n    // store motion vectors for further use in B frames\n\n    if (s->pict_type == AV_PICTURE_TYPE_P) {\n\n        for (i = 0; i < 4; i++) {\n\n            s->current_picture.motion_val[1][s->block_index[i] + v->blocks_off][0] = mx;\n\n            s->current_picture.motion_val[1][s->block_index[i] + v->blocks_off][1] = my;\n\n        }\n\n    }\n\n\n\n    uvmx = (mx + ((mx & 3) == 3)) >> 1;\n\n    uvmy = (my + ((my & 3) == 3)) >> 1;\n\n    v->luma_mv[s->mb_x][0] = uvmx;\n\n    v->luma_mv[s->mb_x][1] = uvmy;\n\n\n\n    if (v->field_mode &&\n\n        v->cur_field_type != v->ref_field_type[dir]) {\n\n        my   = my   - 2 + 4 * v->cur_field_type;\n\n        uvmy = uvmy - 2 + 4 * v->cur_field_type;\n\n    }\n\n\n\n    // fastuvmc shall be ignored for interlaced frame picture\n\n    if (v->fastuvmc && (v->fcm != ILACE_FRAME)) {\n\n        uvmx = uvmx + ((uvmx < 0) ? (uvmx & 1) : -(uvmx & 1));\n\n        uvmy = uvmy + ((uvmy < 0) ? (uvmy & 1) : -(uvmy & 1));\n\n    }\n\n    if (!dir) {\n\n        if (v->field_mode && (v->cur_field_type != v->ref_field_type[dir]) && v->second_field) {\n\n            srcY = s->current_picture.f.data[0];\n\n            srcU = s->current_picture.f.data[1];\n\n            srcV = s->current_picture.f.data[2];\n\n            luty  = v->curr_luty;\n\n            lutuv = v->curr_lutuv;\n\n            use_ic = v->curr_use_ic;\n\n        } else {\n\n            srcY = s->last_picture.f.data[0];\n\n            srcU = s->last_picture.f.data[1];\n\n            srcV = s->last_picture.f.data[2];\n\n            luty  = v->last_luty;\n\n            lutuv = v->last_lutuv;\n\n            use_ic = v->last_use_ic;\n\n        }\n\n    } else {\n\n        srcY = s->next_picture.f.data[0];\n\n        srcU = s->next_picture.f.data[1];\n\n        srcV = s->next_picture.f.data[2];\n\n        luty  = v->next_luty;\n\n        lutuv = v->next_lutuv;\n\n        use_ic = v->next_use_ic;\n\n    }\n\n\n\n    if (!srcY || !srcU) {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Referenced frame missing.\\n\");\n\n        return;\n\n    }\n\n\n\n    src_x   = s->mb_x * 16 + (mx   >> 2);\n\n    src_y   = s->mb_y * 16 + (my   >> 2);\n\n    uvsrc_x = s->mb_x *  8 + (uvmx >> 2);\n\n    uvsrc_y = s->mb_y *  8 + (uvmy >> 2);\n\n\n\n    if (v->profile != PROFILE_ADVANCED) {\n\n        src_x   = av_clip(  src_x, -16, s->mb_width  * 16);\n\n        src_y   = av_clip(  src_y, -16, s->mb_height * 16);\n\n        uvsrc_x = av_clip(uvsrc_x,  -8, s->mb_width  *  8);\n\n        uvsrc_y = av_clip(uvsrc_y,  -8, s->mb_height *  8);\n\n    } else {\n\n        src_x   = av_clip(  src_x, -17, s->avctx->coded_width);\n\n        src_y   = av_clip(  src_y, -18, s->avctx->coded_height + 1);\n\n        uvsrc_x = av_clip(uvsrc_x,  -8, s->avctx->coded_width  >> 1);\n\n        uvsrc_y = av_clip(uvsrc_y,  -8, s->avctx->coded_height >> 1);\n\n    }\n\n\n\n    srcY += src_y   * s->linesize   + src_x;\n\n    srcU += uvsrc_y * s->uvlinesize + uvsrc_x;\n\n    srcV += uvsrc_y * s->uvlinesize + uvsrc_x;\n\n\n\n    if (v->field_mode && v->ref_field_type[dir]) {\n\n        srcY += s->current_picture_ptr->f.linesize[0];\n\n        srcU += s->current_picture_ptr->f.linesize[1];\n\n        srcV += s->current_picture_ptr->f.linesize[2];\n\n    }\n\n\n\n    /* for grayscale we should not try to read from unknown area */\n\n    if (s->flags & CODEC_FLAG_GRAY) {\n\n        srcU = s->edge_emu_buffer + 18 * s->linesize;\n\n        srcV = s->edge_emu_buffer + 18 * s->linesize;\n\n    }\n\n\n\n    if (v->rangeredfrm || use_ic\n\n        || s->h_edge_pos < 22 || v_edge_pos < 22\n\n        || (unsigned)(src_x - s->mspel) > s->h_edge_pos - (mx&3) - 16 - s->mspel * 3\n\n        || (unsigned)(src_y - 1)        > v_edge_pos    - (my&3) - 16 - 3) {\n\n        uint8_t *uvbuf = s->edge_emu_buffer + 19 * s->linesize;\n\n\n\n        srcY -= s->mspel * (1 + s->linesize);\n\n        s->vdsp.emulated_edge_mc(s->edge_emu_buffer, srcY,\n\n                                 s->linesize, s->linesize,\n\n                                 17 + s->mspel * 2, 17 + s->mspel * 2,\n\n                                 src_x - s->mspel, src_y - s->mspel,\n\n                                 s->h_edge_pos, v_edge_pos);\n\n        srcY = s->edge_emu_buffer;\n\n        s->vdsp.emulated_edge_mc(uvbuf, srcU,\n\n                                 s->uvlinesize, s->uvlinesize,\n\n                                 8 + 1, 8 + 1,\n\n                                 uvsrc_x, uvsrc_y, s->h_edge_pos >> 1, v_edge_pos >> 1);\n\n        s->vdsp.emulated_edge_mc(uvbuf + 16, srcV,\n\n                                 s->uvlinesize, s->uvlinesize,\n\n                                 8 + 1, 8 + 1,\n\n                                 uvsrc_x, uvsrc_y, s->h_edge_pos >> 1, v_edge_pos >> 1);\n\n        srcU = uvbuf;\n\n        srcV = uvbuf + 16;\n\n        /* if we deal with range reduction we need to scale source blocks */\n\n        if (v->rangeredfrm) {\n\n            int i, j;\n\n            uint8_t *src, *src2;\n\n\n\n            src = srcY;\n\n            for (j = 0; j < 17 + s->mspel * 2; j++) {\n\n                for (i = 0; i < 17 + s->mspel * 2; i++)\n\n                    src[i] = ((src[i] - 128) >> 1) + 128;\n\n                src += s->linesize;\n\n            }\n\n            src  = srcU;\n\n            src2 = srcV;\n\n            for (j = 0; j < 9; j++) {\n\n                for (i = 0; i < 9; i++) {\n\n                    src[i]  = ((src[i]  - 128) >> 1) + 128;\n\n                    src2[i] = ((src2[i] - 128) >> 1) + 128;\n\n                }\n\n                src  += s->uvlinesize;\n\n                src2 += s->uvlinesize;\n\n            }\n\n        }\n\n        /* if we deal with intensity compensation we need to scale source blocks */\n\n        if (use_ic) {\n\n            int i, j;\n\n            uint8_t *src, *src2;\n\n\n\n            src = srcY;\n\n            for (j = 0; j < 17 + s->mspel * 2; j++) {\n\n                int f = v->field_mode ? v->ref_field_type[dir] : ((j + src_y - s->mspel) & 1) ;\n\n                for (i = 0; i < 17 + s->mspel * 2; i++)\n\n                    src[i] = luty[f][src[i]];\n\n                src += s->linesize;\n\n            }\n\n            src  = srcU;\n\n            src2 = srcV;\n\n            for (j = 0; j < 9; j++) {\n\n                int f = v->field_mode ? v->ref_field_type[dir] : ((j + uvsrc_y) & 1);\n\n                for (i = 0; i < 9; i++) {\n\n                    src[i]  = lutuv[f][src[i]];\n\n                    src2[i] = lutuv[f][src2[i]];\n\n                }\n\n                src  += s->uvlinesize;\n\n                src2 += s->uvlinesize;\n\n            }\n\n        }\n\n        srcY += s->mspel * (1 + s->linesize);\n\n    }\n\n\n\n    if (s->mspel) {\n\n        dxy = ((my & 3) << 2) | (mx & 3);\n\n        v->vc1dsp.put_vc1_mspel_pixels_tab[dxy](s->dest[0]    , srcY    , s->linesize, v->rnd);\n\n        v->vc1dsp.put_vc1_mspel_pixels_tab[dxy](s->dest[0] + 8, srcY + 8, s->linesize, v->rnd);\n\n        srcY += s->linesize * 8;\n\n        v->vc1dsp.put_vc1_mspel_pixels_tab[dxy](s->dest[0] + 8 * s->linesize    , srcY    , s->linesize, v->rnd);\n\n        v->vc1dsp.put_vc1_mspel_pixels_tab[dxy](s->dest[0] + 8 * s->linesize + 8, srcY + 8, s->linesize, v->rnd);\n\n    } else { // hpel mc - always used for luma\n\n        dxy = (my & 2) | ((mx & 2) >> 1);\n\n        if (!v->rnd)\n\n            s->hdsp.put_pixels_tab[0][dxy](s->dest[0], srcY, s->linesize, 16);\n\n        else\n\n            s->hdsp.put_no_rnd_pixels_tab[0][dxy](s->dest[0], srcY, s->linesize, 16);\n\n    }\n\n\n\n    if (s->flags & CODEC_FLAG_GRAY) return;\n\n    /* Chroma MC always uses qpel bilinear */\n\n    uvmx = (uvmx & 3) << 1;\n\n    uvmy = (uvmy & 3) << 1;\n\n    if (!v->rnd) {\n\n        h264chroma->put_h264_chroma_pixels_tab[0](s->dest[1], srcU, s->uvlinesize, 8, uvmx, uvmy);\n\n        h264chroma->put_h264_chroma_pixels_tab[0](s->dest[2], srcV, s->uvlinesize, 8, uvmx, uvmy);\n\n    } else {\n\n        v->vc1dsp.put_no_rnd_vc1_chroma_pixels_tab[0](s->dest[1], srcU, s->uvlinesize, 8, uvmx, uvmy);\n\n        v->vc1dsp.put_no_rnd_vc1_chroma_pixels_tab[0](s->dest[2], srcV, s->uvlinesize, 8, uvmx, uvmy);\n\n    }\n\n}\n", "idx": 7168, "_split": "test", "_hash": "9fc08a9f181c4f9fb3639e2c12b55320"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(yuy2ToUV)(uint8_t *dstU, uint8_t *dstV, uint8_t *src1, uint8_t *src2, int width)\n\n{\n\n#if defined (HAVE_MMX2) || defined (HAVE_3DNOW)\n\n\tasm volatile(\n\n\t\t\"movq \"MANGLE(bm01010101)\", %%mm4\\n\\t\"\n\n\t\t\"mov %0, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\"movq (%1, %%\"REG_a\",4), %%mm0\t\\n\\t\"\n\n\t\t\"movq 8(%1, %%\"REG_a\",4), %%mm1\t\\n\\t\"\n\n\t\t\"movq (%2, %%\"REG_a\",4), %%mm2\t\\n\\t\"\n\n\t\t\"movq 8(%2, %%\"REG_a\",4), %%mm3\t\\n\\t\"\n\n\t\tPAVGB(%%mm2, %%mm0)\n\n\t\tPAVGB(%%mm3, %%mm1)\n\n\t\t\"psrlw $8, %%mm0\t\t\\n\\t\"\n\n\t\t\"psrlw $8, %%mm1\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\"movq %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"psrlw $8, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm4, %%mm1\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\"packuswb %%mm1, %%mm1\t\t\\n\\t\"\n\n\t\t\"movd %%mm0, (%4, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"movd %%mm1, (%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"add $4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t: : \"g\" ((long)-width), \"r\" (src1+width*4), \"r\" (src2+width*4), \"r\" (dstU+width), \"r\" (dstV+width)\n\n\t\t: \"%\"REG_a\n\n\t);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<width; i++)\n\n\t{\n\n\t\tdstU[i]= (src1[4*i + 1] + src2[4*i + 1])>>1;\n\n\t\tdstV[i]= (src1[4*i + 3] + src2[4*i + 3])>>1;\n\n\t}\n\n#endif\n\n}\n", "idx": 7174, "_split": "test", "_hash": "5ed31ae247fcd7c4902f1008b3cdc4e8"}
{"project": "FFmpeg", "commit_id": "ba15aab4a4a296c632bd8d3428b002055109c7d1", "target": 0, "func": "static int mtv_read_header(AVFormatContext *s)\n\n{\n\n    MTVDemuxContext *mtv = s->priv_data;\n\n    AVIOContext   *pb  = s->pb;\n\n    AVStream        *st;\n\n    unsigned int    audio_subsegments;\n\n\n\n    avio_skip(pb, 3);\n\n    mtv->file_size         = avio_rl32(pb);\n\n    mtv->segments          = avio_rl32(pb);\n\n    avio_skip(pb, 32);\n\n    mtv->audio_identifier  = avio_rl24(pb);\n\n    mtv->audio_br          = avio_rl16(pb);\n\n    mtv->img_colorfmt      = avio_rl24(pb);\n\n    mtv->img_bpp           = avio_r8(pb);\n\n    mtv->img_width         = avio_rl16(pb);\n\n    mtv->img_height        = avio_rl16(pb);\n\n    mtv->img_segment_size  = avio_rl16(pb);\n\n\n\n    /* Calculate width and height if missing from header */\n\n\n\n    if(mtv->img_bpp>>3){\n\n    if(!mtv->img_width && mtv->img_height)\n\n        mtv->img_width=mtv->img_segment_size / (mtv->img_bpp>>3)\n\n                        / mtv->img_height;\n\n\n\n    if(!mtv->img_height && mtv->img_width)\n\n        mtv->img_height=mtv->img_segment_size / (mtv->img_bpp>>3)\n\n                        / mtv->img_width;\n\n    }\n\n    if(!mtv->img_height || !mtv->img_width || !mtv->img_segment_size){\n\n        av_log(s, AV_LOG_ERROR, \"width or height or segment_size is invalid and I cannot calculate them from other information\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    avio_skip(pb, 4);\n\n    audio_subsegments = avio_rl16(pb);\n\n\n\n    if (audio_subsegments == 0) {\n\n        avpriv_request_sample(s, \"MTV files without audio\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    mtv->full_segment_size =\n\n        audio_subsegments * (MTV_AUDIO_PADDING_SIZE + MTV_ASUBCHUNK_DATA_SIZE) +\n\n        mtv->img_segment_size;\n\n    mtv->video_fps         = (mtv->audio_br / 4) / audio_subsegments;\n\n\n\n    // FIXME Add sanity check here\n\n\n\n    // all systems go! init decoders\n\n\n\n    // video - raw rgb565\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if(!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avpriv_set_pts_info(st, 64, 1, mtv->video_fps);\n\n    st->codec->codec_type      = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id        = AV_CODEC_ID_RAWVIDEO;\n\n    st->codec->pix_fmt         = AV_PIX_FMT_RGB565BE;\n\n    st->codec->width           = mtv->img_width;\n\n    st->codec->height          = mtv->img_height;\n\n    st->codec->sample_rate     = mtv->video_fps;\n\n    st->codec->extradata       = av_strdup(\"BottomUp\");\n\n    st->codec->extradata_size  = 9;\n\n\n\n    // audio - mp3\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if(!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avpriv_set_pts_info(st, 64, 1, AUDIO_SAMPLING_RATE);\n\n    st->codec->codec_type      = AVMEDIA_TYPE_AUDIO;\n\n    st->codec->codec_id        = AV_CODEC_ID_MP3;\n\n    st->codec->bit_rate        = mtv->audio_br;\n\n    st->need_parsing           = AVSTREAM_PARSE_FULL;\n\n\n\n    // Jump over header\n\n\n\n    if(avio_seek(pb, MTV_HEADER_SIZE, SEEK_SET) != MTV_HEADER_SIZE)\n\n        return AVERROR(EIO);\n\n\n\n    return 0;\n\n\n\n}\n", "idx": 7177, "_split": "test", "_hash": "aa666057311288e8d839c652bd003e1f"}
{"project": "FFmpeg", "commit_id": "6e1b1a27a4034c578018d5042b3c8228278c4cd6", "target": 1, "func": "static int copy_packet_data(AVPacket *pkt, AVPacket *src, int dup)\n\n{\n\n    pkt->data      = NULL;\n\n    pkt->side_data = NULL;\n\n    if (pkt->buf) {\n\n        AVBufferRef *ref = av_buffer_ref(src->buf);\n\n        if (!ref)\n\n            return AVERROR(ENOMEM);\n\n        pkt->buf  = ref;\n\n        pkt->data = ref->data;\n\n    } else {\n\n        DUP_DATA(pkt->data, src->data, pkt->size, 1, ALLOC_BUF);\n\n    }\n\n#if FF_API_DESTRUCT_PACKET\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    pkt->destruct = dummy_destruct_packet;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n    if (pkt->side_data_elems && dup)\n\n        pkt->side_data = src->side_data;\n\n    if (pkt->side_data_elems && !dup) {\n\n        return av_copy_packet_side_data(pkt, src);\n\n    }\n\n    return 0;\n\n\n\nfailed_alloc:\n\n    av_destruct_packet(pkt);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 7204, "_split": "test", "_hash": "59acbafa5a4d3e5920ee82e0ca631a3a"}
{"project": "FFmpeg", "commit_id": "3b9a913db4d303a0305a80de496b1933cba8980f", "target": 1, "func": "offset_t url_fseek(ByteIOContext *s, offset_t offset, int whence)\n\n{\n\n    offset_t offset1;\n\n    offset_t pos= s->pos - (s->write_flag ? 0 : (s->buf_end - s->buffer));\n\n\n\n    if (whence != SEEK_CUR && whence != SEEK_SET)\n\n        return -EINVAL;\n\n\n\n    if (whence == SEEK_CUR) {\n\n        offset1 = pos + (s->buf_ptr - s->buffer);\n\n        if (offset == 0)\n\n            return offset1;\n\n        offset += offset1;\n\n    }\n\n    offset1 = offset - pos;\n\n    if (!s->must_flush &&\n\n        offset1 >= 0 && offset1 < (s->buf_end - s->buffer)) {\n\n        /* can do the seek inside the buffer */\n\n        s->buf_ptr = s->buffer + offset1;\n\n    } else {\n\n        if (!s->seek)\n\n            return -EPIPE;\n\n\n\n#ifdef CONFIG_MUXERS\n\n        if (s->write_flag) {\n\n            flush_buffer(s);\n\n            s->must_flush = 1;\n\n        } else\n\n#endif //CONFIG_MUXERS\n\n        {\n\n            s->buf_end = s->buffer;\n\n        }\n\n        s->buf_ptr = s->buffer;\n\n        if (s->seek(s->opaque, offset, SEEK_SET) == (offset_t)-EPIPE)\n\n            return -EPIPE;\n\n        s->pos = offset;\n\n    }\n\n    s->eof_reached = 0;\n\n    return offset;\n\n}\n", "idx": 7351, "_split": "test", "_hash": "b808f8c2c3241ce0a629001d6f0b16d7"}
{"project": "FFmpeg", "commit_id": "4029f05c8b0943a5446f254142d5e2bfedb50a0d", "target": 1, "func": "static int cuvid_decode_frame(AVCodecContext *avctx, void *data, int *got_frame, AVPacket *avpkt)\n\n{\n\n    CuvidContext *ctx = avctx->priv_data;\n\n    AVHWDeviceContext *device_ctx = (AVHWDeviceContext*)ctx->hwdevice->data;\n\n    AVCUDADeviceContext *device_hwctx = device_ctx->hwctx;\n\n    CUcontext dummy, cuda_ctx = device_hwctx->cuda_ctx;\n\n    AVFrame *frame = data;\n\n    CUVIDSOURCEDATAPACKET cupkt;\n\n    AVPacket filter_packet = { 0 };\n\n    AVPacket filtered_packet = { 0 };\n\n    CUdeviceptr mapped_frame = 0;\n\n    int ret = 0, eret = 0;\n\n\n\n    if (ctx->bsf && avpkt->size) {\n\n        if ((ret = av_packet_ref(&filter_packet, avpkt)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"av_packet_ref failed\\n\");\n\n            return ret;\n\n        }\n\n\n\n        if ((ret = av_bsf_send_packet(ctx->bsf, &filter_packet)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"av_bsf_send_packet failed\\n\");\n\n            av_packet_unref(&filter_packet);\n\n            return ret;\n\n        }\n\n\n\n        if ((ret = av_bsf_receive_packet(ctx->bsf, &filtered_packet)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"av_bsf_receive_packet failed\\n\");\n\n            return ret;\n\n        }\n\n\n\n        avpkt = &filtered_packet;\n\n    }\n\n\n\n    ret = CHECK_CU(cuCtxPushCurrent(cuda_ctx));\n\n    if (ret < 0) {\n\n        av_packet_unref(&filtered_packet);\n\n        return ret;\n\n    }\n\n\n\n    memset(&cupkt, 0, sizeof(cupkt));\n\n\n\n    if (avpkt->size) {\n\n        cupkt.payload_size = avpkt->size;\n\n        cupkt.payload = avpkt->data;\n\n\n\n        if (avpkt->pts != AV_NOPTS_VALUE) {\n\n            cupkt.flags = CUVID_PKT_TIMESTAMP;\n\n            if (avctx->pkt_timebase.num && avctx->pkt_timebase.den)\n\n                cupkt.timestamp = av_rescale_q(avpkt->pts, avctx->pkt_timebase, (AVRational){1, 10000000});\n\n            else\n\n                cupkt.timestamp = avpkt->pts;\n\n        }\n\n    } else {\n\n        cupkt.flags = CUVID_PKT_ENDOFSTREAM;\n\n    }\n\n\n\n    ret = CHECK_CU(cuvidParseVideoData(ctx->cuparser, &cupkt));\n\n\n\n    av_packet_unref(&filtered_packet);\n\n\n\n    if (ret < 0) {\n\n        if (ctx->internal_error)\n\n            ret = ctx->internal_error;\n\n        goto error;\n\n    }\n\n\n\n    if (av_fifo_size(ctx->frame_queue)) {\n\n        CUVIDPARSERDISPINFO dispinfo;\n\n        CUVIDPROCPARAMS params;\n\n        unsigned int pitch = 0;\n\n        int offset = 0;\n\n        int i;\n\n\n\n        av_fifo_generic_read(ctx->frame_queue, &dispinfo, sizeof(CUVIDPARSERDISPINFO), NULL);\n\n\n\n        memset(&params, 0, sizeof(params));\n\n        params.progressive_frame = dispinfo.progressive_frame;\n\n        params.second_field = 0;\n\n        params.top_field_first = dispinfo.top_field_first;\n\n\n\n        ret = CHECK_CU(cuvidMapVideoFrame(ctx->cudecoder, dispinfo.picture_index, &mapped_frame, &pitch, &params));\n\n        if (ret < 0)\n\n            goto error;\n\n\n\n        if (avctx->pix_fmt == AV_PIX_FMT_CUDA) {\n\n            ret = av_hwframe_get_buffer(ctx->hwframe, frame, 0);\n\n            if (ret < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"av_hwframe_get_buffer failed\\n\");\n\n                goto error;\n\n            }\n\n\n\n            ret = ff_decode_frame_props(avctx, frame);\n\n            if (ret < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"ff_decode_frame_props failed\\n\");\n\n                goto error;\n\n            }\n\n\n\n            for (i = 0; i < 2; i++) {\n\n                CUDA_MEMCPY2D cpy = {\n\n                    .srcMemoryType = CU_MEMORYTYPE_DEVICE,\n\n                    .dstMemoryType = CU_MEMORYTYPE_DEVICE,\n\n                    .srcDevice     = mapped_frame,\n\n                    .dstDevice     = (CUdeviceptr)frame->data[i],\n\n                    .srcPitch      = pitch,\n\n                    .dstPitch      = frame->linesize[i],\n\n                    .srcY          = offset,\n\n                    .WidthInBytes  = FFMIN(pitch, frame->linesize[i]),\n\n                    .Height        = avctx->coded_height >> (i ? 1 : 0),\n\n                };\n\n\n\n                ret = CHECK_CU(cuMemcpy2D(&cpy));\n\n                if (ret < 0)\n\n                    goto error;\n\n\n\n                offset += avctx->coded_height;\n\n            }\n\n        } else if (avctx->pix_fmt == AV_PIX_FMT_NV12) {\n\n            AVFrame *tmp_frame = av_frame_alloc();\n\n            if (!tmp_frame) {\n\n                av_log(avctx, AV_LOG_ERROR, \"av_frame_alloc failed\\n\");\n\n                ret = AVERROR(ENOMEM);\n\n                goto error;\n\n            }\n\n\n\n            tmp_frame->format        = AV_PIX_FMT_CUDA;\n\n            tmp_frame->hw_frames_ctx = av_buffer_ref(ctx->hwframe);\n\n            tmp_frame->data[0]       = (uint8_t*)mapped_frame;\n\n            tmp_frame->linesize[0]   = pitch;\n\n            tmp_frame->data[1]       = (uint8_t*)(mapped_frame + avctx->coded_height * pitch);\n\n            tmp_frame->linesize[1]   = pitch;\n\n            tmp_frame->width         = avctx->width;\n\n            tmp_frame->height        = avctx->height;\n\n\n\n            ret = ff_get_buffer(avctx, frame, 0);\n\n            if (ret < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"ff_get_buffer failed\\n\");\n\n                av_frame_free(&tmp_frame);\n\n                goto error;\n\n            }\n\n\n\n            ret = av_hwframe_transfer_data(frame, tmp_frame, 0);\n\n            if (ret) {\n\n                av_log(avctx, AV_LOG_ERROR, \"av_hwframe_transfer_data failed\\n\");\n\n                av_frame_free(&tmp_frame);\n\n                goto error;\n\n            }\n\n\n\n            av_frame_free(&tmp_frame);\n\n        } else {\n\n            ret = AVERROR_BUG;\n\n            goto error;\n\n        }\n\n\n\n        frame->width = avctx->width;\n\n        frame->height = avctx->height;\n\n        if (avctx->pkt_timebase.num && avctx->pkt_timebase.den)\n\n            frame->pts = av_rescale_q(dispinfo.timestamp, (AVRational){1, 10000000}, avctx->pkt_timebase);\n\n        else\n\n            frame->pts = dispinfo.timestamp;\n\n\n\n        /* CUVIDs opaque reordering breaks the internal pkt logic.\n\n         * So set pkt_pts and clear all the other pkt_ fields.\n\n         */\n\n        frame->pkt_pts = frame->pts;\n\n        av_frame_set_pkt_pos(frame, -1);\n\n        av_frame_set_pkt_duration(frame, 0);\n\n        av_frame_set_pkt_size(frame, -1);\n\n\n\n        frame->interlaced_frame = !dispinfo.progressive_frame;\n\n\n\n        if (!dispinfo.progressive_frame)\n\n            frame->top_field_first = dispinfo.top_field_first;\n\n\n\n        *got_frame = 1;\n\n    } else {\n\n        *got_frame = 0;\n\n    }\n\n\n\nerror:\n\n    if (mapped_frame)\n\n        eret = CHECK_CU(cuvidUnmapVideoFrame(ctx->cudecoder, mapped_frame));\n\n\n\n    eret = CHECK_CU(cuCtxPopCurrent(&dummy));\n\n\n\n    if (eret < 0)\n\n        return eret;\n\n    else\n\n        return ret;\n\n}\n", "idx": 7398, "_split": "test", "_hash": "c88306738a9decc3ed6bc7b5f1498da6"}
{"project": "FFmpeg", "commit_id": "1d16a1cf99488f16492b1bb48e023f4da8377e07", "target": 0, "func": "static void ff_h264_idct8_add_sse2(uint8_t *dst, int16_t *block, int stride)\n\n{\n\n    __asm__ volatile(\n\n        \"movdqa   0x10(%1), %%xmm1 \\n\"\n\n        \"movdqa   0x20(%1), %%xmm2 \\n\"\n\n        \"movdqa   0x30(%1), %%xmm3 \\n\"\n\n        \"movdqa   0x50(%1), %%xmm5 \\n\"\n\n        \"movdqa   0x60(%1), %%xmm6 \\n\"\n\n        \"movdqa   0x70(%1), %%xmm7 \\n\"\n\n        H264_IDCT8_1D_SSE2(%%xmm0, %%xmm1, %%xmm2, %%xmm3, %%xmm4, %%xmm5, %%xmm6, %%xmm7)\n\n        TRANSPOSE8(%%xmm4, %%xmm1, %%xmm7, %%xmm3, %%xmm5, %%xmm0, %%xmm2, %%xmm6, (%1))\n\n        \"paddw          %4, %%xmm4 \\n\"\n\n        \"movdqa     %%xmm4, 0x00(%1) \\n\"\n\n        \"movdqa     %%xmm2, 0x40(%1) \\n\"\n\n        H264_IDCT8_1D_SSE2(%%xmm4, %%xmm0, %%xmm6, %%xmm3, %%xmm2, %%xmm5, %%xmm7, %%xmm1)\n\n        \"movdqa     %%xmm6, 0x60(%1) \\n\"\n\n        \"movdqa     %%xmm7, 0x70(%1) \\n\"\n\n        \"pxor       %%xmm7, %%xmm7 \\n\"\n\n        STORE_DIFF_8P(%%xmm2, (%0),      %%xmm6, %%xmm7)\n\n        STORE_DIFF_8P(%%xmm0, (%0,%2),   %%xmm6, %%xmm7)\n\n        STORE_DIFF_8P(%%xmm1, (%0,%2,2), %%xmm6, %%xmm7)\n\n        STORE_DIFF_8P(%%xmm3, (%0,%3),   %%xmm6, %%xmm7)\n\n        \"lea     (%0,%2,4), %0 \\n\"\n\n        STORE_DIFF_8P(%%xmm5, (%0),      %%xmm6, %%xmm7)\n\n        STORE_DIFF_8P(%%xmm4, (%0,%2),   %%xmm6, %%xmm7)\n\n        \"movdqa   0x60(%1), %%xmm0 \\n\"\n\n        \"movdqa   0x70(%1), %%xmm1 \\n\"\n\n        STORE_DIFF_8P(%%xmm0, (%0,%2,2), %%xmm6, %%xmm7)\n\n        STORE_DIFF_8P(%%xmm1, (%0,%3),   %%xmm6, %%xmm7)\n\n        :\"+r\"(dst)\n\n        :\"r\"(block), \"r\"((x86_reg)stride), \"r\"((x86_reg)3L*stride), \"m\"(ff_pw_32)\n\n    );\n\n}\n", "idx": 7428, "_split": "test", "_hash": "0aa0abe699e7202817ec282a36ab3d18"}
{"project": "FFmpeg", "commit_id": "7ec9c5ce8a753175244da971fed9f1e25aef7971", "target": 0, "func": "static int encode_apng(AVCodecContext *avctx, AVPacket *pkt,\n\n                       const AVFrame *pict, int *got_packet)\n\n{\n\n    PNGEncContext *s = avctx->priv_data;\n\n    int ret;\n\n    int enc_row_size;\n\n    size_t max_packet_size;\n\n    APNGFctlChunk fctl_chunk = {0};\n\n\n\n    if (pict && avctx->codec_id == AV_CODEC_ID_APNG && s->color_type == PNG_COLOR_TYPE_PALETTE) {\n\n        uint32_t checksum = ~av_crc(av_crc_get_table(AV_CRC_32_IEEE_LE), ~0U, pict->data[1], 256 * sizeof(uint32_t));\n\n\n\n        if (avctx->frame_number == 0) {\n\n            s->palette_checksum = checksum;\n\n        } else if (checksum != s->palette_checksum) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Input contains more than one unique palette. APNG does not support multiple palettes.\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    enc_row_size    = deflateBound(&s->zstream, (avctx->width * s->bits_per_pixel + 7) >> 3);\n\n    max_packet_size =\n\n        AV_INPUT_BUFFER_MIN_SIZE + // headers\n\n        avctx->height * (\n\n            enc_row_size +\n\n            (4 + 12) * (((int64_t)enc_row_size + IOBUF_SIZE - 1) / IOBUF_SIZE) // fdAT * ceil(enc_row_size / IOBUF_SIZE)\n\n        );\n\n    if (max_packet_size > INT_MAX)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (avctx->frame_number == 0) {\n\n        if (!pict)\n\n            return AVERROR(EINVAL);\n\n\n\n        s->bytestream = avctx->extradata = av_malloc(FF_MIN_BUFFER_SIZE);\n\n        if (!avctx->extradata)\n\n            return AVERROR(ENOMEM);\n\n\n\n        ret = encode_headers(avctx, pict);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        avctx->extradata_size = s->bytestream - avctx->extradata;\n\n\n\n        s->last_frame_packet = av_malloc(max_packet_size);\n\n        if (!s->last_frame_packet)\n\n            return AVERROR(ENOMEM);\n\n    } else if (s->last_frame) {\n\n        ret = ff_alloc_packet2(avctx, pkt, max_packet_size, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        memcpy(pkt->data, s->last_frame_packet, s->last_frame_packet_size);\n\n        pkt->size = s->last_frame_packet_size;\n\n        pkt->pts = pkt->dts = s->last_frame->pts;\n\n    }\n\n\n\n    if (pict) {\n\n        s->bytestream_start =\n\n        s->bytestream       = s->last_frame_packet;\n\n        s->bytestream_end   = s->bytestream + max_packet_size;\n\n\n\n        // We're encoding the frame first, so we have to do a bit of shuffling around\n\n        // to have the image data write to the correct place in the buffer\n\n        fctl_chunk.sequence_number = s->sequence_number;\n\n        ++s->sequence_number;\n\n        s->bytestream += 26 + 12;\n\n\n\n        ret = apng_encode_frame(avctx, pict, &fctl_chunk, &s->last_frame_fctl);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        fctl_chunk.delay_num = 0; // delay filled in during muxing\n\n        fctl_chunk.delay_den = 0;\n\n    } else {\n\n        s->last_frame_fctl.dispose_op = APNG_DISPOSE_OP_NONE;\n\n    }\n\n\n\n    if (s->last_frame) {\n\n        uint8_t* last_fctl_chunk_start = pkt->data;\n\n        uint8_t buf[26];\n\n\n\n        AV_WB32(buf + 0, s->last_frame_fctl.sequence_number);\n\n        AV_WB32(buf + 4, s->last_frame_fctl.width);\n\n        AV_WB32(buf + 8, s->last_frame_fctl.height);\n\n        AV_WB32(buf + 12, s->last_frame_fctl.x_offset);\n\n        AV_WB32(buf + 16, s->last_frame_fctl.y_offset);\n\n        AV_WB16(buf + 20, s->last_frame_fctl.delay_num);\n\n        AV_WB16(buf + 22, s->last_frame_fctl.delay_den);\n\n        buf[24] = s->last_frame_fctl.dispose_op;\n\n        buf[25] = s->last_frame_fctl.blend_op;\n\n        png_write_chunk(&last_fctl_chunk_start, MKTAG('f', 'c', 'T', 'L'), buf, 26);\n\n\n\n        *got_packet = 1;\n\n    }\n\n\n\n    if (pict) {\n\n        if (!s->last_frame) {\n\n            s->last_frame = av_frame_alloc();\n\n            if (!s->last_frame)\n\n                return AVERROR(ENOMEM);\n\n        } else if (s->last_frame_fctl.dispose_op != APNG_DISPOSE_OP_PREVIOUS) {\n\n            if (!s->prev_frame) {\n\n                s->prev_frame = av_frame_alloc();\n\n                if (!s->prev_frame)\n\n                    return AVERROR(ENOMEM);\n\n\n\n                s->prev_frame->format = pict->format;\n\n                s->prev_frame->width = pict->width;\n\n                s->prev_frame->height = pict->height;\n\n                if ((ret = av_frame_get_buffer(s->prev_frame, 32)) < 0)\n\n                    return ret;\n\n            }\n\n\n\n            // Do disposal, but not blending\n\n            memcpy(s->prev_frame->data[0], s->last_frame->data[0],\n\n                   s->last_frame->linesize[0] * s->last_frame->height);\n\n            if (s->last_frame_fctl.dispose_op == APNG_DISPOSE_OP_BACKGROUND) {\n\n                uint32_t y;\n\n                uint8_t bpp = (s->bits_per_pixel + 7) >> 3;\n\n                for (y = s->last_frame_fctl.y_offset; y < s->last_frame_fctl.y_offset + s->last_frame_fctl.height; ++y) {\n\n                    size_t row_start = s->last_frame->linesize[0] * y + bpp * s->last_frame_fctl.x_offset;\n\n                    memset(s->prev_frame->data[0] + row_start, 0, bpp * s->last_frame_fctl.width);\n\n                }\n\n            }\n\n        }\n\n\n\n        av_frame_unref(s->last_frame);\n\n        ret = av_frame_ref(s->last_frame, (AVFrame*)pict);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        s->last_frame_fctl = fctl_chunk;\n\n        s->last_frame_packet_size = s->bytestream - s->bytestream_start;\n\n    } else {\n\n        av_frame_free(&s->last_frame);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 7448, "_split": "test", "_hash": "a1d54735de949866e64030395a1bb1b9"}
{"project": "FFmpeg", "commit_id": "1f28a991effadc64acd6915805b989ab43500f08", "target": 0, "func": "static int decode_unregistered_user_data(H264SEIUnregistered *h, GetBitContext *gb,\n\n                                         void *logctx, int size)\n\n{\n\n    uint8_t *user_data;\n\n    int e, build, i;\n\n\n\n    if (size < 16 || size >= INT_MAX - 16)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    user_data = av_malloc(16 + size + 1);\n\n    if (!user_data)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < size + 16; i++)\n\n        user_data[i] = get_bits(gb, 8);\n\n\n\n    user_data[i] = 0;\n\n    e = sscanf(user_data + 16, \"x264 - core %d\", &build);\n\n    if (e == 1 && build > 0)\n\n        h->x264_build = build;\n\n    if (e == 1 && build == 1 && !strncmp(user_data+16, \"x264 - core 0000\", 16))\n\n        h->x264_build = 67;\n\n\n\n    if (strlen(user_data + 16) > 0)\n\n        av_log(logctx, AV_LOG_DEBUG, \"user data:\\\"%s\\\"\\n\", user_data + 16);\n\n\n\n    av_free(user_data);\n\n    return 0;\n\n}\n", "idx": 7471, "_split": "test", "_hash": "e1977ecfcc25fe1b1c2d2340e5eba6a5"}
{"project": "FFmpeg", "commit_id": "ae21776207e8a2bbe268e7c9e203f7599dd87ddb", "target": 0, "func": "void avfilter_filter_samples(AVFilterLink *link, AVFilterBufferRef *samplesref)\n\n{\n\n    void (*filter_samples)(AVFilterLink *, AVFilterBufferRef *);\n\n    AVFilterPad *dst = link->dstpad;\n\n    int i;\n\n\n\n    FF_DPRINTF_START(NULL, filter_samples); ff_dlog_link(NULL, link, 1);\n\n\n\n    if (!(filter_samples = dst->filter_samples))\n\n        filter_samples = avfilter_default_filter_samples;\n\n\n\n    /* prepare to copy the samples if the buffer has insufficient permissions */\n\n    if ((dst->min_perms & samplesref->perms) != dst->min_perms ||\n\n        dst->rej_perms & samplesref->perms) {\n\n\n\n        av_log(link->dst, AV_LOG_DEBUG,\n\n               \"Copying audio data in avfilter (have perms %x, need %x, reject %x)\\n\",\n\n               samplesref->perms, link->dstpad->min_perms, link->dstpad->rej_perms);\n\n\n\n        link->cur_buf = avfilter_default_get_audio_buffer(link, dst->min_perms,\n\n                                                          samplesref->audio->nb_samples);\n\n        link->cur_buf->pts                = samplesref->pts;\n\n        link->cur_buf->audio->sample_rate = samplesref->audio->sample_rate;\n\n\n\n        /* Copy actual data into new samples buffer */\n\n        for (i = 0; samplesref->data[i]; i++)\n\n            memcpy(link->cur_buf->data[i], samplesref->data[i], samplesref->linesize[0]);\n\n\n\n        avfilter_unref_buffer(samplesref);\n\n    } else\n\n        link->cur_buf = samplesref;\n\n\n\n    filter_samples(link, link->cur_buf);\n\n}\n", "idx": 7472, "_split": "test", "_hash": "0350e652e739dffdad954733e5db3cc2"}
{"project": "FFmpeg", "commit_id": "5674d4b0a35a34b75e3533a8580e0b5a0a8895a7", "target": 0, "func": "static int mpc8_decode_frame(AVCodecContext * avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MPCContext *c = avctx->priv_data;\n\n    GetBitContext gb2, *gb = &gb2;\n\n    int i, j, k, ch, cnt, res, t;\n\n    Band *bands = c->bands;\n\n    int off;\n\n    int maxband, keyframe;\n\n    int last[2];\n\n\n\n    keyframe = c->cur_frame == 0;\n\n\n\n    if(keyframe){\n\n        memset(c->Q, 0, sizeof(c->Q));\n\n        c->last_bits_used = 0;\n\n    }\n\n    init_get_bits(gb, buf, buf_size * 8);\n\n    skip_bits(gb, c->last_bits_used & 7);\n\n\n\n    if(keyframe)\n\n        maxband = mpc8_get_mod_golomb(gb, c->maxbands + 1);\n\n    else{\n\n        maxband = c->last_max_band + get_vlc2(gb, band_vlc.table, MPC8_BANDS_BITS, 2);\n\n        if(maxband > 32) maxband -= 33;\n\n    }\n\n    c->last_max_band = maxband;\n\n\n\n    /* read subband indexes */\n\n    if(maxband){\n\n        last[0] = last[1] = 0;\n\n        for(i = maxband - 1; i >= 0; i--){\n\n            for(ch = 0; ch < 2; ch++){\n\n                last[ch] = get_vlc2(gb, res_vlc[last[ch] > 2].table, MPC8_RES_BITS, 2) + last[ch];\n\n                if(last[ch] > 15) last[ch] -= 17;\n\n                bands[i].res[ch] = last[ch];\n\n            }\n\n        }\n\n        if(c->MSS){\n\n            int mask;\n\n\n\n            cnt = 0;\n\n            for(i = 0; i < maxband; i++)\n\n                if(bands[i].res[0] || bands[i].res[1])\n\n                    cnt++;\n\n            t = mpc8_get_mod_golomb(gb, cnt);\n\n            mask = mpc8_get_mask(gb, cnt, t);\n\n            for(i = maxband - 1; i >= 0; i--)\n\n                if(bands[i].res[0] || bands[i].res[1]){\n\n                    bands[i].msf = mask & 1;\n\n                    mask >>= 1;\n\n                }\n\n        }\n\n    }\n\n    for(i = maxband; i < c->maxbands; i++)\n\n        bands[i].res[0] = bands[i].res[1] = 0;\n\n\n\n    if(keyframe){\n\n        for(i = 0; i < 32; i++)\n\n            c->oldDSCF[0][i] = c->oldDSCF[1][i] = 1;\n\n    }\n\n\n\n    for(i = 0; i < maxband; i++){\n\n        if(bands[i].res[0] || bands[i].res[1]){\n\n            cnt = !!bands[i].res[0] + !!bands[i].res[1] - 1;\n\n            if(cnt >= 0){\n\n                t = get_vlc2(gb, scfi_vlc[cnt].table, scfi_vlc[cnt].bits, 1);\n\n                if(bands[i].res[0]) bands[i].scfi[0] = t >> (2 * cnt);\n\n                if(bands[i].res[1]) bands[i].scfi[1] = t & 3;\n\n            }\n\n        }\n\n    }\n\n\n\n    for(i = 0; i < maxband; i++){\n\n        for(ch = 0; ch < 2; ch++){\n\n            if(!bands[i].res[ch]) continue;\n\n\n\n            if(c->oldDSCF[ch][i]){\n\n                bands[i].scf_idx[ch][0] = get_bits(gb, 7) - 6;\n\n                c->oldDSCF[ch][i] = 0;\n\n            }else{\n\n                t = get_vlc2(gb, dscf_vlc[1].table, MPC8_DSCF1_BITS, 2);\n\n                if(t == 64)\n\n                    t += get_bits(gb, 6);\n\n                bands[i].scf_idx[ch][0] = ((bands[i].scf_idx[ch][2] + t - 25) & 0x7F) - 6;\n\n            }\n\n            for(j = 0; j < 2; j++){\n\n                if((bands[i].scfi[ch] << j) & 2)\n\n                    bands[i].scf_idx[ch][j + 1] = bands[i].scf_idx[ch][j];\n\n                else{\n\n                    t = get_vlc2(gb, dscf_vlc[0].table, MPC8_DSCF0_BITS, 2);\n\n                    if(t == 31)\n\n                        t = 64 + get_bits(gb, 6);\n\n                    bands[i].scf_idx[ch][j + 1] = ((bands[i].scf_idx[ch][j] + t - 25) & 0x7F) - 6;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    for(i = 0, off = 0; i < maxband; i++, off += SAMPLES_PER_BAND){\n\n        for(ch = 0; ch < 2; ch++){\n\n            res = bands[i].res[ch];\n\n            switch(res){\n\n            case -1:\n\n                for(j = 0; j < SAMPLES_PER_BAND; j++)\n\n                    c->Q[ch][off + j] = (av_lfg_get(&c->rnd) & 0x3FC) - 510;\n\n                break;\n\n            case 0:\n\n                break;\n\n            case 1:\n\n                for(j = 0; j < SAMPLES_PER_BAND; j += SAMPLES_PER_BAND / 2){\n\n                    cnt = get_vlc2(gb, q1_vlc.table, MPC8_Q1_BITS, 2);\n\n                    t = mpc8_get_mask(gb, 18, cnt);\n\n                    for(k = 0; k < SAMPLES_PER_BAND / 2; k++, t <<= 1)\n\n                        c->Q[ch][off + j + k] = (t & 0x20000) ? (get_bits1(gb) << 1) - 1 : 0;\n\n                }\n\n                break;\n\n            case 2:\n\n                cnt = 6;//2*mpc8_thres[res]\n\n                for(j = 0; j < SAMPLES_PER_BAND; j += 3){\n\n                    t = get_vlc2(gb, q2_vlc[cnt > 3].table, MPC8_Q2_BITS, 2);\n\n                    c->Q[ch][off + j + 0] = mpc8_idx50[t];\n\n                    c->Q[ch][off + j + 1] = mpc8_idx51[t];\n\n                    c->Q[ch][off + j + 2] = mpc8_idx52[t];\n\n                    cnt = (cnt >> 1) + mpc8_huffq2[t];\n\n                }\n\n                break;\n\n            case 3:\n\n            case 4:\n\n                for(j = 0; j < SAMPLES_PER_BAND; j += 2){\n\n                    t = get_vlc2(gb, q3_vlc[res - 3].table, MPC8_Q3_BITS, 2) + q3_offsets[res - 3];\n\n                    c->Q[ch][off + j + 1] = t >> 4;\n\n                    c->Q[ch][off + j + 0] = (t & 8) ? (t & 0xF) - 16 : (t & 0xF);\n\n                }\n\n                break;\n\n            case 5:\n\n            case 6:\n\n            case 7:\n\n            case 8:\n\n                cnt = 2 * mpc8_thres[res];\n\n                for(j = 0; j < SAMPLES_PER_BAND; j++){\n\n                    t = get_vlc2(gb, quant_vlc[res - 5][cnt > mpc8_thres[res]].table, quant_vlc[res - 5][cnt > mpc8_thres[res]].bits, 2) + quant_offsets[res - 5];\n\n                    c->Q[ch][off + j] = t;\n\n                    cnt = (cnt >> 1) + FFABS(c->Q[ch][off + j]);\n\n                }\n\n                break;\n\n            default:\n\n                for(j = 0; j < SAMPLES_PER_BAND; j++){\n\n                    c->Q[ch][off + j] = get_vlc2(gb, q9up_vlc.table, MPC8_Q9UP_BITS, 2);\n\n                    if(res != 9){\n\n                        c->Q[ch][off + j] <<= res - 9;\n\n                        c->Q[ch][off + j] |= get_bits(gb, res - 9);\n\n                    }\n\n                    c->Q[ch][off + j] -= (1 << (res - 2)) - 1;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    ff_mpc_dequantize_and_synth(c, maxband, data, avctx->channels);\n\n\n\n    c->cur_frame++;\n\n\n\n    c->last_bits_used = get_bits_count(gb);\n\n    if(c->cur_frame >= c->frames)\n\n        c->cur_frame = 0;\n\n    *data_size =  MPC_FRAME_SIZE * 2 * avctx->channels;\n\n\n\n    return c->cur_frame ? c->last_bits_used >> 3 : buf_size;\n\n}\n", "idx": 7558, "_split": "test", "_hash": "126349332fcd57e2ff2132ba91075b17"}
{"project": "FFmpeg", "commit_id": "596b5c488fa1d40f114a64d3b73e1863cab073fb", "target": 0, "func": "static av_cold void init_coef_vlc(VLC *vlc, uint16_t **prun_table,\n\n                                  float **plevel_table, uint16_t **pint_table,\n\n                                  const CoefVLCTable *vlc_table)\n\n{\n\n    int n                        = vlc_table->n;\n\n    const uint8_t  *table_bits   = vlc_table->huffbits;\n\n    const uint32_t *table_codes  = vlc_table->huffcodes;\n\n    const uint16_t *levels_table = vlc_table->levels;\n\n    uint16_t *run_table, *level_table, *int_table;\n\n    float *flevel_table;\n\n    int i, l, j, k, level;\n\n\n\n    init_vlc(vlc, VLCBITS, n, table_bits, 1, 1, table_codes, 4, 4, 0);\n\n\n\n    run_table    = av_malloc(n * sizeof(uint16_t));\n\n    level_table  = av_malloc(n * sizeof(uint16_t));\n\n    flevel_table = av_malloc(n * sizeof(*flevel_table));\n\n    int_table    = av_malloc(n * sizeof(uint16_t));\n\n    i            = 2;\n\n    level        = 1;\n\n    k            = 0;\n\n    while (i < n) {\n\n        int_table[k] = i;\n\n        l            = levels_table[k++];\n\n        for (j = 0; j < l; j++) {\n\n            run_table[i]    = j;\n\n            level_table[i]  = level;\n\n            flevel_table[i] = level;\n\n            i++;\n\n        }\n\n        level++;\n\n    }\n\n    *prun_table   = run_table;\n\n    *plevel_table = flevel_table;\n\n    *pint_table   = int_table;\n\n    av_free(level_table);\n\n}\n", "idx": 7598, "_split": "test", "_hash": "2908d3248d2fa1468860a6196219ac74"}
{"project": "FFmpeg", "commit_id": "d7b2bb5391bf55e8f9421bff7feb4c1fddfac4bf", "target": 0, "func": "static inline int parse_nal_units(AVCodecParserContext *s,\n\n                                  AVCodecContext *avctx,\n\n                                  const uint8_t *buf, int buf_size)\n\n{\n\n    H264ParseContext *p = s->priv_data;\n\n    const uint8_t *buf_end = buf + buf_size;\n\n\n\n    H2645NAL nal = { NULL };\n\n\n\n    unsigned int pps_id;\n\n    unsigned int slice_type;\n\n    int state = -1, got_reset = 0;\n\n    int field_poc[2];\n\n    int ret;\n\n\n\n    /* set some sane default values */\n\n    s->pict_type         = AV_PICTURE_TYPE_I;\n\n    s->key_frame         = 0;\n\n    s->picture_structure = AV_PICTURE_STRUCTURE_UNKNOWN;\n\n\n\n    ff_h264_sei_uninit(&p->sei);\n\n\n\n    if (!buf_size)\n\n        return 0;\n\n\n\n    for (;;) {\n\n        const SPS *sps;\n\n        int src_length, consumed;\n\n        buf = avpriv_find_start_code(buf, buf_end, &state);\n\n        if (buf >= buf_end)\n\n            break;\n\n        --buf;\n\n        src_length = buf_end - buf;\n\n        switch (state & 0x1f) {\n\n        case H264_NAL_SLICE:\n\n        case H264_NAL_IDR_SLICE:\n\n            // Do not walk the whole buffer just to decode slice header\n\n            if ((state & 0x1f) == H264_NAL_IDR_SLICE || ((state >> 5) & 0x3) == 0) {\n\n                /* IDR or disposable slice\n\n                 * No need to decode many bytes because MMCOs shall not be present. */\n\n                if (src_length > 60)\n\n                    src_length = 60;\n\n            } else {\n\n                /* To decode up to MMCOs */\n\n                if (src_length > 1000)\n\n                    src_length = 1000;\n\n            }\n\n            break;\n\n        }\n\n\n\n        consumed = ff_h2645_extract_rbsp(buf, src_length, &nal);\n\n        if (consumed < 0)\n\n            break;\n\n\n\n        ret = init_get_bits(&nal.gb, nal.data, nal.size * 8);\n\n        if (ret < 0)\n\n            goto fail;\n\n        get_bits1(&nal.gb);\n\n        nal.ref_idc = get_bits(&nal.gb, 2);\n\n        nal.type    = get_bits(&nal.gb, 5);\n\n\n\n        switch (nal.type) {\n\n        case H264_NAL_SPS:\n\n            ff_h264_decode_seq_parameter_set(&nal.gb, avctx, &p->ps);\n\n            break;\n\n        case H264_NAL_PPS:\n\n            ff_h264_decode_picture_parameter_set(&nal.gb, avctx, &p->ps,\n\n                                                 nal.size_bits);\n\n            break;\n\n        case H264_NAL_SEI:\n\n            ff_h264_sei_decode(&p->sei, &nal.gb, &p->ps, avctx);\n\n            break;\n\n        case H264_NAL_IDR_SLICE:\n\n            s->key_frame = 1;\n\n\n\n            p->poc.prev_frame_num        = 0;\n\n            p->poc.prev_frame_num_offset = 0;\n\n            p->poc.prev_poc_msb          =\n\n            p->poc.prev_poc_lsb          = 0;\n\n        /* fall through */\n\n        case H264_NAL_SLICE:\n\n            get_ue_golomb(&nal.gb);  // skip first_mb_in_slice\n\n            slice_type   = get_ue_golomb_31(&nal.gb);\n\n            s->pict_type = ff_h264_golomb_to_pict_type[slice_type % 5];\n\n            if (p->sei.recovery_point.recovery_frame_cnt >= 0) {\n\n                /* key frame, since recovery_frame_cnt is set */\n\n                s->key_frame = 1;\n\n            }\n\n            pps_id = get_ue_golomb(&nal.gb);\n\n            if (pps_id >= MAX_PPS_COUNT) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"pps_id %u out of range\\n\", pps_id);\n\n                goto fail;\n\n            }\n\n            if (!p->ps.pps_list[pps_id]) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"non-existing PPS %u referenced\\n\", pps_id);\n\n                goto fail;\n\n            }\n\n            p->ps.pps = (const PPS*)p->ps.pps_list[pps_id]->data;\n\n            if (!p->ps.sps_list[p->ps.pps->sps_id]) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"non-existing SPS %u referenced\\n\", p->ps.pps->sps_id);\n\n                goto fail;\n\n            }\n\n            p->ps.sps = (SPS*)p->ps.sps_list[p->ps.pps->sps_id]->data;\n\n\n\n            sps = p->ps.sps;\n\n\n\n            p->poc.frame_num = get_bits(&nal.gb, sps->log2_max_frame_num);\n\n\n\n            s->coded_width  = 16 * sps->mb_width;\n\n            s->coded_height = 16 * sps->mb_height;\n\n            s->width        = s->coded_width  - (sps->crop_right + sps->crop_left);\n\n            s->height       = s->coded_height - (sps->crop_top   + sps->crop_bottom);\n\n            if (s->width <= 0 || s->height <= 0) {\n\n                s->width  = s->coded_width;\n\n                s->height = s->coded_height;\n\n            }\n\n\n\n            switch (sps->bit_depth_luma) {\n\n            case 9:\n\n                if (sps->chroma_format_idc == 3)      s->format = AV_PIX_FMT_YUV444P9;\n\n                else if (sps->chroma_format_idc == 2) s->format = AV_PIX_FMT_YUV422P9;\n\n                else                                  s->format = AV_PIX_FMT_YUV420P9;\n\n                break;\n\n            case 10:\n\n                if (sps->chroma_format_idc == 3)      s->format = AV_PIX_FMT_YUV444P10;\n\n                else if (sps->chroma_format_idc == 2) s->format = AV_PIX_FMT_YUV422P10;\n\n                else                                  s->format = AV_PIX_FMT_YUV420P10;\n\n                break;\n\n            case 8:\n\n                if (sps->chroma_format_idc == 3)      s->format = AV_PIX_FMT_YUV444P;\n\n                else if (sps->chroma_format_idc == 2) s->format = AV_PIX_FMT_YUV422P;\n\n                else                                  s->format = AV_PIX_FMT_YUV420P;\n\n                break;\n\n            default:\n\n                s->format = AV_PIX_FMT_NONE;\n\n            }\n\n\n\n            avctx->profile = ff_h264_get_profile(sps);\n\n            avctx->level   = sps->level_idc;\n\n\n\n            if (sps->frame_mbs_only_flag) {\n\n                p->picture_structure = PICT_FRAME;\n\n            } else {\n\n                if (get_bits1(&nal.gb)) { // field_pic_flag\n\n                    p->picture_structure = PICT_TOP_FIELD + get_bits1(&nal.gb); // bottom_field_flag\n\n                } else {\n\n                    p->picture_structure = PICT_FRAME;\n\n                }\n\n            }\n\n\n\n            if (nal.type == H264_NAL_IDR_SLICE)\n\n                get_ue_golomb(&nal.gb); /* idr_pic_id */\n\n            if (sps->poc_type == 0) {\n\n                p->poc.poc_lsb = get_bits(&nal.gb, sps->log2_max_poc_lsb);\n\n\n\n                if (p->ps.pps->pic_order_present == 1 &&\n\n                    p->picture_structure == PICT_FRAME)\n\n                    p->poc.delta_poc_bottom = get_se_golomb(&nal.gb);\n\n            }\n\n\n\n            if (sps->poc_type == 1 &&\n\n                !sps->delta_pic_order_always_zero_flag) {\n\n                p->poc.delta_poc[0] = get_se_golomb(&nal.gb);\n\n\n\n                if (p->ps.pps->pic_order_present == 1 &&\n\n                    p->picture_structure == PICT_FRAME)\n\n                    p->poc.delta_poc[1] = get_se_golomb(&nal.gb);\n\n            }\n\n\n\n            /* Decode POC of this picture.\n\n             * The prev_ values needed for decoding POC of the next picture are not set here. */\n\n            field_poc[0] = field_poc[1] = INT_MAX;\n\n            ff_h264_init_poc(field_poc, &s->output_picture_number, sps,\n\n                             &p->poc, p->picture_structure, nal.ref_idc);\n\n\n\n            /* Continue parsing to check if MMCO_RESET is present.\n\n             * FIXME: MMCO_RESET could appear in non-first slice.\n\n             *        Maybe, we should parse all undisposable non-IDR slice of this\n\n             *        picture until encountering MMCO_RESET in a slice of it. */\n\n            if (nal.ref_idc && nal.type != H264_NAL_IDR_SLICE) {\n\n                got_reset = scan_mmco_reset(s, &nal.gb, avctx);\n\n                if (got_reset < 0)\n\n                    goto fail;\n\n            }\n\n\n\n            /* Set up the prev_ values for decoding POC of the next picture. */\n\n            p->poc.prev_frame_num        = got_reset ? 0 : p->poc.frame_num;\n\n            p->poc.prev_frame_num_offset = got_reset ? 0 : p->poc.frame_num_offset;\n\n            if (nal.ref_idc != 0) {\n\n                if (!got_reset) {\n\n                    p->poc.prev_poc_msb = p->poc.poc_msb;\n\n                    p->poc.prev_poc_lsb = p->poc.poc_lsb;\n\n                } else {\n\n                    p->poc.prev_poc_msb = 0;\n\n                    p->poc.prev_poc_lsb =\n\n                        p->picture_structure == PICT_BOTTOM_FIELD ? 0 : field_poc[0];\n\n                }\n\n            }\n\n\n\n            if (sps->pic_struct_present_flag) {\n\n                switch (p->sei.picture_timing.pic_struct) {\n\n                case SEI_PIC_STRUCT_TOP_FIELD:\n\n                case SEI_PIC_STRUCT_BOTTOM_FIELD:\n\n                    s->repeat_pict = 0;\n\n                    break;\n\n                case SEI_PIC_STRUCT_FRAME:\n\n                case SEI_PIC_STRUCT_TOP_BOTTOM:\n\n                case SEI_PIC_STRUCT_BOTTOM_TOP:\n\n                    s->repeat_pict = 1;\n\n                    break;\n\n                case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n\n                case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n\n                    s->repeat_pict = 2;\n\n                    break;\n\n                case SEI_PIC_STRUCT_FRAME_DOUBLING:\n\n                    s->repeat_pict = 3;\n\n                    break;\n\n                case SEI_PIC_STRUCT_FRAME_TRIPLING:\n\n                    s->repeat_pict = 5;\n\n                    break;\n\n                default:\n\n                    s->repeat_pict = p->picture_structure == PICT_FRAME ? 1 : 0;\n\n                    break;\n\n                }\n\n            } else {\n\n                s->repeat_pict = p->picture_structure == PICT_FRAME ? 1 : 0;\n\n            }\n\n\n\n            if (p->picture_structure == PICT_FRAME) {\n\n                s->picture_structure = AV_PICTURE_STRUCTURE_FRAME;\n\n                if (sps->pic_struct_present_flag) {\n\n                    switch (p->sei.picture_timing.pic_struct) {\n\n                    case SEI_PIC_STRUCT_TOP_BOTTOM:\n\n                    case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n\n                        s->field_order = AV_FIELD_TT;\n\n                        break;\n\n                    case SEI_PIC_STRUCT_BOTTOM_TOP:\n\n                    case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n\n                        s->field_order = AV_FIELD_BB;\n\n                        break;\n\n                    default:\n\n                        s->field_order = AV_FIELD_PROGRESSIVE;\n\n                        break;\n\n                    }\n\n                } else {\n\n                    if (field_poc[0] < field_poc[1])\n\n                        s->field_order = AV_FIELD_TT;\n\n                    else if (field_poc[0] > field_poc[1])\n\n                        s->field_order = AV_FIELD_BB;\n\n                    else\n\n                        s->field_order = AV_FIELD_PROGRESSIVE;\n\n                }\n\n            } else {\n\n                if (p->picture_structure == PICT_TOP_FIELD)\n\n                    s->picture_structure = AV_PICTURE_STRUCTURE_TOP_FIELD;\n\n                else\n\n                    s->picture_structure = AV_PICTURE_STRUCTURE_BOTTOM_FIELD;\n\n                s->field_order = AV_FIELD_UNKNOWN;\n\n            }\n\n\n\n            av_freep(&nal.rbsp_buffer);\n\n            return 0; /* no need to evaluate the rest */\n\n        }\n\n        buf += consumed;\n\n    }\n\n    /* didn't find a picture! */\n\n    av_log(avctx, AV_LOG_ERROR, \"missing picture in access unit\\n\");\n\nfail:\n\n    av_freep(&nal.rbsp_buffer);\n\n    return -1;\n\n}\n", "idx": 7609, "_split": "test", "_hash": "db64731ca359c7ffda97cb9894a7d769"}
{"project": "FFmpeg", "commit_id": "c94326c1fc2fb5719c6f28fe1b95c0c74417998b", "target": 1, "func": "static av_always_inline void FUNC(intra_pred)(HEVCContext *s, int x0, int y0,\n\n                                              int log2_size, int c_idx)\n\n{\n\n#define PU(x) \\\n\n    ((x) >> s->ps.sps->log2_min_pu_size)\n\n#define MVF(x, y) \\\n\n    (s->ref->tab_mvf[(x) + (y) * min_pu_width])\n\n#define MVF_PU(x, y) \\\n\n    MVF(PU(x0 + ((x) << hshift)), PU(y0 + ((y) << vshift)))\n\n#define IS_INTRA(x, y) \\\n\n    (MVF_PU(x, y).pred_flag == PF_INTRA)\n\n#define MIN_TB_ADDR_ZS(x, y) \\\n\n    s->ps.pps->min_tb_addr_zs[(y) * (s->ps.sps->tb_mask+2) + (x)]\n\n#define EXTEND(ptr, val, len)         \\\n\ndo {                                  \\\n\n    pixel4 pix = PIXEL_SPLAT_X4(val); \\\n\n    for (i = 0; i < (len); i += 4)    \\\n\n        AV_WN4P(ptr + i, pix);        \\\n\n} while (0)\n\n\n\n#define EXTEND_RIGHT_CIP(ptr, start, length)                                   \\\n\n        for (i = start; i < (start) + (length); i += 4)                        \\\n\n            if (!IS_INTRA(i, -1))                                              \\\n\n                AV_WN4P(&ptr[i], a);                                           \\\n\n            else                                                               \\\n\n                a = PIXEL_SPLAT_X4(ptr[i+3])\n\n#define EXTEND_LEFT_CIP(ptr, start, length) \\\n\n        for (i = start; i > (start) - (length); i--) \\\n\n            if (!IS_INTRA(i - 1, -1)) \\\n\n                ptr[i - 1] = ptr[i]\n\n#define EXTEND_UP_CIP(ptr, start, length)                                      \\\n\n        for (i = (start); i > (start) - (length); i -= 4)                      \\\n\n            if (!IS_INTRA(-1, i - 3))                                          \\\n\n                AV_WN4P(&ptr[i - 3], a);                                       \\\n\n            else                                                               \\\n\n                a = PIXEL_SPLAT_X4(ptr[i - 3])\n\n#define EXTEND_DOWN_CIP(ptr, start, length)                                    \\\n\n        for (i = start; i < (start) + (length); i += 4)                        \\\n\n            if (!IS_INTRA(-1, i))                                              \\\n\n                AV_WN4P(&ptr[i], a);                                           \\\n\n            else                                                               \\\n\n                a = PIXEL_SPLAT_X4(ptr[i + 3])\n\n\n\n    HEVCLocalContext *lc = s->HEVClc;\n\n    int i;\n\n    int hshift = s->ps.sps->hshift[c_idx];\n\n    int vshift = s->ps.sps->vshift[c_idx];\n\n    int size = (1 << log2_size);\n\n    int size_in_luma_h = size << hshift;\n\n    int size_in_tbs_h  = size_in_luma_h >> s->ps.sps->log2_min_tb_size;\n\n    int size_in_luma_v = size << vshift;\n\n    int size_in_tbs_v  = size_in_luma_v >> s->ps.sps->log2_min_tb_size;\n\n    int x = x0 >> hshift;\n\n    int y = y0 >> vshift;\n\n    int x_tb = (x0 >> s->ps.sps->log2_min_tb_size) & s->ps.sps->tb_mask;\n\n    int y_tb = (y0 >> s->ps.sps->log2_min_tb_size) & s->ps.sps->tb_mask;\n\n\n\n    int cur_tb_addr = MIN_TB_ADDR_ZS(x_tb, y_tb);\n\n\n\n    ptrdiff_t stride = s->frame->linesize[c_idx] / sizeof(pixel);\n\n    pixel *src = (pixel*)s->frame->data[c_idx] + x + y * stride;\n\n\n\n    int min_pu_width = s->ps.sps->min_pu_width;\n\n\n\n    enum IntraPredMode mode = c_idx ? lc->tu.intra_pred_mode_c :\n\n                              lc->tu.intra_pred_mode;\n\n    pixel4 a;\n\n    pixel  left_array[2 * MAX_TB_SIZE + 1];\n\n    pixel  filtered_left_array[2 * MAX_TB_SIZE + 1];\n\n    pixel  top_array[2 * MAX_TB_SIZE + 1];\n\n    pixel  filtered_top_array[2 * MAX_TB_SIZE + 1];\n\n\n\n    pixel  *left          = left_array + 1;\n\n    pixel  *top           = top_array  + 1;\n\n    pixel  *filtered_left = filtered_left_array + 1;\n\n    pixel  *filtered_top  = filtered_top_array  + 1;\n\n    int cand_bottom_left = lc->na.cand_bottom_left && cur_tb_addr > MIN_TB_ADDR_ZS( x_tb - 1, (y_tb + size_in_tbs_v) & s->ps.sps->tb_mask);\n\n    int cand_left        = lc->na.cand_left;\n\n    int cand_up_left     = lc->na.cand_up_left;\n\n    int cand_up          = lc->na.cand_up;\n\n    int cand_up_right    = lc->na.cand_up_right    && cur_tb_addr > MIN_TB_ADDR_ZS((x_tb + size_in_tbs_h) & s->ps.sps->tb_mask, y_tb - 1);\n\n\n\n    int bottom_left_size = (FFMIN(y0 + 2 * size_in_luma_v, s->ps.sps->height) -\n\n                           (y0 + size_in_luma_v)) >> vshift;\n\n    int top_right_size   = (FFMIN(x0 + 2 * size_in_luma_h, s->ps.sps->width) -\n\n                           (x0 + size_in_luma_h)) >> hshift;\n\n\n\n    if (s->ps.pps->constrained_intra_pred_flag == 1) {\n\n        int size_in_luma_pu_v = PU(size_in_luma_v);\n\n        int size_in_luma_pu_h = PU(size_in_luma_h);\n\n        int on_pu_edge_x    = !av_mod_uintp2(x0, s->ps.sps->log2_min_pu_size);\n\n        int on_pu_edge_y    = !av_mod_uintp2(y0, s->ps.sps->log2_min_pu_size);\n\n        if (!size_in_luma_pu_h)\n\n            size_in_luma_pu_h++;\n\n        if (cand_bottom_left == 1 && on_pu_edge_x) {\n\n            int x_left_pu   = PU(x0 - 1);\n\n            int y_bottom_pu = PU(y0 + size_in_luma_v);\n\n            int max = FFMIN(size_in_luma_pu_v, s->ps.sps->min_pu_height - y_bottom_pu);\n\n            cand_bottom_left = 0;\n\n            for (i = 0; i < max; i += 2)\n\n                cand_bottom_left |= (MVF(x_left_pu, y_bottom_pu + i).pred_flag == PF_INTRA);\n\n        }\n\n        if (cand_left == 1 && on_pu_edge_x) {\n\n            int x_left_pu   = PU(x0 - 1);\n\n            int y_left_pu   = PU(y0);\n\n            int max = FFMIN(size_in_luma_pu_v, s->ps.sps->min_pu_height - y_left_pu);\n\n            cand_left = 0;\n\n            for (i = 0; i < max; i += 2)\n\n                cand_left |= (MVF(x_left_pu, y_left_pu + i).pred_flag == PF_INTRA);\n\n        }\n\n        if (cand_up_left == 1) {\n\n            int x_left_pu   = PU(x0 - 1);\n\n            int y_top_pu    = PU(y0 - 1);\n\n            cand_up_left = MVF(x_left_pu, y_top_pu).pred_flag == PF_INTRA;\n\n        }\n\n        if (cand_up == 1 && on_pu_edge_y) {\n\n            int x_top_pu    = PU(x0);\n\n            int y_top_pu    = PU(y0 - 1);\n\n            int max = FFMIN(size_in_luma_pu_h, s->ps.sps->min_pu_width - x_top_pu);\n\n            cand_up = 0;\n\n            for (i = 0; i < max; i += 2)\n\n                cand_up |= (MVF(x_top_pu + i, y_top_pu).pred_flag == PF_INTRA);\n\n        }\n\n        if (cand_up_right == 1 && on_pu_edge_y) {\n\n            int y_top_pu    = PU(y0 - 1);\n\n            int x_right_pu  = PU(x0 + size_in_luma_h);\n\n            int max = FFMIN(size_in_luma_pu_h, s->ps.sps->min_pu_width - x_right_pu);\n\n            cand_up_right = 0;\n\n            for (i = 0; i < max; i += 2)\n\n                cand_up_right |= (MVF(x_right_pu + i, y_top_pu).pred_flag == PF_INTRA);\n\n        }\n\n        memset(left, 128, 2 * MAX_TB_SIZE*sizeof(pixel));\n\n        memset(top , 128, 2 * MAX_TB_SIZE*sizeof(pixel));\n\n        top[-1] = 128;\n\n    }\n\n    if (cand_up_left) {\n\n        left[-1] = POS(-1, -1);\n\n        top[-1]  = left[-1];\n\n    }\n\n    if (cand_up)\n\n        memcpy(top, src - stride, size * sizeof(pixel));\n\n    if (cand_up_right) {\n\n        memcpy(top + size, src - stride + size, size * sizeof(pixel));\n\n        EXTEND(top + size + top_right_size, POS(size + top_right_size - 1, -1),\n\n               size - top_right_size);\n\n    }\n\n    if (cand_left)\n\n        for (i = 0; i < size; i++)\n\n            left[i] = POS(-1, i);\n\n    if (cand_bottom_left) {\n\n        for (i = size; i < size + bottom_left_size; i++)\n\n            left[i] = POS(-1, i);\n\n        EXTEND(left + size + bottom_left_size, POS(-1, size + bottom_left_size - 1),\n\n               size - bottom_left_size);\n\n    }\n\n\n\n    if (s->ps.pps->constrained_intra_pred_flag == 1) {\n\n        if (cand_bottom_left || cand_left || cand_up_left || cand_up || cand_up_right) {\n\n            int size_max_x = x0 + ((2 * size) << hshift) < s->ps.sps->width ?\n\n                                    2 * size : (s->ps.sps->width - x0) >> hshift;\n\n            int size_max_y = y0 + ((2 * size) << vshift) < s->ps.sps->height ?\n\n                                    2 * size : (s->ps.sps->height - y0) >> vshift;\n\n            int j = size + (cand_bottom_left? bottom_left_size: 0) -1;\n\n            if (!cand_up_right) {\n\n                size_max_x = x0 + ((size) << hshift) < s->ps.sps->width ?\n\n                                                    size : (s->ps.sps->width - x0) >> hshift;\n\n            }\n\n            if (!cand_bottom_left) {\n\n                size_max_y = y0 + (( size) << vshift) < s->ps.sps->height ?\n\n                                                     size : (s->ps.sps->height - y0) >> vshift;\n\n            }\n\n            if (cand_bottom_left || cand_left || cand_up_left) {\n\n                while (j > -1 && !IS_INTRA(-1, j))\n\n                    j--;\n\n                if (!IS_INTRA(-1, j)) {\n\n                    j = 0;\n\n                    while (j < size_max_x && !IS_INTRA(j, -1))\n\n                        j++;\n\n                    EXTEND_LEFT_CIP(top, j, j + 1);\n\n                    left[-1] = top[-1];\n\n                }\n\n            } else {\n\n                j = 0;\n\n                while (j < size_max_x && !IS_INTRA(j, -1))\n\n                    j++;\n\n                if (j > 0)\n\n                    if (x0 > 0) {\n\n                        EXTEND_LEFT_CIP(top, j, j + 1);\n\n                    } else {\n\n                        EXTEND_LEFT_CIP(top, j, j);\n\n                        top[-1] = top[0];\n\n                    }\n\n                left[-1] = top[-1];\n\n            }\n\n            left[-1] = top[-1];\n\n            if (cand_bottom_left || cand_left) {\n\n                a = PIXEL_SPLAT_X4(left[-1]);\n\n                EXTEND_DOWN_CIP(left, 0, size_max_y);\n\n            }\n\n            if (!cand_left)\n\n                EXTEND(left, left[-1], size);\n\n            if (!cand_bottom_left)\n\n                EXTEND(left + size, left[size - 1], size);\n\n            if (x0 != 0 && y0 != 0) {\n\n                a = PIXEL_SPLAT_X4(left[size_max_y - 1]);\n\n                EXTEND_UP_CIP(left, size_max_y - 1, size_max_y);\n\n                if (!IS_INTRA(-1, - 1))\n\n                    left[-1] = left[0];\n\n            } else if (x0 == 0) {\n\n                EXTEND(left, 0, size_max_y);\n\n            } else {\n\n                a = PIXEL_SPLAT_X4(left[size_max_y - 1]);\n\n                EXTEND_UP_CIP(left, size_max_y - 1, size_max_y);\n\n            }\n\n            top[-1] = left[-1];\n\n            if (y0 != 0) {\n\n                a = PIXEL_SPLAT_X4(left[-1]);\n\n                EXTEND_RIGHT_CIP(top, 0, size_max_x);\n\n            }\n\n        }\n\n    }\n\n    // Infer the unavailable samples\n\n    if (!cand_bottom_left) {\n\n        if (cand_left) {\n\n            EXTEND(left + size, left[size - 1], size);\n\n        } else if (cand_up_left) {\n\n            EXTEND(left, left[-1], 2 * size);\n\n            cand_left = 1;\n\n        } else if (cand_up) {\n\n            left[-1] = top[0];\n\n            EXTEND(left, left[-1], 2 * size);\n\n            cand_up_left = 1;\n\n            cand_left    = 1;\n\n        } else if (cand_up_right) {\n\n            EXTEND(top, top[size], size);\n\n            left[-1] = top[size];\n\n            EXTEND(left, left[-1], 2 * size);\n\n            cand_up      = 1;\n\n            cand_up_left = 1;\n\n            cand_left    = 1;\n\n        } else { // No samples available\n\n            left[-1] = (1 << (BIT_DEPTH - 1));\n\n            EXTEND(top,  left[-1], 2 * size);\n\n            EXTEND(left, left[-1], 2 * size);\n\n        }\n\n    }\n\n\n\n    if (!cand_left)\n\n        EXTEND(left, left[size], size);\n\n    if (!cand_up_left) {\n\n        left[-1] = left[0];\n\n    }\n\n    if (!cand_up)\n\n        EXTEND(top, left[-1], size);\n\n    if (!cand_up_right)\n\n        EXTEND(top + size, top[size - 1], size);\n\n\n\n    top[-1] = left[-1];\n\n\n\n    // Filtering process\n\n    if (!s->ps.sps->intra_smoothing_disabled_flag && (c_idx == 0  || s->ps.sps->chroma_format_idc == 3)) {\n\n        if (mode != INTRA_DC && size != 4){\n\n            int intra_hor_ver_dist_thresh[] = { 7, 1, 0 };\n\n            int min_dist_vert_hor = FFMIN(FFABS((int)(mode - 26U)),\n\n                                          FFABS((int)(mode - 10U)));\n\n            if (min_dist_vert_hor > intra_hor_ver_dist_thresh[log2_size - 3]) {\n\n                int threshold = 1 << (BIT_DEPTH - 5);\n\n                if (s->ps.sps->sps_strong_intra_smoothing_enable_flag && c_idx == 0 &&\n\n                    log2_size == 5 &&\n\n                    FFABS(top[-1]  + top[63]  - 2 * top[31])  < threshold &&\n\n                    FFABS(left[-1] + left[63] - 2 * left[31]) < threshold) {\n\n                    // We can't just overwrite values in top because it could be\n\n                    // a pointer into src\n\n                    filtered_top[-1] = top[-1];\n\n                    filtered_top[63] = top[63];\n\n                    for (i = 0; i < 63; i++)\n\n                        filtered_top[i] = ((64 - (i + 1)) * top[-1] +\n\n                                           (i + 1)  * top[63] + 32) >> 6;\n\n                    for (i = 0; i < 63; i++)\n\n                        left[i] = ((64 - (i + 1)) * left[-1] +\n\n                                   (i + 1)  * left[63] + 32) >> 6;\n\n                    top = filtered_top;\n\n                } else {\n\n                    filtered_left[2 * size - 1] = left[2 * size - 1];\n\n                    filtered_top[2 * size - 1]  = top[2 * size - 1];\n\n                    for (i = 2 * size - 2; i >= 0; i--)\n\n                        filtered_left[i] = (left[i + 1] + 2 * left[i] +\n\n                                            left[i - 1] + 2) >> 2;\n\n                    filtered_top[-1]  =\n\n                    filtered_left[-1] = (left[0] + 2 * left[-1] + top[0] + 2) >> 2;\n\n                    for (i = 2 * size - 2; i >= 0; i--)\n\n                        filtered_top[i] = (top[i + 1] + 2 * top[i] +\n\n                                           top[i - 1] + 2) >> 2;\n\n                    left = filtered_left;\n\n                    top  = filtered_top;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    switch (mode) {\n\n    case INTRA_PLANAR:\n\n        s->hpc.pred_planar[log2_size - 2]((uint8_t *)src, (uint8_t *)top,\n\n                                          (uint8_t *)left, stride);\n\n        break;\n\n    case INTRA_DC:\n\n        s->hpc.pred_dc((uint8_t *)src, (uint8_t *)top,\n\n                       (uint8_t *)left, stride, log2_size, c_idx);\n\n        break;\n\n    default:\n\n        s->hpc.pred_angular[log2_size - 2]((uint8_t *)src, (uint8_t *)top,\n\n                                           (uint8_t *)left, stride, c_idx,\n\n                                           mode);\n\n        break;\n\n    }\n\n}\n", "idx": 7622, "_split": "test", "_hash": "0b47c5fece968d270a377e378b6f36ee"}
{"project": "FFmpeg", "commit_id": "6f3d2fb18bb6225c27e22a95846c42f2093dc3b7", "target": 0, "func": "static void end_last_frame(AVFilterContext *ctx)\n\n{\n\n    TileContext *tile    = ctx->priv;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n    AVFilterBufferRef *out_buf = outlink->out_buf;\n\n\n\n    outlink->out_buf = NULL;\n\n    ff_start_frame(outlink, out_buf);\n\n    while (tile->current < tile->nb_frames)\n\n        draw_blank_frame(ctx, out_buf);\n\n    ff_draw_slice(outlink, 0, out_buf->video->h, 1);\n\n    ff_end_frame(outlink);\n\n    tile->current = 0;\n\n}\n", "idx": 7649, "_split": "test", "_hash": "d5b4b0d8c6c4ab46b29fc7b744a0c8c3"}
{"project": "FFmpeg", "commit_id": "4b1f5e5090abed6c618c8ba380cd7d28d140f867", "target": 0, "func": "void av_register_output_format(AVOutputFormat *format)\n\n{\n\n    AVOutputFormat **p = &first_oformat;\n\n\n\n    while (*p != NULL)\n\n        p = &(*p)->next;\n\n\n\n    *p = format;\n\n    format->next = NULL;\n\n}\n", "idx": 7651, "_split": "test", "_hash": "20eca8d0029108ea428d7534f1df2d8c"}
{"project": "FFmpeg", "commit_id": "a150bad4062a29fc11b32117bc1ade38115cd95b", "target": 0, "func": "AVFilterBufferRef *avfilter_get_video_buffer_ref_from_frame(const AVFrame *frame,\n\n                                                            int perms)\n\n{\n\n    AVFilterBufferRef *picref =\n\n        avfilter_get_video_buffer_ref_from_arrays(frame->data, frame->linesize, perms,\n\n                                                  frame->width, frame->height,\n\n                                                  frame->format);\n\n    if (!picref)\n\n        return NULL;\n\n    avfilter_copy_frame_props(picref, frame);\n\n    return picref;\n\n}\n", "idx": 7659, "_split": "test", "_hash": "d26a4be6b618dfcbc62e21ba9624fc62"}
{"project": "FFmpeg", "commit_id": "369cb092ecbbaff20bb0a2a1d60536c3bc04a8f0", "target": 1, "func": "static OutputStream *new_audio_stream(OptionsContext *o, AVFormatContext *oc)\n\n{\n\n    AVStream *st;\n\n    OutputStream *ost;\n\n    AVCodecContext *audio_enc;\n\n\n\n    ost = new_output_stream(o, oc, AVMEDIA_TYPE_AUDIO);\n\n    st  = ost->st;\n\n\n\n    audio_enc = st->codec;\n\n    audio_enc->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n    if (!ost->stream_copy) {\n\n        char *sample_fmt = NULL;\n\n\n\n        MATCH_PER_STREAM_OPT(audio_channels, i, audio_enc->channels, oc, st);\n\n\n\n        MATCH_PER_STREAM_OPT(sample_fmts, str, sample_fmt, oc, st);\n\n        if (sample_fmt &&\n\n            (audio_enc->sample_fmt = av_get_sample_fmt(sample_fmt)) == AV_SAMPLE_FMT_NONE) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Invalid sample format '%s'\\n\", sample_fmt);\n\n            exit_program(1);\n\n        }\n\n\n\n        MATCH_PER_STREAM_OPT(audio_sample_rate, i, audio_enc->sample_rate, oc, st);\n\n    }\n\n\n\n    return ost;\n\n}\n", "idx": 7666, "_split": "test", "_hash": "da503e5a21eaf2ea2f61699cb3b3fbe1"}
{"project": "FFmpeg", "commit_id": "221402c1c88b9d12130c6f5834029b535ee0e0c5", "target": 1, "func": "static int pcx_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                            AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size       = avpkt->size;\n    AVFrame *const p   = data;\n    int compressed, xmin, ymin, xmax, ymax;\n    unsigned int w, h, bits_per_pixel, bytes_per_line, nplanes, stride, y, x,\n                 bytes_per_scanline;\n    uint8_t *ptr;\n    const uint8_t *buf_end = buf + buf_size;\n    const uint8_t *bufstart = buf;\n    uint8_t *scanline;\n    int ret = -1;\n    if (buf[0] != 0x0a || buf[1] > 5) {\n        av_log(avctx, AV_LOG_ERROR, \"this is not PCX encoded data\\n\");\n    compressed = buf[2];\n    xmin       = AV_RL16(buf + 4);\n    ymin       = AV_RL16(buf + 6);\n    xmax       = AV_RL16(buf + 8);\n    ymax       = AV_RL16(buf + 10);\n    if (xmax < xmin || ymax < ymin) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid image dimensions\\n\");\n    w = xmax - xmin + 1;\n    h = ymax - ymin + 1;\n    bits_per_pixel     = buf[3];\n    bytes_per_line     = AV_RL16(buf + 66);\n    nplanes            = buf[65];\n    bytes_per_scanline = nplanes * bytes_per_line;\n    if (bytes_per_scanline < (w * bits_per_pixel * nplanes + 7) / 8 ||\n        (!compressed && bytes_per_scanline > buf_size / h)) {\n        av_log(avctx, AV_LOG_ERROR, \"PCX data is corrupted\\n\");\n    switch ((nplanes << 8) + bits_per_pixel) {\n    case 0x0308:\n        avctx->pix_fmt = AV_PIX_FMT_RGB24;\n        break;\n    case 0x0108:\n    case 0x0104:\n    case 0x0102:\n    case 0x0101:\n    case 0x0401:\n    case 0x0301:\n    case 0x0201:\n        avctx->pix_fmt = AV_PIX_FMT_PAL8;\n        break;\n    default:\n        av_log(avctx, AV_LOG_ERROR, \"invalid PCX file\\n\");\n    buf += 128;\n    if ((ret = ff_set_dimensions(avctx, w, h)) < 0)\n        return ret;\n    if ((ret = ff_get_buffer(avctx, p, 0)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n        return ret;\n    p->pict_type = AV_PICTURE_TYPE_I;\n    ptr    = p->data[0];\n    stride = p->linesize[0];\n    scanline = av_malloc(bytes_per_scanline + AV_INPUT_BUFFER_PADDING_SIZE);\n    if (!scanline)\n        return AVERROR(ENOMEM);\n    if (nplanes == 3 && bits_per_pixel == 8) {\n        for (y = 0; y < h; y++) {\n            buf = pcx_rle_decode(buf, buf_end,\n                                 scanline, bytes_per_scanline, compressed);\n            for (x = 0; x < w; x++) {\n                ptr[3 * x]     = scanline[x];\n                ptr[3 * x + 1] = scanline[x + bytes_per_line];\n                ptr[3 * x + 2] = scanline[x + (bytes_per_line << 1)];\n            ptr += stride;\n    } else if (nplanes == 1 && bits_per_pixel == 8) {\n        const uint8_t *palstart = bufstart + buf_size - 769;\n        if (buf_size < 769) {\n            av_log(avctx, AV_LOG_ERROR, \"File is too short\\n\");\n            ret = avctx->err_recognition & AV_EF_EXPLODE ?\n                  AVERROR_INVALIDDATA : buf_size;\n            goto end;\n        for (y = 0; y < h; y++, ptr += stride) {\n            buf = pcx_rle_decode(buf, buf_end,\n                                 scanline, bytes_per_scanline, compressed);\n            memcpy(ptr, scanline, w);\n        if (buf != palstart) {\n            av_log(avctx, AV_LOG_WARNING, \"image data possibly corrupted\\n\");\n            buf = palstart;\n        if (*buf++ != 12) {\n            av_log(avctx, AV_LOG_ERROR, \"expected palette after image data\\n\");\n            ret = avctx->err_recognition & AV_EF_EXPLODE ?\n                  AVERROR_INVALIDDATA : buf_size;\n            goto end;\n    } else if (nplanes == 1) {   /* all packed formats, max. 16 colors */\n        GetBitContext s;\n        for (y = 0; y < h; y++) {\n            init_get_bits(&s, scanline, bytes_per_scanline << 3);\n            buf = pcx_rle_decode(buf, buf_end,\n                                 scanline, bytes_per_scanline, compressed);\n            for (x = 0; x < w; x++)\n                ptr[x] = get_bits(&s, bits_per_pixel);\n            ptr += stride;\n    } else {    /* planar, 4, 8 or 16 colors */\n        int i;\n        for (y = 0; y < h; y++) {\n            buf = pcx_rle_decode(buf, buf_end,\n                                 scanline, bytes_per_scanline, compressed);\n            for (x = 0; x < w; x++) {\n                int m = 0x80 >> (x & 7), v = 0;\n                for (i = nplanes - 1; i >= 0; i--) {\n                    v <<= 1;\n                    v  += !!(scanline[i * bytes_per_line + (x >> 3)] & m);\n                ptr[x] = v;\n            ptr += stride;\n    if (nplanes == 1 && bits_per_pixel == 8) {\n        pcx_palette(&buf, (uint32_t *)p->data[1], 256);\n    } else if (bits_per_pixel < 8) {\n        const uint8_t *palette = bufstart + 16;\n        pcx_palette(&palette, (uint32_t *)p->data[1], 16);\n    *got_frame = 1;\n    ret = buf - bufstart;\nend:\n    av_free(scanline);\n    return ret;", "idx": 7670, "_split": "test", "_hash": "319232977e3e099953b52e2a2566c835"}
{"project": "FFmpeg", "commit_id": "4cec43a9eeb58eb9e581a2d9d25f78e5bfbb0960", "target": 0, "func": "static int h264_slice_header_parse(H264Context *h, H264SliceContext *sl)\n\n{\n\n    const SPS *sps;\n\n    const PPS *pps;\n\n    unsigned int first_mb_in_slice;\n\n    unsigned int pps_id;\n\n    int ret;\n\n    unsigned int slice_type, tmp, i;\n\n    int last_pic_structure, last_pic_droppable;\n\n    int needs_reinit = 0;\n\n    int field_pic_flag, bottom_field_flag;\n\n    int frame_num, droppable, picture_structure;\n\n    int mb_aff_frame = 0;\n\n\n\n    first_mb_in_slice = get_ue_golomb(&sl->gb);\n\n\n\n    if (first_mb_in_slice == 0) { // FIXME better field boundary detection\n\n        if (h->current_slice && h->cur_pic_ptr && FIELD_PICTURE(h)) {\n\n            ff_h264_field_end(h, sl, 1);\n\n        }\n\n\n\n        h->current_slice = 0;\n\n        if (!h->first_field) {\n\n            if (h->cur_pic_ptr && !h->droppable) {\n\n                ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                          h->picture_structure == PICT_BOTTOM_FIELD);\n\n            }\n\n            h->cur_pic_ptr = NULL;\n\n        }\n\n    }\n\n\n\n    slice_type = get_ue_golomb_31(&sl->gb);\n\n    if (slice_type > 9) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"slice type %d too large at %d\\n\",\n\n               slice_type, first_mb_in_slice);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (slice_type > 4) {\n\n        slice_type -= 5;\n\n        sl->slice_type_fixed = 1;\n\n    } else\n\n        sl->slice_type_fixed = 0;\n\n\n\n    slice_type         = ff_h264_golomb_to_pict_type[slice_type];\n\n    sl->slice_type     = slice_type;\n\n    sl->slice_type_nos = slice_type & 3;\n\n\n\n    if (h->nal_unit_type  == NAL_IDR_SLICE &&\n\n        sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"A non-intra slice in an IDR NAL unit.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    pps_id = get_ue_golomb(&sl->gb);\n\n    if (pps_id >= MAX_PPS_COUNT) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"pps_id %u out of range\\n\", pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!h->ps.pps_list[pps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing PPS %u referenced\\n\",\n\n               pps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!h->setup_finished) {\n\n        h->ps.pps = (const PPS*)h->ps.pps_list[pps_id]->data;\n\n    } else if (h->ps.pps != (const PPS*)h->ps.pps_list[pps_id]->data) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"PPS changed between slices\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (!h->ps.sps_list[h->ps.pps->sps_id]) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"non-existing SPS %u referenced\\n\",\n\n               h->ps.pps->sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (h->ps.sps != (const SPS*)h->ps.sps_list[h->ps.pps->sps_id]->data) {\n\n        h->ps.sps = (SPS*)h->ps.sps_list[h->ps.pps->sps_id]->data;\n\n\n\n        if (h->bit_depth_luma    != h->ps.sps->bit_depth_luma ||\n\n            h->chroma_format_idc != h->ps.sps->chroma_format_idc)\n\n            needs_reinit         = 1;\n\n    }\n\n\n\n    pps = h->ps.pps;\n\n    sps = h->ps.sps;\n\n\n\n    if (!h->setup_finished) {\n\n        h->avctx->profile = ff_h264_get_profile(sps);\n\n        h->avctx->level   = sps->level_idc;\n\n        h->avctx->refs    = sps->ref_frame_count;\n\n\n\n        if (h->mb_width  != sps->mb_width ||\n\n            h->mb_height != sps->mb_height * (2 - sps->frame_mbs_only_flag))\n\n            needs_reinit = 1;\n\n\n\n        h->mb_width  = sps->mb_width;\n\n        h->mb_height = sps->mb_height * (2 - sps->frame_mbs_only_flag);\n\n        h->mb_num    = h->mb_width * h->mb_height;\n\n        h->mb_stride = h->mb_width + 1;\n\n\n\n        h->b_stride = h->mb_width * 4;\n\n\n\n        h->chroma_y_shift = sps->chroma_format_idc <= 1; // 400 uses yuv420p\n\n\n\n        h->width  = 16 * h->mb_width;\n\n        h->height = 16 * h->mb_height;\n\n\n\n        ret = init_dimensions(h);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        if (sps->video_signal_type_present_flag) {\n\n            h->avctx->color_range = sps->full_range ? AVCOL_RANGE_JPEG\n\n                : AVCOL_RANGE_MPEG;\n\n            if (sps->colour_description_present_flag) {\n\n                if (h->avctx->colorspace != sps->colorspace)\n\n                    needs_reinit = 1;\n\n                h->avctx->color_primaries = sps->color_primaries;\n\n                h->avctx->color_trc       = sps->color_trc;\n\n                h->avctx->colorspace      = sps->colorspace;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (h->context_initialized && needs_reinit) {\n\n        h->context_initialized = 0;\n\n        if (sl != h->slice_ctx) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"changing width %d -> %d / height %d -> %d on \"\n\n                   \"slice %d\\n\",\n\n                   h->width, h->avctx->coded_width,\n\n                   h->height, h->avctx->coded_height,\n\n                   h->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        ff_h264_flush_change(h);\n\n\n\n        if ((ret = get_pixel_format(h)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        av_log(h->avctx, AV_LOG_INFO, \"Reinit context to %dx%d, \"\n\n               \"pix_fmt: %d\\n\", h->width, h->height, h->avctx->pix_fmt);\n\n\n\n        if ((ret = h264_slice_header_init(h)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n    if (!h->context_initialized) {\n\n        if (sl != h->slice_ctx) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Cannot (re-)initialize context during parallel decoding.\\n\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n\n\n        if ((ret = get_pixel_format(h)) < 0)\n\n            return ret;\n\n        h->avctx->pix_fmt = ret;\n\n\n\n        if ((ret = h264_slice_header_init(h)) < 0) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"h264_slice_header_init() failed\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    frame_num = get_bits(&sl->gb, sps->log2_max_frame_num);\n\n    if (!h->setup_finished)\n\n        h->poc.frame_num = frame_num;\n\n\n\n    sl->mb_mbaff       = 0;\n\n\n\n    last_pic_structure = h->picture_structure;\n\n    last_pic_droppable = h->droppable;\n\n\n\n    droppable = h->nal_ref_idc == 0;\n\n    if (sps->frame_mbs_only_flag) {\n\n        picture_structure = PICT_FRAME;\n\n    } else {\n\n        field_pic_flag = get_bits1(&sl->gb);\n\n        if (field_pic_flag) {\n\n            bottom_field_flag = get_bits1(&sl->gb);\n\n            picture_structure = PICT_TOP_FIELD + bottom_field_flag;\n\n        } else {\n\n            picture_structure = PICT_FRAME;\n\n            mb_aff_frame      = sps->mb_aff;\n\n        }\n\n    }\n\n    if (!h->setup_finished) {\n\n        h->droppable         = droppable;\n\n        h->picture_structure = picture_structure;\n\n        h->mb_aff_frame      = mb_aff_frame;\n\n    }\n\n    sl->mb_field_decoding_flag = h->picture_structure != PICT_FRAME;\n\n\n\n    if (h->current_slice != 0) {\n\n        if (last_pic_structure != picture_structure ||\n\n            last_pic_droppable != droppable) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Changing field mode (%d -> %d) between slices is not allowed\\n\",\n\n                   last_pic_structure, h->picture_structure);\n\n            return AVERROR_INVALIDDATA;\n\n        } else if (!h->cur_pic_ptr) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"unset cur_pic_ptr on slice %d\\n\",\n\n                   h->current_slice + 1);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else {\n\n        /* Shorten frame num gaps so we don't have to allocate reference\n\n         * frames just to throw them away */\n\n        if (h->poc.frame_num != h->poc.prev_frame_num) {\n\n            int unwrap_prev_frame_num = h->poc.prev_frame_num;\n\n            int max_frame_num         = 1 << sps->log2_max_frame_num;\n\n\n\n            if (unwrap_prev_frame_num > h->poc.frame_num)\n\n                unwrap_prev_frame_num -= max_frame_num;\n\n\n\n            if ((h->poc.frame_num - unwrap_prev_frame_num) > sps->ref_frame_count) {\n\n                unwrap_prev_frame_num = (h->poc.frame_num - sps->ref_frame_count) - 1;\n\n                if (unwrap_prev_frame_num < 0)\n\n                    unwrap_prev_frame_num += max_frame_num;\n\n\n\n                h->poc.prev_frame_num = unwrap_prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * Here, we're using that to see if we should mark previously\n\n         * decode frames as \"finished\".\n\n         * We have to do that before the \"dummy\" in-between frame allocation,\n\n         * since that can modify s->current_picture_ptr. */\n\n        if (h->first_field) {\n\n            assert(h->cur_pic_ptr);\n\n            assert(h->cur_pic_ptr->f->buf[0]);\n\n            assert(h->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                if (!last_pic_droppable && last_pic_structure != PICT_FRAME) {\n\n                    ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                              last_pic_structure == PICT_TOP_FIELD);\n\n                }\n\n            } else {\n\n                if (h->cur_pic_ptr->frame_num != h->poc.frame_num) {\n\n                    /* This and previous field were reference, but had\n\n                     * different frame_nums. Consider this field first in\n\n                     * pair. Throw away previous field except for reference\n\n                     * purposes. */\n\n                    if (!last_pic_droppable && last_pic_structure != PICT_FRAME) {\n\n                        ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n\n                                                  last_pic_structure == PICT_TOP_FIELD);\n\n                    }\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    if (!((last_pic_structure   == PICT_TOP_FIELD &&\n\n                           h->picture_structure == PICT_BOTTOM_FIELD) ||\n\n                          (last_pic_structure   == PICT_BOTTOM_FIELD &&\n\n                           h->picture_structure == PICT_TOP_FIELD))) {\n\n                        av_log(h->avctx, AV_LOG_ERROR,\n\n                               \"Invalid field mode combination %d/%d\\n\",\n\n                               last_pic_structure, h->picture_structure);\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_INVALIDDATA;\n\n                    } else if (last_pic_droppable != h->droppable) {\n\n                        avpriv_request_sample(h->avctx,\n\n                                              \"Found reference and non-reference fields in the same frame, which\");\n\n                        h->picture_structure = last_pic_structure;\n\n                        h->droppable         = last_pic_droppable;\n\n                        return AVERROR_PATCHWELCOME;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n\n\n        while (h->poc.frame_num != h->poc.prev_frame_num &&\n\n               h->poc.frame_num != (h->poc.prev_frame_num + 1) % (1 << sps->log2_max_frame_num)) {\n\n            H264Picture *prev = h->short_ref_count ? h->short_ref[0] : NULL;\n\n            av_log(h->avctx, AV_LOG_DEBUG, \"Frame num gap %d %d\\n\",\n\n                   h->poc.frame_num, h->poc.prev_frame_num);\n\n            ret = initialize_cur_frame(h);\n\n            if (ret < 0) {\n\n                h->first_field = 0;\n\n                return ret;\n\n            }\n\n\n\n            h->poc.prev_frame_num++;\n\n            h->poc.prev_frame_num        %= 1 << sps->log2_max_frame_num;\n\n            h->cur_pic_ptr->frame_num = h->poc.prev_frame_num;\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 0);\n\n            ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX, 1);\n\n            ret = ff_generate_sliding_window_mmcos(h, 1);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            ret = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n\n            if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n                return ret;\n\n            /* Error concealment: If a ref is missing, copy the previous ref\n\n             * in its place.\n\n             * FIXME: Avoiding a memcpy would be nice, but ref handling makes\n\n             * many assumptions about there being no actual duplicates.\n\n             * FIXME: This does not copy padding for out-of-frame motion\n\n             * vectors.  Given we are concealing a lost frame, this probably\n\n             * is not noticeable by comparison, but it should be fixed. */\n\n            if (h->short_ref_count) {\n\n                if (prev &&\n\n                    h->short_ref[0]->f->width == prev->f->width &&\n\n                    h->short_ref[0]->f->height == prev->f->height &&\n\n                    h->short_ref[0]->f->format == prev->f->format) {\n\n                    av_image_copy(h->short_ref[0]->f->data,\n\n                                  h->short_ref[0]->f->linesize,\n\n                                  (const uint8_t **)prev->f->data,\n\n                                  prev->f->linesize,\n\n                                  prev->f->format,\n\n                                  h->mb_width  * 16,\n\n                                  h->mb_height * 16);\n\n                    h->short_ref[0]->poc = prev->poc + 2;\n\n                }\n\n                h->short_ref[0]->frame_num = h->poc.prev_frame_num;\n\n            }\n\n        }\n\n\n\n        /* See if we have a decoded first field looking for a pair...\n\n         * We're using that to see whether to continue decoding in that\n\n         * frame, or to allocate a new one. */\n\n        if (h->first_field) {\n\n            assert(h->cur_pic_ptr);\n\n            assert(h->cur_pic_ptr->f->buf[0]);\n\n            assert(h->cur_pic_ptr->reference != DELAYED_PIC_REF);\n\n\n\n            /* figure out if we have a complementary field pair */\n\n            if (!FIELD_PICTURE(h) || h->picture_structure == last_pic_structure) {\n\n                /* Previous field is unmatched. Don't display it, but let it\n\n                 * remain for reference if marked as such. */\n\n                h->cur_pic_ptr = NULL;\n\n                h->first_field = FIELD_PICTURE(h);\n\n            } else {\n\n                if (h->cur_pic_ptr->frame_num != h->poc.frame_num) {\n\n                    /* This and the previous field had different frame_nums.\n\n                     * Consider this field first in pair. Throw away previous\n\n                     * one except for reference purposes. */\n\n                    h->first_field = 1;\n\n                    h->cur_pic_ptr = NULL;\n\n                } else {\n\n                    /* Second field in complementary pair */\n\n                    h->first_field = 0;\n\n                }\n\n            }\n\n        } else {\n\n            /* Frame or first field in a potentially complementary pair */\n\n            h->first_field = FIELD_PICTURE(h);\n\n        }\n\n\n\n        if (!FIELD_PICTURE(h) || h->first_field) {\n\n            if (h264_frame_start(h) < 0) {\n\n                h->first_field = 0;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            release_unused_pictures(h, 0);\n\n        }\n\n    }\n\n\n\n    assert(h->mb_num == h->mb_width * h->mb_height);\n\n    if (first_mb_in_slice << FIELD_OR_MBAFF_PICTURE(h) >= h->mb_num ||\n\n        first_mb_in_slice >= h->mb_num) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"first_mb_in_slice overflow\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sl->resync_mb_x = sl->mb_x =  first_mb_in_slice % h->mb_width;\n\n    sl->resync_mb_y = sl->mb_y = (first_mb_in_slice / h->mb_width) <<\n\n                                 FIELD_OR_MBAFF_PICTURE(h);\n\n    if (h->picture_structure == PICT_BOTTOM_FIELD)\n\n        sl->resync_mb_y = sl->mb_y = sl->mb_y + 1;\n\n    assert(sl->mb_y < h->mb_height);\n\n\n\n    if (h->picture_structure == PICT_FRAME) {\n\n        h->curr_pic_num = h->poc.frame_num;\n\n        h->max_pic_num  = 1 << sps->log2_max_frame_num;\n\n    } else {\n\n        h->curr_pic_num = 2 * h->poc.frame_num + 1;\n\n        h->max_pic_num  = 1 << (sps->log2_max_frame_num + 1);\n\n    }\n\n\n\n    if (h->nal_unit_type == NAL_IDR_SLICE)\n\n        get_ue_golomb(&sl->gb); /* idr_pic_id */\n\n\n\n    if (sps->poc_type == 0) {\n\n        int poc_lsb = get_bits(&sl->gb, sps->log2_max_poc_lsb);\n\n\n\n        if (!h->setup_finished)\n\n            h->poc.poc_lsb = poc_lsb;\n\n\n\n        if (pps->pic_order_present == 1 && h->picture_structure == PICT_FRAME) {\n\n            int delta_poc_bottom = get_se_golomb(&sl->gb);\n\n            if (!h->setup_finished)\n\n                h->poc.delta_poc_bottom = delta_poc_bottom;\n\n        }\n\n    }\n\n\n\n    if (sps->poc_type == 1 && !sps->delta_pic_order_always_zero_flag) {\n\n        int delta_poc = get_se_golomb(&sl->gb);\n\n\n\n        if (!h->setup_finished)\n\n            h->poc.delta_poc[0] = delta_poc;\n\n\n\n        if (pps->pic_order_present == 1 && h->picture_structure == PICT_FRAME) {\n\n            delta_poc = get_se_golomb(&sl->gb);\n\n\n\n            if (!h->setup_finished)\n\n                h->poc.delta_poc[1] = delta_poc;\n\n        }\n\n    }\n\n\n\n    if (!h->setup_finished)\n\n        ff_h264_init_poc(h->cur_pic_ptr->field_poc, &h->cur_pic_ptr->poc,\n\n                         sps, &h->poc, h->picture_structure, h->nal_ref_idc);\n\n\n\n    if (pps->redundant_pic_cnt_present)\n\n        sl->redundant_pic_count = get_ue_golomb(&sl->gb);\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B)\n\n        sl->direct_spatial_mv_pred = get_bits1(&sl->gb);\n\n\n\n    ret = ff_h264_parse_ref_count(&sl->list_count, sl->ref_count,\n\n                                  &sl->gb, pps, sl->slice_type_nos,\n\n                                  h->picture_structure);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I) {\n\n       ret = ff_h264_decode_ref_pic_list_reordering(h, sl);\n\n       if (ret < 0) {\n\n           sl->ref_count[1] = sl->ref_count[0] = 0;\n\n           return ret;\n\n       }\n\n    }\n\n\n\n    sl->pwt.use_weight = 0;\n\n    for (i = 0; i < 2; i++) {\n\n        sl->pwt.luma_weight_flag[i]   = 0;\n\n        sl->pwt.chroma_weight_flag[i] = 0;\n\n    }\n\n    if ((pps->weighted_pred && sl->slice_type_nos == AV_PICTURE_TYPE_P) ||\n\n        (pps->weighted_bipred_idc == 1 &&\n\n         sl->slice_type_nos == AV_PICTURE_TYPE_B))\n\n        ff_h264_pred_weight_table(&sl->gb, sps, sl->ref_count,\n\n                                  sl->slice_type_nos, &sl->pwt);\n\n\n\n    // If frame-mt is enabled, only update mmco tables for the first slice\n\n    // in a field. Subsequent slices can temporarily clobber h->mmco_index\n\n    // or h->mmco, which will cause ref list mix-ups and decoding errors\n\n    // further down the line. This may break decoding if the first slice is\n\n    // corrupt, thus we only do this if frame-mt is enabled.\n\n    if (h->nal_ref_idc) {\n\n        ret = ff_h264_decode_ref_pic_marking(h, &sl->gb,\n\n                                             !(h->avctx->active_thread_type & FF_THREAD_FRAME) ||\n\n                                             h->current_slice == 0);\n\n        if (ret < 0 && (h->avctx->err_recognition & AV_EF_EXPLODE))\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (sl->slice_type_nos != AV_PICTURE_TYPE_I && pps->cabac) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"cabac_init_idc %u overflow\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->cabac_init_idc = tmp;\n\n    }\n\n\n\n    sl->last_qscale_diff = 0;\n\n    tmp = pps->init_qp + get_se_golomb(&sl->gb);\n\n    if (tmp > 51 + 6 * (sps->bit_depth_luma - 8)) {\n\n        av_log(h->avctx, AV_LOG_ERROR, \"QP %u out of range\\n\", tmp);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    sl->qscale       = tmp;\n\n    sl->chroma_qp[0] = get_chroma_qp(h, 0, sl->qscale);\n\n    sl->chroma_qp[1] = get_chroma_qp(h, 1, sl->qscale);\n\n    // FIXME qscale / qp ... stuff\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP)\n\n        get_bits1(&sl->gb); /* sp_for_switch_flag */\n\n    if (sl->slice_type == AV_PICTURE_TYPE_SP ||\n\n        sl->slice_type == AV_PICTURE_TYPE_SI)\n\n        get_se_golomb(&sl->gb); /* slice_qs_delta */\n\n\n\n    sl->deblocking_filter     = 1;\n\n    sl->slice_alpha_c0_offset = 0;\n\n    sl->slice_beta_offset     = 0;\n\n    if (pps->deblocking_filter_parameters_present) {\n\n        tmp = get_ue_golomb_31(&sl->gb);\n\n        if (tmp > 2) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"deblocking_filter_idc %u out of range\\n\", tmp);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sl->deblocking_filter = tmp;\n\n        if (sl->deblocking_filter < 2)\n\n            sl->deblocking_filter ^= 1;  // 1<->0\n\n\n\n        if (sl->deblocking_filter) {\n\n            sl->slice_alpha_c0_offset = get_se_golomb(&sl->gb) * 2;\n\n            sl->slice_beta_offset     = get_se_golomb(&sl->gb) * 2;\n\n            if (sl->slice_alpha_c0_offset >  12 ||\n\n                sl->slice_alpha_c0_offset < -12 ||\n\n                sl->slice_beta_offset >  12     ||\n\n                sl->slice_beta_offset < -12) {\n\n                av_log(h->avctx, AV_LOG_ERROR,\n\n                       \"deblocking filter parameters %d %d out of range\\n\",\n\n                       sl->slice_alpha_c0_offset, sl->slice_beta_offset);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 7716, "_split": "test", "_hash": "1a8dbf6815bdbe75f338f738ee723d62"}
{"project": "FFmpeg", "commit_id": "be4dfbf7b71e44a53ca8da882a081e35ea134c83", "target": 0, "func": "int ffurl_shutdown(URLContext *h, int flags)\n\n{\n\n    if (!h->prot->url_shutdown)\n\n        return AVERROR(EINVAL);\n\n    return h->prot->url_shutdown(h, flags);\n\n}\n", "idx": 7729, "_split": "test", "_hash": "c523888b538b99d856189544c5d942a6"}
{"project": "FFmpeg", "commit_id": "465e1dadbef7596a3eb87089a66bb4ecdc26d3c4", "target": 0, "func": "static int get_packetheader(NUTContext *nut, ByteIOContext *bc, int prefix_length, int calculate_checksum)\n\n{\n\n    int64_t start, size, last_size;\n\n    start= url_ftell(bc) - prefix_length;\n\n\n\n    if(start != nut->packet_start + nut->written_packet_size){\n\n        av_log(nut->avf, AV_LOG_ERROR, \"get_packetheader called at weird position\\n\");\n\n        return -1;\n\n    }\n\n    \n\n    if(calculate_checksum)\n\n        init_checksum(bc, update_adler32, 0);\n\n\n\n    size= get_v(bc);\n\n    last_size= get_v(bc);\n\n    if(nut->written_packet_size != last_size){\n\n        av_log(nut->avf, AV_LOG_ERROR, \"packet size missmatch %d != %lld at %lld\\n\", nut->written_packet_size, last_size, start);\n\n        return -1;\n\n    }\n\n\n\n    nut->last_packet_start = nut->packet_start;\n\n    nut->packet_start = start;\n\n    nut->written_packet_size= size;\n\n\n\n    return size;\n\n}\n", "idx": 7777, "_split": "test", "_hash": "d3e7860dc69ff05554eed0c308901eb1"}
{"project": "FFmpeg", "commit_id": "4bb0b31f762c422ad15bee68da7bcf76940cc9fa", "target": 0, "func": "static int output_packet(InputStream *ist, int ist_index,\n\n                         OutputStream *ost_table, int nb_ostreams,\n\n                         const AVPacket *pkt)\n\n{\n\n    AVFormatContext *os;\n\n    OutputStream *ost;\n\n    int ret, i;\n\n    int got_output;\n\n    void *buffer_to_free = NULL;\n\n    static unsigned int samples_size= 0;\n\n    AVSubtitle subtitle, *subtitle_to_free;\n\n    int64_t pkt_pts = AV_NOPTS_VALUE;\n\n#if CONFIG_AVFILTER\n\n    int frame_available;\n\n#endif\n\n    float quality;\n\n\n\n    AVPacket avpkt;\n\n    int bps = av_get_bytes_per_sample(ist->st->codec->sample_fmt);\n\n\n\n    if(ist->next_pts == AV_NOPTS_VALUE)\n\n        ist->next_pts= ist->pts;\n\n\n\n    if (pkt == NULL) {\n\n        /* EOF handling */\n\n        av_init_packet(&avpkt);\n\n        avpkt.data = NULL;\n\n        avpkt.size = 0;\n\n        goto handle_eof;\n\n    } else {\n\n        avpkt = *pkt;\n\n    }\n\n\n\n    if(pkt->dts != AV_NOPTS_VALUE)\n\n        ist->next_pts = ist->pts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n    if(pkt->pts != AV_NOPTS_VALUE)\n\n        pkt_pts = av_rescale_q(pkt->pts, ist->st->time_base, AV_TIME_BASE_Q);\n\n\n\n    //while we have more to decode or while the decoder did output something on EOF\n\n    while (avpkt.size > 0 || (!pkt && got_output)) {\n\n        uint8_t *data_buf, *decoded_data_buf;\n\n        int data_size, decoded_data_size;\n\n        AVFrame *decoded_frame, *filtered_frame;\n\n    handle_eof:\n\n        ist->pts= ist->next_pts;\n\n\n\n        if(avpkt.size && avpkt.size != pkt->size)\n\n            av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING,\n\n                   \"Multiple frames in a packet from stream %d\\n\", pkt->stream_index);\n\n            ist->showed_multi_packet_warning=1;\n\n\n\n        /* decode the packet if needed */\n\n        decoded_frame    = filtered_frame = NULL;\n\n        decoded_data_buf = NULL; /* fail safe */\n\n        decoded_data_size= 0;\n\n        data_buf  = avpkt.data;\n\n        data_size = avpkt.size;\n\n        subtitle_to_free = NULL;\n\n        if (ist->decoding_needed) {\n\n            switch(ist->st->codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:{\n\n                if(pkt && samples_size < FFMAX(pkt->size * bps, AVCODEC_MAX_AUDIO_FRAME_SIZE)) {\n\n                    samples_size = FFMAX(pkt->size * bps, AVCODEC_MAX_AUDIO_FRAME_SIZE);\n\n                    av_free(samples);\n\n                    samples= av_malloc(samples_size);\n\n                }\n\n                decoded_data_size= samples_size;\n\n                    /* XXX: could avoid copy if PCM 16 bits with same\n\n                       endianness as CPU */\n\n                ret = avcodec_decode_audio3(ist->st->codec, samples, &decoded_data_size,\n\n                                            &avpkt);\n\n                if (ret < 0)\n\n                    return ret;\n\n                avpkt.data += ret;\n\n                avpkt.size -= ret;\n\n                data_size   = ret;\n\n                got_output  = decoded_data_size > 0;\n\n                /* Some bug in mpeg audio decoder gives */\n\n                /* decoded_data_size < 0, it seems they are overflows */\n\n                if (!got_output) {\n\n                    /* no audio frame */\n\n                    continue;\n\n                }\n\n                decoded_data_buf = (uint8_t *)samples;\n\n                ist->next_pts += ((int64_t)AV_TIME_BASE/bps * decoded_data_size) /\n\n                    (ist->st->codec->sample_rate * ist->st->codec->channels);\n\n                break;}\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                    decoded_data_size = (ist->st->codec->width * ist->st->codec->height * 3) / 2;\n\n                    if (!(decoded_frame = avcodec_alloc_frame()))\n\n                        return AVERROR(ENOMEM);\n\n                    avpkt.pts = pkt_pts;\n\n                    avpkt.dts = ist->pts;\n\n                    pkt_pts = AV_NOPTS_VALUE;\n\n\n\n                    ret = avcodec_decode_video2(ist->st->codec,\n\n                                                decoded_frame, &got_output, &avpkt);\n\n                    quality = same_quant ? decoded_frame->quality : 0;\n\n                    if (ret < 0)\n\n                        goto fail;\n\n                    if (!got_output) {\n\n                        /* no picture yet */\n\n                        av_freep(&decoded_frame);\n\n                        goto discard_packet;\n\n                    }\n\n                    ist->next_pts = ist->pts = guess_correct_pts(&ist->pts_ctx, decoded_frame->pkt_pts,\n\n                                                                 decoded_frame->pkt_dts);\n\n                    if (ist->st->codec->time_base.num != 0) {\n\n                        int ticks= ist->st->parser ? ist->st->parser->repeat_pict+1 : ist->st->codec->ticks_per_frame;\n\n                        ist->next_pts += ((int64_t)AV_TIME_BASE *\n\n                                          ist->st->codec->time_base.num * ticks) /\n\n                            ist->st->codec->time_base.den;\n\n                    }\n\n                    avpkt.size = 0;\n\n                    buffer_to_free = NULL;\n\n                    pre_process_video_frame(ist, (AVPicture *)decoded_frame, &buffer_to_free);\n\n                    break;\n\n            case AVMEDIA_TYPE_SUBTITLE:\n\n                ret = avcodec_decode_subtitle2(ist->st->codec,\n\n                                               &subtitle, &got_output, &avpkt);\n\n                if (ret < 0)\n\n                    return ret;\n\n                if (!got_output) {\n\n                    goto discard_packet;\n\n                }\n\n                subtitle_to_free = &subtitle;\n\n                avpkt.size = 0;\n\n                break;\n\n            default:\n\n                return -1;\n\n            }\n\n        } else {\n\n            switch(ist->st->codec->codec_type) {\n\n            case AVMEDIA_TYPE_AUDIO:\n\n                ist->next_pts += ((int64_t)AV_TIME_BASE * ist->st->codec->frame_size) /\n\n                    ist->st->codec->sample_rate;\n\n                break;\n\n            case AVMEDIA_TYPE_VIDEO:\n\n                if (ist->st->codec->time_base.num != 0) {\n\n                    int ticks= ist->st->parser ? ist->st->parser->repeat_pict+1 : ist->st->codec->ticks_per_frame;\n\n                    ist->next_pts += ((int64_t)AV_TIME_BASE *\n\n                                      ist->st->codec->time_base.num * ticks) /\n\n                        ist->st->codec->time_base.den;\n\n                }\n\n                break;\n\n            }\n\n            avpkt.size = 0;\n\n        }\n\n\n\n        // preprocess audio (volume)\n\n        if (ist->st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (audio_volume != 256) {\n\n                switch (ist->st->codec->sample_fmt) {\n\n                case AV_SAMPLE_FMT_U8:\n\n                {\n\n                    uint8_t *volp = samples;\n\n                    for (i = 0; i < (decoded_data_size / sizeof(*volp)); i++) {\n\n                        int v = (((*volp - 128) * audio_volume + 128) >> 8) + 128;\n\n                        *volp++ = av_clip_uint8(v);\n\n                    }\n\n                    break;\n\n                }\n\n                case AV_SAMPLE_FMT_S16:\n\n                {\n\n                short *volp;\n\n                volp = samples;\n\n                for(i=0;i<(decoded_data_size / sizeof(short));i++) {\n\n                    int v = ((*volp) * audio_volume + 128) >> 8;\n\n                    *volp++ = av_clip_int16(v);\n\n                }\n\n                break;\n\n                }\n\n                case AV_SAMPLE_FMT_S32:\n\n                {\n\n                    int32_t *volp = samples;\n\n                    for (i = 0; i < (decoded_data_size / sizeof(*volp)); i++) {\n\n                        int64_t v = (((int64_t)*volp * audio_volume + 128) >> 8);\n\n                        *volp++ = av_clipl_int32(v);\n\n                    }\n\n                    break;\n\n                }\n\n                case AV_SAMPLE_FMT_FLT:\n\n                {\n\n                    float *volp = samples;\n\n                    float scale = audio_volume / 256.f;\n\n                    for (i = 0; i < (decoded_data_size / sizeof(*volp)); i++) {\n\n                        *volp++ *= scale;\n\n                    }\n\n                    break;\n\n                }\n\n                case AV_SAMPLE_FMT_DBL:\n\n                {\n\n                    double *volp = samples;\n\n                    double scale = audio_volume / 256.;\n\n                    for (i = 0; i < (decoded_data_size / sizeof(*volp)); i++) {\n\n                        *volp++ *= scale;\n\n                    }\n\n                    break;\n\n                }\n\n                default:\n\n                    av_log(NULL, AV_LOG_FATAL,\n\n                           \"Audio volume adjustment on sample format %s is not supported.\\n\",\n\n                           av_get_sample_fmt_name(ist->st->codec->sample_fmt));\n\n                    exit_program(1);\n\n                }\n\n            }\n\n        }\n\n\n\n        /* frame rate emulation */\n\n        if (input_files[ist->file_index].rate_emu) {\n\n            int64_t pts = av_rescale(ist->pts, 1000000, AV_TIME_BASE);\n\n            int64_t now = av_gettime() - ist->start;\n\n            if (pts > now)\n\n                usleep(pts - now);\n\n        }\n\n        /* if output time reached then transcode raw format,\n\n           encode packets and output them */\n\n        for (i = 0; i < nb_ostreams; i++) {\n\n            OutputFile *of = &output_files[ost_table[i].file_index];\n\n            int frame_size;\n\n\n\n            ost = &ost_table[i];\n\n            if (ost->source_index != ist_index)\n\n                continue;\n\n\n\n            if (of->start_time && ist->pts < of->start_time)\n\n                continue;\n\n\n\n            if (of->recording_time != INT64_MAX &&\n\n                av_compare_ts(ist->pts, AV_TIME_BASE_Q, of->recording_time + of->start_time,\n\n                              (AVRational){1, 1000000}) >= 0) {\n\n                ost->is_past_recording_time = 1;\n\n                continue;\n\n            }\n\n\n\n#if CONFIG_AVFILTER\n\n            if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n                ost->input_video_filter) {\n\n                AVRational sar;\n\n                if (ist->st->sample_aspect_ratio.num)\n\n                    sar = ist->st->sample_aspect_ratio;\n\n                else\n\n                    sar = ist->st->codec->sample_aspect_ratio;\n\n                av_vsrc_buffer_add_frame(ost->input_video_filter, decoded_frame, ist->pts, sar);\n\n                if (!(filtered_frame = avcodec_alloc_frame())) {\n\n                    ret = AVERROR(ENOMEM);\n\n                    goto fail;\n\n                }\n\n            }\n\n            frame_available = ist->st->codec->codec_type != AVMEDIA_TYPE_VIDEO ||\n\n                !ost->output_video_filter || avfilter_poll_frame(ost->output_video_filter->inputs[0]);\n\n            while (frame_available) {\n\n                AVRational ist_pts_tb;\n\n                if (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO && ost->output_video_filter)\n\n                    get_filtered_video_frame(ost->output_video_filter, filtered_frame, &ost->picref, &ist_pts_tb);\n\n                if (ost->picref)\n\n                    ist->pts = av_rescale_q(ost->picref->pts, ist_pts_tb, AV_TIME_BASE_Q);\n\n#else\n\n                filtered_frame = decoded_frame;\n\n#endif\n\n                os = output_files[ost->file_index].ctx;\n\n\n\n                /* set the input output pts pairs */\n\n                //ost->sync_ipts = (double)(ist->pts + input_files[ist->file_index].ts_offset - start_time)/ AV_TIME_BASE;\n\n\n\n                if (ost->encoding_needed) {\n\n                    av_assert0(ist->decoding_needed);\n\n                    switch(ost->st->codec->codec_type) {\n\n                    case AVMEDIA_TYPE_AUDIO:\n\n                        do_audio_out(os, ost, ist, decoded_data_buf, decoded_data_size);\n\n                        break;\n\n                    case AVMEDIA_TYPE_VIDEO:\n\n#if CONFIG_AVFILTER\n\n                        if (ost->picref->video && !ost->frame_aspect_ratio)\n\n                            ost->st->codec->sample_aspect_ratio = ost->picref->video->pixel_aspect;\n\n#endif\n\n                        do_video_out(os, ost, ist, filtered_frame, &frame_size,\n\n                                     same_quant ? quality : ost->st->codec->global_quality);\n\n                        if (vstats_filename && frame_size)\n\n                            do_video_stats(os, ost, frame_size);\n\n                        break;\n\n                    case AVMEDIA_TYPE_SUBTITLE:\n\n                        do_subtitle_out(os, ost, ist, &subtitle,\n\n                                        pkt->pts);\n\n                        break;\n\n                    default:\n\n                        abort();\n\n                    }\n\n                } else {\n\n                    AVPacket opkt;\n\n                    int64_t ost_tb_start_time= av_rescale_q(of->start_time, AV_TIME_BASE_Q, ost->st->time_base);\n\n\n\n                    av_init_packet(&opkt);\n\n\n\n                    if ((!ost->frame_number && !(pkt->flags & AV_PKT_FLAG_KEY)) && !copy_initial_nonkeyframes)\n\n#if !CONFIG_AVFILTER\n\n                        continue;\n\n#else\n\n                        goto cont;\n\n#endif\n\n\n\n                    /* no reencoding needed : output the packet directly */\n\n                    /* force the input stream PTS */\n\n\n\n                    if(ost->st->codec->codec_type == AVMEDIA_TYPE_AUDIO)\n\n                        audio_size += data_size;\n\n                    else if (ost->st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n                        video_size += data_size;\n\n                        ost->sync_opts++;\n\n                    }\n\n\n\n                    opkt.stream_index= ost->index;\n\n                    if(pkt->pts != AV_NOPTS_VALUE)\n\n                        opkt.pts= av_rescale_q(pkt->pts, ist->st->time_base, ost->st->time_base) - ost_tb_start_time;\n\n                    else\n\n                        opkt.pts= AV_NOPTS_VALUE;\n\n\n\n                    if (pkt->dts == AV_NOPTS_VALUE)\n\n                        opkt.dts = av_rescale_q(ist->pts, AV_TIME_BASE_Q, ost->st->time_base);\n\n                    else\n\n                        opkt.dts = av_rescale_q(pkt->dts, ist->st->time_base, ost->st->time_base);\n\n                    opkt.dts -= ost_tb_start_time;\n\n\n\n                    opkt.duration = av_rescale_q(pkt->duration, ist->st->time_base, ost->st->time_base);\n\n                    opkt.flags= pkt->flags;\n\n\n\n                    //FIXME remove the following 2 lines they shall be replaced by the bitstream filters\n\n                    if(   ost->st->codec->codec_id != CODEC_ID_H264\n\n                       && ost->st->codec->codec_id != CODEC_ID_MPEG1VIDEO\n\n                       && ost->st->codec->codec_id != CODEC_ID_MPEG2VIDEO\n\n                       ) {\n\n                        if(av_parser_change(ist->st->parser, ost->st->codec, &opkt.data, &opkt.size, data_buf, data_size, pkt->flags & AV_PKT_FLAG_KEY))\n\n                            opkt.destruct= av_destruct_packet;\n\n                    } else {\n\n                        opkt.data = data_buf;\n\n                        opkt.size = data_size;\n\n                    }\n\n\n\n                    write_frame(os, &opkt, ost->st->codec, ost->bitstream_filters);\n\n                    ost->st->codec->frame_number++;\n\n                    ost->frame_number++;\n\n                    av_free_packet(&opkt);\n\n                }\n\n#if CONFIG_AVFILTER\n\n                cont:\n\n                frame_available = (ist->st->codec->codec_type == AVMEDIA_TYPE_VIDEO) &&\n\n                                   ost->output_video_filter && avfilter_poll_frame(ost->output_video_filter->inputs[0]);\n\n                if (ost->picref)\n\n                    avfilter_unref_buffer(ost->picref);\n\n            }\n\n            av_freep(&filtered_frame);\n\n#endif\n\n            }\n\n\n\nfail:\n\n        av_free(buffer_to_free);\n\n        /* XXX: allocate the subtitles in the codec ? */\n\n        if (subtitle_to_free) {\n\n            avsubtitle_free(subtitle_to_free);\n\n            subtitle_to_free = NULL;\n\n        }\n\n        av_freep(&decoded_frame);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n discard_packet:\n\n\n\n    return 0;\n\n}\n", "idx": 7808, "_split": "test", "_hash": "3a6c9044699b5b2aff4caddd4ddd4fe6"}
{"project": "FFmpeg", "commit_id": "a4c7a5ea27050a28625eabf1ba98cfef9ac6620d", "target": 0, "func": "int ff_mpeg1_find_frame_end(ParseContext *pc, const uint8_t *buf, int buf_size)\n\n{\n\n    int i;\n\n    uint32_t state= pc->state;\n\n\n\n    /* EOF considered as end of frame */\n\n    if (buf_size == 0)\n\n        return 0;\n\n\n\n/*\n\n 0  frame start         -> 1/4\n\n 1  first_SEQEXT        -> 0/2\n\n 2  first field start   -> 3/0\n\n 3  second_SEQEXT       -> 2/0\n\n 4  searching end\n\n*/\n\n\n\n    for(i=0; i<buf_size; i++){\n\n        assert(pc->frame_start_found>=0 && pc->frame_start_found<=4);\n\n        if(pc->frame_start_found&1){\n\n            if(state == EXT_START_CODE && (buf[i]&0xF0) != 0x80)\n\n                pc->frame_start_found--;\n\n            else if(state == EXT_START_CODE+2){\n\n                if((buf[i]&3) == 3) pc->frame_start_found= 0;\n\n                else                pc->frame_start_found= (pc->frame_start_found+1)&3;\n\n            }\n\n            state++;\n\n        }else{\n\n            i= ff_find_start_code(buf+i, buf+buf_size, &state) - buf - 1;\n\n            if(pc->frame_start_found==0 && state >= SLICE_MIN_START_CODE && state <= SLICE_MAX_START_CODE){\n\n                i++;\n\n                pc->frame_start_found=4;\n\n            }\n\n            if(state == SEQ_END_CODE){\n\n                pc->state=-1;\n\n                return i+1;\n\n            }\n\n            if(pc->frame_start_found==2 && state == SEQ_START_CODE)\n\n                pc->frame_start_found= 0;\n\n            if(pc->frame_start_found<4 && state == EXT_START_CODE)\n\n                pc->frame_start_found++;\n\n            if(pc->frame_start_found == 4 && (state&0xFFFFFF00) == 0x100){\n\n                if(state < SLICE_MIN_START_CODE || state > SLICE_MAX_START_CODE){\n\n                    pc->frame_start_found=0;\n\n                    pc->state=-1;\n\n                    return i-3;\n\n                }\n\n            }\n\n        }\n\n    }\n\n    pc->state= state;\n\n    return END_NOT_FOUND;\n\n}\n", "idx": 7834, "_split": "test", "_hash": "66cfbc2721ad9aea7aa61dc8f3b3f6f6"}
{"project": "FFmpeg", "commit_id": "0f8d3d8a462c0152ac489dbb013f6df027edd6c4", "target": 0, "func": "static av_cold int encode_init(AVCodecContext *avctx)\n\n{\n\n    FFV1Context *s = avctx->priv_data;\n\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    int i, j, k, m, ret;\n\n\n\n    if ((ret = ff_ffv1_common_init(avctx)) < 0)\n\n        return ret;\n\n\n\n    s->version = 0;\n\n\n\n    if ((avctx->flags & (AV_CODEC_FLAG_PASS1 | AV_CODEC_FLAG_PASS2)) ||\n\n        avctx->slices > 1)\n\n        s->version = FFMAX(s->version, 2);\n\n\n\n    // Unspecified level & slices, we choose version 1.2+ to ensure multithreaded decodability\n\n    if (avctx->slices == 0 && avctx->level < 0 && avctx->width * avctx->height > 720*576)\n\n        s->version = FFMAX(s->version, 2);\n\n\n\n    if (avctx->level <= 0 && s->version == 2) {\n\n        s->version = 3;\n\n    }\n\n    if (avctx->level >= 0 && avctx->level <= 4) {\n\n        if (avctx->level < s->version) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Version %d needed for requested features but %d requested\\n\", s->version, avctx->level);\n\n            return AVERROR(EINVAL);\n\n        }\n\n        s->version = avctx->level;\n\n    }\n\n\n\n    if (s->ec < 0) {\n\n        s->ec = (s->version >= 3);\n\n    }\n\n\n\n    if ((s->version == 2 || s->version>3) && avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Version 2 needed for requested features but version 2 is experimental and not enabled\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n#if FF_API_CODER_TYPE\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    if (avctx->coder_type != -1)\n\n        s->ac = avctx->coder_type > 0 ? AC_RANGE_CUSTOM_TAB : AC_GOLOMB_RICE;\n\n    else\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n    if (s->ac == 1) // Compatbility with common command line usage\n\n        s->ac = AC_RANGE_CUSTOM_TAB;\n\n    else if (s->ac == AC_RANGE_DEFAULT_TAB_FORCE)\n\n        s->ac = AC_RANGE_DEFAULT_TAB;\n\n\n\n    s->plane_count = 3;\n\n    switch(avctx->pix_fmt) {\n\n    case AV_PIX_FMT_YUV444P9:\n\n    case AV_PIX_FMT_YUV422P9:\n\n    case AV_PIX_FMT_YUV420P9:\n\n    case AV_PIX_FMT_YUVA444P9:\n\n    case AV_PIX_FMT_YUVA422P9:\n\n    case AV_PIX_FMT_YUVA420P9:\n\n        if (!avctx->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 9;\n\n    case AV_PIX_FMT_GRAY10:\n\n    case AV_PIX_FMT_YUV444P10:\n\n    case AV_PIX_FMT_YUV420P10:\n\n    case AV_PIX_FMT_YUV422P10:\n\n    case AV_PIX_FMT_YUVA444P10:\n\n    case AV_PIX_FMT_YUVA422P10:\n\n    case AV_PIX_FMT_YUVA420P10:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 10;\n\n    case AV_PIX_FMT_GRAY12:\n\n    case AV_PIX_FMT_YUV444P12:\n\n    case AV_PIX_FMT_YUV420P12:\n\n    case AV_PIX_FMT_YUV422P12:\n\n        s->packed_at_lsb = 1;\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 12;\n\n    case AV_PIX_FMT_GRAY16:\n\n    case AV_PIX_FMT_YUV444P16:\n\n    case AV_PIX_FMT_YUV422P16:\n\n    case AV_PIX_FMT_YUV420P16:\n\n    case AV_PIX_FMT_YUVA444P16:\n\n    case AV_PIX_FMT_YUVA422P16:\n\n    case AV_PIX_FMT_YUVA420P16:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample) {\n\n            s->bits_per_raw_sample = 16;\n\n        } else if (!s->bits_per_raw_sample) {\n\n            s->bits_per_raw_sample = avctx->bits_per_raw_sample;\n\n        }\n\n        if (s->bits_per_raw_sample <= 8) {\n\n            av_log(avctx, AV_LOG_ERROR, \"bits_per_raw_sample invalid\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        s->version = FFMAX(s->version, 1);\n\n    case AV_PIX_FMT_GRAY8:\n\n    case AV_PIX_FMT_YA8:\n\n    case AV_PIX_FMT_YUV444P:\n\n    case AV_PIX_FMT_YUV440P:\n\n    case AV_PIX_FMT_YUV422P:\n\n    case AV_PIX_FMT_YUV420P:\n\n    case AV_PIX_FMT_YUV411P:\n\n    case AV_PIX_FMT_YUV410P:\n\n    case AV_PIX_FMT_YUVA444P:\n\n    case AV_PIX_FMT_YUVA422P:\n\n    case AV_PIX_FMT_YUVA420P:\n\n        s->chroma_planes = desc->nb_components < 3 ? 0 : 1;\n\n        s->colorspace = 0;\n\n        s->transparency = desc->nb_components == 4 || desc->nb_components == 2;\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 8;\n\n        else if (!s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 8;\n\n        break;\n\n    case AV_PIX_FMT_RGB32:\n\n        s->colorspace = 1;\n\n        s->transparency = 1;\n\n        s->chroma_planes = 1;\n\n        s->bits_per_raw_sample = 8;\n\n        break;\n\n    case AV_PIX_FMT_RGB48:\n\n        s->colorspace = 1;\n\n        s->chroma_planes = 1;\n\n        s->bits_per_raw_sample = 16;\n\n        s->use32bit = 1;\n\n        s->version = FFMAX(s->version, 1);\n\n        if (avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n\n            av_log(avctx, AV_LOG_ERROR, \"16bit RGB is experimental and under development, only use it for experiments\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        break;\n\n    case AV_PIX_FMT_0RGB32:\n\n        s->colorspace = 1;\n\n        s->chroma_planes = 1;\n\n        s->bits_per_raw_sample = 8;\n\n        break;\n\n    case AV_PIX_FMT_GBRP9:\n\n        if (!avctx->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 9;\n\n    case AV_PIX_FMT_GBRP10:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 10;\n\n    case AV_PIX_FMT_GBRP12:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 12;\n\n    case AV_PIX_FMT_GBRP14:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 14;\n\n    case AV_PIX_FMT_GBRP16:\n\n        if (!avctx->bits_per_raw_sample && !s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = 16;\n\n        else if (!s->bits_per_raw_sample)\n\n            s->bits_per_raw_sample = avctx->bits_per_raw_sample;\n\n        s->colorspace = 1;\n\n        s->chroma_planes = 1;\n\n        if (s->bits_per_raw_sample >= 16) {\n\n            s->use32bit = 1;\n\n            if (avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n\n                av_log(avctx, AV_LOG_ERROR, \"16bit RGB is experimental and under development, only use it for experiments\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n        s->version = FFMAX(s->version, 1);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"format not supported\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n    av_assert0(s->bits_per_raw_sample >= 8);\n\n\n\n    if (s->bits_per_raw_sample > 8) {\n\n        if (s->ac == AC_GOLOMB_RICE) {\n\n            av_log(avctx, AV_LOG_INFO,\n\n                    \"bits_per_raw_sample > 8, forcing range coder\\n\");\n\n            s->ac = AC_RANGE_CUSTOM_TAB;\n\n        }\n\n    }\n\n    if (s->transparency) {\n\n        av_log(avctx, AV_LOG_WARNING, \"Storing alpha plane, this will require a recent FFV1 decoder to playback!\\n\");\n\n    }\n\n#if FF_API_PRIVATE_OPT\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    if (avctx->context_model)\n\n        s->context_model = avctx->context_model;\n\n    if (avctx->context_model > 1U) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid context model %d, valid values are 0 and 1\\n\", avctx->context_model);\n\n        return AVERROR(EINVAL);\n\n    }\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    if (s->ac == AC_RANGE_CUSTOM_TAB) {\n\n        for (i = 1; i < 256; i++)\n\n            s->state_transition[i] = ver2_state[i];\n\n    } else {\n\n        RangeCoder c;\n\n        ff_build_rac_states(&c, 0.05 * (1LL << 32), 256 - 8);\n\n        for (i = 1; i < 256; i++)\n\n            s->state_transition[i] = c.one_state[i];\n\n    }\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        s->quant_table_count = 2;\n\n        if (s->bits_per_raw_sample <= 8) {\n\n            s->quant_tables[0][0][i]=           quant11[i];\n\n            s->quant_tables[0][1][i]=        11*quant11[i];\n\n            s->quant_tables[0][2][i]=     11*11*quant11[i];\n\n            s->quant_tables[1][0][i]=           quant11[i];\n\n            s->quant_tables[1][1][i]=        11*quant11[i];\n\n            s->quant_tables[1][2][i]=     11*11*quant5 [i];\n\n            s->quant_tables[1][3][i]=   5*11*11*quant5 [i];\n\n            s->quant_tables[1][4][i]= 5*5*11*11*quant5 [i];\n\n        } else {\n\n            s->quant_tables[0][0][i]=           quant9_10bit[i];\n\n            s->quant_tables[0][1][i]=        11*quant9_10bit[i];\n\n            s->quant_tables[0][2][i]=     11*11*quant9_10bit[i];\n\n            s->quant_tables[1][0][i]=           quant9_10bit[i];\n\n            s->quant_tables[1][1][i]=        11*quant9_10bit[i];\n\n            s->quant_tables[1][2][i]=     11*11*quant5_10bit[i];\n\n            s->quant_tables[1][3][i]=   5*11*11*quant5_10bit[i];\n\n            s->quant_tables[1][4][i]= 5*5*11*11*quant5_10bit[i];\n\n        }\n\n    }\n\n    s->context_count[0] = (11 * 11 * 11        + 1) / 2;\n\n    s->context_count[1] = (11 * 11 * 5 * 5 * 5 + 1) / 2;\n\n    memcpy(s->quant_table, s->quant_tables[s->context_model],\n\n           sizeof(s->quant_table));\n\n\n\n    for (i = 0; i < s->plane_count; i++) {\n\n        PlaneContext *const p = &s->plane[i];\n\n\n\n        memcpy(p->quant_table, s->quant_table, sizeof(p->quant_table));\n\n        p->quant_table_index = s->context_model;\n\n        p->context_count     = s->context_count[p->quant_table_index];\n\n    }\n\n\n\n    if ((ret = ff_ffv1_allocate_initial_states(s)) < 0)\n\n        return ret;\n\n\n\n#if FF_API_CODED_FRAME\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    avctx->coded_frame->pict_type = AV_PICTURE_TYPE_I;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n\n\n    if (!s->transparency)\n\n        s->plane_count = 2;\n\n    if (!s->chroma_planes && s->version > 3)\n\n        s->plane_count--;\n\n\n\n    avcodec_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_h_shift, &s->chroma_v_shift);\n\n    s->picture_number = 0;\n\n\n\n    if (avctx->flags & (AV_CODEC_FLAG_PASS1 | AV_CODEC_FLAG_PASS2)) {\n\n        for (i = 0; i < s->quant_table_count; i++) {\n\n            s->rc_stat2[i] = av_mallocz(s->context_count[i] *\n\n                                        sizeof(*s->rc_stat2[i]));\n\n            if (!s->rc_stat2[i])\n\n                return AVERROR(ENOMEM);\n\n        }\n\n    }\n\n    if (avctx->stats_in) {\n\n        char *p = avctx->stats_in;\n\n        uint8_t (*best_state)[256] = av_malloc_array(256, 256);\n\n        int gob_count = 0;\n\n        char *next;\n\n        if (!best_state)\n\n            return AVERROR(ENOMEM);\n\n\n\n        av_assert0(s->version >= 2);\n\n\n\n        for (;;) {\n\n            for (j = 0; j < 256; j++)\n\n                for (i = 0; i < 2; i++) {\n\n                    s->rc_stat[j][i] = strtol(p, &next, 0);\n\n                    if (next == p) {\n\n                        av_log(avctx, AV_LOG_ERROR,\n\n                               \"2Pass file invalid at %d %d [%s]\\n\", j, i, p);\n\n                        av_freep(&best_state);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    p = next;\n\n                }\n\n            for (i = 0; i < s->quant_table_count; i++)\n\n                for (j = 0; j < s->context_count[i]; j++) {\n\n                    for (k = 0; k < 32; k++)\n\n                        for (m = 0; m < 2; m++) {\n\n                            s->rc_stat2[i][j][k][m] = strtol(p, &next, 0);\n\n                            if (next == p) {\n\n                                av_log(avctx, AV_LOG_ERROR,\n\n                                       \"2Pass file invalid at %d %d %d %d [%s]\\n\",\n\n                                       i, j, k, m, p);\n\n                                av_freep(&best_state);\n\n                                return AVERROR_INVALIDDATA;\n\n                            }\n\n                            p = next;\n\n                        }\n\n                }\n\n            gob_count = strtol(p, &next, 0);\n\n            if (next == p || gob_count <= 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"2Pass file invalid\\n\");\n\n                av_freep(&best_state);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            p = next;\n\n            while (*p == '\\n' || *p == ' ')\n\n                p++;\n\n            if (p[0] == 0)\n\n                break;\n\n        }\n\n        if (s->ac == AC_RANGE_CUSTOM_TAB)\n\n            sort_stt(s, s->state_transition);\n\n\n\n        find_best_state(best_state, s->state_transition);\n\n\n\n        for (i = 0; i < s->quant_table_count; i++) {\n\n            for (k = 0; k < 32; k++) {\n\n                double a=0, b=0;\n\n                int jp = 0;\n\n                for (j = 0; j < s->context_count[i]; j++) {\n\n                    double p = 128;\n\n                    if (s->rc_stat2[i][j][k][0] + s->rc_stat2[i][j][k][1] > 200 && j || a+b > 200) {\n\n                        if (a+b)\n\n                            p = 256.0 * b / (a + b);\n\n                        s->initial_states[i][jp][k] =\n\n                            best_state[av_clip(round(p), 1, 255)][av_clip_uint8((a + b) / gob_count)];\n\n                        for(jp++; jp<j; jp++)\n\n                            s->initial_states[i][jp][k] = s->initial_states[i][jp-1][k];\n\n                        a=b=0;\n\n                    }\n\n                    a += s->rc_stat2[i][j][k][0];\n\n                    b += s->rc_stat2[i][j][k][1];\n\n                    if (a+b) {\n\n                        p = 256.0 * b / (a + b);\n\n                    }\n\n                    s->initial_states[i][j][k] =\n\n                        best_state[av_clip(round(p), 1, 255)][av_clip_uint8((a + b) / gob_count)];\n\n                }\n\n            }\n\n        }\n\n        av_freep(&best_state);\n\n    }\n\n\n\n    if (s->version > 1) {\n\n        int plane_count = 1 + 2*s->chroma_planes + s->transparency;\n\n        s->num_v_slices = (avctx->width > 352 || avctx->height > 288 || !avctx->slices) ? 2 : 1;\n\n\n\n        if (avctx->height < 5)\n\n            s->num_v_slices = 1;\n\n\n\n        for (; s->num_v_slices < 32; s->num_v_slices++) {\n\n            for (s->num_h_slices = s->num_v_slices; s->num_h_slices < 2*s->num_v_slices; s->num_h_slices++) {\n\n                int maxw = (avctx->width  + s->num_h_slices - 1) / s->num_h_slices;\n\n                int maxh = (avctx->height + s->num_v_slices - 1) / s->num_v_slices;\n\n                if (s->num_h_slices > avctx->width || s->num_v_slices > avctx->height)\n\n                    continue;\n\n                if (maxw * maxh * (int64_t)(s->bits_per_raw_sample+1) * plane_count > 8<<24)\n\n                    continue;\n\n                if (avctx->slices == s->num_h_slices * s->num_v_slices && avctx->slices <= MAX_SLICES || !avctx->slices)\n\n                    goto slices_ok;\n\n            }\n\n        }\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Unsupported number %d of slices requested, please specify a \"\n\n               \"supported number with -slices (ex:4,6,9,12,16, ...)\\n\",\n\n               avctx->slices);\n\n        return AVERROR(ENOSYS);\n\nslices_ok:\n\n        if ((ret = write_extradata(s)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    if ((ret = ff_ffv1_init_slice_contexts(s)) < 0)\n\n        return ret;\n\n    s->slice_count = s->max_slice_count;\n\n    if ((ret = ff_ffv1_init_slices_state(s)) < 0)\n\n        return ret;\n\n\n\n#define STATS_OUT_SIZE 1024 * 1024 * 6\n\n    if (avctx->flags & AV_CODEC_FLAG_PASS1) {\n\n        avctx->stats_out = av_mallocz(STATS_OUT_SIZE);\n\n        if (!avctx->stats_out)\n\n            return AVERROR(ENOMEM);\n\n        for (i = 0; i < s->quant_table_count; i++)\n\n            for (j = 0; j < s->max_slice_count; j++) {\n\n                FFV1Context *sf = s->slice_context[j];\n\n                av_assert0(!sf->rc_stat2[i]);\n\n                sf->rc_stat2[i] = av_mallocz(s->context_count[i] *\n\n                                             sizeof(*sf->rc_stat2[i]));\n\n                if (!sf->rc_stat2[i])\n\n                    return AVERROR(ENOMEM);\n\n            }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 7852, "_split": "test", "_hash": "27b4277f0255baca7c9fdf22054a9464"}
{"project": "FFmpeg", "commit_id": "d85aa76115214183e7e3b7d65e950da61474959a", "target": 0, "func": "static int hls_slice_data_wpp(HEVCContext *s, const HEVCNAL *nal)\n\n{\n\n    const uint8_t *data = nal->data;\n\n    int length          = nal->size;\n\n    HEVCLocalContext *lc = s->HEVClc;\n\n    int *ret = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n\n    int *arg = av_malloc_array(s->sh.num_entry_point_offsets + 1, sizeof(int));\n\n    int64_t offset;\n\n    int startheader, cmpt = 0;\n\n    int i, j, res = 0;\n\n\n\n    if (!ret || !arg) {\n\n        av_free(ret);\n\n        av_free(arg);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n\n\n    if (!s->sList[1]) {\n\n        ff_alloc_entries(s->avctx, s->sh.num_entry_point_offsets + 1);\n\n\n\n\n\n        for (i = 1; i < s->threads_number; i++) {\n\n            s->sList[i] = av_malloc(sizeof(HEVCContext));\n\n            memcpy(s->sList[i], s, sizeof(HEVCContext));\n\n            s->HEVClcList[i] = av_mallocz(sizeof(HEVCLocalContext));\n\n            s->sList[i]->HEVClc = s->HEVClcList[i];\n\n        }\n\n    }\n\n\n\n    offset = (lc->gb.index >> 3);\n\n\n\n    for (j = 0, cmpt = 0, startheader = offset + s->sh.entry_point_offset[0]; j < nal->skipped_bytes; j++) {\n\n        if (nal->skipped_bytes_pos[j] >= offset && nal->skipped_bytes_pos[j] < startheader) {\n\n            startheader--;\n\n            cmpt++;\n\n        }\n\n    }\n\n\n\n    for (i = 1; i < s->sh.num_entry_point_offsets; i++) {\n\n        offset += (s->sh.entry_point_offset[i - 1] - cmpt);\n\n        for (j = 0, cmpt = 0, startheader = offset\n\n             + s->sh.entry_point_offset[i]; j < nal->skipped_bytes; j++) {\n\n            if (nal->skipped_bytes_pos[j] >= offset && nal->skipped_bytes_pos[j] < startheader) {\n\n                startheader--;\n\n                cmpt++;\n\n            }\n\n        }\n\n        s->sh.size[i - 1] = s->sh.entry_point_offset[i] - cmpt;\n\n        s->sh.offset[i - 1] = offset;\n\n\n\n    }\n\n    if (s->sh.num_entry_point_offsets != 0) {\n\n        offset += s->sh.entry_point_offset[s->sh.num_entry_point_offsets - 1] - cmpt;\n\n        if (length < offset) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"entry_point_offset table is corrupted\\n\");\n\n            res = AVERROR_INVALIDDATA;\n\n            goto error;\n\n        }\n\n        s->sh.size[s->sh.num_entry_point_offsets - 1] = length - offset;\n\n        s->sh.offset[s->sh.num_entry_point_offsets - 1] = offset;\n\n\n\n    }\n\n    s->data = data;\n\n\n\n    for (i = 1; i < s->threads_number; i++) {\n\n        s->sList[i]->HEVClc->first_qp_group = 1;\n\n        s->sList[i]->HEVClc->qp_y = s->sList[0]->HEVClc->qp_y;\n\n        memcpy(s->sList[i], s, sizeof(HEVCContext));\n\n        s->sList[i]->HEVClc = s->HEVClcList[i];\n\n    }\n\n\n\n    avpriv_atomic_int_set(&s->wpp_err, 0);\n\n    ff_reset_entries(s->avctx);\n\n\n\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++) {\n\n        arg[i] = i;\n\n        ret[i] = 0;\n\n    }\n\n\n\n    if (s->ps.pps->entropy_coding_sync_enabled_flag)\n\n        s->avctx->execute2(s->avctx, hls_decode_entry_wpp, arg, ret, s->sh.num_entry_point_offsets + 1);\n\n\n\n    for (i = 0; i <= s->sh.num_entry_point_offsets; i++)\n\n        res += ret[i];\n\nerror:\n\n    av_free(ret);\n\n    av_free(arg);\n\n    return res;\n\n}\n", "idx": 7854, "_split": "test", "_hash": "a0032863d0abff88fdfd2cae9128a945"}
{"project": "FFmpeg", "commit_id": "bf2cba453244a74331238a472fe0e309f116f4d9", "target": 1, "func": "yuv2rgb_2_c_template(SwsContext *c, const int16_t *buf[2],\n\n                     const int16_t *ubuf[2], const int16_t *vbuf[2],\n\n                     const int16_t *abuf[2], uint8_t *dest, int dstW,\n\n                     int yalpha, int uvalpha, int y,\n\n                     enum PixelFormat target, int hasAlpha)\n\n{\n\n    const int16_t *buf0  = buf[0],  *buf1  = buf[1],\n\n                  *ubuf0 = ubuf[0], *ubuf1 = ubuf[1],\n\n                  *vbuf0 = vbuf[0], *vbuf1 = vbuf[1],\n\n                  *abuf0 = abuf[0], *abuf1 = abuf[1];\n\n    int  yalpha1 = 4095 - yalpha;\n\n    int uvalpha1 = 4095 - uvalpha;\n\n    int i;\n\n\n\n    for (i = 0; i < (dstW >> 1); i++) {\n\n        int Y1 = (buf0[i * 2]     * yalpha1  + buf1[i * 2]     * yalpha)  >> 19;\n\n        int Y2 = (buf0[i * 2 + 1] * yalpha1  + buf1[i * 2 + 1] * yalpha)  >> 19;\n\n        int U  = (ubuf0[i]        * uvalpha1 + ubuf1[i]        * uvalpha) >> 19;\n\n        int V  = (vbuf0[i]        * uvalpha1 + vbuf1[i]        * uvalpha) >> 19;\n\n        int A1, A2;\n\n        const void *r =  c->table_rV[V],\n\n                   *g = (c->table_gU[U] + c->table_gV[V]),\n\n                   *b =  c->table_bU[U];\n\n\n\n        if (hasAlpha) {\n\n            A1 = (abuf0[i * 2    ] * yalpha1 + abuf1[i * 2    ] * yalpha) >> 19;\n\n            A2 = (abuf0[i * 2 + 1] * yalpha1 + abuf1[i * 2 + 1] * yalpha) >> 19;\n\n        }\n\n\n\n        yuv2rgb_write(dest, i, Y1, Y2, U, V, hasAlpha ? A1 : 0, hasAlpha ? A2 : 0,\n\n                      r, g, b, y, target, hasAlpha);\n\n    }\n\n}\n", "idx": 7885, "_split": "test", "_hash": "ebea9c5d4ec11122e7b1369f07f64075"}
{"project": "FFmpeg", "commit_id": "b88be742fac7a77a8095e8155ba8790db4b77568", "target": 1, "func": "static int minimum_frame_bits(VC2EncContext *s)\n\n{\n\n    int slice_x, slice_y, bits = 0;\n\n    s->size_scaler = 64;\n\n    for (slice_y = 0; slice_y < s->num_y; slice_y++) {\n\n        for (slice_x = 0; slice_x < s->num_x; slice_x++) {\n\n            bits += count_hq_slice(s, NULL, slice_x, slice_y, s->q_ceil);\n\n        }\n\n    }\n\n    return bits;\n\n}\n", "idx": 7892, "_split": "test", "_hash": "24a18297175e6f402382afb2514d3a0b"}
{"project": "FFmpeg", "commit_id": "08d2cee49c323715b66df0e4ff45ec0e07aaea7b", "target": 0, "func": "static int opt_input_file(const char *opt, const char *filename)\n\n{\n\n    AVFormatContext *ic;\n\n    AVInputFormat *file_iformat = NULL;\n\n    int err, i, ret, rfps, rfps_base;\n\n    int64_t timestamp;\n\n    uint8_t buf[128];\n\n    AVDictionary **opts;\n\n    int orig_nb_streams;                     // number of streams before avformat_find_stream_info\n\n\n\n    if (last_asked_format) {\n\n        if (!(file_iformat = av_find_input_format(last_asked_format))) {\n\n            fprintf(stderr, \"Unknown input format: '%s'\\n\", last_asked_format);\n\n            ffmpeg_exit(1);\n\n        }\n\n        last_asked_format = NULL;\n\n    }\n\n\n\n    if (!strcmp(filename, \"-\"))\n\n        filename = \"pipe:\";\n\n\n\n    using_stdin |= !strncmp(filename, \"pipe:\", 5) ||\n\n                    !strcmp(filename, \"/dev/stdin\");\n\n\n\n    /* get default parameters from command line */\n\n    ic = avformat_alloc_context();\n\n    if (!ic) {\n\n        print_error(filename, AVERROR(ENOMEM));\n\n        ffmpeg_exit(1);\n\n    }\n\n    if (audio_sample_rate) {\n\n        snprintf(buf, sizeof(buf), \"%d\", audio_sample_rate);\n\n        av_dict_set(&format_opts, \"sample_rate\", buf, 0);\n\n    }\n\n    if (audio_channels) {\n\n        snprintf(buf, sizeof(buf), \"%d\", audio_channels);\n\n        av_dict_set(&format_opts, \"channels\", buf, 0);\n\n    }\n\n    if (frame_rate.num) {\n\n        snprintf(buf, sizeof(buf), \"%d/%d\", frame_rate.num, frame_rate.den);\n\n        av_dict_set(&format_opts, \"framerate\", buf, 0);\n\n    }\n\n    if (frame_width && frame_height) {\n\n        snprintf(buf, sizeof(buf), \"%dx%d\", frame_width, frame_height);\n\n        av_dict_set(&format_opts, \"video_size\", buf, 0);\n\n    }\n\n    if (frame_pix_fmt != PIX_FMT_NONE)\n\n        av_dict_set(&format_opts, \"pixel_format\", av_get_pix_fmt_name(frame_pix_fmt), 0);\n\n\n\n    ic->video_codec_id   =\n\n        find_codec_or_die(video_codec_name   , AVMEDIA_TYPE_VIDEO   , 0);\n\n    ic->audio_codec_id   =\n\n        find_codec_or_die(audio_codec_name   , AVMEDIA_TYPE_AUDIO   , 0);\n\n    ic->subtitle_codec_id=\n\n        find_codec_or_die(subtitle_codec_name, AVMEDIA_TYPE_SUBTITLE, 0);\n\n    ic->flags |= AVFMT_FLAG_NONBLOCK;\n\n\n\n    /* open the input file with generic libav function */\n\n    err = avformat_open_input(&ic, filename, file_iformat, &format_opts);\n\n    if (err < 0) {\n\n        print_error(filename, err);\n\n        ffmpeg_exit(1);\n\n    }\n\n    assert_avoptions(format_opts);\n\n\n\n    if(opt_programid) {\n\n        int i, j;\n\n        int found=0;\n\n        for(i=0; i<ic->nb_streams; i++){\n\n            ic->streams[i]->discard= AVDISCARD_ALL;\n\n        }\n\n        for(i=0; i<ic->nb_programs; i++){\n\n            AVProgram *p= ic->programs[i];\n\n            if(p->id != opt_programid){\n\n                p->discard = AVDISCARD_ALL;\n\n            }else{\n\n                found=1;\n\n                for(j=0; j<p->nb_stream_indexes; j++){\n\n                    ic->streams[p->stream_index[j]]->discard= AVDISCARD_DEFAULT;\n\n                }\n\n            }\n\n        }\n\n        if(!found){\n\n            fprintf(stderr, \"Specified program id not found\\n\");\n\n            ffmpeg_exit(1);\n\n        }\n\n        opt_programid=0;\n\n    }\n\n\n\n    if (loop_input) {\n\n        av_log(NULL, AV_LOG_WARNING, \"-loop_input is deprecated, use -loop 1\\n\");\n\n        ic->loop_input = loop_input;\n\n    }\n\n\n\n    /* Set AVCodecContext options for avformat_find_stream_info */\n\n    opts = setup_find_stream_info_opts(ic, codec_opts);\n\n    orig_nb_streams = ic->nb_streams;\n\n\n\n    /* If not enough info to get the stream parameters, we decode the\n\n       first frames to get it. (used in mpeg case for example) */\n\n    ret = avformat_find_stream_info(ic, opts);\n\n    if (ret < 0 && verbose >= 0) {\n\n        fprintf(stderr, \"%s: could not find codec parameters\\n\", filename);\n\n        av_close_input_file(ic);\n\n        ffmpeg_exit(1);\n\n    }\n\n\n\n    timestamp = start_time;\n\n    /* add the stream start time */\n\n    if (ic->start_time != AV_NOPTS_VALUE)\n\n        timestamp += ic->start_time;\n\n\n\n    /* if seeking requested, we execute it */\n\n    if (start_time != 0) {\n\n        ret = av_seek_frame(ic, -1, timestamp, AVSEEK_FLAG_BACKWARD);\n\n        if (ret < 0) {\n\n            fprintf(stderr, \"%s: could not seek to position %0.3f\\n\",\n\n                    filename, (double)timestamp / AV_TIME_BASE);\n\n        }\n\n        /* reset seek info */\n\n        start_time = 0;\n\n    }\n\n\n\n    /* update the current parameters so that they match the one of the input stream */\n\n    for(i=0;i<ic->nb_streams;i++) {\n\n        AVStream *st = ic->streams[i];\n\n        AVCodecContext *dec = st->codec;\n\n        InputStream *ist;\n\n\n\n        dec->thread_count = thread_count;\n\n\n\n        input_streams = grow_array(input_streams, sizeof(*input_streams), &nb_input_streams, nb_input_streams + 1);\n\n        ist = &input_streams[nb_input_streams - 1];\n\n        ist->st = st;\n\n        ist->file_index = nb_input_files;\n\n        ist->discard = 1;\n\n        ist->opts = filter_codec_opts(codec_opts, ist->st->codec->codec_id, 0);\n\n\n\n        if (i < nb_ts_scale)\n\n            ist->ts_scale = ts_scale[i];\n\n\n\n        switch (dec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ist->dec = avcodec_find_decoder_by_name(audio_codec_name);\n\n            if(!ist->dec)\n\n                ist->dec = avcodec_find_decoder(dec->codec_id);\n\n            if(audio_disable)\n\n                st->discard= AVDISCARD_ALL;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            ist->dec= avcodec_find_decoder_by_name(video_codec_name);\n\n            if(!ist->dec)\n\n                ist->dec = avcodec_find_decoder(dec->codec_id);\n\n            rfps      = ic->streams[i]->r_frame_rate.num;\n\n            rfps_base = ic->streams[i]->r_frame_rate.den;\n\n            if (dec->lowres) {\n\n                dec->flags |= CODEC_FLAG_EMU_EDGE;\n\n            }\n\n            if(me_threshold)\n\n                dec->debug |= FF_DEBUG_MV;\n\n\n\n            if (dec->time_base.den != rfps*dec->ticks_per_frame || dec->time_base.num != rfps_base) {\n\n\n\n                if (verbose >= 0)\n\n                    fprintf(stderr,\"\\nSeems stream %d codec frame rate differs from container frame rate: %2.2f (%d/%d) -> %2.2f (%d/%d)\\n\",\n\n                            i, (float)dec->time_base.den / dec->time_base.num, dec->time_base.den, dec->time_base.num,\n\n\n\n                    (float)rfps / rfps_base, rfps, rfps_base);\n\n            }\n\n\n\n            if(video_disable)\n\n                st->discard= AVDISCARD_ALL;\n\n            else if(video_discard)\n\n                st->discard= video_discard;\n\n            break;\n\n        case AVMEDIA_TYPE_DATA:\n\n            break;\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            ist->dec = avcodec_find_decoder_by_name(subtitle_codec_name);\n\n            if(!ist->dec)\n\n                ist->dec = avcodec_find_decoder(dec->codec_id);\n\n            if(subtitle_disable)\n\n                st->discard = AVDISCARD_ALL;\n\n            break;\n\n        case AVMEDIA_TYPE_ATTACHMENT:\n\n        case AVMEDIA_TYPE_UNKNOWN:\n\n            break;\n\n        default:\n\n            abort();\n\n        }\n\n    }\n\n\n\n    /* dump the file content */\n\n    if (verbose >= 0)\n\n        av_dump_format(ic, nb_input_files, filename, 0);\n\n\n\n    input_files = grow_array(input_files, sizeof(*input_files), &nb_input_files, nb_input_files + 1);\n\n    input_files[nb_input_files - 1].ctx        = ic;\n\n    input_files[nb_input_files - 1].ist_index  = nb_input_streams - ic->nb_streams;\n\n    input_files[nb_input_files - 1].ts_offset  = input_ts_offset - (copy_ts ? 0 : timestamp);\n\n\n\n    top_field_first = -1;\n\n    frame_rate    = (AVRational){0, 0};\n\n    frame_pix_fmt = PIX_FMT_NONE;\n\n    frame_height = 0;\n\n    frame_width  = 0;\n\n    audio_sample_rate = 0;\n\n    audio_channels    = 0;\n\n    audio_sample_fmt  = AV_SAMPLE_FMT_NONE;\n\n    av_freep(&ts_scale);\n\n    nb_ts_scale = 0;\n\n\n\n    for (i = 0; i < orig_nb_streams; i++)\n\n        av_dict_free(&opts[i]);\n\n    av_freep(&opts);\n\n    av_freep(&video_codec_name);\n\n    av_freep(&audio_codec_name);\n\n    av_freep(&subtitle_codec_name);\n\n    uninit_opts();\n\n    init_opts();\n\n    return 0;\n\n}\n", "idx": 7925, "_split": "test", "_hash": "f4e9608605bc2a8f77d5d15ac825d303"}
{"project": "FFmpeg", "commit_id": "7684a36113fa12c88ba80b5498f05849a6b58632", "target": 0, "func": "static int mxf_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st = s->streams[pkt->stream_index];\n\n    MXFStreamContext *sc = st->priv_data;\n\n    MXFIndexEntry ie = {0};\n\n\n\n    if (!mxf->edit_unit_byte_count && !(mxf->edit_units_count % EDIT_UNITS_PER_BODY)) {\n\n        mxf->index_entries = av_realloc(mxf->index_entries,\n\n            (mxf->edit_units_count + EDIT_UNITS_PER_BODY)*sizeof(*mxf->index_entries));\n\n        if (!mxf->index_entries) {\n\n            av_log(s, AV_LOG_ERROR, \"could not allocate index entries\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        if (!mxf_parse_mpeg2_frame(s, st, pkt, &ie)) {\n\n            av_log(s, AV_LOG_ERROR, \"could not get mpeg2 profile and level\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (!mxf->header_written) {\n\n        if (mxf->edit_unit_byte_count) {\n\n            mxf_write_partition(s, 1, 2, header_open_partition_key, 1);\n\n            mxf_write_klv_fill(s);\n\n            mxf_write_index_table_segment(s);\n\n        } else {\n\n            mxf_write_partition(s, 0, 0, header_open_partition_key, 1);\n\n        }\n\n        mxf->header_written = 1;\n\n    }\n\n\n\n    if (st->index == 0) {\n\n        if (!mxf->edit_unit_byte_count &&\n\n            (!mxf->edit_units_count || mxf->edit_units_count > EDIT_UNITS_PER_BODY) &&\n\n            !(ie.flags & 0x33)) { // I frame, Gop start\n\n            mxf_write_klv_fill(s);\n\n            mxf_write_partition(s, 1, 2, body_partition_key, 0);\n\n\n\n            mxf_write_klv_fill(s);\n\n            mxf_write_index_table_segment(s);\n\n        }\n\n\n\n        mxf_write_klv_fill(s);\n\n        mxf_write_system_item(s);\n\n\n\n        if (!mxf->edit_unit_byte_count) {\n\n            mxf->index_entries[mxf->edit_units_count].offset = mxf->body_offset;\n\n            mxf->index_entries[mxf->edit_units_count].flags = ie.flags;\n\n            mxf->index_entries[mxf->edit_units_count].temporal_ref = ie.temporal_ref;\n\n            mxf->body_offset += KAG_SIZE; // size of system element\n\n        }\n\n        mxf->edit_units_count++;\n\n    } else if (!mxf->edit_unit_byte_count && st->index == 1) {\n\n        mxf->index_entries[mxf->edit_units_count-1].slice_offset =\n\n            mxf->body_offset - mxf->index_entries[mxf->edit_units_count-1].offset;\n\n    }\n\n\n\n    mxf_write_klv_fill(s);\n\n    avio_write(pb, sc->track_essence_element_key, 16); // write key\n\n    if (s->oformat == &ff_mxf_d10_muxer) {\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            mxf_write_d10_video_packet(s, st, pkt);\n\n        else\n\n            mxf_write_d10_audio_packet(s, st, pkt);\n\n    } else {\n\n        klv_encode_ber4_length(pb, pkt->size); // write length\n\n        avio_write(pb, pkt->data, pkt->size);\n\n        mxf->body_offset += 16+4+pkt->size + klv_fill_size(16+4+pkt->size);\n\n    }\n\n\n\n    avio_flush(pb);\n\n\n\n    return 0;\n\n}\n", "idx": 7967, "_split": "test", "_hash": "f4a683bf40575748b789af579bfa8e2d"}
{"project": "FFmpeg", "commit_id": "082cf97106e2e94a969877d4f8c05c1e526acf54", "target": 0, "func": "static inline int get_chroma_qp(H264Context *h, int t, int qscale){\n\n    return h->pps.chroma_qp_table[t][qscale];\n\n}\n", "idx": 7977, "_split": "test", "_hash": "87e3eec589137c42ce14fde55a9360ac"}
{"project": "FFmpeg", "commit_id": "fd92dafaff8844b5fedf94679b93d953939a7f7b", "target": 0, "func": "static int binkb_decode_plane(BinkContext *c, AVFrame *frame, BitstreamContext *bc,\n\n                              int plane_idx, int is_key, int is_chroma)\n\n{\n\n    int blk, ret;\n\n    int i, j, bx, by;\n\n    uint8_t *dst, *ref, *ref_start, *ref_end;\n\n    int v, col[2];\n\n    const uint8_t *scan;\n\n    int xoff, yoff;\n\n    LOCAL_ALIGNED_16(int16_t, block, [64]);\n\n    LOCAL_ALIGNED_16(int32_t, dctblock, [64]);\n\n    int coordmap[64];\n\n    int ybias = is_key ? -15 : 0;\n\n    int qp;\n\n\n\n    const int stride = frame->linesize[plane_idx];\n\n    int bw = is_chroma ? (c->avctx->width  + 15) >> 4 : (c->avctx->width  + 7) >> 3;\n\n    int bh = is_chroma ? (c->avctx->height + 15) >> 4 : (c->avctx->height + 7) >> 3;\n\n\n\n    binkb_init_bundles(c);\n\n    ref_start = frame->data[plane_idx];\n\n    ref_end   = frame->data[plane_idx] + (bh * frame->linesize[plane_idx] + bw) * 8;\n\n\n\n    for (i = 0; i < 64; i++)\n\n        coordmap[i] = (i & 7) + (i >> 3) * stride;\n\n\n\n    for (by = 0; by < bh; by++) {\n\n        for (i = 0; i < BINKB_NB_SRC; i++) {\n\n            if ((ret = binkb_read_bundle(c, bc, i)) < 0)\n\n                return ret;\n\n        }\n\n\n\n        dst  = frame->data[plane_idx]  + 8*by*stride;\n\n        for (bx = 0; bx < bw; bx++, dst += 8) {\n\n            blk = binkb_get_value(c, BINKB_SRC_BLOCK_TYPES);\n\n            switch (blk) {\n\n            case 0:\n\n                break;\n\n            case 1:\n\n                scan = bink_patterns[bitstream_read(bc, 4)];\n\n                i = 0;\n\n                do {\n\n                    int mode = bitstream_read_bit(bc);\n\n                    int run  = bitstream_read(bc, binkb_runbits[i]) + 1;\n\n\n\n                    i += run;\n\n                    if (i > 64) {\n\n                        av_log(c->avctx, AV_LOG_ERROR, \"Run went out of bounds\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    if (mode) {\n\n                        v = binkb_get_value(c, BINKB_SRC_COLORS);\n\n                        for (j = 0; j < run; j++)\n\n                            dst[coordmap[*scan++]] = v;\n\n                    } else {\n\n                        for (j = 0; j < run; j++)\n\n                            dst[coordmap[*scan++]] = binkb_get_value(c, BINKB_SRC_COLORS);\n\n                    }\n\n                } while (i < 63);\n\n                if (i == 63)\n\n                    dst[coordmap[*scan++]] = binkb_get_value(c, BINKB_SRC_COLORS);\n\n                break;\n\n            case 2:\n\n                memset(dctblock, 0, sizeof(*dctblock) * 64);\n\n                dctblock[0] = binkb_get_value(c, BINKB_SRC_INTRA_DC);\n\n                qp = binkb_get_value(c, BINKB_SRC_INTRA_Q);\n\n                read_dct_coeffs(bc, dctblock, bink_scan, binkb_intra_quant, qp);\n\n                c->binkdsp.idct_put(dst, stride, dctblock);\n\n                break;\n\n            case 3:\n\n                xoff = binkb_get_value(c, BINKB_SRC_X_OFF);\n\n                yoff = binkb_get_value(c, BINKB_SRC_Y_OFF) + ybias;\n\n                ref = dst + xoff + yoff * stride;\n\n                if (ref < ref_start || ref + 8*stride > ref_end) {\n\n                    av_log(c->avctx, AV_LOG_WARNING, \"Reference block is out of bounds\\n\");\n\n                } else if (ref + 8*stride < dst || ref >= dst + 8*stride) {\n\n                    c->hdsp.put_pixels_tab[1][0](dst, ref, stride, 8);\n\n                } else {\n\n                    put_pixels8x8_overlapped(dst, ref, stride);\n\n                }\n\n                c->bdsp.clear_block(block);\n\n                v = binkb_get_value(c, BINKB_SRC_INTER_COEFS);\n\n                read_residue(bc, block, v);\n\n                c->binkdsp.add_pixels8(dst, block, stride);\n\n                break;\n\n            case 4:\n\n                xoff = binkb_get_value(c, BINKB_SRC_X_OFF);\n\n                yoff = binkb_get_value(c, BINKB_SRC_Y_OFF) + ybias;\n\n                ref = dst + xoff + yoff * stride;\n\n                if (ref < ref_start || ref + 8 * stride > ref_end) {\n\n                    av_log(c->avctx, AV_LOG_WARNING, \"Reference block is out of bounds\\n\");\n\n                } else if (ref + 8*stride < dst || ref >= dst + 8*stride) {\n\n                    c->hdsp.put_pixels_tab[1][0](dst, ref, stride, 8);\n\n                } else {\n\n                    put_pixels8x8_overlapped(dst, ref, stride);\n\n                }\n\n                memset(dctblock, 0, sizeof(*dctblock) * 64);\n\n                dctblock[0] = binkb_get_value(c, BINKB_SRC_INTER_DC);\n\n                qp = binkb_get_value(c, BINKB_SRC_INTER_Q);\n\n                read_dct_coeffs(bc, dctblock, bink_scan, binkb_inter_quant, qp);\n\n                c->binkdsp.idct_add(dst, stride, dctblock);\n\n                break;\n\n            case 5:\n\n                v = binkb_get_value(c, BINKB_SRC_COLORS);\n\n                c->bdsp.fill_block_tab[1](dst, v, stride, 8);\n\n                break;\n\n            case 6:\n\n                for (i = 0; i < 2; i++)\n\n                    col[i] = binkb_get_value(c, BINKB_SRC_COLORS);\n\n                for (i = 0; i < 8; i++) {\n\n                    v = binkb_get_value(c, BINKB_SRC_PATTERN);\n\n                    for (j = 0; j < 8; j++, v >>= 1)\n\n                        dst[i*stride + j] = col[v & 1];\n\n                }\n\n                break;\n\n            case 7:\n\n                xoff = binkb_get_value(c, BINKB_SRC_X_OFF);\n\n                yoff = binkb_get_value(c, BINKB_SRC_Y_OFF) + ybias;\n\n                ref = dst + xoff + yoff * stride;\n\n                if (ref < ref_start || ref + 8 * stride > ref_end) {\n\n                    av_log(c->avctx, AV_LOG_WARNING, \"Reference block is out of bounds\\n\");\n\n                } else if (ref + 8*stride < dst || ref >= dst + 8*stride) {\n\n                    c->hdsp.put_pixels_tab[1][0](dst, ref, stride, 8);\n\n                } else {\n\n                    put_pixels8x8_overlapped(dst, ref, stride);\n\n                }\n\n                break;\n\n            case 8:\n\n                for (i = 0; i < 8; i++)\n\n                    memcpy(dst + i*stride, c->bundle[BINKB_SRC_COLORS].cur_ptr + i*8, 8);\n\n                c->bundle[BINKB_SRC_COLORS].cur_ptr += 64;\n\n                break;\n\n            default:\n\n                av_log(c->avctx, AV_LOG_ERROR, \"Unknown block type %d\\n\", blk);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n    if (bitstream_tell(bc) & 0x1F) // next plane data starts at 32-bit boundary\n\n        bitstream_skip(bc, 32 - (bitstream_tell(bc) & 0x1F));\n\n\n\n    return 0;\n\n}\n", "idx": 7980, "_split": "test", "_hash": "c8754c6ef1572568237238a7f1bc9822"}
{"project": "FFmpeg", "commit_id": "dc5d1515681b57a257443ba72bb81fb3e6e6621b", "target": 0, "func": "static int replace_int_data_in_filename(char *buf, int buf_size, const char *filename, char placeholder, int64_t number)\n\n{\n\n    const char *p;\n\n    char *q, buf1[20], c;\n\n    int nd, len, addchar_count;\n\n    int found_count = 0;\n\n\n\n    q = buf;\n\n    p = filename;\n\n    for (;;) {\n\n        c = *p;\n\n        if (c == '\\0')\n\n            break;\n\n        if (c == '%' && *(p+1) == '%')  // %%\n\n            addchar_count = 2;\n\n        else if (c == '%' && (av_isdigit(*(p+1)) || *(p+1) == placeholder)) {\n\n            nd = 0;\n\n            addchar_count = 1;\n\n            while (av_isdigit(*(p + addchar_count))) {\n\n                nd = nd * 10 + *(p + addchar_count) - '0';\n\n                addchar_count++;\n\n            }\n\n\n\n            if (*(p + addchar_count) == placeholder) {\n\n                len = snprintf(buf1, sizeof(buf1), \"%0*\"PRId64, (number < 0) ? nd : nd++, number);\n\n                if (len < 1)  // returned error or empty buf1\n\n                    goto fail;\n\n                if ((q - buf + len) > buf_size - 1)\n\n                    goto fail;\n\n                memcpy(q, buf1, len);\n\n                q += len;\n\n                p += (addchar_count + 1);\n\n                addchar_count = 0;\n\n                found_count++;\n\n            }\n\n\n\n        } else\n\n            addchar_count = 1;\n\n\n\n        while (addchar_count--)\n\n            if ((q - buf) < buf_size - 1)\n\n                *q++ = *p++;\n\n            else\n\n                goto fail;\n\n    }\n\n    *q = '\\0';\n\n    return found_count;\n\nfail:\n\n    *q = '\\0';\n\n    return -1;\n\n}\n", "idx": 8046, "_split": "test", "_hash": "6cc1ea193b0f6c6e36ddd6fd557065be"}
{"project": "FFmpeg", "commit_id": "aa6aa2ef091818c2669c48051286ce361401f31b", "target": 0, "func": "static void apply_window_and_mdct(AVCodecContext *avctx, const AVFrame *frame)\n\n{\n\n    WMACodecContext *s = avctx->priv_data;\n\n    float **audio      = (float **) frame->extended_data;\n\n    int len            = frame->nb_samples;\n\n    int window_index   = s->frame_len_bits - s->block_len_bits;\n\n    FFTContext *mdct   = &s->mdct_ctx[window_index];\n\n    int ch;\n\n    const float *win   = s->windows[window_index];\n\n    int window_len     = 1 << s->block_len_bits;\n\n    float n            = 2.0 * 32768.0 / window_len;\n\n\n\n    for (ch = 0; ch < avctx->channels; ch++) {\n\n        memcpy(s->output, s->frame_out[ch], window_len * sizeof(*s->output));\n\n        s->fdsp->vector_fmul_scalar(s->frame_out[ch], audio[ch], n, len);\n\n        s->fdsp->vector_fmul_reverse(&s->output[window_len], s->frame_out[ch],\n\n                                    win, len);\n\n        s->fdsp->vector_fmul(s->frame_out[ch], s->frame_out[ch], win, len);\n\n        mdct->mdct_calc(mdct, s->coefs[ch], s->output);\n\n    }\n\n}\n", "idx": 8085, "_split": "test", "_hash": "c4bbb60f9d309cdf593234d47070ba10"}
{"project": "FFmpeg", "commit_id": "3932ccc472ad4f4d370dcfc1c2f574b0f3acb88c", "target": 1, "func": "static void diff_pixels_altivec(int16_t *restrict block, const uint8_t *s1,\n\n                                const uint8_t *s2, int stride)\n\n{\n\n    int i;\n\n    vec_u8 perm1 = vec_lvsl(0, s1);\n\n    vec_u8 perm2 = vec_lvsl(0, s2);\n\n    const vec_u8 zero = (const vec_u8)vec_splat_u8(0);\n\n    vec_s16 shorts1, shorts2;\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        /* Read potentially unaligned pixels.\n\n         * We're reading 16 pixels, and actually only want 8,\n\n         * but we simply ignore the extras. */\n\n        vec_u8 pixl  = vec_ld(0,  s1);\n\n        vec_u8 pixr  = vec_ld(15, s1);\n\n        vec_u8 bytes = vec_perm(pixl, pixr, perm1);\n\n\n\n        // Convert the bytes into shorts.\n\n        shorts1 = (vec_s16)vec_mergeh(zero, bytes);\n\n\n\n        // Do the same for the second block of pixels.\n\n        pixl  = vec_ld(0,  s2);\n\n        pixr  = vec_ld(15, s2);\n\n        bytes = vec_perm(pixl, pixr, perm2);\n\n\n\n        // Convert the bytes into shorts.\n\n        shorts2 = (vec_s16)vec_mergeh(zero, bytes);\n\n\n\n        // Do the subtraction.\n\n        shorts1 = vec_sub(shorts1, shorts2);\n\n\n\n        // Save the data to the block, we assume the block is 16-byte aligned.\n\n        vec_st(shorts1, 0, (vec_s16 *)block);\n\n\n\n        s1    += stride;\n\n        s2    += stride;\n\n        block += 8;\n\n\n\n        /* The code below is a copy of the code above...\n\n         * This is a manual unroll. */\n\n\n\n        /* Read potentially unaligned pixels.\n\n         * We're reading 16 pixels, and actually only want 8,\n\n         * but we simply ignore the extras. */\n\n        pixl  = vec_ld(0,  s1);\n\n        pixr  = vec_ld(15, s1);\n\n        bytes = vec_perm(pixl, pixr, perm1);\n\n\n\n        // Convert the bytes into shorts.\n\n        shorts1 = (vec_s16)vec_mergeh(zero, bytes);\n\n\n\n        // Do the same for the second block of pixels.\n\n        pixl  = vec_ld(0,  s2);\n\n        pixr  = vec_ld(15, s2);\n\n        bytes = vec_perm(pixl, pixr, perm2);\n\n\n\n        // Convert the bytes into shorts.\n\n        shorts2 = (vec_s16)vec_mergeh(zero, bytes);\n\n\n\n        // Do the subtraction.\n\n        shorts1 = vec_sub(shorts1, shorts2);\n\n\n\n        // Save the data to the block, we assume the block is 16-byte aligned.\n\n        vec_st(shorts1, 0, (vec_s16 *)block);\n\n\n\n        s1    += stride;\n\n        s2    += stride;\n\n        block += 8;\n\n    }\n\n}\n", "idx": 8103, "_split": "test", "_hash": "26455c020d01d38f32bec8e543e6b041"}
{"project": "FFmpeg", "commit_id": "199d4478de102ca7987adb97f2e66a1820a98ebd", "target": 1, "func": "int ff_thread_get_buffer(AVCodecContext *avctx, AVFrame *f)\n\n{\n\n    PerThreadContext *p = avctx->thread_opaque;\n\n    int *progress, err;\n\n\n\n    f->owner = avctx;\n\n\n\n    ff_init_buffer_info(avctx, f);\n\n\n\n    if (!(avctx->active_thread_type&FF_THREAD_FRAME)) {\n\n        f->thread_opaque = NULL;\n\n        return avctx->get_buffer(avctx, f);\n\n    }\n\n\n\n    if (p->state != STATE_SETTING_UP &&\n\n        (avctx->codec->update_thread_context || (!avctx->thread_safe_callbacks &&\n\n                avctx->get_buffer != avcodec_default_get_buffer))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() cannot be called after ff_thread_finish_setup()\\n\");\n\n        return -1;\n\n    }\n\n\n\n    pthread_mutex_lock(&p->parent->buffer_mutex);\n\n    f->thread_opaque = progress = allocate_progress(p);\n\n\n\n    if (!progress) {\n\n        pthread_mutex_unlock(&p->parent->buffer_mutex);\n\n        return -1;\n\n    }\n\n\n\n    progress[0] =\n\n    progress[1] = -1;\n\n\n\n    if (avctx->thread_safe_callbacks ||\n\n        avctx->get_buffer == avcodec_default_get_buffer) {\n\n        err = avctx->get_buffer(avctx, f);\n\n    } else {\n\n        p->requested_frame = f;\n\n        p->state = STATE_GET_BUFFER;\n\n        pthread_mutex_lock(&p->progress_mutex);\n\n        pthread_cond_signal(&p->progress_cond);\n\n\n\n        while (p->state != STATE_SETTING_UP)\n\n            pthread_cond_wait(&p->progress_cond, &p->progress_mutex);\n\n\n\n        err = p->result;\n\n\n\n        pthread_mutex_unlock(&p->progress_mutex);\n\n\n\n        if (!avctx->codec->update_thread_context)\n\n            ff_thread_finish_setup(avctx);\n\n    }\n\n\n\n    pthread_mutex_unlock(&p->parent->buffer_mutex);\n\n\n\n    return err;\n\n}\n", "idx": 8105, "_split": "test", "_hash": "c9b6ca98793a7eb9212f817f13d19801"}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static void hds_free(AVFormatContext *s)\n\n{\n\n    HDSContext *c = s->priv_data;\n\n    int i, j;\n\n    if (!c->streams)\n\n        return;\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        OutputStream *os = &c->streams[i];\n\n        if (os->out)\n\n            avio_close(os->out);\n\n        os->out = NULL;\n\n        if (os->ctx && os->ctx_inited)\n\n            av_write_trailer(os->ctx);\n\n        if (os->ctx && os->ctx->pb)\n\n            av_free(os->ctx->pb);\n\n        if (os->ctx)\n\n            avformat_free_context(os->ctx);\n\n        av_free(os->metadata);\n\n        for (j = 0; j < os->nb_extra_packets; j++)\n\n            av_free(os->extra_packets[j]);\n\n        for (j = 0; j < os->nb_fragments; j++)\n\n            av_free(os->fragments[j]);\n\n        av_free(os->fragments);\n\n    }\n\n    av_freep(&c->streams);\n\n}\n", "idx": 8112, "_split": "test", "_hash": "7a815ba8efa76f2524145bd33280e8bc"}
{"project": "FFmpeg", "commit_id": "ab80d3fb3a7595db44fc143c80f8c2a3480fe28d", "target": 1, "func": "yuv2ya8_2_c(SwsContext *c, const int16_t *buf[2],\n\n            const int16_t *ubuf[2], const int16_t *vbuf[2],\n\n            const int16_t *abuf[2], uint8_t *dest, int dstW,\n\n            int yalpha, int uvalpha, int y)\n\n{\n\n    int hasAlpha = abuf[0] && abuf[1];\n\n    const int16_t *buf0  = buf[0],  *buf1  = buf[1],\n\n                  *abuf0 = hasAlpha ? abuf[0] : NULL,\n\n                  *abuf1 = hasAlpha ? abuf[1] : NULL;\n\n    int  yalpha1 = 4096 - yalpha;\n\n    int i;\n\n\n\n    for (i = 0; i < dstW; i++) {\n\n        int Y = (buf0[i * 2] * yalpha1 + buf1[i * 2] * yalpha) >> 19;\n\n        int A;\n\n\n\n        Y = av_clip_uint8(Y);\n\n\n\n        if (hasAlpha) {\n\n            A = (abuf0[i * 2] * yalpha1 + abuf1[i * 2] * yalpha) >> 19;\n\n            A = av_clip_uint8(A);\n\n        }\n\n\n\n        dest[i * 2    ] = Y;\n\n        dest[i * 2 + 1] = hasAlpha ? A : 255;\n\n    }\n\n}\n", "idx": 8124, "_split": "test", "_hash": "eb5a57a423830dd0594d3bb88f6d17ac"}
{"project": "FFmpeg", "commit_id": "e6bc38fd49c94726b45d5d5cc2b756ad8ec49ee0", "target": 1, "func": "av_cold void ff_wmv2_common_init(Wmv2Context * w){\n\n    MpegEncContext * const s= &w->s;\n\n\n\n    ff_init_scantable(s->dsp.idct_permutation, &w->abt_scantable[0], ff_wmv2_scantableA);\n\n    ff_init_scantable(s->dsp.idct_permutation, &w->abt_scantable[1], ff_wmv2_scantableB);\n\n}\n", "idx": 8157, "_split": "test", "_hash": "04f7c7d107250f359261eb0e853dc575"}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "void ff_mpeg1_encode_init(MpegEncContext *s)\n\n{\n\n    static int done=0;\n\n\n\n    common_init(s);\n\n\n\n    if(!done){\n\n        int f_code;\n\n        int mv;\n\n\tint i;\n\n\n\n        done=1;\n\n        init_rl(&rl_mpeg1);\n\n\n\n\tfor(i=0; i<64; i++)\n\n\t{\n\n\t\tmpeg1_max_level[0][i]= rl_mpeg1.max_level[0][i];\n\n\t\tmpeg1_index_run[0][i]= rl_mpeg1.index_run[0][i];\n\n\t}\n\n        \n\n        init_uni_ac_vlc(&rl_mpeg1, uni_mpeg1_ac_vlc_bits, uni_mpeg1_ac_vlc_len);\n\n\n\n\t/* build unified dc encoding tables */\n\n\tfor(i=-255; i<256; i++)\n\n\t{\n\n\t\tint adiff, index;\n\n\t\tint bits, code;\n\n\t\tint diff=i;\n\n\n\n\t\tadiff = ABS(diff);\n\n\t\tif(diff<0) diff--;\n\n\t\tindex = av_log2(2*adiff);\n\n\n\n\t\tbits= vlc_dc_lum_bits[index] + index;\n\n\t\tcode= (vlc_dc_lum_code[index]<<index) + (diff & ((1 << index) - 1));\n\n\t\tmpeg1_lum_dc_uni[i+255]= bits + (code<<8);\n\n\t\t\n\n\t\tbits= vlc_dc_chroma_bits[index] + index;\n\n\t\tcode= (vlc_dc_chroma_code[index]<<index) + (diff & ((1 << index) - 1));\n\n\t\tmpeg1_chr_dc_uni[i+255]= bits + (code<<8);\n\n\t}\n\n\n\n        mv_penalty= av_mallocz( sizeof(uint8_t)*(MAX_FCODE+1)*(2*MAX_MV+1) );\n\n\n\n        for(f_code=1; f_code<=MAX_FCODE; f_code++){\n\n            for(mv=-MAX_MV; mv<=MAX_MV; mv++){\n\n                int len;\n\n\n\n                if(mv==0) len= mbMotionVectorTable[0][1];\n\n                else{\n\n                    int val, bit_size, range, code;\n\n\n\n                    bit_size = f_code - 1;\n\n                    range = 1 << bit_size;\n\n\n\n                    val=mv;\n\n                    if (val < 0) \n\n                        val = -val;\n\n                    val--;\n\n                    code = (val >> bit_size) + 1;\n\n                    if(code<17){\n\n                        len= mbMotionVectorTable[code][1] + 1 + bit_size;\n\n                    }else{\n\n                        len= mbMotionVectorTable[16][1] + 2 + bit_size;\n\n                    }\n\n                }\n\n\n\n                mv_penalty[f_code][mv+MAX_MV]= len;\n\n            }\n\n        }\n\n        \n\n\n\n        for(f_code=MAX_FCODE; f_code>0; f_code--){\n\n            for(mv=-(8<<f_code); mv<(8<<f_code); mv++){\n\n                fcode_tab[mv+MAX_MV]= f_code;\n\n            }\n\n        }\n\n    }\n\n    s->me.mv_penalty= mv_penalty;\n\n    s->fcode_tab= fcode_tab;\n\n    if(s->codec_id == CODEC_ID_MPEG1VIDEO){\n\n        s->min_qcoeff=-255;\n\n        s->max_qcoeff= 255;\n\n    }else{\n\n        s->min_qcoeff=-2047;\n\n        s->max_qcoeff= 2047;\n\n    }\n\n    s->intra_ac_vlc_length=\n\n    s->inter_ac_vlc_length=\n\n    s->intra_ac_vlc_last_length=\n\n    s->inter_ac_vlc_last_length= uni_mpeg1_ac_vlc_len;\n\n}\n", "idx": 8169, "_split": "test", "_hash": "2c2f6b93cd20ae79d714c51b880d332c"}
{"project": "FFmpeg", "commit_id": "c9f6eab184cac379c7a44d5899979165798d45d4", "target": 1, "func": "static av_cold int ac3_decode_init(AVCodecContext *avctx)\n\n{\n\n    AC3DecodeContext *s = avctx->priv_data;\n\n    s->avctx = avctx;\n\n\n\n    ff_ac3_common_init();\n\n    ac3_tables_init();\n\n    ff_mdct_init(&s->imdct_256, 8, 1, 1.0);\n\n    ff_mdct_init(&s->imdct_512, 9, 1, 1.0);\n\n    ff_kbd_window_init(s->window, 5.0, 256);\n\n    dsputil_init(&s->dsp, avctx);\n\n    ff_fmt_convert_init(&s->fmt_conv, avctx);\n\n    av_lfg_init(&s->dith_state, 0);\n\n\n\n    /* set scale value for float to int16 conversion */\n\n    s->mul_bias = 32767.0f;\n\n\n\n    /* allow downmixing to stereo or mono */\n\n    if (avctx->channels > 0 && avctx->request_channels > 0 &&\n\n            avctx->request_channels < avctx->channels &&\n\n            avctx->request_channels <= 2) {\n\n        avctx->channels = avctx->request_channels;\n\n    }\n\n    s->downmixed = 1;\n\n\n\n    /* allocate context input buffer */\n\n    if (avctx->error_recognition >= FF_ER_CAREFUL) {\n\n        s->input_buffer = av_mallocz(AC3_FRAME_BUFFER_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!s->input_buffer)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n    return 0;\n\n}\n", "idx": 8171, "_split": "test", "_hash": "1af5926967777cbf109438df74cf72d7"}
{"project": "FFmpeg", "commit_id": "08a747afb98c11da48b89339c2f1c5fdc56ced7e", "target": 0, "func": "static void count_frame_bits_fixed(AC3EncodeContext *s)\n\n{\n\n    static const int frame_bits_inc[8] = { 0, 0, 2, 2, 2, 4, 2, 4 };\n\n    int blk;\n\n    int frame_bits;\n\n\n\n    /* assumptions:\n\n     *   no dynamic range codes\n\n     *   bit allocation parameters do not change between blocks\n\n     *   no delta bit allocation\n\n     *   no skipped data\n\n     *   no auxilliary data\n\n     *   no E-AC-3 metadata\n\n     */\n\n\n\n    /* header */\n\n    frame_bits = 16; /* sync info */\n\n    if (s->eac3) {\n\n        /* bitstream info header */\n\n        frame_bits += 35;\n\n        frame_bits += 1 + 1 + 1;\n\n        /* audio frame header */\n\n        frame_bits += 2;\n\n        frame_bits += 10;\n\n        /* exponent strategy */\n\n        for (blk = 0; blk < AC3_MAX_BLOCKS; blk++)\n\n            frame_bits += 2 * s->fbw_channels + s->lfe_on;\n\n        /* converter exponent strategy */\n\n        frame_bits += s->fbw_channels * 5;\n\n        /* snr offsets */\n\n        frame_bits += 10;\n\n        /* block start info */\n\n        frame_bits++;\n\n    } else {\n\n        frame_bits += 49;\n\n        frame_bits += frame_bits_inc[s->channel_mode];\n\n    }\n\n\n\n    /* audio blocks */\n\n    for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) {\n\n        if (!s->eac3) {\n\n            /* block switch flags */\n\n            frame_bits += s->fbw_channels;\n\n\n\n            /* dither flags */\n\n            frame_bits += s->fbw_channels;\n\n        }\n\n\n\n        /* dynamic range */\n\n        frame_bits++;\n\n\n\n        /* spectral extension */\n\n        if (s->eac3)\n\n            frame_bits++;\n\n\n\n        if (!s->eac3) {\n\n            /* exponent strategy */\n\n            frame_bits += 2 * s->fbw_channels;\n\n            if (s->lfe_on)\n\n                frame_bits++;\n\n\n\n            /* bit allocation params */\n\n            frame_bits++;\n\n            if (!blk)\n\n                frame_bits += 2 + 2 + 2 + 2 + 3;\n\n        }\n\n\n\n        /* converter snr offset */\n\n        if (s->eac3)\n\n            frame_bits++;\n\n\n\n        if (!s->eac3) {\n\n            /* delta bit allocation */\n\n            frame_bits++;\n\n\n\n            /* skipped data */\n\n            frame_bits++;\n\n        }\n\n    }\n\n\n\n    /* auxiliary data */\n\n    frame_bits++;\n\n\n\n    /* CRC */\n\n    frame_bits += 1 + 16;\n\n\n\n    s->frame_bits_fixed = frame_bits;\n\n}\n", "idx": 8181, "_split": "test", "_hash": "b788020e5e73d16b54a95496bcd3c4f3"}
{"project": "FFmpeg", "commit_id": "0c32e19d584ba6ddbc27f0a796260404daaf4b6a", "target": 0, "func": "static void av_noinline filter_mb_edgev( uint8_t *pix, int stride, int16_t bS[4], unsigned int qp, H264Context *h) {\n\n    const unsigned int index_a = 52 + qp + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = (beta_table+52)[qp + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]];\n\n        tc[1] = tc0_table[index_a][bS[1]];\n\n        tc[2] = tc0_table[index_a][bS[2]];\n\n        tc[3] = tc0_table[index_a][bS[3]];\n\n        h->s.dsp.h264_h_loop_filter_luma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->s.dsp.h264_h_loop_filter_luma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 8197, "_split": "test", "_hash": "ebd8620c5a2a5a6c42d12c3d91c40501"}
{"project": "FFmpeg", "commit_id": "ac66834c759b7130fb5be51f63cb6dff9b294cba", "target": 0, "func": "int avcodec_decode_audio(AVCodecContext *avctx, int16_t *samples,\n\n                         int *frame_size_ptr,\n\n                         uint8_t *buf, int buf_size)\n\n{\n\n    int ret;\n\n\n\n    *frame_size_ptr= 0;\n\n    if((avctx->codec->capabilities & CODEC_CAP_DELAY) || buf_size){\n\n        ret = avctx->codec->decode(avctx, samples, frame_size_ptr,\n\n                                buf, buf_size);\n\n        avctx->frame_number++;\n\n    }else\n\n        ret= 0;\n\n    return ret;\n\n}\n", "idx": 8199, "_split": "test", "_hash": "370dd480022eb8fa81c2a4d9663f1c5c"}
{"project": "FFmpeg", "commit_id": "fed92adbb3fc6cbf735e3df9a2f7d0a2917fcfbd", "target": 1, "func": "void vp8_decode_mvs(VP8Context *s, VP8Macroblock *mb,\n\n                    int mb_x, int mb_y, int layout)\n\n{\n\n    VP8Macroblock *mb_edge[3] = { 0      /* top */,\n\n                                  mb - 1 /* left */,\n\n                                  0      /* top-left */ };\n\n    enum { CNT_ZERO, CNT_NEAREST, CNT_NEAR, CNT_SPLITMV };\n\n    enum { VP8_EDGE_TOP, VP8_EDGE_LEFT, VP8_EDGE_TOPLEFT };\n\n    int idx = CNT_ZERO;\n\n    int cur_sign_bias = s->sign_bias[mb->ref_frame];\n\n    int8_t *sign_bias = s->sign_bias;\n\n    VP56mv near_mv[4];\n\n    uint8_t cnt[4] = { 0 };\n\n    VP56RangeCoder *c = &s->c;\n\n\n\n    if (!layout) { // layout is inlined (s->mb_layout is not)\n\n        mb_edge[0] = mb + 2;\n\n        mb_edge[2] = mb + 1;\n\n    } else {\n\n        mb_edge[0] = mb - s->mb_width - 1;\n\n        mb_edge[2] = mb - s->mb_width - 2;\n\n    }\n\n\n\n    AV_ZERO32(&near_mv[0]);\n\n    AV_ZERO32(&near_mv[1]);\n\n    AV_ZERO32(&near_mv[2]);\n\n\n\n    /* Process MB on top, left and top-left */\n\n#define MV_EDGE_CHECK(n)                                                      \\\n\n    {                                                                         \\\n\n        VP8Macroblock *edge = mb_edge[n];                                     \\\n\n        int edge_ref = edge->ref_frame;                                       \\\n\n        if (edge_ref != VP56_FRAME_CURRENT) {                                 \\\n\n            uint32_t mv = AV_RN32A(&edge->mv);                                \\\n\n            if (mv) {                                                         \\\n\n                if (cur_sign_bias != sign_bias[edge_ref]) {                   \\\n\n                    /* SWAR negate of the values in mv. */                    \\\n\n                    mv = ~mv;                                                 \\\n\n                    mv = ((mv & 0x7fff7fff) +                                 \\\n\n                          0x00010001) ^ (mv & 0x80008000);                    \\\n\n                }                                                             \\\n\n                if (!n || mv != AV_RN32A(&near_mv[idx]))                      \\\n\n                    AV_WN32A(&near_mv[++idx], mv);                            \\\n\n                cnt[idx] += 1 + (n != 2);                                     \\\n\n            } else                                                            \\\n\n                cnt[CNT_ZERO] += 1 + (n != 2);                                \\\n\n        }                                                                     \\\n\n    }\n\n\n\n    MV_EDGE_CHECK(0)\n\n    MV_EDGE_CHECK(1)\n\n    MV_EDGE_CHECK(2)\n\n\n\n    mb->partitioning = VP8_SPLITMVMODE_NONE;\n\n    if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_ZERO]][0])) {\n\n        mb->mode = VP8_MVMODE_MV;\n\n\n\n        /* If we have three distinct MVs, merge first and last if they're the same */\n\n        if (cnt[CNT_SPLITMV] &&\n\n            AV_RN32A(&near_mv[1 + VP8_EDGE_TOP]) == AV_RN32A(&near_mv[1 + VP8_EDGE_TOPLEFT]))\n\n            cnt[CNT_NEAREST] += 1;\n\n\n\n        /* Swap near and nearest if necessary */\n\n        if (cnt[CNT_NEAR] > cnt[CNT_NEAREST]) {\n\n            FFSWAP(uint8_t,     cnt[CNT_NEAREST],     cnt[CNT_NEAR]);\n\n            FFSWAP( VP56mv, near_mv[CNT_NEAREST], near_mv[CNT_NEAR]);\n\n        }\n\n\n\n        if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAREST]][1])) {\n\n            if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAR]][2])) {\n\n                /* Choose the best mv out of 0,0 and the nearest mv */\n\n                clamp_mv(s, &mb->mv, &near_mv[CNT_ZERO + (cnt[CNT_NEAREST] >= cnt[CNT_ZERO])]);\n\n                cnt[CNT_SPLITMV] = ((mb_edge[VP8_EDGE_LEFT]->mode    == VP8_MVMODE_SPLIT) +\n\n                                    (mb_edge[VP8_EDGE_TOP]->mode     == VP8_MVMODE_SPLIT)) * 2 +\n\n                                    (mb_edge[VP8_EDGE_TOPLEFT]->mode == VP8_MVMODE_SPLIT);\n\n\n\n                if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_SPLITMV]][3])) {\n\n                    mb->mode = VP8_MVMODE_SPLIT;\n\n                    mb->mv = mb->bmv[decode_splitmvs(s, c, mb, layout, IS_VP8) - 1];\n\n                } else {\n\n                    mb->mv.y  += vp8_read_mv_component(c, s->prob->mvc[0]);\n\n                    mb->mv.x  += vp8_read_mv_component(c, s->prob->mvc[1]);\n\n                    mb->bmv[0] = mb->mv;\n\n                }\n\n            } else {\n\n                clamp_mv(s, &mb->mv, &near_mv[CNT_NEAR]);\n\n                mb->bmv[0] = mb->mv;\n\n            }\n\n        } else {\n\n            clamp_mv(s, &mb->mv, &near_mv[CNT_NEAREST]);\n\n            mb->bmv[0] = mb->mv;\n\n        }\n\n    } else {\n\n        mb->mode = VP8_MVMODE_ZERO;\n\n        AV_ZERO32(&mb->mv);\n\n        mb->bmv[0] = mb->mv;\n\n    }\n\n}\n", "idx": 8208, "_split": "test", "_hash": "21e94e7fad8e28b3edd40b91b857556f"}
{"project": "FFmpeg", "commit_id": "eb24fd64589b7eea91fa752861f0c6f07e5a48a8", "target": 0, "func": "int ff_rle_encode(uint8_t *outbuf, int out_size, const uint8_t *ptr , int bpp, int w, int8_t add, uint8_t xor)\n\n{\n\n    int count, x;\n\n    uint8_t *out;\n\n\n\n    out = outbuf;\n\n\n\n\n\n        for(x = 0; x < w; x += count) {\n\n            /* see if we can encode the next set of pixels with RLE */\n\n            if((count = count_pixels(ptr, w-x, bpp, 1)) > 1) {\n\n                if(out + bpp + 1 > outbuf + out_size) return -1;\n\n                *out++ = (count ^ xor) + add;\n\n                memcpy(out, ptr, bpp);\n\n                out += bpp;\n\n            } else {\n\n                /* fall back on uncompressed */\n\n                count = count_pixels(ptr, w-x, bpp, 0);\n\n                *out++ = count - 1;\n\n\n\n                if(out + bpp*count > outbuf + out_size) return -1;\n\n                memcpy(out, ptr, bpp * count);\n\n                out += bpp * count;\n\n        }\n\n\n\n        ptr += count * bpp;\n\n    }\n\n\n\n    return out - outbuf;\n\n}\n", "idx": 8211, "_split": "test", "_hash": "b6b12d390c44d1c7ecd9a7305745df5a"}
{"project": "FFmpeg", "commit_id": "cbbb2067341d7c2d98f560f81c6fb103af33a490", "target": 1, "func": "static int vdpau_frames_init(AVHWFramesContext *ctx)\n\n{\n\n    VDPAUDeviceContext *device_priv = ctx->device_ctx->internal->priv;\n\n    VDPAUFramesContext        *priv = ctx->internal->priv;\n\n\n\n    int i;\n\n\n\n    switch (ctx->sw_format) {\n\n    case AV_PIX_FMT_YUV420P: priv->chroma_type = VDP_CHROMA_TYPE_420; break;\n\n    case AV_PIX_FMT_YUV422P: priv->chroma_type = VDP_CHROMA_TYPE_422; break;\n\n    case AV_PIX_FMT_YUV444P: priv->chroma_type = VDP_CHROMA_TYPE_444; break;\n\n    default:\n\n        av_log(ctx, AV_LOG_ERROR, \"Unsupported data layout: %s\\n\",\n\n               av_get_pix_fmt_name(ctx->sw_format));\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(vdpau_pix_fmts); i++) {\n\n        if (vdpau_pix_fmts[i].chroma_type == priv->chroma_type) {\n\n            priv->chroma_idx  = i;\n\n            priv->pix_fmts    = device_priv->pix_fmts[i];\n\n            priv->nb_pix_fmts = device_priv->nb_pix_fmts[i];\n\n            break;\n\n        }\n\n    }\n\n    if (!priv->pix_fmts) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Unsupported chroma type: %d\\n\", priv->chroma_type);\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    if (!ctx->pool) {\n\n        ctx->internal->pool_internal = av_buffer_pool_init2(sizeof(VdpVideoSurface), ctx,\n\n                                                            vdpau_pool_alloc, NULL);\n\n        if (!ctx->internal->pool_internal)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    priv->get_data = device_priv->get_data;\n\n    priv->put_data = device_priv->put_data;\n\n\n\n    return 0;\n\n}\n", "idx": 8217, "_split": "test", "_hash": "8f71f5c7dddd12c7e1ec3d56528ae821"}
{"project": "FFmpeg", "commit_id": "801c39e1e3058fc4ba822bfb5d8612d777111e32", "target": 0, "func": "static int dca_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    AVFrame *frame     = data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n\n\n    int lfe_samples;\n\n    int num_core_channels = 0;\n\n    int i, ret;\n\n    float  **samples_flt;\n\n    DCAContext *s = avctx->priv_data;\n\n    int channels, full_channels;\n\n    int core_ss_end;\n\n\n\n\n\n    s->xch_present = 0;\n\n\n\n    s->dca_buffer_size = ff_dca_convert_bitstream(buf, buf_size, s->dca_buffer,\n\n                                                  DCA_MAX_FRAME_SIZE + DCA_MAX_EXSS_HEADER_SIZE);\n\n    if (s->dca_buffer_size == AVERROR_INVALIDDATA) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Not a valid DCA frame\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    init_get_bits(&s->gb, s->dca_buffer, s->dca_buffer_size * 8);\n\n    if ((ret = dca_parse_frame_header(s)) < 0) {\n\n        //seems like the frame is corrupt, try with the next one\n\n        return ret;\n\n    }\n\n    //set AVCodec values with parsed data\n\n    avctx->sample_rate = s->sample_rate;\n\n    avctx->bit_rate    = s->bit_rate;\n\n\n\n    s->profile = FF_PROFILE_DTS;\n\n\n\n    for (i = 0; i < (s->sample_blocks / 8); i++) {\n\n        if ((ret = dca_decode_block(s, 0, i))) {\n\n            av_log(avctx, AV_LOG_ERROR, \"error decoding block\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    /* record number of core channels incase less than max channels are requested */\n\n    num_core_channels = s->prim_channels;\n\n\n\n    if (s->ext_coding)\n\n        s->core_ext_mask = dca_ext_audio_descr_mask[s->ext_descr];\n\n    else\n\n        s->core_ext_mask = 0;\n\n\n\n    core_ss_end = FFMIN(s->frame_size, s->dca_buffer_size) * 8;\n\n\n\n    /* only scan for extensions if ext_descr was unknown or indicated a\n\n     * supported XCh extension */\n\n    if (s->core_ext_mask < 0 || s->core_ext_mask & DCA_EXT_XCH) {\n\n\n\n        /* if ext_descr was unknown, clear s->core_ext_mask so that the\n\n         * extensions scan can fill it up */\n\n        s->core_ext_mask = FFMAX(s->core_ext_mask, 0);\n\n\n\n        /* extensions start at 32-bit boundaries into bitstream */\n\n        skip_bits_long(&s->gb, (-get_bits_count(&s->gb)) & 31);\n\n\n\n        while (core_ss_end - get_bits_count(&s->gb) >= 32) {\n\n            uint32_t bits = get_bits_long(&s->gb, 32);\n\n\n\n            switch (bits) {\n\n            case 0x5a5a5a5a: {\n\n                int ext_amode, xch_fsize;\n\n\n\n                s->xch_base_channel = s->prim_channels;\n\n\n\n                /* validate sync word using XCHFSIZE field */\n\n                xch_fsize = show_bits(&s->gb, 10);\n\n                if ((s->frame_size != (get_bits_count(&s->gb) >> 3) - 4 + xch_fsize) &&\n\n                    (s->frame_size != (get_bits_count(&s->gb) >> 3) - 4 + xch_fsize + 1))\n\n                    continue;\n\n\n\n                /* skip length-to-end-of-frame field for the moment */\n\n                skip_bits(&s->gb, 10);\n\n\n\n                s->core_ext_mask |= DCA_EXT_XCH;\n\n\n\n                /* extension amode(number of channels in extension) should be 1 */\n\n                /* AFAIK XCh is not used for more channels */\n\n                if ((ext_amode = get_bits(&s->gb, 4)) != 1) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"XCh extension amode %d not\"\n\n                           \" supported!\\n\", ext_amode);\n\n                    continue;\n\n                }\n\n\n\n                /* much like core primary audio coding header */\n\n                dca_parse_audio_coding_header(s, s->xch_base_channel);\n\n\n\n                for (i = 0; i < (s->sample_blocks / 8); i++)\n\n                    if ((ret = dca_decode_block(s, s->xch_base_channel, i))) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"error decoding XCh extension\\n\");\n\n                        continue;\n\n                    }\n\n\n\n                s->xch_present = 1;\n\n                break;\n\n            }\n\n            case 0x47004a03:\n\n                /* XXCh: extended channels */\n\n                /* usually found either in core or HD part in DTS-HD HRA streams,\n\n                 * but not in DTS-ES which contains XCh extensions instead */\n\n                s->core_ext_mask |= DCA_EXT_XXCH;\n\n                break;\n\n\n\n            case 0x1d95f262: {\n\n                int fsize96 = show_bits(&s->gb, 12) + 1;\n\n                if (s->frame_size != (get_bits_count(&s->gb) >> 3) - 4 + fsize96)\n\n                    continue;\n\n\n\n                av_log(avctx, AV_LOG_DEBUG, \"X96 extension found at %d bits\\n\",\n\n                       get_bits_count(&s->gb));\n\n                skip_bits(&s->gb, 12);\n\n                av_log(avctx, AV_LOG_DEBUG, \"FSIZE96 = %d bytes\\n\", fsize96);\n\n                av_log(avctx, AV_LOG_DEBUG, \"REVNO = %d\\n\", get_bits(&s->gb, 4));\n\n\n\n                s->core_ext_mask |= DCA_EXT_X96;\n\n                break;\n\n            }\n\n            }\n\n\n\n            skip_bits_long(&s->gb, (-get_bits_count(&s->gb)) & 31);\n\n        }\n\n    } else {\n\n        /* no supported extensions, skip the rest of the core substream */\n\n        skip_bits_long(&s->gb, core_ss_end - get_bits_count(&s->gb));\n\n    }\n\n\n\n    if (s->core_ext_mask & DCA_EXT_X96)\n\n        s->profile = FF_PROFILE_DTS_96_24;\n\n    else if (s->core_ext_mask & (DCA_EXT_XCH | DCA_EXT_XXCH))\n\n        s->profile = FF_PROFILE_DTS_ES;\n\n\n\n    /* check for ExSS (HD part) */\n\n    if (s->dca_buffer_size - s->frame_size > 32 &&\n\n        get_bits_long(&s->gb, 32) == DCA_HD_MARKER)\n\n        dca_exss_parse_header(s);\n\n\n\n    avctx->profile = s->profile;\n\n\n\n    full_channels = channels = s->prim_channels + !!s->lfe;\n\n\n\n    if (s->amode < 16) {\n\n        avctx->channel_layout = dca_core_channel_layout[s->amode];\n\n\n\n        if (s->prim_channels + !!s->lfe > 2 &&\n\n            avctx->request_channel_layout == AV_CH_LAYOUT_STEREO) {\n\n            /*\n\n             * Neither the core's auxiliary data nor our default tables contain\n\n             * downmix coefficients for the additional channel coded in the XCh\n\n             * extension, so when we're doing a Stereo downmix, don't decode it.\n\n             */\n\n            s->xch_disable = 1;\n\n        }\n\n\n\n#if FF_API_REQUEST_CHANNELS\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        if (s->xch_present && !s->xch_disable &&\n\n            (!avctx->request_channels ||\n\n             avctx->request_channels > num_core_channels + !!s->lfe)) {\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#else\n\n        if (s->xch_present && !s->xch_disable) {\n\n#endif\n\n            avctx->channel_layout |= AV_CH_BACK_CENTER;\n\n            if (s->lfe) {\n\n                avctx->channel_layout |= AV_CH_LOW_FREQUENCY;\n\n                s->channel_order_tab = dca_channel_reorder_lfe_xch[s->amode];\n\n            } else {\n\n                s->channel_order_tab = dca_channel_reorder_nolfe_xch[s->amode];\n\n            }\n\n        } else {\n\n            channels = num_core_channels + !!s->lfe;\n\n            s->xch_present = 0; /* disable further xch processing */\n\n            if (s->lfe) {\n\n                avctx->channel_layout |= AV_CH_LOW_FREQUENCY;\n\n                s->channel_order_tab = dca_channel_reorder_lfe[s->amode];\n\n            } else\n\n                s->channel_order_tab = dca_channel_reorder_nolfe[s->amode];\n\n        }\n\n\n\n        if (channels > !!s->lfe &&\n\n            s->channel_order_tab[channels - 1 - !!s->lfe] < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        if (s->prim_channels + !!s->lfe > 2 &&\n\n            avctx->request_channel_layout == AV_CH_LAYOUT_STEREO) {\n\n            channels = 2;\n\n            s->output = s->prim_channels == 2 ? s->amode : DCA_STEREO;\n\n            avctx->channel_layout = AV_CH_LAYOUT_STEREO;\n\n\n\n            /* Stereo downmix coefficients\n\n             *\n\n             * The decoder can only downmix to 2-channel, so we need to ensure\n\n             * embedded downmix coefficients are actually targeting 2-channel.\n\n             */\n\n            if (s->core_downmix && (s->core_downmix_amode == DCA_STEREO ||\n\n                                    s->core_downmix_amode == DCA_STEREO_TOTAL)) {\n\n                int sign, code;\n\n                for (i = 0; i < s->prim_channels + !!s->lfe; i++) {\n\n                    sign = s->core_downmix_codes[i][0] & 0x100 ? 1 : -1;\n\n                    code = s->core_downmix_codes[i][0] & 0x0FF;\n\n                    s->downmix_coef[i][0] = (!code ? 0.0f :\n\n                                             sign * dca_dmixtable[code - 1]);\n\n                    sign = s->core_downmix_codes[i][1] & 0x100 ? 1 : -1;\n\n                    code = s->core_downmix_codes[i][1] & 0x0FF;\n\n                    s->downmix_coef[i][1] = (!code ? 0.0f :\n\n                                             sign * dca_dmixtable[code - 1]);\n\n                }\n\n                s->output = s->core_downmix_amode;\n\n            } else {\n\n                int am = s->amode & DCA_CHANNEL_MASK;\n\n                if (am >= FF_ARRAY_ELEMS(dca_default_coeffs)) {\n\n                    av_log(s->avctx, AV_LOG_ERROR,\n\n                           \"Invalid channel mode %d\\n\", am);\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n                if (s->prim_channels + !!s->lfe >\n\n                    FF_ARRAY_ELEMS(dca_default_coeffs[0])) {\n\n                    avpriv_request_sample(s->avctx, \"Downmixing %d channels\",\n\n                                          s->prim_channels + !!s->lfe);\n\n                    return AVERROR_PATCHWELCOME;\n\n                }\n\n                for (i = 0; i < s->prim_channels + !!s->lfe; i++) {\n\n                    s->downmix_coef[i][0] = dca_default_coeffs[am][i][0];\n\n                    s->downmix_coef[i][1] = dca_default_coeffs[am][i][1];\n\n                }\n\n            }\n\n            av_dlog(s->avctx, \"Stereo downmix coeffs:\\n\");\n\n            for (i = 0; i < s->prim_channels + !!s->lfe; i++) {\n\n                av_dlog(s->avctx, \"L, input channel %d = %f\\n\", i,\n\n                        s->downmix_coef[i][0]);\n\n                av_dlog(s->avctx, \"R, input channel %d = %f\\n\", i,\n\n                        s->downmix_coef[i][1]);\n\n            }\n\n            av_dlog(s->avctx, \"\\n\");\n\n        }\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Non standard configuration %d !\\n\", s->amode);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avctx->channels = channels;\n\n\n\n    /* get output buffer */\n\n    frame->nb_samples = 256 * (s->sample_blocks / 8);\n\n    if ((ret = ff_get_buffer(avctx, frame, 0)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    samples_flt = (float **)frame->extended_data;\n\n\n\n    /* allocate buffer for extra channels if downmixing */\n\n    if (avctx->channels < full_channels) {\n\n        ret = av_samples_get_buffer_size(NULL, full_channels - channels,\n\n                                         frame->nb_samples,\n\n                                         avctx->sample_fmt, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        av_fast_malloc(&s->extra_channels_buffer,\n\n                       &s->extra_channels_buffer_size, ret);\n\n        if (!s->extra_channels_buffer)\n\n            return AVERROR(ENOMEM);\n\n\n\n        ret = av_samples_fill_arrays((uint8_t **)s->extra_channels, NULL,\n\n                                     s->extra_channels_buffer,\n\n                                     full_channels - channels,\n\n                                     frame->nb_samples, avctx->sample_fmt, 0);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    /* filter to get final output */\n\n    for (i = 0; i < (s->sample_blocks / 8); i++) {\n\n        int ch;\n\n\n\n        for (ch = 0; ch < channels; ch++)\n\n            s->samples_chanptr[ch] = samples_flt[ch] + i * 256;\n\n        for (; ch < full_channels; ch++)\n\n            s->samples_chanptr[ch] = s->extra_channels[ch - channels] + i * 256;\n\n\n\n        dca_filter_channels(s, i);\n\n\n\n        /* If this was marked as a DTS-ES stream we need to subtract back- */\n\n        /* channel from SL & SR to remove matrixed back-channel signal */\n\n        if ((s->source_pcm_res & 1) && s->xch_present) {\n\n            float *back_chan = s->samples_chanptr[s->channel_order_tab[s->xch_base_channel]];\n\n            float *lt_chan   = s->samples_chanptr[s->channel_order_tab[s->xch_base_channel - 2]];\n\n            float *rt_chan   = s->samples_chanptr[s->channel_order_tab[s->xch_base_channel - 1]];\n\n            s->fdsp.vector_fmac_scalar(lt_chan, back_chan, -M_SQRT1_2, 256);\n\n            s->fdsp.vector_fmac_scalar(rt_chan, back_chan, -M_SQRT1_2, 256);\n\n        }\n\n    }\n\n\n\n    /* update lfe history */\n\n    lfe_samples = 2 * s->lfe * (s->sample_blocks / 8);\n\n    for (i = 0; i < 2 * s->lfe * 4; i++)\n\n        s->lfe_data[i] = s->lfe_data[i + lfe_samples];\n\n\n\n    /* AVMatrixEncoding\n\n     *\n\n     * DCA_STEREO_TOTAL (Lt/Rt) is equivalent to Dolby Surround */\n\n    ret = ff_side_data_update_matrix_encoding(frame,\n\n                                              (s->output & ~DCA_LFE) == DCA_STEREO_TOTAL ?\n\n                                              AV_MATRIX_ENCODING_DOLBY : AV_MATRIX_ENCODING_NONE);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    *got_frame_ptr = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 8241, "_split": "test", "_hash": "0c1217963a6de426d5d1a39dcbe2c3cd"}
{"project": "FFmpeg", "commit_id": "b52b398c30a729dda38c0dd5a0cdeef160c4ca54", "target": 0, "func": "static av_cold int vc2_encode_init(AVCodecContext *avctx)\n\n{\n\n    Plane *p;\n\n    SubBand *b;\n\n    int i, j, level, o, shift;\n\n    const AVPixFmtDescriptor *fmt = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    const int depth = fmt->comp[0].depth;\n\n    VC2EncContext *s = avctx->priv_data;\n\n\n\n    s->picture_number = 0;\n\n\n\n    /* Total allowed quantization range */\n\n    s->q_ceil    = DIRAC_MAX_QUANT_INDEX;\n\n\n\n    s->ver.major = 2;\n\n    s->ver.minor = 0;\n\n    s->profile   = 3;\n\n    s->level     = 3;\n\n\n\n    s->base_vf   = -1;\n\n    s->strict_compliance = 1;\n\n\n\n    s->q_avg = 0;\n\n    s->slice_max_bytes = 0;\n\n    s->slice_min_bytes = 0;\n\n\n\n    /* Mark unknown as progressive */\n\n    s->interlaced = !((avctx->field_order == AV_FIELD_UNKNOWN) ||\n\n                      (avctx->field_order == AV_FIELD_PROGRESSIVE));\n\n\n\n    for (i = 0; i < base_video_fmts_len; i++) {\n\n        const VC2BaseVideoFormat *fmt = &base_video_fmts[i];\n\n        if (avctx->pix_fmt != fmt->pix_fmt)\n\n            continue;\n\n        if (avctx->time_base.num != fmt->time_base.num)\n\n            continue;\n\n        if (avctx->time_base.den != fmt->time_base.den)\n\n            continue;\n\n        if (avctx->width != fmt->width)\n\n            continue;\n\n        if (avctx->height != fmt->height)\n\n            continue;\n\n        if (s->interlaced != fmt->interlaced)\n\n            continue;\n\n        s->base_vf = i;\n\n        s->level   = base_video_fmts[i].level;\n\n        break;\n\n    }\n\n\n\n    if (s->interlaced)\n\n        av_log(avctx, AV_LOG_WARNING, \"Interlacing enabled!\\n\");\n\n\n\n    if ((s->slice_width  & (s->slice_width  - 1)) ||\n\n        (s->slice_height & (s->slice_height - 1))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Slice size is not a power of two!\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if ((s->slice_width > avctx->width) ||\n\n        (s->slice_height > avctx->height)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Slice size is bigger than the image!\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if (s->base_vf <= 0) {\n\n        if (avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL) {\n\n            s->strict_compliance = s->base_vf = 0;\n\n            av_log(avctx, AV_LOG_WARNING, \"Disabling strict compliance\\n\");\n\n        } else {\n\n            av_log(avctx, AV_LOG_WARNING, \"Given format does not strictly comply with \"\n\n                   \"the specifications, please add a -strict -1 flag to use it\\n\");\n\n            return AVERROR_UNKNOWN;\n\n        }\n\n    } else {\n\n        av_log(avctx, AV_LOG_INFO, \"Selected base video format = %i (%s)\\n\",\n\n               s->base_vf, base_video_fmts[s->base_vf].name);\n\n    }\n\n\n\n    /* Chroma subsampling */\n\n    avcodec_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_x_shift, &s->chroma_y_shift);\n\n\n\n    /* Bit depth and color range index */\n\n    if (depth == 8 && avctx->color_range == AVCOL_RANGE_JPEG) {\n\n        s->bpp = 1;\n\n        s->bpp_idx = 1;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 8 && (avctx->color_range == AVCOL_RANGE_MPEG ||\n\n               avctx->color_range == AVCOL_RANGE_UNSPECIFIED)) {\n\n        s->bpp = 1;\n\n        s->bpp_idx = 2;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 10) {\n\n        s->bpp = 2;\n\n        s->bpp_idx = 3;\n\n        s->diff_offset = 512;\n\n    } else {\n\n        s->bpp = 2;\n\n        s->bpp_idx = 4;\n\n        s->diff_offset = 2048;\n\n    }\n\n\n\n    /* Planes initialization */\n\n    for (i = 0; i < 3; i++) {\n\n        int w, h;\n\n        p = &s->plane[i];\n\n        p->width      = avctx->width  >> (i ? s->chroma_x_shift : 0);\n\n        p->height     = avctx->height >> (i ? s->chroma_y_shift : 0);\n\n        if (s->interlaced)\n\n            p->height >>= 1;\n\n        p->dwt_width  = w = FFALIGN(p->width,  (1 << s->wavelet_depth));\n\n        p->dwt_height = h = FFALIGN(p->height, (1 << s->wavelet_depth));\n\n        p->coef_stride = FFALIGN(p->dwt_width, 32);\n\n        p->coef_buf = av_malloc(p->coef_stride*p->dwt_height*sizeof(dwtcoef));\n\n        if (!p->coef_buf)\n\n            goto alloc_fail;\n\n        for (level = s->wavelet_depth-1; level >= 0; level--) {\n\n            w = w >> 1;\n\n            h = h >> 1;\n\n            for (o = 0; o < 4; o++) {\n\n                b = &p->band[level][o];\n\n                b->width  = w;\n\n                b->height = h;\n\n                b->stride = p->coef_stride;\n\n                shift = (o > 1)*b->height*b->stride + (o & 1)*b->width;\n\n                b->buf = p->coef_buf + shift;\n\n            }\n\n        }\n\n\n\n        /* DWT init */\n\n        if (ff_vc2enc_init_transforms(&s->transform_args[i].t,\n\n                                      s->plane[i].coef_stride,\n\n                                      s->plane[i].dwt_height))\n\n            goto alloc_fail;\n\n    }\n\n\n\n    /* Slices */\n\n    s->num_x = s->plane[0].dwt_width/s->slice_width;\n\n    s->num_y = s->plane[0].dwt_height/s->slice_height;\n\n\n\n    s->slice_args = av_calloc(s->num_x*s->num_y, sizeof(SliceArgs));\n\n    if (!s->slice_args)\n\n        goto alloc_fail;\n\n\n\n    /* Lookup tables */\n\n    s->coef_lut_len = av_malloc(COEF_LUT_TAB*(s->q_ceil+1)*sizeof(*s->coef_lut_len));\n\n    if (!s->coef_lut_len)\n\n        goto alloc_fail;\n\n\n\n    s->coef_lut_val = av_malloc(COEF_LUT_TAB*(s->q_ceil+1)*sizeof(*s->coef_lut_val));\n\n    if (!s->coef_lut_val)\n\n        goto alloc_fail;\n\n\n\n    for (i = 0; i < s->q_ceil; i++) {\n\n        uint8_t  *len_lut = &s->coef_lut_len[i*COEF_LUT_TAB];\n\n        uint32_t *val_lut = &s->coef_lut_val[i*COEF_LUT_TAB];\n\n        for (j = 0; j < COEF_LUT_TAB; j++) {\n\n            get_vc2_ue_uint(QUANT(j, ff_dirac_qscale_tab[i]),\n\n                            &len_lut[j], &val_lut[j]);\n\n            if (len_lut[j] != 1) {\n\n                len_lut[j] += 1;\n\n                val_lut[j] <<= 1;\n\n            } else {\n\n                val_lut[j] = 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n\n\nalloc_fail:\n\n    vc2_encode_end(avctx);\n\n    av_log(avctx, AV_LOG_ERROR, \"Unable to allocate memory!\\n\");\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 8271, "_split": "test", "_hash": "7b2d1b9ee2b34232b0647b5d56ad3c0a"}
{"project": "FFmpeg", "commit_id": "ebbcdc9ac0ea190748a1605bda86ce84466c8b4e", "target": 0, "func": "void ff_fix_long_b_mvs(MpegEncContext * s, int16_t (*mv_table)[2], int f_code, int type)\n\n{\n\n    int y;\n\n    uint8_t * fcode_tab= s->fcode_tab;\n\n\n\n    // RAL: 8 in MPEG-1, 16 in MPEG-4\n\n    int range = (((s->codec_id == CODEC_ID_MPEG1VIDEO) ? 8 : 16) << f_code);\n\n\n\n    /* clip / convert to intra 16x16 type MVs */\n\n    for(y=0; y<s->mb_height; y++){\n\n        int x;\n\n        int xy= (y+1)* (s->mb_width+2)+1;\n\n        int i= y*s->mb_width;\n\n        for(x=0; x<s->mb_width; x++)\n\n            {\n\n            if (s->mb_type[i] & type)    // RAL: \"type\" test added...\n\n                {\n\n                if (fcode_tab[mv_table[xy][0] + MAX_MV] > f_code || fcode_tab[mv_table[xy][0] + MAX_MV] == 0)\n\n                    {\n\n                    if(mv_table[xy][0]>0) \n\n                        mv_table[xy][0]=  range-1;\n\n                    else\n\n                        mv_table[xy][0]= -range;\n\n                    }\n\n                if (fcode_tab[mv_table[xy][1] + MAX_MV] > f_code || fcode_tab[mv_table[xy][1] + MAX_MV] == 0)\n\n                    {\n\n                    if(mv_table[xy][1]>0) \n\n                        mv_table[xy][1]=  range-1;\n\n                    else                  \n\n                        mv_table[xy][1]= -range;\n\n            }\n\n            }\n\n            xy++;\n\n            i++;\n\n        }\n\n    }\n\n}\n", "idx": 8273, "_split": "test", "_hash": "c3d65377e3b77805f7253c4a1f452836"}
{"project": "FFmpeg", "commit_id": "3beb9cbad35218ed1fb3473eeb3cfc97a931bff4", "target": 0, "func": "static void create_cel_evals(RoqContext *enc, RoqTempdata *tempData)\n\n{\n\n    int n=0, x, y, i;\n\n\n\n    tempData->cel_evals = av_malloc(enc->width*enc->height/64 * sizeof(CelEvaluation));\n\n\n\n    /* Map to the ROQ quadtree order */\n\n    for (y=0; y<enc->height; y+=16)\n\n        for (x=0; x<enc->width; x+=16)\n\n            for(i=0; i<4; i++) {\n\n                tempData->cel_evals[n  ].sourceX = x + (i&1)*8;\n\n                tempData->cel_evals[n++].sourceY = y + (i&2)*4;\n\n            }\n\n}\n", "idx": 8313, "_split": "test", "_hash": "7997bf296897befe5a7b67cc3c3802d6"}
{"project": "FFmpeg", "commit_id": "273e6af47b38391f2bcc157cca0423fe7fcbf55c", "target": 0, "func": "static int ea_read_packet(AVFormatContext *s,\n\n                          AVPacket *pkt)\n\n{\n\n    EaDemuxContext *ea = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int ret = 0;\n\n    int packet_read = 0;\n\n    unsigned int chunk_type, chunk_size;\n\n    int key = 0;\n\n    int av_uninit(num_samples);\n\n\n\n    while (!packet_read) {\n\n        chunk_type = avio_rl32(pb);\n\n        chunk_size = (ea->big_endian ? avio_rb32(pb) : avio_rl32(pb)) - 8;\n\n\n\n        switch (chunk_type) {\n\n        /* audio data */\n\n        case ISNh_TAG:\n\n            /* header chunk also contains data; skip over the header portion*/\n\n            avio_skip(pb, 32);\n\n            chunk_size -= 32;\n\n        case ISNd_TAG:\n\n        case SCDl_TAG:\n\n        case SNDC_TAG:\n\n        case SDEN_TAG:\n\n            if (!ea->audio_codec) {\n\n                avio_skip(pb, chunk_size);\n\n                break;\n\n            } else if (ea->audio_codec == CODEC_ID_PCM_S16LE_PLANAR ||\n\n                       ea->audio_codec == CODEC_ID_MP3) {\n\n                num_samples = avio_rl32(pb);\n\n                avio_skip(pb, 8);\n\n                chunk_size -= 12;\n\n            }\n\n            ret = av_get_packet(pb, pkt, chunk_size);\n\n            if (ret < 0)\n\n                return ret;\n\n            pkt->stream_index = ea->audio_stream_index;\n\n\n\n            switch (ea->audio_codec) {\n\n            case CODEC_ID_ADPCM_EA:\n\n            case CODEC_ID_ADPCM_EA_R1:\n\n            case CODEC_ID_ADPCM_EA_R2:\n\n            case CODEC_ID_ADPCM_IMA_EA_EACS:\n\n                pkt->duration = AV_RL32(pkt->data);\n\n                break;\n\n            case CODEC_ID_ADPCM_EA_R3:\n\n                pkt->duration = AV_RB32(pkt->data);\n\n                break;\n\n            case CODEC_ID_ADPCM_IMA_EA_SEAD:\n\n                pkt->duration = ret * 2 / ea->num_channels;\n\n                break;\n\n            case CODEC_ID_PCM_S16LE_PLANAR:\n\n            case CODEC_ID_MP3:\n\n                pkt->duration = num_samples;\n\n                break;\n\n            default:\n\n                pkt->duration = chunk_size / (ea->bytes * ea->num_channels);\n\n            }\n\n\n\n            packet_read = 1;\n\n            break;\n\n\n\n        /* ending tag */\n\n        case 0:\n\n        case ISNe_TAG:\n\n        case SCEl_TAG:\n\n        case SEND_TAG:\n\n        case SEEN_TAG:\n\n            ret = AVERROR(EIO);\n\n            packet_read = 1;\n\n            break;\n\n\n\n        case MVIh_TAG:\n\n        case kVGT_TAG:\n\n        case pQGT_TAG:\n\n        case TGQs_TAG:\n\n        case MADk_TAG:\n\n            key = AV_PKT_FLAG_KEY;\n\n        case MVIf_TAG:\n\n        case fVGT_TAG:\n\n        case MADm_TAG:\n\n        case MADe_TAG:\n\n            avio_seek(pb, -8, SEEK_CUR);     // include chunk preamble\n\n            chunk_size += 8;\n\n            goto get_video_packet;\n\n\n\n        case mTCD_TAG:\n\n            avio_skip(pb, 8);  // skip ea dct header\n\n            chunk_size -= 8;\n\n            goto get_video_packet;\n\n\n\n        case MV0K_TAG:\n\n        case MPCh_TAG:\n\n        case pIQT_TAG:\n\n            key = AV_PKT_FLAG_KEY;\n\n        case MV0F_TAG:\n\nget_video_packet:\n\n            ret = av_get_packet(pb, pkt, chunk_size);\n\n            if (ret < 0)\n\n                return ret;\n\n            pkt->stream_index = ea->video_stream_index;\n\n            pkt->flags |= key;\n\n            packet_read = 1;\n\n            break;\n\n\n\n        default:\n\n            avio_skip(pb, chunk_size);\n\n            break;\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 8340, "_split": "test", "_hash": "8840d92879c909ba225531e5b21e4acd"}
{"project": "FFmpeg", "commit_id": "c97f54020d5d55511e28622551f13233bd8ceb56", "target": 0, "func": "static int video_open(VideoState *is){\n\n    int flags = SDL_HWSURFACE|SDL_ASYNCBLIT|SDL_HWACCEL;\n\n    int w,h;\n\n\n\n    if(is_full_screen) flags |= SDL_FULLSCREEN;\n\n    else               flags |= SDL_RESIZABLE;\n\n\n\n    if (is_full_screen && fs_screen_width) {\n\n        w = fs_screen_width;\n\n        h = fs_screen_height;\n\n    } else if(!is_full_screen && screen_width){\n\n        w = screen_width;\n\n        h = screen_height;\n\n    }else if (is->video_st && is->video_st->codec->width){\n\n        w = is->video_st->codec->width;\n\n        h = is->video_st->codec->height;\n\n    } else {\n\n        w = 640;\n\n        h = 480;\n\n    }\n\n#ifndef SYS_DARWIN\n\n    screen = SDL_SetVideoMode(w, h, 0, flags);\n\n#else\n\n    /* setting bits_per_pixel = 0 or 32 causes blank video on OS X */\n\n    screen = SDL_SetVideoMode(w, h, 24, flags);\n\n#endif\n\n    if (!screen) {\n\n        fprintf(stderr, \"SDL: could not set video mode - exiting\\n\");\n\n        return -1;\n\n    }\n\n    SDL_WM_SetCaption(\"FFplay\", \"FFplay\");\n\n\n\n    is->width = screen->w;\n\n    is->height = screen->h;\n\n\n\n    return 0;\n\n}\n", "idx": 8370, "_split": "test", "_hash": "a7a974d1c96cce723214ae1848da0623"}
{"project": "FFmpeg", "commit_id": "b1306823d0b3ae998c8e10ad832004eb13bdd93e", "target": 0, "func": "static int write_option(void *optctx, const OptionDef *po, const char *opt,\n\n                        const char *arg)\n\n{\n\n    /* new-style options contain an offset into optctx, old-style address of\n\n     * a global var*/\n\n    void *dst = po->flags & (OPT_OFFSET | OPT_SPEC) ?\n\n                (uint8_t *)optctx + po->u.off : po->u.dst_ptr;\n\n    int *dstcount;\n\n\n\n    if (po->flags & OPT_SPEC) {\n\n        SpecifierOpt **so = dst;\n\n        char *p = strchr(opt, ':');\n\n\n\n        dstcount = (int *)(so + 1);\n\n        *so = grow_array(*so, sizeof(**so), dstcount, *dstcount + 1);\n\n        (*so)[*dstcount - 1].specifier = av_strdup(p ? p + 1 : \"\");\n\n        dst = &(*so)[*dstcount - 1].u;\n\n    }\n\n\n\n    if (po->flags & OPT_STRING) {\n\n        char *str;\n\n        str = av_strdup(arg);\n\n        av_freep(dst);\n\n        *(char **)dst = str;\n\n    } else if (po->flags & OPT_BOOL || po->flags & OPT_INT) {\n\n        *(int *)dst = parse_number_or_die(opt, arg, OPT_INT64, INT_MIN, INT_MAX);\n\n    } else if (po->flags & OPT_INT64) {\n\n        *(int64_t *)dst = parse_number_or_die(opt, arg, OPT_INT64, INT64_MIN, INT64_MAX);\n\n    } else if (po->flags & OPT_TIME) {\n\n        *(int64_t *)dst = parse_time_or_die(opt, arg, 1);\n\n    } else if (po->flags & OPT_FLOAT) {\n\n        *(float *)dst = parse_number_or_die(opt, arg, OPT_FLOAT, -INFINITY, INFINITY);\n\n    } else if (po->flags & OPT_DOUBLE) {\n\n        *(double *)dst = parse_number_or_die(opt, arg, OPT_DOUBLE, -INFINITY, INFINITY);\n\n    } else if (po->u.func_arg) {\n\n        int ret = po->u.func_arg(optctx, opt, arg);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_ERROR,\n\n                   \"Failed to set value '%s' for option '%s'\\n\", arg, opt);\n\n            return ret;\n\n        }\n\n    }\n\n    if (po->flags & OPT_EXIT)\n\n        exit_program(0);\n\n\n\n    return 0;\n\n}\n", "idx": 8425, "_split": "test", "_hash": "df925e12944e5283d6a3d8886bd06023"}
{"project": "FFmpeg", "commit_id": "6f1ec38ce2193d3d4cacd87edb452c6d7ba751ec", "target": 0, "func": "static av_cold int decode_init(AVCodecContext * avctx)\n\n{\n\n    MPADecodeContext *s = avctx->priv_data;\n\n    static int init=0;\n\n    int i, j, k;\n\n\n\n    s->avctx = avctx;\n\n\n\n    ff_mpadsp_init(&s->mpadsp);\n\n\n\n    avctx->sample_fmt= OUT_FMT;\n\n    s->error_recognition= avctx->error_recognition;\n\n\n\n    if (!init && !avctx->parse_only) {\n\n        int offset;\n\n\n\n        /* scale factors table for layer 1/2 */\n\n        for(i=0;i<64;i++) {\n\n            int shift, mod;\n\n            /* 1.0 (i = 3) is normalized to 2 ^ FRAC_BITS */\n\n            shift = (i / 3);\n\n            mod = i % 3;\n\n            scale_factor_modshift[i] = mod | (shift << 2);\n\n        }\n\n\n\n        /* scale factor multiply for layer 1 */\n\n        for(i=0;i<15;i++) {\n\n            int n, norm;\n\n            n = i + 2;\n\n            norm = ((INT64_C(1) << n) * FRAC_ONE) / ((1 << n) - 1);\n\n            scale_factor_mult[i][0] = MULLx(norm, FIXR(1.0          * 2.0), FRAC_BITS);\n\n            scale_factor_mult[i][1] = MULLx(norm, FIXR(0.7937005259 * 2.0), FRAC_BITS);\n\n            scale_factor_mult[i][2] = MULLx(norm, FIXR(0.6299605249 * 2.0), FRAC_BITS);\n\n            av_dlog(avctx, \"%d: norm=%x s=%x %x %x\\n\",\n\n                    i, norm,\n\n                    scale_factor_mult[i][0],\n\n                    scale_factor_mult[i][1],\n\n                    scale_factor_mult[i][2]);\n\n        }\n\n\n\n        RENAME(ff_mpa_synth_init)(RENAME(ff_mpa_synth_window));\n\n\n\n        /* huffman decode tables */\n\n        offset = 0;\n\n        for(i=1;i<16;i++) {\n\n            const HuffTable *h = &mpa_huff_tables[i];\n\n            int xsize, x, y;\n\n            uint8_t  tmp_bits [512];\n\n            uint16_t tmp_codes[512];\n\n\n\n            memset(tmp_bits , 0, sizeof(tmp_bits ));\n\n            memset(tmp_codes, 0, sizeof(tmp_codes));\n\n\n\n            xsize = h->xsize;\n\n\n\n            j = 0;\n\n            for(x=0;x<xsize;x++) {\n\n                for(y=0;y<xsize;y++){\n\n                    tmp_bits [(x << 5) | y | ((x&&y)<<4)]= h->bits [j  ];\n\n                    tmp_codes[(x << 5) | y | ((x&&y)<<4)]= h->codes[j++];\n\n                }\n\n            }\n\n\n\n            /* XXX: fail test */\n\n            huff_vlc[i].table = huff_vlc_tables+offset;\n\n            huff_vlc[i].table_allocated = huff_vlc_tables_sizes[i];\n\n            init_vlc(&huff_vlc[i], 7, 512,\n\n                     tmp_bits, 1, 1, tmp_codes, 2, 2,\n\n                     INIT_VLC_USE_NEW_STATIC);\n\n            offset += huff_vlc_tables_sizes[i];\n\n        }\n\n        assert(offset == FF_ARRAY_ELEMS(huff_vlc_tables));\n\n\n\n        offset = 0;\n\n        for(i=0;i<2;i++) {\n\n            huff_quad_vlc[i].table = huff_quad_vlc_tables+offset;\n\n            huff_quad_vlc[i].table_allocated = huff_quad_vlc_tables_sizes[i];\n\n            init_vlc(&huff_quad_vlc[i], i == 0 ? 7 : 4, 16,\n\n                     mpa_quad_bits[i], 1, 1, mpa_quad_codes[i], 1, 1,\n\n                     INIT_VLC_USE_NEW_STATIC);\n\n            offset += huff_quad_vlc_tables_sizes[i];\n\n        }\n\n        assert(offset == FF_ARRAY_ELEMS(huff_quad_vlc_tables));\n\n\n\n        for(i=0;i<9;i++) {\n\n            k = 0;\n\n            for(j=0;j<22;j++) {\n\n                band_index_long[i][j] = k;\n\n                k += band_size_long[i][j];\n\n            }\n\n            band_index_long[i][22] = k;\n\n        }\n\n\n\n        /* compute n ^ (4/3) and store it in mantissa/exp format */\n\n\n\n        int_pow_init();\n\n        mpegaudio_tableinit();\n\n\n\n        for (i = 0; i < 4; i++)\n\n            if (ff_mpa_quant_bits[i] < 0)\n\n                for (j = 0; j < (1<<(-ff_mpa_quant_bits[i]+1)); j++) {\n\n                    int val1, val2, val3, steps;\n\n                    int val = j;\n\n                    steps  = ff_mpa_quant_steps[i];\n\n                    val1 = val % steps;\n\n                    val /= steps;\n\n                    val2 = val % steps;\n\n                    val3 = val / steps;\n\n                    division_tabs[i][j] = val1 + (val2 << 4) + (val3 << 8);\n\n                }\n\n\n\n\n\n        for(i=0;i<7;i++) {\n\n            float f;\n\n            INTFLOAT v;\n\n            if (i != 6) {\n\n                f = tan((double)i * M_PI / 12.0);\n\n                v = FIXR(f / (1.0 + f));\n\n            } else {\n\n                v = FIXR(1.0);\n\n            }\n\n            is_table[0][i] = v;\n\n            is_table[1][6 - i] = v;\n\n        }\n\n        /* invalid values */\n\n        for(i=7;i<16;i++)\n\n            is_table[0][i] = is_table[1][i] = 0.0;\n\n\n\n        for(i=0;i<16;i++) {\n\n            double f;\n\n            int e, k;\n\n\n\n            for(j=0;j<2;j++) {\n\n                e = -(j + 1) * ((i + 1) >> 1);\n\n                f = pow(2.0, e / 4.0);\n\n                k = i & 1;\n\n                is_table_lsf[j][k ^ 1][i] = FIXR(f);\n\n                is_table_lsf[j][k][i] = FIXR(1.0);\n\n                av_dlog(avctx, \"is_table_lsf %d %d: %x %x\\n\",\n\n                        i, j, is_table_lsf[j][0][i], is_table_lsf[j][1][i]);\n\n            }\n\n        }\n\n\n\n        for(i=0;i<8;i++) {\n\n            float ci, cs, ca;\n\n            ci = ci_table[i];\n\n            cs = 1.0 / sqrt(1.0 + ci * ci);\n\n            ca = cs * ci;\n\n            csa_table[i][0] = FIXHR(cs/4);\n\n            csa_table[i][1] = FIXHR(ca/4);\n\n            csa_table[i][2] = FIXHR(ca/4) + FIXHR(cs/4);\n\n            csa_table[i][3] = FIXHR(ca/4) - FIXHR(cs/4);\n\n            csa_table_float[i][0] = cs;\n\n            csa_table_float[i][1] = ca;\n\n            csa_table_float[i][2] = ca + cs;\n\n            csa_table_float[i][3] = ca - cs;\n\n        }\n\n\n\n        /* compute mdct windows */\n\n        for(i=0;i<36;i++) {\n\n            for(j=0; j<4; j++){\n\n                double d;\n\n\n\n                if(j==2 && i%3 != 1)\n\n                    continue;\n\n\n\n                d= sin(M_PI * (i + 0.5) / 36.0);\n\n                if(j==1){\n\n                    if     (i>=30) d= 0;\n\n                    else if(i>=24) d= sin(M_PI * (i - 18 + 0.5) / 12.0);\n\n                    else if(i>=18) d= 1;\n\n                }else if(j==3){\n\n                    if     (i<  6) d= 0;\n\n                    else if(i< 12) d= sin(M_PI * (i -  6 + 0.5) / 12.0);\n\n                    else if(i< 18) d= 1;\n\n                }\n\n                //merge last stage of imdct into the window coefficients\n\n                d*= 0.5 / cos(M_PI*(2*i + 19)/72);\n\n\n\n                if(j==2)\n\n                    mdct_win[j][i/3] = FIXHR((d / (1<<5)));\n\n                else\n\n                    mdct_win[j][i  ] = FIXHR((d / (1<<5)));\n\n            }\n\n        }\n\n\n\n        /* NOTE: we do frequency inversion adter the MDCT by changing\n\n           the sign of the right window coefs */\n\n        for(j=0;j<4;j++) {\n\n            for(i=0;i<36;i+=2) {\n\n                mdct_win[j + 4][i] = mdct_win[j][i];\n\n                mdct_win[j + 4][i + 1] = -mdct_win[j][i + 1];\n\n            }\n\n        }\n\n\n\n        init = 1;\n\n    }\n\n\n\n    if (avctx->codec_id == CODEC_ID_MP3ADU)\n\n        s->adu_mode = 1;\n\n    return 0;\n\n}\n", "idx": 8482, "_split": "test", "_hash": "e89cb506d25dd176146e9eca488820c7"}
{"project": "FFmpeg", "commit_id": "480324e7ca0b87105fd7ee168292a0d5692af128", "target": 0, "func": "static int libgsm_decode_frame(AVCodecContext *avctx,\n\n                               void *data, int *data_size,\n\n                               AVPacket *avpkt) {\n\n    uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    int out_size = avctx->frame_size * av_get_bytes_per_sample(avctx->sample_fmt);\n\n\n\n    if (*data_size < out_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Output buffer is too small\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (buf_size < avctx->block_align) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Packet is too small\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch(avctx->codec_id) {\n\n    case CODEC_ID_GSM:\n\n        if(gsm_decode(avctx->priv_data,buf,data)) return -1;\n\n        break;\n\n    case CODEC_ID_GSM_MS:\n\n        if(gsm_decode(avctx->priv_data,buf,data) ||\n\n           gsm_decode(avctx->priv_data,buf+33,((int16_t*)data)+GSM_FRAME_SIZE)) return -1;\n\n    }\n\n\n\n    *data_size = out_size;\n\n    return avctx->block_align;\n\n}\n", "idx": 8487, "_split": "test", "_hash": "d23986b0c3bf5485c4d3bae90e13eb07"}
{"project": "FFmpeg", "commit_id": "fa2a34cd40d124161c748bb0f430dc63c94dd0da", "target": 0, "func": "static void exit_program(void)\n\n{\n\n    int i, j;\n\n\n\n    for (i = 0; i < nb_filtergraphs; i++) {\n\n        avfilter_graph_free(&filtergraphs[i]->graph);\n\n        for (j = 0; j < filtergraphs[i]->nb_inputs; j++) {\n\n            av_freep(&filtergraphs[i]->inputs[j]->name);\n\n            av_freep(&filtergraphs[i]->inputs[j]);\n\n        }\n\n        av_freep(&filtergraphs[i]->inputs);\n\n        for (j = 0; j < filtergraphs[i]->nb_outputs; j++) {\n\n            av_freep(&filtergraphs[i]->outputs[j]->name);\n\n            av_freep(&filtergraphs[i]->outputs[j]);\n\n        }\n\n        av_freep(&filtergraphs[i]->outputs);\n\n        av_freep(&filtergraphs[i]->graph_desc);\n\n        av_freep(&filtergraphs[i]);\n\n    }\n\n    av_freep(&filtergraphs);\n\n\n\n    /* close files */\n\n    for (i = 0; i < nb_output_files; i++) {\n\n        AVFormatContext *s = output_files[i]->ctx;\n\n        if (!(s->oformat->flags & AVFMT_NOFILE) && s->pb)\n\n            avio_close(s->pb);\n\n        avformat_free_context(s);\n\n        av_dict_free(&output_files[i]->opts);\n\n        av_freep(&output_files[i]);\n\n    }\n\n    for (i = 0; i < nb_output_streams; i++) {\n\n        AVBitStreamFilterContext *bsfc = output_streams[i]->bitstream_filters;\n\n        while (bsfc) {\n\n            AVBitStreamFilterContext *next = bsfc->next;\n\n            av_bitstream_filter_close(bsfc);\n\n            bsfc = next;\n\n        }\n\n        output_streams[i]->bitstream_filters = NULL;\n\n        avcodec_free_frame(&output_streams[i]->filtered_frame);\n\n\n\n        av_freep(&output_streams[i]->forced_keyframes);\n\n        av_freep(&output_streams[i]->avfilter);\n\n        av_freep(&output_streams[i]->logfile_prefix);\n\n        av_freep(&output_streams[i]);\n\n    }\n\n    for (i = 0; i < nb_input_files; i++) {\n\n        avformat_close_input(&input_files[i]->ctx);\n\n        av_freep(&input_files[i]);\n\n    }\n\n    for (i = 0; i < nb_input_streams; i++) {\n\n        av_frame_free(&input_streams[i]->decoded_frame);\n\n        av_frame_free(&input_streams[i]->filter_frame);\n\n        av_dict_free(&input_streams[i]->opts);\n\n        av_freep(&input_streams[i]->filters);\n\n        av_freep(&input_streams[i]);\n\n    }\n\n\n\n    if (vstats_file)\n\n        fclose(vstats_file);\n\n    av_free(vstats_filename);\n\n\n\n    av_freep(&input_streams);\n\n    av_freep(&input_files);\n\n    av_freep(&output_streams);\n\n    av_freep(&output_files);\n\n\n\n    uninit_opts();\n\n\n\n    avfilter_uninit();\n\n    avformat_network_deinit();\n\n\n\n    if (received_sigterm) {\n\n        av_log(NULL, AV_LOG_INFO, \"Received signal %d: terminating.\\n\",\n\n               (int) received_sigterm);\n\n        exit (255);\n\n    }\n\n}\n", "idx": 8534, "_split": "test", "_hash": "ea05cd3c1cd817231b3a0b14727884a2"}
{"project": "FFmpeg", "commit_id": "7fffc879798bbbad647ad2b1b30f26855bf2abda", "target": 0, "func": "static int wc3_read_header(AVFormatContext *s,\n\n                           AVFormatParameters *ap)\n\n{\n\n    Wc3DemuxContext *wc3 = s->priv_data;\n\n    ByteIOContext *pb = s->pb;\n\n    unsigned int fourcc_tag;\n\n    unsigned int size;\n\n    AVStream *st;\n\n    unsigned char preamble[WC3_PREAMBLE_SIZE];\n\n    int ret = 0;\n\n    int current_palette = 0;\n\n    int bytes_to_read;\n\n    int i;\n\n    unsigned char rotate;\n\n\n\n    /* default context members */\n\n    wc3->width = WC3_DEFAULT_WIDTH;\n\n    wc3->height = WC3_DEFAULT_HEIGHT;\n\n    wc3->palettes = NULL;\n\n    wc3->palette_count = 0;\n\n    wc3->pts = 0;\n\n    wc3->video_stream_index = wc3->audio_stream_index = 0;\n\n\n\n    /* skip the first 3 32-bit numbers */\n\n    url_fseek(pb, 12, SEEK_CUR);\n\n\n\n    /* traverse through the chunks and load the header information before\n\n     * the first BRCH tag */\n\n    if ((ret = get_buffer(pb, preamble, WC3_PREAMBLE_SIZE)) !=\n\n        WC3_PREAMBLE_SIZE)\n\n        return AVERROR(EIO);\n\n    fourcc_tag = AV_RL32(&preamble[0]);\n\n    size = (AV_RB32(&preamble[4]) + 1) & (~1);\n\n\n\n    do {\n\n        switch (fourcc_tag) {\n\n\n\n        case SOND_TAG:\n\n        case INDX_TAG:\n\n            /* SOND unknown, INDX unnecessary; ignore both */\n\n            url_fseek(pb, size, SEEK_CUR);\n\n            break;\n\n\n\n        case _PC__TAG:\n\n            /* need the number of palettes */\n\n            url_fseek(pb, 8, SEEK_CUR);\n\n            if ((ret = get_buffer(pb, preamble, 4)) != 4)\n\n                return AVERROR(EIO);\n\n            wc3->palette_count = AV_RL32(&preamble[0]);\n\n            if((unsigned)wc3->palette_count >= UINT_MAX / PALETTE_SIZE){\n\n                wc3->palette_count= 0;\n\n                return -1;\n\n            }\n\n            wc3->palettes = av_malloc(wc3->palette_count * PALETTE_SIZE);\n\n            break;\n\n\n\n        case BNAM_TAG:\n\n            /* load up the name */\n\n            if ((unsigned)size < 512)\n\n                bytes_to_read = size;\n\n            else\n\n                bytes_to_read = 512;\n\n            if ((ret = get_buffer(pb, s->title, bytes_to_read)) != bytes_to_read)\n\n                return AVERROR(EIO);\n\n            break;\n\n\n\n        case SIZE_TAG:\n\n            /* video resolution override */\n\n            if ((ret = get_buffer(pb, preamble, WC3_PREAMBLE_SIZE)) !=\n\n                WC3_PREAMBLE_SIZE)\n\n                return AVERROR(EIO);\n\n            wc3->width = AV_RL32(&preamble[0]);\n\n            wc3->height = AV_RL32(&preamble[4]);\n\n            break;\n\n\n\n        case PALT_TAG:\n\n            /* one of several palettes */\n\n            if ((unsigned)current_palette >= wc3->palette_count)\n\n                return AVERROR_INVALIDDATA;\n\n            if ((ret = get_buffer(pb,\n\n                &wc3->palettes[current_palette * PALETTE_SIZE],\n\n                PALETTE_SIZE)) != PALETTE_SIZE)\n\n                return AVERROR(EIO);\n\n\n\n            /* transform the current palette in place */\n\n            for (i = current_palette * PALETTE_SIZE;\n\n                 i < (current_palette + 1) * PALETTE_SIZE; i++) {\n\n                /* rotate each palette component left by 2 and use the result\n\n                 * as an index into the color component table */\n\n                rotate = ((wc3->palettes[i] << 2) & 0xFF) |\n\n                         ((wc3->palettes[i] >> 6) & 0xFF);\n\n                wc3->palettes[i] = wc3_pal_lookup[rotate];\n\n            }\n\n            current_palette++;\n\n            break;\n\n\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"  unrecognized WC3 chunk: %c%c%c%c (0x%02X%02X%02X%02X)\\n\",\n\n                preamble[0], preamble[1], preamble[2], preamble[3],\n\n                preamble[0], preamble[1], preamble[2], preamble[3]);\n\n            return AVERROR_INVALIDDATA;\n\n            break;\n\n        }\n\n\n\n        if ((ret = get_buffer(pb, preamble, WC3_PREAMBLE_SIZE)) !=\n\n            WC3_PREAMBLE_SIZE)\n\n            return AVERROR(EIO);\n\n        fourcc_tag = AV_RL32(&preamble[0]);\n\n        /* chunk sizes are 16-bit aligned */\n\n        size = (AV_RB32(&preamble[4]) + 1) & (~1);\n\n\n\n    } while (fourcc_tag != BRCH_TAG);\n\n\n\n    /* initialize the decoder streams */\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    av_set_pts_info(st, 33, 1, 90000);\n\n    wc3->video_stream_index = st->index;\n\n    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n    st->codec->codec_id = CODEC_ID_XAN_WC3;\n\n    st->codec->codec_tag = 0;  /* no fourcc */\n\n    st->codec->width = wc3->width;\n\n    st->codec->height = wc3->height;\n\n\n\n    /* palette considerations */\n\n    st->codec->palctrl = &wc3->palette_control;\n\n\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    av_set_pts_info(st, 33, 1, 90000);\n\n    wc3->audio_stream_index = st->index;\n\n    st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n    st->codec->codec_id = CODEC_ID_PCM_S16LE;\n\n    st->codec->codec_tag = 1;\n\n    st->codec->channels = WC3_AUDIO_CHANNELS;\n\n    st->codec->bits_per_sample = WC3_AUDIO_BITS;\n\n    st->codec->sample_rate = WC3_SAMPLE_RATE;\n\n    st->codec->bit_rate = st->codec->channels * st->codec->sample_rate *\n\n        st->codec->bits_per_sample;\n\n    st->codec->block_align = WC3_AUDIO_BITS * WC3_AUDIO_CHANNELS;\n\n\n\n    return 0;\n\n}\n", "idx": 8617, "_split": "test", "_hash": "310461cec8a4c38fb6cbaf73377f4db8"}
{"project": "FFmpeg", "commit_id": "a04c2c707de2ce850f79870e84ac9d7ec7aa9143", "target": 1, "func": "static int default_lockmgr_cb(void **arg, enum AVLockOp op)\n\n{\n\n    void * volatile * mutex = arg;\n\n    int err;\n\n\n\n    switch (op) {\n\n    case AV_LOCK_CREATE:\n\n        return 0;\n\n    case AV_LOCK_OBTAIN:\n\n        if (!*mutex) {\n\n            pthread_mutex_t *tmp = av_malloc(sizeof(pthread_mutex_t));\n\n            if (!tmp)\n\n                return AVERROR(ENOMEM);\n\n            if ((err = pthread_mutex_init(tmp, NULL))) {\n\n                av_free(tmp);\n\n                return AVERROR(err);\n\n            }\n\n            if (avpriv_atomic_ptr_cas(mutex, NULL, tmp)) {\n\n                pthread_mutex_destroy(tmp);\n\n                av_free(tmp);\n\n            }\n\n        }\n\n\n\n        if ((err = pthread_mutex_lock(*mutex)))\n\n            return AVERROR(err);\n\n\n\n        return 0;\n\n    case AV_LOCK_RELEASE:\n\n        if ((err = pthread_mutex_unlock(*mutex)))\n\n            return AVERROR(err);\n\n\n\n        return 0;\n\n    case AV_LOCK_DESTROY:\n\n        if (*mutex)\n\n            pthread_mutex_destroy(*mutex);\n\n        av_free(*mutex);\n\n        avpriv_atomic_ptr_cas(mutex, *mutex, NULL);\n\n        return 0;\n\n    }\n\n    return 1;\n\n}\n", "idx": 8794, "_split": "test", "_hash": "2c8189b9d78c0aa8d99c537af22ada57"}
{"project": "FFmpeg", "commit_id": "aacc6615f8e3863cd930d3a1ab2cd28d9838f0f5", "target": 1, "func": "static inline int check_input_motion(MpegEncContext * s, int mb_x, int mb_y, int p_type){\n\n    MotionEstContext * const c= &s->me;\n\n    Picture *p= s->current_picture_ptr;\n\n    int mb_xy= mb_x + mb_y*s->mb_stride;\n\n    int xy= 2*mb_x + 2*mb_y*s->b8_stride;\n\n    int mb_type= s->current_picture.mb_type[mb_xy];\n\n    int flags= c->flags;\n\n    int shift= (flags&FLAG_QPEL) + 1;\n\n    int mask= (1<<shift)-1;\n\n    int x, y, i;\n\n    int d=0;\n\n    me_cmp_func cmpf= s->dsp.sse[0];\n\n    me_cmp_func chroma_cmpf= s->dsp.sse[1];\n\n    \n\n    assert(p_type==0 || !USES_LIST(mb_type, 1));\n\n    assert(IS_INTRA(mb_type) || USES_LIST(mb_type,0) || USES_LIST(mb_type,1));\n\n    \n\n    if(IS_INTERLACED(mb_type)){\n\n        int xy2= xy  + s->b8_stride;\n\n        s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_INTRA;\n\n        c->stride<<=1;\n\n        c->uvstride<<=1;\n\n        init_interlaced_ref(s, 2);\n\n        \n\n        assert(s->flags & CODEC_FLAG_INTERLACED_ME);\n\n\n\n        if(USES_LIST(mb_type, 0)){\n\n            int field_select0= p->ref_index[0][xy ];\n\n            int field_select1= p->ref_index[0][xy2];\n\n            assert(field_select0==0 ||field_select0==1);\n\n            assert(field_select1==0 ||field_select1==1);\n\n            if(p_type){\n\n                s->p_field_select_table[0][mb_xy]= field_select0;\n\n                s->p_field_select_table[1][mb_xy]= field_select1;\n\n                *(uint32_t*)s->p_field_mv_table[0][field_select0][mb_xy]= *(uint32_t*)p->motion_val[0][xy ];\n\n                *(uint32_t*)s->p_field_mv_table[1][field_select1][mb_xy]= *(uint32_t*)p->motion_val[0][xy2];\n\n                s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_INTER_I;\n\n            }else{\n\n                s->b_field_select_table[0][0][mb_xy]= field_select0;\n\n                s->b_field_select_table[0][1][mb_xy]= field_select1;\n\n                *(uint32_t*)s->b_field_mv_table[0][0][field_select0][mb_xy]= *(uint32_t*)p->motion_val[0][xy ];\n\n                *(uint32_t*)s->b_field_mv_table[0][1][field_select1][mb_xy]= *(uint32_t*)p->motion_val[0][xy2];\n\n                s->mb_type[mb_xy]= CANDIDATE_MB_TYPE_FORWARD_I;\n\n            }\n\n\n\n            x= p->motion_val[0][xy ][0]; \n\n            y= p->motion_val[0][xy ][1];\n\n            d = cmp(s, x>>shift, y>>shift, x&mask, y&mask, 0, 8, field_select0, 0, cmpf, chroma_cmpf, flags);\n\n            x= p->motion_val[0][xy2][0]; \n\n            y= p->motion_val[0][xy2][1];\n\n            d+= cmp(s, x>>shift, y>>shift, x&mask, y&mask, 0, 8, field_select1, 1, cmpf, chroma_cmpf, flags);\n\n        }\n\n        if(USES_LIST(mb_type, 1)){\n\n            int field_select0= p->ref_index[1][xy ];\n\n            int field_select1= p->ref_index[1][xy2];\n\n            assert(field_select0==0 ||field_select0==1);\n\n            assert(field_select1==0 ||field_select1==1);\n\n            s->b_field_select_table[1][0][mb_xy]= field_select0;\n\n            s->b_field_select_table[1][1][mb_xy]= field_select1;\n\n            *(uint32_t*)s->b_field_mv_table[1][0][field_select0][mb_xy]= *(uint32_t*)p->motion_val[1][xy ];\n\n            *(uint32_t*)s->b_field_mv_table[1][1][field_select1][mb_xy]= *(uint32_t*)p->motion_val[1][xy2];\n\n            if(USES_LIST(mb_type, 0)){\n\n                s->mb_type[mb_xy]= CANDIDATE_MB_TYPE_BIDIR_I;\n\n            }else{\n\n                s->mb_type[mb_xy]= CANDIDATE_MB_TYPE_BACKWARD_I;\n\n            }\n\n\n\n            x= p->motion_val[1][xy ][0]; \n\n            y= p->motion_val[1][xy ][1];\n\n            d = cmp(s, x>>shift, y>>shift, x&mask, y&mask, 0, 8, field_select0+2, 0, cmpf, chroma_cmpf, flags);\n\n            x= p->motion_val[1][xy2][0]; \n\n            y= p->motion_val[1][xy2][1];\n\n            d+= cmp(s, x>>shift, y>>shift, x&mask, y&mask, 0, 8, field_select1+2, 1, cmpf, chroma_cmpf, flags);\n\n            //FIXME bidir scores\n\n        }\n\n        c->stride>>=1;\n\n        c->uvstride>>=1;\n\n    }else if(IS_8X8(mb_type)){\n\n\n        cmpf= s->dsp.sse[1];\n\n        chroma_cmpf= s->dsp.sse[1];\n\n        init_mv4_ref(s);\n\n        for(i=0; i<4; i++){\n\n            xy= s->block_index[i];\n\n            x= p->motion_val[0][xy][0]; \n\n            y= p->motion_val[0][xy][1];\n\n            d+= cmp(s, x>>shift, y>>shift, x&mask, y&mask, 1, 8, i, i, cmpf, chroma_cmpf, flags);\n\n        }\n\n        s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_INTER4V;\n\n    }else{\n\n        if(USES_LIST(mb_type, 0)){\n\n            if(p_type){\n\n                *(uint32_t*)s->p_mv_table[mb_xy]= *(uint32_t*)p->motion_val[0][xy];\n\n                s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_INTER;\n\n            }else if(USES_LIST(mb_type, 1)){\n\n                *(uint32_t*)s->b_bidir_forw_mv_table[mb_xy]= *(uint32_t*)p->motion_val[0][xy];\n\n                *(uint32_t*)s->b_bidir_back_mv_table[mb_xy]= *(uint32_t*)p->motion_val[1][xy];\n\n                s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_BIDIR;\n\n            }else{\n\n                *(uint32_t*)s->b_forw_mv_table[mb_xy]= *(uint32_t*)p->motion_val[0][xy];\n\n                s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_FORWARD;\n\n            }\n\n            x= p->motion_val[0][xy][0]; \n\n            y= p->motion_val[0][xy][1];\n\n            d = cmp(s, x>>shift, y>>shift, x&mask, y&mask, 0, 16, 0, 0, cmpf, chroma_cmpf, flags);\n\n        }else if(USES_LIST(mb_type, 1)){\n\n            *(uint32_t*)s->b_back_mv_table[mb_xy]= *(uint32_t*)p->motion_val[1][xy];\n\n            s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_BACKWARD;\n\n           \n\n            x= p->motion_val[1][xy][0]; \n\n            y= p->motion_val[1][xy][1];\n\n            d = cmp(s, x>>shift, y>>shift, x&mask, y&mask, 0, 16, 2, 0, cmpf, chroma_cmpf, flags);\n\n        }else\n\n            s->mb_type[mb_xy]=CANDIDATE_MB_TYPE_INTRA;\n\n    }\n\n    return d;\n\n}", "idx": 8815, "_split": "test", "_hash": "a523e25bef4f1c8ba3ab965fa5579879"}
{"project": "FFmpeg", "commit_id": "0d21a84605bad4e75dacb8196e5859902ed36f01", "target": 0, "func": "void ff_estimate_p_frame_motion(MpegEncContext * s,\n\n                                int mb_x, int mb_y)\n\n{\n\n    UINT8 *pix, *ppix;\n\n    int sum, varc, vard, mx, my, range, dmin, xx, yy;\n\n    int xmin, ymin, xmax, ymax;\n\n    int rel_xmin, rel_ymin, rel_xmax, rel_ymax;\n\n    int pred_x=0, pred_y=0;\n\n    int P[6][2];\n\n    const int shift= 1+s->quarter_sample;\n\n    int mb_type=0;\n\n    uint8_t *ref_picture= s->last_picture[0];\n\n\n\n    get_limits(s, &range, &xmin, &ymin, &xmax, &ymax, s->f_code);\n\n\n\n    switch(s->me_method) {\n\n    case ME_ZERO:\n\n    default:\n\n\tno_motion_search(s, &mx, &my);\n\n        dmin = 0;\n\n        break;\n\n    case ME_FULL:\n\n\tdmin = full_motion_search(s, &mx, &my, range, xmin, ymin, xmax, ymax, ref_picture);\n\n        break;\n\n    case ME_LOG:\n\n\tdmin = log_motion_search(s, &mx, &my, range / 2, xmin, ymin, xmax, ymax, ref_picture);\n\n        break;\n\n    case ME_PHODS:\n\n\tdmin = phods_motion_search(s, &mx, &my, range / 2, xmin, ymin, xmax, ymax, ref_picture);\n\n        break;\n\n    case ME_X1:\n\n    case ME_EPZS:\n\n       {\n\n            const int mot_stride = s->block_wrap[0];\n\n            const int mot_xy = s->block_index[0];\n\n\n\n            rel_xmin= xmin - mb_x*16;\n\n            rel_xmax= xmax - mb_x*16;\n\n            rel_ymin= ymin - mb_y*16;\n\n            rel_ymax= ymax - mb_y*16;\n\n\n\n            P[0][0] = s->motion_val[mot_xy    ][0];\n\n            P[0][1] = s->motion_val[mot_xy    ][1];\n\n            P[1][0] = s->motion_val[mot_xy - 1][0];\n\n            P[1][1] = s->motion_val[mot_xy - 1][1];\n\n            if(P[1][0] > (rel_xmax<<shift)) P[1][0]= (rel_xmax<<shift);\n\n\n\n            /* special case for first line */\n\n            if ((mb_y == 0 || s->first_slice_line || s->first_gob_line)) {\n\n                P[4][0] = P[1][0];\n\n                P[4][1] = P[1][1];\n\n            } else {\n\n                P[2][0] = s->motion_val[mot_xy - mot_stride             ][0];\n\n                P[2][1] = s->motion_val[mot_xy - mot_stride             ][1];\n\n                P[3][0] = s->motion_val[mot_xy - mot_stride + 2         ][0];\n\n                P[3][1] = s->motion_val[mot_xy - mot_stride + 2         ][1];\n\n                if(P[2][1] > (rel_ymax<<shift)) P[2][1]= (rel_ymax<<shift);\n\n                if(P[3][0] < (rel_xmin<<shift)) P[3][0]= (rel_xmin<<shift);\n\n                if(P[3][1] > (rel_ymax<<shift)) P[3][1]= (rel_ymax<<shift);\n\n        \n\n                P[4][0]= mid_pred(P[1][0], P[2][0], P[3][0]);\n\n                P[4][1]= mid_pred(P[1][1], P[2][1], P[3][1]);\n\n            }\n\n            if(s->out_format == FMT_H263){\n\n                pred_x = P[4][0];\n\n                pred_y = P[4][1];\n\n            }else { /* mpeg1 at least */\n\n                pred_x= P[1][0];\n\n                pred_y= P[1][1];\n\n            }\n\n        }\n\n        dmin = epzs_motion_search(s, &mx, &my, P, pred_x, pred_y, rel_xmin, rel_ymin, rel_xmax, rel_ymax, ref_picture);\n\n \n\n        mx+= mb_x*16;\n\n        my+= mb_y*16;\n\n        break;\n\n    }\n\n    \n\n    if(s->flags&CODEC_FLAG_4MV){\n\n        int block;\n\n\n\n        mb_type|= MB_TYPE_INTER4V;\n\n\n\n        for(block=0; block<4; block++){\n\n            int mx4, my4;\n\n            int pred_x4, pred_y4;\n\n            int dmin4;\n\n            static const int off[4]= {2, 1, 1, -1};\n\n            const int mot_stride = s->block_wrap[0];\n\n            const int mot_xy = s->block_index[block];\n\n            const int block_x= mb_x*2 + (block&1);\n\n            const int block_y= mb_y*2 + (block>>1);\n\n\n\n            const int rel_xmin4= xmin - block_x*8;\n\n            const int rel_xmax4= xmax - block_x*8 + 8;\n\n            const int rel_ymin4= ymin - block_y*8;\n\n            const int rel_ymax4= ymax - block_y*8 + 8;\n\n\n\n            P[0][0] = s->motion_val[mot_xy    ][0];\n\n            P[0][1] = s->motion_val[mot_xy    ][1];\n\n            P[1][0] = s->motion_val[mot_xy - 1][0];\n\n            P[1][1] = s->motion_val[mot_xy - 1][1];\n\n            if(P[1][0] > (rel_xmax4<<shift)) P[1][0]= (rel_xmax4<<shift);\n\n\n\n            /* special case for first line */\n\n            if ((mb_y == 0 || s->first_slice_line || s->first_gob_line) && block<2) {\n\n                P[4][0] = P[1][0];\n\n                P[4][1] = P[1][1];\n\n            } else {\n\n                P[2][0] = s->motion_val[mot_xy - mot_stride             ][0];\n\n                P[2][1] = s->motion_val[mot_xy - mot_stride             ][1];\n\n                P[3][0] = s->motion_val[mot_xy - mot_stride + off[block]][0];\n\n                P[3][1] = s->motion_val[mot_xy - mot_stride + off[block]][1];\n\n                if(P[2][1] > (rel_ymax4<<shift)) P[2][1]= (rel_ymax4<<shift);\n\n                if(P[3][0] < (rel_xmin4<<shift)) P[3][0]= (rel_xmin4<<shift);\n\n                if(P[3][0] > (rel_xmax4<<shift)) P[3][0]= (rel_xmax4<<shift);\n\n                if(P[3][1] > (rel_ymax4<<shift)) P[3][1]= (rel_ymax4<<shift);\n\n        \n\n                P[4][0]= mid_pred(P[1][0], P[2][0], P[3][0]);\n\n                P[4][1]= mid_pred(P[1][1], P[2][1], P[3][1]);\n\n            }\n\n            if(s->out_format == FMT_H263){\n\n                pred_x4 = P[4][0];\n\n                pred_y4 = P[4][1];\n\n            }else { /* mpeg1 at least */\n\n                pred_x4= P[1][0];\n\n                pred_y4= P[1][1];\n\n            }\n\n            P[5][0]= mx - mb_x*16;\n\n            P[5][1]= my - mb_y*16;\n\n\n\n            dmin4 = epzs_motion_search4(s, block, &mx4, &my4, P, pred_x4, pred_y4, rel_xmin4, rel_ymin4, rel_xmax4, rel_ymax4, ref_picture);\n\n\n\n            halfpel_motion_search4(s, &mx4, &my4, dmin4, rel_xmin4, rel_ymin4, rel_xmax4, rel_ymax4, \n\n                                   pred_x4, pred_y4, block_x, block_y, ref_picture);\n\n     \n\n            s->motion_val[ s->block_index[block] ][0]= mx4;\n\n            s->motion_val[ s->block_index[block] ][1]= my4;\n\n        }\n\n    }\n\n\n\n    /* intra / predictive decision */\n\n    xx = mb_x * 16;\n\n    yy = mb_y * 16;\n\n\n\n    pix = s->new_picture[0] + (yy * s->linesize) + xx;\n\n    /* At this point (mx,my) are full-pell and the absolute displacement */\n\n    ppix = ref_picture + (my * s->linesize) + mx;\n\n    \n\n    sum = pix_sum(pix, s->linesize);\n\n#if 0\n\n    varc = pix_dev(pix, s->linesize, (sum+128)>>8) + INTER_BIAS;\n\n    vard = pix_abs16x16(pix, ppix, s->linesize);\n\n#else\n\n    sum= (sum+8)>>4;\n\n    varc = ((pix_norm1(pix, s->linesize) - sum*sum + 128 + 500)>>8);\n\n    vard = (pix_norm(pix, ppix, s->linesize)+128)>>8;\n\n#endif\n\n\n\n    s->mb_var[s->mb_width * mb_y + mb_x] = varc;\n\n    s->avg_mb_var+= varc;\n\n    s->mc_mb_var += vard;\n\n\n\n    \n\n#if 0\n\n    printf(\"varc=%4d avg_var=%4d (sum=%4d) vard=%4d mx=%2d my=%2d\\n\",\n\n\t   varc, s->avg_mb_var, sum, vard, mx - xx, my - yy);\n\n#endif\n\n    if(s->flags&CODEC_FLAG_HQ){\n\n        if (vard*2 + 200 > varc)\n\n            mb_type|= MB_TYPE_INTRA;\n\n        if (varc*2 + 200 > vard){\n\n            mb_type|= MB_TYPE_INTER;\n\n            halfpel_motion_search(s, &mx, &my, dmin, xmin, ymin, xmax, ymax, pred_x, pred_y, ref_picture);\n\n        }else{\n\n            mx = mx*2 - mb_x*32;\n\n            my = my*2 - mb_y*32;\n\n        }\n\n    }else{\n\n        if (vard <= 64 || vard < varc) {\n\n            mb_type|= MB_TYPE_INTER;\n\n            if (s->me_method != ME_ZERO) {\n\n                halfpel_motion_search(s, &mx, &my, dmin, xmin, ymin, xmax, ymax, pred_x, pred_y, ref_picture);\n\n            } else {\n\n                mx -= 16 * mb_x;\n\n                my -= 16 * mb_y;\n\n            }\n\n#if 0\n\n            if (vard < 10) {\n\n                skip++;\n\n                fprintf(stderr,\"\\nEarly skip: %d vard: %2d varc: %5d dmin: %d\", \n\n                                skip, vard, varc, dmin);\n\n            }\n\n#endif\n\n        }else{\n\n            mb_type|= MB_TYPE_INTRA;\n\n            mx = 0;//mx*2 - 32 * mb_x;\n\n            my = 0;//my*2 - 32 * mb_y;\n\n        }\n\n    }\n\n\n\n    s->mb_type[mb_y*s->mb_width + mb_x]= mb_type;\n\n    set_p_mv_tables(s, mx, my);\n\n}\n", "idx": 8825, "_split": "test", "_hash": "1d2a84cbe536bc83ffb3fd2bd85adf78"}
{"project": "FFmpeg", "commit_id": "c8241e730f116f1c9cfc0b34110aa7f052e05332", "target": 0, "func": "av_cold int ff_vaapi_encode_close(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext *ctx = avctx->priv_data;\n\n    VAAPIEncodePicture *pic, *next;\n\n\n\n    for (pic = ctx->pic_start; pic; pic = next) {\n\n        next = pic->next;\n\n        vaapi_encode_free(avctx, pic);\n\n    }\n\n\n\n    if (ctx->va_context != VA_INVALID_ID) {\n\n        vaDestroyContext(ctx->hwctx->display, ctx->va_context);\n\n        ctx->va_context = VA_INVALID_ID;\n\n    }\n\n\n\n    if (ctx->va_config != VA_INVALID_ID) {\n\n        vaDestroyConfig(ctx->hwctx->display, ctx->va_config);\n\n        ctx->va_config = VA_INVALID_ID;\n\n    }\n\n\n\n    if (ctx->codec->close)\n\n        ctx->codec->close(avctx);\n\n\n\n    av_buffer_pool_uninit(&ctx->output_buffer_pool);\n\n\n\n    av_freep(&ctx->codec_sequence_params);\n\n    av_freep(&ctx->codec_picture_params);\n\n\n\n    av_buffer_unref(&ctx->recon_frames_ref);\n\n    av_buffer_unref(&ctx->input_frames_ref);\n\n    av_buffer_unref(&ctx->device_ref);\n\n\n\n    av_freep(&ctx->priv_data);\n\n\n\n    return 0;\n\n}\n", "idx": 8835, "_split": "test", "_hash": "6272993378a77928ce95bb053d657148"}
{"project": "FFmpeg", "commit_id": "d7eabd50425a61b31e90c763a0c3e4316a725404", "target": 0, "func": "static int mpc7_decode_frame(AVCodecContext * avctx, void *data,\n\n                             int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size;\n\n    MPCContext *c = avctx->priv_data;\n\n    GetBitContext gb;\n\n    int i, ch;\n\n    int mb = -1;\n\n    Band *bands = c->bands;\n\n    int off, ret, last_frame, skip;\n\n    int bits_used, bits_avail;\n\n\n\n    memset(bands, 0, sizeof(*bands) * (c->maxbands + 1));\n\n\n\n    buf_size = avpkt->size & ~3;\n\n    if (buf_size <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"packet size is too small (%i bytes)\\n\",\n\n               avpkt->size);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (buf_size != avpkt->size) {\n\n        av_log(avctx, AV_LOG_WARNING, \"packet size is not a multiple of 4. \"\n\n               \"extra bytes at the end will be skipped.\\n\");\n\n    }\n\n\n\n    skip       = buf[0];\n\n    last_frame = buf[1];\n\n    buf       += 4;\n\n    buf_size  -= 4;\n\n\n\n    /* get output buffer */\n\n    c->frame.nb_samples = last_frame ? c->lastframelen : MPC_FRAME_SIZE;\n\n    if ((ret = avctx->get_buffer(avctx, &c->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    av_fast_padded_malloc(&c->bits, &c->buf_size, buf_size);\n\n    if (!c->bits)\n\n        return AVERROR(ENOMEM);\n\n    c->dsp.bswap_buf((uint32_t *)c->bits, (const uint32_t *)buf, buf_size >> 2);\n\n    init_get_bits(&gb, c->bits, buf_size * 8);\n\n    skip_bits_long(&gb, skip);\n\n\n\n    /* read subband indexes */\n\n    for(i = 0; i <= c->maxbands; i++){\n\n        for(ch = 0; ch < 2; ch++){\n\n            int t = 4;\n\n            if(i) t = get_vlc2(&gb, hdr_vlc.table, MPC7_HDR_BITS, 1) - 5;\n\n            if(t == 4) bands[i].res[ch] = get_bits(&gb, 4);\n\n            else bands[i].res[ch] = bands[i-1].res[ch] + t;\n\n        }\n\n\n\n        if(bands[i].res[0] || bands[i].res[1]){\n\n            mb = i;\n\n            if(c->MSS) bands[i].msf = get_bits1(&gb);\n\n        }\n\n    }\n\n    /* get scale indexes coding method */\n\n    for(i = 0; i <= mb; i++)\n\n        for(ch = 0; ch < 2; ch++)\n\n            if(bands[i].res[ch]) bands[i].scfi[ch] = get_vlc2(&gb, scfi_vlc.table, MPC7_SCFI_BITS, 1);\n\n    /* get scale indexes */\n\n    for(i = 0; i <= mb; i++){\n\n        for(ch = 0; ch < 2; ch++){\n\n            if(bands[i].res[ch]){\n\n                bands[i].scf_idx[ch][2] = c->oldDSCF[ch][i];\n\n                bands[i].scf_idx[ch][0] = get_scale_idx(&gb, bands[i].scf_idx[ch][2]);\n\n                switch(bands[i].scfi[ch]){\n\n                case 0:\n\n                    bands[i].scf_idx[ch][1] = get_scale_idx(&gb, bands[i].scf_idx[ch][0]);\n\n                    bands[i].scf_idx[ch][2] = get_scale_idx(&gb, bands[i].scf_idx[ch][1]);\n\n                    break;\n\n                case 1:\n\n                    bands[i].scf_idx[ch][1] = get_scale_idx(&gb, bands[i].scf_idx[ch][0]);\n\n                    bands[i].scf_idx[ch][2] = bands[i].scf_idx[ch][1];\n\n                    break;\n\n                case 2:\n\n                    bands[i].scf_idx[ch][1] = bands[i].scf_idx[ch][0];\n\n                    bands[i].scf_idx[ch][2] = get_scale_idx(&gb, bands[i].scf_idx[ch][1]);\n\n                    break;\n\n                case 3:\n\n                    bands[i].scf_idx[ch][2] = bands[i].scf_idx[ch][1] = bands[i].scf_idx[ch][0];\n\n                    break;\n\n                }\n\n                c->oldDSCF[ch][i] = bands[i].scf_idx[ch][2];\n\n            }\n\n        }\n\n    }\n\n    /* get quantizers */\n\n    memset(c->Q, 0, sizeof(c->Q));\n\n    off = 0;\n\n    for(i = 0; i < BANDS; i++, off += SAMPLES_PER_BAND)\n\n        for(ch = 0; ch < 2; ch++)\n\n            idx_to_quant(c, &gb, bands[i].res[ch], c->Q[ch] + off);\n\n\n\n    ff_mpc_dequantize_and_synth(c, mb, c->frame.data[0], 2);\n\n\n\n    bits_used = get_bits_count(&gb);\n\n    bits_avail = buf_size * 8;\n\n    if (!last_frame && ((bits_avail < bits_used) || (bits_used + 32 <= bits_avail))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error decoding frame: used %i of %i bits\\n\", bits_used, bits_avail);\n\n        return -1;\n\n    }\n\n    if(c->frames_to_skip){\n\n        c->frames_to_skip--;\n\n        *got_frame_ptr = 0;\n\n        return avpkt->size;\n\n    }\n\n\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = c->frame;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 8878, "_split": "test", "_hash": "3adcffee05598d07385d6b82ecfb95d5"}
{"project": "FFmpeg", "commit_id": "35cb6854bb76b4a5b6f2aea2dce81e18d7ab61cd", "target": 1, "func": "static int rle_unpack(const unsigned char *src, int src_len, int src_count,\n\n                      unsigned char *dest, int dest_len)\n\n{\n\n    const unsigned char *ps;\n\n    const unsigned char *ps_end;\n\n    unsigned char *pd;\n\n    int i, l;\n\n    unsigned char *dest_end = dest + dest_len;\n\n\n\n    ps = src;\n\n    ps_end = src + src_len;\n\n    pd = dest;\n\n    if (src_count & 1) {\n\n        if (ps_end - ps < 1)\n\n            return 0;\n\n        *pd++ = *ps++;\n\n    }\n\n\n\n    src_count >>= 1;\n\n    i = 0;\n\n    do {\n\n        if (ps_end - ps < 1)\n\n            break;\n\n        l = *ps++;\n\n        if (l & 0x80) {\n\n            l = (l & 0x7F) * 2;\n\n            if (pd + l > dest_end || ps_end - ps < l)\n\n                return ps - src;\n\n            memcpy(pd, ps, l);\n\n            ps += l;\n\n            pd += l;\n\n        } else {\n\n            if (pd + i > dest_end || ps_end - ps < 2)\n\n                return ps - src;\n\n            for (i = 0; i < l; i++) {\n\n                *pd++ = ps[0];\n\n                *pd++ = ps[1];\n\n            }\n\n            ps += 2;\n\n        }\n\n        i += l;\n\n    } while (i < src_count);\n\n\n\n    return ps - src;\n\n}\n", "idx": 8900, "_split": "test", "_hash": "134cd605998dab2927aa6e484251a1db"}
{"project": "FFmpeg", "commit_id": "4f00519d9508e07aac58a00a9b514dae8ad95723", "target": 1, "func": "int vc1_decode_sequence_header(AVCodecContext *avctx, VC1Context *v, GetBitContext *gb)\n\n{\n\n    av_log(avctx, AV_LOG_DEBUG, \"Header: %0X\\n\", show_bits(gb, 32));\n\n    v->profile = get_bits(gb, 2);\n\n    if (v->profile == PROFILE_COMPLEX)\n\n    {\n\n        av_log(avctx, AV_LOG_WARNING, \"WMV3 Complex Profile is not fully supported\\n\");\n\n    }\n\n\n\n    if (v->profile == PROFILE_ADVANCED)\n\n    {\n\n        v->zz_8x4 = ff_vc1_adv_progressive_8x4_zz;\n\n        v->zz_4x8 = ff_vc1_adv_progressive_4x8_zz;\n\n        return decode_sequence_header_adv(v, gb);\n\n    }\n\n    else\n\n    {\n\n        v->zz_8x4 = wmv2_scantableA;\n\n        v->zz_4x8 = wmv2_scantableB;\n\n        v->res_y411   = get_bits1(gb);\n\n        v->res_sprite = get_bits1(gb);\n\n        if (v->res_y411)\n\n        {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Old interlaced mode is not supported\\n\");\n\n            return -1;\n\n        }\n\n        if (v->res_sprite) {\n\n            av_log(avctx, AV_LOG_ERROR, \"WMVP is not fully supported\\n\");\n\n        }\n\n    }\n\n\n\n    // (fps-2)/4 (->30)\n\n    v->frmrtq_postproc = get_bits(gb, 3); //common\n\n    // (bitrate-32kbps)/64kbps\n\n    v->bitrtq_postproc = get_bits(gb, 5); //common\n\n    v->s.loop_filter = get_bits1(gb); //common\n\n    if(v->s.loop_filter == 1 && v->profile == PROFILE_SIMPLE)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"LOOPFILTER shall not be enabled in Simple Profile\\n\");\n\n    }\n\n    if(v->s.avctx->skip_loop_filter >= AVDISCARD_ALL)\n\n        v->s.loop_filter = 0;\n\n\n\n    v->res_x8 = get_bits1(gb); //reserved\n\n    v->multires = get_bits1(gb);\n\n    v->res_fasttx = get_bits1(gb);\n\n    if (!v->res_fasttx)\n\n    {\n\n        v->vc1dsp.vc1_inv_trans_8x8 = ff_simple_idct_8;\n\n        v->vc1dsp.vc1_inv_trans_8x4 = ff_simple_idct84_add;\n\n        v->vc1dsp.vc1_inv_trans_4x8 = ff_simple_idct48_add;\n\n        v->vc1dsp.vc1_inv_trans_4x4 = ff_simple_idct44_add;\n\n        v->vc1dsp.vc1_inv_trans_8x8_dc = ff_simple_idct_add_8;\n\n        v->vc1dsp.vc1_inv_trans_8x4_dc = ff_simple_idct84_add;\n\n        v->vc1dsp.vc1_inv_trans_4x8_dc = ff_simple_idct48_add;\n\n        v->vc1dsp.vc1_inv_trans_4x4_dc = ff_simple_idct44_add;\n\n    }\n\n\n\n    v->fastuvmc =  get_bits1(gb); //common\n\n    if (!v->profile && !v->fastuvmc)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"FASTUVMC unavailable in Simple Profile\\n\");\n\n        return -1;\n\n    }\n\n    v->extended_mv =  get_bits1(gb); //common\n\n    if (!v->profile && v->extended_mv)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Extended MVs unavailable in Simple Profile\\n\");\n\n        return -1;\n\n    }\n\n    v->dquant =  get_bits(gb, 2); //common\n\n    v->vstransform =  get_bits1(gb); //common\n\n\n\n    v->res_transtab = get_bits1(gb);\n\n    if (v->res_transtab)\n\n    {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"1 for reserved RES_TRANSTAB is forbidden\\n\");\n\n        return -1;\n\n    }\n\n\n\n    v->overlap = get_bits1(gb); //common\n\n\n\n    v->s.resync_marker = get_bits1(gb);\n\n    v->rangered = get_bits1(gb);\n\n    if (v->rangered && v->profile == PROFILE_SIMPLE)\n\n    {\n\n        av_log(avctx, AV_LOG_INFO,\n\n               \"RANGERED should be set to 0 in Simple Profile\\n\");\n\n    }\n\n\n\n    v->s.max_b_frames = avctx->max_b_frames = get_bits(gb, 3); //common\n\n    v->quantizer_mode = get_bits(gb, 2); //common\n\n\n\n    v->finterpflag = get_bits1(gb); //common\n\n\n\n    if (v->res_sprite) {\n\n        v->s.avctx->width  = v->s.avctx->coded_width  = get_bits(gb, 11);\n\n        v->s.avctx->height = v->s.avctx->coded_height = get_bits(gb, 11);\n\n        skip_bits(gb, 5); //frame rate\n\n        v->res_x8 = get_bits1(gb);\n\n        if (get_bits1(gb)) { // something to do with DC VLC selection\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported sprite feature\\n\");\n\n            return -1;\n\n        }\n\n        skip_bits(gb, 3); //slice code\n\n        v->res_rtm_flag = 0;\n\n    } else {\n\n        v->res_rtm_flag = get_bits1(gb); //reserved\n\n    }\n\n    if (!v->res_rtm_flag)\n\n    {\n\n//            av_log(avctx, AV_LOG_ERROR,\n\n//                   \"0 for reserved RES_RTM_FLAG is forbidden\\n\");\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Old WMV3 version detected, some frames may be decoded incorrectly\\n\");\n\n        //return -1;\n\n    }\n\n    //TODO: figure out what they mean (always 0x402F)\n\n    if(!v->res_fasttx) skip_bits(gb, 16);\n\n    av_log(avctx, AV_LOG_DEBUG,\n\n               \"Profile %i:\\nfrmrtq_postproc=%i, bitrtq_postproc=%i\\n\"\n\n               \"LoopFilter=%i, MultiRes=%i, FastUVMC=%i, Extended MV=%i\\n\"\n\n               \"Rangered=%i, VSTransform=%i, Overlap=%i, SyncMarker=%i\\n\"\n\n               \"DQuant=%i, Quantizer mode=%i, Max B frames=%i\\n\",\n\n               v->profile, v->frmrtq_postproc, v->bitrtq_postproc,\n\n               v->s.loop_filter, v->multires, v->fastuvmc, v->extended_mv,\n\n               v->rangered, v->vstransform, v->overlap, v->s.resync_marker,\n\n               v->dquant, v->quantizer_mode, avctx->max_b_frames\n\n               );\n\n    return 0;\n\n}\n", "idx": 8901, "_split": "test", "_hash": "1f3beb52e73c743859b249b4190e7c07"}
{"project": "FFmpeg", "commit_id": "73bb8f61d48dbf7237df2e9cacd037f12b84b00a", "target": 0, "func": "static void FUNC(hevc_h_loop_filter_luma)(uint8_t *pix, ptrdiff_t stride,\n\n                                          int *beta, int *tc, uint8_t *no_p,\n\n                                          uint8_t *no_q)\n\n{\n\n    FUNC(hevc_loop_filter_luma)(pix, stride, sizeof(pixel),\n\n                                beta, tc, no_p, no_q);\n\n}\n", "idx": 8963, "_split": "test", "_hash": "8af74b95cd7ac71f4fd31e37f5a62624"}
{"project": "FFmpeg", "commit_id": "93c04e095dc37ebdab22174e88cfa91e24940866", "target": 0, "func": "static int flv_read_metabody(AVFormatContext *s, int64_t next_pos)\n\n{\n\n    AMFDataType type;\n\n    AVStream *stream, *astream, *vstream;\n\n    AVIOContext *ioc;\n\n    int i;\n\n    // only needs to hold the string \"onMetaData\".\n\n    // Anything longer is something we don't want.\n\n    char buffer[11];\n\n\n\n    astream = NULL;\n\n    vstream = NULL;\n\n    ioc     = s->pb;\n\n\n\n    // first object needs to be \"onMetaData\" string\n\n    type = avio_r8(ioc);\n\n    if (type != AMF_DATA_TYPE_STRING ||\n\n        amf_get_string(ioc, buffer, sizeof(buffer)) < 0)\n\n        return -1;\n\n\n\n    if (!strcmp(buffer, \"onTextData\"))\n\n        return 1;\n\n\n\n    if (strcmp(buffer, \"onMetaData\"))\n\n        return -1;\n\n\n\n    // find the streams now so that amf_parse_object doesn't need to do\n\n    // the lookup every time it is called.\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        stream = s->streams[i];\n\n        if (stream->codec->codec_type == AVMEDIA_TYPE_AUDIO)\n\n            astream = stream;\n\n        else if (stream->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            vstream = stream;\n\n    }\n\n\n\n    // parse the second object (we want a mixed array)\n\n    if (amf_parse_object(s, astream, vstream, buffer, next_pos, 0) < 0)\n\n        return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 9036, "_split": "test", "_hash": "c984856598700427de2953df9fdf4d6b"}
{"project": "FFmpeg", "commit_id": "ebea370dc3909aa182bae4c728b83516a904beca", "target": 0, "func": "static int write_fragments(struct Tracks *tracks, int start_index,\n\n                           AVIOContext *in)\n\n{\n\n    char dirname[100], filename[500];\n\n    int i, j;\n\n\n\n    for (i = start_index; i < tracks->nb_tracks; i++) {\n\n        struct Track *track = tracks->tracks[i];\n\n        const char *type    = track->is_video ? \"video\" : \"audio\";\n\n        snprintf(dirname, sizeof(dirname), \"QualityLevels(%d)\", track->bitrate);\n\n        mkdir(dirname, 0777);\n\n        for (j = 0; j < track->chunks; j++) {\n\n            snprintf(filename, sizeof(filename), \"%s/Fragments(%s=%\"PRId64\")\",\n\n                     dirname, type, track->offsets[j].time);\n\n            avio_seek(in, track->offsets[j].offset, SEEK_SET);\n\n            write_fragment(filename, in);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 9047, "_split": "test", "_hash": "d91d53b5e5c0a505a28a012f1f5df5a8"}
{"project": "FFmpeg", "commit_id": "f27b22b4974c740f4c7b4140a793cac196179266", "target": 0, "func": "static av_always_inline void xchg_mb_border(H264Context *h, uint8_t *src_y,\n\n                                            uint8_t *src_cb, uint8_t *src_cr,\n\n                                            int linesize, int uvlinesize,\n\n                                            int xchg, int chroma444,\n\n                                            int simple, int pixel_shift)\n\n{\n\n    int deblock_topleft;\n\n    int deblock_top;\n\n    int top_idx = 1;\n\n    uint8_t *top_border_m1;\n\n    uint8_t *top_border;\n\n\n\n    if (!simple && FRAME_MBAFF(h)) {\n\n        if (h->mb_y & 1) {\n\n            if (!MB_MBAFF(h))\n\n                return;\n\n        } else {\n\n            top_idx = MB_MBAFF(h) ? 0 : 1;\n\n        }\n\n    }\n\n\n\n    if (h->deblocking_filter == 2) {\n\n        deblock_topleft = h->slice_table[h->mb_xy - 1 - h->mb_stride] == h->slice_num;\n\n        deblock_top     = h->top_type;\n\n    } else {\n\n        deblock_topleft = (h->mb_x > 0);\n\n        deblock_top     = (h->mb_y > !!MB_FIELD(h));\n\n    }\n\n\n\n    src_y  -= linesize   + 1 + pixel_shift;\n\n    src_cb -= uvlinesize + 1 + pixel_shift;\n\n    src_cr -= uvlinesize + 1 + pixel_shift;\n\n\n\n    top_border_m1 = h->top_borders[top_idx][h->mb_x - 1];\n\n    top_border    = h->top_borders[top_idx][h->mb_x];\n\n\n\n#define XCHG(a, b, xchg)                        \\\n\n    if (pixel_shift) {                          \\\n\n        if (xchg) {                             \\\n\n            AV_SWAP64(b + 0, a + 0);            \\\n\n            AV_SWAP64(b + 8, a + 8);            \\\n\n        } else {                                \\\n\n            AV_COPY128(b, a);                   \\\n\n        }                                       \\\n\n    } else if (xchg)                            \\\n\n        AV_SWAP64(b, a);                        \\\n\n    else                                        \\\n\n        AV_COPY64(b, a);\n\n\n\n    if (deblock_top) {\n\n        if (deblock_topleft) {\n\n            XCHG(top_border_m1 + (8 << pixel_shift),\n\n                 src_y - (7 << pixel_shift), 1);\n\n        }\n\n        XCHG(top_border + (0 << pixel_shift), src_y + (1 << pixel_shift), xchg);\n\n        XCHG(top_border + (8 << pixel_shift), src_y + (9 << pixel_shift), 1);\n\n        if (h->mb_x + 1 < h->mb_width) {\n\n            XCHG(h->top_borders[top_idx][h->mb_x + 1],\n\n                 src_y + (17 << pixel_shift), 1);\n\n        }\n\n    }\n\n    if (simple || !CONFIG_GRAY || !(h->flags & CODEC_FLAG_GRAY)) {\n\n        if (chroma444) {\n\n            if (deblock_topleft) {\n\n                XCHG(top_border_m1 + (24 << pixel_shift), src_cb - (7 << pixel_shift), 1);\n\n                XCHG(top_border_m1 + (40 << pixel_shift), src_cr - (7 << pixel_shift), 1);\n\n            }\n\n            XCHG(top_border + (16 << pixel_shift), src_cb + (1 << pixel_shift), xchg);\n\n            XCHG(top_border + (24 << pixel_shift), src_cb + (9 << pixel_shift), 1);\n\n            XCHG(top_border + (32 << pixel_shift), src_cr + (1 << pixel_shift), xchg);\n\n            XCHG(top_border + (40 << pixel_shift), src_cr + (9 << pixel_shift), 1);\n\n            if (h->mb_x + 1 < h->mb_width) {\n\n                XCHG(h->top_borders[top_idx][h->mb_x + 1] + (16 << pixel_shift), src_cb + (17 << pixel_shift), 1);\n\n                XCHG(h->top_borders[top_idx][h->mb_x + 1] + (32 << pixel_shift), src_cr + (17 << pixel_shift), 1);\n\n            }\n\n        } else {\n\n            if (deblock_top) {\n\n                if (deblock_topleft) {\n\n                    XCHG(top_border_m1 + (16 << pixel_shift), src_cb - (7 << pixel_shift), 1);\n\n                    XCHG(top_border_m1 + (24 << pixel_shift), src_cr - (7 << pixel_shift), 1);\n\n                }\n\n                XCHG(top_border + (16 << pixel_shift), src_cb + 1 + pixel_shift, 1);\n\n                XCHG(top_border + (24 << pixel_shift), src_cr + 1 + pixel_shift, 1);\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 9094, "_split": "test", "_hash": "4da1bd51906cc8149391b3c8444a997b"}
{"project": "FFmpeg", "commit_id": "c56e71309ec1a585ed4d4dc11ae0ba3ca7d19618", "target": 1, "func": "static int gif_image_write_image(AVCodecContext *avctx,\n\n                                 uint8_t **bytestream, uint8_t *end,\n\n                                 const uint8_t *buf, int linesize)\n\n{\n\n    GIFContext *s = avctx->priv_data;\n\n    int len, height;\n\n    const uint8_t *ptr;\n\n    /* image block */\n\n\n\n    bytestream_put_byte(bytestream, 0x2c);\n\n    bytestream_put_le16(bytestream, 0);\n\n    bytestream_put_le16(bytestream, 0);\n\n    bytestream_put_le16(bytestream, avctx->width);\n\n    bytestream_put_le16(bytestream, avctx->height);\n\n    bytestream_put_byte(bytestream, 0x00); /* flags */\n\n    /* no local clut */\n\n\n\n    bytestream_put_byte(bytestream, 0x08);\n\n\n\n    ff_lzw_encode_init(s->lzw, s->buf, avctx->width*avctx->height,\n\n                       12, FF_LZW_GIF, put_bits);\n\n\n\n    ptr = buf;\n\n    for (height = avctx->height; height--;) {\n\n        len += ff_lzw_encode(s->lzw, ptr, avctx->width);\n\n        ptr += linesize;\n\n    }\n\n    len += ff_lzw_encode_flush(s->lzw, flush_put_bits);\n\n\n\n    ptr = s->buf;\n\n    while (len > 0) {\n\n        int size = FFMIN(255, len);\n\n        bytestream_put_byte(bytestream, size);\n\n        if (end - *bytestream < size)\n\n            return -1;\n\n        bytestream_put_buffer(bytestream, ptr, size);\n\n        ptr += size;\n\n        len -= size;\n\n    }\n\n    bytestream_put_byte(bytestream, 0x00); /* end of image block */\n\n    bytestream_put_byte(bytestream, 0x3b);\n\n    return 0;\n\n}\n", "idx": 9095, "_split": "test", "_hash": "774b0626a1c5f56403f8d98341d97252"}
{"project": "FFmpeg", "commit_id": "da048c6d24729d3bab6ccb0ac340ea129e3e88d5", "target": 1, "func": "static int mov_write_stbl_tag(AVIOContext *pb, MOVTrack *track)\n\n{\n\n    int64_t pos = avio_tell(pb);\n\n    avio_wb32(pb, 0); /* size */\n\n    ffio_wfourcc(pb, \"stbl\");\n\n    mov_write_stsd_tag(pb, track);\n\n    mov_write_stts_tag(pb, track);\n\n    if ((track->enc->codec_type == AVMEDIA_TYPE_VIDEO ||\n\n         track->enc->codec_tag == MKTAG('r','t','p',' ')) &&\n\n        track->has_keyframes && track->has_keyframes < track->entry)\n\n        mov_write_stss_tag(pb, track, MOV_SYNC_SAMPLE);\n\n    if (track->mode == MODE_MOV && track->flags & MOV_TRACK_STPS)\n\n        mov_write_stss_tag(pb, track, MOV_PARTIAL_SYNC_SAMPLE);\n\n    if (track->enc->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n        track->flags & MOV_TRACK_CTTS && track->entry)\n\n        mov_write_ctts_tag(pb, track);\n\n    mov_write_stsc_tag(pb, track);\n\n    mov_write_stsz_tag(pb, track);\n\n    mov_write_stco_tag(pb, track);\n\n    return update_size(pb, pos);\n\n}\n", "idx": 9101, "_split": "test", "_hash": "af131e452b7cebf12003fad80bd1b1d5"}
{"project": "FFmpeg", "commit_id": "428098165de4c3edfe42c1b7f00627d287015863", "target": 1, "func": "static inline int RENAME(yuv420_rgb16)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,\n\n             int srcSliceH, uint8_t* dst[], int dstStride[]){\n\n    int y, h_size;\n\n\n\n    if(c->srcFormat == PIX_FMT_YUV422P){\n\n\tsrcStride[1] *= 2;\n\n\tsrcStride[2] *= 2;\n\n    }\n\n\n\n    h_size= (c->dstW+7)&~7;\n\n    if(h_size*2 > FFABS(dstStride[0])) h_size-=8;\n\n\n\n    __asm__ __volatile__ (\"pxor %mm4, %mm4;\" /* zero mm4 */ );\n\n//printf(\"%X %X %X %X %X %X %X %X %X %X\\n\", (int)&c->redDither, (int)&b5Dither, (int)src[0], (int)src[1], (int)src[2], (int)dst[0],\n\n//srcStride[0],srcStride[1],srcStride[2],dstStride[0]);\n\n    for (y= 0; y<srcSliceH; y++ ) {\n\n\tuint8_t *_image = dst[0] + (y+srcSliceY)*dstStride[0];\n\n\tuint8_t *_py = src[0] + y*srcStride[0];\n\n\tuint8_t *_pu = src[1] + (y>>1)*srcStride[1];\n\n\tuint8_t *_pv = src[2] + (y>>1)*srcStride[2];\n\n\tlong index= -h_size/2;\n\n\n\n\tb5Dither= dither8[y&1];\n\n\tg6Dither= dither4[y&1];\n\n\tg5Dither= dither8[y&1];\n\n\tr5Dither= dither8[(y+1)&1];\n\n\t    /* this mmx assembly code deals with SINGLE scan line at a time, it convert 8\n\n\t       pixels in each iteration */\n\n\t    __asm__ __volatile__ (\n\n\t/* load data for start of next scan line */\n\n\t\t     \"movd (%2, %0), %%mm0;\" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\n\n\t\t     \"movd (%3, %0), %%mm1;\" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\n\n\t\t     \"movq (%5, %0, 2), %%mm6;\" /* Load 8  Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\n\n//\t\t    \".balign 16\t\t\t\\n\\t\"\n\n\t\t    \"1:\t\t\t\t\\n\\t\"\n\n/* no speed diference on my p3@500 with prefetch,\n\n * if it is faster for anyone with -benchmark then tell me\n\n\t\t\tPREFETCH\" 64(%0) \\n\\t\"\n\n\t\t\tPREFETCH\" 64(%1) \\n\\t\"\n\n\t\t\tPREFETCH\" 64(%2) \\n\\t\"\n\n*/\n\nYUV2RGB\n\n\n\n#ifdef DITHER1XBPP\n\n\t\t\t\"paddusb \"MANGLE(b5Dither)\", %%mm0;\"\n\n\t\t\t\"paddusb \"MANGLE(g6Dither)\", %%mm2;\"\n\n\t\t\t\"paddusb \"MANGLE(r5Dither)\", %%mm1;\"\n\n#endif\n\n\t\t     /* mask unneeded bits off */\n\n\t\t     \"pand \"MANGLE(mmx_redmask)\", %%mm0;\" /* b7b6b5b4 b3_0_0_0 b7b6b5b4 b3_0_0_0 */\n\n\t\t     \"pand \"MANGLE(mmx_grnmask)\", %%mm2;\" /* g7g6g5g4 g3g2_0_0 g7g6g5g4 g3g2_0_0 */\n\n\t\t     \"pand \"MANGLE(mmx_redmask)\", %%mm1;\" /* r7r6r5r4 r3_0_0_0 r7r6r5r4 r3_0_0_0 */\n\n\n\n\t\t     \"psrlw $3,%%mm0;\" /* 0_0_0_b7 b6b5b4b3 0_0_0_b7 b6b5b4b3 */\n\n\t\t     \"pxor %%mm4, %%mm4;\" /* zero mm4 */\n\n\n\n\t\t     \"movq %%mm0, %%mm5;\" /* Copy B7-B0 */\n\n\t\t     \"movq %%mm2, %%mm7;\" /* Copy G7-G0 */\n\n\n\n\t\t     /* convert rgb24 plane to rgb16 pack for pixel 0-3 */\n\n\t\t     \"punpcklbw %%mm4, %%mm2;\" /* 0_0_0_0 0_0_0_0 g7g6g5g4 g3g2_0_0 */\n\n\t\t     \"punpcklbw %%mm1, %%mm0;\" /* r7r6r5r4 r3_0_0_0 0_0_0_b7 b6b5b4b3 */\n\n\n\n\t\t     \"psllw $3, %%mm2;\" /* 0_0_0_0 0_g7g6g5 g4g3g2_0 0_0_0_0 */\n\n\t\t     \"por %%mm2, %%mm0;\" /* r7r6r5r4 r3g7g6g5 g4g3g2b7 b6b5b4b3 */\n\n\n\n\t\t     \"movq 8 (%5, %0, 2), %%mm6;\" /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\n\n\t\t     MOVNTQ \" %%mm0, (%1);\" /* store pixel 0-3 */\n\n\n\n\t\t     /* convert rgb24 plane to rgb16 pack for pixel 0-3 */\n\n\t\t     \"punpckhbw %%mm4, %%mm7;\" /* 0_0_0_0 0_0_0_0 g7g6g5g4 g3g2_0_0 */\n\n\t\t     \"punpckhbw %%mm1, %%mm5;\" /* r7r6r5r4 r3_0_0_0 0_0_0_b7 b6b5b4b3 */\n\n\n\n\t\t     \"psllw $3, %%mm7;\" /* 0_0_0_0 0_g7g6g5 g4g3g2_0 0_0_0_0 */\n\n\t\t     \"movd 4 (%2, %0), %%mm0;\" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\n\n\n\n\t\t     \"por %%mm7, %%mm5;\" /* r7r6r5r4 r3g7g6g5 g4g3g2b7 b6b5b4b3 */\n\n\t\t     \"movd 4 (%3, %0), %%mm1;\" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\n\n\n\n\t\t     MOVNTQ \" %%mm5, 8 (%1);\" /* store pixel 4-7 */\n\n\n\n\t\t     \"add $16, %1\t\t\t\\n\\t\"\n\n\t\t     \"add $4, %0\t\t\t\\n\\t\"\n\n\t\t     \" js 1b\t\t\t\t\\n\\t\"\n\n\n\n\t\t     : \"+r\" (index), \"+r\" (_image)\n\n\t\t     : \"r\" (_pu - index), \"r\" (_pv - index), \"r\"(&c->redDither), \"r\" (_py - 2*index)\n\n\t\t     );\n\n    }\n\n\n\n    __asm__ __volatile__ (EMMS);\n\n\n\n    return srcSliceH;\n\n}\n", "idx": 9109, "_split": "test", "_hash": "e8e0cff2f6e98f7f9d001fe64d59f2a8"}
{"project": "FFmpeg", "commit_id": "c3778df2d4c05e76d28d77a2d740e435393046c9", "target": 0, "func": "enum AVPixelFormat choose_pixel_fmt(AVStream *st, AVCodec *codec, enum AVPixelFormat target)\n\n{\n\n    if (codec && codec->pix_fmts) {\n\n        const enum AVPixelFormat *p = codec->pix_fmts;\n\n        int has_alpha= av_pix_fmt_desc_get(target)->nb_components % 2 == 0;\n\n        enum AVPixelFormat best= AV_PIX_FMT_NONE;\n\n        if (st->codec->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL) {\n\n            if (st->codec->codec_id == AV_CODEC_ID_MJPEG) {\n\n                p = (const enum AVPixelFormat[]) { AV_PIX_FMT_YUVJ420P, AV_PIX_FMT_YUVJ422P, AV_PIX_FMT_YUV420P, AV_PIX_FMT_YUV422P, AV_PIX_FMT_NONE };\n\n            } else if (st->codec->codec_id == AV_CODEC_ID_LJPEG) {\n\n                p = (const enum AVPixelFormat[]) { AV_PIX_FMT_YUVJ420P, AV_PIX_FMT_YUVJ422P, AV_PIX_FMT_YUVJ444P, AV_PIX_FMT_YUV420P,\n\n                                                 AV_PIX_FMT_YUV422P, AV_PIX_FMT_YUV444P, AV_PIX_FMT_BGRA, AV_PIX_FMT_NONE };\n\n            }\n\n        }\n\n        for (; *p != AV_PIX_FMT_NONE; p++) {\n\n            best= avcodec_find_best_pix_fmt_of_2(best, *p, target, has_alpha, NULL);\n\n            if (*p == target)\n\n                break;\n\n        }\n\n        if (*p == AV_PIX_FMT_NONE) {\n\n            if (target != AV_PIX_FMT_NONE)\n\n                av_log(NULL, AV_LOG_WARNING,\n\n                       \"Incompatible pixel format '%s' for codec '%s', auto-selecting format '%s'\\n\",\n\n                       av_get_pix_fmt_name(target),\n\n                       codec->name,\n\n                       av_get_pix_fmt_name(best));\n\n            return best;\n\n        }\n\n    }\n\n    return target;\n\n}\n", "idx": 9134, "_split": "test", "_hash": "166b9269731f1b70ed4931fa8b7e9c42"}
{"project": "FFmpeg", "commit_id": "366ac22ea5a8bab63c7f46cdad2ddb2ff22cdbed", "target": 1, "func": "static int decode_mb_info(IVI5DecContext *ctx, IVIBandDesc *band,\n                          IVITile *tile, AVCodecContext *avctx)\n{\n    int         x, y, mv_x, mv_y, mv_delta, offs, mb_offset,\n                mv_scale, blks_per_mb;\n    IVIMbInfo   *mb, *ref_mb;\n    int         row_offset = band->mb_size * band->pitch;\n    mb     = tile->mbs;\n    ref_mb = tile->ref_mbs;\n    offs   = tile->ypos * band->pitch + tile->xpos;\n    /* scale factor for motion vectors */\n    mv_scale = (ctx->planes[0].bands[0].mb_size >> 3) - (band->mb_size >> 3);\n    mv_x = mv_y = 0;\n    for (y = tile->ypos; y < (tile->ypos + tile->height); y += band->mb_size) {\n        mb_offset = offs;\n        for (x = tile->xpos; x < (tile->xpos + tile->width); x += band->mb_size) {\n            mb->xpos     = x;\n            mb->ypos     = y;\n            mb->buf_offs = mb_offset;\n            if (get_bits1(&ctx->gb)) {\n                if (ctx->frame_type == FRAMETYPE_INTRA) {\n                    av_log(avctx, AV_LOG_ERROR, \"Empty macroblock in an INTRA picture!\\n\");\n                    return -1;\n                }\n                mb->type = 1; /* empty macroblocks are always INTER */\n                mb->cbp  = 0; /* all blocks are empty */\n                mb->q_delta = 0;\n                if (!band->plane && !band->band_num && (ctx->frame_flags & 8)) {\n                    mb->q_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                           IVI_VLC_BITS, 1);\n                    mb->q_delta = IVI_TOSIGNED(mb->q_delta);\n                }\n                mb->mv_x = mb->mv_y = 0; /* no motion vector coded */\n                if (band->inherit_mv){\n                    /* motion vector inheritance */\n                    if (mv_scale) {\n                        mb->mv_x = ivi_scale_mv(ref_mb->mv_x, mv_scale);\n                        mb->mv_y = ivi_scale_mv(ref_mb->mv_y, mv_scale);\n                    } else {\n                        mb->mv_x = ref_mb->mv_x;\n                        mb->mv_y = ref_mb->mv_y;\n                    }\n                }\n            } else {\n                if (band->inherit_mv) {\n                    mb->type = ref_mb->type; /* copy mb_type from corresponding reference mb */\n                } else if (ctx->frame_type == FRAMETYPE_INTRA) {\n                    mb->type = 0; /* mb_type is always INTRA for intra-frames */\n                } else {\n                    mb->type = get_bits1(&ctx->gb);\n                }\n                blks_per_mb = band->mb_size != band->blk_size ? 4 : 1;\n                mb->cbp = get_bits(&ctx->gb, blks_per_mb);\n                mb->q_delta = 0;\n                if (band->qdelta_present) {\n                    if (band->inherit_qdelta) {\n                        if (ref_mb) mb->q_delta = ref_mb->q_delta;\n                    } else if (mb->cbp || (!band->plane && !band->band_num &&\n                                           (ctx->frame_flags & 8))) {\n                        mb->q_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                               IVI_VLC_BITS, 1);\n                        mb->q_delta = IVI_TOSIGNED(mb->q_delta);\n                    }\n                }\n                if (!mb->type) {\n                    mb->mv_x = mb->mv_y = 0; /* there is no motion vector in intra-macroblocks */\n                } else {\n                    if (band->inherit_mv){\n                        /* motion vector inheritance */\n                        if (mv_scale) {\n                            mb->mv_x = ivi_scale_mv(ref_mb->mv_x, mv_scale);\n                            mb->mv_y = ivi_scale_mv(ref_mb->mv_y, mv_scale);\n                        } else {\n                            mb->mv_x = ref_mb->mv_x;\n                            mb->mv_y = ref_mb->mv_y;\n                        }\n                    } else {\n                        /* decode motion vector deltas */\n                        mv_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                            IVI_VLC_BITS, 1);\n                        mv_y += IVI_TOSIGNED(mv_delta);\n                        mv_delta = get_vlc2(&ctx->gb, ctx->mb_vlc.tab->table,\n                                            IVI_VLC_BITS, 1);\n                        mv_x += IVI_TOSIGNED(mv_delta);\n                        mb->mv_x = mv_x;\n                        mb->mv_y = mv_y;\n                    }\n                }\n            }\n            mb++;\n            if (ref_mb)\n                ref_mb++;\n            mb_offset += band->mb_size;\n        }\n        offs += row_offset;\n    }\n    align_get_bits(&ctx->gb);\n    return 0;\n}", "idx": 9162, "_split": "test", "_hash": "6a3704a7d001e6a91cba45fc165394cf"}
{"project": "FFmpeg", "commit_id": "44ac13eed49593f4f8efdb72ab0d5b48e05aa305", "target": 1, "func": "int avpriv_dca_convert_bitstream(const uint8_t *src, int src_size, uint8_t *dst,\n\n                             int max_size)\n\n{\n\n    uint32_t mrk;\n\n    int i, tmp;\n\n    const uint16_t *ssrc = (const uint16_t *) src;\n\n    uint16_t *sdst = (uint16_t *) dst;\n\n    PutBitContext pb;\n\n\n\n    if ((unsigned) src_size > (unsigned) max_size)\n\n        src_size = max_size;\n\n\n\n    mrk = AV_RB32(src);\n\n    switch (mrk) {\n\n    case DCA_SYNCWORD_CORE_BE:\n\n        memcpy(dst, src, src_size);\n\n        return src_size;\n\n    case DCA_SYNCWORD_CORE_LE:\n\n        for (i = 0; i < (src_size + 1) >> 1; i++)\n\n            *sdst++ = av_bswap16(*ssrc++);\n\n        return src_size;\n\n    case DCA_SYNCWORD_CORE_14B_BE:\n\n    case DCA_SYNCWORD_CORE_14B_LE:\n\n        init_put_bits(&pb, dst, max_size);\n\n        for (i = 0; i < (src_size + 1) >> 1; i++, src += 2) {\n\n            tmp = ((mrk == DCA_SYNCWORD_CORE_14B_BE) ? AV_RB16(src) : AV_RL16(src)) & 0x3FFF;\n\n            put_bits(&pb, 14, tmp);\n\n        }\n\n        flush_put_bits(&pb);\n\n        return (put_bits_count(&pb) + 7) >> 3;\n\n    default:\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n}\n", "idx": 9178, "_split": "test", "_hash": "199bc70fe2226e17b30700a04c6b5075"}
{"project": "FFmpeg", "commit_id": "486637af8ef29ec215e0e0b7ecd3b5470f0e04e5", "target": 0, "func": "static inline void mix_3f_1r_to_mono(AC3DecodeContext *ctx)\n\n{\n\n    int i;\n\n    float (*output)[256] = ctx->audio_block.block_output;\n\n\n\n    for (i = 0; i < 256; i++)\n\n        output[1][i] = (output[2][i] + output[3][i] + output[4][i]);\n\n    memset(output[2], 0, sizeof(output[2]));\n\n    memset(output[3], 0, sizeof(output[3]));\n\n    memset(output[4], 0, sizeof(output[4]));\n\n}\n", "idx": 9238, "_split": "test", "_hash": "9ab4b07cdae26d170994425585951ecc"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(nv21ToUV)(uint8_t *dstU, uint8_t *dstV,\n\n                                    const uint8_t *src1, const uint8_t *src2,\n\n                                    long width, uint32_t *unused)\n\n{\n\n    RENAME(nvXXtoUV)(dstV, dstU, src1, width);\n\n}\n", "idx": 9246, "_split": "test", "_hash": "21829c2a7b7bce59cbb47838b8849d1f"}
{"project": "FFmpeg", "commit_id": "c94d551ea7b39c4e467e146cd347c407e8eb38ee", "target": 0, "func": "static int read_low_coeffs(AVCodecContext *avctx, int16_t *dst, int size, int width, ptrdiff_t stride)\n\n{\n\n    PixletContext *ctx = avctx->priv_data;\n\n    GetBitContext *b = &ctx->gbit;\n\n    unsigned cnt1, nbits, k, j = 0, i = 0;\n\n    int64_t value, state = 3;\n\n    int rlen, escape, flag = 0;\n\n\n\n    while (i < size) {\n\n        nbits = FFMIN(ff_clz((state >> 8) + 3) ^ 0x1F, 14);\n\n\n\n        cnt1 = get_unary(b, 0, 8);\n\n        if (cnt1 < 8) {\n\n            value = show_bits(b, nbits);\n\n            if (value <= 1) {\n\n                skip_bits(b, nbits - 1);\n\n                escape = ((1 << nbits) - 1) * cnt1;\n\n            } else {\n\n                skip_bits(b, nbits);\n\n                escape = value + ((1 << nbits) - 1) * cnt1 - 1;\n\n            }\n\n        } else {\n\n            escape = get_bits(b, 16);\n\n        }\n\n\n\n        value = -((escape + flag) & 1) | 1;\n\n        dst[j++] = value * ((escape + flag + 1) >> 1);\n\n        i++;\n\n        if (j == width) {\n\n            j = 0;\n\n            dst += stride;\n\n        }\n\n        state = 120 * (escape + flag) + state - (120 * state >> 8);\n\n        flag = 0;\n\n\n\n        if (state * 4 > 0xFF || i >= size)\n\n            continue;\n\n\n\n        nbits = ((state + 8) >> 5) + (state ? ff_clz(state) : 32) - 24;\n\n        escape = av_mod_uintp2(16383, nbits);\n\n        cnt1 = get_unary(b, 0, 8);\n\n        if (cnt1 > 7) {\n\n            rlen = get_bits(b, 16);\n\n        } else {\n\n            value = show_bits(b, nbits);\n\n            if (value > 1) {\n\n                skip_bits(b, nbits);\n\n                rlen = value + escape * cnt1 - 1;\n\n            } else {\n\n                skip_bits(b, nbits - 1);\n\n                rlen = escape * cnt1;\n\n            }\n\n        }\n\n\n\n        if (i + rlen > size)\n\n            return AVERROR_INVALIDDATA;\n\n        i += rlen;\n\n\n\n        for (k = 0; k < rlen; k++) {\n\n            dst[j++] = 0;\n\n            if (j == width) {\n\n                j = 0;\n\n                dst += stride;\n\n            }\n\n        }\n\n\n\n        state = 0;\n\n        flag = rlen < 0xFFFF ? 1 : 0;\n\n    }\n\n\n\n    align_get_bits(b);\n\n    return get_bits_count(b) >> 3;\n\n}\n", "idx": 9258, "_split": "test", "_hash": "0653b094c28ac129b9595090e61cce5d"}
{"project": "FFmpeg", "commit_id": "dd5d61795690e339ae271692e7ab9df66b5eb153", "target": 0, "func": "static int request_frame(AVFilterLink *link)\n\n{\n\n    AVFilterContext *ctx = link->src;\n\n    IDETContext *idet = ctx->priv;\n\n\n\n    do {\n\n        int ret;\n\n\n\n        if (idet->eof)\n\n            return AVERROR_EOF;\n\n\n\n        ret = ff_request_frame(link->src->inputs[0]);\n\n\n\n        if (ret == AVERROR_EOF && idet->cur) {\n\n            AVFrame *next = av_frame_clone(idet->next);\n\n\n\n            if (!next)\n\n                return AVERROR(ENOMEM);\n\n\n\n            filter_frame(link->src->inputs[0], next);\n\n            idet->eof = 1;\n\n        } else if (ret < 0) {\n\n            return ret;\n\n        }\n\n    } while (!idet->cur);\n\n\n\n    return 0;\n\n}\n", "idx": 9282, "_split": "test", "_hash": "ac4e74613b70c80c4f057b5f70d15a24"}
{"project": "FFmpeg", "commit_id": "a2085a7e9d83d99aca58bfb385f6db1afa5673dd", "target": 1, "func": "static int dpcm_decode_frame(AVCodecContext *avctx,\n                             void *data, int *data_size,\n                             uint8_t *buf, int buf_size)\n{\n    DPCMContext *s = avctx->priv_data;\n    int in, out = 0;\n    int predictor[2];\n    int channel_number = 0;\n    short *output_samples = data;\n    int shift[2];\n    unsigned char byte;\n    short diff;\n    if (!buf_size)\n        return 0;\n    switch(avctx->codec->id) {\n    case CODEC_ID_ROQ_DPCM:\n        if (s->channels == 1)\n            predictor[0] = AV_RL16(&buf[6]);\n        else {\n            predictor[0] = buf[7] << 8;\n            predictor[1] = buf[6] << 8;\n        }\n        SE_16BIT(predictor[0]);\n        SE_16BIT(predictor[1]);\n        /* decode the samples */\n        for (in = 8, out = 0; in < buf_size; in++, out++) {\n            predictor[channel_number] += s->roq_square_array[buf[in]];\n            predictor[channel_number] = av_clip_int16(predictor[channel_number]);\n            output_samples[out] = predictor[channel_number];\n            /* toggle channel */\n            channel_number ^= s->channels - 1;\n        }\n        break;\n    case CODEC_ID_INTERPLAY_DPCM:\n        in = 6;  /* skip over the stream mask and stream length */\n        predictor[0] = AV_RL16(&buf[in]);\n        in += 2;\n        SE_16BIT(predictor[0])\n        output_samples[out++] = predictor[0];\n        if (s->channels == 2) {\n            predictor[1] = AV_RL16(&buf[in]);\n            in += 2;\n            SE_16BIT(predictor[1])\n            output_samples[out++] = predictor[1];\n        }\n        while (in < buf_size) {\n            predictor[channel_number] += interplay_delta_table[buf[in++]];\n            predictor[channel_number] = av_clip_int16(predictor[channel_number]);\n            output_samples[out++] = predictor[channel_number];\n            /* toggle channel */\n            channel_number ^= s->channels - 1;\n        }\n        break;\n    case CODEC_ID_XAN_DPCM:\n        in = 0;\n        shift[0] = shift[1] = 4;\n        predictor[0] = AV_RL16(&buf[in]);\n        in += 2;\n        SE_16BIT(predictor[0]);\n        if (s->channels == 2) {\n            predictor[1] = AV_RL16(&buf[in]);\n            in += 2;\n            SE_16BIT(predictor[1]);\n        }\n        while (in < buf_size) {\n            byte = buf[in++];\n            diff = (byte & 0xFC) << 8;\n            if ((byte & 0x03) == 3)\n                shift[channel_number]++;\n            else\n                shift[channel_number] -= (2 * (byte & 3));\n            /* saturate the shifter to a lower limit of 0 */\n            if (shift[channel_number] < 0)\n                shift[channel_number] = 0;\n            diff >>= shift[channel_number];\n            predictor[channel_number] += diff;\n            predictor[channel_number] = av_clip_int16(predictor[channel_number]);\n            output_samples[out++] = predictor[channel_number];\n            /* toggle channel */\n            channel_number ^= s->channels - 1;\n        }\n        break;\n    case CODEC_ID_SOL_DPCM:\n        in = 0;\n        if (avctx->codec_tag != 3) {\n            if(*data_size/4 < buf_size)\n            while (in < buf_size) {\n                int n1, n2;\n                n1 = (buf[in] >> 4) & 0xF;\n                n2 = buf[in++] & 0xF;\n                s->sample[0] += s->sol_table[n1];\n                 if (s->sample[0] < 0) s->sample[0] = 0;\n                if (s->sample[0] > 255) s->sample[0] = 255;\n                output_samples[out++] = (s->sample[0] - 128) << 8;\n                s->sample[s->channels - 1] += s->sol_table[n2];\n                if (s->sample[s->channels - 1] < 0) s->sample[s->channels - 1] = 0;\n                if (s->sample[s->channels - 1] > 255) s->sample[s->channels - 1] = 255;\n                output_samples[out++] = (s->sample[s->channels - 1] - 128) << 8;\n            }\n        } else {\n            while (in < buf_size) {\n                int n;\n                n = buf[in++];\n                if (n & 0x80) s->sample[channel_number] -= s->sol_table[n & 0x7F];\n                else s->sample[channel_number] += s->sol_table[n & 0x7F];\n                s->sample[channel_number] = av_clip_int16(s->sample[channel_number]);\n                output_samples[out++] = s->sample[channel_number];\n                /* toggle channel */\n                channel_number ^= s->channels - 1;\n            }\n        }\n        break;\n    }\n    *data_size = out * sizeof(short);\n    return buf_size;\n}", "idx": 9283, "_split": "test", "_hash": "640e753214fa2779189ca07d9205a039"}
{"project": "FFmpeg", "commit_id": "03abf55f252945c70f4a79eaf4d609cee4d98710", "target": 1, "func": "int ff_rm_read_mdpr_codecdata(AVFormatContext *s, AVIOContext *pb,\n\n                              AVStream *st, RMStream *rst,\n\n                              unsigned int codec_data_size, const uint8_t *mime)\n\n{\n\n    unsigned int v;\n\n    int size;\n\n    int64_t codec_pos;\n\n    int ret;\n\n\n\n    if (codec_data_size > INT_MAX)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    avpriv_set_pts_info(st, 64, 1, 1000);\n\n    codec_pos = avio_tell(pb);\n\n    v = avio_rb32(pb);\n\n\n\n    if (v == MKBETAG('M', 'L', 'T', 'I')) {\n\n        int number_of_streams = avio_rb16(pb);\n\n        int number_of_mdpr;\n\n        int i;\n\n        for (i = 0; i<number_of_streams; i++)\n\n            avio_rb16(pb);\n\n        number_of_mdpr = avio_rb16(pb);\n\n        if (number_of_mdpr != 1) {\n\n            avpriv_request_sample(s, \"MLTI with multiple MDPR\");\n\n        }\n\n        avio_rb32(pb);\n\n        v = avio_rb32(pb);\n\n    }\n\n\n\n    if (v == MKTAG(0xfd, 'a', 'r', '.')) {\n\n        /* ra type header */\n\n        if (rm_read_audio_stream_info(s, pb, st, rst, 0))\n\n            return -1;\n\n    } else if (v == MKBETAG('L', 'S', 'D', ':')) {\n\n        avio_seek(pb, -4, SEEK_CUR);\n\n        if ((ret = rm_read_extradata(pb, st->codec, codec_data_size)) < 0)\n\n            return ret;\n\n\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_tag  = AV_RL32(st->codec->extradata);\n\n        st->codec->codec_id   = ff_codec_get_id(ff_rm_codec_tags,\n\n                                                st->codec->codec_tag);\n\n    } else if(mime && !strcmp(mime, \"logical-fileinfo\")){\n\n        int stream_count, rule_count, property_count, i;\n\n        ff_free_stream(s, st);\n\n        if (avio_rb16(pb) != 0) {\n\n            av_log(s, AV_LOG_WARNING, \"Unsupported version\\n\");\n\n            goto skip;\n\n        }\n\n        stream_count = avio_rb16(pb);\n\n        avio_skip(pb, 6*stream_count);\n\n        rule_count = avio_rb16(pb);\n\n        avio_skip(pb, 2*rule_count);\n\n        property_count = avio_rb16(pb);\n\n        for(i=0; i<property_count; i++){\n\n            uint8_t name[128], val[128];\n\n            avio_rb32(pb);\n\n            if (avio_rb16(pb) != 0) {\n\n                av_log(s, AV_LOG_WARNING, \"Unsupported Name value property version\\n\");\n\n                goto skip; //FIXME skip just this one\n\n            }\n\n            get_str8(pb, name, sizeof(name));\n\n            switch(avio_rb32(pb)) {\n\n            case 2: get_strl(pb, val, sizeof(val), avio_rb16(pb));\n\n                av_dict_set(&s->metadata, name, val, 0);\n\n                break;\n\n            default: avio_skip(pb, avio_rb16(pb));\n\n            }\n\n        }\n\n    } else {\n\n        int fps;\n\n        if (avio_rl32(pb) != MKTAG('V', 'I', 'D', 'O')) {\n\n        fail1:\n\n            av_log(s, AV_LOG_WARNING, \"Unsupported stream type %08x\\n\", v);\n\n            goto skip;\n\n        }\n\n        st->codec->codec_tag = avio_rl32(pb);\n\n        st->codec->codec_id  = ff_codec_get_id(ff_rm_codec_tags,\n\n                                               st->codec->codec_tag);\n\n        av_dlog(s, \"%X %X\\n\", st->codec->codec_tag, MKTAG('R', 'V', '2', '0'));\n\n        if (st->codec->codec_id == AV_CODEC_ID_NONE)\n\n            goto fail1;\n\n        st->codec->width  = avio_rb16(pb);\n\n        st->codec->height = avio_rb16(pb);\n\n        avio_skip(pb, 2); // looks like bits per sample\n\n        avio_skip(pb, 4); // always zero?\n\n        st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n\n        fps = avio_rb32(pb);\n\n\n\n        if ((ret = rm_read_extradata(pb, st->codec, codec_data_size - (avio_tell(pb) - codec_pos))) < 0)\n\n            return ret;\n\n\n\n        if (fps > 0) {\n\n            av_reduce(&st->avg_frame_rate.den, &st->avg_frame_rate.num,\n\n                      0x10000, fps, (1 << 30) - 1);\n\n#if FF_API_R_FRAME_RATE\n\n            st->r_frame_rate = st->avg_frame_rate;\n\n#endif\n\n        } else if (s->error_recognition & AV_EF_EXPLODE) {\n\n            av_log(s, AV_LOG_ERROR, \"Invalid framerate\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\nskip:\n\n    /* skip codec info */\n\n    size = avio_tell(pb) - codec_pos;\n\n    avio_skip(pb, codec_data_size - size);\n\n\n\n    return 0;\n\n}\n", "idx": 9301, "_split": "test", "_hash": "d3b108413aede8b103720ddfba84e5a0"}
{"project": "FFmpeg", "commit_id": "76db17dc7d4f19f9a03bdd6de79c2ea37b76888f", "target": 0, "func": "static int dpcm_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    DPCMContext *s = avctx->priv_data;\n\n    int in, out = 0;\n\n    int predictor[2];\n\n    int ch = 0;\n\n    int stereo = s->channels - 1;\n\n    short *output_samples = data;\n\n    int shift[2];\n\n    unsigned char byte;\n\n    short diff;\n\n\n\n    if (!buf_size)\n\n        return 0;\n\n\n\n    // almost every DPCM variant expands one byte of data into two\n\n    if(*data_size/2 < buf_size)\n\n        return -1;\n\n\n\n    switch(avctx->codec->id) {\n\n\n\n    case CODEC_ID_ROQ_DPCM:\n\n        if (stereo) {\n\n            predictor[0] = buf[7] << 8;\n\n            predictor[1] = buf[6] << 8;\n\n        } else {\n\n            predictor[0] = AV_RL16(&buf[6]);\n\n        }\n\n        SE_16BIT(predictor[0]);\n\n        SE_16BIT(predictor[1]);\n\n\n\n        /* decode the samples */\n\n        for (in = 8, out = 0; in < buf_size; in++, out++) {\n\n            predictor[ch] += s->roq_square_array[buf[in]];\n\n            predictor[ch] = av_clip_int16(predictor[ch]);\n\n            output_samples[out] = predictor[ch];\n\n\n\n            /* toggle channel */\n\n            ch ^= stereo;\n\n        }\n\n        break;\n\n\n\n    case CODEC_ID_INTERPLAY_DPCM:\n\n        in = 6;  /* skip over the stream mask and stream length */\n\n        predictor[0] = AV_RL16(&buf[in]);\n\n        in += 2;\n\n        SE_16BIT(predictor[0])\n\n        output_samples[out++] = predictor[0];\n\n        if (stereo) {\n\n            predictor[1] = AV_RL16(&buf[in]);\n\n            in += 2;\n\n            SE_16BIT(predictor[1])\n\n            output_samples[out++] = predictor[1];\n\n        }\n\n\n\n        while (in < buf_size) {\n\n            predictor[ch] += interplay_delta_table[buf[in++]];\n\n            predictor[ch] = av_clip_int16(predictor[ch]);\n\n            output_samples[out++] = predictor[ch];\n\n\n\n            /* toggle channel */\n\n            ch ^= stereo;\n\n        }\n\n\n\n        break;\n\n\n\n    case CODEC_ID_XAN_DPCM:\n\n        in = 0;\n\n        shift[0] = shift[1] = 4;\n\n        predictor[0] = AV_RL16(&buf[in]);\n\n        in += 2;\n\n        SE_16BIT(predictor[0]);\n\n        if (stereo) {\n\n            predictor[1] = AV_RL16(&buf[in]);\n\n            in += 2;\n\n            SE_16BIT(predictor[1]);\n\n        }\n\n\n\n        while (in < buf_size) {\n\n            byte = buf[in++];\n\n            diff = (byte & 0xFC) << 8;\n\n            if ((byte & 0x03) == 3)\n\n                shift[ch]++;\n\n            else\n\n                shift[ch] -= (2 * (byte & 3));\n\n            /* saturate the shifter to a lower limit of 0 */\n\n            if (shift[ch] < 0)\n\n                shift[ch] = 0;\n\n\n\n            diff >>= shift[ch];\n\n            predictor[ch] += diff;\n\n\n\n            predictor[ch] = av_clip_int16(predictor[ch]);\n\n            output_samples[out++] = predictor[ch];\n\n\n\n            /* toggle channel */\n\n            ch ^= stereo;\n\n        }\n\n        break;\n\n    case CODEC_ID_SOL_DPCM:\n\n        in = 0;\n\n        if (avctx->codec_tag != 3) {\n\n            if(*data_size/4 < buf_size)\n\n                return -1;\n\n            while (in < buf_size) {\n\n                int n1, n2;\n\n                n1 = (buf[in] >> 4) & 0xF;\n\n                n2 = buf[in++] & 0xF;\n\n                s->sample[0] += s->sol_table[n1];\n\n                if (s->sample[0] < 0)   s->sample[0] = 0;\n\n                if (s->sample[0] > 255) s->sample[0] = 255;\n\n                output_samples[out++] = (s->sample[0] - 128) << 8;\n\n                s->sample[stereo] += s->sol_table[n2];\n\n                if (s->sample[stereo] < 0)   s->sample[stereo] = 0;\n\n                if (s->sample[stereo] > 255) s->sample[stereo] = 255;\n\n                output_samples[out++] = (s->sample[stereo] - 128) << 8;\n\n            }\n\n        } else {\n\n            while (in < buf_size) {\n\n                int n;\n\n                n = buf[in++];\n\n                if (n & 0x80) s->sample[ch] -= s->sol_table[n & 0x7F];\n\n                else s->sample[ch] += s->sol_table[n & 0x7F];\n\n                s->sample[ch] = av_clip_int16(s->sample[ch]);\n\n                output_samples[out++] = s->sample[ch];\n\n                /* toggle channel */\n\n                ch ^= stereo;\n\n            }\n\n        }\n\n        break;\n\n    }\n\n\n\n    *data_size = out * sizeof(short);\n\n    return buf_size;\n\n}\n", "idx": 9343, "_split": "test", "_hash": "b02d45b59138fea41851c8e95d83574e"}
{"project": "FFmpeg", "commit_id": "0f34c0789f855f04dce518ffc93a01bb943ba1aa", "target": 1, "func": "static void picmemset(PicContext *s, AVFrame *frame, unsigned value, int run,\n\n                      int *x, int *y, int *plane, int bits_per_plane)\n\n{\n\n    uint8_t *d;\n\n    int shift = *plane * bits_per_plane;\n\n    unsigned mask  = ((1 << bits_per_plane) - 1) << shift;\n\n    value   <<= shift;\n\n\n\n    while (run > 0) {\n\n        int j;\n\n        for (j = 8-bits_per_plane; j >= 0; j -= bits_per_plane) {\n\n            d = frame->data[0] + *y * frame->linesize[0];\n\n            d[*x] |= (value >> j) & mask;\n\n            *x += 1;\n\n            if (*x == s->width) {\n\n                *y -= 1;\n\n                *x = 0;\n\n                if (*y < 0) {\n\n                   *y = s->height - 1;\n\n                   *plane += 1;\n\n                   if (*plane >= s->nb_planes)\n\n                       return;\n\n                   value <<= bits_per_plane;\n\n                   mask  <<= bits_per_plane;\n\n                }\n\n            }\n\n        }\n\n        run--;\n\n    }\n\n}\n", "idx": 9347, "_split": "test", "_hash": "b1a792cf2be9fd7171fb899b7082504d"}
{"project": "FFmpeg", "commit_id": "aaf78e4d14b4875e4cff30e979421a1087337b9f", "target": 1, "func": "mp_image_t* vf_get_image(vf_instance_t* vf, unsigned int outfmt, int mp_imgtype, int mp_imgflag, int w, int h){\n\n    MPContext *m= (MPContext*)(((uint8_t*)vf) - offsetof(MPContext, next_vf));\n\n  mp_image_t* mpi=NULL;\n\n  int w2;\n\n  int number = mp_imgtype >> 16;\n\n\n\n  av_assert0(vf->next == NULL); // all existing filters call this just on next\n\n\n\n  //vf_dint needs these as it calls vf_get_image() before configuring the output\n\n  if(vf->w==0 && w>0) vf->w=w;\n\n  if(vf->h==0 && h>0) vf->h=h;\n\n\n\n  av_assert0(w == -1 || w >= vf->w);\n\n  av_assert0(h == -1 || h >= vf->h);\n\n  av_assert0(vf->w > 0);\n\n  av_assert0(vf->h > 0);\n\n\n\n  av_log(m->avfctx, AV_LOG_DEBUG, \"get_image: %d:%d, vf: %d:%d\\n\", w,h,vf->w,vf->h);\n\n\n\n  if (w == -1) w = vf->w;\n\n  if (h == -1) h = vf->h;\n\n\n\n  w2=(mp_imgflag&MP_IMGFLAG_ACCEPT_ALIGNED_STRIDE)?((w+15)&(~15)):w;\n\n\n\n  // Note: we should call libvo first to check if it supports direct rendering\n\n  // and if not, then fallback to software buffers:\n\n  switch(mp_imgtype & 0xff){\n\n  case MP_IMGTYPE_EXPORT:\n\n    if(!vf->imgctx.export_images[0]) vf->imgctx.export_images[0]=new_mp_image(w2,h);\n\n    mpi=vf->imgctx.export_images[0];\n\n    break;\n\n  case MP_IMGTYPE_STATIC:\n\n    if(!vf->imgctx.static_images[0]) vf->imgctx.static_images[0]=new_mp_image(w2,h);\n\n    mpi=vf->imgctx.static_images[0];\n\n    break;\n\n  case MP_IMGTYPE_TEMP:\n\n    if(!vf->imgctx.temp_images[0]) vf->imgctx.temp_images[0]=new_mp_image(w2,h);\n\n    mpi=vf->imgctx.temp_images[0];\n\n    break;\n\n  case MP_IMGTYPE_IPB:\n\n    if(!(mp_imgflag&MP_IMGFLAG_READABLE)){ // B frame:\n\n      if(!vf->imgctx.temp_images[0]) vf->imgctx.temp_images[0]=new_mp_image(w2,h);\n\n      mpi=vf->imgctx.temp_images[0];\n\n      break;\n\n    }\n\n  case MP_IMGTYPE_IP:\n\n    if(!vf->imgctx.static_images[vf->imgctx.static_idx]) vf->imgctx.static_images[vf->imgctx.static_idx]=new_mp_image(w2,h);\n\n    mpi=vf->imgctx.static_images[vf->imgctx.static_idx];\n\n    vf->imgctx.static_idx^=1;\n\n    break;\n\n  case MP_IMGTYPE_NUMBERED:\n\n    if (number == -1) {\n\n      int i;\n\n      for (i = 0; i < NUM_NUMBERED_MPI; i++)\n\n        if (!vf->imgctx.numbered_images[i] || !vf->imgctx.numbered_images[i]->usage_count)\n\n          break;\n\n      number = i;\n\n    }\n\n    if (number < 0 || number >= NUM_NUMBERED_MPI) return NULL;\n\n    if (!vf->imgctx.numbered_images[number]) vf->imgctx.numbered_images[number] = new_mp_image(w2,h);\n\n    mpi = vf->imgctx.numbered_images[number];\n\n    mpi->number = number;\n\n    break;\n\n  }\n\n  if(mpi){\n\n    mpi->type=mp_imgtype;\n\n    mpi->w=vf->w; mpi->h=vf->h;\n\n    // keep buffer allocation status & color flags only:\n\n//    mpi->flags&=~(MP_IMGFLAG_PRESERVE|MP_IMGFLAG_READABLE|MP_IMGFLAG_DIRECT);\n\n    mpi->flags&=MP_IMGFLAG_ALLOCATED|MP_IMGFLAG_TYPE_DISPLAYED|MP_IMGFLAGMASK_COLORS;\n\n    // accept restrictions, draw_slice and palette flags only:\n\n    mpi->flags|=mp_imgflag&(MP_IMGFLAGMASK_RESTRICTIONS|MP_IMGFLAG_DRAW_CALLBACK|MP_IMGFLAG_RGB_PALETTE);\n\n    if(!vf->draw_slice) mpi->flags&=~MP_IMGFLAG_DRAW_CALLBACK;\n\n    if(mpi->width!=w2 || mpi->height!=h){\n\n//      printf(\"vf.c: MPI parameters changed!  %dx%d -> %dx%d   \\n\", mpi->width,mpi->height,w2,h);\n\n        if(mpi->flags&MP_IMGFLAG_ALLOCATED){\n\n            if(mpi->width<w2 || mpi->height<h){\n\n                // need to re-allocate buffer memory:\n\n                av_free(mpi->planes[0]);\n\n                mpi->flags&=~MP_IMGFLAG_ALLOCATED;\n\n                mp_msg(MSGT_VFILTER,MSGL_V,\"vf.c: have to REALLOCATE buffer memory :(\\n\");\n\n            }\n\n//      } else {\n\n        } {\n\n            mpi->width=w2; mpi->chroma_width=(w2 + (1<<mpi->chroma_x_shift) - 1)>>mpi->chroma_x_shift;\n\n            mpi->height=h; mpi->chroma_height=(h + (1<<mpi->chroma_y_shift) - 1)>>mpi->chroma_y_shift;\n\n        }\n\n    }\n\n    if(!mpi->bpp) mp_image_setfmt(mpi,outfmt);\n\n    if(!(mpi->flags&MP_IMGFLAG_ALLOCATED) && mpi->type>MP_IMGTYPE_EXPORT){\n\n\n\n        av_assert0(!vf->get_image);\n\n        // check libvo first!\n\n        if(vf->get_image) vf->get_image(vf,mpi);\n\n\n\n        if(!(mpi->flags&MP_IMGFLAG_DIRECT)){\n\n          // non-direct and not yet allocated image. allocate it!\n\n          if (!mpi->bpp) { // no way we can allocate this\n\n              mp_msg(MSGT_DECVIDEO, MSGL_FATAL,\n\n                     \"vf_get_image: Tried to allocate a format that can not be allocated!\\n\");\n\n              return NULL;\n\n          }\n\n\n\n          // check if codec prefer aligned stride:\n\n          if(mp_imgflag&MP_IMGFLAG_PREFER_ALIGNED_STRIDE){\n\n              int align=(mpi->flags&MP_IMGFLAG_PLANAR &&\n\n                         mpi->flags&MP_IMGFLAG_YUV) ?\n\n                         (8<<mpi->chroma_x_shift)-1 : 15; // -- maybe FIXME\n\n              w2=((w+align)&(~align));\n\n              if(mpi->width!=w2){\n\n#if 0\n\n                  // we have to change width... check if we CAN co it:\n\n                  int flags=vf->query_format(vf,outfmt); // should not fail\n\n                  if(!(flags&3)) mp_msg(MSGT_DECVIDEO,MSGL_WARN,\"??? vf_get_image{vf->query_format(outfmt)} failed!\\n\");\n\n//                printf(\"query -> 0x%X    \\n\",flags);\n\n                  if(flags&VFCAP_ACCEPT_STRIDE){\n\n#endif\n\n                      mpi->width=w2;\n\n                      mpi->chroma_width=(w2 + (1<<mpi->chroma_x_shift) - 1)>>mpi->chroma_x_shift;\n\n//                  }\n\n              }\n\n          }\n\n\n\n          mp_image_alloc_planes(mpi);\n\n//        printf(\"clearing img!\\n\");\n\n          vf_mpi_clear(mpi,0,0,mpi->width,mpi->height);\n\n        }\n\n    }\n\n    av_assert0(!vf->start_slice);\n\n    if(mpi->flags&MP_IMGFLAG_DRAW_CALLBACK)\n\n        if(vf->start_slice) vf->start_slice(vf,mpi);\n\n    if(!(mpi->flags&MP_IMGFLAG_TYPE_DISPLAYED)){\n\n            mp_msg(MSGT_DECVIDEO,MSGL_V,\"*** [%s] %s%s mp_image_t, %dx%dx%dbpp %s %s, %d bytes\\n\",\n\n                  \"NULL\"/*vf->info->name*/,\n\n                  (mpi->type==MP_IMGTYPE_EXPORT)?\"Exporting\":\n\n                  ((mpi->flags&MP_IMGFLAG_DIRECT)?\"Direct Rendering\":\"Allocating\"),\n\n                  (mpi->flags&MP_IMGFLAG_DRAW_CALLBACK)?\" (slices)\":\"\",\n\n                  mpi->width,mpi->height,mpi->bpp,\n\n                  (mpi->flags&MP_IMGFLAG_YUV)?\"YUV\":((mpi->flags&MP_IMGFLAG_SWAPPED)?\"BGR\":\"RGB\"),\n\n                  (mpi->flags&MP_IMGFLAG_PLANAR)?\"planar\":\"packed\",\n\n                  mpi->bpp*mpi->width*mpi->height/8);\n\n            mp_msg(MSGT_DECVIDEO,MSGL_DBG2,\"(imgfmt: %x, planes: %p,%p,%p strides: %d,%d,%d, chroma: %dx%d, shift: h:%d,v:%d)\\n\",\n\n                mpi->imgfmt, mpi->planes[0], mpi->planes[1], mpi->planes[2],\n\n                mpi->stride[0], mpi->stride[1], mpi->stride[2],\n\n                mpi->chroma_width, mpi->chroma_height, mpi->chroma_x_shift, mpi->chroma_y_shift);\n\n            mpi->flags|=MP_IMGFLAG_TYPE_DISPLAYED;\n\n    }\n\n\n\n  mpi->qscale = NULL;\n\n  }\n\n  mpi->usage_count++;\n\n//    printf(\"\\rVF_MPI: %p %p %p %d %d %d    \\n\",\n\n//      mpi->planes[0],mpi->planes[1],mpi->planes[2],\n\n//      mpi->stride[0],mpi->stride[1],mpi->stride[2]);\n\n  return mpi;\n\n}\n", "idx": 9349, "_split": "test", "_hash": "d3db96ca34e7c699dfd72782e8bf82d5"}
{"project": "FFmpeg", "commit_id": "e630ca5111077fa8adc972fe8a3d7e2b3e8dc91f", "target": 1, "func": "static int parse_MP4SLDescrTag(MP4DescrParseContext *d, int64_t off, int len)\n\n{\n\n    Mp4Descr *descr = d->active_descr;\n\n    int predefined;\n\n    if (!descr)\n\n        return -1;\n\n\n\n    predefined = avio_r8(&d->pb);\n\n    if (!predefined) {\n\n        int lengths;\n\n        int flags = avio_r8(&d->pb);\n\n        descr->sl.use_au_start       = !!(flags & 0x80);\n\n        descr->sl.use_au_end         = !!(flags & 0x40);\n\n        descr->sl.use_rand_acc_pt    = !!(flags & 0x20);\n\n        descr->sl.use_padding        = !!(flags & 0x08);\n\n        descr->sl.use_timestamps     = !!(flags & 0x04);\n\n        descr->sl.use_idle           = !!(flags & 0x02);\n\n        descr->sl.timestamp_res      = avio_rb32(&d->pb);\n\n                                       avio_rb32(&d->pb);\n\n        descr->sl.timestamp_len      = avio_r8(&d->pb);\n\n\n\n\n\n\n        descr->sl.ocr_len            = avio_r8(&d->pb);\n\n        descr->sl.au_len             = avio_r8(&d->pb);\n\n        descr->sl.inst_bitrate_len   = avio_r8(&d->pb);\n\n        lengths                      = avio_rb16(&d->pb);\n\n        descr->sl.degr_prior_len     = lengths >> 12;\n\n        descr->sl.au_seq_num_len     = (lengths >> 7) & 0x1f;\n\n        descr->sl.packet_seq_num_len = (lengths >> 2) & 0x1f;\n\n    } else {\n\n        avpriv_report_missing_feature(d->s, \"Predefined SLConfigDescriptor\");\n\n\n    return 0;\n", "idx": 9351, "_split": "test", "_hash": "0fa46160debc0dd29ddd7314db277f65"}
{"project": "FFmpeg", "commit_id": "ec79b1fc88b2cc6a9ab6cd953efcdbaebedde233", "target": 1, "func": "static int parse_chunks(AVFormatContext *s, int mode, int64_t seekts, int *len_ptr)\n\n{\n\n    WtvContext *wtv = s->priv_data;\n\n    AVIOContext *pb = wtv->pb;\n\n    while (!url_feof(pb)) {\n\n        ff_asf_guid g;\n\n        int len, sid, consumed;\n\n\n\n        ff_get_guid(pb, &g);\n\n        len = avio_rl32(pb);\n\n        if (len < 32)\n\n            break;\n\n        sid = avio_rl32(pb) & 0x7FFF;\n\n        avio_skip(pb, 8);\n\n        consumed = 32;\n\n\n\n        if (!ff_guidcmp(g, ff_SBE2_STREAM_DESC_EVENT)) {\n\n            if (ff_find_stream_index(s, sid) < 0) {\n\n                ff_asf_guid mediatype, subtype, formattype;\n\n                int size;\n\n                avio_skip(pb, 28);\n\n                ff_get_guid(pb, &mediatype);\n\n                ff_get_guid(pb, &subtype);\n\n                avio_skip(pb, 12);\n\n                ff_get_guid(pb, &formattype);\n\n                size = avio_rl32(pb);\n\n                parse_media_type(s, 0, sid, mediatype, subtype, formattype, size);\n\n                consumed += 92 + size;\n\n            }\n\n        } else if (!ff_guidcmp(g, ff_stream2_guid)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0 && !((WtvStream*)s->streams[stream_index]->priv_data)->seen_data) {\n\n                ff_asf_guid mediatype, subtype, formattype;\n\n                int size;\n\n                avio_skip(pb, 12);\n\n                ff_get_guid(pb, &mediatype);\n\n                ff_get_guid(pb, &subtype);\n\n                avio_skip(pb, 12);\n\n                ff_get_guid(pb, &formattype);\n\n                size = avio_rl32(pb);\n\n                parse_media_type(s, s->streams[stream_index], sid, mediatype, subtype, formattype, size);\n\n                consumed += 76 + size;\n\n            }\n\n        } else if (!ff_guidcmp(g, EVENTID_AudioDescriptorSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_CtxADescriptorSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_CSDescriptorSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_StreamIDSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_SubtitleSpanningEvent) ||\n\n                   !ff_guidcmp(g, EVENTID_TeletextSpanningEvent)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                AVStream *st = s->streams[stream_index];\n\n                uint8_t buf[258];\n\n                const uint8_t *pbuf = buf;\n\n                int buf_size;\n\n\n\n                avio_skip(pb, 8);\n\n                consumed += 8;\n\n                if (!ff_guidcmp(g, EVENTID_CtxADescriptorSpanningEvent) ||\n\n                    !ff_guidcmp(g, EVENTID_CSDescriptorSpanningEvent)) {\n\n                    avio_skip(pb, 6);\n\n                    consumed += 6;\n\n                }\n\n\n\n                buf_size = FFMIN(len - consumed, sizeof(buf));\n\n                avio_read(pb, buf, buf_size);\n\n                consumed += buf_size;\n\n                ff_parse_mpeg2_descriptor(s, st, 0, &pbuf, buf + buf_size, NULL, 0, 0, NULL);\n\n            }\n\n        } else if (!ff_guidcmp(g, EVENTID_AudioTypeSpanningEvent)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                AVStream *st = s->streams[stream_index];\n\n                int audio_type;\n\n                avio_skip(pb, 8);\n\n                audio_type = avio_r8(pb);\n\n                if (audio_type == 2)\n\n                    st->disposition |= AV_DISPOSITION_HEARING_IMPAIRED;\n\n                else if (audio_type == 3)\n\n                    st->disposition |= AV_DISPOSITION_VISUAL_IMPAIRED;\n\n                consumed += 9;\n\n            }\n\n        } else if (!ff_guidcmp(g, EVENTID_DVBScramblingControlSpanningEvent)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                avio_skip(pb, 12);\n\n                if (avio_rl32(pb))\n\n                    av_log(s, AV_LOG_WARNING, \"DVB scrambled stream detected (st:%d), decoding will likely fail\\n\", stream_index);\n\n                consumed += 16;\n\n            }\n\n        } else if (!ff_guidcmp(g, EVENTID_LanguageSpanningEvent)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                AVStream *st = s->streams[stream_index];\n\n                uint8_t language[4];\n\n                avio_skip(pb, 12);\n\n                avio_read(pb, language, 3);\n\n                if (language[0]) {\n\n                    language[3] = 0;\n\n                    av_dict_set(&st->metadata, \"language\", language, 0);\n\n                    if (!strcmp(language, \"nar\") || !strcmp(language, \"NAR\"))\n\n                        st->disposition |= AV_DISPOSITION_VISUAL_IMPAIRED;\n\n                }\n\n                consumed += 15;\n\n            }\n\n        } else if (!ff_guidcmp(g, ff_timestamp_guid)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0) {\n\n                avio_skip(pb, 8);\n\n                wtv->pts = avio_rl64(pb);\n\n                consumed += 16;\n\n                if (wtv->pts == -1)\n\n                    wtv->pts = AV_NOPTS_VALUE;\n\n                else {\n\n                    wtv->last_valid_pts = wtv->pts;\n\n                    if (wtv->epoch == AV_NOPTS_VALUE || wtv->pts < wtv->epoch)\n\n                        wtv->epoch = wtv->pts;\n\n                if (mode == SEEK_TO_PTS && wtv->pts >= seekts) {\n\n                    avio_skip(pb, WTV_PAD8(len) - consumed);\n\n                    return 0;\n\n                }\n\n                }\n\n            }\n\n        } else if (!ff_guidcmp(g, ff_data_guid)) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (mode == SEEK_TO_DATA && stream_index >= 0 && len > 32 && s->streams[stream_index]->priv_data) {\n\n                WtvStream *wst = s->streams[stream_index]->priv_data;\n\n                wst->seen_data = 1;\n\n                if (len_ptr) {\n\n                    *len_ptr = len;\n\n                }\n\n                return stream_index;\n\n            }\n\n        } else if (!ff_guidcmp(g, /* DSATTRIB_WMDRMProtectionInfo */ (const ff_asf_guid){0x83,0x95,0x74,0x40,0x9D,0x6B,0xEC,0x4E,0xB4,0x3C,0x67,0xA1,0x80,0x1E,0x1A,0x9B})) {\n\n            int stream_index = ff_find_stream_index(s, sid);\n\n            if (stream_index >= 0)\n\n                av_log(s, AV_LOG_WARNING, \"encrypted stream detected (st:%d), decoding will likely fail\\n\", stream_index);\n\n        } else if (\n\n            !ff_guidcmp(g, /* DSATTRIB_CAPTURE_STREAMTIME */ (const ff_asf_guid){0x14,0x56,0x1A,0x0C,0xCD,0x30,0x40,0x4F,0xBC,0xBF,0xD0,0x3E,0x52,0x30,0x62,0x07}) ||\n\n            !ff_guidcmp(g, /* DSATTRIB_PBDATAG_ATTRIBUTE */ (const ff_asf_guid){0x79,0x66,0xB5,0xE0,0xB9,0x12,0xCC,0x43,0xB7,0xDF,0x57,0x8C,0xAA,0x5A,0x7B,0x63}) ||\n\n            !ff_guidcmp(g, /* DSATTRIB_PicSampleSeq */ (const ff_asf_guid){0x02,0xAE,0x5B,0x2F,0x8F,0x7B,0x60,0x4F,0x82,0xD6,0xE4,0xEA,0x2F,0x1F,0x4C,0x99}) ||\n\n            !ff_guidcmp(g, /* DSATTRIB_TRANSPORT_PROPERTIES */ ff_DSATTRIB_TRANSPORT_PROPERTIES) ||\n\n            !ff_guidcmp(g, /* dvr_ms_vid_frame_rep_data */ (const ff_asf_guid){0xCC,0x32,0x64,0xDD,0x29,0xE2,0xDB,0x40,0x80,0xF6,0xD2,0x63,0x28,0xD2,0x76,0x1F}) ||\n\n            !ff_guidcmp(g, /* EVENTID_ChannelChangeSpanningEvent */ (const ff_asf_guid){0xE5,0xC5,0x67,0x90,0x5C,0x4C,0x05,0x42,0x86,0xC8,0x7A,0xFE,0x20,0xFE,0x1E,0xFA}) ||\n\n            !ff_guidcmp(g, /* EVENTID_ChannelInfoSpanningEvent */ (const ff_asf_guid){0x80,0x6D,0xF3,0x41,0x32,0x41,0xC2,0x4C,0xB1,0x21,0x01,0xA4,0x32,0x19,0xD8,0x1B}) ||\n\n            !ff_guidcmp(g, /* EVENTID_ChannelTypeSpanningEvent */ (const ff_asf_guid){0x51,0x1D,0xAB,0x72,0xD2,0x87,0x9B,0x48,0xBA,0x11,0x0E,0x08,0xDC,0x21,0x02,0x43}) ||\n\n            !ff_guidcmp(g, /* EVENTID_PIDListSpanningEvent */ (const ff_asf_guid){0x65,0x8F,0xFC,0x47,0xBB,0xE2,0x34,0x46,0x9C,0xEF,0xFD,0xBF,0xE6,0x26,0x1D,0x5C}) ||\n\n            !ff_guidcmp(g, /* EVENTID_SignalAndServiceStatusSpanningEvent */ (const ff_asf_guid){0xCB,0xC5,0x68,0x80,0x04,0x3C,0x2B,0x49,0xB4,0x7D,0x03,0x08,0x82,0x0D,0xCE,0x51}) ||\n\n            !ff_guidcmp(g, /* EVENTID_StreamTypeSpanningEvent */ (const ff_asf_guid){0xBC,0x2E,0xAF,0x82,0xA6,0x30,0x64,0x42,0xA8,0x0B,0xAD,0x2E,0x13,0x72,0xAC,0x60}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x1E,0xBE,0xC3,0xC5,0x43,0x92,0xDC,0x11,0x85,0xE5,0x00,0x12,0x3F,0x6F,0x73,0xB9}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x3B,0x86,0xA2,0xB1,0xEB,0x1E,0xC3,0x44,0x8C,0x88,0x1C,0xA3,0xFF,0xE3,0xE7,0x6A}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x4E,0x7F,0x4C,0x5B,0xC4,0xD0,0x38,0x4B,0xA8,0x3E,0x21,0x7F,0x7B,0xBF,0x52,0xE7}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x63,0x36,0xEB,0xFE,0xA1,0x7E,0xD9,0x11,0x83,0x08,0x00,0x07,0xE9,0x5E,0xAD,0x8D}) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0x70,0xE9,0xF1,0xF8,0x89,0xA4,0x4C,0x4D,0x83,0x73,0xB8,0x12,0xE0,0xD5,0xF8,0x1E}) ||\n\n            !ff_guidcmp(g, ff_index_guid) ||\n\n            !ff_guidcmp(g, ff_sync_guid) ||\n\n            !ff_guidcmp(g, ff_stream1_guid) ||\n\n            !ff_guidcmp(g, (const ff_asf_guid){0xF7,0x10,0x02,0xB9,0xEE,0x7C,0xED,0x4E,0xBD,0x7F,0x05,0x40,0x35,0x86,0x18,0xA1})) {\n\n            //ignore known guids\n\n        } else\n\n            av_log(s, AV_LOG_WARNING, \"unsupported chunk:\"FF_PRI_GUID\"\\n\", FF_ARG_GUID(g));\n\n\n\n        avio_skip(pb, WTV_PAD8(len) - consumed);\n\n    }\n\n    return AVERROR_EOF;\n\n}\n", "idx": 9366, "_split": "test", "_hash": "d0a6f134b70bffdc6402ba61be0e9367"}
{"project": "FFmpeg", "commit_id": "6f7f2396049575fcf2054b4dafa19ca01381638e", "target": 1, "func": "static int nut_read_header(AVFormatContext * avf, AVFormatParameters * ap) {\n\n    NUTContext * priv = avf->priv_data;\n\n    AVIOContext * bc = avf->pb;\n\n    nut_demuxer_opts_tt dopts = {\n\n        .input = {\n\n            .priv = bc,\n\n            .seek = av_seek,\n\n            .read = av_read,\n\n            .eof = NULL,\n\n            .file_pos = 0,\n\n        },\n\n        .alloc = { av_malloc, av_realloc, av_free },\n\n        .read_index = 1,\n\n        .cache_syncpoints = 1,\n\n    };\n\n    nut_context_tt * nut = priv->nut = nut_demuxer_init(&dopts);\n\n    nut_stream_header_tt * s;\n\n    int ret, i;\n\n\n\n    if ((ret = nut_read_headers(nut, &s, NULL))) {\n\n        av_log(avf, AV_LOG_ERROR, \" NUT error: %s\\n\", nut_error(ret));\n\n\n        return -1;\n\n\n\n\n    priv->s = s;\n\n\n\n    for (i = 0; s[i].type != -1 && i < 2; i++) {\n\n        AVStream * st = avformat_new_stream(avf, NULL);\n\n        int j;\n\n\n\n        for (j = 0; j < s[i].fourcc_len && j < 8; j++) st->codec->codec_tag |= s[i].fourcc[j]<<(j*8);\n\n\n\n        st->codec->has_b_frames = s[i].decode_delay;\n\n\n\n        st->codec->extradata_size = s[i].codec_specific_len;\n\n        if (st->codec->extradata_size) {\n\n            st->codec->extradata = av_mallocz(st->codec->extradata_size);\n\n\n\n\n\n            memcpy(st->codec->extradata, s[i].codec_specific, st->codec->extradata_size);\n\n\n\n\n        avpriv_set_pts_info(avf->streams[i], 60, s[i].time_base.num, s[i].time_base.den);\n\n        st->start_time = 0;\n\n        st->duration = s[i].max_pts;\n\n\n\n        st->codec->codec_id = ff_codec_get_id(nut_tags, st->codec->codec_tag);\n\n\n\n        switch(s[i].type) {\n\n        case NUT_AUDIO_CLASS:\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n            if (st->codec->codec_id == CODEC_ID_NONE) st->codec->codec_id = ff_codec_get_id(ff_codec_wav_tags, st->codec->codec_tag);\n\n\n\n            st->codec->channels = s[i].channel_count;\n\n            st->codec->sample_rate = s[i].samplerate_num / s[i].samplerate_denom;\n\n            break;\n\n        case NUT_VIDEO_CLASS:\n\n            st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n            if (st->codec->codec_id == CODEC_ID_NONE) st->codec->codec_id = ff_codec_get_id(ff_codec_bmp_tags, st->codec->codec_tag);\n\n\n\n            st->codec->width = s[i].width;\n\n            st->codec->height = s[i].height;\n\n            st->sample_aspect_ratio.num = s[i].sample_width;\n\n            st->sample_aspect_ratio.den = s[i].sample_height;\n\n            break;\n\n\n        if (st->codec->codec_id == CODEC_ID_NONE) av_log(avf, AV_LOG_ERROR, \"Unknown codec?!\\n\");\n\n\n\n\n    return 0;\n", "idx": 9435, "_split": "test", "_hash": "dc6eab14f243b1336c7af0d5ccdad82e"}
{"project": "FFmpeg", "commit_id": "842e98b4d83d8cf297e2bc2761f1f47eb89e49e4", "target": 0, "func": "static int parse_object_segment(AVCodecContext *avctx,\n\n                                  const uint8_t *buf, int buf_size)\n\n{\n\n    PGSSubContext *ctx = avctx->priv_data;\n\n    PGSSubObject *object;\n\n\n\n    uint8_t sequence_desc;\n\n    unsigned int rle_bitmap_len, width, height;\n\n    int id;\n\n\n\n    if (buf_size <= 4)\n\n        return AVERROR_INVALIDDATA;\n\n    buf_size -= 4;\n\n\n\n    id = bytestream_get_be16(&buf);\n\n    object = find_object(id, &ctx->objects);\n\n    if (!object) {\n\n        if (ctx->objects.count >= MAX_EPOCH_OBJECTS) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Too many objects in epoch\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        object = &ctx->objects.object[ctx->objects.count++];\n\n        object->id = id;\n\n    }\n\n\n\n    /* skip object version number */\n\n    buf += 1;\n\n\n\n    /* Read the Sequence Description to determine if start of RLE data or appended to previous RLE */\n\n    sequence_desc = bytestream_get_byte(&buf);\n\n\n\n    if (!(sequence_desc & 0x80)) {\n\n        /* Additional RLE data */\n\n        if (buf_size > object->rle_remaining_len)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        memcpy(object->rle + object->rle_data_len, buf, buf_size);\n\n        object->rle_data_len += buf_size;\n\n        object->rle_remaining_len -= buf_size;\n\n\n\n        return 0;\n\n    }\n\n\n\n    if (buf_size <= 7)\n\n        return AVERROR_INVALIDDATA;\n\n    buf_size -= 7;\n\n\n\n    /* Decode rle bitmap length, stored size includes width/height data */\n\n    rle_bitmap_len = bytestream_get_be24(&buf) - 2*2;\n\n\n\n    if (buf_size > rle_bitmap_len) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Buffer dimension %d larger than the expected RLE data %d\\n\",\n\n               buf_size, rle_bitmap_len);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* Get bitmap dimensions from data */\n\n    width  = bytestream_get_be16(&buf);\n\n    height = bytestream_get_be16(&buf);\n\n\n\n    /* Make sure the bitmap is not too large */\n\n    if (avctx->width < width || avctx->height < height || !width || !height) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Bitmap dimensions (%dx%d) invalid.\\n\", width, height);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    object->w = width;\n\n    object->h = height;\n\n\n\n    av_fast_padded_malloc(&object->rle, &object->rle_buffer_size, rle_bitmap_len);\n\n\n\n    if (!object->rle)\n\n        return AVERROR(ENOMEM);\n\n\n\n    memcpy(object->rle, buf, buf_size);\n\n    object->rle_data_len = buf_size;\n\n    object->rle_remaining_len = rle_bitmap_len - buf_size;\n\n\n\n    return 0;\n\n}\n", "idx": 9482, "_split": "test", "_hash": "bbaaf36fbfed5cbb17cba2cb3987644a"}
{"project": "FFmpeg", "commit_id": "a0e5f7f363555d2befafb1c9e1579dbe0a2fbca7", "target": 1, "func": "static inline void mv_pred_direct(AVSContext *h, cavs_vector *pmv_fw,\n\n                                  cavs_vector *col_mv)\n\n{\n\n    cavs_vector *pmv_bw = pmv_fw + MV_BWD_OFFS;\n\n    int den = h->direct_den[col_mv->ref];\n\n    int m = FF_SIGNBIT(col_mv->x);\n\n\n\n    pmv_fw->dist = h->dist[1];\n\n    pmv_bw->dist = h->dist[0];\n\n    pmv_fw->ref = 1;\n\n    pmv_bw->ref = 0;\n\n    /* scale the co-located motion vector according to its temporal span */\n\n    pmv_fw->x =     (((den + (den * col_mv->x * pmv_fw->dist ^ m) - m - 1) >> 14) ^ m) - m;\n\n    pmv_bw->x = m - (((den + (den * col_mv->x * pmv_bw->dist ^ m) - m - 1) >> 14) ^ m);\n\n    m = FF_SIGNBIT(col_mv->y);\n\n    pmv_fw->y =     (((den + (den * col_mv->y * pmv_fw->dist ^ m) - m - 1) >> 14) ^ m) - m;\n\n    pmv_bw->y = m - (((den + (den * col_mv->y * pmv_bw->dist ^ m) - m - 1) >> 14) ^ m);\n\n}\n", "idx": 9528, "_split": "test", "_hash": "4c3ce889d36d9b92ff1465115228362b"}
{"project": "FFmpeg", "commit_id": "22fa38f0c85fb31cddbb0bc22a2df5953c702b95", "target": 0, "func": "static inline void h264_deblock_q1(register vector unsigned char p0,\n\n                                                   register vector unsigned char p1,\n\n                                                   register vector unsigned char p2,\n\n                                                   register vector unsigned char q0,\n\n                                                   register vector unsigned char tc0) {\n\n\n\n    register vector unsigned char average = vec_avg(p0, q0);\n\n    register vector unsigned char temp;\n\n    register vector unsigned char uncliped;\n\n    register vector unsigned char ones;\n\n    register vector unsigned char max;\n\n    register vector unsigned char min;\n\n\n\n    temp = vec_xor(average, p2);\n\n    average = vec_avg(average, p2);     /*avg(p2, avg(p0, q0)) */\n\n    ones = vec_splat_u8(1);\n\n    temp = vec_and(temp, ones);         /*(p2^avg(p0, q0)) & 1 */\n\n    uncliped = vec_subs(average, temp); /*(p2+((p0+q0+1)>>1))>>1 */\n\n    max = vec_adds(p1, tc0);\n\n    min = vec_subs(p1, tc0);\n\n    p1 = vec_max(min, uncliped);\n\n    p1 = vec_min(max, p1);\n\n}\n", "idx": 9533, "_split": "test", "_hash": "c2716f7d57fa02d5d589f1d4f885474f"}
{"project": "FFmpeg", "commit_id": "bd8ae4885b905415f0e86d4e348c4b72be81e6e6", "target": 0, "func": "AVFilterFormats *avfilter_all_colorspaces(void)\n\n{\n\n    return avfilter_make_format_list(35,\n\n                PIX_FMT_YUV444P,  PIX_FMT_YUV422P,  PIX_FMT_YUV420P,\n\n                PIX_FMT_YUV411P,  PIX_FMT_YUV410P,\n\n                PIX_FMT_YUYV422,  PIX_FMT_UYVY422,  PIX_FMT_UYYVYY411,\n\n                PIX_FMT_YUVJ444P, PIX_FMT_YUVJ422P, PIX_FMT_YUVJ420P,\n\n                PIX_FMT_YUV440P,  PIX_FMT_YUVJ440P,\n\n                PIX_FMT_RGB32,    PIX_FMT_BGR32,\n\n                PIX_FMT_RGB32_1,  PIX_FMT_BGR32_1,\n\n                PIX_FMT_RGB24,    PIX_FMT_BGR24,\n\n                PIX_FMT_RGB565,   PIX_FMT_BGR565,\n\n                PIX_FMT_RGB555,   PIX_FMT_BGR555,\n\n                PIX_FMT_RGB8,     PIX_FMT_BGR8,\n\n                PIX_FMT_RGB4_BYTE,PIX_FMT_BGR4_BYTE,\n\n                PIX_FMT_GRAY16BE, PIX_FMT_GRAY16LE,\n\n                PIX_FMT_GRAY8,    PIX_FMT_PAL8,\n\n                PIX_FMT_MONOWHITE,PIX_FMT_MONOBLACK\n\n                PIX_FMT_NV12,     PIX_FMT_NV21);\n\n}\n", "idx": 9576, "_split": "test", "_hash": "a6d554e5979fc20e70a8083492f210ff"}
{"project": "FFmpeg", "commit_id": "a744064c4155bde063b9e8a47699542be3b8e5eb", "target": 1, "func": "static void free_geotags(TiffContext *const s)\n\n{\n\n    int i;\n\n    for (i = 0; i < s->geotag_count; i++) {\n\n        if (s->geotags[i].val)\n\n            av_freep(&s->geotags[i].val);\n\n    }\n\n    av_freep(&s->geotags);\n\n\n}", "idx": 9598, "_split": "test", "_hash": "d8c57fa4ae53b70cb9b048234fbd0349"}
{"project": "FFmpeg", "commit_id": "c3afa4db913668e50ac8ffc0bc66621664adc1f4", "target": 1, "func": "void ff_bink_idct_c(DCTELEM *block)\n\n{\n\n    int i;\n\n    DCTELEM temp[64];\n\n\n\n    for (i = 0; i < 8; i++)\n\n        bink_idct_col(&temp[i], &block[i]);\n\n    for (i = 0; i < 8; i++) {\n\n        IDCT_ROW( (&block[8*i]), (&temp[8*i]) );\n\n    }\n\n}\n", "idx": 9607, "_split": "test", "_hash": "394a4f08ac48ea2f2003877118bb234a"}
{"project": "FFmpeg", "commit_id": "461cd5bfb5c38e48a81b4a9a5912dfd65da1ba3d", "target": 0, "func": "void mpeg1_encode_mb(MpegEncContext *s,\n\n                     DCTELEM block[6][64],\n\n                     int motion_x, int motion_y)\n\n{\n\n    int i, cbp;\n\n    const int mb_x = s->mb_x;\n\n    const int mb_y = s->mb_y;\n\n    const int first_mb= mb_x == s->resync_mb_x && mb_y == s->resync_mb_y;\n\n\n\n    /* compute cbp */\n\n    cbp = 0;\n\n    for(i=0;i<6;i++) {\n\n        if (s->block_last_index[i] >= 0)\n\n            cbp |= 1 << (5 - i);\n\n    }\n\n    \n\n    if (cbp == 0 && !first_mb && (mb_x != s->mb_width - 1 || (mb_y != s->mb_height - 1 && s->codec_id == CODEC_ID_MPEG1VIDEO)) && \n\n        ((s->pict_type == P_TYPE && s->mv_type == MV_TYPE_16X16 && (motion_x | motion_y) == 0) ||\n\n        (s->pict_type == B_TYPE && s->mv_dir == s->last_mv_dir && (((s->mv_dir & MV_DIR_FORWARD) ? ((s->mv[0][0][0] - s->last_mv[0][0][0])|(s->mv[0][0][1] - s->last_mv[0][0][1])) : 0) |\n\n        ((s->mv_dir & MV_DIR_BACKWARD) ? ((s->mv[1][0][0] - s->last_mv[1][0][0])|(s->mv[1][0][1] - s->last_mv[1][0][1])) : 0)) == 0))) {\n\n        s->mb_skip_run++;\n\n        s->qscale -= s->dquant;\n\n        s->skip_count++;\n\n        s->misc_bits++;\n\n        s->last_bits++;\n\n        if(s->pict_type == P_TYPE){\n\n            s->last_mv[0][1][0]= s->last_mv[0][0][0]= \n\n            s->last_mv[0][1][1]= s->last_mv[0][0][1]= 0;\n\n        }\n\n    } else {\n\n        if(first_mb){\n\n            assert(s->mb_skip_run == 0);\n\n            encode_mb_skip_run(s, s->mb_x);\n\n        }else{\n\n            encode_mb_skip_run(s, s->mb_skip_run);\n\n        }\n\n        \n\n        if (s->pict_type == I_TYPE) {\n\n            if(s->dquant && cbp){\n\n                put_mb_modes(s, 2, 1, 0, 0); /* macroblock_type : macroblock_quant = 1 */\n\n                put_bits(&s->pb, 5, s->qscale);\n\n            }else{\n\n                put_mb_modes(s, 1, 1, 0, 0); /* macroblock_type : macroblock_quant = 0 */\n\n                s->qscale -= s->dquant;\n\n            }\n\n            s->misc_bits+= get_bits_diff(s);\n\n            s->i_count++;\n\n        } else if (s->mb_intra) {\n\n            if(s->dquant && cbp){\n\n                put_mb_modes(s, 6, 0x01, 0, 0);\n\n                put_bits(&s->pb, 5, s->qscale);\n\n            }else{\n\n                put_mb_modes(s, 5, 0x03, 0, 0);\n\n                s->qscale -= s->dquant;\n\n            }\n\n            s->misc_bits+= get_bits_diff(s);\n\n            s->i_count++;\n\n            memset(s->last_mv, 0, sizeof(s->last_mv));\n\n        } else if (s->pict_type == P_TYPE) { \n\n            if(s->mv_type == MV_TYPE_16X16){\n\n                if (cbp != 0) {\n\n                    if ((motion_x|motion_y) == 0) {\n\n                        if(s->dquant){\n\n                            put_mb_modes(s, 5, 1, 0, 0); /* macroblock_pattern & quant */\n\n                            put_bits(&s->pb, 5, s->qscale);\n\n                        }else{\n\n                            put_mb_modes(s, 2, 1, 0, 0); /* macroblock_pattern only */\n\n                        }\n\n                        s->misc_bits+= get_bits_diff(s);\n\n                    } else {\n\n                        if(s->dquant){\n\n                            put_mb_modes(s, 5, 2, 1, 0); /* motion + cbp */\n\n                            put_bits(&s->pb, 5, s->qscale);\n\n                        }else{\n\n                            put_mb_modes(s, 1, 1, 1, 0); /* motion + cbp */\n\n                        }\n\n                        s->misc_bits+= get_bits_diff(s);\n\n                        mpeg1_encode_motion(s, motion_x - s->last_mv[0][0][0], s->f_code);    // RAL: f_code parameter added\n\n                        mpeg1_encode_motion(s, motion_y - s->last_mv[0][0][1], s->f_code);    // RAL: f_code parameter added\n\n                        s->mv_bits+= get_bits_diff(s);\n\n                    }\n\n                } else {\n\n                    put_bits(&s->pb, 3, 1); /* motion only */\n\n                    if (!s->frame_pred_frame_dct)\n\n                        put_bits(&s->pb, 2, 2); /* motion_type: frame */\n\n                    s->misc_bits+= get_bits_diff(s);\n\n                    mpeg1_encode_motion(s, motion_x - s->last_mv[0][0][0], s->f_code);    // RAL: f_code parameter added\n\n                    mpeg1_encode_motion(s, motion_y - s->last_mv[0][0][1], s->f_code);    // RAL: f_code parameter added\n\n                    s->qscale -= s->dquant;\n\n                    s->mv_bits+= get_bits_diff(s);\n\n                }\n\n                s->last_mv[0][1][0]= s->last_mv[0][0][0]= motion_x;\n\n                s->last_mv[0][1][1]= s->last_mv[0][0][1]= motion_y;\n\n            }else{\n\n                assert(!s->frame_pred_frame_dct && s->mv_type == MV_TYPE_FIELD);\n\n\n\n                if (cbp) {\n\n                    if(s->dquant){\n\n                        put_mb_modes(s, 5, 2, 1, 1); /* motion + cbp */\n\n                        put_bits(&s->pb, 5, s->qscale);\n\n                    }else{\n\n                        put_mb_modes(s, 1, 1, 1, 1); /* motion + cbp */\n\n                    }\n\n                } else {\n\n                    put_bits(&s->pb, 3, 1); /* motion only */\n\n                    put_bits(&s->pb, 2, 1); /* motion_type: field */\n\n                    s->qscale -= s->dquant;\n\n                }\n\n                s->misc_bits+= get_bits_diff(s);\n\n                for(i=0; i<2; i++){\n\n                    put_bits(&s->pb, 1, s->field_select[0][i]);\n\n                    mpeg1_encode_motion(s, s->mv[0][i][0] -  s->last_mv[0][i][0]    , s->f_code);\n\n                    mpeg1_encode_motion(s, s->mv[0][i][1] - (s->last_mv[0][i][1]>>1), s->f_code);\n\n                    s->last_mv[0][i][0]=   s->mv[0][i][0];\n\n                    s->last_mv[0][i][1]= 2*s->mv[0][i][1];\n\n                }\n\n                s->mv_bits+= get_bits_diff(s);\n\n            }\n\n            if(cbp)\n\n                put_bits(&s->pb, mbPatTable[cbp - 1][1], mbPatTable[cbp - 1][0]);\n\n            s->f_count++;\n\n        } else{  \n\n            static const int mb_type_len[4]={0,3,4,2}; //bak,for,bi\n\n\n\n            if(s->mv_type == MV_TYPE_16X16){\n\n                if (cbp){    // With coded bloc pattern\n\n                    if (s->dquant) {\n\n                        if(s->mv_dir == MV_DIR_FORWARD)\n\n                            put_mb_modes(s, 6, 3, 1, 0);\n\n                        else\n\n                            put_mb_modes(s, mb_type_len[s->mv_dir]+3, 2, 1, 0);\n\n                        put_bits(&s->pb, 5, s->qscale);\n\n                    } else {\n\n                        put_mb_modes(s, mb_type_len[s->mv_dir], 3, 1, 0);\n\n                    }\n\n                }else{    // No coded bloc pattern\n\n                    put_bits(&s->pb, mb_type_len[s->mv_dir], 2);\n\n                    if (!s->frame_pred_frame_dct)\n\n                        put_bits(&s->pb, 2, 2); /* motion_type: frame */\n\n                    s->qscale -= s->dquant;\n\n                }\n\n                s->misc_bits += get_bits_diff(s);\n\n                if (s->mv_dir&MV_DIR_FORWARD){\n\n                    mpeg1_encode_motion(s, s->mv[0][0][0] - s->last_mv[0][0][0], s->f_code); \n\n                    mpeg1_encode_motion(s, s->mv[0][0][1] - s->last_mv[0][0][1], s->f_code); \n\n                    s->last_mv[0][0][0]=s->last_mv[0][1][0]= s->mv[0][0][0];\n\n                    s->last_mv[0][0][1]=s->last_mv[0][1][1]= s->mv[0][0][1];\n\n                    s->f_count++;\n\n                }\n\n                if (s->mv_dir&MV_DIR_BACKWARD){\n\n                    mpeg1_encode_motion(s, s->mv[1][0][0] - s->last_mv[1][0][0], s->b_code); \n\n                    mpeg1_encode_motion(s, s->mv[1][0][1] - s->last_mv[1][0][1], s->b_code); \n\n                    s->last_mv[1][0][0]=s->last_mv[1][1][0]= s->mv[1][0][0];\n\n                    s->last_mv[1][0][1]=s->last_mv[1][1][1]= s->mv[1][0][1];\n\n                    s->b_count++;\n\n                }\n\n            }else{\n\n                assert(s->mv_type == MV_TYPE_FIELD);\n\n                assert(!s->frame_pred_frame_dct);\n\n                if (cbp){    // With coded bloc pattern\n\n                    if (s->dquant) {\n\n                        if(s->mv_dir == MV_DIR_FORWARD)\n\n                            put_mb_modes(s, 6, 3, 1, 1);\n\n                        else\n\n                            put_mb_modes(s, mb_type_len[s->mv_dir]+3, 2, 1, 1);\n\n                        put_bits(&s->pb, 5, s->qscale);\n\n                    } else {\n\n                        put_mb_modes(s, mb_type_len[s->mv_dir], 3, 1, 1);\n\n                    }\n\n                }else{    // No coded bloc pattern\n\n                    put_bits(&s->pb, mb_type_len[s->mv_dir], 2);\n\n                    put_bits(&s->pb, 2, 1); /* motion_type: field */\n\n                    s->qscale -= s->dquant;\n\n                }\n\n                s->misc_bits += get_bits_diff(s);\n\n                if (s->mv_dir&MV_DIR_FORWARD){\n\n                    for(i=0; i<2; i++){\n\n                        put_bits(&s->pb, 1, s->field_select[0][i]);\n\n                        mpeg1_encode_motion(s, s->mv[0][i][0] -  s->last_mv[0][i][0]    , s->f_code);\n\n                        mpeg1_encode_motion(s, s->mv[0][i][1] - (s->last_mv[0][i][1]>>1), s->f_code);\n\n                        s->last_mv[0][i][0]=   s->mv[0][i][0];\n\n                        s->last_mv[0][i][1]= 2*s->mv[0][i][1];\n\n                    }\n\n                    s->f_count++;\n\n                }\n\n                if (s->mv_dir&MV_DIR_BACKWARD){\n\n                    for(i=0; i<2; i++){\n\n                        put_bits(&s->pb, 1, s->field_select[1][i]);\n\n                        mpeg1_encode_motion(s, s->mv[1][i][0] -  s->last_mv[1][i][0]    , s->b_code);\n\n                        mpeg1_encode_motion(s, s->mv[1][i][1] - (s->last_mv[1][i][1]>>1), s->b_code);\n\n                        s->last_mv[1][i][0]=   s->mv[1][i][0];\n\n                        s->last_mv[1][i][1]= 2*s->mv[1][i][1];\n\n                    }\n\n                    s->b_count++;\n\n                }\n\n            }\n\n            s->mv_bits += get_bits_diff(s);\n\n            if(cbp)\n\n                put_bits(&s->pb, mbPatTable[cbp - 1][1], mbPatTable[cbp - 1][0]);\n\n        }\n\n        for(i=0;i<6;i++) {\n\n            if (cbp & (1 << (5 - i))) {\n\n                mpeg1_encode_block(s, block[i], i);\n\n            }\n\n        }\n\n        s->mb_skip_run = 0;\n\n        if(s->mb_intra)\n\n            s->i_tex_bits+= get_bits_diff(s);\n\n        else\n\n            s->p_tex_bits+= get_bits_diff(s);\n\n    }\n\n}\n", "idx": 9727, "_split": "test", "_hash": "c02d3d35f84d51915f4eecbb25722c9e"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(rgb24tobgr24)(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tunsigned i;\n\n#ifdef HAVE_MMX\n\n\tlong mmx_size= 23 - src_size;\n\n\tasm volatile (\n\n\t\t\"test %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\n\n\t\t\"jns 2f\t\t\t\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(mask24r)\", %%mm5\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(mask24g)\", %%mm6\t\\n\\t\"\n\n\t\t\"movq \"MANGLE(mask24b)\", %%mm7\t\\n\\t\"\n\n\t\tASMALIGN(4)\n\n\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\tPREFETCH\" 32(%1, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\"movq   (%1, %%\"REG_a\"), %%mm0\t\\n\\t\" // BGR BGR BG\n\n\t\t\"movq   (%1, %%\"REG_a\"), %%mm1\t\\n\\t\" // BGR BGR BG\n\n\t\t\"movq  2(%1, %%\"REG_a\"), %%mm2\t\\n\\t\" // R BGR BGR B\n\n\t\t\"psllq $16, %%mm0\t\t\\n\\t\" // 00 BGR BGR\n\n\t\t\"pand %%mm5, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm6, %%mm1\t\t\\n\\t\"\n\n\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\"por %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"por %%mm2, %%mm1\t\t\\n\\t\"\n\n\t\t\"movq  6(%1, %%\"REG_a\"), %%mm0\t\\n\\t\" // BGR BGR BG\n\n\t\tMOVNTQ\" %%mm1,   (%2, %%\"REG_a\")\\n\\t\" // RGB RGB RG\n\n\t\t\"movq  8(%1, %%\"REG_a\"), %%mm1\t\\n\\t\" // R BGR BGR B\n\n\t\t\"movq 10(%1, %%\"REG_a\"), %%mm2\t\\n\\t\" // GR BGR BGR\n\n\t\t\"pand %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm5, %%mm1\t\t\\n\\t\"\n\n\t\t\"pand %%mm6, %%mm2\t\t\\n\\t\"\n\n\t\t\"por %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"por %%mm2, %%mm1\t\t\\n\\t\"\n\n\t\t\"movq 14(%1, %%\"REG_a\"), %%mm0\t\\n\\t\" // R BGR BGR B\n\n\t\tMOVNTQ\" %%mm1,  8(%2, %%\"REG_a\")\\n\\t\" // B RGB RGB R\n\n\t\t\"movq 16(%1, %%\"REG_a\"), %%mm1\t\\n\\t\" // GR BGR BGR\n\n\t\t\"movq 18(%1, %%\"REG_a\"), %%mm2\t\\n\\t\" // BGR BGR BG\n\n\t\t\"pand %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\"pand %%mm7, %%mm1\t\t\\n\\t\"\n\n\t\t\"pand %%mm5, %%mm2\t\t\\n\\t\"\n\n\t\t\"por %%mm0, %%mm1\t\t\\n\\t\"\n\n\t\t\"por %%mm2, %%mm1\t\t\\n\\t\"\n\n\t\tMOVNTQ\" %%mm1, 16(%2, %%\"REG_a\")\\n\\t\"\n\n\t\t\"add $24, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t\"2:\t\t\t\t\\n\\t\"\n\n\t\t: \"+a\" (mmx_size)\n\n\t\t: \"r\" (src-mmx_size), \"r\"(dst-mmx_size)\n\n\t);\n\n\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n\n\n\tif(mmx_size==23) return; //finihsed, was multiple of 8\n\n\n\n\tsrc+= src_size;\n\n\tdst+= src_size;\n\n\tsrc_size= 23-mmx_size;\n\n\tsrc-= src_size;\n\n\tdst-= src_size;\n\n#endif\n\n\tfor(i=0; i<src_size; i+=3)\n\n\t{\n\n\t\tregister uint8_t x;\n\n\t\tx          = src[i + 2];\n\n\t\tdst[i + 1] = src[i + 1];\n\n\t\tdst[i + 2] = src[i + 0];\n\n\t\tdst[i + 0] = x;\n\n\t}\n\n}\n", "idx": 9761, "_split": "test", "_hash": "b1cf7b4a8d72085e5625fcc965c22ee5"}
{"project": "FFmpeg", "commit_id": "ffd7fd79441f97f1edb25181af0603ff6ea9b342", "target": 1, "func": "static int vda_h264_end_frame(AVCodecContext *avctx)\n{\n    H264Context *h                      = avctx->priv_data;\n    struct vda_context *vda_ctx         = avctx->hwaccel_context;\n    AVFrame *frame                      = &h->cur_pic_ptr->f;\n    struct vda_buffer *context;\n    AVBufferRef *buffer;\n    int status;\n    if (!vda_ctx->decoder || !vda_ctx->priv_bitstream)\n    status = vda_sync_decode(vda_ctx);\n    frame->data[3] = (void*)vda_ctx->cv_buffer;\n    if (status)\n        av_log(avctx, AV_LOG_ERROR, \"Failed to decode frame (%d)\\n\", status);", "idx": 9772, "_split": "test", "_hash": "961f9a38a60a865c2b3b21506edd51db"}
{"project": "FFmpeg", "commit_id": "fbaf75b166cd067cf383a75ffcccb1e2b370bf6d", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, void *data,\n\n                        int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    H264Context *h     = avctx->priv_data;\n\n    AVFrame *pict      = data;\n\n    int buf_index      = 0;\n\n    Picture *out;\n\n    int i, out_idx;\n\n    int ret;\n\n\n\n    h->flags  = avctx->flags;\n\n\n\n    /* end of stream, output what is still in the buffers */\n\n    if (buf_size == 0) {\n\n out:\n\n\n\n        h->cur_pic_ptr = NULL;\n\n        h->first_field = 0;\n\n\n\n        // FIXME factorize this with the output code below\n\n        out     = h->delayed_pic[0];\n\n        out_idx = 0;\n\n        for (i = 1;\n\n             h->delayed_pic[i] &&\n\n             !h->delayed_pic[i]->f.key_frame &&\n\n             !h->delayed_pic[i]->mmco_reset;\n\n             i++)\n\n            if (h->delayed_pic[i]->poc < out->poc) {\n\n                out     = h->delayed_pic[i];\n\n                out_idx = i;\n\n            }\n\n\n\n        for (i = out_idx; h->delayed_pic[i]; i++)\n\n            h->delayed_pic[i] = h->delayed_pic[i + 1];\n\n\n\n        if (out) {\n\n            out->reference &= ~DELAYED_PIC_REF;\n\n            ret = output_frame(h, pict, &out->f);\n\n            if (ret < 0)\n\n                return ret;\n\n            *got_frame = 1;\n\n        }\n\n\n\n        return buf_index;\n\n    }\n\n    if(h->is_avc && buf_size >= 9 && buf[0]==1 && buf[2]==0 && (buf[4]&0xFC)==0xFC && (buf[5]&0x1F) && buf[8]==0x67){\n\n        int cnt= buf[5]&0x1f;\n\n        const uint8_t *p= buf+6;\n\n        while(cnt--){\n\n            int nalsize= AV_RB16(p) + 2;\n\n            if(nalsize > buf_size - (p-buf) || p[2]!=0x67)\n\n                goto not_extra;\n\n            p += nalsize;\n\n        }\n\n        cnt = *(p++);\n\n        if(!cnt)\n\n            goto not_extra;\n\n        while(cnt--){\n\n            int nalsize= AV_RB16(p) + 2;\n\n            if(nalsize > buf_size - (p-buf) || p[2]!=0x68)\n\n                goto not_extra;\n\n            p += nalsize;\n\n        }\n\n\n\n        return ff_h264_decode_extradata(h, buf, buf_size);\n\n    }\n\nnot_extra:\n\n\n\n    buf_index = decode_nal_units(h, buf, buf_size, 0);\n\n    if (buf_index < 0)\n\n        return -1;\n\n\n\n    if (!h->cur_pic_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {\n\n        av_assert0(buf_index <= buf_size);\n\n        goto out;\n\n    }\n\n\n\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS) && !h->cur_pic_ptr) {\n\n        if (avctx->skip_frame >= AVDISCARD_NONREF ||\n\n            buf_size >= 4 && !memcmp(\"Q264\", buf, 4))\n\n            return buf_size;\n\n        av_log(avctx, AV_LOG_ERROR, \"no frame!\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (!(avctx->flags2 & CODEC_FLAG2_CHUNKS) ||\n\n        (h->mb_y >= h->mb_height && h->mb_height)) {\n\n        if (avctx->flags2 & CODEC_FLAG2_CHUNKS)\n\n            decode_postinit(h, 1);\n\n\n\n        field_end(h, 0);\n\n\n\n        /* Wait for second field. */\n\n        *got_frame = 0;\n\n        if (h->next_output_pic && (h->next_output_pic->sync || h->sync>1)) {\n\n            ret = output_frame(h, pict, &h->next_output_pic->f);\n\n            if (ret < 0)\n\n                return ret;\n\n            *got_frame = 1;\n\n            if (CONFIG_MPEGVIDEO) {\n\n                ff_print_debug_info2(h->avctx, h->next_output_pic, pict, h->er.mbskip_table,\n\n                                    &h->low_delay,\n\n                                    h->mb_width, h->mb_height, h->mb_stride, 1);\n\n            }\n\n        }\n\n    }\n\n\n\n    assert(pict->data[0] || !*got_frame);\n\n\n\n    return get_consumed_bytes(buf_index, buf_size);\n\n}\n", "idx": 9781, "_split": "test", "_hash": "f3b245f0ae6543e31ca6a7cb66d3572d"}
{"project": "FFmpeg", "commit_id": "22ecfcd4c79cdf812fdf406525ddf0fd1f7114e4", "target": 1, "func": "static int channelmap_query_formats(AVFilterContext *ctx)\n\n{\n\n    ChannelMapContext *s = ctx->priv;\n\n\n\n    ff_set_common_formats(ctx, ff_planar_sample_fmts());\n\n    ff_set_common_samplerates(ctx, ff_all_samplerates());\n\n    ff_channel_layouts_ref(ff_all_channel_layouts(), &ctx->inputs[0]->out_channel_layouts);\n\n    ff_channel_layouts_ref(s->channel_layouts,       &ctx->outputs[0]->in_channel_layouts);\n\n\n\n    return 0;\n\n}\n", "idx": 9789, "_split": "test", "_hash": "562e3b64e51fd10a1a26bb5654de037d"}
{"project": "FFmpeg", "commit_id": "5b0ad91b996506632708dcefc22d2835d04a4dba", "target": 1, "func": "static int img_write_packet(AVFormatContext *s, int stream_index,\n\n                            UINT8 *buf, int size)\n\n{\n\n    VideoData *img = s->priv_data;\n\n    AVStream *st = s->streams[stream_index];\n\n    ByteIOContext pb1, *pb;\n\n    AVPicture picture;\n\n    int width, height, ret, size1;\n\n    char filename[1024];\n\n\n\n    width = st->codec.width;\n\n    height = st->codec.height;\n\n\n\n    switch(st->codec.pix_fmt) {\n\n    case PIX_FMT_YUV420P:\n\n        size1 = (width * height * 3) / 2;\n\n        if (size != size1)\n\n            return -EIO;\n\n        \n\n        picture.data[0] = buf;\n\n        picture.data[1] = picture.data[0] + width * height;\n\n        picture.data[2] = picture.data[1] + (width * height) / 4;\n\n        picture.linesize[0] = width;\n\n        picture.linesize[1] = width >> 1; \n\n        picture.linesize[2] = width >> 1;\n\n        break;\n\n    case PIX_FMT_RGB24:\n\n        size1 = (width * height * 3);\n\n        if (size != size1)\n\n            return -EIO;\n\n        picture.data[0] = buf;\n\n        picture.linesize[0] = width * 3;\n\n        break;\n\n    default:\n\n        return -EIO;\n\n    }\n\n    \n\n    if (get_frame_filename(filename, sizeof(filename), \n\n                           img->path, img->img_number) < 0)\n\n        return -EIO;\n\n\n\n    if (!img->is_pipe) {\n\n        pb = &pb1;\n\n        if (url_fopen(pb, filename, URL_WRONLY) < 0)\n\n            return -EIO;\n\n    } else {\n\n        pb = &s->pb;\n\n    }\n\n    switch(img->img_fmt) {\n\n    case IMGFMT_PGMYUV:\n\n        ret = pgm_save(&picture, width, height, pb, 1);\n\n        break;\n\n    case IMGFMT_PGM:\n\n        ret = pgm_save(&picture, width, height, pb, 0);\n\n        break;\n\n    case IMGFMT_YUV:\n\n        ret = yuv_save(&picture, width, height, filename);\n\n        break;\n\n    case IMGFMT_PPM:\n\n        ret = ppm_save(&picture, width, height, pb);\n\n        break;\n\n    }\n\n    if (!img->is_pipe) {\n\n        url_fclose(pb);\n\n    }\n\n\n\n    img->img_number++;\n\n    return 0;\n\n}\n", "idx": 9842, "_split": "test", "_hash": "66787e8b9fafad6421f85c62666e76df"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline int yv12toyuy2_unscaled_altivec(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,\n\n     int srcSliceH, uint8_t* dstParam[], int dstStride_a[]) {\n\n  uint8_t *dst=dstParam[0] + dstStride_a[0]*srcSliceY;\n\n  // yv12toyuy2( src[0],src[1],src[2],dst,c->srcW,srcSliceH,srcStride[0],srcStride[1],dstStride[0] );\n\n  uint8_t *ysrc = src[0];\n\n  uint8_t *usrc = src[1];\n\n  uint8_t *vsrc = src[2];\n\n  const int width = c->srcW;\n\n  const int height = srcSliceH;\n\n  const int lumStride = srcStride[0];\n\n  const int chromStride = srcStride[1];\n\n  const int dstStride = dstStride_a[0];\n\n  const vector unsigned char yperm = vec_lvsl(0, ysrc);\n\n  const int vertLumPerChroma = 2;\n\n  register unsigned int y;\n\n\n\n  if(width&15){\n\n    yv12toyuy2( ysrc, usrc, vsrc, dst,c->srcW,srcSliceH, lumStride, chromStride, dstStride);\n\n    return srcSliceH;\n\n  }\n\n\n\n  /* this code assume:\n\n\n\n  1) dst is 16 bytes-aligned\n\n  2) dstStride is a multiple of 16\n\n  3) width is a multiple of 16\n\n  4) lum&chrom stride are multiple of 8\n\n  */\n\n\n\n  for(y=0; y<height; y++)\n\n    {\n\n      int i;\n\n      for (i = 0; i < width - 31; i+= 32) {\n\n\tconst unsigned int j = i >> 1;\n\n\tvector unsigned char v_yA = vec_ld(i, ysrc);\n\n\tvector unsigned char v_yB = vec_ld(i + 16, ysrc);\n\n\tvector unsigned char v_yC = vec_ld(i + 32, ysrc);\n\n\tvector unsigned char v_y1 = vec_perm(v_yA, v_yB, yperm);\n\n\tvector unsigned char v_y2 = vec_perm(v_yB, v_yC, yperm);\n\n\tvector unsigned char v_uA = vec_ld(j, usrc);\n\n\tvector unsigned char v_uB = vec_ld(j + 16, usrc);\n\n\tvector unsigned char v_u = vec_perm(v_uA, v_uB, vec_lvsl(j, usrc));\n\n\tvector unsigned char v_vA = vec_ld(j, vsrc);\n\n\tvector unsigned char v_vB = vec_ld(j + 16, vsrc);\n\n\tvector unsigned char v_v = vec_perm(v_vA, v_vB, vec_lvsl(j, vsrc));\n\n\tvector unsigned char v_uv_a = vec_mergeh(v_u, v_v);\n\n\tvector unsigned char v_uv_b = vec_mergel(v_u, v_v);\n\n\tvector unsigned char v_yuy2_0 = vec_mergeh(v_y1, v_uv_a);\n\n\tvector unsigned char v_yuy2_1 = vec_mergel(v_y1, v_uv_a);\n\n\tvector unsigned char v_yuy2_2 = vec_mergeh(v_y2, v_uv_b);\n\n\tvector unsigned char v_yuy2_3 = vec_mergel(v_y2, v_uv_b);\n\n\tvec_st(v_yuy2_0, (i << 1), dst);\n\n\tvec_st(v_yuy2_1, (i << 1) + 16, dst);\n\n\tvec_st(v_yuy2_2, (i << 1) + 32, dst);\n\n\tvec_st(v_yuy2_3, (i << 1) + 48, dst);\n\n      }\n\n      if (i < width) {\n\n\tconst unsigned int j = i >> 1;\n\n\tvector unsigned char v_y1 = vec_ld(i, ysrc);\n\n\tvector unsigned char v_u = vec_ld(j, usrc);\n\n\tvector unsigned char v_v = vec_ld(j, vsrc);\n\n\tvector unsigned char v_uv_a = vec_mergeh(v_u, v_v);\n\n\tvector unsigned char v_yuy2_0 = vec_mergeh(v_y1, v_uv_a);\n\n\tvector unsigned char v_yuy2_1 = vec_mergel(v_y1, v_uv_a);\n\n\tvec_st(v_yuy2_0, (i << 1), dst);\n\n\tvec_st(v_yuy2_1, (i << 1) + 16, dst);\n\n      }\n\n      if((y&(vertLumPerChroma-1))==(vertLumPerChroma-1) )\n\n\t{\n\n\t  usrc += chromStride;\n\n\t  vsrc += chromStride;\n\n\t}\n\n      ysrc += lumStride;\n\n      dst += dstStride;\n\n    }\n\n\n\n  return srcSliceH;\n\n}\n", "idx": 9846, "_split": "test", "_hash": "ecfbdc524df5098d89c49d311180a492"}
{"project": "FFmpeg", "commit_id": "c95fefa0420be9cc0f09a95041acf11114aaacd0", "target": 0, "func": "static void cin_decode_lzss(const unsigned char *src, int src_size, unsigned char *dst, int dst_size)\n\n{\n\n    uint16_t cmd;\n\n    int i, sz, offset, code;\n\n    unsigned char *dst_end = dst + dst_size;\n\n    const unsigned char *src_end = src + src_size;\n\n\n\n    while (src < src_end && dst < dst_end) {\n\n        code = *src++;\n\n        for (i = 0; i < 8 && src < src_end && dst < dst_end; ++i) {\n\n            if (code & (1 << i)) {\n\n                *dst++ = *src++;\n\n            } else {\n\n                cmd = AV_RL16(src); src += 2;\n\n                offset = cmd >> 4;\n\n                sz = (cmd & 0xF) + 2;\n\n                /* don't use memcpy/memmove here as the decoding routine (ab)uses */\n\n                /* buffer overlappings to repeat bytes in the destination */\n\n                sz = FFMIN(sz, dst_end - dst);\n\n                while (sz--) {\n\n                    *dst = *(dst - offset - 1);\n\n                    ++dst;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 9896, "_split": "test", "_hash": "f201df1c6e1f93c93d619a9e3c678e8b"}
{"project": "FFmpeg", "commit_id": "84f0aba18dc8815c5cd408238909e4dc8b60684f", "target": 1, "func": "ff_rdt_parse_open(AVFormatContext *ic, int first_stream_of_set_idx,\n\n                  void *priv_data, RTPDynamicProtocolHandler *handler)\n\n{\n\n    RDTDemuxContext *s = av_mallocz(sizeof(RDTDemuxContext));\n\n    if (!s)\n\n        return NULL;\n\n\n\n    s->ic = ic;\n\n    s->streams = &ic->streams[first_stream_of_set_idx];\n\n    do {\n\n        s->n_streams++;\n\n    } while (first_stream_of_set_idx + s->n_streams < ic->nb_streams &&\n\n             s->streams[s->n_streams]->priv_data == s->streams[0]->priv_data);\n\n    s->prev_set_id    = -1;\n\n    s->prev_stream_id = -1;\n\n    s->prev_timestamp = -1;\n\n    s->parse_packet = handler->parse_packet;\n\n    s->dynamic_protocol_context = priv_data;\n\n\n\n    return s;\n\n}\n", "idx": 9913, "_split": "test", "_hash": "8e8439ba93266e50c0b28818e4682102"}
{"project": "FFmpeg", "commit_id": "2fed05f53a881b64a02de7a324d67d8c029c6cf1", "target": 1, "func": "int ff_set_systematic_pal2(uint32_t pal[256], enum AVPixelFormat pix_fmt)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        int r, g, b;\n\n\n\n        switch (pix_fmt) {\n\n        case AV_PIX_FMT_RGB8:\n\n            r = (i>>5    )*36;\n\n            g = ((i>>2)&7)*36;\n\n            b = (i&3     )*85;\n\n            break;\n\n        case AV_PIX_FMT_BGR8:\n\n            b = (i>>6    )*85;\n\n            g = ((i>>3)&7)*36;\n\n            r = (i&7     )*36;\n\n            break;\n\n        case AV_PIX_FMT_RGB4_BYTE:\n\n            r = (i>>3    )*255;\n\n            g = ((i>>1)&3)*85;\n\n            b = (i&1     )*255;\n\n            break;\n\n        case AV_PIX_FMT_BGR4_BYTE:\n\n            b = (i>>3    )*255;\n\n            g = ((i>>1)&3)*85;\n\n            r = (i&1     )*255;\n\n            break;\n\n        case AV_PIX_FMT_GRAY8:\n\n            r = b = g = i;\n\n            break;\n\n        default:\n\n            return AVERROR(EINVAL);\n\n        }\n\n        pal[i] = b + (g<<8) + (r<<16) + (0xFF<<24);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 9934, "_split": "test", "_hash": "34c78f287238dd97c457e7cda8afb7ab"}
{"project": "FFmpeg", "commit_id": "3622988f2162e502727da476a70f5e4f48cd19c5", "target": 0, "func": "static inline void pred_direct_motion(H264Context * const h, int *mb_type){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy =   s->mb_x +   s->mb_y*s->mb_stride;\n\n    const int b8_xy = 2*s->mb_x + 2*s->mb_y*h->b8_stride;\n\n    const int b4_xy = 4*s->mb_x + 4*s->mb_y*h->b_stride;\n\n    const int mb_type_col = h->ref_list[1][0].mb_type[mb_xy];\n\n    const int16_t (*l1mv0)[2] = (const int16_t (*)[2]) &h->ref_list[1][0].motion_val[0][b4_xy];\n\n    const int8_t *l1ref0 = &h->ref_list[1][0].ref_index[0][b8_xy];\n\n    const int is_b8x8 = IS_8X8(*mb_type);\n\n    int sub_mb_type;\n\n    int i8, i4;\n\n\n\n    if(IS_8X8(mb_type_col) && !h->sps.direct_8x8_inference_flag){\n\n        /* FIXME save sub mb types from previous frames (or derive from MVs)\n\n         * so we know exactly what block size to use */\n\n        sub_mb_type = MB_TYPE_8x8|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_4x4 */\n\n        *mb_type =    MB_TYPE_8x8;\n\n    }else if(!is_b8x8 && (IS_16X16(mb_type_col) || IS_INTRA(mb_type_col))){\n\n        sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n        *mb_type =    MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_16x16 */\n\n    }else{\n\n        sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n        *mb_type =    MB_TYPE_8x8;\n\n    }\n\n    if(!is_b8x8)\n\n        *mb_type |= MB_TYPE_DIRECT2;\n\n\n\n    tprintf(\"mb_type = %08x, sub_mb_type = %08x, is_b8x8 = %d, mb_type_col = %08x\\n\", *mb_type, sub_mb_type, is_b8x8, mb_type_col);\n\n    \n\n    if(h->direct_spatial_mv_pred){\n\n        int ref[2];\n\n        int mv[2][2];\n\n        int list;\n\n\n\n        /* ref = min(neighbors) */\n\n        for(list=0; list<2; list++){\n\n            int refa = h->ref_cache[list][scan8[0] - 1];\n\n            int refb = h->ref_cache[list][scan8[0] - 8];\n\n            int refc = h->ref_cache[list][scan8[0] - 8 + 4];\n\n            if(refc == -2)\n\n                refc = h->ref_cache[list][scan8[0] - 8 - 1];\n\n            ref[list] = refa;\n\n            if(ref[list] < 0 || (refb < ref[list] && refb >= 0))\n\n                ref[list] = refb;\n\n            if(ref[list] < 0 || (refc < ref[list] && refc >= 0))\n\n                ref[list] = refc;\n\n            if(ref[list] < 0)\n\n                ref[list] = -1;\n\n        }\n\n\n\n        if(ref[0] < 0 && ref[1] < 0){\n\n            ref[0] = ref[1] = 0;\n\n            mv[0][0] = mv[0][1] =\n\n            mv[1][0] = mv[1][1] = 0;\n\n        }else{\n\n            for(list=0; list<2; list++){\n\n                if(ref[list] >= 0)\n\n                    pred_motion(h, 0, 4, list, ref[list], &mv[list][0], &mv[list][1]);\n\n                else\n\n                    mv[list][0] = mv[list][1] = 0;\n\n            }\n\n        }\n\n\n\n        if(ref[1] < 0){\n\n            *mb_type &= ~MB_TYPE_P0L1;\n\n            sub_mb_type &= ~MB_TYPE_P0L1;\n\n        }else if(ref[0] < 0){\n\n            *mb_type &= ~MB_TYPE_P0L0;\n\n            sub_mb_type &= ~MB_TYPE_P0L0;\n\n        }\n\n\n\n        if(IS_16X16(*mb_type)){\n\n            fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, ref[0], 1);\n\n            fill_rectangle(&h->ref_cache[1][scan8[0]], 4, 4, 8, ref[1], 1);\n\n            if(!IS_INTRA(mb_type_col) && l1ref0[0] == 0 &&\n\n                ABS(l1mv0[0][0]) <= 1 && ABS(l1mv0[0][1]) <= 1){\n\n                if(ref[0] > 0)\n\n                    fill_rectangle(&h->mv_cache[0][scan8[0]], 4, 4, 8, pack16to32(mv[0][0],mv[0][1]), 4);\n\n                else\n\n                    fill_rectangle(&h->mv_cache[0][scan8[0]], 4, 4, 8, 0, 4);\n\n                if(ref[1] > 0)\n\n                    fill_rectangle(&h->mv_cache[1][scan8[0]], 4, 4, 8, pack16to32(mv[1][0],mv[1][1]), 4);\n\n                else\n\n                    fill_rectangle(&h->mv_cache[1][scan8[0]], 4, 4, 8, 0, 4);\n\n            }else{\n\n                fill_rectangle(&h->mv_cache[0][scan8[0]], 4, 4, 8, pack16to32(mv[0][0],mv[0][1]), 4);\n\n                fill_rectangle(&h->mv_cache[1][scan8[0]], 4, 4, 8, pack16to32(mv[1][0],mv[1][1]), 4);\n\n            }\n\n        }else{\n\n            for(i8=0; i8<4; i8++){\n\n                const int x8 = i8&1;\n\n                const int y8 = i8>>1;\n\n    \n\n                if(is_b8x8 && !IS_DIRECT(h->sub_mb_type[i8]))\n\n                    continue;\n\n                h->sub_mb_type[i8] = sub_mb_type;\n\n    \n\n                fill_rectangle(&h->mv_cache[0][scan8[i8*4]], 2, 2, 8, pack16to32(mv[0][0],mv[0][1]), 4);\n\n                fill_rectangle(&h->mv_cache[1][scan8[i8*4]], 2, 2, 8, pack16to32(mv[1][0],mv[1][1]), 4);\n\n                fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, ref[0], 1);\n\n                fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, ref[1], 1);\n\n    \n\n                /* col_zero_flag */\n\n                if(!IS_INTRA(mb_type_col) && l1ref0[x8 + y8*h->b8_stride] == 0){\n\n                    for(i4=0; i4<4; i4++){\n\n                        const int16_t *mv_col = l1mv0[x8*2 + (i4&1) + (y8*2 + (i4>>1))*h->b_stride];\n\n                        if(ABS(mv_col[0]) <= 1 && ABS(mv_col[1]) <= 1){\n\n                            if(ref[0] == 0)\n\n                                *(uint32_t*)h->mv_cache[0][scan8[i8*4+i4]] = 0;\n\n                            if(ref[1] == 0)\n\n                                *(uint32_t*)h->mv_cache[1][scan8[i8*4+i4]] = 0;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }else{ /* direct temporal mv pred */\n\n        /* FIXME assumes that L1ref0 used the same ref lists as current frame */\n\n        if(IS_16X16(*mb_type)){\n\n            fill_rectangle(&h->ref_cache[1][scan8[0]], 4, 4, 8, 0, 1);\n\n            if(IS_INTRA(mb_type_col)){\n\n                fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&h-> mv_cache[0][scan8[0]], 4, 4, 8, 0, 4);\n\n                fill_rectangle(&h-> mv_cache[1][scan8[0]], 4, 4, 8, 0, 4);\n\n            }else{\n\n                const int ref0 = l1ref0[0];\n\n                const int dist_scale_factor = h->dist_scale_factor[ref0];\n\n                const int16_t *mv_col = l1mv0[0];\n\n                int mv_l0[2];\n\n                mv_l0[0] = (dist_scale_factor * mv_col[0] + 128) >> 8;\n\n                mv_l0[1] = (dist_scale_factor * mv_col[1] + 128) >> 8;\n\n                fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, ref0, 1);\n\n                fill_rectangle(&h-> mv_cache[0][scan8[0]], 4, 4, 8, pack16to32(mv_l0[0],mv_l0[1]), 4);\n\n                fill_rectangle(&h-> mv_cache[1][scan8[0]], 4, 4, 8, pack16to32(mv_l0[0]-mv_col[0],mv_l0[1]-mv_col[1]), 4);\n\n            }\n\n        }else{\n\n            for(i8=0; i8<4; i8++){\n\n                const int x8 = i8&1;\n\n                const int y8 = i8>>1;\n\n                int ref0, dist_scale_factor;\n\n    \n\n                if(is_b8x8 && !IS_DIRECT(h->sub_mb_type[i8]))\n\n                    continue;\n\n                h->sub_mb_type[i8] = sub_mb_type;\n\n                if(IS_INTRA(mb_type_col)){\n\n                    fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, 0, 1);\n\n                    fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, 0, 1);\n\n                    fill_rectangle(&h-> mv_cache[0][scan8[i8*4]], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(&h-> mv_cache[1][scan8[i8*4]], 2, 2, 8, 0, 4);\n\n                    continue;\n\n                }\n\n    \n\n                ref0 = l1ref0[x8 + y8*h->b8_stride];\n\n                dist_scale_factor = h->dist_scale_factor[ref0];\n\n    \n\n                fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, ref0, 1);\n\n                fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, 0, 1);\n\n                for(i4=0; i4<4; i4++){\n\n                    const int16_t *mv_col = l1mv0[x8*2 + (i4&1) + (y8*2 + (i4>>1))*h->b_stride];\n\n                    int16_t *mv_l0 = h->mv_cache[0][scan8[i8*4+i4]];\n\n                    mv_l0[0] = (dist_scale_factor * mv_col[0] + 128) >> 8;\n\n                    mv_l0[1] = (dist_scale_factor * mv_col[1] + 128) >> 8;\n\n                    *(uint32_t*)h->mv_cache[1][scan8[i8*4+i4]] =\n\n                        pack16to32(mv_l0[0]-mv_col[0],mv_l0[1]-mv_col[1]);\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 9977, "_split": "test", "_hash": "8d885d34db7f0e39b8d5ea3804e64362"}
{"project": "FFmpeg", "commit_id": "e8c4db0d4d07738fed716b1d2f20c85aac944641", "target": 0, "func": "static int create_stream(AVFormatContext *s)\n\n{\n\n    XCBGrabContext *c = s->priv_data;\n\n    AVStream *st      = avformat_new_stream(s, NULL);\n\n    xcb_get_geometry_cookie_t gc;\n\n    xcb_get_geometry_reply_t *geo;\n\n    int ret;\n\n\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ret = av_parse_video_size(&c->width, &c->height, c->video_size);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    ret = av_parse_video_rate(&st->avg_frame_rate, c->framerate);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    avpriv_set_pts_info(st, 64, 1, 1000000);\n\n\n\n    gc  = xcb_get_geometry(c->conn, c->screen->root);\n\n    geo = xcb_get_geometry_reply(c->conn, gc, NULL);\n\n\n\n    c->width      = FFMIN(geo->width, c->width);\n\n    c->height     = FFMIN(geo->height, c->height);\n\n    c->time_base  = (AVRational){ st->avg_frame_rate.den,\n\n                                  st->avg_frame_rate.num };\n\n    c->time_frame = av_gettime();\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id   = AV_CODEC_ID_RAWVIDEO;\n\n    st->codec->width      = c->width;\n\n    st->codec->height     = c->height;\n\n    st->codec->time_base  = c->time_base;\n\n\n\n    ret = pixfmt_from_pixmap_format(s, geo->depth, &st->codec->pix_fmt);\n\n\n\n    free(geo);\n\n\n\n    return ret;\n\n}\n", "idx": 10161, "_split": "test", "_hash": "9747d48f05a1db213acfb13d735a0ac0"}
{"project": "FFmpeg", "commit_id": "02055b6d40d0cff867a9e41cad48edcaf6e10f2f", "target": 0, "func": "static int vorbis_parse_setup_hdr_codebooks(vorbis_context *vc)\n\n{\n\n    unsigned cb;\n\n    uint8_t  *tmp_vlc_bits;\n\n    uint32_t *tmp_vlc_codes;\n\n    GetBitContext *gb = &vc->gb;\n\n    uint16_t *codebook_multiplicands;\n\n    int ret = 0;\n\n\n\n    vc->codebook_count = get_bits(gb, 8) + 1;\n\n\n\n    av_dlog(NULL, \" Codebooks: %d \\n\", vc->codebook_count);\n\n\n\n    vc->codebooks = av_mallocz(vc->codebook_count * sizeof(*vc->codebooks));\n\n    tmp_vlc_bits  = av_mallocz(V_MAX_VLCS * sizeof(*tmp_vlc_bits));\n\n    tmp_vlc_codes = av_mallocz(V_MAX_VLCS * sizeof(*tmp_vlc_codes));\n\n    codebook_multiplicands = av_malloc(V_MAX_VLCS * sizeof(*codebook_multiplicands));\n\n\n\n    for (cb = 0; cb < vc->codebook_count; ++cb) {\n\n        vorbis_codebook *codebook_setup = &vc->codebooks[cb];\n\n        unsigned ordered, t, entries, used_entries = 0;\n\n\n\n        av_dlog(NULL, \" %u. Codebook\\n\", cb);\n\n\n\n        if (get_bits(gb, 24) != 0x564342) {\n\n            av_log(vc->avctx, AV_LOG_ERROR,\n\n                   \" %u. Codebook setup data corrupt.\\n\", cb);\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto error;\n\n        }\n\n\n\n        codebook_setup->dimensions=get_bits(gb, 16);\n\n        if (codebook_setup->dimensions > 16 || codebook_setup->dimensions == 0) {\n\n            av_log(vc->avctx, AV_LOG_ERROR,\n\n                   \" %u. Codebook's dimension is invalid (%d).\\n\",\n\n                   cb, codebook_setup->dimensions);\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto error;\n\n        }\n\n        entries = get_bits(gb, 24);\n\n        if (entries > V_MAX_VLCS) {\n\n            av_log(vc->avctx, AV_LOG_ERROR,\n\n                   \" %u. Codebook has too many entries (%u).\\n\",\n\n                   cb, entries);\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto error;\n\n        }\n\n\n\n        ordered = get_bits1(gb);\n\n\n\n        av_dlog(NULL, \" codebook_dimensions %d, codebook_entries %u\\n\",\n\n                codebook_setup->dimensions, entries);\n\n\n\n        if (!ordered) {\n\n            unsigned ce, flag;\n\n            unsigned sparse = get_bits1(gb);\n\n\n\n            av_dlog(NULL, \" not ordered \\n\");\n\n\n\n            if (sparse) {\n\n                av_dlog(NULL, \" sparse \\n\");\n\n\n\n                used_entries = 0;\n\n                for (ce = 0; ce < entries; ++ce) {\n\n                    flag = get_bits1(gb);\n\n                    if (flag) {\n\n                        tmp_vlc_bits[ce] = get_bits(gb, 5) + 1;\n\n                        ++used_entries;\n\n                    } else\n\n                        tmp_vlc_bits[ce] = 0;\n\n                }\n\n            } else {\n\n                av_dlog(NULL, \" not sparse \\n\");\n\n\n\n                used_entries = entries;\n\n                for (ce = 0; ce < entries; ++ce)\n\n                    tmp_vlc_bits[ce] = get_bits(gb, 5) + 1;\n\n            }\n\n        } else {\n\n            unsigned current_entry  = 0;\n\n            unsigned current_length = get_bits(gb, 5) + 1;\n\n\n\n            av_dlog(NULL, \" ordered, current length: %u\\n\", current_length);  //FIXME\n\n\n\n            used_entries = entries;\n\n            for (; current_entry < used_entries && current_length <= 32; ++current_length) {\n\n                unsigned i, number;\n\n\n\n                av_dlog(NULL, \" number bits: %u \", ilog(entries - current_entry));\n\n\n\n                number = get_bits(gb, ilog(entries - current_entry));\n\n\n\n                av_dlog(NULL, \" number: %u\\n\", number);\n\n\n\n                for (i = current_entry; i < number+current_entry; ++i)\n\n                    if (i < used_entries)\n\n                        tmp_vlc_bits[i] = current_length;\n\n\n\n                current_entry+=number;\n\n            }\n\n            if (current_entry>used_entries) {\n\n                av_log(vc->avctx, AV_LOG_ERROR, \" More codelengths than codes in codebook. \\n\");\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto error;\n\n            }\n\n        }\n\n\n\n        codebook_setup->lookup_type = get_bits(gb, 4);\n\n\n\n        av_dlog(NULL, \" lookup type: %d : %s \\n\", codebook_setup->lookup_type,\n\n                codebook_setup->lookup_type ? \"vq\" : \"no lookup\");\n\n\n\n// If the codebook is used for (inverse) VQ, calculate codevectors.\n\n\n\n        if (codebook_setup->lookup_type == 1) {\n\n            unsigned i, j, k;\n\n            unsigned codebook_lookup_values = ff_vorbis_nth_root(entries, codebook_setup->dimensions);\n\n\n\n            float codebook_minimum_value = vorbisfloat2float(get_bits_long(gb, 32));\n\n            float codebook_delta_value   = vorbisfloat2float(get_bits_long(gb, 32));\n\n            unsigned codebook_value_bits = get_bits(gb, 4) + 1;\n\n            unsigned codebook_sequence_p = get_bits1(gb);\n\n\n\n            av_dlog(NULL, \" We expect %d numbers for building the codevectors. \\n\",\n\n                    codebook_lookup_values);\n\n            av_dlog(NULL, \"  delta %f minmum %f \\n\",\n\n                    codebook_delta_value, codebook_minimum_value);\n\n\n\n            for (i = 0; i < codebook_lookup_values; ++i) {\n\n                codebook_multiplicands[i] = get_bits(gb, codebook_value_bits);\n\n\n\n                av_dlog(NULL, \" multiplicands*delta+minmum : %e \\n\",\n\n                        (float)codebook_multiplicands[i] * codebook_delta_value + codebook_minimum_value);\n\n                av_dlog(NULL, \" multiplicand %u\\n\", codebook_multiplicands[i]);\n\n            }\n\n\n\n// Weed out unused vlcs and build codevector vector\n\n            codebook_setup->codevectors = used_entries ? av_mallocz(used_entries *\n\n                                                                    codebook_setup->dimensions *\n\n                                                                    sizeof(*codebook_setup->codevectors))\n\n                                                       : NULL;\n\n            for (j = 0, i = 0; i < entries; ++i) {\n\n                unsigned dim = codebook_setup->dimensions;\n\n\n\n                if (tmp_vlc_bits[i]) {\n\n                    float last = 0.0;\n\n                    unsigned lookup_offset = i;\n\n\n\n                    av_dlog(vc->avctx, \"Lookup offset %u ,\", i);\n\n\n\n                    for (k = 0; k < dim; ++k) {\n\n                        unsigned multiplicand_offset = lookup_offset % codebook_lookup_values;\n\n                        codebook_setup->codevectors[j * dim + k] = codebook_multiplicands[multiplicand_offset] * codebook_delta_value + codebook_minimum_value + last;\n\n                        if (codebook_sequence_p)\n\n                            last = codebook_setup->codevectors[j * dim + k];\n\n                        lookup_offset/=codebook_lookup_values;\n\n                    }\n\n                    tmp_vlc_bits[j] = tmp_vlc_bits[i];\n\n\n\n                    av_dlog(vc->avctx, \"real lookup offset %u, vector: \", j);\n\n                    for (k = 0; k < dim; ++k)\n\n                        av_dlog(vc->avctx, \" %f \",\n\n                                codebook_setup->codevectors[j * dim + k]);\n\n                    av_dlog(vc->avctx, \"\\n\");\n\n\n\n                    ++j;\n\n                }\n\n            }\n\n            if (j != used_entries) {\n\n                av_log(vc->avctx, AV_LOG_ERROR, \"Bug in codevector vector building code. \\n\");\n\n                ret = AVERROR_INVALIDDATA;\n\n                goto error;\n\n            }\n\n            entries = used_entries;\n\n        } else if (codebook_setup->lookup_type >= 2) {\n\n            av_log(vc->avctx, AV_LOG_ERROR, \"Codebook lookup type not supported. \\n\");\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto error;\n\n        }\n\n\n\n// Initialize VLC table\n\n        if (ff_vorbis_len2vlc(tmp_vlc_bits, tmp_vlc_codes, entries)) {\n\n            av_log(vc->avctx, AV_LOG_ERROR, \" Invalid code lengths while generating vlcs. \\n\");\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto error;\n\n        }\n\n        codebook_setup->maxdepth = 0;\n\n        for (t = 0; t < entries; ++t)\n\n            if (tmp_vlc_bits[t] >= codebook_setup->maxdepth)\n\n                codebook_setup->maxdepth = tmp_vlc_bits[t];\n\n\n\n        if (codebook_setup->maxdepth > 3 * V_NB_BITS)\n\n            codebook_setup->nb_bits = V_NB_BITS2;\n\n        else\n\n            codebook_setup->nb_bits = V_NB_BITS;\n\n\n\n        codebook_setup->maxdepth = (codebook_setup->maxdepth+codebook_setup->nb_bits - 1) / codebook_setup->nb_bits;\n\n\n\n        if ((ret = init_vlc(&codebook_setup->vlc, codebook_setup->nb_bits,\n\n                            entries, tmp_vlc_bits, sizeof(*tmp_vlc_bits),\n\n                            sizeof(*tmp_vlc_bits), tmp_vlc_codes,\n\n                            sizeof(*tmp_vlc_codes), sizeof(*tmp_vlc_codes),\n\n                            INIT_VLC_LE))) {\n\n            av_log(vc->avctx, AV_LOG_ERROR, \" Error generating vlc tables. \\n\");\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    av_free(tmp_vlc_bits);\n\n    av_free(tmp_vlc_codes);\n\n    av_free(codebook_multiplicands);\n\n    return 0;\n\n\n\n// Error:\n\nerror:\n\n    av_free(tmp_vlc_bits);\n\n    av_free(tmp_vlc_codes);\n\n    av_free(codebook_multiplicands);\n\n    return ret;\n\n}\n", "idx": 10175, "_split": "test", "_hash": "c69efd66c735e3e58df8f011bdf191c0"}
{"project": "FFmpeg", "commit_id": "979bea13003ef489d95d2538ac2fb1c26c6f103b", "target": 0, "func": "static int rv40_decode_mb_info(RV34DecContext *r)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    GetBitContext *gb = &s->gb;\n\n    int q, i;\n\n    int prev_type = 0;\n\n    int mb_pos = s->mb_x + s->mb_y * s->mb_stride;\n\n    int blocks[RV34_MB_TYPES] = {0};\n\n    int count = 0;\n\n\n\n    if(!r->s.mb_skip_run)\n\n        r->s.mb_skip_run = svq3_get_ue_golomb(gb) + 1;\n\n\n\n    if(--r->s.mb_skip_run)\n\n         return RV34_MB_SKIP;\n\n\n\n    if(r->avail_cache[6-1])\n\n        blocks[r->mb_type[mb_pos - 1]]++;\n\n    if(r->avail_cache[6-4]){\n\n        blocks[r->mb_type[mb_pos - s->mb_stride]]++;\n\n        if(r->avail_cache[6-2])\n\n            blocks[r->mb_type[mb_pos - s->mb_stride + 1]]++;\n\n        if(r->avail_cache[6-5])\n\n            blocks[r->mb_type[mb_pos - s->mb_stride - 1]]++;\n\n    }\n\n\n\n    for(i = 0; i < RV34_MB_TYPES; i++){\n\n        if(blocks[i] > count){\n\n            count = blocks[i];\n\n            prev_type = i;\n\n        }\n\n    }\n\n    if(s->pict_type == AV_PICTURE_TYPE_P){\n\n        prev_type = block_num_to_ptype_vlc_num[prev_type];\n\n        q = get_vlc2(gb, ptype_vlc[prev_type].table, PTYPE_VLC_BITS, 1);\n\n        if(q < PBTYPE_ESCAPE)\n\n            return q;\n\n        q = get_vlc2(gb, ptype_vlc[prev_type].table, PTYPE_VLC_BITS, 1);\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Dquant for P-frame\\n\");\n\n    }else{\n\n        prev_type = block_num_to_btype_vlc_num[prev_type];\n\n        q = get_vlc2(gb, btype_vlc[prev_type].table, BTYPE_VLC_BITS, 1);\n\n        if(q < PBTYPE_ESCAPE)\n\n            return q;\n\n        q = get_vlc2(gb, btype_vlc[prev_type].table, BTYPE_VLC_BITS, 1);\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Dquant for B-frame\\n\");\n\n    }\n\n    return 0;\n\n}\n", "idx": 10213, "_split": "test", "_hash": "62894a43759a533570b4d6afbac26f9f"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yvu9_to_yuy2)(const uint8_t *src1, const uint8_t *src2, const uint8_t *src3,\n\n                                        uint8_t *dst,\n\n                                        long width, long height,\n\n                                        long srcStride1, long srcStride2,\n\n                                        long srcStride3, long dstStride)\n\n{\n\n    x86_reg x;\n\n    long y,w,h;\n\n    w=width/2; h=height;\n\n    for (y=0;y<h;y++) {\n\n        const uint8_t* yp=src1+srcStride1*y;\n\n        const uint8_t* up=src2+srcStride2*(y>>2);\n\n        const uint8_t* vp=src3+srcStride3*(y>>2);\n\n        uint8_t* d=dst+dstStride*y;\n\n        x=0;\n\n#if COMPILE_TEMPLATE_MMX\n\n        for (;x<w-7;x+=8) {\n\n            __asm__ volatile(\n\n                PREFETCH\"   32(%1, %0)          \\n\\t\"\n\n                PREFETCH\"   32(%2, %0)          \\n\\t\"\n\n                PREFETCH\"   32(%3, %0)          \\n\\t\"\n\n                \"movq      (%1, %0, 4), %%mm0   \\n\\t\" /* Y0Y1Y2Y3Y4Y5Y6Y7 */\n\n                \"movq         (%2, %0), %%mm1   \\n\\t\" /* U0U1U2U3U4U5U6U7 */\n\n                \"movq         (%3, %0), %%mm2   \\n\\t\" /* V0V1V2V3V4V5V6V7 */\n\n                \"movq            %%mm0, %%mm3   \\n\\t\" /* Y0Y1Y2Y3Y4Y5Y6Y7 */\n\n                \"movq            %%mm1, %%mm4   \\n\\t\" /* U0U1U2U3U4U5U6U7 */\n\n                \"movq            %%mm2, %%mm5   \\n\\t\" /* V0V1V2V3V4V5V6V7 */\n\n                \"punpcklbw       %%mm1, %%mm1   \\n\\t\" /* U0U0 U1U1 U2U2 U3U3 */\n\n                \"punpcklbw       %%mm2, %%mm2   \\n\\t\" /* V0V0 V1V1 V2V2 V3V3 */\n\n                \"punpckhbw       %%mm4, %%mm4   \\n\\t\" /* U4U4 U5U5 U6U6 U7U7 */\n\n                \"punpckhbw       %%mm5, %%mm5   \\n\\t\" /* V4V4 V5V5 V6V6 V7V7 */\n\n\n\n                \"movq            %%mm1, %%mm6   \\n\\t\"\n\n                \"punpcklbw       %%mm2, %%mm1   \\n\\t\" /* U0V0 U0V0 U1V1 U1V1*/\n\n                \"punpcklbw       %%mm1, %%mm0   \\n\\t\" /* Y0U0 Y1V0 Y2U0 Y3V0*/\n\n                \"punpckhbw       %%mm1, %%mm3   \\n\\t\" /* Y4U1 Y5V1 Y6U1 Y7V1*/\n\n                MOVNTQ\"          %%mm0,  (%4, %0, 8)    \\n\\t\"\n\n                MOVNTQ\"          %%mm3, 8(%4, %0, 8)    \\n\\t\"\n\n\n\n                \"punpckhbw       %%mm2, %%mm6   \\n\\t\" /* U2V2 U2V2 U3V3 U3V3*/\n\n                \"movq     8(%1, %0, 4), %%mm0   \\n\\t\"\n\n                \"movq            %%mm0, %%mm3   \\n\\t\"\n\n                \"punpcklbw       %%mm6, %%mm0   \\n\\t\" /* Y U2 Y V2 Y U2 Y V2*/\n\n                \"punpckhbw       %%mm6, %%mm3   \\n\\t\" /* Y U3 Y V3 Y U3 Y V3*/\n\n                MOVNTQ\"          %%mm0, 16(%4, %0, 8)   \\n\\t\"\n\n                MOVNTQ\"          %%mm3, 24(%4, %0, 8)   \\n\\t\"\n\n\n\n                \"movq            %%mm4, %%mm6   \\n\\t\"\n\n                \"movq    16(%1, %0, 4), %%mm0   \\n\\t\"\n\n                \"movq            %%mm0, %%mm3   \\n\\t\"\n\n                \"punpcklbw       %%mm5, %%mm4   \\n\\t\"\n\n                \"punpcklbw       %%mm4, %%mm0   \\n\\t\" /* Y U4 Y V4 Y U4 Y V4*/\n\n                \"punpckhbw       %%mm4, %%mm3   \\n\\t\" /* Y U5 Y V5 Y U5 Y V5*/\n\n                MOVNTQ\"          %%mm0, 32(%4, %0, 8)   \\n\\t\"\n\n                MOVNTQ\"          %%mm3, 40(%4, %0, 8)   \\n\\t\"\n\n\n\n                \"punpckhbw       %%mm5, %%mm6   \\n\\t\"\n\n                \"movq    24(%1, %0, 4), %%mm0   \\n\\t\"\n\n                \"movq            %%mm0, %%mm3   \\n\\t\"\n\n                \"punpcklbw       %%mm6, %%mm0   \\n\\t\" /* Y U6 Y V6 Y U6 Y V6*/\n\n                \"punpckhbw       %%mm6, %%mm3   \\n\\t\" /* Y U7 Y V7 Y U7 Y V7*/\n\n                MOVNTQ\"          %%mm0, 48(%4, %0, 8)   \\n\\t\"\n\n                MOVNTQ\"          %%mm3, 56(%4, %0, 8)   \\n\\t\"\n\n\n\n                : \"+r\" (x)\n\n                : \"r\"(yp), \"r\" (up), \"r\"(vp), \"r\"(d)\n\n                :\"memory\");\n\n        }\n\n#endif\n\n        for (; x<w; x++) {\n\n            const long x2 = x<<2;\n\n            d[8*x+0] = yp[x2];\n\n            d[8*x+1] = up[x];\n\n            d[8*x+2] = yp[x2+1];\n\n            d[8*x+3] = vp[x];\n\n            d[8*x+4] = yp[x2+2];\n\n            d[8*x+5] = up[x];\n\n            d[8*x+6] = yp[x2+3];\n\n            d[8*x+7] = vp[x];\n\n        }\n\n    }\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__(\n\n            EMMS\"       \\n\\t\"\n\n            SFENCE\"     \\n\\t\"\n\n            ::: \"memory\"\n\n        );\n\n#endif\n\n}\n", "idx": 10233, "_split": "test", "_hash": "5ca3137872e80941abe4eba5e0a11007"}
{"project": "FFmpeg", "commit_id": "381e195b46d080aee1d9b05ef2b6b140e9463519", "target": 0, "func": "static int pcm_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    PCMDecode *s = avctx->priv_data;\n\n    int sample_size, c, n, i;\n\n    uint8_t *samples;\n\n    const uint8_t *src, *src8, *src2[MAX_CHANNELS];\n\n    int32_t *dst_int32_t;\n\n\n\n    samples = data;\n\n    src = buf;\n\n\n\n    if (avctx->sample_fmt!=avctx->codec->sample_fmts[0]) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid sample_fmt\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(avctx->channels <= 0 || avctx->channels > MAX_CHANNELS){\n\n        av_log(avctx, AV_LOG_ERROR, \"PCM channels out of bounds\\n\");\n\n        return -1;\n\n    }\n\n\n\n    sample_size = av_get_bits_per_sample(avctx->codec_id)/8;\n\n\n\n    /* av_get_bits_per_sample returns 0 for CODEC_ID_PCM_DVD */\n\n    if (CODEC_ID_PCM_DVD == avctx->codec_id)\n\n        /* 2 samples are interleaved per block in PCM_DVD */\n\n        sample_size = avctx->bits_per_coded_sample * 2 / 8;\n\n    else if (avctx->codec_id == CODEC_ID_PCM_LXF)\n\n        /* we process 40-bit blocks per channel for LXF */\n\n        sample_size = 5;\n\n\n\n    if (sample_size == 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid sample_size\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    n = avctx->channels * sample_size;\n\n\n\n    if(n && buf_size % n){\n\n        if (buf_size < n) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid PCM packet\\n\");\n\n            return -1;\n\n        }else\n\n            buf_size -= buf_size % n;\n\n    }\n\n\n\n    buf_size= FFMIN(buf_size, *data_size/2);\n\n\n\n    n = buf_size/sample_size;\n\n\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_PCM_U32LE:\n\n        DECODE(32, le32, src, samples, n, 0, 0x80000000)\n\n        break;\n\n    case CODEC_ID_PCM_U32BE:\n\n        DECODE(32, be32, src, samples, n, 0, 0x80000000)\n\n        break;\n\n    case CODEC_ID_PCM_S24LE:\n\n        DECODE(32, le24, src, samples, n, 8, 0)\n\n        break;\n\n    case CODEC_ID_PCM_S24BE:\n\n        DECODE(32, be24, src, samples, n, 8, 0)\n\n        break;\n\n    case CODEC_ID_PCM_U24LE:\n\n        DECODE(32, le24, src, samples, n, 8, 0x800000)\n\n        break;\n\n    case CODEC_ID_PCM_U24BE:\n\n        DECODE(32, be24, src, samples, n, 8, 0x800000)\n\n        break;\n\n    case CODEC_ID_PCM_S24DAUD:\n\n        for(;n>0;n--) {\n\n          uint32_t v = bytestream_get_be24(&src);\n\n          v >>= 4; // sync flags are here\n\n          AV_WN16A(samples, av_reverse[(v >> 8) & 0xff] +\n\n                           (av_reverse[v & 0xff] << 8));\n\n          samples += 2;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_S16LE_PLANAR:\n\n        n /= avctx->channels;\n\n        for(c=0;c<avctx->channels;c++)\n\n            src2[c] = &src[c*n*2];\n\n        for(;n>0;n--)\n\n            for(c=0;c<avctx->channels;c++) {\n\n                AV_WN16A(samples, bytestream_get_le16(&src2[c]));\n\n                samples += 2;\n\n            }\n\n        src = src2[avctx->channels-1];\n\n        break;\n\n    case CODEC_ID_PCM_U16LE:\n\n        DECODE(16, le16, src, samples, n, 0, 0x8000)\n\n        break;\n\n    case CODEC_ID_PCM_U16BE:\n\n        DECODE(16, be16, src, samples, n, 0, 0x8000)\n\n        break;\n\n    case CODEC_ID_PCM_S8:\n\n        for(;n>0;n--) {\n\n            *samples++ = *src++ + 128;\n\n        }\n\n        break;\n\n#if HAVE_BIGENDIAN\n\n    case CODEC_ID_PCM_F64LE:\n\n        DECODE(64, le64, src, samples, n, 0, 0)\n\n        break;\n\n    case CODEC_ID_PCM_S32LE:\n\n    case CODEC_ID_PCM_F32LE:\n\n        DECODE(32, le32, src, samples, n, 0, 0)\n\n        break;\n\n    case CODEC_ID_PCM_S16LE:\n\n        DECODE(16, le16, src, samples, n, 0, 0)\n\n        break;\n\n    case CODEC_ID_PCM_F64BE:\n\n    case CODEC_ID_PCM_F32BE:\n\n    case CODEC_ID_PCM_S32BE:\n\n    case CODEC_ID_PCM_S16BE:\n\n#else\n\n    case CODEC_ID_PCM_F64BE:\n\n        DECODE(64, be64, src, samples, n, 0, 0)\n\n        break;\n\n    case CODEC_ID_PCM_F32BE:\n\n    case CODEC_ID_PCM_S32BE:\n\n        DECODE(32, be32, src, samples, n, 0, 0)\n\n        break;\n\n    case CODEC_ID_PCM_S16BE:\n\n        DECODE(16, be16, src, samples, n, 0, 0)\n\n        break;\n\n    case CODEC_ID_PCM_F64LE:\n\n    case CODEC_ID_PCM_F32LE:\n\n    case CODEC_ID_PCM_S32LE:\n\n    case CODEC_ID_PCM_S16LE:\n\n#endif /* HAVE_BIGENDIAN */\n\n    case CODEC_ID_PCM_U8:\n\n        memcpy(samples, src, n*sample_size);\n\n        src += n*sample_size;\n\n        samples += n * sample_size;\n\n        break;\n\n    case CODEC_ID_PCM_ZORK:\n\n        for(;n>0;n--) {\n\n            int x= *src++;\n\n            if(x&128) x-= 128;\n\n            else      x = -x;\n\n            AV_WN16A(samples, x << 8);\n\n            samples += 2;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_ALAW:\n\n    case CODEC_ID_PCM_MULAW:\n\n        for(;n>0;n--) {\n\n            AV_WN16A(samples, s->table[*src++]);\n\n            samples += 2;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_DVD:\n\n        dst_int32_t = data;\n\n        n /= avctx->channels;\n\n        switch (avctx->bits_per_coded_sample) {\n\n        case 20:\n\n            while (n--) {\n\n                c = avctx->channels;\n\n                src8 = src + 4*c;\n\n                while (c--) {\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8   &0xf0) << 8);\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++ &0x0f) << 12);\n\n                }\n\n                src = src8;\n\n            }\n\n            break;\n\n        case 24:\n\n            while (n--) {\n\n                c = avctx->channels;\n\n                src8 = src + 4*c;\n\n                while (c--) {\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n\n                }\n\n                src = src8;\n\n            }\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"PCM DVD unsupported sample depth\\n\");\n\n            return -1;\n\n        }\n\n        samples = (uint8_t *) dst_int32_t;\n\n        break;\n\n    case CODEC_ID_PCM_LXF:\n\n        dst_int32_t = data;\n\n        n /= avctx->channels;\n\n        //unpack and de-planerize\n\n        for (i = 0; i < n; i++) {\n\n            for (c = 0, src8 = src + i*5; c < avctx->channels; c++, src8 += n*5) {\n\n                //extract low 20 bits and expand to 32 bits\n\n                *dst_int32_t++ = (src8[2] << 28) | (src8[1] << 20) | (src8[0] << 12) |\n\n                                 ((src8[2] & 0xF) << 8) | src8[1];\n\n            }\n\n\n\n            for (c = 0, src8 = src + i*5; c < avctx->channels; c++, src8 += n*5) {\n\n                //extract high 20 bits and expand to 32 bits\n\n                *dst_int32_t++ = (src8[4] << 24) | (src8[3] << 16) |\n\n                                 ((src8[2] & 0xF0) << 8) | (src8[4] << 4) | (src8[3] >> 4);\n\n            }\n\n        }\n\n        src += n * avctx->channels * 5;\n\n        samples = (uint8_t *) dst_int32_t;\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n    *data_size = samples - (uint8_t *)data;\n\n    return src - buf;\n\n}\n", "idx": 10244, "_split": "test", "_hash": "24bbef78e6d43eeaa4eea9a7bc82dc3b"}
{"project": "FFmpeg", "commit_id": "253d0be6a1ecc343d29ff8e1df0ddf961ab9c772", "target": 0, "func": "static int parse_presentation_segment(AVCodecContext *avctx,\n\n                                      const uint8_t *buf, int buf_size,\n\n                                      int64_t pts)\n\n{\n\n    PGSSubContext *ctx = avctx->priv_data;\n\n\n\n    int x, y, ret;\n\n\n\n    int w = bytestream_get_be16(&buf);\n\n    int h = bytestream_get_be16(&buf);\n\n\n\n    ctx->presentation.pts = pts;\n\n\n\n    av_dlog(avctx, \"Video Dimensions %dx%d\\n\",\n\n            w, h);\n\n    ret = ff_set_dimensions(avctx, w, h);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* Skip 1 bytes of unknown, frame rate? */\n\n    buf++;\n\n\n\n    ctx->presentation.id_number = bytestream_get_be16(&buf);\n\n\n\n    /*\n\n     * Skip 3 bytes of unknown:\n\n     *     state\n\n     *     palette_update_flag (0x80),\n\n     *     palette_id_to_use,\n\n     */\n\n    buf += 3;\n\n\n\n    ctx->presentation.object_number = bytestream_get_byte(&buf);\n\n    ctx->presentation.composition_flag = 0;\n\n    if (!ctx->presentation.object_number)\n\n        return 0;\n\n\n\n    /*\n\n     * Skip 3 bytes of unknown:\n\n     *     object_id_ref (2 bytes),\n\n     *     window_id_ref,\n\n     */\n\n    buf += 3;\n\n    ctx->presentation.composition_flag = bytestream_get_byte(&buf);\n\n\n\n    x = bytestream_get_be16(&buf);\n\n    y = bytestream_get_be16(&buf);\n\n\n\n    /* TODO If cropping, cropping_x, cropping_y, cropping_width, cropping_height (all 2 bytes).*/\n\n\n\n    av_dlog(avctx, \"Subtitle Placement x=%d, y=%d\\n\", x, y);\n\n\n\n    if (x > avctx->width || y > avctx->height) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Subtitle out of video bounds. x = %d, y = %d, video width = %d, video height = %d.\\n\",\n\n               x, y, avctx->width, avctx->height);\n\n        x = 0; y = 0;\n\n    }\n\n\n\n    /* Fill in dimensions */\n\n    ctx->presentation.x = x;\n\n    ctx->presentation.y = y;\n\n\n\n    return 0;\n\n}\n", "idx": 10253, "_split": "test", "_hash": "6bacbaf574fd05e202d12926fff4b7e6"}
{"project": "FFmpeg", "commit_id": "53e5462040f6f7273fb6b0d7592eea1f5d26829f", "target": 0, "func": "inline static void RENAME(hcscale)(SwsContext *c, uint16_t *dst, long dstWidth, const uint8_t *src1, const uint8_t *src2,\n\n                                   int srcW, int xInc, int flags, const int16_t *hChrFilter,\n\n                                   const int16_t *hChrFilterPos, int hChrFilterSize,\n\n                                   int srcFormat, uint8_t *formatConvBuffer,\n\n                                   uint32_t *pal)\n\n{\n\n    int32_t av_unused *mmx2FilterPos = c->chrMmx2FilterPos;\n\n    int16_t av_unused *mmx2Filter    = c->chrMmx2Filter;\n\n    int     av_unused canMMX2BeUsed  = c->canMMX2BeUsed;\n\n    void    av_unused *mmx2FilterCode= c->chrMmx2FilterCode;\n\n\n\n    if (isGray(srcFormat) || srcFormat==PIX_FMT_MONOBLACK || srcFormat==PIX_FMT_MONOWHITE)\n\n        return;\n\n\n\n    if (srcFormat==PIX_FMT_RGB32_1 || srcFormat==PIX_FMT_BGR32_1) {\n\n        src1 += ALT32_CORR;\n\n        src2 += ALT32_CORR;\n\n    }\n\n\n\n    if (srcFormat==PIX_FMT_RGB48LE) {\n\n        src1++;\n\n        src2++;\n\n    }\n\n\n\n    if (c->hcscale_internal) {\n\n        c->hcscale_internal(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW, pal);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n\n\n#if COMPILE_TEMPLATE_MMX\n\n    // Use the new MMX scaler if the MMX2 one can't be used (it is faster than the x86 ASM one).\n\n    if (!(flags&SWS_FAST_BILINEAR) || (!canMMX2BeUsed))\n\n#else\n\n    if (!(flags&SWS_FAST_BILINEAR))\n\n#endif\n\n    {\n\n        c->hScale(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n        c->hScale(dst+VOFW, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    } else { // fast bilinear upscale / crap downscale\n\n#if ARCH_X86 && CONFIG_GPL\n\n#if COMPILE_TEMPLATE_MMX2\n\n        int i;\n\n#if defined(PIC)\n\n        DECLARE_ALIGNED(8, uint64_t, ebxsave);\n\n#endif\n\n        if (canMMX2BeUsed) {\n\n            __asm__ volatile(\n\n#if defined(PIC)\n\n                \"mov          %%\"REG_b\", %6         \\n\\t\"\n\n#endif\n\n                \"pxor             %%mm7, %%mm7      \\n\\t\"\n\n                \"mov                 %0, %%\"REG_c\"  \\n\\t\"\n\n                \"mov                 %1, %%\"REG_D\"  \\n\\t\"\n\n                \"mov                 %2, %%\"REG_d\"  \\n\\t\"\n\n                \"mov                 %3, %%\"REG_b\"  \\n\\t\"\n\n                \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n                PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n                PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n                PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\n                CALL_MMX2_FILTER_CODE\n\n                CALL_MMX2_FILTER_CODE\n\n                CALL_MMX2_FILTER_CODE\n\n                CALL_MMX2_FILTER_CODE\n\n                \"xor          %%\"REG_a\", %%\"REG_a\"  \\n\\t\" // i\n\n                \"mov                 %5, %%\"REG_c\"  \\n\\t\" // src\n\n                \"mov                 %1, %%\"REG_D\"  \\n\\t\" // buf1\n\n                \"add              $\"AV_STRINGIFY(VOF)\", %%\"REG_D\"  \\n\\t\"\n\n                PREFETCH\"   (%%\"REG_c\")             \\n\\t\"\n\n                PREFETCH\" 32(%%\"REG_c\")             \\n\\t\"\n\n                PREFETCH\" 64(%%\"REG_c\")             \\n\\t\"\n\n\n\n                CALL_MMX2_FILTER_CODE\n\n                CALL_MMX2_FILTER_CODE\n\n                CALL_MMX2_FILTER_CODE\n\n                CALL_MMX2_FILTER_CODE\n\n\n\n#if defined(PIC)\n\n                \"mov %6, %%\"REG_b\"    \\n\\t\"\n\n#endif\n\n                :: \"m\" (src1), \"m\" (dst), \"m\" (mmx2Filter), \"m\" (mmx2FilterPos),\n\n                \"m\" (mmx2FilterCode), \"m\" (src2)\n\n#if defined(PIC)\n\n                ,\"m\" (ebxsave)\n\n#endif\n\n                : \"%\"REG_a, \"%\"REG_c, \"%\"REG_d, \"%\"REG_S, \"%\"REG_D\n\n#if !defined(PIC)\n\n                ,\"%\"REG_b\n\n#endif\n\n            );\n\n            for (i=dstWidth-1; (i*xInc)>>16 >=srcW-1; i--) {\n\n                //printf(\"%d %d %d\\n\", dstWidth, i, srcW);\n\n                dst[i] = src1[srcW-1]*128;\n\n                dst[i+VOFW] = src2[srcW-1]*128;\n\n            }\n\n        } else {\n\n#endif /* COMPILE_TEMPLATE_MMX2 */\n\n            x86_reg xInc_shr16 = (x86_reg) (xInc >> 16);\n\n            uint16_t xInc_mask = xInc & 0xffff;\n\n            __asm__ volatile(\n\n                \"xor %%\"REG_a\", %%\"REG_a\"               \\n\\t\" // i\n\n                \"xor %%\"REG_d\", %%\"REG_d\"               \\n\\t\" // xx\n\n                \"xorl    %%ecx, %%ecx                   \\n\\t\" // xalpha\n\n                ASMALIGN(4)\n\n                \"1:                                     \\n\\t\"\n\n                \"mov        %0, %%\"REG_S\"               \\n\\t\"\n\n                \"movzbl  (%%\"REG_S\", %%\"REG_d\"), %%edi  \\n\\t\" //src[xx]\n\n                \"movzbl 1(%%\"REG_S\", %%\"REG_d\"), %%esi  \\n\\t\" //src[xx+1]\n\n                FAST_BILINEAR_X86\n\n                \"movw     %%si, (%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n\n\n                \"movzbl    (%5, %%\"REG_d\"), %%edi       \\n\\t\" //src[xx]\n\n                \"movzbl   1(%5, %%\"REG_d\"), %%esi       \\n\\t\" //src[xx+1]\n\n                FAST_BILINEAR_X86\n\n                \"movw     %%si, \"AV_STRINGIFY(VOF)\"(%%\"REG_D\", %%\"REG_a\", 2)   \\n\\t\"\n\n\n\n                \"addw       %4, %%cx                    \\n\\t\" //xalpha += xInc&0xFFFF\n\n                \"adc        %3, %%\"REG_d\"               \\n\\t\" //xx+= xInc>>16 + carry\n\n                \"add        $1, %%\"REG_a\"               \\n\\t\"\n\n                \"cmp        %2, %%\"REG_a\"               \\n\\t\"\n\n                \" jb        1b                          \\n\\t\"\n\n\n\n/* GCC 3.3 makes MPlayer crash on IA-32 machines when using \"g\" operand here,\n\n   which is needed to support GCC 4.0. */\n\n#if ARCH_X86_64 && ((__GNUC__ > 3) || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))\n\n                :: \"m\" (src1), \"m\" (dst), \"g\" (dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#else\n\n                :: \"m\" (src1), \"m\" (dst), \"m\" (dstWidth), \"m\" (xInc_shr16), \"m\" (xInc_mask),\n\n#endif\n\n                \"r\" (src2)\n\n                : \"%\"REG_a, \"%\"REG_d, \"%ecx\", \"%\"REG_D, \"%esi\"\n\n            );\n\n#if COMPILE_TEMPLATE_MMX2\n\n        } //if MMX2 can't be used\n\n#endif\n\n#else\n\n        c->hcscale_fast(c, dst, dstWidth, src1, src2, srcW, xInc);\n\n#endif /* ARCH_X86 */\n\n    }\n\n    if(c->srcRange != c->dstRange && !(isRGB(c->dstFormat) || isBGR(c->dstFormat))) {\n\n        int i;\n\n        //FIXME all pal and rgb srcFormats could do this convertion as well\n\n        //FIXME all scalers more complex than bilinear could do half of this transform\n\n        if(c->srcRange) {\n\n            for (i=0; i<dstWidth; i++) {\n\n                dst[i     ]= (dst[i     ]*1799 + 4081085)>>11; //1469\n\n                dst[i+VOFW]= (dst[i+VOFW]*1799 + 4081085)>>11; //1469\n\n            }\n\n        } else {\n\n            for (i=0; i<dstWidth; i++) {\n\n                dst[i     ]= (FFMIN(dst[i     ],30775)*4663 - 9289992)>>12; //-264\n\n                dst[i+VOFW]= (FFMIN(dst[i+VOFW],30775)*4663 - 9289992)>>12; //-264\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 10308, "_split": "test", "_hash": "93cc1fe22e5369cffe3dcd77e7bec094"}
{"project": "FFmpeg", "commit_id": "6d24231e504f71a76a8fabe87c8d7cfa826da75a", "target": 0, "func": "static int raw_init_encoder(AVCodecContext *avctx)\n\n{\n\n    avctx->coded_frame = (AVFrame *)avctx->priv_data;\n\n    avctx->coded_frame->pict_type = FF_I_TYPE;\n\n    avctx->coded_frame->key_frame = 1;\n\n    avctx->codec_tag = findFourCC(avctx->pix_fmt);\n\n    return 0;\n\n}\n", "idx": 10410, "_split": "test", "_hash": "20431505383b53689ddb6b3b5d245080"}
{"project": "FFmpeg", "commit_id": "14f3f3a1ad9aca7599bdaa399cdb8680c52dc696", "target": 1, "func": "static int decode_sequence_header_adv(VC1Context *v, GetBitContext *gb)\n\n{\n\n    v->res_rtm_flag = 1;\n\n    v->level = get_bits(gb, 3);\n\n    if(v->level >= 5)\n\n    {\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Reserved LEVEL %i\\n\",v->level);\n\n    }\n\n    v->chromaformat = get_bits(gb, 2);\n\n    if (v->chromaformat != 1)\n\n    {\n\n        av_log(v->s.avctx, AV_LOG_ERROR,\n\n               \"Only 4:2:0 chroma format supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    // (fps-2)/4 (->30)\n\n    v->frmrtq_postproc = get_bits(gb, 3); //common\n\n    // (bitrate-32kbps)/64kbps\n\n    v->bitrtq_postproc = get_bits(gb, 5); //common\n\n    v->postprocflag = get_bits(gb, 1); //common\n\n\n\n    v->s.avctx->coded_width = (get_bits(gb, 12) + 1) << 1;\n\n    v->s.avctx->coded_height = (get_bits(gb, 12) + 1) << 1;\n\n    v->broadcast = get_bits1(gb);\n\n    v->interlace = get_bits1(gb);\n\n    if(v->interlace){\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Interlaced mode not supported (yet)\\n\");\n\n        return -1;\n\n    }\n\n    v->tfcntrflag = get_bits1(gb);\n\n    v->finterpflag = get_bits1(gb);\n\n    get_bits1(gb); // reserved\n\n    v->psf = get_bits1(gb);\n\n    if(v->psf) { //PsF, 6.1.13\n\n        av_log(v->s.avctx, AV_LOG_ERROR, \"Progressive Segmented Frame mode: not supported (yet)\\n\");\n\n        return -1;\n\n    }\n\n    if(get_bits1(gb)) { //Display Info - decoding is not affected by it\n\n        int w, h, ar = 0;\n\n        av_log(v->s.avctx, AV_LOG_INFO, \"Display extended info:\\n\");\n\n        w = get_bits(gb, 14);\n\n        h = get_bits(gb, 14);\n\n        av_log(v->s.avctx, AV_LOG_INFO, \"Display dimensions: %ix%i\\n\", w, h);\n\n        //TODO: store aspect ratio in AVCodecContext\n\n        if(get_bits1(gb))\n\n            ar = get_bits(gb, 4);\n\n        if(ar == 15) {\n\n            w = get_bits(gb, 8);\n\n            h = get_bits(gb, 8);\n\n        }\n\n\n\n        if(get_bits1(gb)){ //framerate stuff\n\n            if(get_bits1(gb)) {\n\n                get_bits(gb, 16);\n\n            } else {\n\n                get_bits(gb, 8);\n\n                get_bits(gb, 4);\n\n            }\n\n        }\n\n\n\n        if(get_bits1(gb)){\n\n            v->color_prim = get_bits(gb, 8);\n\n            v->transfer_char = get_bits(gb, 8);\n\n            v->matrix_coef = get_bits(gb, 8);\n\n        }\n\n    }\n\n\n\n    v->hrd_param_flag = get_bits1(gb);\n\n    if(v->hrd_param_flag) {\n\n        int i;\n\n        v->hrd_num_leaky_buckets = get_bits(gb, 5);\n\n        get_bits(gb, 4); //bitrate exponent\n\n        get_bits(gb, 4); //buffer size exponent\n\n        for(i = 0; i < v->hrd_num_leaky_buckets; i++) {\n\n            get_bits(gb, 16); //hrd_rate[n]\n\n            get_bits(gb, 16); //hrd_buffer[n]\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 10414, "_split": "test", "_hash": "4b4e6d4ce102afc9bd75601153de18f4"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "void ff_put_h264_qpel8_mc23_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_midv_qrt_8w_msa(src - (2 * stride) - 2, stride, dst, stride, 8, 1);\n\n}\n", "idx": 10429, "_split": "test", "_hash": "e2b0b08aa2ec0ae9c58dfebd3f8f1fea"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int film_probe(AVProbeData *p)\n\n{\n\n    if (p->buf_size < 4)\n\n        return 0;\n\n\n\n    if (AV_RB32(&p->buf[0]) != FILM_TAG)\n\n        return 0;\n\n\n\n    return AVPROBE_SCORE_MAX;\n\n}\n", "idx": 10449, "_split": "test", "_hash": "44b7e0586ba0333c74af3301a9f3fabc"}
{"project": "FFmpeg", "commit_id": "70143a3954e1c4412efb2bf1a3a818adea2d3abf", "target": 0, "func": "static int dxva2_retrieve_data(AVCodecContext *s, AVFrame *frame)\n\n{\n\n    InputStream        *ist = s->opaque;\n\n    DXVA2Context       *ctx = ist->hwaccel_ctx;\n\n    int                ret;\n\n\n\n    ret = av_hwframe_transfer_data(ctx->tmp_frame, frame, 0);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    ret = av_frame_copy_props(ctx->tmp_frame, frame);\n\n    if (ret < 0) {\n\n        av_frame_unref(ctx->tmp_frame);\n\n        return ret;\n\n    }\n\n\n\n    av_frame_unref(frame);\n\n    av_frame_move_ref(frame, ctx->tmp_frame);\n\n\n\n    return 0;\n\n}\n", "idx": 10498, "_split": "test", "_hash": "c96107a29a5772ef24f0dce0f9edb95f"}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "void decode_mb_mode(VP8Context *s, VP8Macroblock *mb, int mb_x, int mb_y,\n\n                    uint8_t *segment, uint8_t *ref, int layout)\n\n{\n\n    VP56RangeCoder *c = &s->c;\n\n\n\n    if (s->segmentation.update_map)\n\n        *segment = vp8_rac_get_tree(c, vp8_segmentid_tree, s->prob->segmentid);\n\n    else if (s->segmentation.enabled)\n\n        *segment = ref ? *ref : *segment;\n\n    mb->segment = *segment;\n\n\n\n    mb->skip = s->mbskip_enabled ? vp56_rac_get_prob(c, s->prob->mbskip) : 0;\n\n\n\n    if (s->keyframe) {\n\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_intra,\n\n                                    vp8_pred16x16_prob_intra);\n\n\n\n        if (mb->mode == MODE_I4x4) {\n\n            decode_intra4x4_modes(s, c, mb, mb_x, 1, layout);\n\n        } else {\n\n            const uint32_t modes = vp8_pred4x4_mode[mb->mode] * 0x01010101u;\n\n            if (s->mb_layout == 1)\n\n                AV_WN32A(mb->intra4x4_pred_mode_top, modes);\n\n            else\n\n                AV_WN32A(s->intra4x4_pred_mode_top + 4 * mb_x, modes);\n\n            AV_WN32A(s->intra4x4_pred_mode_left, modes);\n\n        }\n\n\n\n        mb->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree,\n\n                                                vp8_pred8x8c_prob_intra);\n\n        mb->ref_frame        = VP56_FRAME_CURRENT;\n\n    } else if (vp56_rac_get_prob_branchy(c, s->prob->intra)) {\n\n        // inter MB, 16.2\n\n        if (vp56_rac_get_prob_branchy(c, s->prob->last))\n\n            mb->ref_frame =\n\n                vp56_rac_get_prob(c, s->prob->golden) ? VP56_FRAME_GOLDEN2 /* altref */\n\n                                                      : VP56_FRAME_GOLDEN;\n\n        else\n\n            mb->ref_frame = VP56_FRAME_PREVIOUS;\n\n        s->ref_count[mb->ref_frame - 1]++;\n\n\n\n        // motion vectors, 16.3\n\n        decode_mvs(s, mb, mb_x, mb_y, layout);\n\n    } else {\n\n        // intra MB, 16.1\n\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_inter, s->prob->pred16x16);\n\n\n\n        if (mb->mode == MODE_I4x4)\n\n            decode_intra4x4_modes(s, c, mb, mb_x, 0, layout);\n\n\n\n        mb->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree,\n\n                                                s->prob->pred8x8c);\n\n        mb->ref_frame        = VP56_FRAME_CURRENT;\n\n        mb->partitioning     = VP8_SPLITMVMODE_NONE;\n\n        AV_ZERO32(&mb->bmv[0]);\n\n    }\n\n}\n", "idx": 10502, "_split": "test", "_hash": "6bbb33b3673bb72776c35f4423ac512c"}
{"project": "FFmpeg", "commit_id": "ccb76ad91f2b97009b06c22ae1b2e0234dbf26ca", "target": 0, "func": "static void decouple_info(COOKContext *q, COOKSubpacket *p, int *decouple_tab)\n\n{\n\n    int i;\n\n    int vlc    = get_bits1(&q->gb);\n\n    int start  = cplband[p->js_subband_start];\n\n    int end    = cplband[p->subbands - 1];\n\n    int length = end - start + 1;\n\n\n\n    if (start > end)\n\n        return;\n\n\n\n    if (vlc)\n\n        for (i = 0; i < length; i++)\n\n            decouple_tab[start + i] = get_vlc2(&q->gb, p->ccpl.table, p->ccpl.bits, 2);\n\n    else\n\n        for (i = 0; i < length; i++)\n\n            decouple_tab[start + i] = get_bits(&q->gb, p->js_vlc_bits);\n\n}\n", "idx": 10513, "_split": "test", "_hash": "059cd6e6a8c8eaf52b9b5528d01cecab"}
{"project": "FFmpeg", "commit_id": "d1f3e475f9807b445ba37ff2fd23f71c4645de79", "target": 1, "func": "static int prepare_packet(AVPacket *pkt,const FailingMuxerPacketData *pkt_data, int64_t pts)\n\n{\n\n    int ret;\n\n    FailingMuxerPacketData *data = av_malloc(sizeof(*data));\n\n\n\n\n    memcpy(data, pkt_data, sizeof(FailingMuxerPacketData));\n\n    ret = av_packet_from_data(pkt, (uint8_t*) data, sizeof(*data));\n\n\n\n    pkt->pts = pkt->dts = pts;\n\n    pkt->duration = 1;\n\n\n\n    return ret;\n", "idx": 10520, "_split": "test", "_hash": "63c6e983d4dab5dbf9911a28ba1bf15b"}
{"project": "FFmpeg", "commit_id": "54b2d317ed99622efa07b10aca217e1a083105d9", "target": 0, "func": "static void find_best_state(uint8_t best_state[256][256], const uint8_t one_state[256]){\n\n    int i,j,k,m;\n\n    double l2tab[256];\n\n\n\n    for(i=1; i<256; i++)\n\n        l2tab[i]= log2(i/256.0);\n\n\n\n    for(i=0; i<256; i++){\n\n        double best_len[256];\n\n        double p= i/256.0;\n\n\n\n        for(j=0; j<256; j++)\n\n            best_len[j]= 1<<30;\n\n\n\n        for(j=FFMAX(i-10,1); j<FFMIN(i+11,256); j++){\n\n            double occ[256]={0};\n\n            double len=0;\n\n            occ[j]=1.0;\n\n            for(k=0; k<256; k++){\n\n                double newocc[256]={0};\n\n                for(m=0; m<256; m++){\n\n                    if(occ[m]){\n\n                        len -=occ[m]*(     p *l2tab[    m]\n\n                                      + (1-p)*l2tab[256-m]);\n\n                    }\n\n                }\n\n                if(len < best_len[k]){\n\n                    best_len[k]= len;\n\n                    best_state[i][k]= j;\n\n                }\n\n                for(m=0; m<256; m++){\n\n                    if(occ[m]){\n\n                        newocc[    one_state[    m]] += occ[m]*   p ;\n\n                        newocc[256-one_state[256-m]] += occ[m]*(1-p);\n\n                    }\n\n                }\n\n                memcpy(occ, newocc, sizeof(occ));\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 10539, "_split": "test", "_hash": "72b993edefb276aa51153e2a75a019e4"}
{"project": "FFmpeg", "commit_id": "ff486c0f7f6b2ace3f0238660bc06cc35b389676", "target": 0, "func": "static int get_pcm(HEVCContext *s, int x, int y)\n\n{\n\n    int log2_min_pu_size = s->sps->log2_min_pu_size;\n\n    int x_pu             = x >> log2_min_pu_size;\n\n    int y_pu             = y >> log2_min_pu_size;\n\n\n\n    if (x < 0 || x_pu >= s->sps->min_pu_width ||\n\n        y < 0 || y_pu >= s->sps->min_pu_height)\n\n        return 2;\n\n    return s->is_pcm[y_pu * s->sps->min_pu_width + x_pu];\n\n}\n", "idx": 10547, "_split": "test", "_hash": "30749cf897113b9c6d899b0c50bae608"}
{"project": "FFmpeg", "commit_id": "5c2fb561d94fc51d76ab21d6f7cc5b6cc3aa599c", "target": 0, "func": "static int h264_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *got_frame, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    H264Context *h     = avctx->priv_data;\n\n    AVFrame *pict      = data;\n\n    int buf_index      = 0;\n\n    int ret;\n\n    const uint8_t *new_extradata;\n\n    int new_extradata_size;\n\n\n\n    h->flags = avctx->flags;\n\n    h->setup_finished = 0;\n\n\n\n    /* end of stream, output what is still in the buffers */\n\nout:\n\n    if (buf_size == 0) {\n\n        H264Picture *out;\n\n        int i, out_idx;\n\n\n\n        h->cur_pic_ptr = NULL;\n\n\n\n        // FIXME factorize this with the output code below\n\n        out     = h->delayed_pic[0];\n\n        out_idx = 0;\n\n        for (i = 1;\n\n             h->delayed_pic[i] &&\n\n             !h->delayed_pic[i]->f->key_frame &&\n\n             !h->delayed_pic[i]->mmco_reset;\n\n             i++)\n\n            if (h->delayed_pic[i]->poc < out->poc) {\n\n                out     = h->delayed_pic[i];\n\n                out_idx = i;\n\n            }\n\n\n\n        for (i = out_idx; h->delayed_pic[i]; i++)\n\n            h->delayed_pic[i] = h->delayed_pic[i + 1];\n\n\n\n        if (out) {\n\n            ret = output_frame(h, pict, out->f);\n\n            if (ret < 0)\n\n                return ret;\n\n            *got_frame = 1;\n\n        }\n\n\n\n        return buf_index;\n\n    }\n\n\n\n    new_extradata_size = 0;\n\n    new_extradata = av_packet_get_side_data(avpkt, AV_PKT_DATA_NEW_EXTRADATA,\n\n                                            &new_extradata_size);\n\n    if (new_extradata_size > 0 && new_extradata) {\n\n        ret = ff_h264_decode_extradata(new_extradata, new_extradata_size,\n\n                                       &h->ps, &h->is_avc, &h->nal_length_size,\n\n                                       avctx->err_recognition, avctx);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    buf_index = decode_nal_units(h, buf, buf_size);\n\n    if (buf_index < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (!h->cur_pic_ptr && h->nal_unit_type == NAL_END_SEQUENCE) {\n\n        buf_size = 0;\n\n        goto out;\n\n    }\n\n\n\n    if (!(avctx->flags2 & AV_CODEC_FLAG2_CHUNKS) && !h->cur_pic_ptr) {\n\n        if (avctx->skip_frame >= AVDISCARD_NONREF)\n\n            return 0;\n\n        av_log(avctx, AV_LOG_ERROR, \"no frame!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (!(avctx->flags2 & AV_CODEC_FLAG2_CHUNKS) ||\n\n        (h->mb_y >= h->mb_height && h->mb_height)) {\n\n        if (avctx->flags2 & AV_CODEC_FLAG2_CHUNKS)\n\n            decode_postinit(h, 1);\n\n\n\n        ff_h264_field_end(h, &h->slice_ctx[0], 0);\n\n\n\n        *got_frame = 0;\n\n        if (h->next_output_pic && ((avctx->flags & AV_CODEC_FLAG_OUTPUT_CORRUPT) ||\n\n                                   h->next_output_pic->recovered)) {\n\n            if (!h->next_output_pic->recovered)\n\n                h->next_output_pic->f->flags |= AV_FRAME_FLAG_CORRUPT;\n\n\n\n            ret = output_frame(h, pict, h->next_output_pic->f);\n\n            if (ret < 0)\n\n                return ret;\n\n            *got_frame = 1;\n\n        }\n\n    }\n\n\n\n    assert(pict->buf[0] || !*got_frame);\n\n\n\n    return get_consumed_bytes(buf_index, buf_size);\n\n}\n", "idx": 10554, "_split": "test", "_hash": "3c68fc371153fc2b6c042bc587847f73"}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline int16_t calc_lowcomp(int16_t a, int16_t b0, int16_t b1, uint8_t bin)\n\n{\n\n    if (bin < 7) {\n\n        if ((b0 + 256) == b1)\n\n            a = 384;\n\n        else if (b0 > b1)\n\n            a = FFMAX(0, a - 64);\n\n    }\n\n    else if (bin < 20) {\n\n        if ((b0 + 256) == b1)\n\n            a = 320;\n\n        else if (b0 > b1)\n\n            a = FFMAX(0, a - 64);\n\n    }\n\n    else {\n\n        a = FFMAX(0, a - 128);\n\n    }\n\n\n\n    return a;\n\n}\n", "idx": 10556, "_split": "test", "_hash": "e01a220551e123d3558ea025d98ce6f8"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t *udst, uint8_t *vdst,\n\n                                      long width, long height,\n\n                                      long lumStride, long chromStride, long srcStride)\n\n{\n\n    long y;\n\n    const x86_reg chromWidth= width>>1;\n\n    for (y=0; y<height; y+=2) {\n\n#if COMPILE_TEMPLATE_MMX\n\n        __asm__ volatile(\n\n            \"xor                 %%\"REG_a\", %%\"REG_a\"   \\n\\t\"\n\n            \"pcmpeqw                 %%mm7, %%mm7       \\n\\t\"\n\n            \"psrlw                      $8, %%mm7       \\n\\t\" // FF,00,FF,00...\n\n            \".p2align                    4              \\n\\t\"\n\n            \"1:                \\n\\t\"\n\n            PREFETCH\" 64(%0, %%\"REG_a\", 4)              \\n\\t\"\n\n            \"movq       (%0, %%\"REG_a\", 4), %%mm0       \\n\\t\" // YUYV YUYV(0)\n\n            \"movq      8(%0, %%\"REG_a\", 4), %%mm1       \\n\\t\" // YUYV YUYV(4)\n\n            \"movq                    %%mm0, %%mm2       \\n\\t\" // YUYV YUYV(0)\n\n            \"movq                    %%mm1, %%mm3       \\n\\t\" // YUYV YUYV(4)\n\n            \"psrlw                      $8, %%mm0       \\n\\t\" // U0V0 U0V0(0)\n\n            \"psrlw                      $8, %%mm1       \\n\\t\" // U0V0 U0V0(4)\n\n            \"pand                    %%mm7, %%mm2       \\n\\t\" // Y0Y0 Y0Y0(0)\n\n            \"pand                    %%mm7, %%mm3       \\n\\t\" // Y0Y0 Y0Y0(4)\n\n            \"packuswb                %%mm1, %%mm0       \\n\\t\" // UVUV UVUV(0)\n\n            \"packuswb                %%mm3, %%mm2       \\n\\t\" // YYYY YYYY(0)\n\n\n\n            MOVNTQ\"                  %%mm2, (%1, %%\"REG_a\", 2)  \\n\\t\"\n\n\n\n            \"movq     16(%0, %%\"REG_a\", 4), %%mm1       \\n\\t\" // YUYV YUYV(8)\n\n            \"movq     24(%0, %%\"REG_a\", 4), %%mm2       \\n\\t\" // YUYV YUYV(12)\n\n            \"movq                    %%mm1, %%mm3       \\n\\t\" // YUYV YUYV(8)\n\n            \"movq                    %%mm2, %%mm4       \\n\\t\" // YUYV YUYV(12)\n\n            \"psrlw                      $8, %%mm1       \\n\\t\" // U0V0 U0V0(8)\n\n            \"psrlw                      $8, %%mm2       \\n\\t\" // U0V0 U0V0(12)\n\n            \"pand                    %%mm7, %%mm3       \\n\\t\" // Y0Y0 Y0Y0(8)\n\n            \"pand                    %%mm7, %%mm4       \\n\\t\" // Y0Y0 Y0Y0(12)\n\n            \"packuswb                %%mm2, %%mm1       \\n\\t\" // UVUV UVUV(8)\n\n            \"packuswb                %%mm4, %%mm3       \\n\\t\" // YYYY YYYY(8)\n\n\n\n            MOVNTQ\"                  %%mm3, 8(%1, %%\"REG_a\", 2) \\n\\t\"\n\n\n\n            \"movq                    %%mm0, %%mm2       \\n\\t\" // UVUV UVUV(0)\n\n            \"movq                    %%mm1, %%mm3       \\n\\t\" // UVUV UVUV(8)\n\n            \"psrlw                      $8, %%mm0       \\n\\t\" // V0V0 V0V0(0)\n\n            \"psrlw                      $8, %%mm1       \\n\\t\" // V0V0 V0V0(8)\n\n            \"pand                    %%mm7, %%mm2       \\n\\t\" // U0U0 U0U0(0)\n\n            \"pand                    %%mm7, %%mm3       \\n\\t\" // U0U0 U0U0(8)\n\n            \"packuswb                %%mm1, %%mm0       \\n\\t\" // VVVV VVVV(0)\n\n            \"packuswb                %%mm3, %%mm2       \\n\\t\" // UUUU UUUU(0)\n\n\n\n            MOVNTQ\"                  %%mm0, (%3, %%\"REG_a\")     \\n\\t\"\n\n            MOVNTQ\"                  %%mm2, (%2, %%\"REG_a\")     \\n\\t\"\n\n\n\n            \"add                        $8, %%\"REG_a\"   \\n\\t\"\n\n            \"cmp                        %4, %%\"REG_a\"   \\n\\t\"\n\n            \" jb                        1b              \\n\\t\"\n\n            ::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n            : \"memory\", \"%\"REG_a\n\n        );\n\n\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n\n\n        __asm__ volatile(\n\n            \"xor                 %%\"REG_a\", %%\"REG_a\"   \\n\\t\"\n\n            \".p2align                    4              \\n\\t\"\n\n            \"1:                                         \\n\\t\"\n\n            PREFETCH\" 64(%0, %%\"REG_a\", 4)              \\n\\t\"\n\n            \"movq       (%0, %%\"REG_a\", 4), %%mm0       \\n\\t\" // YUYV YUYV(0)\n\n            \"movq      8(%0, %%\"REG_a\", 4), %%mm1       \\n\\t\" // YUYV YUYV(4)\n\n            \"movq     16(%0, %%\"REG_a\", 4), %%mm2       \\n\\t\" // YUYV YUYV(8)\n\n            \"movq     24(%0, %%\"REG_a\", 4), %%mm3       \\n\\t\" // YUYV YUYV(12)\n\n            \"pand                    %%mm7, %%mm0       \\n\\t\" // Y0Y0 Y0Y0(0)\n\n            \"pand                    %%mm7, %%mm1       \\n\\t\" // Y0Y0 Y0Y0(4)\n\n            \"pand                    %%mm7, %%mm2       \\n\\t\" // Y0Y0 Y0Y0(8)\n\n            \"pand                    %%mm7, %%mm3       \\n\\t\" // Y0Y0 Y0Y0(12)\n\n            \"packuswb                %%mm1, %%mm0       \\n\\t\" // YYYY YYYY(0)\n\n            \"packuswb                %%mm3, %%mm2       \\n\\t\" // YYYY YYYY(8)\n\n\n\n            MOVNTQ\"                  %%mm0,  (%1, %%\"REG_a\", 2) \\n\\t\"\n\n            MOVNTQ\"                  %%mm2, 8(%1, %%\"REG_a\", 2) \\n\\t\"\n\n\n\n            \"add                        $8, %%\"REG_a\"   \\n\\t\"\n\n            \"cmp                        %4, %%\"REG_a\"   \\n\\t\"\n\n            \" jb                        1b              \\n\\t\"\n\n\n\n            ::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" (chromWidth)\n\n            : \"memory\", \"%\"REG_a\n\n        );\n\n#else\n\n        long i;\n\n        for (i=0; i<chromWidth; i++) {\n\n            ydst[2*i+0]     = src[4*i+0];\n\n            udst[i]     = src[4*i+1];\n\n            ydst[2*i+1]     = src[4*i+2];\n\n            vdst[i]     = src[4*i+3];\n\n        }\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n\n\n        for (i=0; i<chromWidth; i++) {\n\n            ydst[2*i+0]     = src[4*i+0];\n\n            ydst[2*i+1]     = src[4*i+2];\n\n        }\n\n#endif\n\n        udst += chromStride;\n\n        vdst += chromStride;\n\n        ydst += lumStride;\n\n        src  += srcStride;\n\n    }\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(EMMS\"       \\n\\t\"\n\n                     SFENCE\"     \\n\\t\"\n\n                     :::\"memory\");\n\n#endif\n\n}\n", "idx": 10564, "_split": "test", "_hash": "658b68aa0873dd0a31fa1e4f35af12db"}
{"project": "FFmpeg", "commit_id": "a026a3efaeb9c2026668dccbbda339a21ab3206b", "target": 1, "func": "static av_always_inline int coeff_abs_level_remaining_decode(HEVCContext *s, int rc_rice_param)\n\n{\n\n    int prefix = 0;\n\n    int suffix = 0;\n\n    int last_coeff_abs_level_remaining;\n\n    int i;\n\n\n\n    while (prefix < CABAC_MAX_BIN && get_cabac_bypass(&s->HEVClc->cc))\n\n        prefix++;\n\n\n\n    if (prefix < 3) {\n\n        for (i = 0; i < rc_rice_param; i++)\n\n            suffix = (suffix << 1) | get_cabac_bypass(&s->HEVClc->cc);\n\n        last_coeff_abs_level_remaining = (prefix << rc_rice_param) + suffix;\n\n    } else {\n\n        int prefix_minus3 = prefix - 3;\n\n\n\n        if (prefix == CABAC_MAX_BIN) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"CABAC_MAX_BIN : %d\\n\", prefix);\n\n            return 0;\n\n        }\n\n\n\n        for (i = 0; i < prefix_minus3 + rc_rice_param; i++)\n\n            suffix = (suffix << 1) | get_cabac_bypass(&s->HEVClc->cc);\n\n        last_coeff_abs_level_remaining = (((1 << prefix_minus3) + 3 - 1)\n\n                                              << rc_rice_param) + suffix;\n\n    }\n\n    return last_coeff_abs_level_remaining;\n\n}\n", "idx": 10609, "_split": "test", "_hash": "f85e34fe3a5d469c85e0f2ae33b5f8d3"}
{"project": "FFmpeg", "commit_id": "9f61abc8111c7c43f49ca012e957a108b9cc7610", "target": 0, "func": "static int segment_hls_window(AVFormatContext *s, int last)\n\n{\n\n    SegmentContext *seg = s->priv_data;\n\n    int i, ret = 0;\n\n    char buf[1024];\n\n\n\n    if ((ret = avio_open2(&seg->pb, seg->list, AVIO_FLAG_WRITE,\n\n                              &s->interrupt_callback, NULL)) < 0)\n\n        goto fail;\n\n\n\n    avio_printf(seg->pb, \"#EXTM3U\\n\");\n\n    avio_printf(seg->pb, \"#EXT-X-VERSION:3\\n\");\n\n    avio_printf(seg->pb, \"#EXT-X-TARGETDURATION:%d\\n\", (int)seg->time);\n\n    avio_printf(seg->pb, \"#EXT-X-MEDIA-SEQUENCE:%d\\n\",\n\n                FFMAX(0, seg->number - seg->size));\n\n\n\n    av_log(s, AV_LOG_VERBOSE, \"EXT-X-MEDIA-SEQUENCE:%d\\n\",\n\n           FFMAX(0, seg->number - seg->size));\n\n\n\n    for (i = FFMAX(0, seg->number - seg->size);\n\n         i < seg->number; i++) {\n\n        avio_printf(seg->pb, \"#EXTINF:%d,\\n\", (int)seg->time);\n\n        if (seg->entry_prefix) {\n\n            avio_printf(seg->pb, \"%s\", seg->entry_prefix);\n\n        }\n\n        ret = av_get_frame_filename(buf, sizeof(buf), s->filename, i);\n\n        if (ret < 0) {\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        avio_printf(seg->pb, \"%s\\n\", buf);\n\n    }\n\n\n\n    if (last)\n\n        avio_printf(seg->pb, \"#EXT-X-ENDLIST\\n\");\n\nfail:\n\n    avio_closep(&seg->pb);\n\n    return ret;\n\n}\n", "idx": 10620, "_split": "test", "_hash": "bf5533fcd2eee3e21a3d7f319da0fd6f"}
{"project": "FFmpeg", "commit_id": "b4886795108e319a5b3a88370e90207d9c15a01e", "target": 1, "func": "static int decode_frame_byterun1(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    IffContext *s = avctx->priv_data;\n\n    const uint8_t *buf = avpkt->size >= 2 ? avpkt->data + AV_RB16(avpkt->data) : NULL;\n\n    const int buf_size = avpkt->size >= 2 ? avpkt->size - AV_RB16(avpkt->data) : 0;\n\n    const uint8_t *buf_end = buf+buf_size;\n\n    int y, plane, res;\n\n\n\n    if ((res = extract_header(avctx, avpkt)) < 0)\n\n        return res;\n\n    if (s->init) {\n\n        if ((res = avctx->reget_buffer(avctx, &s->frame)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n            return res;\n\n        }\n\n    } else if ((res = avctx->get_buffer(avctx, &s->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return res;\n\n    } else if (avctx->bits_per_coded_sample <= 8 && avctx->pix_fmt != PIX_FMT_GRAY8) {\n\n        if ((res = ff_cmap_read_palette(avctx, (uint32_t*)s->frame.data[1])) < 0)\n\n            return res;\n\n    }\n\n    s->init = 1;\n\n\n\n    if (avctx->codec_tag == MKTAG('I','L','B','M')) { //interleaved\n\n        if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n            for(y = 0; y < avctx->height ; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                memset(row, 0, avctx->width);\n\n                for (plane = 0; plane < s->bpp; plane++) {\n\n                    buf += decode_byterun(s->planebuf, s->planesize, buf, buf_end);\n\n                    decodeplane8(row, s->planebuf, s->planesize, plane);\n\n                }\n\n            }\n\n        } else if (s->ham) { // HAM to PIX_FMT_BGR32\n\n            for (y = 0; y < avctx->height ; y++) {\n\n                uint8_t *row = &s->frame.data[0][y*s->frame.linesize[0]];\n\n                memset(s->ham_buf, 0, avctx->width);\n\n                for (plane = 0; plane < s->bpp; plane++) {\n\n                    buf += decode_byterun(s->planebuf, s->planesize, buf, buf_end);\n\n                    decodeplane8(s->ham_buf, s->planebuf, s->planesize, plane);\n\n                }\n\n                decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, s->planesize);\n\n            }\n\n        } else { //PIX_FMT_BGR32\n\n            for(y = 0; y < avctx->height ; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][y*s->frame.linesize[0]];\n\n                memset(row, 0, avctx->width << 2);\n\n                for (plane = 0; plane < s->bpp; plane++) {\n\n                    buf += decode_byterun(s->planebuf, s->planesize, buf, buf_end);\n\n                    decodeplane32((uint32_t *) row, s->planebuf, s->planesize, plane);\n\n                }\n\n            }\n\n        }\n\n    } else if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) { // IFF-PBM\n\n        for(y = 0; y < avctx->height ; y++ ) {\n\n            uint8_t *row = &s->frame.data[0][y*s->frame.linesize[0]];\n\n            buf += decode_byterun(row, avctx->width, buf, buf_end);\n\n        }\n\n    } else { // IFF-PBM: HAM to PIX_FMT_BGR32\n\n        for (y = 0; y < avctx->height ; y++) {\n\n            uint8_t *row = &s->frame.data[0][y*s->frame.linesize[0]];\n\n            buf += decode_byterun(s->ham_buf, avctx->width, buf, buf_end);\n\n            decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, avctx->width);\n\n        }\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n    return buf_size;\n\n}\n", "idx": 10665, "_split": "test", "_hash": "b9d88e21ba3a6a64455ba7f6702aa126"}
{"project": "FFmpeg", "commit_id": "29d2dc59f973f9495c703b4cab17ded5c24ab3e8", "target": 1, "func": "int alloc_picture(MpegEncContext *s, Picture *pic, int shared){\n\n    const int big_mb_num= s->mb_stride*(s->mb_height+1) + 1; //the +1 is needed so memset(,,stride*height) does not sig11\n\n    const int mb_array_size= s->mb_stride*s->mb_height;\n\n    const int b8_array_size= s->b8_stride*s->mb_height*2;\n\n    const int b4_array_size= s->b4_stride*s->mb_height*4;\n\n    int i;\n\n\n\n    if(shared){\n\n        assert(pic->data[0]);\n\n        assert(pic->type == 0 || pic->type == FF_BUFFER_TYPE_SHARED);\n\n        pic->type= FF_BUFFER_TYPE_SHARED;\n\n    }else{\n\n        int r;\n\n\n\n        assert(!pic->data[0]);\n\n\n\n        r= s->avctx->get_buffer(s->avctx, (AVFrame*)pic);\n\n\n\n        if(r<0 || !pic->age || !pic->type || !pic->data[0]){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed (%d %d %d %p)\\n\", r, pic->age, pic->type, pic->data[0]);\n\n            return -1;\n\n        }\n\n\n\n        if(s->linesize && (s->linesize != pic->linesize[0] || s->uvlinesize != pic->linesize[1])){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed (stride changed)\\n\");\n\n            return -1;\n\n        }\n\n\n\n        if(pic->linesize[1] != pic->linesize[2]){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed (uv stride mismatch)\\n\");\n\n            return -1;\n\n        }\n\n\n\n        s->linesize  = pic->linesize[0];\n\n        s->uvlinesize= pic->linesize[1];\n\n    }\n\n\n\n    if(pic->qscale_table==NULL){\n\n        if (s->encoding) {\n\n            CHECKED_ALLOCZ(pic->mb_var   , mb_array_size * sizeof(int16_t))\n\n            CHECKED_ALLOCZ(pic->mc_mb_var, mb_array_size * sizeof(int16_t))\n\n            CHECKED_ALLOCZ(pic->mb_mean  , mb_array_size * sizeof(int8_t))\n\n        }\n\n\n\n        CHECKED_ALLOCZ(pic->mbskip_table , mb_array_size * sizeof(uint8_t)+2) //the +2 is for the slice end check\n\n        CHECKED_ALLOCZ(pic->qscale_table , mb_array_size * sizeof(uint8_t))\n\n        CHECKED_ALLOCZ(pic->mb_type_base , big_mb_num    * sizeof(uint32_t))\n\n        pic->mb_type= pic->mb_type_base + s->mb_stride+1;\n\n        if(s->out_format == FMT_H264){\n\n            for(i=0; i<2; i++){\n\n                CHECKED_ALLOCZ(pic->motion_val_base[i], 2 * (b4_array_size+4)  * sizeof(int16_t))\n\n                pic->motion_val[i]= pic->motion_val_base[i]+4;\n\n                CHECKED_ALLOCZ(pic->ref_index[i], b8_array_size * sizeof(uint8_t))\n\n            }\n\n            pic->motion_subsample_log2= 2;\n\n        }else if(s->out_format == FMT_H263 || s->encoding || (s->avctx->debug&FF_DEBUG_MV) || (s->avctx->debug_mv)){\n\n            for(i=0; i<2; i++){\n\n                CHECKED_ALLOCZ(pic->motion_val_base[i], 2 * (b8_array_size+4) * sizeof(int16_t))\n\n                pic->motion_val[i]= pic->motion_val_base[i]+4;\n\n                CHECKED_ALLOCZ(pic->ref_index[i], b8_array_size * sizeof(uint8_t))\n\n            }\n\n            pic->motion_subsample_log2= 3;\n\n        }\n\n        if(s->avctx->debug&FF_DEBUG_DCT_COEFF) {\n\n            CHECKED_ALLOCZ(pic->dct_coeff, 64 * mb_array_size * sizeof(DCTELEM)*6)\n\n        }\n\n        pic->qstride= s->mb_stride;\n\n        CHECKED_ALLOCZ(pic->pan_scan , 1 * sizeof(AVPanScan))\n\n    }\n\n\n\n    /* It might be nicer if the application would keep track of these\n\n     * but it would require an API change. */\n\n    memmove(s->prev_pict_types+1, s->prev_pict_types, PREV_PICT_TYPES_BUFFER_SIZE-1);\n\n    s->prev_pict_types[0]= s->pict_type;\n\n    if(pic->age < PREV_PICT_TYPES_BUFFER_SIZE && s->prev_pict_types[pic->age] == B_TYPE)\n\n        pic->age= INT_MAX; // Skipped MBs in B-frames are quite rare in MPEG-1/2 and it is a bit tricky to skip them anyway.\n\n\n\n    return 0;\n\nfail: //for the CHECKED_ALLOCZ macro\n\n    return -1;\n\n}\n", "idx": 10670, "_split": "test", "_hash": "a031955b44c71a5d887fdd1ed720b629"}
{"project": "FFmpeg", "commit_id": "fa5dacce143f3fbe8eac14d5a99e926b2787e9e6", "target": 1, "func": "static int decode_pic_hdr(IVI5DecContext *ctx, AVCodecContext *avctx)\n{\n    if (get_bits(&ctx->gb, 5) != 0x1F) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid picture start code!\\n\");\n        return -1;\n    ctx->prev_frame_type = ctx->frame_type;\n    ctx->frame_type      = get_bits(&ctx->gb, 3);\n    if (ctx->frame_type >= 5) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid frame type: %d \\n\", ctx->frame_type);\n        return -1;\n    ctx->frame_num = get_bits(&ctx->gb, 8);\n    if (ctx->frame_type == FRAMETYPE_INTRA) {\n        ctx->gop_invalid = 1;\n        if (decode_gop_header(ctx, avctx))\n            return -1;\n        ctx->gop_invalid = 0;\n    if (ctx->frame_type != FRAMETYPE_NULL) {\n        ctx->frame_flags = get_bits(&ctx->gb, 8);\n        ctx->pic_hdr_size = (ctx->frame_flags & 1) ? get_bits_long(&ctx->gb, 24) : 0;\n        ctx->checksum = (ctx->frame_flags & 0x10) ? get_bits(&ctx->gb, 16) : 0;\n        /* skip unknown extension if any */\n        if (ctx->frame_flags & 0x20)\n            skip_hdr_extension(&ctx->gb); /* XXX: untested */\n        /* decode macroblock huffman codebook */\n        if (ff_ivi_dec_huff_desc(&ctx->gb, ctx->frame_flags & 0x40, IVI_MB_HUFF, &ctx->mb_vlc, avctx))\n            return -1;\n        skip_bits(&ctx->gb, 3); /* FIXME: unknown meaning! */\n    align_get_bits(&ctx->gb);\n    return 0;", "idx": 10671, "_split": "test", "_hash": "1aaff68c612e06ad235c8717ce9c6a85"}
{"project": "FFmpeg", "commit_id": "64f7db554ee83846f207e82a08946a6a5a6acfe2", "target": 1, "func": "static int mpegts_write_header(AVFormatContext *s)\n\n{\n\n    MpegTSWrite *ts = s->priv_data;\n\n    MpegTSWriteStream *ts_st;\n\n    MpegTSService *service;\n\n    AVStream *st, *pcr_st = NULL;\n\n    AVDictionaryEntry *title, *provider;\n\n    int i, j;\n\n    const char *service_name;\n\n    const char *provider_name;\n\n    int *pids;\n\n    int ret;\n\n\n\n    if (s->max_delay < 0) /* Not set by the caller */\n\n        s->max_delay = 0;\n\n\n\n    // round up to a whole number of TS packets\n\n    ts->pes_payload_size = (ts->pes_payload_size + 14 + 183) / 184 * 184 - 14;\n\n\n\n    ts->tsid = ts->transport_stream_id;\n\n    ts->onid = ts->original_network_id;\n\n    /* allocate a single DVB service */\n\n    title = av_dict_get(s->metadata, \"service_name\", NULL, 0);\n\n    if (!title)\n\n        title = av_dict_get(s->metadata, \"title\", NULL, 0);\n\n    service_name  = title ? title->value : DEFAULT_SERVICE_NAME;\n\n    provider      = av_dict_get(s->metadata, \"service_provider\", NULL, 0);\n\n    provider_name = provider ? provider->value : DEFAULT_PROVIDER_NAME;\n\n    service       = mpegts_add_service(ts, ts->service_id,\n\n                                       provider_name, service_name);\n\n\n\n    if (!service)\n\n        return AVERROR(ENOMEM);\n\n\n\n    service->pmt.write_packet = section_write_packet;\n\n    service->pmt.opaque       = s;\n\n    service->pmt.cc           = 15;\n\n\n\n    ts->pat.pid          = PAT_PID;\n\n    /* Initialize at 15 so that it wraps and is equal to 0 for the\n\n     * first packet we write. */\n\n    ts->pat.cc           = 15;\n\n    ts->pat.write_packet = section_write_packet;\n\n    ts->pat.opaque       = s;\n\n\n\n    ts->sdt.pid          = SDT_PID;\n\n    ts->sdt.cc           = 15;\n\n    ts->sdt.write_packet = section_write_packet;\n\n    ts->sdt.opaque       = s;\n\n\n\n    pids = av_malloc_array(s->nb_streams, sizeof(*pids));\n\n    if (!pids) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    /* assign pids to each stream */\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        st = s->streams[i];\n\n\n\n        ts_st = av_mallocz(sizeof(MpegTSWriteStream));\n\n        if (!ts_st) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        st->priv_data = ts_st;\n\n\n\n        ts_st->user_tb = st->time_base;\n\n        avpriv_set_pts_info(st, 33, 1, 90000);\n\n\n\n        ts_st->payload = av_mallocz(ts->pes_payload_size);\n\n        if (!ts_st->payload) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        ts_st->service = service;\n\n        /* MPEG pid values < 16 are reserved. Applications which set st->id in\n\n         * this range are assigned a calculated pid. */\n\n        if (st->id < 16) {\n\n            ts_st->pid = ts->start_pid + i;\n\n        } else if (st->id < 0x1FFF) {\n\n            ts_st->pid = st->id;\n\n        } else {\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"Invalid stream id %d, must be less than 8191\\n\", st->id);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        if (ts_st->pid == service->pmt.pid) {\n\n            av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n\n            ret = AVERROR(EINVAL);\n\n            goto fail;\n\n        }\n\n        for (j = 0; j < i; j++) {\n\n            if (pids[j] == ts_st->pid) {\n\n                av_log(s, AV_LOG_ERROR, \"Duplicate stream id %d\\n\", ts_st->pid);\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n        }\n\n        pids[i]                = ts_st->pid;\n\n        ts_st->payload_pts     = AV_NOPTS_VALUE;\n\n        ts_st->payload_dts     = AV_NOPTS_VALUE;\n\n        ts_st->first_pts_check = 1;\n\n        ts_st->cc              = 15;\n\n        /* update PCR pid by using the first video stream */\n\n        if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO &&\n\n            service->pcr_pid == 0x1fff) {\n\n            service->pcr_pid = ts_st->pid;\n\n            pcr_st           = st;\n\n        }\n\n        if (st->codec->codec_id == AV_CODEC_ID_AAC &&\n\n            st->codec->extradata_size > 0) {\n\n            AVStream *ast;\n\n            ts_st->amux = avformat_alloc_context();\n\n            if (!ts_st->amux) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            ts_st->amux->oformat =\n\n                av_guess_format((ts->flags & MPEGTS_FLAG_AAC_LATM) ? \"latm\" : \"adts\",\n\n                                NULL, NULL);\n\n            if (!ts_st->amux->oformat) {\n\n                ret = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            if (!(ast = avformat_new_stream(ts_st->amux, NULL))) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            ret = avcodec_copy_context(ast->codec, st->codec);\n\n            if (ret != 0)\n\n                goto fail;\n\n            ast->time_base = st->time_base;\n\n            ret = avformat_write_header(ts_st->amux, NULL);\n\n            if (ret < 0)\n\n                goto fail;\n\n        }\n\n        if (st->codec->codec_id == AV_CODEC_ID_OPUS) {\n\n            ts_st->opus_pending_trim_start = st->codec->initial_padding * 48000 / st->codec->sample_rate;\n\n        }\n\n    }\n\n\n\n    av_freep(&pids);\n\n\n\n    /* if no video stream, use the first stream as PCR */\n\n    if (service->pcr_pid == 0x1fff && s->nb_streams > 0) {\n\n        pcr_st           = s->streams[0];\n\n        ts_st            = pcr_st->priv_data;\n\n        service->pcr_pid = ts_st->pid;\n\n    } else\n\n        ts_st = pcr_st->priv_data;\n\n\n\n    if (ts->mux_rate > 1) {\n\n        service->pcr_packet_period = (ts->mux_rate * ts->pcr_period) /\n\n                                     (TS_PACKET_SIZE * 8 * 1000);\n\n        ts->sdt_packet_period      = (ts->mux_rate * SDT_RETRANS_TIME) /\n\n                                     (TS_PACKET_SIZE * 8 * 1000);\n\n        ts->pat_packet_period      = (ts->mux_rate * PAT_RETRANS_TIME) /\n\n                                     (TS_PACKET_SIZE * 8 * 1000);\n\n\n\n        if (ts->copyts < 1)\n\n            ts->first_pcr = av_rescale(s->max_delay, PCR_TIME_BASE, AV_TIME_BASE);\n\n    } else {\n\n        /* Arbitrary values, PAT/PMT will also be written on video key frames */\n\n        ts->sdt_packet_period = 200;\n\n        ts->pat_packet_period = 40;\n\n        if (pcr_st->codec->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (!pcr_st->codec->frame_size) {\n\n                av_log(s, AV_LOG_WARNING, \"frame size not set\\n\");\n\n                service->pcr_packet_period =\n\n                    pcr_st->codec->sample_rate / (10 * 512);\n\n            } else {\n\n                service->pcr_packet_period =\n\n                    pcr_st->codec->sample_rate / (10 * pcr_st->codec->frame_size);\n\n            }\n\n        } else {\n\n            // max delta PCR 0.1s\n\n            // TODO: should be avg_frame_rate\n\n            service->pcr_packet_period =\n\n                ts_st->user_tb.den / (10 * ts_st->user_tb.num);\n\n        }\n\n        if (!service->pcr_packet_period)\n\n            service->pcr_packet_period = 1;\n\n    }\n\n\n\n    ts->last_pat_ts = AV_NOPTS_VALUE;\n\n    ts->last_sdt_ts = AV_NOPTS_VALUE;\n\n    // The user specified a period, use only it\n\n    if (ts->pat_period < INT_MAX/2) {\n\n        ts->pat_packet_period = INT_MAX;\n\n    }\n\n    if (ts->sdt_period < INT_MAX/2) {\n\n        ts->sdt_packet_period = INT_MAX;\n\n    }\n\n\n\n    // output a PCR as soon as possible\n\n    service->pcr_packet_count = service->pcr_packet_period;\n\n    ts->pat_packet_count      = ts->pat_packet_period - 1;\n\n    ts->sdt_packet_count      = ts->sdt_packet_period - 1;\n\n\n\n    if (ts->mux_rate == 1)\n\n        av_log(s, AV_LOG_VERBOSE, \"muxrate VBR, \");\n\n    else\n\n        av_log(s, AV_LOG_VERBOSE, \"muxrate %d, \", ts->mux_rate);\n\n    av_log(s, AV_LOG_VERBOSE,\n\n           \"pcr every %d pkts, sdt every %d, pat/pmt every %d pkts\\n\",\n\n           service->pcr_packet_period,\n\n           ts->sdt_packet_period, ts->pat_packet_period);\n\n\n\n    if (ts->m2ts_mode == -1) {\n\n        if (av_match_ext(s->filename, \"m2ts\")) {\n\n            ts->m2ts_mode = 1;\n\n        } else {\n\n            ts->m2ts_mode = 0;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_freep(&pids);\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        st    = s->streams[i];\n\n        ts_st = st->priv_data;\n\n        if (ts_st) {\n\n            av_freep(&ts_st->payload);\n\n            if (ts_st->amux) {\n\n                avformat_free_context(ts_st->amux);\n\n                ts_st->amux = NULL;\n\n            }\n\n        }\n\n        av_freep(&st->priv_data);\n\n    }\n\n\n\n    for (i = 0; i < ts->nb_services; i++) {\n\n        service = ts->services[i];\n\n        av_freep(&service->provider_name);\n\n        av_freep(&service->name);\n\n        av_freep(&service);\n\n    }\n\n    av_freep(&ts->services);\n\n    return ret;\n\n}\n", "idx": 10672, "_split": "test", "_hash": "2f8307b9ce53a13dea9330c54583d17e"}
{"project": "FFmpeg", "commit_id": "15ccaa344c4f645ae791aafecdef3d886e196127", "target": 1, "func": "void dct32(INTFLOAT *out, const INTFLOAT *tab)\n\n{\n\n    INTFLOAT tmp0, tmp1;\n\n\n\n    INTFLOAT val0 , val1 , val2 , val3 , val4 , val5 , val6 , val7 ,\n\n             val8 , val9 , val10, val11, val12, val13, val14, val15,\n\n             val16, val17, val18, val19, val20, val21, val22, val23,\n\n             val24, val25, val26, val27, val28, val29, val30, val31;\n\n\n\n    /* pass 1 */\n\n    BF0( 0, 31, COS0_0 , 1);\n\n    BF0(15, 16, COS0_15, 5);\n\n    /* pass 2 */\n\n    BF( 0, 15, COS1_0 , 1);\n\n    BF(16, 31,-COS1_0 , 1);\n\n    /* pass 1 */\n\n    BF0( 7, 24, COS0_7 , 1);\n\n    BF0( 8, 23, COS0_8 , 1);\n\n    /* pass 2 */\n\n    BF( 7,  8, COS1_7 , 4);\n\n    BF(23, 24,-COS1_7 , 4);\n\n    /* pass 3 */\n\n    BF( 0,  7, COS2_0 , 1);\n\n    BF( 8, 15,-COS2_0 , 1);\n\n    BF(16, 23, COS2_0 , 1);\n\n    BF(24, 31,-COS2_0 , 1);\n\n    /* pass 1 */\n\n    BF0( 3, 28, COS0_3 , 1);\n\n    BF0(12, 19, COS0_12, 2);\n\n    /* pass 2 */\n\n    BF( 3, 12, COS1_3 , 1);\n\n    BF(19, 28,-COS1_3 , 1);\n\n    /* pass 1 */\n\n    BF0( 4, 27, COS0_4 , 1);\n\n    BF0(11, 20, COS0_11, 2);\n\n    /* pass 2 */\n\n    BF( 4, 11, COS1_4 , 1);\n\n    BF(20, 27,-COS1_4 , 1);\n\n    /* pass 3 */\n\n    BF( 3,  4, COS2_3 , 3);\n\n    BF(11, 12,-COS2_3 , 3);\n\n    BF(19, 20, COS2_3 , 3);\n\n    BF(27, 28,-COS2_3 , 3);\n\n    /* pass 4 */\n\n    BF( 0,  3, COS3_0 , 1);\n\n    BF( 4,  7,-COS3_0 , 1);\n\n    BF( 8, 11, COS3_0 , 1);\n\n    BF(12, 15,-COS3_0 , 1);\n\n    BF(16, 19, COS3_0 , 1);\n\n    BF(20, 23,-COS3_0 , 1);\n\n    BF(24, 27, COS3_0 , 1);\n\n    BF(28, 31,-COS3_0 , 1);\n\n\n\n\n\n\n\n    /* pass 1 */\n\n    BF0( 1, 30, COS0_1 , 1);\n\n    BF0(14, 17, COS0_14, 3);\n\n    /* pass 2 */\n\n    BF( 1, 14, COS1_1 , 1);\n\n    BF(17, 30,-COS1_1 , 1);\n\n    /* pass 1 */\n\n    BF0( 6, 25, COS0_6 , 1);\n\n    BF0( 9, 22, COS0_9 , 1);\n\n    /* pass 2 */\n\n    BF( 6,  9, COS1_6 , 2);\n\n    BF(22, 25,-COS1_6 , 2);\n\n    /* pass 3 */\n\n    BF( 1,  6, COS2_1 , 1);\n\n    BF( 9, 14,-COS2_1 , 1);\n\n    BF(17, 22, COS2_1 , 1);\n\n    BF(25, 30,-COS2_1 , 1);\n\n\n\n    /* pass 1 */\n\n    BF0( 2, 29, COS0_2 , 1);\n\n    BF0(13, 18, COS0_13, 3);\n\n    /* pass 2 */\n\n    BF( 2, 13, COS1_2 , 1);\n\n    BF(18, 29,-COS1_2 , 1);\n\n    /* pass 1 */\n\n    BF0( 5, 26, COS0_5 , 1);\n\n    BF0(10, 21, COS0_10, 1);\n\n    /* pass 2 */\n\n    BF( 5, 10, COS1_5 , 2);\n\n    BF(21, 26,-COS1_5 , 2);\n\n    /* pass 3 */\n\n    BF( 2,  5, COS2_2 , 1);\n\n    BF(10, 13,-COS2_2 , 1);\n\n    BF(18, 21, COS2_2 , 1);\n\n    BF(26, 29,-COS2_2 , 1);\n\n    /* pass 4 */\n\n    BF( 1,  2, COS3_1 , 2);\n\n    BF( 5,  6,-COS3_1 , 2);\n\n    BF( 9, 10, COS3_1 , 2);\n\n    BF(13, 14,-COS3_1 , 2);\n\n    BF(17, 18, COS3_1 , 2);\n\n    BF(21, 22,-COS3_1 , 2);\n\n    BF(25, 26, COS3_1 , 2);\n\n    BF(29, 30,-COS3_1 , 2);\n\n\n\n    /* pass 5 */\n\n    BF1( 0,  1,  2,  3);\n\n    BF2( 4,  5,  6,  7);\n\n    BF1( 8,  9, 10, 11);\n\n    BF2(12, 13, 14, 15);\n\n    BF1(16, 17, 18, 19);\n\n    BF2(20, 21, 22, 23);\n\n    BF1(24, 25, 26, 27);\n\n    BF2(28, 29, 30, 31);\n\n\n\n    /* pass 6 */\n\n\n\n    ADD( 8, 12);\n\n    ADD(12, 10);\n\n    ADD(10, 14);\n\n    ADD(14,  9);\n\n    ADD( 9, 13);\n\n    ADD(13, 11);\n\n    ADD(11, 15);\n\n\n\n    out[ 0] = val0;\n\n    out[16] = val1;\n\n    out[ 8] = val2;\n\n    out[24] = val3;\n\n    out[ 4] = val4;\n\n    out[20] = val5;\n\n    out[12] = val6;\n\n    out[28] = val7;\n\n    out[ 2] = val8;\n\n    out[18] = val9;\n\n    out[10] = val10;\n\n    out[26] = val11;\n\n    out[ 6] = val12;\n\n    out[22] = val13;\n\n    out[14] = val14;\n\n    out[30] = val15;\n\n\n\n    ADD(24, 28);\n\n    ADD(28, 26);\n\n    ADD(26, 30);\n\n    ADD(30, 25);\n\n    ADD(25, 29);\n\n    ADD(29, 27);\n\n    ADD(27, 31);\n\n\n\n    out[ 1] = val16 + val24;\n\n    out[17] = val17 + val25;\n\n    out[ 9] = val18 + val26;\n\n    out[25] = val19 + val27;\n\n    out[ 5] = val20 + val28;\n\n    out[21] = val21 + val29;\n\n    out[13] = val22 + val30;\n\n    out[29] = val23 + val31;\n\n    out[ 3] = val24 + val20;\n\n    out[19] = val25 + val21;\n\n    out[11] = val26 + val22;\n\n    out[27] = val27 + val23;\n\n    out[ 7] = val28 + val18;\n\n    out[23] = val29 + val19;\n\n    out[15] = val30 + val17;\n\n    out[31] = val31;\n\n}\n", "idx": 10699, "_split": "test", "_hash": "0ce33e4bb065fc33ad6169db635ce705"}
{"project": "FFmpeg", "commit_id": "5a446bc88e49cc6400d0c646ca1eb540a727c9de", "target": 1, "func": "static void vc1_v_overlap_c(uint8_t* src, int stride)\n\n{\n\n    int i;\n\n    int a, b, c, d;\n\n    int d1, d2;\n\n    int rnd = 1;\n\n    for(i = 0; i < 8; i++) {\n\n        a = src[-2*stride];\n\n        b = src[-stride];\n\n        c = src[0];\n\n        d = src[stride];\n\n        d1 = (a - d + 3 + rnd) >> 3;\n\n        d2 = (a - d + b - c + 4 - rnd) >> 3;\n\n\n\n        src[-2*stride] = a - d1;\n\n        src[-stride] = b - d2;\n\n        src[0] = c + d2;\n\n        src[stride] = d + d1;\n\n        src++;\n\n        rnd = !rnd;\n\n    }\n\n}\n", "idx": 10723, "_split": "test", "_hash": "7d8fc495d4e4921cce9d955807d97c75"}
{"project": "FFmpeg", "commit_id": "4bb1070c154e49d35805fbcdac9c9e92f702ef96", "target": 0, "func": "static int decode_slice_header(FFV1Context *f, FFV1Context *fs)\n\n{\n\n    RangeCoder *c = &fs->c;\n\n    uint8_t state[CONTEXT_SIZE];\n\n    unsigned ps, i, context_count;\n\n    memset(state, 128, sizeof(state));\n\n\n\n    if (fs->ac > 1) {\n\n        for (i = 1; i < 256; i++) {\n\n            fs->c.one_state[i]        = f->state_transition[i];\n\n            fs->c.zero_state[256 - i] = 256 - fs->c.one_state[i];\n\n        }\n\n    }\n\n\n\n    fs->slice_x      = get_symbol(c, state, 0) * f->width;\n\n    fs->slice_y      = get_symbol(c, state, 0) * f->height;\n\n    fs->slice_width  = (get_symbol(c, state, 0) + 1) * f->width + fs->slice_x;\n\n    fs->slice_height = (get_symbol(c, state, 0) + 1) * f->height + fs->slice_y;\n\n\n\n    fs->slice_x     /= f->num_h_slices;\n\n    fs->slice_y     /= f->num_v_slices;\n\n    fs->slice_width  = fs->slice_width / f->num_h_slices - fs->slice_x;\n\n    fs->slice_height = fs->slice_height / f->num_v_slices - fs->slice_y;\n\n    if ((unsigned)fs->slice_width  > f->width ||\n\n        (unsigned)fs->slice_height > f->height)\n\n        return AVERROR_INVALIDDATA;\n\n    if ((unsigned)fs->slice_x + (uint64_t)fs->slice_width  > f->width ||\n\n        (unsigned)fs->slice_y + (uint64_t)fs->slice_height > f->height)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    for (i = 0; i < f->plane_count; i++) {\n\n        PlaneContext *const p = &fs->plane[i];\n\n        int idx               = get_symbol(c, state, 0);\n\n        if (idx > (unsigned)f->quant_table_count) {\n\n            av_log(f->avctx, AV_LOG_ERROR, \"quant_table_index out of range\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        p->quant_table_index = idx;\n\n        memcpy(p->quant_table, f->quant_tables[idx], sizeof(p->quant_table));\n\n        context_count = f->context_count[idx];\n\n\n\n        if (p->context_count < context_count) {\n\n            av_freep(&p->state);\n\n            av_freep(&p->vlc_state);\n\n        }\n\n        p->context_count = context_count;\n\n    }\n\n\n\n    ps = get_symbol(c, state, 0);\n\n    if (ps == 1) {\n\n        f->cur->interlaced_frame = 1;\n\n        f->cur->top_field_first  = 1;\n\n    } else if (ps == 2) {\n\n        f->cur->interlaced_frame = 1;\n\n        f->cur->top_field_first  = 0;\n\n    } else if (ps == 3) {\n\n        f->cur->interlaced_frame = 0;\n\n    }\n\n    f->cur->sample_aspect_ratio.num = get_symbol(c, state, 0);\n\n    f->cur->sample_aspect_ratio.den = get_symbol(c, state, 0);\n\n\n\n    if (av_image_check_sar(f->width, f->height,\n\n                           f->cur->sample_aspect_ratio) < 0) {\n\n        av_log(f->avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n\n               f->cur->sample_aspect_ratio.num,\n\n               f->cur->sample_aspect_ratio.den);\n\n        f->cur->sample_aspect_ratio = (AVRational){ 0, 1 };\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 10738, "_split": "test", "_hash": "2c0c125586dcf756cd0ccca732e8e2bb"}
{"project": "FFmpeg", "commit_id": "a1e093a6fb324612266d40e3168a14f58adab265", "target": 0, "func": "static int decode_element(AVCodecContext *avctx, void *data, int ch_index,\n\n                          int channels)\n\n{\n\n    ALACContext *alac = avctx->priv_data;\n\n    int has_size, bps, is_compressed, decorr_shift, decorr_left_weight, ret;\n\n    uint32_t output_samples;\n\n    int i, ch;\n\n\n\n    skip_bits(&alac->gb, 4);  /* element instance tag */\n\n    skip_bits(&alac->gb, 12); /* unused header bits */\n\n\n\n    /* the number of output samples is stored in the frame */\n\n    has_size = get_bits1(&alac->gb);\n\n\n\n    alac->extra_bits = get_bits(&alac->gb, 2) << 3;\n\n    bps = alac->sample_size - alac->extra_bits + channels - 1;\n\n    if (bps > 32) {\n\n        av_log(avctx, AV_LOG_ERROR, \"bps is unsupported: %d\\n\", bps);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    /* whether the frame is compressed */\n\n    is_compressed = !get_bits1(&alac->gb);\n\n\n\n    if (has_size)\n\n        output_samples = get_bits_long(&alac->gb, 32);\n\n    else\n\n        output_samples = alac->max_samples_per_frame;\n\n    if (!output_samples || output_samples > alac->max_samples_per_frame) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid samples per frame: %d\\n\",\n\n               output_samples);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (!alac->nb_samples) {\n\n        /* get output buffer */\n\n        alac->frame.nb_samples = output_samples;\n\n        if ((ret = avctx->get_buffer(avctx, &alac->frame)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n            return ret;\n\n        }\n\n    } else if (output_samples != alac->nb_samples) {\n\n        av_log(avctx, AV_LOG_ERROR, \"sample count mismatch: %u != %d\\n\",\n\n               output_samples, alac->nb_samples);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    alac->nb_samples = output_samples;\n\n    if (alac->direct_output) {\n\n        for (ch = 0; ch < channels; ch++)\n\n            alac->output_samples_buffer[ch] = (int32_t *)alac->frame.extended_data[ch_index + ch];\n\n    }\n\n\n\n    if (is_compressed) {\n\n        int16_t lpc_coefs[2][32];\n\n        int lpc_order[2];\n\n        int prediction_type[2];\n\n        int lpc_quant[2];\n\n        int rice_history_mult[2];\n\n\n\n        decorr_shift       = get_bits(&alac->gb, 8);\n\n        decorr_left_weight = get_bits(&alac->gb, 8);\n\n\n\n        for (ch = 0; ch < channels; ch++) {\n\n            prediction_type[ch]   = get_bits(&alac->gb, 4);\n\n            lpc_quant[ch]         = get_bits(&alac->gb, 4);\n\n            rice_history_mult[ch] = get_bits(&alac->gb, 3);\n\n            lpc_order[ch]         = get_bits(&alac->gb, 5);\n\n\n\n            /* read the predictor table */\n\n            for (i = lpc_order[ch] - 1; i >= 0; i--)\n\n                lpc_coefs[ch][i] = get_sbits(&alac->gb, 16);\n\n        }\n\n\n\n        if (alac->extra_bits) {\n\n            for (i = 0; i < alac->nb_samples; i++) {\n\n                if(get_bits_left(&alac->gb) <= 0)\n\n                    return -1;\n\n                for (ch = 0; ch < channels; ch++)\n\n                    alac->extra_bits_buffer[ch][i] = get_bits(&alac->gb, alac->extra_bits);\n\n            }\n\n        }\n\n        for (ch = 0; ch < channels; ch++) {\n\n            int ret=rice_decompress(alac, alac->predict_error_buffer[ch],\n\n                            alac->nb_samples, bps,\n\n                            rice_history_mult[ch] * alac->rice_history_mult / 4);\n\n            if(ret<0)\n\n                return ret;\n\n\n\n            /* adaptive FIR filter */\n\n            if (prediction_type[ch] == 15) {\n\n                /* Prediction type 15 runs the adaptive FIR twice.\n\n                 * The first pass uses the special-case coef_num = 31, while\n\n                 * the second pass uses the coefs from the bitstream.\n\n                 *\n\n                 * However, this prediction type is not currently used by the\n\n                 * reference encoder.\n\n                 */\n\n                lpc_prediction(alac->predict_error_buffer[ch],\n\n                               alac->predict_error_buffer[ch],\n\n                               alac->nb_samples, bps, NULL, 31, 0);\n\n            } else if (prediction_type[ch] > 0) {\n\n                av_log(avctx, AV_LOG_WARNING, \"unknown prediction type: %i\\n\",\n\n                       prediction_type[ch]);\n\n            }\n\n            lpc_prediction(alac->predict_error_buffer[ch],\n\n                           alac->output_samples_buffer[ch], alac->nb_samples,\n\n                           bps, lpc_coefs[ch], lpc_order[ch], lpc_quant[ch]);\n\n        }\n\n    } else {\n\n        /* not compressed, easy case */\n\n        for (i = 0; i < alac->nb_samples; i++) {\n\n            if(get_bits_left(&alac->gb) <= 0)\n\n                return -1;\n\n            for (ch = 0; ch < channels; ch++) {\n\n                alac->output_samples_buffer[ch][i] =\n\n                         get_sbits_long(&alac->gb, alac->sample_size);\n\n            }\n\n        }\n\n        alac->extra_bits   = 0;\n\n        decorr_shift       = 0;\n\n        decorr_left_weight = 0;\n\n    }\n\n\n\n    if (channels == 2 && decorr_left_weight) {\n\n        decorrelate_stereo(alac->output_samples_buffer, alac->nb_samples,\n\n                           decorr_shift, decorr_left_weight);\n\n    }\n\n\n\n    if (alac->extra_bits) {\n\n        append_extra_bits(alac->output_samples_buffer, alac->extra_bits_buffer,\n\n                          alac->extra_bits, channels, alac->nb_samples);\n\n    }\n\n\n\n    if(av_sample_fmt_is_planar(avctx->sample_fmt)) {\n\n    switch(alac->sample_size) {\n\n    case 16: {\n\n        for (ch = 0; ch < channels; ch++) {\n\n            int16_t *outbuffer = (int16_t *)alac->frame.extended_data[ch_index + ch];\n\n            for (i = 0; i < alac->nb_samples; i++)\n\n                *outbuffer++ = alac->output_samples_buffer[ch][i];\n\n        }}\n\n        break;\n\n    case 24: {\n\n        for (ch = 0; ch < channels; ch++) {\n\n            for (i = 0; i < alac->nb_samples; i++)\n\n                alac->output_samples_buffer[ch][i] <<= 8;\n\n        }}\n\n        break;\n\n    }\n\n    }else{\n\n        switch(alac->sample_size) {\n\n        case 16: {\n\n            int16_t *outbuffer = ((int16_t *)alac->frame.extended_data[0]) + ch_index;\n\n            for (i = 0; i < alac->nb_samples; i++) {\n\n                for (ch = 0; ch < channels; ch++)\n\n                    *outbuffer++ = alac->output_samples_buffer[ch][i];\n\n                outbuffer += alac->channels - channels;\n\n            }\n\n            }\n\n            break;\n\n        case 24: {\n\n            int32_t *outbuffer = ((int32_t *)alac->frame.extended_data[0]) + ch_index;\n\n            for (i = 0; i < alac->nb_samples; i++) {\n\n                for (ch = 0; ch < channels; ch++)\n\n                    *outbuffer++ = alac->output_samples_buffer[ch][i] << 8;\n\n                outbuffer += alac->channels - channels;\n\n            }\n\n            }\n\n            break;\n\n        case 32: {\n\n            int32_t *outbuffer = ((int32_t *)alac->frame.extended_data[0]) + ch_index;\n\n            for (i = 0; i < alac->nb_samples; i++) {\n\n                for (ch = 0; ch < channels; ch++)\n\n                    *outbuffer++ = alac->output_samples_buffer[ch][i];\n\n                outbuffer += alac->channels - channels;\n\n            }\n\n            }\n\n            break;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 10750, "_split": "test", "_hash": "5aa60bcd29e3b311bf334572829f38dc"}
{"project": "FFmpeg", "commit_id": "57cc1ad35fd488c7a879661498f6f3508038d5a9", "target": 0, "func": "static av_always_inline float quantize_and_encode_band_cost_template(\n\n                                struct AACEncContext *s,\n\n                                PutBitContext *pb, const float *in,\n\n                                const float *scaled, int size, int scale_idx,\n\n                                int cb, const float lambda, const float uplim,\n\n                                int *bits, int BT_ZERO, int BT_UNSIGNED,\n\n                                int BT_PAIR, int BT_ESC)\n\n{\n\n    const float IQ = ff_aac_pow2sf_tab[200 + scale_idx - SCALE_ONE_POS + SCALE_DIV_512];\n\n    const float  Q = ff_aac_pow2sf_tab[200 - scale_idx + SCALE_ONE_POS - SCALE_DIV_512];\n\n    const float CLIPPED_ESCAPE = 165140.0f*IQ;\n\n    int i, j, k;\n\n    float cost = 0;\n\n    const int dim = BT_PAIR ? 2 : 4;\n\n    int resbits = 0;\n\n    const float  Q34 = sqrtf(Q * sqrtf(Q));\n\n    const int range  = aac_cb_range[cb];\n\n    const int maxval = aac_cb_maxval[cb];\n\n    int off;\n\n\n\n    if (BT_ZERO) {\n\n        for (i = 0; i < size; i++)\n\n            cost += in[i]*in[i];\n\n        if (bits)\n\n            *bits = 0;\n\n        return cost * lambda;\n\n    }\n\n    if (!scaled) {\n\n        abs_pow34_v(s->scoefs, in, size);\n\n        scaled = s->scoefs;\n\n    }\n\n    quantize_bands(s->qcoefs, in, scaled, size, Q34, !BT_UNSIGNED, maxval);\n\n    if (BT_UNSIGNED) {\n\n        off = 0;\n\n    } else {\n\n        off = maxval;\n\n    }\n\n    for (i = 0; i < size; i += dim) {\n\n        const float *vec;\n\n        int *quants = s->qcoefs + i;\n\n        int curidx = 0;\n\n        int curbits;\n\n        float rd = 0.0f;\n\n        for (j = 0; j < dim; j++) {\n\n            curidx *= range;\n\n            curidx += quants[j] + off;\n\n        }\n\n        curbits =  ff_aac_spectral_bits[cb-1][curidx];\n\n        vec     = &ff_aac_codebook_vectors[cb-1][curidx*dim];\n\n        if (BT_UNSIGNED) {\n\n            for (k = 0; k < dim; k++) {\n\n                float t = fabsf(in[i+k]);\n\n                float di;\n\n                if (BT_ESC && vec[k] == 64.0f) { //FIXME: slow\n\n                    if (t >= CLIPPED_ESCAPE) {\n\n                        di = t - CLIPPED_ESCAPE;\n\n                        curbits += 21;\n\n                    } else {\n\n                        int c = av_clip(quant(t, Q), 0, 8191);\n\n                        di = t - c*cbrtf(c)*IQ;\n\n                        curbits += av_log2(c)*2 - 4 + 1;\n\n                    }\n\n                } else {\n\n                    di = t - vec[k]*IQ;\n\n                }\n\n                if (vec[k] != 0.0f)\n\n                    curbits++;\n\n                rd += di*di;\n\n            }\n\n        } else {\n\n            for (k = 0; k < dim; k++) {\n\n                float di = in[i+k] - vec[k]*IQ;\n\n                rd += di*di;\n\n            }\n\n        }\n\n        cost    += rd * lambda + curbits;\n\n        resbits += curbits;\n\n        if (cost >= uplim)\n\n            return uplim;\n\n        if (pb) {\n\n            put_bits(pb, ff_aac_spectral_bits[cb-1][curidx], ff_aac_spectral_codes[cb-1][curidx]);\n\n            if (BT_UNSIGNED)\n\n                for (j = 0; j < dim; j++)\n\n                    if (ff_aac_codebook_vectors[cb-1][curidx*dim+j] != 0.0f)\n\n                        put_bits(pb, 1, in[i+j] < 0.0f);\n\n            if (BT_ESC) {\n\n                for (j = 0; j < 2; j++) {\n\n                    if (ff_aac_codebook_vectors[cb-1][curidx*2+j] == 64.0f) {\n\n                        int coef = av_clip(quant(fabsf(in[i+j]), Q), 0, 8191);\n\n                        int len = av_log2(coef);\n\n\n\n                        put_bits(pb, len - 4 + 1, (1 << (len - 4 + 1)) - 2);\n\n                        put_bits(pb, len, coef & ((1 << len) - 1));\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if (bits)\n\n        *bits = resbits;\n\n    return cost;\n\n}\n", "idx": 10765, "_split": "test", "_hash": "be5ec6418690e0f80ec207916f742fbc"}
{"project": "FFmpeg", "commit_id": "ba571f6b4d15a998d6fde387509cd84177fccd96", "target": 0, "func": "static void event_loop(VideoState *cur_stream)\n\n{\n\n    SDL_Event event;\n\n    double incr, pos, frac;\n\n\n\n    for(;;) {\n\n        double x;\n\n        SDL_WaitEvent(&event);\n\n        switch(event.type) {\n\n        case SDL_KEYDOWN:\n\n            if (exit_on_keydown) {\n\n                do_exit(cur_stream);\n\n                break;\n\n            }\n\n            switch(event.key.keysym.sym) {\n\n            case SDLK_ESCAPE:\n\n            case SDLK_q:\n\n                do_exit(cur_stream);\n\n                break;\n\n            case SDLK_f:\n\n                toggle_full_screen(cur_stream);\n\n                break;\n\n            case SDLK_p:\n\n            case SDLK_SPACE:\n\n                if (cur_stream)\n\n                    toggle_pause(cur_stream);\n\n                break;\n\n            case SDLK_s: //S: Step to next frame\n\n                if (cur_stream)\n\n                    step_to_next_frame(cur_stream);\n\n                break;\n\n            case SDLK_a:\n\n                if (cur_stream)\n\n                    stream_cycle_channel(cur_stream, AVMEDIA_TYPE_AUDIO);\n\n                break;\n\n            case SDLK_v:\n\n                if (cur_stream)\n\n                    stream_cycle_channel(cur_stream, AVMEDIA_TYPE_VIDEO);\n\n                break;\n\n            case SDLK_t:\n\n                if (cur_stream)\n\n                    stream_cycle_channel(cur_stream, AVMEDIA_TYPE_SUBTITLE);\n\n                break;\n\n            case SDLK_w:\n\n                if (cur_stream)\n\n                    toggle_audio_display(cur_stream);\n\n                break;\n\n            case SDLK_LEFT:\n\n                incr = -10.0;\n\n                goto do_seek;\n\n            case SDLK_RIGHT:\n\n                incr = 10.0;\n\n                goto do_seek;\n\n            case SDLK_UP:\n\n                incr = 60.0;\n\n                goto do_seek;\n\n            case SDLK_DOWN:\n\n                incr = -60.0;\n\n            do_seek:\n\n                if (cur_stream) {\n\n                    if (seek_by_bytes) {\n\n                        if (cur_stream->video_stream >= 0 && cur_stream->video_current_pos>=0){\n\n                            pos= cur_stream->video_current_pos;\n\n                        }else if(cur_stream->audio_stream >= 0 && cur_stream->audio_pkt.pos>=0){\n\n                            pos= cur_stream->audio_pkt.pos;\n\n                        }else\n\n                            pos = avio_tell(cur_stream->ic->pb);\n\n                        if (cur_stream->ic->bit_rate)\n\n                            incr *= cur_stream->ic->bit_rate / 8.0;\n\n                        else\n\n                            incr *= 180000.0;\n\n                        pos += incr;\n\n                        stream_seek(cur_stream, pos, incr, 1);\n\n                    } else {\n\n                        pos = get_master_clock(cur_stream);\n\n                        pos += incr;\n\n                        stream_seek(cur_stream, (int64_t)(pos * AV_TIME_BASE), (int64_t)(incr * AV_TIME_BASE), 0);\n\n                    }\n\n                }\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n            break;\n\n        case SDL_MOUSEBUTTONDOWN:\n\n            if (exit_on_mousedown) {\n\n                do_exit(cur_stream);\n\n                break;\n\n            }\n\n        case SDL_MOUSEMOTION:\n\n            if(event.type ==SDL_MOUSEBUTTONDOWN){\n\n                x= event.button.x;\n\n            }else{\n\n                if(event.motion.state != SDL_PRESSED)\n\n                    break;\n\n                x= event.motion.x;\n\n            }\n\n            if (cur_stream) {\n\n                if(seek_by_bytes || cur_stream->ic->duration<=0){\n\n                    uint64_t size=  avio_size(cur_stream->ic->pb);\n\n                    stream_seek(cur_stream, size*x/cur_stream->width, 0, 1);\n\n                }else{\n\n                    int64_t ts;\n\n                    int ns, hh, mm, ss;\n\n                    int tns, thh, tmm, tss;\n\n                    tns = cur_stream->ic->duration/1000000LL;\n\n                    thh = tns/3600;\n\n                    tmm = (tns%3600)/60;\n\n                    tss = (tns%60);\n\n                    frac = x/cur_stream->width;\n\n                    ns = frac*tns;\n\n                    hh = ns/3600;\n\n                    mm = (ns%3600)/60;\n\n                    ss = (ns%60);\n\n                    fprintf(stderr, \"Seek to %2.0f%% (%2d:%02d:%02d) of total duration (%2d:%02d:%02d)       \\n\", frac*100,\n\n                            hh, mm, ss, thh, tmm, tss);\n\n                    ts = frac*cur_stream->ic->duration;\n\n                    if (cur_stream->ic->start_time != AV_NOPTS_VALUE)\n\n                        ts += cur_stream->ic->start_time;\n\n                    stream_seek(cur_stream, ts, 0, 0);\n\n                }\n\n            }\n\n            break;\n\n        case SDL_VIDEORESIZE:\n\n            if (cur_stream) {\n\n                screen = SDL_SetVideoMode(event.resize.w, event.resize.h, 0,\n\n                                          SDL_HWSURFACE|SDL_RESIZABLE|SDL_ASYNCBLIT|SDL_HWACCEL);\n\n                screen_width = cur_stream->width = event.resize.w;\n\n                screen_height= cur_stream->height= event.resize.h;\n\n            }\n\n            break;\n\n        case SDL_QUIT:\n\n        case FF_QUIT_EVENT:\n\n            do_exit(cur_stream);\n\n            break;\n\n        case FF_ALLOC_EVENT:\n\n            video_open(event.user.data1);\n\n            alloc_picture(event.user.data1);\n\n            break;\n\n        case FF_REFRESH_EVENT:\n\n            video_refresh(event.user.data1);\n\n            cur_stream->refresh=0;\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 10767, "_split": "test", "_hash": "db0ae5621c17c41d1c3e34b7a58a4e55"}
{"project": "FFmpeg", "commit_id": "7effbee66cf457c62f795d9b9ed3a1110b364b89", "target": 1, "func": "static int sox_read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    int ret, size;\n\n\n\n    if (url_feof(s->pb))\n\n        return AVERROR_EOF;\n\n\n\n    size = SOX_SAMPLES*s->streams[0]->codec->block_align;\n\n    ret = av_get_packet(s->pb, pkt, size);\n\n    if (ret < 0)\n\n        return AVERROR(EIO);\n\n\n    pkt->stream_index = 0;\n\n    pkt->size = ret;\n\n\n\n    return 0;\n\n}", "idx": 10772, "_split": "test", "_hash": "ee81c65ad46264422b8ce29ecac953d0"}
{"project": "FFmpeg", "commit_id": "d094052c8e8a036666ac02bfc52bf221ad39e4c8", "target": 1, "func": "static av_cold int svq1_encode_init(AVCodecContext *avctx)\n\n{\n\n    SVQ1Context * const s = avctx->priv_data;\n\n\n\n    dsputil_init(&s->dsp, avctx);\n\n    avctx->coded_frame= (AVFrame*)&s->picture;\n\n\n\n    s->frame_width = avctx->width;\n\n    s->frame_height = avctx->height;\n\n\n\n    s->y_block_width = (s->frame_width + 15) / 16;\n\n    s->y_block_height = (s->frame_height + 15) / 16;\n\n\n\n    s->c_block_width = (s->frame_width / 4 + 15) / 16;\n\n    s->c_block_height = (s->frame_height / 4 + 15) / 16;\n\n\n\n    s->avctx= avctx;\n\n    s->m.avctx= avctx;\n\n\n    s->m.me.scratchpad= av_mallocz((avctx->width+64)*2*16*2*sizeof(uint8_t));\n\n    s->m.me.map       = av_mallocz(ME_MAP_SIZE*sizeof(uint32_t));\n\n    s->m.me.score_map = av_mallocz(ME_MAP_SIZE*sizeof(uint32_t));\n\n    s->mb_type        = av_mallocz((s->y_block_width+1)*s->y_block_height*sizeof(int16_t));\n\n    s->dummy          = av_mallocz((s->y_block_width+1)*s->y_block_height*sizeof(int32_t));\n\n    h263_encode_init(&s->m); //mv_penalty\n\n\n\n    return 0;\n\n}", "idx": 10773, "_split": "test", "_hash": "126e7594f5c1045f2038f12fe9f21cb1"}
{"project": "FFmpeg", "commit_id": "9b6aafba6c06ef62783dd5e9c5ed668f3a095128", "target": 1, "func": "static av_always_inline void mpeg_motion_lowres(MpegEncContext *s,\n\n                                                uint8_t *dest_y,\n\n                                                uint8_t *dest_cb,\n\n                                                uint8_t *dest_cr,\n\n                                                int field_based,\n\n                                                int bottom_field,\n\n                                                int field_select,\n\n                                                uint8_t **ref_picture,\n\n                                                h264_chroma_mc_func *pix_op,\n\n                                                int motion_x, int motion_y,\n\n                                                int h, int mb_y)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int mx, my, src_x, src_y, uvsrc_x, uvsrc_y, uvlinesize, linesize, sx, sy,\n\n        uvsx, uvsy;\n\n    const int lowres     = s->avctx->lowres;\n\n    const int op_index   = FFMIN(lowres, 2);\n\n    const int block_s    = 8>>lowres;\n\n    const int s_mask     = (2 << lowres) - 1;\n\n    const int h_edge_pos = s->h_edge_pos >> lowres;\n\n    const int v_edge_pos = s->v_edge_pos >> lowres;\n\n    linesize   = s->current_picture.f.linesize[0] << field_based;\n\n    uvlinesize = s->current_picture.f.linesize[1] << field_based;\n\n\n\n    // FIXME obviously not perfect but qpel will not work in lowres anyway\n\n    if (s->quarter_sample) {\n\n        motion_x /= 2;\n\n        motion_y /= 2;\n\n    }\n\n\n\n    if (field_based) {\n\n        motion_y += (bottom_field - field_select) * (1 << lowres - 1);\n\n    }\n\n\n\n    sx = motion_x & s_mask;\n\n    sy = motion_y & s_mask;\n\n    src_x = s->mb_x * 2 * block_s + (motion_x >> lowres + 1);\n\n    src_y = (mb_y * 2 * block_s >> field_based) + (motion_y >> lowres + 1);\n\n\n\n    if (s->out_format == FMT_H263) {\n\n        uvsx    = ((motion_x >> 1) & s_mask) | (sx & 1);\n\n        uvsy    = ((motion_y >> 1) & s_mask) | (sy & 1);\n\n        uvsrc_x = src_x >> 1;\n\n        uvsrc_y = src_y >> 1;\n\n    } else if (s->out_format == FMT_H261) {\n\n        // even chroma mv's are full pel in H261\n\n        mx      = motion_x / 4;\n\n        my      = motion_y / 4;\n\n        uvsx    = (2 * mx) & s_mask;\n\n        uvsy    = (2 * my) & s_mask;\n\n        uvsrc_x = s->mb_x * block_s + (mx >> lowres);\n\n        uvsrc_y =    mb_y * block_s + (my >> lowres);\n\n    } else {\n\n        mx      = motion_x / 2;\n\n        my      = motion_y / 2;\n\n        uvsx    = mx & s_mask;\n\n        uvsy    = my & s_mask;\n\n        uvsrc_x = s->mb_x * block_s                 + (mx >> lowres + 1);\n\n        uvsrc_y =   (mb_y * block_s >> field_based) + (my >> lowres + 1);\n\n    }\n\n\n\n    ptr_y  = ref_picture[0] + src_y   * linesize   + src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if ((unsigned) src_x >  h_edge_pos - (!!sx) - 2 * block_s ||\n\n        (unsigned) src_y > (v_edge_pos >> field_based) - (!!sy) - h) {\n\n        s->dsp.emulated_edge_mc(s->edge_emu_buffer, ptr_y,\n\n                                s->linesize, 17, 17 + field_based,\n\n                                src_x, src_y << field_based, h_edge_pos,\n\n                                v_edge_pos);\n\n        ptr_y = s->edge_emu_buffer;\n\n        if (!CONFIG_GRAY || !(s->flags & CODEC_FLAG_GRAY)) {\n\n            uint8_t *uvbuf = s->edge_emu_buffer + 18 * s->linesize;\n\n            s->dsp.emulated_edge_mc(uvbuf , ptr_cb, s->uvlinesize, 9,\n\n                                    9 + field_based,\n\n                                    uvsrc_x, uvsrc_y << field_based,\n\n                                    h_edge_pos >> 1, v_edge_pos >> 1);\n\n            s->dsp.emulated_edge_mc(uvbuf + 16, ptr_cr, s->uvlinesize, 9,\n\n                                    9 + field_based,\n\n                                    uvsrc_x, uvsrc_y << field_based,\n\n                                    h_edge_pos >> 1, v_edge_pos >> 1);\n\n            ptr_cb = uvbuf;\n\n            ptr_cr = uvbuf + 16;\n\n        }\n\n    }\n\n\n\n    // FIXME use this for field pix too instead of the obnoxious hack which changes picture.f.data\n\n    if (bottom_field) {\n\n        dest_y  += s->linesize;\n\n        dest_cb += s->uvlinesize;\n\n        dest_cr += s->uvlinesize;\n\n    }\n\n\n\n    if (field_select) {\n\n        ptr_y   += s->linesize;\n\n        ptr_cb  += s->uvlinesize;\n\n        ptr_cr  += s->uvlinesize;\n\n    }\n\n\n\n    sx = (sx << 2) >> lowres;\n\n    sy = (sy << 2) >> lowres;\n\n    pix_op[lowres - 1](dest_y, ptr_y, linesize, h, sx, sy);\n\n\n\n    if (!CONFIG_GRAY || !(s->flags & CODEC_FLAG_GRAY)) {\n\n        uvsx = (uvsx << 2) >> lowres;\n\n        uvsy = (uvsy << 2) >> lowres;\n\n        pix_op[op_index](dest_cb, ptr_cb, uvlinesize, h >> s->chroma_y_shift,\n\n                         uvsx, uvsy);\n\n        pix_op[op_index](dest_cr, ptr_cr, uvlinesize, h >> s->chroma_y_shift,\n\n                         uvsx, uvsy);\n\n    }\n\n    // FIXME h261 lowres loop filter\n\n}\n", "idx": 10836, "_split": "test", "_hash": "accb51ca3f143135ad92cc9914bde4f9"}
{"project": "FFmpeg", "commit_id": "1178868683d25c0f358b0364eb55f69b563b24f3", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx,\n\n                        void *data,\n\n                        int *got_frame,\n\n                        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf      = avpkt->data;\n\n    unsigned int   buf_size = avpkt->size;\n\n    const uint8_t *buf_end  = buf + buf_size;\n\n\n\n    const AVPixFmtDescriptor *desc;\n\n    EXRContext *const s = avctx->priv_data;\n\n    AVFrame *picture  = data;\n\n    AVFrame *const p = &s->picture;\n\n    uint8_t *ptr;\n\n\n\n    int i, x, y, stride, magic_number, version, flags, ret;\n\n    int w = 0;\n\n    int h = 0;\n\n    unsigned int xmin   = ~0;\n\n    unsigned int xmax   = ~0;\n\n    unsigned int ymin   = ~0;\n\n    unsigned int ymax   = ~0;\n\n    unsigned int xdelta = ~0;\n\n\n\n    int out_line_size;\n\n    int bxmin, axmax;\n\n    int scan_lines_per_block;\n\n    unsigned long scan_line_size;\n\n    unsigned long uncompressed_size;\n\n\n\n    unsigned int current_channel_offset = 0;\n\n\n\n    s->channel_offsets[0] = -1;\n\n    s->channel_offsets[1] = -1;\n\n    s->channel_offsets[2] = -1;\n\n    s->channel_offsets[3] = -1;\n\n    s->bits_per_color_id = -1;\n\n    s->compr = -1;\n\n\n\n    if (buf_size < 10) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Too short header to parse\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    magic_number = bytestream_get_le32(&buf);\n\n    if (magic_number != 20000630) { // As per documentation of OpenEXR it's supposed to be int 20000630 little-endian\n\n        av_log(avctx, AV_LOG_ERROR, \"Wrong magic number %d\\n\", magic_number);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    version = bytestream_get_byte(&buf);\n\n    if (version != 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported version %d\\n\", version);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    flags = bytestream_get_le24(&buf);\n\n    if (flags & 0x2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Tile based images are not supported\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    // Parse the header\n\n    while (buf < buf_end && buf[0]) {\n\n        unsigned int variable_buffer_data_size;\n\n        // Process the channel list\n\n        if (check_header_variable(avctx, &buf, buf_end, \"channels\", \"chlist\", 38, &variable_buffer_data_size) >= 0) {\n\n            const uint8_t *channel_list_end;\n\n            if (!variable_buffer_data_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            channel_list_end = buf + variable_buffer_data_size;\n\n            while (channel_list_end - buf >= 19) {\n\n                int current_bits_per_color_id = -1;\n\n                int channel_index = -1;\n\n\n\n                if (!strcmp(buf, \"R\"))\n\n                    channel_index = 0;\n\n                else if (!strcmp(buf, \"G\"))\n\n                    channel_index = 1;\n\n                else if (!strcmp(buf, \"B\"))\n\n                    channel_index = 2;\n\n                else if (!strcmp(buf, \"A\"))\n\n                    channel_index = 3;\n\n                else\n\n                    av_log(avctx, AV_LOG_WARNING, \"Unsupported channel %.256s\\n\", buf);\n\n\n\n                while (bytestream_get_byte(&buf) && buf < channel_list_end)\n\n                    continue; /* skip */\n\n\n\n                if (channel_list_end - * &buf < 4) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Incomplete header\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                current_bits_per_color_id = bytestream_get_le32(&buf);\n\n                if (current_bits_per_color_id > 2) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"Unknown color format\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                if (channel_index >= 0) {\n\n                    if (s->bits_per_color_id != -1 && s->bits_per_color_id != current_bits_per_color_id) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"RGB channels not of the same depth\\n\");\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    s->bits_per_color_id  = current_bits_per_color_id;\n\n                    s->channel_offsets[channel_index] = current_channel_offset;\n\n                }\n\n\n\n                current_channel_offset += 1 << current_bits_per_color_id;\n\n                buf += 12;\n\n            }\n\n\n\n            /* Check if all channels are set with an offset or if the channels\n\n             * are causing an overflow  */\n\n\n\n            if (FFMIN3(s->channel_offsets[0],\n\n                       s->channel_offsets[1],\n\n                       s->channel_offsets[2]) < 0) {\n\n                if (s->channel_offsets[0] < 0)\n\n                    av_log(avctx, AV_LOG_ERROR, \"Missing red channel\\n\");\n\n                if (s->channel_offsets[1] < 0)\n\n                    av_log(avctx, AV_LOG_ERROR, \"Missing green channel\\n\");\n\n                if (s->channel_offsets[2] < 0)\n\n                    av_log(avctx, AV_LOG_ERROR, \"Missing blue channel\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            buf = channel_list_end;\n\n            continue;\n\n        } else if (check_header_variable(avctx, &buf, buf_end, \"dataWindow\", \"box2i\", 31, &variable_buffer_data_size) >= 0) {\n\n            if (!variable_buffer_data_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            xmin = AV_RL32(buf);\n\n            ymin = AV_RL32(buf + 4);\n\n            xmax = AV_RL32(buf + 8);\n\n            ymax = AV_RL32(buf + 12);\n\n            xdelta = (xmax-xmin) + 1;\n\n\n\n            buf += variable_buffer_data_size;\n\n            continue;\n\n        } else if (check_header_variable(avctx, &buf, buf_end, \"displayWindow\", \"box2i\", 34, &variable_buffer_data_size) >= 0) {\n\n            if (!variable_buffer_data_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            w = AV_RL32(buf + 8) + 1;\n\n            h = AV_RL32(buf + 12) + 1;\n\n\n\n            buf += variable_buffer_data_size;\n\n            continue;\n\n        } else if (check_header_variable(avctx, &buf, buf_end, \"lineOrder\", \"lineOrder\", 25, &variable_buffer_data_size) >= 0) {\n\n            if (!variable_buffer_data_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            if (*buf) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Doesn't support this line order : %d\\n\", *buf);\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n            buf += variable_buffer_data_size;\n\n            continue;\n\n        } else if (check_header_variable(avctx, &buf, buf_end, \"pixelAspectRatio\", \"float\", 31, &variable_buffer_data_size) >= 0) {\n\n            if (!variable_buffer_data_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            avctx->sample_aspect_ratio = av_d2q(av_int2float(AV_RL32(buf)), 255);\n\n\n\n            buf += variable_buffer_data_size;\n\n            continue;\n\n        } else if (check_header_variable(avctx, &buf, buf_end, \"compression\", \"compression\", 29, &variable_buffer_data_size) >= 0) {\n\n            if (!variable_buffer_data_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            if (s->compr == -1)\n\n                s->compr = *buf;\n\n            else\n\n                av_log(avctx, AV_LOG_WARNING, \"Found more than one compression attribute\\n\");\n\n\n\n            buf += variable_buffer_data_size;\n\n            continue;\n\n        }\n\n\n\n        // Check if there is enough bytes for a header\n\n        if (buf_end - buf <= 9) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Incomplete header\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        // Process unknown variables\n\n        for (i = 0; i < 2; i++) {\n\n            // Skip variable name/type\n\n            while (++buf < buf_end)\n\n                if (buf[0] == 0x0)\n\n                    break;\n\n        }\n\n        buf++;\n\n        // Skip variable length\n\n        if (buf_end - buf >= 5) {\n\n            variable_buffer_data_size = get_header_variable_length(&buf, buf_end);\n\n            if (!variable_buffer_data_size) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Incomplete header\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            buf += variable_buffer_data_size;\n\n        }\n\n    }\n\n\n\n    if (s->compr == -1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Missing compression attribute\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (buf >= buf_end) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Incomplete frame\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    buf++;\n\n\n\n    switch (s->bits_per_color_id) {\n\n    case 2: // 32-bit\n\n    case 1: // 16-bit\n\n        if (s->channel_offsets[3] >= 0)\n\n            avctx->pix_fmt = AV_PIX_FMT_RGBA64;\n\n        else\n\n            avctx->pix_fmt = AV_PIX_FMT_RGB48;\n\n        break;\n\n    // 8-bit\n\n    case 0:\n\n        av_log_missing_feature(avctx, \"8-bit OpenEXR\", 1);\n\n        return AVERROR_PATCHWELCOME;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown color format : %d\\n\", s->bits_per_color_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (s->compr) {\n\n    case EXR_RAW:\n\n    case EXR_RLE:\n\n    case EXR_ZIP1:\n\n        scan_lines_per_block = 1;\n\n        break;\n\n    case EXR_ZIP16:\n\n        scan_lines_per_block = 16;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Compression type %d is not supported\\n\", s->compr);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (s->picture.data[0])\n\n        ff_thread_release_buffer(avctx, &s->picture);\n\n    if (av_image_check_size(w, h, 0, avctx))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    // Verify the xmin, xmax, ymin, ymax and xdelta before setting the actual image size\n\n    if (xmin > xmax || ymin > ymax || xdelta != xmax - xmin + 1 || xmax >= w || ymax >= h) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Wrong sizing or missing size information\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (w != avctx->width || h != avctx->height) {\n\n        avcodec_set_dimensions(avctx, w, h);\n\n    }\n\n\n\n    desc = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    bxmin = xmin * 2 * desc->nb_components;\n\n    axmax = (avctx->width - (xmax + 1)) * 2 * desc->nb_components;\n\n    out_line_size = avctx->width * 2 * desc->nb_components;\n\n    scan_line_size = xdelta * current_channel_offset;\n\n    uncompressed_size = scan_line_size * scan_lines_per_block;\n\n\n\n    if (s->compr != EXR_RAW) {\n\n        av_fast_padded_malloc(&s->uncompressed_data, &s->uncompressed_size, uncompressed_size);\n\n        av_fast_padded_malloc(&s->tmp, &s->tmp_size, uncompressed_size);\n\n        if (!s->uncompressed_data || !s->tmp)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    if ((ret = ff_thread_get_buffer(avctx, p)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    ptr    = p->data[0];\n\n    stride = p->linesize[0];\n\n\n\n    // Zero out the start if ymin is not 0\n\n    for (y = 0; y < ymin; y++) {\n\n        memset(ptr, 0, out_line_size);\n\n        ptr += stride;\n\n    }\n\n\n\n    // Process the actual scan line blocks\n\n    for (y = ymin; y <= ymax; y += scan_lines_per_block) {\n\n        uint16_t *ptr_x = (uint16_t *)ptr;\n\n        if (buf_end - buf > 8) {\n\n            /* Read the lineoffset from the line offset table and add 8 bytes\n\n               to skip the coordinates and data size fields */\n\n            const uint64_t line_offset = bytestream_get_le64(&buf) + 8;\n\n            int32_t data_size;\n\n\n\n            // Check if the buffer has the required bytes needed from the offset\n\n            if ((line_offset > buf_size) ||\n\n                (s->compr == EXR_RAW && line_offset > avpkt->size - xdelta * current_channel_offset) ||\n\n                (s->compr != EXR_RAW && line_offset > buf_size - (data_size = AV_RL32(avpkt->data + line_offset - 4)))) {\n\n                // Line offset is probably wrong and not inside the buffer\n\n                av_log(avctx, AV_LOG_WARNING, \"Line offset for line %d is out of reach setting it to black\\n\", y);\n\n                for (i = 0; i < scan_lines_per_block && y + i <= ymax; i++, ptr += stride) {\n\n                    ptr_x = (uint16_t *)ptr;\n\n                    memset(ptr_x, 0, out_line_size);\n\n                }\n\n            } else {\n\n                const uint8_t *red_channel_buffer, *green_channel_buffer, *blue_channel_buffer, *alpha_channel_buffer = 0;\n\n\n\n                if (scan_lines_per_block > 1)\n\n                    uncompressed_size = scan_line_size * FFMIN(scan_lines_per_block, ymax - y + 1);\n\n                if ((s->compr == EXR_ZIP1 || s->compr == EXR_ZIP16) && data_size < uncompressed_size) {\n\n                    unsigned long dest_len = uncompressed_size;\n\n\n\n                    if (uncompress(s->tmp, &dest_len, avpkt->data + line_offset, data_size) != Z_OK ||\n\n                        dest_len != uncompressed_size) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"error during zlib decompression\\n\");\n\n                        return AVERROR(EINVAL);\n\n                    }\n\n                } else if (s->compr == EXR_RLE && data_size < uncompressed_size) {\n\n                    if (rle_uncompress(avpkt->data + line_offset, data_size, s->tmp, uncompressed_size)) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"error during rle decompression\\n\");\n\n                        return AVERROR(EINVAL);\n\n                    }\n\n                }\n\n\n\n                if (s->compr != EXR_RAW && data_size < uncompressed_size) {\n\n                    predictor(s->tmp, uncompressed_size);\n\n                    reorder_pixels(s->tmp, s->uncompressed_data, uncompressed_size);\n\n\n\n                    red_channel_buffer   = s->uncompressed_data + xdelta * s->channel_offsets[0];\n\n                    green_channel_buffer = s->uncompressed_data + xdelta * s->channel_offsets[1];\n\n                    blue_channel_buffer  = s->uncompressed_data + xdelta * s->channel_offsets[2];\n\n                    if (s->channel_offsets[3] >= 0)\n\n                        alpha_channel_buffer = s->uncompressed_data + xdelta * s->channel_offsets[3];\n\n                } else {\n\n                    red_channel_buffer   = avpkt->data + line_offset + xdelta * s->channel_offsets[0];\n\n                    green_channel_buffer = avpkt->data + line_offset + xdelta * s->channel_offsets[1];\n\n                    blue_channel_buffer  = avpkt->data + line_offset + xdelta * s->channel_offsets[2];\n\n                    if (s->channel_offsets[3] >= 0)\n\n                        alpha_channel_buffer = avpkt->data + line_offset + xdelta * s->channel_offsets[3];\n\n                }\n\n\n\n                for (i = 0; i < scan_lines_per_block && y + i <= ymax; i++, ptr += stride) {\n\n                    const uint8_t *r, *g, *b, *a;\n\n\n\n                    r = red_channel_buffer;\n\n                    g = green_channel_buffer;\n\n                    b = blue_channel_buffer;\n\n                    if (alpha_channel_buffer)\n\n                        a = alpha_channel_buffer;\n\n\n\n                    ptr_x = (uint16_t *)ptr;\n\n\n\n                    // Zero out the start if xmin is not 0\n\n                    memset(ptr_x, 0, bxmin);\n\n                    ptr_x += xmin * desc->nb_components;\n\n                    if (s->bits_per_color_id == 2) {\n\n                        // 32-bit\n\n                        for (x = 0; x < xdelta; x++) {\n\n                            *ptr_x++ = exr_flt2uint(bytestream_get_le32(&r));\n\n                            *ptr_x++ = exr_flt2uint(bytestream_get_le32(&g));\n\n                            *ptr_x++ = exr_flt2uint(bytestream_get_le32(&b));\n\n                            if (alpha_channel_buffer)\n\n                                *ptr_x++ = exr_flt2uint(bytestream_get_le32(&a));\n\n                        }\n\n                    } else {\n\n                        // 16-bit\n\n                        for (x = 0; x < xdelta; x++) {\n\n                            *ptr_x++ = exr_halflt2uint(bytestream_get_le16(&r));\n\n                            *ptr_x++ = exr_halflt2uint(bytestream_get_le16(&g));\n\n                            *ptr_x++ = exr_halflt2uint(bytestream_get_le16(&b));\n\n                            if (alpha_channel_buffer)\n\n                                *ptr_x++ = exr_halflt2uint(bytestream_get_le16(&a));\n\n                        }\n\n                    }\n\n\n\n                    // Zero out the end if xmax+1 is not w\n\n                    memset(ptr_x, 0, axmax);\n\n\n\n                    red_channel_buffer   += scan_line_size;\n\n                    green_channel_buffer += scan_line_size;\n\n                    blue_channel_buffer  += scan_line_size;\n\n                    if (alpha_channel_buffer)\n\n                        alpha_channel_buffer += scan_line_size;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    // Zero out the end if ymax+1 is not h\n\n    for (y = ymax + 1; y < avctx->height; y++) {\n\n        memset(ptr, 0, out_line_size);\n\n        ptr += stride;\n\n    }\n\n\n\n    *picture   = s->picture;\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 10842, "_split": "test", "_hash": "9881e6c42ed84b75fb9ae485a49a1e88"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "void rgb15tobgr15(const uint8_t *src, uint8_t *dst, unsigned int src_size)\n\n{\n\n\tunsigned i;\n\n\tunsigned num_pixels = src_size >> 1;\n\n\t\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t    unsigned b,g,r;\n\n\t    register uint16_t rgb;\n\n\t    rgb = src[2*i];\n\n\t    r = rgb&0x1F;\n\n\t    g = (rgb&0x3E0)>>5;\n\n\t    b = (rgb&0x7C00)>>10;\n\n\t    dst[2*i] = (b&0x1F) | ((g&0x1F)<<5) | ((r&0x1F)<<10);\n\n\t}\n\n}\n", "idx": 10849, "_split": "test", "_hash": "7d14f21ecb7ac7ac53ea9e65d58b8322"}
{"project": "FFmpeg", "commit_id": "35dcc8a0405788de392ed116dd628aef2772003d", "target": 1, "func": "static int lag_decode_prob(GetBitContext *gb, uint32_t *value)\n\n{\n\n    static const uint8_t series[] = { 1, 2, 3, 5, 8, 13, 21 };\n\n    int i;\n\n    int bit     = 0;\n\n    int bits    = 0;\n\n    int prevbit = 0;\n\n    unsigned val;\n\n\n\n    for (i = 0; i < 7; i++) {\n\n        if (prevbit && bit)\n\n            break;\n\n        prevbit = bit;\n\n        bit = get_bits1(gb);\n\n        if (bit && !prevbit)\n\n            bits += series[i];\n\n    }\n\n    bits--;\n\n    if (bits < 0 || bits > 31) {\n\n        *value = 0;\n\n        return -1;\n\n    } else if (bits == 0) {\n\n        *value = 0;\n\n        return 0;\n\n    }\n\n\n\n    val  = get_bits_long(gb, bits);\n\n    val |= 1 << bits;\n\n\n\n    *value = val - 1;\n\n\n\n    return 0;\n\n}\n", "idx": 10868, "_split": "test", "_hash": "ab1d5860c551a03bf1cd055d3f86f43d"}
{"project": "FFmpeg", "commit_id": "09ce5519f3b44873ac242e9a2f89db7d459de532", "target": 1, "func": "static void check_add_res(HEVCDSPContext h, int bit_depth)\n\n{\n\n    int i;\n\n    LOCAL_ALIGNED_32(int16_t, res0, [32 * 32]);\n\n    LOCAL_ALIGNED_32(int16_t, res1, [32 * 32]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst0, [32 * 32 * 2]);\n\n    LOCAL_ALIGNED_32(uint8_t, dst1, [32 * 32 * 2]);\n\n\n\n    for (i = 2; i <= 5; i++) {\n\n        int block_size = 1 << i;\n\n        int size = block_size * block_size;\n\n        ptrdiff_t stride = block_size << (bit_depth > 8);\n\n        declare_func_emms(AV_CPU_FLAG_MMX, void, uint8_t *dst, int16_t *res, ptrdiff_t stride);\n\n\n\n        randomize_buffers(res0, size);\n\n        randomize_buffers2(dst0, size);\n\n        memcpy(res1, res0, sizeof(*res0) * size);\n\n        memcpy(dst1, dst0, size);\n\n\n\n        if (check_func(h.add_residual[i - 2], \"add_res_%dx%d_%d\", block_size, block_size, bit_depth)) {\n\n            call_ref(dst0, res0, stride);\n\n            call_new(dst1, res1, stride);\n\n            if (memcmp(dst0, dst1, size))\n\n                fail();\n\n            bench_new(dst1, res1, stride);\n\n        }\n\n    }\n\n}\n", "idx": 10869, "_split": "test", "_hash": "ab8c4fb81cf6f4ff2df08e40149004c8"}
{"project": "FFmpeg", "commit_id": "2862b63783b5556f7f3fb2d097629bc6879f833a", "target": 0, "func": "static int ljpeg_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                              const AVFrame *pict, int *got_packet)\n\n{\n\n    LJpegEncContext *s = avctx->priv_data;\n\n    PutBitContext pb;\n\n    const int width  = avctx->width;\n\n    const int height = avctx->height;\n\n    const int mb_width  = (width  + s->hsample[0] - 1) / s->hsample[0];\n\n    const int mb_height = (height + s->vsample[0] - 1) / s->vsample[0];\n\n    int max_pkt_size = AV_INPUT_BUFFER_MIN_SIZE;\n\n    int ret, header_bits;\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_BGR24)\n\n        max_pkt_size += width * height * 3 * 3;\n\n    else {\n\n        max_pkt_size += mb_width * mb_height * 3 * 4\n\n                        * s->hsample[0] * s->vsample[0];\n\n    }\n\n    if ((ret = ff_alloc_packet(pkt, max_pkt_size)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet of size %d.\\n\", max_pkt_size);\n\n        return ret;\n\n    }\n\n\n\n    init_put_bits(&pb, pkt->data, pkt->size);\n\n\n\n    ff_mjpeg_encode_picture_header(avctx, &pb, &s->scantable,\n\n                                   s->matrix);\n\n\n\n    header_bits = put_bits_count(&pb);\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_BGR24)\n\n        ret = ljpeg_encode_bgr(avctx, &pb, pict);\n\n    else\n\n        ret = ljpeg_encode_yuv(avctx, &pb, pict);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    emms_c();\n\n\n\n    ff_mjpeg_encode_picture_trailer(&pb, header_bits);\n\n\n\n    flush_put_bits(&pb);\n\n    pkt->size   = put_bits_ptr(&pb) - pb.buf;\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 10950, "_split": "test", "_hash": "e12671d14f7fc3a5070e356241e78f27"}
{"project": "FFmpeg", "commit_id": "27bcf55f459e038e81f09c17e72e6d44898b9015", "target": 1, "func": "int av_vsrc_buffer_add_video_buffer_ref(AVFilterContext *buffer_filter, AVFilterBufferRef *picref)\n\n{\n\n    BufferSourceContext *c = buffer_filter->priv;\n\n    AVFilterLink *outlink = buffer_filter->outputs[0];\n\n    int ret;\n\n\n\n    if (c->picref) {\n\n        av_log(buffer_filter, AV_LOG_ERROR,\n\n               \"Buffering several frames is not supported. \"\n\n               \"Please consume all available frames before adding a new one.\\n\"\n\n            );\n\n        //return -1;\n\n    }\n\n\n\n    if (picref->video->w != c->w || picref->video->h != c->h || picref->format != c->pix_fmt) {\n\n        AVFilterContext *scale = buffer_filter->outputs[0]->dst;\n\n        AVFilterLink *link;\n\n        char scale_param[1024];\n\n\n\n        av_log(buffer_filter, AV_LOG_INFO,\n\n               \"Buffer video input changed from size:%dx%d fmt:%s to size:%dx%d fmt:%s\\n\",\n\n               c->w, c->h, av_pix_fmt_descriptors[c->pix_fmt].name,\n\n               picref->video->w, picref->video->h, av_pix_fmt_descriptors[picref->format].name);\n\n\n\n        if (!scale || strcmp(scale->filter->name, \"scale\")) {\n\n            AVFilter *f = avfilter_get_by_name(\"scale\");\n\n\n\n            av_log(buffer_filter, AV_LOG_INFO, \"Inserting scaler filter\\n\");\n\n            if ((ret = avfilter_open(&scale, f, \"Input equalizer\")) < 0)\n\n                return ret;\n\n\n\n            snprintf(scale_param, sizeof(scale_param)-1, \"%d:%d:%s\", c->w, c->h, c->sws_param);\n\n            if ((ret = avfilter_init_filter(scale, scale_param, NULL)) < 0) {\n\n                avfilter_free(scale);\n\n                return ret;\n\n            }\n\n\n\n            if ((ret = avfilter_insert_filter(buffer_filter->outputs[0], scale, 0, 0)) < 0) {\n\n                avfilter_free(scale);\n\n                return ret;\n\n            }\n\n            scale->outputs[0]->time_base = scale->inputs[0]->time_base;\n\n\n\n            scale->outputs[0]->format= c->pix_fmt;\n\n        } else if (!strcmp(scale->filter->name, \"scale\")) {\n\n            snprintf(scale_param, sizeof(scale_param)-1, \"%d:%d:%s\",\n\n                     scale->outputs[0]->w, scale->outputs[0]->h, c->sws_param);\n\n            scale->filter->init(scale, scale_param, NULL);\n\n        }\n\n\n\n        c->pix_fmt = scale->inputs[0]->format = picref->format;\n\n        c->w       = scale->inputs[0]->w      = picref->video->w;\n\n        c->h       = scale->inputs[0]->h      = picref->video->h;\n\n\n\n        link = scale->outputs[0];\n\n        if ((ret =  link->srcpad->config_props(link)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    c->picref = avfilter_get_video_buffer(outlink, AV_PERM_WRITE,\n\n                                          picref->video->w, picref->video->h);\n\n    av_image_copy(c->picref->data, c->picref->linesize,\n\n                  picref->data, picref->linesize,\n\n                  picref->format, picref->video->w, picref->video->h);\n\n    avfilter_copy_buffer_ref_props(c->picref, picref);\n\n\n\n    return 0;\n\n}\n", "idx": 10962, "_split": "test", "_hash": "4ab8273352695e9fa7beaa25bbeb9a20"}
{"project": "FFmpeg", "commit_id": "9568b2e425f127031ddc91dd78cb9b9f2cae206d", "target": 1, "func": "int ff_h264_decode_picture_parameter_set(GetBitContext *gb, AVCodecContext *avctx,\n                                         H264ParamSets *ps, int bit_length)\n{\n    AVBufferRef *pps_buf;\n    const SPS *sps;\n    unsigned int pps_id = get_ue_golomb(gb);\n    PPS *pps;\n    int qp_bd_offset;\n    int bits_left;\n    int ret;\n    if (pps_id >= MAX_PPS_COUNT) {\n        av_log(avctx, AV_LOG_ERROR, \"pps_id %u out of range\\n\", pps_id);\n        return AVERROR_INVALIDDATA;\n    pps_buf = av_buffer_allocz(sizeof(*pps));\n    if (!pps_buf)\n        return AVERROR(ENOMEM);\n    pps = (PPS*)pps_buf->data;\n    pps->data_size = gb->buffer_end - gb->buffer;\n    if (pps->data_size > sizeof(pps->data)) {\n        av_log(avctx, AV_LOG_WARNING, \"Truncating likely oversized PPS \"\n               \"(%\"SIZE_SPECIFIER\" > %\"SIZE_SPECIFIER\")\\n\",\n               pps->data_size, sizeof(pps->data));\n        pps->data_size = sizeof(pps->data);\n    memcpy(pps->data, gb->buffer, pps->data_size);\n    pps->sps_id = get_ue_golomb_31(gb);\n    if ((unsigned)pps->sps_id >= MAX_SPS_COUNT ||\n        !ps->sps_list[pps->sps_id]) {\n        av_log(avctx, AV_LOG_ERROR, \"sps_id %u out of range\\n\", pps->sps_id);\n    sps = (const SPS*)ps->sps_list[pps->sps_id]->data;\n    if (sps->bit_depth_luma > 14) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Invalid luma bit depth=%d\\n\",\n               sps->bit_depth_luma);\n    } else if (sps->bit_depth_luma == 11 || sps->bit_depth_luma == 13) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Unimplemented luma bit depth=%d\\n\",\n               sps->bit_depth_luma);\n        ret = AVERROR_PATCHWELCOME;\n    pps->cabac             = get_bits1(gb);\n    pps->pic_order_present = get_bits1(gb);\n    pps->slice_group_count = get_ue_golomb(gb) + 1;\n    if (pps->slice_group_count > 1) {\n        pps->mb_slice_group_map_type = get_ue_golomb(gb);\n        av_log(avctx, AV_LOG_ERROR, \"FMO not supported\\n\");\n        switch (pps->mb_slice_group_map_type) {\n        case 0:\n#if 0\n    |       for (i = 0; i <= num_slice_groups_minus1; i++)  |   |      |\n    |           run_length[i]                               |1  |ue(v) |\n#endif\n            break;\n        case 2:\n#if 0\n    |       for (i = 0; i < num_slice_groups_minus1; i++) { |   |      |\n    |           top_left_mb[i]                              |1  |ue(v) |\n    |           bottom_right_mb[i]                          |1  |ue(v) |\n    |       }                                               |   |      |\n#endif\n            break;\n        case 3:\n        case 4:\n        case 5:\n#if 0\n    |       slice_group_change_direction_flag               |1  |u(1)  |\n    |       slice_group_change_rate_minus1                  |1  |ue(v) |\n#endif\n            break;\n        case 6:\n#if 0\n    |       slice_group_id_cnt_minus1                       |1  |ue(v) |\n    |       for (i = 0; i <= slice_group_id_cnt_minus1; i++)|   |      |\n    |           slice_group_id[i]                           |1  |u(v)  |\n#endif\n            break;\n    pps->ref_count[0] = get_ue_golomb(gb) + 1;\n    pps->ref_count[1] = get_ue_golomb(gb) + 1;\n    if (pps->ref_count[0] - 1 > 32 - 1 || pps->ref_count[1] - 1 > 32 - 1) {\n        av_log(avctx, AV_LOG_ERROR, \"reference overflow (pps)\\n\");\n    qp_bd_offset = 6 * (sps->bit_depth_luma - 8);\n    pps->weighted_pred                        = get_bits1(gb);\n    pps->weighted_bipred_idc                  = get_bits(gb, 2);\n    pps->init_qp                              = get_se_golomb(gb) + 26 + qp_bd_offset;\n    pps->init_qs                              = get_se_golomb(gb) + 26 + qp_bd_offset;\n    pps->chroma_qp_index_offset[0]            = get_se_golomb(gb);\n    pps->deblocking_filter_parameters_present = get_bits1(gb);\n    pps->constrained_intra_pred               = get_bits1(gb);\n    pps->redundant_pic_cnt_present            = get_bits1(gb);\n    pps->transform_8x8_mode = 0;\n    memcpy(pps->scaling_matrix4, sps->scaling_matrix4,\n           sizeof(pps->scaling_matrix4));\n    memcpy(pps->scaling_matrix8, sps->scaling_matrix8,\n           sizeof(pps->scaling_matrix8));\n    bits_left = bit_length - get_bits_count(gb);\n    if (bits_left > 0 && more_rbsp_data_in_pps(sps, avctx)) {\n        pps->transform_8x8_mode = get_bits1(gb);\n        decode_scaling_matrices(gb, sps, pps, 0,\n                                pps->scaling_matrix4, pps->scaling_matrix8);\n        // second_chroma_qp_index_offset\n        pps->chroma_qp_index_offset[1] = get_se_golomb(gb);\n        if (pps->chroma_qp_index_offset[1] < -12 || pps->chroma_qp_index_offset[1] > 12) {\n    } else {\n        pps->chroma_qp_index_offset[1] = pps->chroma_qp_index_offset[0];\n    build_qp_table(pps, 0, pps->chroma_qp_index_offset[0],\n                   sps->bit_depth_luma);\n    build_qp_table(pps, 1, pps->chroma_qp_index_offset[1],\n                   sps->bit_depth_luma);\n    init_dequant_tables(pps, sps);\n    if (pps->chroma_qp_index_offset[0] != pps->chroma_qp_index_offset[1])\n        pps->chroma_qp_diff = 1;\n    if (avctx->debug & FF_DEBUG_PICT_INFO) {\n        av_log(avctx, AV_LOG_DEBUG,\n               \"pps:%u sps:%u %s slice_groups:%d ref:%u/%u %s qp:%d/%d/%d/%d %s %s %s %s\\n\",\n               pps_id, pps->sps_id,\n               pps->cabac ? \"CABAC\" : \"CAVLC\",\n               pps->slice_group_count,\n               pps->ref_count[0], pps->ref_count[1],\n               pps->weighted_pred ? \"weighted\" : \"\",\n               pps->init_qp, pps->init_qs, pps->chroma_qp_index_offset[0], pps->chroma_qp_index_offset[1],\n               pps->deblocking_filter_parameters_present ? \"LPAR\" : \"\",\n               pps->constrained_intra_pred ? \"CONSTR\" : \"\",\n               pps->redundant_pic_cnt_present ? \"REDU\" : \"\",\n               pps->transform_8x8_mode ? \"8x8DCT\" : \"\");\n    remove_pps(ps, pps_id);\n    ps->pps_list[pps_id] = pps_buf;\n    return 0;\nfail:\n    av_buffer_unref(&pps_buf);\n    return ret;", "idx": 10971, "_split": "test", "_hash": "92eded40b3a39a915bd8f9aaef74df6c"}
{"project": "FFmpeg", "commit_id": "892fc83e88a20f9543c6c5be3626712be7a2e6f2", "target": 0, "func": "static void init_block_mapping(Vp3DecodeContext *s) \n\n{\n\n    int i, j;\n\n    signed int hilbert_walk_y[16];\n\n    signed int hilbert_walk_c[16];\n\n    signed int hilbert_walk_mb[4];\n\n\n\n    int current_fragment = 0;\n\n    int current_width = 0;\n\n    int current_height = 0;\n\n    int right_edge = 0;\n\n    int bottom_edge = 0;\n\n    int superblock_row_inc = 0;\n\n    int *hilbert = NULL;\n\n    int mapping_index = 0;\n\n\n\n    int current_macroblock;\n\n    int c_fragment;\n\n\n\n    signed char travel_width[16] = {\n\n         1,  1,  0, -1, \n\n         0,  0,  1,  0,\n\n         1,  0,  1,  0,\n\n         0, -1,  0,  1\n\n    };\n\n\n\n    signed char travel_height[16] = {\n\n         0,  0,  1,  0,\n\n         1,  1,  0, -1,\n\n         0,  1,  0, -1,\n\n        -1,  0, -1,  0\n\n    };\n\n\n\n    signed char travel_width_mb[4] = {\n\n         1,  0,  1,  0\n\n    };\n\n\n\n    signed char travel_height_mb[4] = {\n\n         0,  1,  0, -1\n\n    };\n\n\n\n    debug_vp3(\"  vp3: initialize block mapping tables\\n\");\n\n\n\n    /* figure out hilbert pattern per these frame dimensions */\n\n    hilbert_walk_y[0]  = 1;\n\n    hilbert_walk_y[1]  = 1;\n\n    hilbert_walk_y[2]  = s->fragment_width;\n\n    hilbert_walk_y[3]  = -1;\n\n    hilbert_walk_y[4]  = s->fragment_width;\n\n    hilbert_walk_y[5]  = s->fragment_width;\n\n    hilbert_walk_y[6]  = 1;\n\n    hilbert_walk_y[7]  = -s->fragment_width;\n\n    hilbert_walk_y[8]  = 1;\n\n    hilbert_walk_y[9]  = s->fragment_width;\n\n    hilbert_walk_y[10]  = 1;\n\n    hilbert_walk_y[11] = -s->fragment_width;\n\n    hilbert_walk_y[12] = -s->fragment_width;\n\n    hilbert_walk_y[13] = -1;\n\n    hilbert_walk_y[14] = -s->fragment_width;\n\n    hilbert_walk_y[15] = 1;\n\n\n\n    hilbert_walk_c[0]  = 1;\n\n    hilbert_walk_c[1]  = 1;\n\n    hilbert_walk_c[2]  = s->fragment_width / 2;\n\n    hilbert_walk_c[3]  = -1;\n\n    hilbert_walk_c[4]  = s->fragment_width / 2;\n\n    hilbert_walk_c[5]  = s->fragment_width / 2;\n\n    hilbert_walk_c[6]  = 1;\n\n    hilbert_walk_c[7]  = -s->fragment_width / 2;\n\n    hilbert_walk_c[8]  = 1;\n\n    hilbert_walk_c[9]  = s->fragment_width / 2;\n\n    hilbert_walk_c[10]  = 1;\n\n    hilbert_walk_c[11] = -s->fragment_width / 2;\n\n    hilbert_walk_c[12] = -s->fragment_width / 2;\n\n    hilbert_walk_c[13] = -1;\n\n    hilbert_walk_c[14] = -s->fragment_width / 2;\n\n    hilbert_walk_c[15] = 1;\n\n\n\n    hilbert_walk_mb[0] = 1;\n\n    hilbert_walk_mb[1] = s->macroblock_width;\n\n    hilbert_walk_mb[2] = 1;\n\n    hilbert_walk_mb[3] = -s->macroblock_width;\n\n\n\n    /* iterate through each superblock (all planes) and map the fragments */\n\n    for (i = 0; i < s->superblock_count; i++) {\n\n        debug_init(\"    superblock %d (u starts @ %d, v starts @ %d)\\n\",\n\n            i, s->u_superblock_start, s->v_superblock_start);\n\n\n\n        /* time to re-assign the limits? */\n\n        if (i == 0) {\n\n\n\n            /* start of Y superblocks */\n\n            right_edge = s->fragment_width;\n\n            bottom_edge = s->fragment_height;\n\n            current_width = 0;\n\n            current_height = 0;\n\n            superblock_row_inc = 3 * s->fragment_width;\n\n            hilbert = hilbert_walk_y;\n\n\n\n            /* the first operation for this variable is to advance by 1 */\n\n            current_fragment = -1;\n\n\n\n        } else if (i == s->u_superblock_start) {\n\n\n\n            /* start of U superblocks */\n\n            right_edge = s->fragment_width / 2;\n\n            bottom_edge = s->fragment_height / 2;\n\n            current_width = 0;\n\n            current_height = 0;\n\n            superblock_row_inc = 3 * (s->fragment_width / 2);\n\n            hilbert = hilbert_walk_c;\n\n\n\n            /* the first operation for this variable is to advance by 1 */\n\n            current_fragment = s->u_fragment_start - 1;\n\n\n\n        } else if (i == s->v_superblock_start) {\n\n\n\n            /* start of V superblocks */\n\n            right_edge = s->fragment_width / 2;\n\n            bottom_edge = s->fragment_height / 2;\n\n            current_width = 0;\n\n            current_height = 0;\n\n            superblock_row_inc = 3 * (s->fragment_width / 2);\n\n            hilbert = hilbert_walk_c;\n\n\n\n            /* the first operation for this variable is to advance by 1 */\n\n            current_fragment = s->v_fragment_start - 1;\n\n\n\n        }\n\n\n\n        if (current_width >= right_edge) {\n\n            /* reset width and move to next superblock row */\n\n            current_width = 0;\n\n            current_height += 4;\n\n\n\n            /* fragment is now at the start of a new superblock row */\n\n            current_fragment += superblock_row_inc;\n\n        }\n\n\n\n        /* iterate through all 16 fragments in a superblock */\n\n        for (j = 0; j < 16; j++) {\n\n            current_fragment += hilbert[j];\n\n            current_height += travel_height[j];\n\n\n\n            /* check if the fragment is in bounds */\n\n            if ((current_width <= right_edge) &&\n\n                (current_height < bottom_edge)) {\n\n                s->superblock_fragments[mapping_index] = current_fragment;\n\n                debug_init(\"    mapping fragment %d to superblock %d, position %d\\n\", \n\n                    s->superblock_fragments[mapping_index], i, j);\n\n            } else {\n\n                s->superblock_fragments[mapping_index] = -1;\n\n                debug_init(\"    superblock %d, position %d has no fragment\\n\", \n\n                    i, j);\n\n            }\n\n\n\n            current_width += travel_width[j];\n\n            mapping_index++;\n\n        }\n\n    }\n\n\n\n    /* initialize the superblock <-> macroblock mapping; iterate through\n\n     * all of the Y plane superblocks to build this mapping */\n\n    right_edge = s->macroblock_width;\n\n    bottom_edge = s->macroblock_height;\n\n    current_width = 0;\n\n    current_height = 0;\n\n    superblock_row_inc = s->macroblock_width;\n\n    hilbert = hilbert_walk_mb;\n\n    mapping_index = 0;\n\n    current_macroblock = -1;\n\n    for (i = 0; i < s->u_superblock_start; i++) {\n\n\n\n        if (current_width >= right_edge) {\n\n            /* reset width and move to next superblock row */\n\n            current_width = 0;\n\n            current_height += 2;\n\n\n\n            /* macroblock is now at the start of a new superblock row */\n\n            current_macroblock += superblock_row_inc;\n\n        }\n\n\n\n        /* iterate through each potential macroblock in the superblock */\n\n        for (j = 0; j < 4; j++) {\n\n            current_macroblock += hilbert_walk_mb[j];\n\n            current_height += travel_height_mb[j];\n\n\n\n            /* check if the macroblock is in bounds */\n\n            if ((current_width <= right_edge) &&\n\n                (current_height < bottom_edge)) {\n\n                s->superblock_macroblocks[mapping_index] = current_macroblock;\n\n                debug_init(\"    mapping macroblock %d to superblock %d, position %d\\n\",\n\n                    s->superblock_macroblocks[mapping_index], i, j);\n\n            } else {\n\n                s->superblock_macroblocks[mapping_index] = -1;\n\n                debug_init(\"    superblock %d, position %d has no macroblock\\n\",\n\n                    i, j);\n\n            }\n\n\n\n            current_width += travel_width_mb[j];\n\n            mapping_index++;\n\n        }\n\n    }\n\n\n\n    /* initialize the macroblock <-> fragment mapping */\n\n    current_fragment = 0;\n\n    current_macroblock = 0;\n\n    mapping_index = 0;\n\n    for (i = 0; i < s->fragment_height; i += 2) {\n\n\n\n        for (j = 0; j < s->fragment_width; j += 2) {\n\n\n\n            debug_init(\"    macroblock %d contains fragments: \", current_macroblock);\n\n            s->all_fragments[current_fragment].macroblock = current_macroblock;\n\n            s->macroblock_fragments[mapping_index++] = current_fragment;\n\n            debug_init(\"%d \", current_fragment);\n\n\n\n            if (j + 1 < s->fragment_width) {\n\n                s->all_fragments[current_fragment + 1].macroblock = current_macroblock;\n\n                s->macroblock_fragments[mapping_index++] = current_fragment + 1;\n\n                debug_init(\"%d \", current_fragment + 1);\n\n            } else\n\n                s->macroblock_fragments[mapping_index++] = -1;\n\n\n\n            if (i + 1 < s->fragment_height) {\n\n                s->all_fragments[current_fragment + s->fragment_width].macroblock = \n\n                    current_macroblock;\n\n                s->macroblock_fragments[mapping_index++] = \n\n                    current_fragment + s->fragment_width;\n\n                debug_init(\"%d \", current_fragment + s->fragment_width);\n\n            } else\n\n                s->macroblock_fragments[mapping_index++] = -1;\n\n\n\n            if ((j + 1 < s->fragment_width) && (i + 1 < s->fragment_height)) {\n\n                s->all_fragments[current_fragment + s->fragment_width + 1].macroblock = \n\n                    current_macroblock;\n\n                s->macroblock_fragments[mapping_index++] = \n\n                    current_fragment + s->fragment_width + 1;\n\n                debug_init(\"%d \", current_fragment + s->fragment_width + 1);\n\n            } else\n\n                s->macroblock_fragments[mapping_index++] = -1;\n\n\n\n            /* C planes */\n\n            c_fragment = s->u_fragment_start + \n\n                (i * s->fragment_width / 4) + (j / 2);\n\n        s->all_fragments[c_fragment].macroblock = s->macroblock_count;\n\n            s->macroblock_fragments[mapping_index++] = c_fragment;\n\n            debug_init(\"%d \", c_fragment);\n\n\n\n            c_fragment = s->v_fragment_start + \n\n                (i * s->fragment_width / 4) + (j / 2);\n\n        s->all_fragments[c_fragment].macroblock = s->macroblock_count;\n\n            s->macroblock_fragments[mapping_index++] = c_fragment;\n\n            debug_init(\"%d \", c_fragment);\n\n\n\n            debug_init(\"\\n\");\n\n\n\n            if (j + 2 <= s->fragment_width)\n\n                current_fragment += 2;\n\n            else \n\n                current_fragment++;\n\n            current_macroblock++;\n\n        }\n\n\n\n        current_fragment += s->fragment_width;\n\n    }\n\n}\n", "idx": 10992, "_split": "test", "_hash": "c808addc425fc18e0eba4083c57d9c83"}
{"project": "FFmpeg", "commit_id": "af8aa846fa5b9f2c7dcde451c872426528b8b561", "target": 0, "func": "static void frame_start(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    int i;\n\n\n\n    MPV_frame_start(s, s->avctx);\n\n    ff_er_frame_start(s);\n\n\n\n    assert(s->linesize && s->uvlinesize);\n\n\n\n    for(i=0; i<16; i++){\n\n        h->block_offset[i]= 4*((scan8[i] - scan8[0])&7) + 4*s->linesize*((scan8[i] - scan8[0])>>3);\n\n        h->block_offset[24+i]= 4*((scan8[i] - scan8[0])&7) + 8*s->linesize*((scan8[i] - scan8[0])>>3);\n\n    }\n\n    for(i=0; i<4; i++){\n\n        h->block_offset[16+i]=\n\n        h->block_offset[20+i]= 4*((scan8[i] - scan8[0])&7) + 4*s->uvlinesize*((scan8[i] - scan8[0])>>3);\n\n        h->block_offset[24+16+i]=\n\n        h->block_offset[24+20+i]= 4*((scan8[i] - scan8[0])&7) + 8*s->uvlinesize*((scan8[i] - scan8[0])>>3);\n\n    }\n\n\n\n    /* can't be in alloc_tables because linesize isn't known there.\n\n     * FIXME: redo bipred weight to not require extra buffer? */\n\n    if(!s->obmc_scratchpad)\n\n        s->obmc_scratchpad = av_malloc(16*s->linesize + 2*8*s->uvlinesize);\n\n\n\n//    s->decode= (s->flags&CODEC_FLAG_PSNR) || !s->encoding || s->current_picture.reference /*|| h->contains_intra*/ || 1;\n\n}\n", "idx": 11026, "_split": "test", "_hash": "52e34815299f0215b6f7d7eeaa8a4e92"}
{"project": "FFmpeg", "commit_id": "c9aab8a123c0bcf6adeab390db1ec783326456ca", "target": 0, "func": "static void fill_colmap(H264Context *h, int map[2][16+32], int list, int field, int colfield, int mbafi){\n\n    MpegEncContext * const s = &h->s;\n\n    Picture * const ref1 = &h->ref_list[1][0];\n\n    int j, old_ref, rfield;\n\n    int start= mbafi ? 16                      : 0;\n\n    int end  = mbafi ? 16+2*h->ref_count[0]    : h->ref_count[0];\n\n    int interl= mbafi || s->picture_structure != PICT_FRAME;\n\n\n\n    /* bogus; fills in for missing frames */\n\n    memset(map[list], 0, sizeof(map[list]));\n\n\n\n    for(rfield=0; rfield<2; rfield++){\n\n        for(old_ref=0; old_ref<ref1->ref_count[colfield][list]; old_ref++){\n\n            int poc = ref1->ref_poc[colfield][list][old_ref];\n\n\n\n            if     (!interl)\n\n                poc |= 3;\n\n            else if( interl && (poc&3) == 3) //FIXME store all MBAFF references so this isnt needed\n\n                poc= (poc&~3) + rfield + 1;\n\n\n\n            for(j=start; j<end; j++){\n\n                if (4 * h->ref_list[0][j].frame_num + (h->ref_list[0][j].f.reference & 3) == poc) {\n\n                    int cur_ref= mbafi ? (j-16)^field : j;\n\n                    map[list][2*old_ref + (rfield^field) + 16] = cur_ref;\n\n                    if(rfield == field || !interl)\n\n                        map[list][old_ref] = cur_ref;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 11080, "_split": "test", "_hash": "c338b49ea7bafe733a17dc0aee4a025d"}
{"project": "FFmpeg", "commit_id": "3c895fc098f7637f6d5ec3a9d6766e724a8b9e41", "target": 0, "func": "static void compute_frame_duration(int *pnum, int *pden,\n\n                                   AVFormatContext *s, AVStream *st, \n\n                                   AVCodecParserContext *pc, AVPacket *pkt)\n\n{\n\n    int frame_size;\n\n\n\n    *pnum = 0;\n\n    *pden = 0;\n\n    switch(st->codec.codec_type) {\n\n    case CODEC_TYPE_VIDEO:\n\n        *pnum = st->codec.frame_rate_base;\n\n        *pden = st->codec.frame_rate;\n\n        if (pc && pc->repeat_pict) {\n\n            *pden *= 2;\n\n            *pnum = (*pnum) * (2 + pc->repeat_pict);\n\n        }\n\n        break;\n\n    case CODEC_TYPE_AUDIO:\n\n        frame_size = get_audio_frame_size(&st->codec, pkt->size);\n\n        if (frame_size < 0)\n\n            break;\n\n        *pnum = frame_size;\n\n        *pden = st->codec.sample_rate;\n\n        break;\n\n    default:\n\n        break;\n\n    }\n\n}\n", "idx": 11084, "_split": "test", "_hash": "130b93703d9e091d3acb1256c5d08571"}
{"project": "FFmpeg", "commit_id": "c4e554701ec27b31b1b6396130b8bb2aaa0d4ad0", "target": 0, "func": "DVDemuxContext* dv_init_demux(AVFormatContext *s)\n\n{\n\n    DVDemuxContext *c;\n\n\n\n    c = av_mallocz(sizeof(DVDemuxContext));\n\n    if (!c)\n\n        return NULL;\n\n\n\n    c->vst = av_new_stream(s, 0);\n\n    c->ast[0] = av_new_stream(s, 0);\n\n    if (!c->vst || !c->ast[0])\n\n        goto fail;\n\n    av_set_pts_info(c->vst, 64, 1, 30000);\n\n    av_set_pts_info(c->ast[0], 64, 1, 30000);\n\n\n\n    c->fctx = s;\n\n    c->ast[1] = NULL;\n\n    c->ach = 0;\n\n    c->frames = 0;\n\n    c->abytes = 0;\n\n    c->audio_pkt[0].size = 0;\n\n    c->audio_pkt[1].size = 0;\n\n    \n\n    c->vst->codec.codec_type = CODEC_TYPE_VIDEO;\n\n    c->vst->codec.codec_id = CODEC_ID_DVVIDEO;\n\n    c->vst->codec.bit_rate = 25000000;\n\n    \n\n    c->ast[0]->codec.codec_type = CODEC_TYPE_AUDIO;\n\n    c->ast[0]->codec.codec_id = CODEC_ID_PCM_S16LE;\n\n   \n\n    s->ctx_flags |= AVFMTCTX_NOHEADER; \n\n    \n\n    return c;\n\n    \n\nfail:\n\n    if (c->vst)\n\n        av_free(c->vst);\n\n    if (c->ast[0])\n\n        av_free(c->ast[0]);\n\n    av_free(c);\n\n    return NULL;\n\n}\n", "idx": 11140, "_split": "test", "_hash": "1cd1526f74af3db95d860e2eb6f8f70c"}
{"project": "FFmpeg", "commit_id": "a28cccf6d62dc770757491510c248ed632a836ce", "target": 1, "func": "static av_cold void init_atrac3_transforms(ATRAC3Context *q) {\n\n    float enc_window[256];\n\n    int i;\n\n\n\n    /* Generate the mdct window, for details see\n\n     * http://wiki.multimedia.cx/index.php?title=RealAudio_atrc#Windows */\n\n    for (i=0 ; i<256; i++)\n\n        enc_window[i] = (sin(((i + 0.5) / 256.0 - 0.5) * M_PI) + 1.0) * 0.5;\n\n\n\n    if (!mdct_window[0])\n\n        for (i=0 ; i<256; i++) {\n\n            mdct_window[i] = enc_window[i]/(enc_window[i]*enc_window[i] + enc_window[255-i]*enc_window[255-i]);\n\n            mdct_window[511-i] = mdct_window[i];\n\n        }\n\n\n\n    /* Initialize the MDCT transform. */\n\n    ff_mdct_init(&mdct_ctx, 9, 1, 1.0);\n\n}\n", "idx": 11361, "_split": "test", "_hash": "d24d72be24bf2d2ddb0c6a490826b63e"}
{"project": "FFmpeg", "commit_id": "3df2be9fa7365646f22a93cfde1e4097467f498e", "target": 1, "func": "static void matroska_fix_ass_packet(MatroskaDemuxContext *matroska,\n\n                                    AVPacket *pkt, uint64_t display_duration)\n\n{\n\n    char *line, *layer, *ptr = pkt->data, *end = ptr+pkt->size;\n\n    for (; *ptr!=',' && ptr<end-1; ptr++);\n\n    if (*ptr == ',')\n\n        layer = ++ptr;\n\n    for (; *ptr!=',' && ptr<end-1; ptr++);\n\n    if (*ptr == ',') {\n\n        int64_t end_pts = pkt->pts + display_duration;\n\n        int sc = matroska->time_scale * pkt->pts / 10000000;\n\n        int ec = matroska->time_scale * end_pts  / 10000000;\n\n        int sh, sm, ss, eh, em, es, len;\n\n        sh = sc/360000;  sc -= 360000*sh;\n\n        sm = sc/  6000;  sc -=   6000*sm;\n\n        ss = sc/   100;  sc -=    100*ss;\n\n        eh = ec/360000;  ec -= 360000*eh;\n\n        em = ec/  6000;  ec -=   6000*em;\n\n        es = ec/   100;  ec -=    100*es;\n\n        *ptr++ = '\\0';\n\n        len = 50 + end-ptr + FF_INPUT_BUFFER_PADDING_SIZE;\n\n        if (!(line = av_malloc(len)))\n\n            return;\n\n        snprintf(line,len,\"Dialogue: %s,%d:%02d:%02d.%02d,%d:%02d:%02d.%02d,%s\",\n\n                 layer, sh, sm, ss, sc, eh, em, es, ec, ptr);\n\n        av_free(pkt->data);\n\n        pkt->data = line;\n\n        pkt->size = strlen(line);\n\n    }\n\n}\n", "idx": 11383, "_split": "test", "_hash": "28968247073142da52f86b9a163ea13e"}
{"project": "FFmpeg", "commit_id": "1acd7d594c15aa491729c837ad3519d3469e620a", "target": 0, "func": "void FUNCC(ff_h264_idct_dc_add)(uint8_t *_dst, int16_t *block, int stride){\n\n    int i, j;\n\n    int dc = (((dctcoef*)block)[0] + 32) >> 6;\n\n    pixel *dst = (pixel*)_dst;\n\n    stride >>= sizeof(pixel)-1;\n\n    for( j = 0; j < 4; j++ )\n\n    {\n\n        for( i = 0; i < 4; i++ )\n\n            dst[i] = av_clip_pixel( dst[i] + dc );\n\n        dst += stride;\n\n    }\n\n}\n", "idx": 11423, "_split": "test", "_hash": "24d5adcfbce27528588c2e39d8a349c0"}
{"project": "FFmpeg", "commit_id": "2862b63783b5556f7f3fb2d097629bc6879f833a", "target": 0, "func": "static int encode_picture_ls(AVCodecContext *avctx, AVPacket *pkt,\n\n                             const AVFrame *pict, int *got_packet)\n\n{\n\n    const AVFrame *const p = pict;\n\n    const int near         = avctx->prediction_method;\n\n    PutBitContext pb, pb2;\n\n    GetBitContext gb;\n\n    uint8_t *buf2 = NULL;\n\n    uint8_t *zero = NULL;\n\n    uint8_t *cur  = NULL;\n\n    uint8_t *last = NULL;\n\n    JLSState *state;\n\n    int i, size, ret;\n\n    int comps;\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_GRAY8 ||\n\n        avctx->pix_fmt == AV_PIX_FMT_GRAY16)\n\n        comps = 1;\n\n    else\n\n        comps = 3;\n\n\n\n    if ((ret = ff_alloc_packet(pkt, avctx->width * avctx->height * comps * 4 +\n\n                               AV_INPUT_BUFFER_MIN_SIZE)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet.\\n\");\n\n        return ret;\n\n    }\n\n\n\n    buf2 = av_malloc(pkt->size);\n\n    if (!buf2)\n\n        goto memfail;\n\n\n\n    init_put_bits(&pb, pkt->data, pkt->size);\n\n    init_put_bits(&pb2, buf2, pkt->size);\n\n\n\n    /* write our own JPEG header, can't use mjpeg_picture_header */\n\n    put_marker(&pb, SOI);\n\n    put_marker(&pb, SOF48);\n\n    put_bits(&pb, 16, 8 + comps * 3); // header size depends on components\n\n    put_bits(&pb, 8, (avctx->pix_fmt == AV_PIX_FMT_GRAY16) ? 16 : 8);  // bpp\n\n    put_bits(&pb, 16, avctx->height);\n\n    put_bits(&pb, 16, avctx->width);\n\n    put_bits(&pb, 8, comps);          // components\n\n    for (i = 1; i <= comps; i++) {\n\n        put_bits(&pb, 8, i);     // component ID\n\n        put_bits(&pb, 8, 0x11);  // subsampling: none\n\n        put_bits(&pb, 8, 0);     // Tiq, used by JPEG-LS ext\n\n    }\n\n\n\n    put_marker(&pb, SOS);\n\n    put_bits(&pb, 16, 6 + comps * 2);\n\n    put_bits(&pb, 8, comps);\n\n    for (i = 1; i <= comps; i++) {\n\n        put_bits(&pb, 8, i);   // component ID\n\n        put_bits(&pb, 8, 0);   // mapping index: none\n\n    }\n\n    put_bits(&pb, 8, near);\n\n    put_bits(&pb, 8, (comps > 1) ? 1 : 0);  // interleaving: 0 - plane, 1 - line\n\n    put_bits(&pb, 8, 0);  // point transform: none\n\n\n\n    state = av_mallocz(sizeof(JLSState));\n\n    if (!state)\n\n        goto memfail;\n\n\n\n    /* initialize JPEG-LS state from JPEG parameters */\n\n    state->near = near;\n\n    state->bpp  = (avctx->pix_fmt == AV_PIX_FMT_GRAY16) ? 16 : 8;\n\n    ff_jpegls_reset_coding_parameters(state, 0);\n\n    ff_jpegls_init_state(state);\n\n\n\n    ls_store_lse(state, &pb);\n\n\n\n    zero = last = av_mallocz(p->linesize[0]);\n\n    if (!zero)\n\n        goto memfail;\n\n\n\n    cur  = p->data[0];\n\n    if (avctx->pix_fmt == AV_PIX_FMT_GRAY8) {\n\n        int t = 0;\n\n\n\n        for (i = 0; i < avctx->height; i++) {\n\n            ls_encode_line(state, &pb2, last, cur, t, avctx->width, 1, 0, 8);\n\n            t    = last[0];\n\n            last = cur;\n\n            cur += p->linesize[0];\n\n        }\n\n    } else if (avctx->pix_fmt == AV_PIX_FMT_GRAY16) {\n\n        int t = 0;\n\n\n\n        for (i = 0; i < avctx->height; i++) {\n\n            ls_encode_line(state, &pb2, last, cur, t, avctx->width, 1, 0, 16);\n\n            t    = *((uint16_t *)last);\n\n            last = cur;\n\n            cur += p->linesize[0];\n\n        }\n\n    } else if (avctx->pix_fmt == AV_PIX_FMT_RGB24) {\n\n        int j, width;\n\n        int Rc[3] = { 0, 0, 0 };\n\n\n\n        width = avctx->width * 3;\n\n        for (i = 0; i < avctx->height; i++) {\n\n            for (j = 0; j < 3; j++) {\n\n                ls_encode_line(state, &pb2, last + j, cur + j, Rc[j],\n\n                               width, 3, j, 8);\n\n                Rc[j] = last[j];\n\n            }\n\n            last = cur;\n\n            cur += p->linesize[0];\n\n        }\n\n    } else if (avctx->pix_fmt == AV_PIX_FMT_BGR24) {\n\n        int j, width;\n\n        int Rc[3] = { 0, 0, 0 };\n\n\n\n        width = avctx->width * 3;\n\n        for (i = 0; i < avctx->height; i++) {\n\n            for (j = 2; j >= 0; j--) {\n\n                ls_encode_line(state, &pb2, last + j, cur + j, Rc[j],\n\n                               width, 3, j, 8);\n\n                Rc[j] = last[j];\n\n            }\n\n            last = cur;\n\n            cur += p->linesize[0];\n\n        }\n\n    }\n\n\n\n    av_freep(&zero);\n\n    av_freep(&state);\n\n\n\n    /* the specification says that after doing 0xff escaping unused bits in\n\n     * the last byte must be set to 0, so just append 7 \"optional\" zero-bits\n\n     * to avoid special-casing. */\n\n    put_bits(&pb2, 7, 0);\n\n    size = put_bits_count(&pb2);\n\n    flush_put_bits(&pb2);\n\n    /* do escape coding */\n\n    init_get_bits(&gb, buf2, size);\n\n    size -= 7;\n\n    while (get_bits_count(&gb) < size) {\n\n        int v;\n\n        v = get_bits(&gb, 8);\n\n        put_bits(&pb, 8, v);\n\n        if (v == 0xFF) {\n\n            v = get_bits(&gb, 7);\n\n            put_bits(&pb, 8, v);\n\n        }\n\n    }\n\n    avpriv_align_put_bits(&pb);\n\n    av_freep(&buf2);\n\n\n\n    /* End of image */\n\n    put_marker(&pb, EOI);\n\n    flush_put_bits(&pb);\n\n\n\n    emms_c();\n\n\n\n    pkt->size   = put_bits_count(&pb) >> 3;\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n    return 0;\n\n\n\nmemfail:\n\n    av_packet_unref(pkt);\n\n    av_freep(&buf2);\n\n    av_freep(&state);\n\n    av_freep(&zero);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 11427, "_split": "test", "_hash": "17e4cb0dc20920695f290ea4b8407d03"}
{"project": "FFmpeg", "commit_id": "577393321c389ad2973bec6168a8045c94a9e099", "target": 0, "func": "void ff_vc1_decode_blocks(VC1Context *v)\n\n{\n\n\n\n    v->s.esc3_level_length = 0;\n\n    if (v->x8_type) {\n\n        ff_intrax8_decode_picture(&v->x8, 2*v->pq + v->halfpq, v->pq * !v->pquantizer);\n\n\n\n        ff_er_add_slice(&v->s.er, 0, 0,\n\n                        (v->s.mb_x >> 1) - 1, (v->s.mb_y >> 1) - 1,\n\n                        ER_MB_END);\n\n    } else {\n\n        v->cur_blk_idx     =  0;\n\n        v->left_blk_idx    = -1;\n\n        v->topleft_blk_idx =  1;\n\n        v->top_blk_idx     =  2;\n\n        switch (v->s.pict_type) {\n\n        case AV_PICTURE_TYPE_I:\n\n            if (v->profile == PROFILE_ADVANCED)\n\n                vc1_decode_i_blocks_adv(v);\n\n            else\n\n                vc1_decode_i_blocks(v);\n\n            break;\n\n        case AV_PICTURE_TYPE_P:\n\n            if (v->p_frame_skipped)\n\n                vc1_decode_skip_blocks(v);\n\n            else\n\n                vc1_decode_p_blocks(v);\n\n            break;\n\n        case AV_PICTURE_TYPE_B:\n\n            if (v->bi_type) {\n\n                if (v->profile == PROFILE_ADVANCED)\n\n                    vc1_decode_i_blocks_adv(v);\n\n                else\n\n                    vc1_decode_i_blocks(v);\n\n            } else\n\n                vc1_decode_b_blocks(v);\n\n            break;\n\n        }\n\n    }\n\n}\n", "idx": 11428, "_split": "test", "_hash": "d31b1e78cdc814fa357babb3abb3ff31"}
{"project": "FFmpeg", "commit_id": "8ce803db51a28eb662b6271b2b223e0312bdb3d2", "target": 1, "func": "paint_mouse_pointer(XImage *image, struct x11_grab *s)\n\n{\n\n    int x_off = s->x_off;\n\n    int y_off = s->y_off;\n\n    int width = s->width;\n\n    int height = s->height;\n\n    Display *dpy = s->dpy;\n\n    XFixesCursorImage *xcim;\n\n    int x, y;\n\n    int line, column;\n\n    int to_line, to_column;\n\n    int image_addr, xcim_addr;\n\n\n\n    xcim = XFixesGetCursorImage(dpy);\n\n\n\n    x = xcim->x - xcim->xhot;\n\n    y = xcim->y - xcim->yhot;\n\n\n\n    to_line = FFMIN((y + xcim->height), (height + y_off));\n\n    to_column = FFMIN((x + xcim->width), (width + x_off));\n\n\n\n    for (line = FFMAX(y, y_off); line < to_line; line++) {\n\n        for (column = FFMAX(x, x_off); column < to_column; column++) {\n\n            xcim_addr = (line - y) * xcim->width + column - x;\n\n\n\n            if ((unsigned char)(xcim->pixels[xcim_addr] >> 24) != 0) { // skip fully transparent pixel\n\n                image_addr = ((line - y_off) * width + column - x_off) * 4;\n\n\n\n                image->data[image_addr] = (unsigned char)(xcim->pixels[xcim_addr] >> 0);\n\n                image->data[image_addr+1] = (unsigned char)(xcim->pixels[xcim_addr] >> 8);\n\n                image->data[image_addr+2] = (unsigned char)(xcim->pixels[xcim_addr] >> 16);\n\n            }\n\n        }\n\n    }\n\n\n\n    XFree(xcim);\n\n    xcim = NULL;\n\n}\n", "idx": 11433, "_split": "test", "_hash": "d558a0a874d22acf9b75888ac461ff5d"}
{"project": "FFmpeg", "commit_id": "fa2a34cd40d124161c748bb0f430dc63c94dd0da", "target": 0, "func": "int avfilter_register(AVFilter *filter)\n\n{\n\n    if (next_registered_avfilter_idx == MAX_REGISTERED_AVFILTERS_NB)\n\n        return -1;\n\n\n\n    registered_avfilters[next_registered_avfilter_idx++] = filter;\n\n    return 0;\n\n}\n", "idx": 11444, "_split": "test", "_hash": "3b045cd058c40ff4da6f94346d5de54c"}
{"project": "FFmpeg", "commit_id": "5bca5f87d1a32669e0357790e0d0ad8a5c9c998b", "target": 0, "func": "static av_noinline void emulated_edge_mc_sse(uint8_t *buf, const uint8_t *src,\n\n                                             ptrdiff_t buf_stride,\n\n                                             ptrdiff_t src_stride,\n\n                                             int block_w, int block_h,\n\n                                             int src_x, int src_y, int w, int h)\n\n{\n\n    emulated_edge_mc(buf, src, buf_stride, src_stride, block_w, block_h,\n\n                     src_x, src_y, w, h, vfixtbl_sse, &ff_emu_edge_vvar_sse,\n\n                     hfixtbl_mmxext, &ff_emu_edge_hvar_mmxext);\n\n}\n", "idx": 11468, "_split": "test", "_hash": "4397c3044b3f370270542f41d96058ee"}
{"project": "FFmpeg", "commit_id": "a1a32fdb0ee63783d06c63b7d90bb382eea356ce", "target": 1, "func": "static int mov_text_tx3g(AVCodecContext *avctx, MovTextContext *m)\n\n{\n\n    char *tx3g_ptr = avctx->extradata;\n\n    int i, box_size, font_length;\n\n    int8_t v_align, h_align;\n\n    int style_fontID;\n\n    StyleBox s_default;\n\n\n\n    m->count_f = 0;\n\n    m->ftab_entries = 0;\n\n    box_size = BOX_SIZE_INITIAL; /* Size till ftab_entries */\n\n    if (avctx->extradata_size < box_size)\n\n        return -1;\n\n\n\n    // Display Flags\n\n    tx3g_ptr += 4;\n\n    // Alignment\n\n    h_align = *tx3g_ptr++;\n\n    v_align = *tx3g_ptr++;\n\n    if (h_align == 0) {\n\n        if (v_align == 0)\n\n            m->d.alignment = TOP_LEFT;\n\n        if (v_align == 1)\n\n            m->d.alignment = MIDDLE_LEFT;\n\n        if (v_align == -1)\n\n            m->d.alignment = BOTTOM_LEFT;\n\n    }\n\n    if (h_align == 1) {\n\n        if (v_align == 0)\n\n            m->d.alignment = TOP_CENTER;\n\n        if (v_align == 1)\n\n            m->d.alignment = MIDDLE_CENTER;\n\n        if (v_align == -1)\n\n            m->d.alignment = BOTTOM_CENTER;\n\n    }\n\n    if (h_align == -1) {\n\n        if (v_align == 0)\n\n            m->d.alignment = TOP_RIGHT;\n\n        if (v_align == 1)\n\n            m->d.alignment = MIDDLE_RIGHT;\n\n        if (v_align == -1)\n\n            m->d.alignment = BOTTOM_RIGHT;\n\n    }\n\n    // Background Color\n\n    m->d.back_color = AV_RB24(tx3g_ptr);\n\n    tx3g_ptr += 4;\n\n    // BoxRecord\n\n    tx3g_ptr += 8;\n\n    // StyleRecord\n\n    tx3g_ptr += 4;\n\n    // fontID\n\n    style_fontID = AV_RB16(tx3g_ptr);\n\n    tx3g_ptr += 2;\n\n    // face-style-flags\n\n    s_default.style_flag = *tx3g_ptr++;\n\n    m->d.bold = s_default.style_flag & STYLE_FLAG_BOLD;\n\n    m->d.italic = s_default.style_flag & STYLE_FLAG_ITALIC;\n\n    m->d.underline = s_default.style_flag & STYLE_FLAG_UNDERLINE;\n\n    // fontsize\n\n    m->d.fontsize = *tx3g_ptr++;\n\n    // Primary color\n\n    m->d.color = AV_RB24(tx3g_ptr);\n\n    tx3g_ptr += 4;\n\n    // FontRecord\n\n    // FontRecord Size\n\n    tx3g_ptr += 4;\n\n    // ftab\n\n    tx3g_ptr += 4;\n\n\n\n    m->ftab_entries = AV_RB16(tx3g_ptr);\n\n    tx3g_ptr += 2;\n\n\n\n    for (i = 0; i < m->ftab_entries; i++) {\n\n\n\n        box_size += 3;\n\n        if (avctx->extradata_size < box_size) {\n\n            mov_text_cleanup_ftab(m);\n\n            m->ftab_entries = 0;\n\n            return -1;\n\n        }\n\n        m->ftab_temp = av_malloc(sizeof(*m->ftab_temp));\n\n        if (!m->ftab_temp) {\n\n            mov_text_cleanup_ftab(m);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        m->ftab_temp->fontID = AV_RB16(tx3g_ptr);\n\n        tx3g_ptr += 2;\n\n        font_length = *tx3g_ptr++;\n\n\n\n        box_size = box_size + font_length;\n\n        if (avctx->extradata_size < box_size) {\n\n            mov_text_cleanup_ftab(m);\n\n            m->ftab_entries = 0;\n\n            return -1;\n\n        }\n\n        m->ftab_temp->font = av_malloc(font_length + 1);\n\n        if (!m->ftab_temp->font) {\n\n            mov_text_cleanup_ftab(m);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        memcpy(m->ftab_temp->font, tx3g_ptr, font_length);\n\n        m->ftab_temp->font[font_length] = '\\0';\n\n        av_dynarray_add(&m->ftab, &m->count_f, m->ftab_temp);\n\n        if (!m->ftab) {\n\n            mov_text_cleanup_ftab(m);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        tx3g_ptr = tx3g_ptr + font_length;\n\n    }\n\n    for (i = 0; i < m->ftab_entries; i++) {\n\n        if (style_fontID == m->ftab[i]->fontID)\n\n            m->d.font = m->ftab[i]->font;\n\n    }\n\n    return 0;\n\n}\n", "idx": 11488, "_split": "test", "_hash": "ee7a4d4887414d0ee3e70b880f22e63b"}
{"project": "FFmpeg", "commit_id": "83548fe894cdb455cc127f754d09905b6d23c173", "target": 0, "func": "static int avi_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    unsigned char tag[5];\n\n    unsigned int flags = 0;\n\n    const int stream_index = pkt->stream_index;\n\n    int size               = pkt->size;\n\n    AVIContext *avi     = s->priv_data;\n\n    AVIOContext *pb     = s->pb;\n\n    AVIStream *avist    = s->streams[stream_index]->priv_data;\n\n    AVCodecParameters *par = s->streams[stream_index]->codecpar;\n\n\n\n    while (par->block_align == 0 && pkt->dts != AV_NOPTS_VALUE &&\n\n           pkt->dts > avist->packet_count) {\n\n        AVPacket empty_packet;\n\n\n\n        av_init_packet(&empty_packet);\n\n        empty_packet.size         = 0;\n\n        empty_packet.data         = NULL;\n\n        empty_packet.stream_index = stream_index;\n\n        avi_write_packet(s, &empty_packet);\n\n    }\n\n    avist->packet_count++;\n\n\n\n    // Make sure to put an OpenDML chunk when the file size exceeds the limits\n\n    if (pb->seekable &&\n\n        (avio_tell(pb) - avi->riff_start > AVI_MAX_RIFF_SIZE)) {\n\n        avi_write_ix(s);\n\n        ff_end_tag(pb, avi->movi_list);\n\n\n\n        if (avi->riff_id == 1)\n\n            avi_write_idx1(s);\n\n\n\n        ff_end_tag(pb, avi->riff_start);\n\n        avi->movi_list = avi_start_new_riff(s, pb, \"AVIX\", \"movi\");\n\n    }\n\n\n\n    avi_stream2fourcc(tag, stream_index, par->codec_type);\n\n    if (pkt->flags & AV_PKT_FLAG_KEY)\n\n        flags = 0x10;\n\n    if (par->codec_type == AVMEDIA_TYPE_AUDIO)\n\n        avist->audio_strm_length += size;\n\n\n\n    if (s->pb->seekable) {\n\n        int err;\n\n        AVIIndex *idx = &avist->indexes;\n\n        int cl = idx->entry / AVI_INDEX_CLUSTER_SIZE;\n\n        int id = idx->entry % AVI_INDEX_CLUSTER_SIZE;\n\n        if (idx->ents_allocated <= idx->entry) {\n\n            if ((err = av_reallocp(&idx->cluster,\n\n                                   (cl + 1) * sizeof(*idx->cluster))) < 0) {\n\n                idx->ents_allocated = 0;\n\n                idx->entry          = 0;\n\n                return err;\n\n            }\n\n            idx->cluster[cl] =\n\n                av_malloc(AVI_INDEX_CLUSTER_SIZE * sizeof(AVIIentry));\n\n            if (!idx->cluster[cl])\n\n                return -1;\n\n            idx->ents_allocated += AVI_INDEX_CLUSTER_SIZE;\n\n        }\n\n\n\n        idx->cluster[cl][id].flags = flags;\n\n        idx->cluster[cl][id].pos   = avio_tell(pb) - avi->movi_list;\n\n        idx->cluster[cl][id].len   = size;\n\n        idx->entry++;\n\n    }\n\n\n\n    avio_write(pb, tag, 4);\n\n    avio_wl32(pb, size);\n\n    avio_write(pb, pkt->data, size);\n\n    if (size & 1)\n\n        avio_w8(pb, 0);\n\n\n\n    return 0;\n\n}\n", "idx": 11527, "_split": "test", "_hash": "76dcda274e7199cb677f810e59c7663e"}
{"project": "FFmpeg", "commit_id": "0d021cc8b30a6f81c27fbeca7f99f1ee7a20acf8", "target": 0, "func": "static av_cold int check_cuda_errors(AVCodecContext *avctx, CUresult err, const char *func)\n\n{\n\n    if (err != CUDA_SUCCESS) {\n\n        av_log(avctx, AV_LOG_FATAL, \">> %s - failed with error code 0x%x\\n\", func, err);\n\n        return 0;\n\n    }\n\n    return 1;\n\n}\n", "idx": 11529, "_split": "test", "_hash": "300fb33dcb07c87150a3e9ab59f7c752"}
{"project": "FFmpeg", "commit_id": "e87190f5d20d380608f792ceb14d0def1d80e24b", "target": 0, "func": "static void show_stream(WriterContext *w, AVFormatContext *fmt_ctx, int stream_idx, int in_program)\n\n{\n\n    AVStream *stream = fmt_ctx->streams[stream_idx];\n\n    AVCodecContext *dec_ctx;\n\n    const AVCodec *dec;\n\n    char val_str[128];\n\n    const char *s;\n\n    AVRational sar, dar;\n\n    AVBPrint pbuf;\n\n\n\n    av_bprint_init(&pbuf, 1, AV_BPRINT_SIZE_UNLIMITED);\n\n\n\n    writer_print_section_header(w, in_program ? SECTION_ID_PROGRAM_STREAM : SECTION_ID_STREAM);\n\n\n\n    print_int(\"index\", stream->index);\n\n\n\n    if ((dec_ctx = stream->codec)) {\n\n        const char *profile = NULL;\n\n        dec = dec_ctx->codec;\n\n        if (dec) {\n\n            print_str(\"codec_name\", dec->name);\n\n            if (!do_bitexact) {\n\n                if (dec->long_name) print_str    (\"codec_long_name\", dec->long_name);\n\n                else                print_str_opt(\"codec_long_name\", \"unknown\");\n\n            }\n\n        } else {\n\n            print_str_opt(\"codec_name\", \"unknown\");\n\n            if (!do_bitexact) {\n\n                print_str_opt(\"codec_long_name\", \"unknown\");\n\n            }\n\n        }\n\n\n\n        if (dec && (profile = av_get_profile_name(dec, dec_ctx->profile)))\n\n            print_str(\"profile\", profile);\n\n        else\n\n            print_str_opt(\"profile\", \"unknown\");\n\n\n\n        s = av_get_media_type_string(dec_ctx->codec_type);\n\n        if (s) print_str    (\"codec_type\", s);\n\n        else   print_str_opt(\"codec_type\", \"unknown\");\n\n        print_q(\"codec_time_base\", dec_ctx->time_base, '/');\n\n\n\n        /* print AVI/FourCC tag */\n\n        av_get_codec_tag_string(val_str, sizeof(val_str), dec_ctx->codec_tag);\n\n        print_str(\"codec_tag_string\",    val_str);\n\n        print_fmt(\"codec_tag\", \"0x%04x\", dec_ctx->codec_tag);\n\n\n\n        switch (dec_ctx->codec_type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            print_int(\"width\",        dec_ctx->width);\n\n            print_int(\"height\",       dec_ctx->height);\n\n            print_int(\"has_b_frames\", dec_ctx->has_b_frames);\n\n            sar = av_guess_sample_aspect_ratio(fmt_ctx, stream, NULL);\n\n            if (sar.den) {\n\n                print_q(\"sample_aspect_ratio\", sar, ':');\n\n                av_reduce(&dar.num, &dar.den,\n\n                          dec_ctx->width  * sar.num,\n\n                          dec_ctx->height * sar.den,\n\n                          1024*1024);\n\n                print_q(\"display_aspect_ratio\", dar, ':');\n\n            } else {\n\n                print_str_opt(\"sample_aspect_ratio\", \"N/A\");\n\n                print_str_opt(\"display_aspect_ratio\", \"N/A\");\n\n            }\n\n            s = av_get_pix_fmt_name(dec_ctx->pix_fmt);\n\n            if (s) print_str    (\"pix_fmt\", s);\n\n            else   print_str_opt(\"pix_fmt\", \"unknown\");\n\n            print_int(\"level\",   dec_ctx->level);\n\n            if (dec_ctx->timecode_frame_start >= 0) {\n\n                char tcbuf[AV_TIMECODE_STR_SIZE];\n\n                av_timecode_make_mpeg_tc_string(tcbuf, dec_ctx->timecode_frame_start);\n\n                print_str(\"timecode\", tcbuf);\n\n            } else {\n\n                print_str_opt(\"timecode\", \"N/A\");\n\n            }\n\n            break;\n\n\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            s = av_get_sample_fmt_name(dec_ctx->sample_fmt);\n\n            if (s) print_str    (\"sample_fmt\", s);\n\n            else   print_str_opt(\"sample_fmt\", \"unknown\");\n\n            print_val(\"sample_rate\",     dec_ctx->sample_rate, unit_hertz_str);\n\n            print_int(\"channels\",        dec_ctx->channels);\n\n\n\n            if (dec_ctx->channel_layout) {\n\n                av_bprint_clear(&pbuf);\n\n                av_bprint_channel_layout(&pbuf, dec_ctx->channels, dec_ctx->channel_layout);\n\n                print_str    (\"channel_layout\", pbuf.str);\n\n            } else {\n\n                print_str_opt(\"channel_layout\", \"unknown\");\n\n            }\n\n\n\n            print_int(\"bits_per_sample\", av_get_bits_per_sample(dec_ctx->codec_id));\n\n            break;\n\n\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            if (dec_ctx->width)\n\n                print_int(\"width\",       dec_ctx->width);\n\n            else\n\n                print_str_opt(\"width\",   \"N/A\");\n\n            if (dec_ctx->height)\n\n                print_int(\"height\",      dec_ctx->height);\n\n            else\n\n                print_str_opt(\"height\",  \"N/A\");\n\n            break;\n\n        }\n\n    } else {\n\n        print_str_opt(\"codec_type\", \"unknown\");\n\n    }\n\n    if (dec_ctx->codec && dec_ctx->codec->priv_class && show_private_data) {\n\n        const AVOption *opt = NULL;\n\n        while (opt = av_opt_next(dec_ctx->priv_data,opt)) {\n\n            uint8_t *str;\n\n            if (opt->flags) continue;\n\n            if (av_opt_get(dec_ctx->priv_data, opt->name, 0, &str) >= 0) {\n\n                print_str(opt->name, str);\n\n                av_free(str);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (fmt_ctx->iformat->flags & AVFMT_SHOW_IDS) print_fmt    (\"id\", \"0x%x\", stream->id);\n\n    else                                          print_str_opt(\"id\", \"N/A\");\n\n    print_q(\"r_frame_rate\",   stream->r_frame_rate,   '/');\n\n    print_q(\"avg_frame_rate\", stream->avg_frame_rate, '/');\n\n    print_q(\"time_base\",      stream->time_base,      '/');\n\n    print_ts  (\"start_pts\",   stream->start_time);\n\n    print_time(\"start_time\",  stream->start_time, &stream->time_base);\n\n    print_ts  (\"duration_ts\", stream->duration);\n\n    print_time(\"duration\",    stream->duration, &stream->time_base);\n\n    if (dec_ctx->bit_rate > 0) print_val    (\"bit_rate\", dec_ctx->bit_rate, unit_bit_per_second_str);\n\n    else                       print_str_opt(\"bit_rate\", \"N/A\");\n\n    if (stream->nb_frames) print_fmt    (\"nb_frames\", \"%\"PRId64, stream->nb_frames);\n\n    else                   print_str_opt(\"nb_frames\", \"N/A\");\n\n    if (nb_streams_frames[stream_idx])  print_fmt    (\"nb_read_frames\", \"%\"PRIu64, nb_streams_frames[stream_idx]);\n\n    else                                print_str_opt(\"nb_read_frames\", \"N/A\");\n\n    if (nb_streams_packets[stream_idx]) print_fmt    (\"nb_read_packets\", \"%\"PRIu64, nb_streams_packets[stream_idx]);\n\n    else                                print_str_opt(\"nb_read_packets\", \"N/A\");\n\n    if (do_show_data)\n\n        writer_print_data(w, \"extradata\", dec_ctx->extradata,\n\n                                          dec_ctx->extradata_size);\n\n\n\n    /* Print disposition information */\n\n#define PRINT_DISPOSITION(flagname, name) do {                                \\\n\n        print_int(name, !!(stream->disposition & AV_DISPOSITION_##flagname)); \\\n\n    } while (0)\n\n\n\n    if (do_show_stream_disposition) {\n\n    writer_print_section_header(w, in_program ? SECTION_ID_PROGRAM_STREAM_DISPOSITION : SECTION_ID_STREAM_DISPOSITION);\n\n    PRINT_DISPOSITION(DEFAULT,          \"default\");\n\n    PRINT_DISPOSITION(DUB,              \"dub\");\n\n    PRINT_DISPOSITION(ORIGINAL,         \"original\");\n\n    PRINT_DISPOSITION(COMMENT,          \"comment\");\n\n    PRINT_DISPOSITION(LYRICS,           \"lyrics\");\n\n    PRINT_DISPOSITION(KARAOKE,          \"karaoke\");\n\n    PRINT_DISPOSITION(FORCED,           \"forced\");\n\n    PRINT_DISPOSITION(HEARING_IMPAIRED, \"hearing_impaired\");\n\n    PRINT_DISPOSITION(VISUAL_IMPAIRED,  \"visual_impaired\");\n\n    PRINT_DISPOSITION(CLEAN_EFFECTS,    \"clean_effects\");\n\n    PRINT_DISPOSITION(ATTACHED_PIC,     \"attached_pic\");\n\n    writer_print_section_footer(w);\n\n    }\n\n\n\n    show_tags(w, stream->metadata, in_program ? SECTION_ID_PROGRAM_STREAM_TAGS : SECTION_ID_STREAM_TAGS);\n\n\n\n    writer_print_section_footer(w);\n\n    av_bprint_finalize(&pbuf, NULL);\n\n    fflush(stdout);\n\n}\n", "idx": 11535, "_split": "test", "_hash": "20601389509b33d0a63e1c63d5be8a68"}
{"project": "FFmpeg", "commit_id": "8d857c543402911f46ad38b093ab9aaf5b9a9a18", "target": 1, "func": "static inline int get_block(GetBitContext *gb, DCTELEM *block, const uint8_t *scan,\n\n                            const uint32_t *quant) {\n\n    int coeff, i, n;\n\n    int8_t ac;\n\n    uint8_t dc = get_bits(gb, 8);\n\n\n\n    // block not coded\n\n    if (dc == 255)\n\n\n\n\n    // number of non-zero coefficients\n\n    coeff = get_bits(gb, 6);\n\n    if (get_bits_count(gb) + (coeff << 1) >= gb->size_in_bits)\n\n\n\n\n    // normally we would only need to clear the (63 - coeff) last values,\n\n    // but since we do not know where they are we just clear the whole block\n\n    memset(block, 0, 64 * sizeof(DCTELEM));\n\n\n\n    // 2 bits per coefficient\n\n    while (coeff) {\n\n        ac = get_sbits(gb, 2);\n\n        if (ac == -2)\n\n            break; // continue with more bits\n\n        PUT_COEFF(ac);\n\n    }\n\n\n\n    // 4 bits per coefficient\n\n    ALIGN(4);\n\n\n\n    while (coeff) {\n\n        ac = get_sbits(gb, 4);\n\n        if (ac == -8)\n\n            break; // continue with more bits\n\n        PUT_COEFF(ac);\n\n    }\n\n\n\n    // 8 bits per coefficient\n\n    ALIGN(8);\n\n    if (get_bits_count(gb) + (coeff << 3) >= gb->size_in_bits)\n\n\n    while (coeff) {\n\n        ac = get_sbits(gb, 8);\n\n        PUT_COEFF(ac);\n\n    }\n\n\n\n    PUT_COEFF(dc);\n\n    return 1;\n\n}", "idx": 11543, "_split": "test", "_hash": "70689a819840f2fce4df71bdf128ffde"}
{"project": "FFmpeg", "commit_id": "6722e564a82bac471d92b02550b5017c09b539ba", "target": 0, "func": "static int parse_header(OutputStream *os, const uint8_t *buf, int buf_size)\n\n{\n\n    if (buf_size < 13)\n\n        return AVERROR_INVALIDDATA;\n\n    if (memcmp(buf, \"FLV\", 3))\n\n        return AVERROR_INVALIDDATA;\n\n    buf      += 13;\n\n    buf_size -= 13;\n\n    while (buf_size >= 11 + 4) {\n\n        int type = buf[0];\n\n        int size = AV_RB24(&buf[1]) + 11 + 4;\n\n        if (size > buf_size)\n\n            return AVERROR_INVALIDDATA;\n\n        if (type == 8 || type == 9) {\n\n            if (os->nb_extra_packets > FF_ARRAY_ELEMS(os->extra_packets))\n\n                return AVERROR_INVALIDDATA;\n\n            os->extra_packet_sizes[os->nb_extra_packets] = size;\n\n            os->extra_packets[os->nb_extra_packets] = av_malloc(size);\n\n            if (!os->extra_packets[os->nb_extra_packets])\n\n                return AVERROR(ENOMEM);\n\n            memcpy(os->extra_packets[os->nb_extra_packets], buf, size);\n\n            os->nb_extra_packets++;\n\n        } else if (type == 0x12) {\n\n            if (os->metadata)\n\n                return AVERROR_INVALIDDATA;\n\n            os->metadata_size = size - 11 - 4;\n\n            os->metadata      = av_malloc(os->metadata_size);\n\n            if (!os->metadata)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(os->metadata, buf + 11, os->metadata_size);\n\n        }\n\n        buf      += size;\n\n        buf_size -= size;\n\n    }\n\n    if (!os->metadata)\n\n        return AVERROR_INVALIDDATA;\n\n    return 0;\n\n}\n", "idx": 11553, "_split": "test", "_hash": "b3086cc263f18f0249645025e5d6519e"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(nv12ToUV)(uint8_t *dstU, uint8_t *dstV,\n\n                                    const uint8_t *src1, const uint8_t *src2,\n\n                                    long width, uint32_t *unused)\n\n{\n\n    RENAME(nvXXtoUV)(dstU, dstV, src1, width);\n\n}\n", "idx": 11662, "_split": "test", "_hash": "66ea58fa0ad7f80ab6d986d8b38af623"}
{"project": "FFmpeg", "commit_id": "30e256430eb88c6d4c382581b89bca171d79fbc0", "target": 0, "func": "int ff_thread_init(AVCodecContext *avctx)\n\n{\n\n    if (avctx->thread_opaque) {\n\n        av_log(avctx, AV_LOG_ERROR, \"avcodec_thread_init is ignored after avcodec_open\\n\");\n\n        return -1;\n\n    }\n\n\n\n#if HAVE_W32THREADS\n\n    w32thread_init();\n\n#endif\n\n\n\n    if (avctx->codec) {\n\n        validate_thread_parameters(avctx);\n\n\n\n        if (avctx->active_thread_type&FF_THREAD_SLICE)\n\n            return thread_init(avctx);\n\n        else if (avctx->active_thread_type&FF_THREAD_FRAME)\n\n            return frame_thread_init(avctx);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 11665, "_split": "test", "_hash": "7542bc16df1bbf256f194a28ea1c5590"}
{"project": "FFmpeg", "commit_id": "e048a9cab10f1d41dca7b1ad9c8ecaceb3424d86", "target": 1, "func": "static int pcm_decode_frame(AVCodecContext *avctx,\n                            void *data, int *data_size,\n                            AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    PCMDecode *s = avctx->priv_data;\n    int sample_size, c, n, i;\n    short *samples;\n    const uint8_t *src, *src8, *src2[MAX_CHANNELS];\n    uint8_t *dstu8;\n    int16_t *dst_int16_t;\n    int32_t *dst_int32_t;\n    int64_t *dst_int64_t;\n    uint16_t *dst_uint16_t;\n    uint32_t *dst_uint32_t;\n    samples = data;\n    src = buf;\n    if (avctx->sample_fmt!=avctx->codec->sample_fmts[0]) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid sample_fmt\\n\");\n        return -1;\n    if(avctx->channels <= 0 || avctx->channels > MAX_CHANNELS){\n        av_log(avctx, AV_LOG_ERROR, \"PCM channels out of bounds\\n\");\n        return -1;\n    sample_size = av_get_bits_per_sample(avctx->codec_id)/8;\n    /* av_get_bits_per_sample returns 0 for CODEC_ID_PCM_DVD */\n    if (CODEC_ID_PCM_DVD == avctx->codec_id)\n        /* 2 samples are interleaved per block in PCM_DVD */\n        sample_size = avctx->bits_per_coded_sample * 2 / 8;\n    else if (avctx->codec_id == CODEC_ID_PCM_LXF)\n        /* we process 40-bit blocks per channel for LXF */\n        sample_size = 5;\n    n = avctx->channels * sample_size;\n    if(n && buf_size % n){\n        if (buf_size < n) {\n            av_log(avctx, AV_LOG_ERROR, \"invalid PCM packet\\n\");\n            return -1;\n        }else\n            buf_size -= buf_size % n;\n    buf_size= FFMIN(buf_size, *data_size/2);\n    *data_size=0;\n    n = buf_size/sample_size;\n    switch(avctx->codec->id) {\n    case CODEC_ID_PCM_U32LE:\n        DECODE(uint32_t, le32, src, samples, n, 0, 0x80000000)\n        break;\n    case CODEC_ID_PCM_U32BE:\n        DECODE(uint32_t, be32, src, samples, n, 0, 0x80000000)\n        break;\n    case CODEC_ID_PCM_S24LE:\n        DECODE(int32_t, le24, src, samples, n, 8, 0)\n        break;\n    case CODEC_ID_PCM_S24BE:\n        DECODE(int32_t, be24, src, samples, n, 8, 0)\n        break;\n    case CODEC_ID_PCM_U24LE:\n        DECODE(uint32_t, le24, src, samples, n, 8, 0x800000)\n        break;\n    case CODEC_ID_PCM_U24BE:\n        DECODE(uint32_t, be24, src, samples, n, 8, 0x800000)\n        break;\n    case CODEC_ID_PCM_S24DAUD:\n        for(;n>0;n--) {\n          uint32_t v = bytestream_get_be24(&src);\n          v >>= 4; // sync flags are here\n          *samples++ = av_reverse[(v >> 8) & 0xff] +\n                       (av_reverse[v & 0xff] << 8);\n        break;\n    case CODEC_ID_PCM_S16LE_PLANAR:\n        n /= avctx->channels;\n        for(c=0;c<avctx->channels;c++)\n            src2[c] = &src[c*n*2];\n        for(;n>0;n--)\n            for(c=0;c<avctx->channels;c++)\n                *samples++ = bytestream_get_le16(&src2[c]);\n        src = src2[avctx->channels-1];\n        break;\n    case CODEC_ID_PCM_U16LE:\n        DECODE(uint16_t, le16, src, samples, n, 0, 0x8000)\n        break;\n    case CODEC_ID_PCM_U16BE:\n        DECODE(uint16_t, be16, src, samples, n, 0, 0x8000)\n        break;\n    case CODEC_ID_PCM_S8:\n        dstu8= (uint8_t*)samples;\n        for(;n>0;n--) {\n            *dstu8++ = *src++ + 128;\n        samples= (short*)dstu8;\n        break;\n#if HAVE_BIGENDIAN\n    case CODEC_ID_PCM_F64LE:\n        DECODE(int64_t, le64, src, samples, n, 0, 0)\n        break;\n    case CODEC_ID_PCM_S32LE:\n    case CODEC_ID_PCM_F32LE:\n        DECODE(int32_t, le32, src, samples, n, 0, 0)\n        break;\n    case CODEC_ID_PCM_S16LE:\n        DECODE(int16_t, le16, src, samples, n, 0, 0)\n        break;\n    case CODEC_ID_PCM_F64BE:\n    case CODEC_ID_PCM_F32BE:\n    case CODEC_ID_PCM_S32BE:\n    case CODEC_ID_PCM_S16BE:\n#else\n    case CODEC_ID_PCM_F64BE:\n        DECODE(int64_t, be64, src, samples, n, 0, 0)\n        break;\n    case CODEC_ID_PCM_F32BE:\n    case CODEC_ID_PCM_S32BE:\n        DECODE(int32_t, be32, src, samples, n, 0, 0)\n        break;\n    case CODEC_ID_PCM_S16BE:\n        DECODE(int16_t, be16, src, samples, n, 0, 0)\n        break;\n    case CODEC_ID_PCM_F64LE:\n    case CODEC_ID_PCM_F32LE:\n    case CODEC_ID_PCM_S32LE:\n    case CODEC_ID_PCM_S16LE:\n#endif /* HAVE_BIGENDIAN */\n    case CODEC_ID_PCM_U8:\n        memcpy(samples, src, n*sample_size);\n        src += n*sample_size;\n        samples = (short*)((uint8_t*)data + n*sample_size);\n        break;\n    case CODEC_ID_PCM_ZORK:\n        for(;n>0;n--) {\n            int x= *src++;\n            if(x&128) x-= 128;\n            else      x = -x;\n            *samples++ = x << 8;\n        break;\n    case CODEC_ID_PCM_ALAW:\n    case CODEC_ID_PCM_MULAW:\n        for(;n>0;n--) {\n            *samples++ = s->table[*src++];\n        break;\n    case CODEC_ID_PCM_DVD:\n        dst_int32_t = data;\n        n /= avctx->channels;\n        switch (avctx->bits_per_coded_sample) {\n        case 20:\n            while (n--) {\n                c = avctx->channels;\n                src8 = src + 4*c;\n                while (c--) {\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8   &0xf0) << 8);\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++ &0x0f) << 12);\n                src = src8;\n            break;\n        case 24:\n            while (n--) {\n                c = avctx->channels;\n                src8 = src + 4*c;\n                while (c--) {\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n                    *dst_int32_t++ = (bytestream_get_be16(&src) << 16) + ((*src8++) << 8);\n                src = src8;\n            break;\n        default:\n            av_log(avctx, AV_LOG_ERROR, \"PCM DVD unsupported sample depth\\n\");\n            return -1;\n            break;\n        samples = (short *) dst_int32_t;\n        break;\n    case CODEC_ID_PCM_LXF:\n        dst_int32_t = data;\n        n /= avctx->channels;\n        //unpack and de-planerize\n        for (i = 0; i < n; i++) {\n            for (c = 0, src8 = src + i*5; c < avctx->channels; c++, src8 += n*5) {\n                //extract low 20 bits and expand to 32 bits\n                *dst_int32_t++ = (src8[2] << 28) | (src8[1] << 20) | (src8[0] << 12) |\n                                 ((src8[2] & 0xF) << 8) | src8[1];\n            for (c = 0, src8 = src + i*5; c < avctx->channels; c++, src8 += n*5) {\n                //extract high 20 bits and expand to 32 bits\n                *dst_int32_t++ = (src8[4] << 24) | (src8[3] << 16) |\n                                 ((src8[2] & 0xF0) << 8) | (src8[4] << 4) | (src8[3] >> 4);\n        src += n * avctx->channels * 5;\n        samples = (short *) dst_int32_t;\n        break;\n    default:\n        return -1;\n    *data_size = (uint8_t *)samples - (uint8_t *)data;\n    return src - buf;", "idx": 11712, "_split": "test", "_hash": "478037930f708c3f90d18317a50b1c72"}
{"project": "FFmpeg", "commit_id": "8bedbb82cee4463a43e60eb22674c8bf927280ef", "target": 1, "func": "static void copy_frame(Jpeg2000EncoderContext *s)\n\n{\n\n    int tileno, compno, i, y, x;\n\n    uint8_t *line;\n\n    for (tileno = 0; tileno < s->numXtiles * s->numYtiles; tileno++){\n\n        Jpeg2000Tile *tile = s->tile + tileno;\n\n        if (s->planar){\n\n            for (compno = 0; compno < s->ncomponents; compno++){\n\n                Jpeg2000Component *comp = tile->comp + compno;\n\n                int *dst = comp->data;\n\n                line = s->picture.data[compno]\n\n                       + comp->coord[1][0] * s->picture.linesize[compno]\n\n                       + comp->coord[0][0];\n\n                for (y = comp->coord[1][0]; y < comp->coord[1][1]; y++){\n\n                    uint8_t *ptr = line;\n\n                    for (x = comp->coord[0][0]; x < comp->coord[0][1]; x++)\n\n                        *dst++ = *ptr++ - (1 << 7);\n\n                    line += s->picture.linesize[compno];\n\n                }\n\n            }\n\n        } else{\n\n            line = s->picture.data[0] + tile->comp[0].coord[1][0] * s->picture.linesize[0]\n\n                   + tile->comp[0].coord[0][0] * s->ncomponents;\n\n\n\n            i = 0;\n\n            for (y = tile->comp[0].coord[1][0]; y < tile->comp[0].coord[1][1]; y++){\n\n                uint8_t *ptr = line;\n\n                for (x = tile->comp[0].coord[0][0]; x < tile->comp[0].coord[0][1]; x++, i++){\n\n                    for (compno = 0; compno < s->ncomponents; compno++){\n\n                        tile->comp[compno].data[i] = *ptr++  - (1 << 7);\n\n                    }\n\n                }\n\n                line += s->picture.linesize[0];\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 11749, "_split": "test", "_hash": "42d1b79af26eb47ddc4ec7e5733c8d90"}
{"project": "FFmpeg", "commit_id": "4b5a12a2cb0252c4a08b6d099eaf69523e8c62e5", "target": 0, "func": "static int filter_samples(AVFilterLink *inlink, AVFilterBufferRef *insamplesref)\n\n{\n\n    AResampleContext *aresample = inlink->dst->priv;\n\n    const int n_in  = insamplesref->audio->nb_samples;\n\n    int n_out       = FFMAX(n_in * aresample->ratio * 2, 1);\n\n    AVFilterLink *const outlink = inlink->dst->outputs[0];\n\n    AVFilterBufferRef *outsamplesref = ff_get_audio_buffer(outlink, AV_PERM_WRITE, n_out);\n\n    int ret;\n\n\n\n    if(!outsamplesref)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avfilter_copy_buffer_ref_props(outsamplesref, insamplesref);\n\n    outsamplesref->format                = outlink->format;\n\n    outsamplesref->audio->channel_layout = outlink->channel_layout;\n\n    outsamplesref->audio->sample_rate    = outlink->sample_rate;\n\n\n\n    if(insamplesref->pts != AV_NOPTS_VALUE) {\n\n        int64_t inpts = av_rescale(insamplesref->pts, inlink->time_base.num * (int64_t)outlink->sample_rate * inlink->sample_rate, inlink->time_base.den);\n\n        int64_t outpts= swr_next_pts(aresample->swr, inpts);\n\n        aresample->next_pts =\n\n        outsamplesref->pts  = (outpts + inlink->sample_rate/2) / inlink->sample_rate;\n\n    } else {\n\n        outsamplesref->pts  = AV_NOPTS_VALUE;\n\n    }\n\n\n\n    n_out = swr_convert(aresample->swr, outsamplesref->extended_data, n_out,\n\n                                 (void *)insamplesref->extended_data, n_in);\n\n    if (n_out <= 0) {\n\n        avfilter_unref_buffer(outsamplesref);\n\n        avfilter_unref_buffer(insamplesref);\n\n        return 0;\n\n    }\n\n\n\n    outsamplesref->audio->nb_samples  = n_out;\n\n\n\n    ret = ff_filter_samples(outlink, outsamplesref);\n\n    aresample->req_fullfilled= 1;\n\n    avfilter_unref_buffer(insamplesref);\n\n    return ret;\n\n}\n", "idx": 11793, "_split": "test", "_hash": "d1a33fb4a830ea41e29fbae6812da812"}
{"project": "FFmpeg", "commit_id": "138568e9da0e3abfc818329ab12ea3fb667639fb", "target": 0, "func": "static int mov_read_ctts(MOVContext *c, ByteIOContext *pb, MOV_atom_t atom)\n\n{\n\n    AVStream *st = c->fc->streams[c->fc->nb_streams-1];\n\n    MOVStreamContext *sc = st->priv_data;\n\n    unsigned int i, entries;\n\n\n\n    get_byte(pb); /* version */\n\n    get_be24(pb); /* flags */\n\n    entries = get_be32(pb);\n\n    if(entries >= UINT_MAX / sizeof(MOV_stts_t))\n\n        return -1;\n\n\n\n    sc->ctts_count = entries;\n\n    sc->ctts_data = av_malloc(entries * sizeof(MOV_stts_t));\n\n    if (!sc->ctts_data)\n\n        return -1;\n\n    dprintf(c->fc, \"track[%i].ctts.entries = %i\\n\", c->fc->nb_streams-1, entries);\n\n\n\n    for(i=0; i<entries; i++) {\n\n        int count    =get_be32(pb);\n\n        int duration =get_be32(pb);\n\n\n\n        if (duration < 0) {\n\n            av_log(c->fc, AV_LOG_ERROR, \"negative ctts, ignoring\\n\");\n\n            sc->ctts_count = 0;\n\n            url_fskip(pb, 8 * (entries - i - 1));\n\n            break;\n\n        }\n\n        sc->ctts_data[i].count   = count;\n\n        sc->ctts_data[i].duration= duration;\n\n\n\n        sc->time_rate= ff_gcd(sc->time_rate, duration);\n\n    }\n\n    return 0;\n\n}\n", "idx": 11795, "_split": "test", "_hash": "1ae22192863c334cb9145dbe65b9a178"}
{"project": "FFmpeg", "commit_id": "8089b7fa8c5b5a48cc7101daa4be891d0ead5a5e", "target": 1, "func": "int64_t av_get_int(void *obj, const char *name, const AVOption **o_out)\n\n{\n\n    int64_t intnum=1;\n\n    double num=1;\n\n    int den=1;\n\n\n\n    av_get_number(obj, name, o_out, &num, &den, &intnum);\n\n    return num*intnum/den;\n\n}\n", "idx": 11806, "_split": "test", "_hash": "6a34b254cf6ead8917abd13b64f26cd9"}
{"project": "FFmpeg", "commit_id": "4f90688b6e1d79d85ac2e065a2cf1e7e9bd665a7", "target": 1, "func": "static int matroska_decode_buffer(uint8_t** buf, int* buf_size,\n                                  MatroskaTrack *track)\n{\n    MatroskaTrackEncoding *encodings = track->encodings.elem;\n    uint8_t* data = *buf;\n    int isize = *buf_size;\n    uint8_t* pkt_data = NULL;\n    int pkt_size = isize;\n    int result = 0;\n    int olen;\n    switch (encodings[0].compression.algo) {\n    case MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP:\n        return encodings[0].compression.settings.size;\n    case MATROSKA_TRACK_ENCODING_COMP_LZO:\n        do {\n            olen = pkt_size *= 3;\n            pkt_data = av_realloc(pkt_data, pkt_size+AV_LZO_OUTPUT_PADDING);\n            result = av_lzo1x_decode(pkt_data, &olen, data, &isize);\n        } while (result==AV_LZO_OUTPUT_FULL && pkt_size<10000000);\n        if (result)\n            goto failed;\n        pkt_size -= olen;\n        break;\n#if CONFIG_ZLIB\n    case MATROSKA_TRACK_ENCODING_COMP_ZLIB: {\n        z_stream zstream = {0};\n        if (inflateInit(&zstream) != Z_OK)\n        zstream.next_in = data;\n        zstream.avail_in = isize;\n        do {\n            pkt_size *= 3;\n            pkt_data = av_realloc(pkt_data, pkt_size);\n            zstream.avail_out = pkt_size - zstream.total_out;\n            zstream.next_out = pkt_data + zstream.total_out;\n            result = inflate(&zstream, Z_NO_FLUSH);\n        } while (result==Z_OK && pkt_size<10000000);\n        pkt_size = zstream.total_out;\n        inflateEnd(&zstream);\n        if (result != Z_STREAM_END)\n            goto failed;\n        break;\n    }\n#endif\n#if CONFIG_BZLIB\n    case MATROSKA_TRACK_ENCODING_COMP_BZLIB: {\n        bz_stream bzstream = {0};\n        if (BZ2_bzDecompressInit(&bzstream, 0, 0) != BZ_OK)\n        bzstream.next_in = data;\n        bzstream.avail_in = isize;\n        do {\n            pkt_size *= 3;\n            pkt_data = av_realloc(pkt_data, pkt_size);\n            bzstream.avail_out = pkt_size - bzstream.total_out_lo32;\n            bzstream.next_out = pkt_data + bzstream.total_out_lo32;\n            result = BZ2_bzDecompress(&bzstream);\n        } while (result==BZ_OK && pkt_size<10000000);\n        pkt_size = bzstream.total_out_lo32;\n        BZ2_bzDecompressEnd(&bzstream);\n        if (result != BZ_STREAM_END)\n            goto failed;\n        break;\n    }\n#endif\n    default:\n    }\n    *buf = pkt_data;\n    *buf_size = pkt_size;\n    return 0;\n failed:\n    av_free(pkt_data);\n}", "idx": 11813, "_split": "test", "_hash": "445cdbe851ef45756f23f80b1bd0e3c7"}
{"project": "FFmpeg", "commit_id": "03acb035d1292685cc24a2be0f62dd8332711734", "target": 1, "func": "static int decode_format80(VqaContext *s, int src_size,\n\n    unsigned char *dest, int dest_size, int check_size) {\n\n\n\n    int dest_index = 0;\n\n    int count, opcode, start;\n\n    int src_pos;\n\n    unsigned char color;\n\n    int i;\n\n\n\n    start = bytestream2_tell(&s->gb);\n\n    while (bytestream2_tell(&s->gb) - start < src_size) {\n\n        opcode = bytestream2_get_byte(&s->gb);\n\n        av_dlog(s->avctx, \"opcode %02X: \", opcode);\n\n\n\n        /* 0x80 means that frame is finished */\n\n        if (opcode == 0x80)\n\n            break;\n\n\n\n        if (dest_index >= dest_size) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"decode_format80 problem: dest_index (%d) exceeded dest_size (%d)\\n\",\n\n                dest_index, dest_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (opcode == 0xFF) {\n\n\n\n            count   = bytestream2_get_le16(&s->gb);\n\n            src_pos = bytestream2_get_le16(&s->gb);\n\n            av_dlog(s->avctx, \"(1) copy %X bytes from absolute pos %X\\n\", count, src_pos);\n\n            CHECK_COUNT();\n\n            CHECK_COPY(src_pos);\n\n            for (i = 0; i < count; i++)\n\n                dest[dest_index + i] = dest[src_pos + i];\n\n            dest_index += count;\n\n\n\n        } else if (opcode == 0xFE) {\n\n\n\n            count = bytestream2_get_le16(&s->gb);\n\n            color = bytestream2_get_byte(&s->gb);\n\n            av_dlog(s->avctx, \"(2) set %X bytes to %02X\\n\", count, color);\n\n            CHECK_COUNT();\n\n            memset(&dest[dest_index], color, count);\n\n            dest_index += count;\n\n\n\n        } else if ((opcode & 0xC0) == 0xC0) {\n\n\n\n            count = (opcode & 0x3F) + 3;\n\n            src_pos = bytestream2_get_le16(&s->gb);\n\n            av_dlog(s->avctx, \"(3) copy %X bytes from absolute pos %X\\n\", count, src_pos);\n\n            CHECK_COUNT();\n\n            CHECK_COPY(src_pos);\n\n            for (i = 0; i < count; i++)\n\n                dest[dest_index + i] = dest[src_pos + i];\n\n            dest_index += count;\n\n\n\n        } else if (opcode > 0x80) {\n\n\n\n            count = opcode & 0x3F;\n\n            av_dlog(s->avctx, \"(4) copy %X bytes from source to dest\\n\", count);\n\n            CHECK_COUNT();\n\n            bytestream2_get_buffer(&s->gb, &dest[dest_index], count);\n\n            dest_index += count;\n\n\n\n        } else {\n\n\n\n            count = ((opcode & 0x70) >> 4) + 3;\n\n            src_pos = bytestream2_get_byte(&s->gb) | ((opcode & 0x0F) << 8);\n\n            av_dlog(s->avctx, \"(5) copy %X bytes from relpos %X\\n\", count, src_pos);\n\n            CHECK_COUNT();\n\n            CHECK_COPY(dest_index - src_pos);\n\n            for (i = 0; i < count; i++)\n\n                dest[dest_index + i] = dest[dest_index - src_pos + i];\n\n            dest_index += count;\n\n        }\n\n    }\n\n\n\n    /* validate that the entire destination buffer was filled; this is\n\n     * important for decoding frame maps since each vector needs to have a\n\n     * codebook entry; it is not important for compressed codebooks because\n\n     * not every entry needs to be filled */\n\n    if (check_size)\n\n        if (dest_index < dest_size)\n\n            av_log(s->avctx, AV_LOG_ERROR, \"decode_format80 problem: decode finished with dest_index (%d) < dest_size (%d)\\n\",\n\n                dest_index, dest_size);\n\n\n\n    return 0; // let's display what we decoded anyway\n\n}\n", "idx": 11877, "_split": "test", "_hash": "755afc17f4b91f69182e64f58458ce27"}
{"project": "FFmpeg", "commit_id": "d3b25383daffac154846daeb4e4fb46569e728db", "target": 1, "func": "static int zero12v_decode_frame(AVCodecContext *avctx, void *data,\n\n                                int *got_frame, AVPacket *avpkt)\n\n{\n\n    int line = 0, ret;\n\n    const int width = avctx->width;\n\n    AVFrame *pic = data;\n\n    uint16_t *y, *u, *v;\n\n    const uint8_t *line_end, *src = avpkt->data;\n\n    int stride = avctx->width * 8 / 3;\n\n\n\n    if (width == 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Width 1 not supported.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (   avctx->codec_tag == MKTAG('0', '1', '2', 'v')\n\n        && avpkt->size % avctx->height == 0\n\n        && avpkt->size / avctx->height * 3 >= width * 8)\n\n        stride = avpkt->size / avctx->height;\n\n\n\n    if (avpkt->size < avctx->height * stride) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Packet too small: %d instead of %d\\n\",\n\n               avpkt->size, avctx->height * stride);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((ret = ff_get_buffer(avctx, pic, 0)) < 0)\n\n        return ret;\n\n\n\n    pic->pict_type = AV_PICTURE_TYPE_I;\n\n    pic->key_frame = 1;\n\n\n\n    y = (uint16_t *)pic->data[0];\n\n    u = (uint16_t *)pic->data[1];\n\n    v = (uint16_t *)pic->data[2];\n\n    line_end = avpkt->data + stride;\n\n\n\n    while (line++ < avctx->height) {\n\n        while (1) {\n\n            uint32_t t = AV_RL32(src);\n\n            src += 4;\n\n            *u++ = t <<  6 & 0xFFC0;\n\n            *y++ = t >>  4 & 0xFFC0;\n\n            *v++ = t >> 14 & 0xFFC0;\n\n\n\n            if (src >= line_end - 1) {\n\n                *y = 0x80;\n\n                src++;\n\n                line_end += stride;\n\n                y = (uint16_t *)(pic->data[0] + line * pic->linesize[0]);\n\n                u = (uint16_t *)(pic->data[1] + line * pic->linesize[1]);\n\n                v = (uint16_t *)(pic->data[2] + line * pic->linesize[2]);\n\n                break;\n\n            }\n\n\n\n            t = AV_RL32(src);\n\n            src += 4;\n\n            *y++ = t <<  6 & 0xFFC0;\n\n            *u++ = t >>  4 & 0xFFC0;\n\n            *y++ = t >> 14 & 0xFFC0;\n\n            if (src >= line_end - 2) {\n\n                if (!(width & 1)) {\n\n                    *y = 0x80;\n\n                    src += 2;\n\n                }\n\n                line_end += stride;\n\n                y = (uint16_t *)(pic->data[0] + line * pic->linesize[0]);\n\n                u = (uint16_t *)(pic->data[1] + line * pic->linesize[1]);\n\n                v = (uint16_t *)(pic->data[2] + line * pic->linesize[2]);\n\n                break;\n\n            }\n\n\n\n            t = AV_RL32(src);\n\n            src += 4;\n\n            *v++ = t <<  6 & 0xFFC0;\n\n            *y++ = t >>  4 & 0xFFC0;\n\n            *u++ = t >> 14 & 0xFFC0;\n\n\n\n            if (src >= line_end - 1) {\n\n                *y = 0x80;\n\n                src++;\n\n                line_end += stride;\n\n                y = (uint16_t *)(pic->data[0] + line * pic->linesize[0]);\n\n                u = (uint16_t *)(pic->data[1] + line * pic->linesize[1]);\n\n                v = (uint16_t *)(pic->data[2] + line * pic->linesize[2]);\n\n                break;\n\n            }\n\n\n\n            t = AV_RL32(src);\n\n            src += 4;\n\n            *y++ = t <<  6 & 0xFFC0;\n\n            *v++ = t >>  4 & 0xFFC0;\n\n            *y++ = t >> 14 & 0xFFC0;\n\n\n\n            if (src >= line_end - 2) {\n\n                if (width & 1) {\n\n                    *y = 0x80;\n\n                    src += 2;\n\n                }\n\n                line_end += stride;\n\n                y = (uint16_t *)(pic->data[0] + line * pic->linesize[0]);\n\n                u = (uint16_t *)(pic->data[1] + line * pic->linesize[1]);\n\n                v = (uint16_t *)(pic->data[2] + line * pic->linesize[2]);\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    *got_frame = 1;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 11885, "_split": "test", "_hash": "dc7d218aff5cd3cfe5fd9456f5bf4f25"}
{"project": "FFmpeg", "commit_id": "5c720657c23afd798ae0db7c7362eb859a89ab3d", "target": 1, "func": "static int mov_read_ftyp(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    uint32_t minor_ver;\n\n    int comp_brand_size;\n\n    char minor_ver_str[11]; /* 32 bit integer -> 10 digits + null */\n\n    char* comp_brands_str;\n\n    uint8_t type[5] = {0};\n\n\n\n    avio_read(pb, type, 4);\n\n    if (strcmp(type, \"qt  \"))\n\n        c->isom = 1;\n\n    av_log(c->fc, AV_LOG_DEBUG, \"ISO: File Type Major Brand: %.4s\\n\",(char *)&type);\n\n    av_dict_set(&c->fc->metadata, \"major_brand\", type, 0);\n\n    minor_ver = avio_rb32(pb); /* minor version */\n\n    snprintf(minor_ver_str, sizeof(minor_ver_str), \"%\"PRIu32\"\", minor_ver);\n\n    av_dict_set(&c->fc->metadata, \"minor_version\", minor_ver_str, 0);\n\n\n\n    comp_brand_size = atom.size - 8;\n\n    if (comp_brand_size < 0)\n\n        return AVERROR_INVALIDDATA;\n\n    comp_brands_str = av_malloc(comp_brand_size + 1); /* Add null terminator */\n\n    if (!comp_brands_str)\n\n        return AVERROR(ENOMEM);\n\n    avio_read(pb, comp_brands_str, comp_brand_size);\n\n    comp_brands_str[comp_brand_size] = 0;\n\n    av_dict_set(&c->fc->metadata, \"compatible_brands\", comp_brands_str, 0);\n\n    av_freep(&comp_brands_str);\n\n\n\n    return 0;\n\n}\n", "idx": 11979, "_split": "test", "_hash": "ac570f620022ac027e9de7584a4ebfb9"}
{"project": "FFmpeg", "commit_id": "073811cdd29e365498b3455ee4e0eda4b957a957", "target": 0, "func": "static int decode_stream_header(NUTContext *nut){\n\n    AVFormatContext *s= nut->avf;\n\n    ByteIOContext *bc = &s->pb;\n\n    StreamContext *stc;\n\n    int class, stream_id;\n\n    uint64_t tmp, end;\n\n    AVStream *st;\n\n\n\n    end= get_packetheader(nut, bc, 1);\n\n    end += url_ftell(bc);\n\n\n\n    GET_V(stream_id, tmp < s->nb_streams && !nut->stream[tmp].time_base);\n\n    stc= &nut->stream[stream_id];\n\n\n\n    st = s->streams[stream_id];\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    class = get_v(bc);\n\n    tmp = get_fourcc(bc);\n\n    st->codec->codec_tag= tmp;\n\n    switch(class)\n\n    {\n\n        case 0:\n\n            st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n            st->codec->codec_id = codec_get_id(codec_bmp_tags, tmp);\n\n            if (st->codec->codec_id == CODEC_ID_NONE)\n\n                av_log(s, AV_LOG_ERROR, \"Unknown codec?!\\n\");\n\n            break;\n\n        case 1:\n\n            st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n            st->codec->codec_id = codec_get_id(codec_wav_tags, tmp);\n\n            if (st->codec->codec_id == CODEC_ID_NONE)\n\n                av_log(s, AV_LOG_ERROR, \"Unknown codec?!\\n\");\n\n            break;\n\n        case 2:\n\n//            st->codec->codec_type = CODEC_TYPE_TEXT;\n\n//            break;\n\n        case 3:\n\n            st->codec->codec_type = CODEC_TYPE_DATA;\n\n            break;\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"Unknown stream class (%d)\\n\", class);\n\n            return -1;\n\n    }\n\n    GET_V(stc->time_base_id    , tmp < nut->time_base_count);\n\n    GET_V(stc->msb_pts_shift   , tmp < 16);\n\n    stc->max_pts_distance= get_v(bc);\n\n    GET_V(stc->decode_delay    , tmp < 1000); //sanity limit, raise this if moors law is true\n\n    st->codec->has_b_frames= stc->decode_delay;\n\n    get_v(bc); //stream flags\n\n\n\n    GET_V(st->codec->extradata_size, tmp < (1<<30));\n\n    if(st->codec->extradata_size){\n\n        st->codec->extradata= av_mallocz(st->codec->extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        get_buffer(bc, st->codec->extradata, st->codec->extradata_size);\n\n    }\n\n\n\n    if (st->codec->codec_type == CODEC_TYPE_VIDEO){\n\n        GET_V(st->codec->width , tmp > 0)\n\n        GET_V(st->codec->height, tmp > 0)\n\n        st->codec->sample_aspect_ratio.num= get_v(bc);\n\n        st->codec->sample_aspect_ratio.den= get_v(bc);\n\n        if((!st->codec->sample_aspect_ratio.num) != (!st->codec->sample_aspect_ratio.den)){\n\n            av_log(s, AV_LOG_ERROR, \"invalid aspect ratio\\n\");\n\n            return -1;\n\n        }\n\n        get_v(bc); /* csp type */\n\n    }else if (st->codec->codec_type == CODEC_TYPE_AUDIO){\n\n        GET_V(st->codec->sample_rate , tmp > 0)\n\n        tmp= get_v(bc); // samplerate_den\n\n        if(tmp > st->codec->sample_rate){\n\n            av_log(s, AV_LOG_ERROR, \"bleh, libnut muxed this ;)\\n\");\n\n            st->codec->sample_rate= tmp;\n\n        }\n\n        GET_V(st->codec->channels, tmp > 0)\n\n    }\n\n    if(skip_reserved(bc, end) || get_checksum(bc)){\n\n        av_log(s, AV_LOG_ERROR, \"Stream header %d checksum mismatch\\n\", stream_id);\n\n        return -1;\n\n    }\n\n    stc->time_base= &nut->time_base[stc->time_base_id];\n\n    av_set_pts_info(s->streams[stream_id], 63, stc->time_base->num, stc->time_base->den);\n\n    return 0;\n\n}\n", "idx": 11983, "_split": "test", "_hash": "2b145796e88ca1b45e25b74af77f5287"}
{"project": "FFmpeg", "commit_id": "5127f465bd3e2cf9cbf66dea3cf7b481b522d266", "target": 1, "func": "static void lz_unpack(const unsigned char *src, unsigned char *dest, int dest_len)\n\n{\n\n    const unsigned char *s;\n\n    unsigned char *d;\n\n    unsigned char *d_end;\n\n    unsigned char queue[QUEUE_SIZE];\n\n    unsigned int qpos;\n\n    unsigned int dataleft;\n\n    unsigned int chainofs;\n\n    unsigned int chainlen;\n\n    unsigned int speclen;\n\n    unsigned char tag;\n\n    unsigned int i, j;\n\n\n\n    s = src;\n\n    d = dest;\n\n    d_end = d + dest_len;\n\n    dataleft = AV_RL32(s);\n\n    s += 4;\n\n    memset(queue, 0x20, QUEUE_SIZE);\n\n    if (AV_RL32(s) == 0x56781234) {\n\n        s += 4;\n\n        qpos = 0x111;\n\n        speclen = 0xF + 3;\n\n    } else {\n\n        qpos = 0xFEE;\n\n        speclen = 100;  /* no speclen */\n\n    }\n\n\n\n    while (dataleft > 0) {\n\n        tag = *s++;\n\n        if ((tag == 0xFF) && (dataleft > 8)) {\n\n            if (d + 8 > d_end)\n\n                return;\n\n            for (i = 0; i < 8; i++) {\n\n                queue[qpos++] = *d++ = *s++;\n\n                qpos &= QUEUE_MASK;\n\n            }\n\n            dataleft -= 8;\n\n        } else {\n\n            for (i = 0; i < 8; i++) {\n\n                if (dataleft == 0)\n\n                    break;\n\n                if (tag & 0x01) {\n\n                    if (d + 1 > d_end)\n\n                        return;\n\n                    queue[qpos++] = *d++ = *s++;\n\n                    qpos &= QUEUE_MASK;\n\n                    dataleft--;\n\n                } else {\n\n                    chainofs = *s++;\n\n                    chainofs |= ((*s & 0xF0) << 4);\n\n                    chainlen = (*s++ & 0x0F) + 3;\n\n                    if (chainlen == speclen)\n\n                        chainlen = *s++ + 0xF + 3;\n\n                    if (d + chainlen > d_end)\n\n                        return;\n\n                    for (j = 0; j < chainlen; j++) {\n\n                        *d = queue[chainofs++ & QUEUE_MASK];\n\n                        queue[qpos++] = *d++;\n\n                        qpos &= QUEUE_MASK;\n\n                    }\n\n                    dataleft -= chainlen;\n\n                }\n\n                tag >>= 1;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 11985, "_split": "test", "_hash": "eb9498e1762b8b08075a270fac509ede"}
{"project": "FFmpeg", "commit_id": "6a99310fce49f51773ab7d8ffa4f4748bbf58db9", "target": 1, "func": "static int decode_channel_residues(WmallDecodeCtx *s, int ch, int tile_size)\n\n{\n\n    int i = 0;\n\n    unsigned int ave_mean;\n\n    s->transient[ch] = get_bits1(&s->gb);\n\n    if (s->transient[ch]) {\n\n        s->transient_pos[ch] = get_bits(&s->gb, av_log2(tile_size));\n\n        if (s->transient_pos[ch])\n\n            s->transient[ch] = 0;\n\n        s->channel[ch].transient_counter =\n\n            FFMAX(s->channel[ch].transient_counter, s->samples_per_frame / 2);\n\n    } else if (s->channel[ch].transient_counter)\n\n        s->transient[ch] = 1;\n\n\n\n    if (s->seekable_tile) {\n\n        ave_mean = get_bits(&s->gb, s->bits_per_sample);\n\n        s->ave_sum[ch] = ave_mean << (s->movave_scaling + 1);\n\n    }\n\n\n\n    if (s->seekable_tile) {\n\n        if (s->do_inter_ch_decorr)\n\n            s->channel_residues[ch][0] = get_sbits(&s->gb, s->bits_per_sample + 1);\n\n        else\n\n            s->channel_residues[ch][0] = get_sbits(&s->gb, s->bits_per_sample);\n\n        i++;\n\n    }\n\n    for (; i < tile_size; i++) {\n\n        int quo = 0, rem, rem_bits, residue;\n\n        while(get_bits1(&s->gb)) {\n\n            quo++;\n\n            if (get_bits_left(&s->gb) <= 0)\n\n                return -1;\n\n        }\n\n        if (quo >= 32)\n\n            quo += get_bits_long(&s->gb, get_bits(&s->gb, 5) + 1);\n\n\n\n        ave_mean = (s->ave_sum[ch] + (1 << s->movave_scaling)) >> (s->movave_scaling + 1);\n\n        if (ave_mean <= 1)\n\n            residue = quo;\n\n        else {\n\n            rem_bits = av_ceil_log2(ave_mean);\n\n            rem      = rem_bits ? get_bits(&s->gb, rem_bits) : 0;\n\n            residue  = (quo << rem_bits) + rem;\n\n        }\n\n\n\n        s->ave_sum[ch] = residue + s->ave_sum[ch] -\n\n                         (s->ave_sum[ch] >> s->movave_scaling);\n\n\n\n        if (residue & 1)\n\n            residue = -(residue >> 1) - 1;\n\n        else\n\n            residue = residue >> 1;\n\n        s->channel_residues[ch][i] = residue;\n\n    }\n\n\n\n    return 0;\n\n\n\n}\n", "idx": 12095, "_split": "test", "_hash": "2b187efe78fd5e4ccde1f279435d8078"}
{"project": "FFmpeg", "commit_id": "405af431040a57c630716b3940d7240021e8b80c", "target": 0, "func": "static int cinaudio_decode_frame(AVCodecContext *avctx,\n\n                                 void *data, int *data_size,\n\n                                 AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    CinAudioContext *cin = avctx->priv_data;\n\n    const uint8_t *src = buf;\n\n    int16_t *samples = data;\n\n    int delta;\n\n\n\n    buf_size = FFMIN(buf_size, *data_size/2);\n\n\n\n    delta = cin->delta;\n\n    if (cin->initial_decode_frame) {\n\n        cin->initial_decode_frame = 0;\n\n        delta = (int16_t)AV_RL16(src); src += 2;\n\n        *samples++ = delta;\n\n        buf_size -= 2;\n\n    }\n\n    while (buf_size > 0) {\n\n        delta += cinaudio_delta16_table[*src++];\n\n        delta = av_clip_int16(delta);\n\n        *samples++ = delta;\n\n        --buf_size;\n\n    }\n\n    cin->delta = delta;\n\n\n\n    *data_size = (uint8_t *)samples - (uint8_t *)data;\n\n\n\n    return src - buf;\n\n}\n", "idx": 12099, "_split": "test", "_hash": "47e8c49f7c9fac7796e984dcf74b864f"}
{"project": "FFmpeg", "commit_id": "7104c23bd1a1dcb8a7d9e2c8838c7ce55c30a331", "target": 0, "func": "static void rv34_pred_mv_rv3(RV34DecContext *r, int block_type, int dir)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride;\n\n    int A[2] = {0}, B[2], C[2];\n\n    int i, j, k;\n\n    int mx, my;\n\n    int avail_index = avail_indexes[0];\n\n\n\n    if(r->avail_cache[avail_index - 1]){\n\n        A[0] = s->current_picture_ptr->f.motion_val[0][mv_pos - 1][0];\n\n        A[1] = s->current_picture_ptr->f.motion_val[0][mv_pos - 1][1];\n\n    }\n\n    if(r->avail_cache[avail_index - 4]){\n\n        B[0] = s->current_picture_ptr->f.motion_val[0][mv_pos - s->b8_stride][0];\n\n        B[1] = s->current_picture_ptr->f.motion_val[0][mv_pos - s->b8_stride][1];\n\n    }else{\n\n        B[0] = A[0];\n\n        B[1] = A[1];\n\n    }\n\n    if(!r->avail_cache[avail_index - 4 + 2]){\n\n        if(r->avail_cache[avail_index - 4] && (r->avail_cache[avail_index - 1])){\n\n            C[0] = s->current_picture_ptr->f.motion_val[0][mv_pos - s->b8_stride - 1][0];\n\n            C[1] = s->current_picture_ptr->f.motion_val[0][mv_pos - s->b8_stride - 1][1];\n\n        }else{\n\n            C[0] = A[0];\n\n            C[1] = A[1];\n\n        }\n\n    }else{\n\n        C[0] = s->current_picture_ptr->f.motion_val[0][mv_pos - s->b8_stride + 2][0];\n\n        C[1] = s->current_picture_ptr->f.motion_val[0][mv_pos - s->b8_stride + 2][1];\n\n    }\n\n    mx = mid_pred(A[0], B[0], C[0]);\n\n    my = mid_pred(A[1], B[1], C[1]);\n\n    mx += r->dmv[0][0];\n\n    my += r->dmv[0][1];\n\n    for(j = 0; j < 2; j++){\n\n        for(i = 0; i < 2; i++){\n\n            for(k = 0; k < 2; k++){\n\n                s->current_picture_ptr->f.motion_val[k][mv_pos + i + j*s->b8_stride][0] = mx;\n\n                s->current_picture_ptr->f.motion_val[k][mv_pos + i + j*s->b8_stride][1] = my;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 12106, "_split": "test", "_hash": "94d27c268f78eb8b5f6128e65d9f907a"}
{"project": "FFmpeg", "commit_id": "1846a3eac854799fbffc9669dcf4de558b917957", "target": 0, "func": "static int vaapi_build_decoder_config(VAAPIDecoderContext *ctx,\n\n                                      AVCodecContext *avctx,\n\n                                      int fallback_allowed)\n\n{\n\n    AVVAAPIDeviceContext *hwctx = ctx->device->hwctx;\n\n    AVVAAPIHWConfig *hwconfig = NULL;\n\n    AVHWFramesConstraints *constraints = NULL;\n\n    VAStatus vas;\n\n    int err, i, j;\n\n    int loglevel = fallback_allowed ? AV_LOG_VERBOSE : AV_LOG_ERROR;\n\n    const AVCodecDescriptor *codec_desc;\n\n    const AVPixFmtDescriptor *pix_desc;\n\n    enum AVPixelFormat pix_fmt;\n\n    VAProfile profile, *profile_list = NULL;\n\n    int profile_count, exact_match, alt_profile;\n\n\n\n    codec_desc = avcodec_descriptor_get(avctx->codec_id);\n\n    if (!codec_desc) {\n\n        err = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    profile_count = vaMaxNumProfiles(hwctx->display);\n\n    profile_list = av_malloc(profile_count * sizeof(VAProfile));\n\n    if (!profile_list) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    vas = vaQueryConfigProfiles(hwctx->display,\n\n                                profile_list, &profile_count);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(ctx, loglevel, \"Failed to query profiles: %d (%s).\\n\",\n\n               vas, vaErrorStr(vas));\n\n        err = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n\n\n    profile = VAProfileNone;\n\n    exact_match = 0;\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(vaapi_profile_map); i++) {\n\n        int profile_match = 0;\n\n        if (avctx->codec_id != vaapi_profile_map[i].codec_id)\n\n            continue;\n\n        if (avctx->profile == vaapi_profile_map[i].codec_profile)\n\n            profile_match = 1;\n\n        profile = vaapi_profile_map[i].va_profile;\n\n        for (j = 0; j < profile_count; j++) {\n\n            if (profile == profile_list[j]) {\n\n                exact_match = profile_match;\n\n                break;\n\n            }\n\n        }\n\n        if (j < profile_count) {\n\n            if (exact_match)\n\n                break;\n\n            alt_profile = vaapi_profile_map[i].codec_profile;\n\n        }\n\n    }\n\n    av_freep(&profile_list);\n\n\n\n    if (profile == VAProfileNone) {\n\n        av_log(ctx, loglevel, \"No VAAPI support for codec %s.\\n\",\n\n               codec_desc->name);\n\n        err = AVERROR(ENOSYS);\n\n        goto fail;\n\n    }\n\n    if (!exact_match) {\n\n        if (fallback_allowed || !hwaccel_lax_profile_check) {\n\n            av_log(ctx, loglevel, \"No VAAPI support for codec %s \"\n\n                   \"profile %d.\\n\", codec_desc->name, avctx->profile);\n\n            if (!fallback_allowed) {\n\n                av_log(ctx, AV_LOG_WARNING, \"If you want attempt decoding \"\n\n                       \"anyway with a possibly-incompatible profile, add \"\n\n                       \"the option -hwaccel_lax_profile_check.\\n\");\n\n            }\n\n            err = AVERROR(EINVAL);\n\n            goto fail;\n\n        } else {\n\n            av_log(ctx, AV_LOG_WARNING, \"No VAAPI support for codec %s \"\n\n                   \"profile %d: trying instead with profile %d.\\n\",\n\n                   codec_desc->name, avctx->profile, alt_profile);\n\n            av_log(ctx, AV_LOG_WARNING, \"This may fail or give \"\n\n                   \"incorrect results, depending on your hardware.\\n\");\n\n        }\n\n    }\n\n\n\n    ctx->va_profile = profile;\n\n    ctx->va_entrypoint = VAEntrypointVLD;\n\n\n\n    vas = vaCreateConfig(hwctx->display, ctx->va_profile,\n\n                         ctx->va_entrypoint, 0, 0, &ctx->va_config);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Failed to create decode pipeline \"\n\n               \"configuration: %d (%s).\\n\", vas, vaErrorStr(vas));\n\n        err = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n\n\n    hwconfig = av_hwdevice_hwconfig_alloc(ctx->device_ref);\n\n    if (!hwconfig) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    hwconfig->config_id = ctx->va_config;\n\n\n\n    constraints = av_hwdevice_get_hwframe_constraints(ctx->device_ref,\n\n                                                      hwconfig);\n\n    if (!constraints)\n\n        goto fail;\n\n\n\n    // Decide on the decoder target format.\n\n    // If the user specified something with -hwaccel_output_format then\n\n    // try to use that to minimise conversions later.\n\n    ctx->decode_format = AV_PIX_FMT_NONE;\n\n    if (ctx->output_format != AV_PIX_FMT_NONE &&\n\n        ctx->output_format != AV_PIX_FMT_VAAPI) {\n\n        for (i = 0; constraints->valid_sw_formats[i] != AV_PIX_FMT_NONE; i++) {\n\n            if (constraints->valid_sw_formats[i] == ctx->decode_format) {\n\n                ctx->decode_format = ctx->output_format;\n\n                av_log(ctx, AV_LOG_DEBUG, \"Using decode format %s (output \"\n\n                       \"format).\\n\", av_get_pix_fmt_name(ctx->decode_format));\n\n                break;\n\n            }\n\n        }\n\n    }\n\n    // Otherwise, we would like to try to choose something which matches the\n\n    // decoder output, but there isn't enough information available here to\n\n    // do so.  Assume for now that we are always dealing with YUV 4:2:0, so\n\n    // pick a format which does that.\n\n    if (ctx->decode_format == AV_PIX_FMT_NONE) {\n\n        for (i = 0; constraints->valid_sw_formats[i] != AV_PIX_FMT_NONE; i++) {\n\n            pix_fmt  = constraints->valid_sw_formats[i];\n\n            pix_desc = av_pix_fmt_desc_get(pix_fmt);\n\n            if (pix_desc->nb_components == 3 &&\n\n                pix_desc->log2_chroma_w == 1 &&\n\n                pix_desc->log2_chroma_h == 1) {\n\n                ctx->decode_format = pix_fmt;\n\n                av_log(ctx, AV_LOG_DEBUG, \"Using decode format %s (format \"\n\n                       \"matched).\\n\", av_get_pix_fmt_name(ctx->decode_format));\n\n                break;\n\n            }\n\n        }\n\n    }\n\n    // Otherwise pick the first in the list and hope for the best.\n\n    if (ctx->decode_format == AV_PIX_FMT_NONE) {\n\n        ctx->decode_format = constraints->valid_sw_formats[0];\n\n        av_log(ctx, AV_LOG_DEBUG, \"Using decode format %s (first in list).\\n\",\n\n               av_get_pix_fmt_name(ctx->decode_format));\n\n        if (i > 1) {\n\n            // There was a choice, and we picked randomly.  Warn the user\n\n            // that they might want to choose intelligently instead.\n\n            av_log(ctx, AV_LOG_WARNING, \"Using randomly chosen decode \"\n\n                   \"format %s.\\n\", av_get_pix_fmt_name(ctx->decode_format));\n\n        }\n\n    }\n\n\n\n    // Ensure the picture size is supported by the hardware.\n\n    ctx->decode_width  = avctx->coded_width;\n\n    ctx->decode_height = avctx->coded_height;\n\n    if (ctx->decode_width  < constraints->min_width  ||\n\n        ctx->decode_height < constraints->min_height ||\n\n        ctx->decode_width  > constraints->max_width  ||\n\n        ctx->decode_height >constraints->max_height) {\n\n        av_log(ctx, AV_LOG_ERROR, \"VAAPI hardware does not support image \"\n\n               \"size %dx%d (constraints: width %d-%d height %d-%d).\\n\",\n\n               ctx->decode_width, ctx->decode_height,\n\n               constraints->min_width,  constraints->max_width,\n\n               constraints->min_height, constraints->max_height);\n\n        err = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    av_hwframe_constraints_free(&constraints);\n\n    av_freep(&hwconfig);\n\n\n\n    // Decide how many reference frames we need.  This might be doable more\n\n    // nicely based on the codec and input stream?\n\n    ctx->decode_surfaces = DEFAULT_SURFACES;\n\n    // For frame-threaded decoding, one additional surfaces is needed for\n\n    // each thread.\n\n    if (avctx->active_thread_type & FF_THREAD_FRAME)\n\n        ctx->decode_surfaces += avctx->thread_count;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_hwframe_constraints_free(&constraints);\n\n    av_freep(&hwconfig);\n\n    vaDestroyConfig(hwctx->display, ctx->va_config);\n\n    av_freep(&profile_list);\n\n    return err;\n\n}\n", "idx": 12190, "_split": "test", "_hash": "46c324791b41ba9ae9745081b3466c4f"}
{"project": "FFmpeg", "commit_id": "0065d2d520caab2321b35a7bec5d62564913238b", "target": 0, "func": "static int parse(AVCodecParserContext *ctx,\n\n                 AVCodecContext *avctx,\n\n                 const uint8_t **out_data, int *out_size,\n\n                 const uint8_t *data, int size)\n\n{\n\n    VP9ParseContext *s = ctx->priv_data;\n\n    int marker;\n\n\n\n    if (size <= 0) {\n\n        *out_size = 0;\n\n        *out_data = data;\n\n\n\n        return 0;\n\n    }\n\n\n\n    if (s->n_frames > 0) {\n\n        *out_data = data;\n\n        *out_size = s->size[--s->n_frames];\n\n        parse_frame(ctx, *out_data, *out_size);\n\n\n\n        return s->n_frames > 0 ? *out_size : size /* i.e. include idx tail */;\n\n    }\n\n\n\n    marker = data[size - 1];\n\n    if ((marker & 0xe0) == 0xc0) {\n\n        int nbytes = 1 + ((marker >> 3) & 0x3);\n\n        int n_frames = 1 + (marker & 0x7), idx_sz = 2 + n_frames * nbytes;\n\n\n\n        if (size >= idx_sz && data[size - idx_sz] == marker) {\n\n            const uint8_t *idx = data + size + 1 - idx_sz;\n\n            int first = 1;\n\n\n\n            switch (nbytes) {\n\n#define case_n(a, rd) \\\n\n            case a: \\\n\n                while (n_frames--) { \\\n\n                    int sz = rd; \\\n\n                    idx += a; \\\n\n                    if (sz > size) { \\\n\n                        s->n_frames = 0; \\\n\n                        av_log(avctx, AV_LOG_ERROR, \\\n\n                               \"Superframe packet size too big: %d > %d\\n\", \\\n\n                               sz, size); \\\n\n                        return AVERROR_INVALIDDATA; \\\n\n                    } \\\n\n                    if (first) { \\\n\n                        first = 0; \\\n\n                        *out_data = data; \\\n\n                        *out_size = sz; \\\n\n                        s->n_frames = n_frames; \\\n\n                    } else { \\\n\n                        s->size[n_frames] = sz; \\\n\n                    } \\\n\n                    data += sz; \\\n\n                    size -= sz; \\\n\n                } \\\n\n                parse_frame(ctx, *out_data, *out_size); \\\n\n                return *out_size\n\n\n\n                case_n(1, *idx);\n\n                case_n(2, AV_RL16(idx));\n\n                case_n(3, AV_RL24(idx));\n\n                case_n(4, AV_RL32(idx));\n\n            }\n\n        }\n\n    }\n\n\n\n    *out_data = data;\n\n    *out_size = size;\n\n    parse_frame(ctx, data, size);\n\n\n\n    return size;\n\n}\n", "idx": 12192, "_split": "test", "_hash": "04c7807d7e185bd51e4bd271a7f0054a"}
{"project": "FFmpeg", "commit_id": "5d7e3d71673d64a16b58430a0027afadb6b3a54e", "target": 1, "func": "static const unsigned char *seq_unpack_rle_block(const unsigned char *src, unsigned char *dst, int dst_size)\n\n{\n\n    int i, len, sz;\n\n    GetBitContext gb;\n\n    int code_table[64];\n\n\n\n    /* get the rle codes (at most 64 bytes) */\n\n    init_get_bits(&gb, src, 64 * 8);\n\n    for (i = 0, sz = 0; i < 64 && sz < dst_size; i++) {\n\n        code_table[i] = get_sbits(&gb, 4);\n\n        sz += FFABS(code_table[i]);\n\n    }\n\n    src += (get_bits_count(&gb) + 7) / 8;\n\n\n\n    /* do the rle unpacking */\n\n    for (i = 0; i < 64 && dst_size > 0; i++) {\n\n        len = code_table[i];\n\n        if (len < 0) {\n\n            len = -len;\n\n            memset(dst, *src++, FFMIN(len, dst_size));\n\n        } else {\n\n            memcpy(dst, src, FFMIN(len, dst_size));\n\n            src += len;\n\n        }\n\n        dst += len;\n\n        dst_size -= len;\n\n    }\n\n    return src;\n\n}\n", "idx": 12216, "_split": "test", "_hash": "11dc93effa278b165fd5cd29a71be1b7"}
{"project": "FFmpeg", "commit_id": "fa74cdc60d19798c951dcc242ca7273e6483f2b3", "target": 1, "func": "int av_parser_parse2(AVCodecParserContext *s, AVCodecContext *avctx,\n                     uint8_t **poutbuf, int *poutbuf_size,\n                     const uint8_t *buf, int buf_size,\n                     int64_t pts, int64_t dts, int64_t pos)\n{\n    int index, i;\n    uint8_t dummy_buf[AV_INPUT_BUFFER_PADDING_SIZE];\n    if (!(s->flags & PARSER_FLAG_FETCHED_OFFSET)) {\n        s->next_frame_offset =\n        s->cur_offset        = pos;\n        s->flags            |= PARSER_FLAG_FETCHED_OFFSET;\n    }\n    if (buf_size == 0) {\n        /* padding is always necessary even if EOF, so we add it here */\n        memset(dummy_buf, 0, sizeof(dummy_buf));\n        buf = dummy_buf;\n    } else if (s->cur_offset + buf_size != s->cur_frame_end[s->cur_frame_start_index]) { /* skip remainder packets */\n        /* add a new packet descriptor */\n        i = (s->cur_frame_start_index + 1) & (AV_PARSER_PTS_NB - 1);\n        s->cur_frame_start_index = i;\n        s->cur_frame_offset[i]   = s->cur_offset;\n        s->cur_frame_end[i]      = s->cur_offset + buf_size;\n        s->cur_frame_pts[i]      = pts;\n        s->cur_frame_dts[i]      = dts;\n        s->cur_frame_pos[i]      = pos;\n    }\n    if (s->fetch_timestamp) {\n        s->fetch_timestamp = 0;\n        s->last_pts        = s->pts;\n        s->last_dts        = s->dts;\n        s->last_pos        = s->pos;\n        ff_fetch_timestamp(s, 0, 0, 0);\n    }\n    /* WARNING: the returned index can be negative */\n    index = s->parser->parser_parse(s, avctx, (const uint8_t **) poutbuf,\n                                    poutbuf_size, buf, buf_size);\n    av_assert0(index > -0x20000000); // The API does not allow returning AVERROR codes\n    /* update the file pointer */\n    if (*poutbuf_size) {\n        /* fill the data for the current frame */\n        s->frame_offset = s->next_frame_offset;\n        /* offset of the next frame */\n        s->next_frame_offset = s->cur_offset + index;\n        s->fetch_timestamp   = 1;\n    }\n    if (index < 0)\n        index = 0;\n    s->cur_offset += index;\n    return index;\n}", "idx": 12255, "_split": "test", "_hash": "1bfe3bcdff700593c7c7c2519569eb5e"}
{"project": "FFmpeg", "commit_id": "83c285f88016b087c2f0f4b9ef356ad8ef12d947", "target": 1, "func": "static AVIOContext * wtvfile_open2(AVFormatContext *s, const uint8_t *buf, int buf_size, const uint8_t *filename, int filename_size)\n\n{\n\n    const uint8_t *buf_end = buf + buf_size;\n\n\n\n    while(buf + 48 <= buf_end) {\n\n        int dir_length, name_size, first_sector, depth;\n\n        uint64_t file_length;\n\n        const uint8_t *name;\n\n        if (ff_guidcmp(buf, dir_entry_guid)) {\n\n            av_log(s, AV_LOG_ERROR, \"unknown guid \"FF_PRI_GUID\", expected dir_entry_guid; \"\n\n                   \"remaining directory entries ignored\\n\", FF_ARG_GUID(buf));\n\n            break;\n\n        }\n\n        dir_length  = AV_RL16(buf + 16);\n\n        file_length = AV_RL64(buf + 24);\n\n        name_size   = 2 * AV_RL32(buf + 32);\n\n        if (buf + 48 + name_size > buf_end) {\n\n            av_log(s, AV_LOG_ERROR, \"filename exceeds buffer size; remaining directory entries ignored\\n\");\n\n            break;\n\n        }\n\n        first_sector = AV_RL32(buf + 40 + name_size);\n\n        depth        = AV_RL32(buf + 44 + name_size);\n\n\n\n        /* compare file name; test optional null terminator */\n\n        name = buf + 40;\n\n        if (name_size >= filename_size &&\n\n            !memcmp(name, filename, filename_size) &&\n\n            (name_size < filename_size + 2 || !AV_RN16(name + filename_size)))\n\n            return wtvfile_open_sector(first_sector, file_length, depth, s);\n\n\n\n        buf += dir_length;\n\n    }\n\n    return 0;\n\n}\n", "idx": 12273, "_split": "test", "_hash": "6ffbc5b0e00f0c8b72f74863fb2444b0"}
{"project": "FFmpeg", "commit_id": "527f89e05922e840083ac6d49eeb838b1e350dd4", "target": 1, "func": "static void stereo_processing(PSContext *ps, INTFLOAT (*l)[32][2], INTFLOAT (*r)[32][2], int is34)\n\n{\n\n    int e, b, k;\n\n\n\n    INTFLOAT (*H11)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H11;\n\n    INTFLOAT (*H12)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H12;\n\n    INTFLOAT (*H21)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H21;\n\n    INTFLOAT (*H22)[PS_MAX_NUM_ENV+1][PS_MAX_NR_IIDICC] = ps->H22;\n\n    int8_t *opd_hist = ps->opd_hist;\n\n    int8_t *ipd_hist = ps->ipd_hist;\n\n    int8_t iid_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t icc_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t ipd_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t opd_mapped_buf[PS_MAX_NUM_ENV][PS_MAX_NR_IIDICC];\n\n    int8_t (*iid_mapped)[PS_MAX_NR_IIDICC] = iid_mapped_buf;\n\n    int8_t (*icc_mapped)[PS_MAX_NR_IIDICC] = icc_mapped_buf;\n\n    int8_t (*ipd_mapped)[PS_MAX_NR_IIDICC] = ipd_mapped_buf;\n\n    int8_t (*opd_mapped)[PS_MAX_NR_IIDICC] = opd_mapped_buf;\n\n    const int8_t *k_to_i = is34 ? k_to_i_34 : k_to_i_20;\n\n    TABLE_CONST INTFLOAT (*H_LUT)[8][4] = (PS_BASELINE || ps->icc_mode < 3) ? HA : HB;\n\n\n\n    //Remapping\n\n    if (ps->num_env_old) {\n\n        memcpy(H11[0][0], H11[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H11[0][0][0]));\n\n        memcpy(H11[1][0], H11[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H11[1][0][0]));\n\n        memcpy(H12[0][0], H12[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H12[0][0][0]));\n\n        memcpy(H12[1][0], H12[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H12[1][0][0]));\n\n        memcpy(H21[0][0], H21[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H21[0][0][0]));\n\n        memcpy(H21[1][0], H21[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H21[1][0][0]));\n\n        memcpy(H22[0][0], H22[0][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H22[0][0][0]));\n\n        memcpy(H22[1][0], H22[1][ps->num_env_old], PS_MAX_NR_IIDICC*sizeof(H22[1][0][0]));\n\n    }\n\n\n\n    if (is34) {\n\n        remap34(&iid_mapped, ps->iid_par, ps->nr_iid_par, ps->num_env, 1);\n\n        remap34(&icc_mapped, ps->icc_par, ps->nr_icc_par, ps->num_env, 1);\n\n        if (ps->enable_ipdopd) {\n\n            remap34(&ipd_mapped, ps->ipd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n            remap34(&opd_mapped, ps->opd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n        }\n\n        if (!ps->is34bands_old) {\n\n            map_val_20_to_34(H11[0][0]);\n\n            map_val_20_to_34(H11[1][0]);\n\n            map_val_20_to_34(H12[0][0]);\n\n            map_val_20_to_34(H12[1][0]);\n\n            map_val_20_to_34(H21[0][0]);\n\n            map_val_20_to_34(H21[1][0]);\n\n            map_val_20_to_34(H22[0][0]);\n\n            map_val_20_to_34(H22[1][0]);\n\n            ipdopd_reset(ipd_hist, opd_hist);\n\n        }\n\n    } else {\n\n        remap20(&iid_mapped, ps->iid_par, ps->nr_iid_par, ps->num_env, 1);\n\n        remap20(&icc_mapped, ps->icc_par, ps->nr_icc_par, ps->num_env, 1);\n\n        if (ps->enable_ipdopd) {\n\n            remap20(&ipd_mapped, ps->ipd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n            remap20(&opd_mapped, ps->opd_par, ps->nr_ipdopd_par, ps->num_env, 0);\n\n        }\n\n        if (ps->is34bands_old) {\n\n            map_val_34_to_20(H11[0][0]);\n\n            map_val_34_to_20(H11[1][0]);\n\n            map_val_34_to_20(H12[0][0]);\n\n            map_val_34_to_20(H12[1][0]);\n\n            map_val_34_to_20(H21[0][0]);\n\n            map_val_34_to_20(H21[1][0]);\n\n            map_val_34_to_20(H22[0][0]);\n\n            map_val_34_to_20(H22[1][0]);\n\n            ipdopd_reset(ipd_hist, opd_hist);\n\n        }\n\n    }\n\n\n\n    //Mixing\n\n    for (e = 0; e < ps->num_env; e++) {\n\n        for (b = 0; b < NR_PAR_BANDS[is34]; b++) {\n\n            INTFLOAT h11, h12, h21, h22;\n\n            h11 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][0];\n\n            h12 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][1];\n\n            h21 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][2];\n\n            h22 = H_LUT[iid_mapped[e][b] + 7 + 23 * ps->iid_quant][icc_mapped[e][b]][3];\n\n\n\n            if (!PS_BASELINE && ps->enable_ipdopd && b < NR_IPDOPD_BANDS[is34]) {\n\n                //The spec say says to only run this smoother when enable_ipdopd\n\n                //is set but the reference decoder appears to run it constantly\n\n                INTFLOAT h11i, h12i, h21i, h22i;\n\n                INTFLOAT ipd_adj_re, ipd_adj_im;\n\n                int opd_idx = opd_hist[b] * 8 + opd_mapped[e][b];\n\n                int ipd_idx = ipd_hist[b] * 8 + ipd_mapped[e][b];\n\n                INTFLOAT opd_re = pd_re_smooth[opd_idx];\n\n                INTFLOAT opd_im = pd_im_smooth[opd_idx];\n\n                INTFLOAT ipd_re = pd_re_smooth[ipd_idx];\n\n                INTFLOAT ipd_im = pd_im_smooth[ipd_idx];\n\n                opd_hist[b] = opd_idx & 0x3F;\n\n                ipd_hist[b] = ipd_idx & 0x3F;\n\n\n\n                ipd_adj_re = AAC_MADD30(opd_re, ipd_re, opd_im, ipd_im);\n\n                ipd_adj_im = AAC_MSUB30(opd_im, ipd_re, opd_re, ipd_im);\n\n                h11i = AAC_MUL30(h11,  opd_im);\n\n                h11  = AAC_MUL30(h11,  opd_re);\n\n                h12i = AAC_MUL30(h12,  ipd_adj_im);\n\n                h12  = AAC_MUL30(h12,  ipd_adj_re);\n\n                h21i = AAC_MUL30(h21,  opd_im);\n\n                h21  = AAC_MUL30(h21,  opd_re);\n\n                h22i = AAC_MUL30(h22,  ipd_adj_im);\n\n                h22  = AAC_MUL30(h22,  ipd_adj_re);\n\n                H11[1][e+1][b] = h11i;\n\n                H12[1][e+1][b] = h12i;\n\n                H21[1][e+1][b] = h21i;\n\n                H22[1][e+1][b] = h22i;\n\n            }\n\n            H11[0][e+1][b] = h11;\n\n            H12[0][e+1][b] = h12;\n\n            H21[0][e+1][b] = h21;\n\n            H22[0][e+1][b] = h22;\n\n        }\n\n        for (k = 0; k < NR_BANDS[is34]; k++) {\n\n            LOCAL_ALIGNED_16(INTFLOAT, h, [2], [4]);\n\n            LOCAL_ALIGNED_16(INTFLOAT, h_step, [2], [4]);\n\n            int start = ps->border_position[e];\n\n            int stop  = ps->border_position[e+1];\n\n            INTFLOAT width = Q30(1.f) / ((stop - start) ? (stop - start) : 1);\n\n#if USE_FIXED\n\n            width <<= 1;\n\n#endif\n\n            b = k_to_i[k];\n\n            h[0][0] = H11[0][e][b];\n\n            h[0][1] = H12[0][e][b];\n\n            h[0][2] = H21[0][e][b];\n\n            h[0][3] = H22[0][e][b];\n\n            if (!PS_BASELINE && ps->enable_ipdopd) {\n\n            //Is this necessary? ps_04_new seems unchanged\n\n            if ((is34 && k <= 13 && k >= 9) || (!is34 && k <= 1)) {\n\n                h[1][0] = -H11[1][e][b];\n\n                h[1][1] = -H12[1][e][b];\n\n                h[1][2] = -H21[1][e][b];\n\n                h[1][3] = -H22[1][e][b];\n\n            } else {\n\n                h[1][0] = H11[1][e][b];\n\n                h[1][1] = H12[1][e][b];\n\n                h[1][2] = H21[1][e][b];\n\n                h[1][3] = H22[1][e][b];\n\n            }\n\n            }\n\n            //Interpolation\n\n            h_step[0][0] = AAC_MSUB31_V3(H11[0][e+1][b], h[0][0], width);\n\n            h_step[0][1] = AAC_MSUB31_V3(H12[0][e+1][b], h[0][1], width);\n\n            h_step[0][2] = AAC_MSUB31_V3(H21[0][e+1][b], h[0][2], width);\n\n            h_step[0][3] = AAC_MSUB31_V3(H22[0][e+1][b], h[0][3], width);\n\n            if (!PS_BASELINE && ps->enable_ipdopd) {\n\n                h_step[1][0] = AAC_MSUB31_V3(H11[1][e+1][b], h[1][0], width);\n\n                h_step[1][1] = AAC_MSUB31_V3(H12[1][e+1][b], h[1][1], width);\n\n                h_step[1][2] = AAC_MSUB31_V3(H21[1][e+1][b], h[1][2], width);\n\n                h_step[1][3] = AAC_MSUB31_V3(H22[1][e+1][b], h[1][3], width);\n\n            }\n\n            ps->dsp.stereo_interpolate[!PS_BASELINE && ps->enable_ipdopd](\n\n                l[k] + start + 1, r[k] + start + 1,\n\n                h, h_step, stop - start);\n\n        }\n\n    }\n\n}\n", "idx": 12278, "_split": "test", "_hash": "0c8b5c5249489712bed17e75c5a54cae"}
{"project": "FFmpeg", "commit_id": "32c3047cac9294bb56d23c89a40a22409db5cc70", "target": 0, "func": "static int idcin_decode_init(AVCodecContext *avctx)\n\n{\n\n    IdcinContext *s = avctx->priv_data;\n\n    int i, j, histogram_index = 0;\n\n    unsigned char *histograms;\n\n\n\n    s->avctx = avctx;\n\n    avctx->pix_fmt = PIX_FMT_PAL8;\n\n    dsputil_init(&s->dsp, avctx);\n\n\n\n    /* make sure the Huffman tables make it */\n\n    if (s->avctx->extradata_size != HUFFMAN_TABLE_SIZE) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  Id CIN video: expected extradata size of %d\\n\", HUFFMAN_TABLE_SIZE);\n\n        return -1;\n\n    }\n\n\n\n    /* build the 256 Huffman decode trees */\n\n    histograms = (unsigned char *)s->avctx->extradata;\n\n    for (i = 0; i < 256; i++) {\n\n        for(j = 0; j < HUF_TOKENS; j++)\n\n            s->huff_nodes[i][j].count = histograms[histogram_index++];\n\n        huff_build_tree(s, i);\n\n    }\n\n\n\n    s->frame.data[0] = NULL;\n\n\n\n    return 0;\n\n}\n", "idx": 12305, "_split": "test", "_hash": "500d65dc86d172541647af2906980e4f"}
{"project": "FFmpeg", "commit_id": "59c6178a54c414fd19e064f0077d00b82a1eb812", "target": 0, "func": "static int ogg_build_flac_headers(const uint8_t *extradata, int extradata_size,\n\n                                  OGGStreamContext *oggstream, int bitexact)\n\n{\n\n    const char *vendor = bitexact ? \"ffmpeg\" : LIBAVFORMAT_IDENT;\n\n    uint8_t *p;\n\n    if (extradata_size != 34)\n\n        return -1;\n\n    oggstream->header_len[0] = 51;\n\n    oggstream->header[0] = av_mallocz(51); // per ogg flac specs\n\n    p = oggstream->header[0];\n\n    bytestream_put_byte(&p, 0x7F);\n\n    bytestream_put_buffer(&p, \"FLAC\", 4);\n\n    bytestream_put_byte(&p, 1); // major version\n\n    bytestream_put_byte(&p, 0); // minor version\n\n    bytestream_put_be16(&p, 1); // headers packets without this one\n\n    bytestream_put_buffer(&p, \"fLaC\", 4);\n\n    bytestream_put_byte(&p, 0x00); // streaminfo\n\n    bytestream_put_be24(&p, 34);\n\n    bytestream_put_buffer(&p, extradata, 34);\n\n    oggstream->header_len[1] = 1+3+4+strlen(vendor)+4;\n\n    oggstream->header[1] = av_mallocz(oggstream->header_len[1]);\n\n    p = oggstream->header[1];\n\n    bytestream_put_byte(&p, 0x84); // last metadata block and vorbis comment\n\n    bytestream_put_be24(&p, oggstream->header_len[1] - 4);\n\n    bytestream_put_le32(&p, strlen(vendor));\n\n    bytestream_put_buffer(&p, vendor, strlen(vendor));\n\n    bytestream_put_le32(&p, 0); // user comment list length\n\n    return 0;\n\n}\n", "idx": 12353, "_split": "test", "_hash": "121b31fd5af71b995a75aeb344852a55"}
{"project": "FFmpeg", "commit_id": "a6191d098a03f94685ae4c072bfdf10afcd86223", "target": 0, "func": "static void put_subframe(DCAEncContext *c, int subframe)\n\n{\n\n    int i, band, ss, ch;\n\n\n\n    /* Subsubframes count */\n\n    put_bits(&c->pb, 2, SUBSUBFRAMES -1);\n\n\n\n    /* Partial subsubframe sample count: dummy */\n\n    put_bits(&c->pb, 3, 0);\n\n\n\n    /* Prediction mode: no ADPCM, in each channel and subband */\n\n    for (ch = 0; ch < c->fullband_channels; ch++)\n\n        for (band = 0; band < DCAENC_SUBBANDS; band++)\n\n            put_bits(&c->pb, 1, 0);\n\n\n\n    /* Prediction VQ address: not transmitted */\n\n    /* Bit allocation index */\n\n    for (ch = 0; ch < c->fullband_channels; ch++)\n\n        for (band = 0; band < DCAENC_SUBBANDS; band++)\n\n            put_bits(&c->pb, 5, c->abits[band][ch]);\n\n\n\n    if (SUBSUBFRAMES > 1) {\n\n        /* Transition mode: none for each channel and subband */\n\n        for (ch = 0; ch < c->fullband_channels; ch++)\n\n            for (band = 0; band < DCAENC_SUBBANDS; band++)\n\n                put_bits(&c->pb, 1, 0); /* codebook A4 */\n\n    }\n\n\n\n    /* Scale factors */\n\n    for (ch = 0; ch < c->fullband_channels; ch++)\n\n        for (band = 0; band < DCAENC_SUBBANDS; band++)\n\n            put_bits(&c->pb, 7, c->scale_factor[band][ch]);\n\n\n\n    /* Joint subband scale factor codebook select: not transmitted */\n\n    /* Scale factors for joint subband coding: not transmitted */\n\n    /* Stereo down-mix coefficients: not transmitted */\n\n    /* Dynamic range coefficient: not transmitted */\n\n    /* Stde information CRC check word: not transmitted */\n\n    /* VQ encoded high frequency subbands: not transmitted */\n\n\n\n    /* LFE data: 8 samples and scalefactor */\n\n    if (c->lfe_channel) {\n\n        for (i = 0; i < DCA_LFE_SAMPLES; i++)\n\n            put_bits(&c->pb, 8, quantize_value(c->downsampled_lfe[i], c->lfe_quant) & 0xff);\n\n        put_bits(&c->pb, 8, c->lfe_scale_factor);\n\n    }\n\n\n\n    /* Audio data (subsubframes) */\n\n    for (ss = 0; ss < SUBSUBFRAMES ; ss++)\n\n        for (ch = 0; ch < c->fullband_channels; ch++)\n\n            for (band = 0; band < DCAENC_SUBBANDS; band++)\n\n                    put_subframe_samples(c, ss, band, ch);\n\n\n\n    /* DSYNC */\n\n    put_bits(&c->pb, 16, 0xffff);\n\n}\n", "idx": 12357, "_split": "test", "_hash": "64e80b8ec4ac59adb1dee7ad349ae6e4"}
{"project": "FFmpeg", "commit_id": "11b47038135442ec546dc348f2411e52e47549b8", "target": 0, "func": "static void decode_gray_bitstream(HYuvContext *s, int count)\n\n{\n\n    int i;\n\n\n\n    count/=2;\n\n\n\n    if (count >= (get_bits_left(&s->gb)) / (31 * 2)) {\n\n        for (i = 0; i < count && get_bits_left(&s->gb) > 0; i++) {\n\n            READ_2PIX(s->temp[0][2 * i], s->temp[0][2 * i + 1], 0);\n\n        }\n\n    } else {\n\n        for(i=0; i<count; i++){\n\n            READ_2PIX(s->temp[0][2 * i], s->temp[0][2 * i + 1], 0);\n\n        }\n\n    }\n\n}\n", "idx": 12362, "_split": "test", "_hash": "357dbdc346fef76be398ff31e00e8823"}
{"project": "FFmpeg", "commit_id": "892bbbcdc171ff0d08d69636a240ffb95f54243c", "target": 0, "func": "static av_cold int vaapi_encode_config_attributes(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext *ctx = avctx->priv_data;\n\n    VAStatus vas;\n\n    int i, n, err;\n\n    VAProfile    *profiles    = NULL;\n\n    VAEntrypoint *entrypoints = NULL;\n\n    VAConfigAttrib attr[] = {\n\n        { VAConfigAttribRTFormat        },\n\n        { VAConfigAttribRateControl     },\n\n        { VAConfigAttribEncMaxRefFrames },\n\n    };\n\n\n\n    n = vaMaxNumProfiles(ctx->hwctx->display);\n\n    profiles = av_malloc_array(n, sizeof(VAProfile));\n\n    if (!profiles) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    vas = vaQueryConfigProfiles(ctx->hwctx->display, profiles, &n);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Failed to query profiles: %d (%s).\\n\",\n\n               vas, vaErrorStr(vas));\n\n        err = AVERROR(ENOSYS);\n\n        goto fail;\n\n    }\n\n    for (i = 0; i < n; i++) {\n\n        if (profiles[i] == ctx->va_profile)\n\n            break;\n\n    }\n\n    if (i >= n) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Encoding profile not found (%d).\\n\",\n\n               ctx->va_profile);\n\n        err = AVERROR(ENOSYS);\n\n        goto fail;\n\n    }\n\n\n\n    n = vaMaxNumEntrypoints(ctx->hwctx->display);\n\n    entrypoints = av_malloc_array(n, sizeof(VAEntrypoint));\n\n    if (!entrypoints) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    vas = vaQueryConfigEntrypoints(ctx->hwctx->display, ctx->va_profile,\n\n                                   entrypoints, &n);\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Failed to query entrypoints for \"\n\n               \"profile %u: %d (%s).\\n\", ctx->va_profile,\n\n               vas, vaErrorStr(vas));\n\n        err = AVERROR(ENOSYS);\n\n        goto fail;\n\n    }\n\n    for (i = 0; i < n; i++) {\n\n        if (entrypoints[i] == ctx->va_entrypoint)\n\n            break;\n\n    }\n\n    if (i >= n) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Encoding entrypoint not found \"\n\n               \"(%d / %d).\\n\", ctx->va_profile, ctx->va_entrypoint);\n\n        err = AVERROR(ENOSYS);\n\n        goto fail;\n\n    }\n\n\n\n    vas = vaGetConfigAttributes(ctx->hwctx->display,\n\n                                ctx->va_profile, ctx->va_entrypoint,\n\n                                attr, FF_ARRAY_ELEMS(attr));\n\n    if (vas != VA_STATUS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to fetch config \"\n\n               \"attributes: %d (%s).\\n\", vas, vaErrorStr(vas));\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    for (i = 0; i < FF_ARRAY_ELEMS(attr); i++) {\n\n        if (attr[i].value == VA_ATTRIB_NOT_SUPPORTED) {\n\n            // Unfortunately we have to treat this as \"don't know\" and hope\n\n            // for the best, because the Intel MJPEG encoder returns this\n\n            // for all the interesting attributes.\n\n            continue;\n\n        }\n\n        switch (attr[i].type) {\n\n        case VAConfigAttribRTFormat:\n\n            if (!(ctx->va_rt_format & attr[i].value)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Surface RT format %#x \"\n\n                       \"is not supported (mask %#x).\\n\",\n\n                       ctx->va_rt_format, attr[i].value);\n\n                err = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            ctx->config_attributes[ctx->nb_config_attributes++] =\n\n                (VAConfigAttrib) {\n\n                .type  = VAConfigAttribRTFormat,\n\n                .value = ctx->va_rt_format,\n\n            };\n\n            break;\n\n        case VAConfigAttribRateControl:\n\n            if (!(ctx->va_rc_mode & attr[i].value)) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Rate control mode %#x \"\n\n                       \"is not supported (mask: %#x).\\n\",\n\n                       ctx->va_rc_mode, attr[i].value);\n\n                err = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            ctx->config_attributes[ctx->nb_config_attributes++] =\n\n                (VAConfigAttrib) {\n\n                .type  = VAConfigAttribRateControl,\n\n                .value = ctx->va_rc_mode,\n\n            };\n\n            break;\n\n        case VAConfigAttribEncMaxRefFrames:\n\n        {\n\n            unsigned int ref_l0 = attr[i].value & 0xffff;\n\n            unsigned int ref_l1 = (attr[i].value >> 16) & 0xffff;\n\n\n\n            if (avctx->gop_size > 1 && ref_l0 < 1) {\n\n                av_log(avctx, AV_LOG_ERROR, \"P frames are not \"\n\n                       \"supported (%#x).\\n\", attr[i].value);\n\n                err = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n            if (avctx->max_b_frames > 0 && ref_l1 < 1) {\n\n                av_log(avctx, AV_LOG_ERROR, \"B frames are not \"\n\n                       \"supported (%#x).\\n\", attr[i].value);\n\n                err = AVERROR(EINVAL);\n\n                goto fail;\n\n            }\n\n        }\n\n        break;\n\n        default:\n\n            av_assert0(0 && \"Unexpected config attribute.\");\n\n        }\n\n    }\n\n\n\n    err = 0;\n\nfail:\n\n    av_freep(&profiles);\n\n    av_freep(&entrypoints);\n\n    return err;\n\n}\n", "idx": 12395, "_split": "test", "_hash": "6fdd3d4bee01772c01de06c00fc2fc2c"}
{"project": "FFmpeg", "commit_id": "be00ec832c519427cd92218abac77dafdc1d5487", "target": 0, "func": "static int targa_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                              const AVFrame *p, int *got_packet)\n\n{\n\n    int bpp, picsize, datasize = -1, ret;\n\n    uint8_t *out;\n\n\n\n    if(avctx->width > 0xffff || avctx->height > 0xffff) {\n\n        av_log(avctx, AV_LOG_ERROR, \"image dimensions too large\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    picsize = av_image_get_buffer_size(avctx->pix_fmt,\n\n                                       avctx->width, avctx->height, 1);\n\n    if ((ret = ff_alloc_packet(pkt, picsize + 45)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n        return ret;\n\n    }\n\n\n\n    /* zero out the header and only set applicable fields */\n\n    memset(pkt->data, 0, 12);\n\n    AV_WL16(pkt->data+12, avctx->width);\n\n    AV_WL16(pkt->data+14, avctx->height);\n\n    /* image descriptor byte: origin is always top-left, bits 0-3 specify alpha */\n\n    pkt->data[17] = 0x20 | (avctx->pix_fmt == AV_PIX_FMT_BGRA ? 8 : 0);\n\n\n\n    switch(avctx->pix_fmt) {\n\n    case AV_PIX_FMT_GRAY8:\n\n        pkt->data[2]  = TGA_BW;     /* uncompressed grayscale image */\n\n        pkt->data[16] = 8;          /* bpp */\n\n        break;\n\n    case AV_PIX_FMT_RGB555LE:\n\n        pkt->data[2]  = TGA_RGB;    /* uncompresses true-color image */\n\n        pkt->data[16] = 16;         /* bpp */\n\n        break;\n\n    case AV_PIX_FMT_BGR24:\n\n        pkt->data[2]  = TGA_RGB;    /* uncompressed true-color image */\n\n        pkt->data[16] = 24;         /* bpp */\n\n        break;\n\n    case AV_PIX_FMT_BGRA:\n\n        pkt->data[2]  = TGA_RGB;    /* uncompressed true-color image */\n\n        pkt->data[16] = 32;         /* bpp */\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Pixel format '%s' not supported.\\n\",\n\n               av_get_pix_fmt_name(avctx->pix_fmt));\n\n        return AVERROR(EINVAL);\n\n    }\n\n    bpp = pkt->data[16] >> 3;\n\n\n\n    out = pkt->data + 18;  /* skip past the header we just output */\n\n\n\n    /* try RLE compression */\n\n    if (avctx->coder_type != FF_CODER_TYPE_RAW)\n\n        datasize = targa_encode_rle(out, picsize, p, bpp, avctx->width, avctx->height);\n\n\n\n    /* if that worked well, mark the picture as RLE compressed */\n\n    if(datasize >= 0)\n\n        pkt->data[2] |= 8;\n\n\n\n    /* if RLE didn't make it smaller, go back to no compression */\n\n    else datasize = targa_encode_normal(out, p, bpp, avctx->width, avctx->height);\n\n\n\n    out += datasize;\n\n\n\n    /* The standard recommends including this section, even if we don't use\n\n     * any of the features it affords. TODO: take advantage of the pixel\n\n     * aspect ratio and encoder ID fields available? */\n\n    memcpy(out, \"\\0\\0\\0\\0\\0\\0\\0\\0TRUEVISION-XFILE.\", 26);\n\n\n\n    pkt->size   = out + 26 - pkt->data;\n\n    pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 12402, "_split": "test", "_hash": "6e2eaa6b2a4e86a16f1d43c0784f5fea"}
{"project": "FFmpeg", "commit_id": "5e53486545726987ab4482321d4dcf7e23e7652f", "target": 0, "func": "static void qdm2_init(QDM2Context *q) {\n\n    static int inited = 0;\n\n\n\n    if (inited != 0)\n\n        return;\n\n    inited = 1;\n\n\n\n    qdm2_init_vlc();\n\n    ff_mpa_synth_init(mpa_window);\n\n    softclip_table_init();\n\n    rnd_table_init();\n\n    init_noise_samples();\n\n\n\n    av_log(NULL, AV_LOG_DEBUG, \"init done\\n\");\n\n}\n", "idx": 12412, "_split": "test", "_hash": "542426a392d15c3cd1da6354c1897b27"}
{"project": "FFmpeg", "commit_id": "5ff998a233d759d0de83ea6f95c383d03d25d88e", "target": 1, "func": "static int encode_frame(FlacEncodeContext *s)\n\n{\n\n    int ch, count;\n\n\n\n    count = count_frame_header(s);\n\n\n\n    for (ch = 0; ch < s->channels; ch++)\n\n        count += encode_residual_ch(s, ch);\n\n\n\n    count += (8 - (count & 7)) & 7; // byte alignment\n\n    count += 16;                    // CRC-16\n\n\n\n    return count >> 3;\n\n}\n", "idx": 12429, "_split": "test", "_hash": "ed42fe048d48d7fef4bad627e10af15a"}
{"project": "FFmpeg", "commit_id": "45198477de19ccb00729b7eec07d81494f0353e0", "target": 1, "func": "static inline void FUNC(idctRowCondDC_extrashift)(int16_t *row, int extra_shift)\n\n#else\n\nstatic inline void FUNC(idctRowCondDC)(int16_t *row, int extra_shift)\n\n#endif\n\n{\n\n    int a0, a1, a2, a3, b0, b1, b2, b3;\n\n\n\n#if HAVE_FAST_64BIT\n\n#define ROW0_MASK (0xffffLL << 48 * HAVE_BIGENDIAN)\n\n    if (((AV_RN64A(row) & ~ROW0_MASK) | AV_RN64A(row+4)) == 0) {\n\n        uint64_t temp;\n\n        if (DC_SHIFT - extra_shift >= 0) {\n\n            temp = (row[0] * (1 << (DC_SHIFT - extra_shift))) & 0xffff;\n\n        } else {\n\n            temp = ((row[0] + (1<<(extra_shift - DC_SHIFT-1))) >> (extra_shift - DC_SHIFT)) & 0xffff;\n\n        }\n\n        temp += temp * (1 << 16);\n\n        temp += temp * ((uint64_t) 1 << 32);\n\n        AV_WN64A(row, temp);\n\n        AV_WN64A(row + 4, temp);\n\n        return;\n\n    }\n\n#else\n\n    if (!(AV_RN32A(row+2) |\n\n          AV_RN32A(row+4) |\n\n          AV_RN32A(row+6) |\n\n          row[1])) {\n\n        uint32_t temp;\n\n        if (DC_SHIFT - extra_shift >= 0) {\n\n            temp = (row[0] * (1 << (DC_SHIFT - extra_shift))) & 0xffff;\n\n        } else {\n\n            temp = ((row[0] + (1<<(extra_shift - DC_SHIFT-1))) >> (extra_shift - DC_SHIFT)) & 0xffff;\n\n        }\n\n        temp += temp * (1 << 16);\n\n        AV_WN32A(row, temp);\n\n        AV_WN32A(row+2, temp);\n\n        AV_WN32A(row+4, temp);\n\n        AV_WN32A(row+6, temp);\n\n        return;\n\n    }\n\n#endif\n\n\n\n    a0 = (W4 * row[0]) + (1 << (ROW_SHIFT + extra_shift - 1));\n\n    a1 = a0;\n\n    a2 = a0;\n\n    a3 = a0;\n\n\n\n    a0 += W2 * row[2];\n\n    a1 += W6 * row[2];\n\n    a2 -= W6 * row[2];\n\n    a3 -= W2 * row[2];\n\n\n\n    b0 = MUL(W1, row[1]);\n\n    MAC(b0, W3, row[3]);\n\n    b1 = MUL(W3, row[1]);\n\n    MAC(b1, -W7, row[3]);\n\n    b2 = MUL(W5, row[1]);\n\n    MAC(b2, -W1, row[3]);\n\n    b3 = MUL(W7, row[1]);\n\n    MAC(b3, -W5, row[3]);\n\n\n\n    if (AV_RN64A(row + 4)) {\n\n        a0 +=   W4*row[4] + W6*row[6];\n\n        a1 += - W4*row[4] - W2*row[6];\n\n        a2 += - W4*row[4] + W2*row[6];\n\n        a3 +=   W4*row[4] - W6*row[6];\n\n\n\n        MAC(b0,  W5, row[5]);\n\n        MAC(b0,  W7, row[7]);\n\n\n\n        MAC(b1, -W1, row[5]);\n\n        MAC(b1, -W5, row[7]);\n\n\n\n        MAC(b2,  W7, row[5]);\n\n        MAC(b2,  W3, row[7]);\n\n\n\n        MAC(b3,  W3, row[5]);\n\n        MAC(b3, -W1, row[7]);\n\n    }\n\n\n\n    row[0] = (a0 + b0) >> (ROW_SHIFT + extra_shift);\n\n    row[7] = (a0 - b0) >> (ROW_SHIFT + extra_shift);\n\n    row[1] = (a1 + b1) >> (ROW_SHIFT + extra_shift);\n\n    row[6] = (a1 - b1) >> (ROW_SHIFT + extra_shift);\n\n    row[2] = (a2 + b2) >> (ROW_SHIFT + extra_shift);\n\n    row[5] = (a2 - b2) >> (ROW_SHIFT + extra_shift);\n\n    row[3] = (a3 + b3) >> (ROW_SHIFT + extra_shift);\n\n    row[4] = (a3 - b3) >> (ROW_SHIFT + extra_shift);\n\n}\n", "idx": 12493, "_split": "test", "_hash": "78735727d9478263295eb349d3aacaae"}
{"project": "FFmpeg", "commit_id": "7546964f96168cd6ac819ef4c3212ee586619f1a", "target": 0, "func": "int ff_nvdec_decode_init(AVCodecContext *avctx, unsigned int dpb_size)\n\n{\n\n    NVDECContext *ctx = avctx->internal->hwaccel_priv_data;\n\n\n\n    NVDECFramePool      *pool;\n\n    AVHWFramesContext   *frames_ctx;\n\n    const AVPixFmtDescriptor *sw_desc;\n\n\n\n    CUVIDDECODECREATEINFO params = { 0 };\n\n\n\n    int cuvid_codec_type, cuvid_chroma_format;\n\n    int ret = 0;\n\n\n\n    sw_desc = av_pix_fmt_desc_get(avctx->sw_pix_fmt);\n\n    if (!sw_desc)\n\n        return AVERROR_BUG;\n\n\n\n    cuvid_codec_type = map_avcodec_id(avctx->codec_id);\n\n    if (cuvid_codec_type < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported codec ID\\n\");\n\n        return AVERROR_BUG;\n\n    }\n\n\n\n    cuvid_chroma_format = map_chroma_format(avctx->sw_pix_fmt);\n\n    if (cuvid_chroma_format < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported chroma format\\n\");\n\n        return AVERROR(ENOSYS);\n\n    }\n\n\n\n    if (avctx->thread_type & FF_THREAD_FRAME)\n\n        dpb_size += avctx->thread_count;\n\n\n\n    if (!avctx->hw_frames_ctx) {\n\n        AVHWFramesContext *frames_ctx;\n\n\n\n        if (!avctx->hw_device_ctx) {\n\n            av_log(avctx, AV_LOG_ERROR, \"A hardware device or frames context \"\n\n                   \"is required for CUVID decoding.\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        avctx->hw_frames_ctx = av_hwframe_ctx_alloc(avctx->hw_device_ctx);\n\n        if (!avctx->hw_frames_ctx)\n\n            return AVERROR(ENOMEM);\n\n        frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n\n\n        frames_ctx->format            = AV_PIX_FMT_CUDA;\n\n        frames_ctx->width             = avctx->coded_width;\n\n        frames_ctx->height            = avctx->coded_height;\n\n        frames_ctx->sw_format         = AV_PIX_FMT_NV12;\n\n        frames_ctx->sw_format         = sw_desc->comp[0].depth > 8 ?\n\n                                        AV_PIX_FMT_P010 : AV_PIX_FMT_NV12;\n\n        frames_ctx->initial_pool_size = dpb_size;\n\n\n\n        ret = av_hwframe_ctx_init(avctx->hw_frames_ctx);\n\n        if (ret < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Error initializing internal frames context\\n\");\n\n            return ret;\n\n        }\n\n    }\n\n    frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n\n\n    params.ulWidth             = avctx->coded_width;\n\n    params.ulHeight            = avctx->coded_height;\n\n    params.ulTargetWidth       = avctx->coded_width;\n\n    params.ulTargetHeight      = avctx->coded_height;\n\n    params.bitDepthMinus8      = sw_desc->comp[0].depth - 8;\n\n    params.OutputFormat        = params.bitDepthMinus8 ?\n\n                                 cudaVideoSurfaceFormat_P016 : cudaVideoSurfaceFormat_NV12;\n\n    params.CodecType           = cuvid_codec_type;\n\n    params.ChromaFormat        = cuvid_chroma_format;\n\n    params.ulNumDecodeSurfaces = dpb_size;\n\n    params.ulNumOutputSurfaces = 1;\n\n\n\n    ret = nvdec_decoder_create(&ctx->decoder_ref, frames_ctx->device_ref, &params, avctx);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    pool = av_mallocz(sizeof(*pool));\n\n    if (!pool) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    pool->dpb_size = dpb_size;\n\n\n\n    ctx->decoder_pool = av_buffer_pool_init2(sizeof(int), pool,\n\n                                             nvdec_decoder_frame_alloc, av_free);\n\n    if (!ctx->decoder_pool) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    return 0;\n\nfail:\n\n    ff_nvdec_decode_uninit(avctx);\n\n    return ret;\n\n}\n", "idx": 12556, "_split": "test", "_hash": "fd2190958ff7ecc49a7d51d9610cca76"}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "int decode_block_coeffs(VP56RangeCoder *c, int16_t block[16],\n\n                        uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n\n                        int i, int zero_nhood, int16_t qmul[2])\n\n{\n\n    uint8_t *token_prob = probs[i][zero_nhood];\n\n    if (!vp56_rac_get_prob_branchy(c, token_prob[0]))   // DCT_EOB\n\n        return 0;\n\n    return decode_block_coeffs_internal(c, block, probs, i, token_prob, qmul);\n\n}\n", "idx": 12585, "_split": "test", "_hash": "e8cd85f8e003f18b2ddb0501008aa78d"}
{"project": "FFmpeg", "commit_id": "f5be84cfbc9c132a867ae8a8c0e0de26ed1a4e88", "target": 1, "func": "static int load_ipmovie_packet(IPMVEContext *s, AVIOContext *pb,\n\n    AVPacket *pkt) {\n\n\n\n    int chunk_type;\n\n\n\n    if (s->audio_chunk_offset) {\n\n\n\n\n\n\n\n\n        /* adjust for PCM audio by skipping chunk header */\n\n        if (s->audio_type != CODEC_ID_INTERPLAY_DPCM) {\n\n            s->audio_chunk_offset += 6;\n\n            s->audio_chunk_size -= 6;\n\n\n\n\n        avio_seek(pb, s->audio_chunk_offset, SEEK_SET);\n\n        s->audio_chunk_offset = 0;\n\n\n\n        if (s->audio_chunk_size != av_get_packet(pb, pkt, s->audio_chunk_size))\n\n            return CHUNK_EOF;\n\n\n\n        pkt->stream_index = s->audio_stream_index;\n\n        pkt->pts = s->audio_frame_count;\n\n\n\n        /* audio frame maintenance */\n\n        if (s->audio_type != CODEC_ID_INTERPLAY_DPCM)\n\n            s->audio_frame_count +=\n\n            (s->audio_chunk_size / s->audio_channels / (s->audio_bits / 8));\n\n        else\n\n            s->audio_frame_count +=\n\n                (s->audio_chunk_size - 6) / s->audio_channels;\n\n\n\n        av_dlog(NULL, \"sending audio frame with pts %\"PRId64\" (%d audio frames)\\n\",\n\n                pkt->pts, s->audio_frame_count);\n\n\n\n        chunk_type = CHUNK_VIDEO;\n\n\n\n    } else if (s->decode_map_chunk_offset) {\n\n\n\n        /* send both the decode map and the video data together */\n\n\n\n        if (av_new_packet(pkt, s->decode_map_chunk_size + s->video_chunk_size))\n\n            return CHUNK_NOMEM;\n\n\n\n        if (s->has_palette) {\n\n            uint8_t *pal;\n\n\n\n            pal = av_packet_new_side_data(pkt, AV_PKT_DATA_PALETTE,\n\n                                          AVPALETTE_SIZE);\n\n            if (pal) {\n\n                memcpy(pal, s->palette, AVPALETTE_SIZE);\n\n                s->has_palette = 0;\n\n\n\n\n\n        pkt->pos= s->decode_map_chunk_offset;\n\n        avio_seek(pb, s->decode_map_chunk_offset, SEEK_SET);\n\n        s->decode_map_chunk_offset = 0;\n\n\n\n        if (avio_read(pb, pkt->data, s->decode_map_chunk_size) !=\n\n            s->decode_map_chunk_size) {\n\n            av_free_packet(pkt);\n\n            return CHUNK_EOF;\n\n\n\n\n        avio_seek(pb, s->video_chunk_offset, SEEK_SET);\n\n        s->video_chunk_offset = 0;\n\n\n\n        if (avio_read(pb, pkt->data + s->decode_map_chunk_size,\n\n            s->video_chunk_size) != s->video_chunk_size) {\n\n            av_free_packet(pkt);\n\n            return CHUNK_EOF;\n\n\n\n\n        pkt->stream_index = s->video_stream_index;\n\n        pkt->pts = s->video_pts;\n\n\n\n        av_dlog(NULL, \"sending video frame with pts %\"PRId64\"\\n\", pkt->pts);\n\n\n\n        s->video_pts += s->frame_pts_inc;\n\n\n\n        chunk_type = CHUNK_VIDEO;\n\n\n\n    } else {\n\n\n\n        avio_seek(pb, s->next_chunk_offset, SEEK_SET);\n\n        chunk_type = CHUNK_DONE;\n\n\n\n\n\n\n    return chunk_type;\n", "idx": 12607, "_split": "test", "_hash": "6f6dbbdb7459aad7db945802041610ef"}
{"project": "FFmpeg", "commit_id": "f21cf2b38365caaa8a130a32521c2648600c3f50", "target": 0, "func": "static int encode_hq_slice(AVCodecContext *avctx, void *arg)\n\n{\n\n    SliceArgs *slice_dat = arg;\n\n    VC2EncContext *s = slice_dat->ctx;\n\n    PutBitContext *pb = &slice_dat->pb;\n\n    const int slice_x = slice_dat->x;\n\n    const int slice_y = slice_dat->y;\n\n    const int quant_idx = slice_dat->quant_idx;\n\n    const int slice_bytes_max = slice_dat->bytes;\n\n    uint8_t quants[MAX_DWT_LEVELS][4];\n\n    int p, level, orientation;\n\n\n\n    avpriv_align_put_bits(pb);\n\n    skip_put_bytes(pb, s->prefix_bytes);\n\n    put_bits(pb, 8, quant_idx);\n\n\n\n    /* Slice quantization (slice_quantizers() in the specs) */\n\n    for (level = 0; level < s->wavelet_depth; level++)\n\n        for (orientation = !!level; orientation < 4; orientation++)\n\n            quants[level][orientation] = FFMAX(quant_idx - s->quant[level][orientation], 0);\n\n\n\n    /* Luma + 2 Chroma planes */\n\n    for (p = 0; p < 3; p++) {\n\n        int bytes_start, bytes_len, pad_s, pad_c;\n\n        bytes_start = put_bits_count(pb) >> 3;\n\n        put_bits(pb, 8, 0);\n\n        for (level = 0; level < s->wavelet_depth; level++) {\n\n            for (orientation = !!level; orientation < 4; orientation++) {\n\n                encode_subband(s, pb, slice_x, slice_y,\n\n                               &s->plane[p].band[level][orientation],\n\n                               quants[level][orientation]);\n\n            }\n\n        }\n\n        avpriv_align_put_bits(pb);\n\n        bytes_len = (put_bits_count(pb) >> 3) - bytes_start - 1;\n\n        if (p == 2) {\n\n            int len_diff = slice_bytes_max - (put_bits_count(pb) >> 3);\n\n            pad_s = FFALIGN((bytes_len + len_diff), s->size_scaler)/s->size_scaler;\n\n            pad_c = (pad_s*s->size_scaler) - bytes_len;\n\n        } else {\n\n            pad_s = FFALIGN(bytes_len, s->size_scaler)/s->size_scaler;\n\n            pad_c = (pad_s*s->size_scaler) - bytes_len;\n\n        }\n\n        pb->buf[bytes_start] = pad_s;\n\n        flush_put_bits(pb);\n\n        skip_put_bytes(pb, pad_c);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 12616, "_split": "test", "_hash": "79a363af868030a199feff88740f9c88"}
{"project": "FFmpeg", "commit_id": "2df0c32ea12ddfa72ba88309812bfb13b674130f", "target": 0, "func": "static int av_cold libopus_encode_init(AVCodecContext *avctx)\n\n{\n\n    LibopusEncContext *opus = avctx->priv_data;\n\n    const uint8_t *channel_mapping;\n\n    OpusMSEncoder *enc;\n\n    int ret = OPUS_OK;\n\n    int coupled_stream_count, header_size, frame_size;\n\n\n\n    coupled_stream_count = opus_coupled_streams[avctx->channels - 1];\n\n    opus->stream_count   = avctx->channels - coupled_stream_count;\n\n    channel_mapping      = libav_libopus_channel_map[avctx->channels - 1];\n\n\n\n    /* FIXME: Opus can handle up to 255 channels. However, the mapping for\n\n     * anything greater than 8 is undefined. */\n\n    if (avctx->channels > 8)\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Channel layout undefined for %d channels.\\n\", avctx->channels);\n\n\n\n    if (!avctx->bit_rate) {\n\n        /* Sane default copied from opusenc */\n\n        avctx->bit_rate = 64000 * opus->stream_count +\n\n                          32000 * coupled_stream_count;\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"No bit rate set. Defaulting to %d bps.\\n\", avctx->bit_rate);\n\n    }\n\n\n\n    if (avctx->bit_rate < 500 || avctx->bit_rate > 256000 * avctx->channels) {\n\n        av_log(avctx, AV_LOG_ERROR, \"The bit rate %d bps is unsupported. \"\n\n               \"Please choose a value between 500 and %d.\\n\", avctx->bit_rate,\n\n               256000 * avctx->channels);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    frame_size = opus->opts.frame_duration * 48000 / 1000;\n\n    switch (frame_size) {\n\n    case 120:\n\n    case 240:\n\n        if (opus->opts.application != OPUS_APPLICATION_RESTRICTED_LOWDELAY)\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"LPC mode cannot be used with a frame duration of less \"\n\n                   \"than 10ms. Enabling restricted low-delay mode.\\n\"\n\n                   \"Use a longer frame duration if this is not what you want.\\n\");\n\n        /* Frame sizes less than 10 ms can only use MDCT mode, so switching to\n\n         * RESTRICTED_LOWDELAY avoids an unnecessary extra 2.5ms lookahead. */\n\n        opus->opts.application = OPUS_APPLICATION_RESTRICTED_LOWDELAY;\n\n    case 480:\n\n    case 960:\n\n    case 1920:\n\n    case 2880:\n\n        opus->opts.packet_size =\n\n        avctx->frame_size      = frame_size * avctx->sample_rate / 48000;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid frame duration: %g.\\n\"\n\n               \"Frame duration must be exactly one of: 2.5, 5, 10, 20, 40 or 60.\\n\",\n\n               opus->opts.frame_duration);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (avctx->compression_level < 0 || avctx->compression_level > 10) {\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Compression level must be in the range 0 to 10. \"\n\n               \"Defaulting to 10.\\n\");\n\n        opus->opts.complexity = 10;\n\n    } else {\n\n        opus->opts.complexity = avctx->compression_level;\n\n    }\n\n\n\n    if (avctx->cutoff) {\n\n        switch (avctx->cutoff) {\n\n        case  4000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_NARROWBAND;\n\n            break;\n\n        case  6000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_MEDIUMBAND;\n\n            break;\n\n        case  8000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_WIDEBAND;\n\n            break;\n\n        case 12000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_SUPERWIDEBAND;\n\n            break;\n\n        case 20000:\n\n            opus->opts.max_bandwidth = OPUS_BANDWIDTH_FULLBAND;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"Invalid frequency cutoff: %d. Using default maximum bandwidth.\\n\"\n\n                   \"Cutoff frequency must be exactly one of: 4000, 6000, 8000, 12000 or 20000.\\n\",\n\n                   avctx->cutoff);\n\n            avctx->cutoff = 0;\n\n        }\n\n    }\n\n\n\n    enc = opus_multistream_encoder_create(avctx->sample_rate, avctx->channels,\n\n                                          opus->stream_count,\n\n                                          coupled_stream_count,\n\n                                          channel_mapping,\n\n                                          opus->opts.application, &ret);\n\n    if (ret != OPUS_OK) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Failed to create encoder: %s\\n\", opus_strerror(ret));\n\n        return ff_opus_error_to_averror(ret);\n\n    }\n\n\n\n    ret = libopus_configure_encoder(avctx, enc, &opus->opts);\n\n    if (ret != OPUS_OK) {\n\n        ret = ff_opus_error_to_averror(ret);\n\n        goto fail;\n\n    }\n\n\n\n    header_size = 19 + (avctx->channels > 2 ? 2 + avctx->channels : 0);\n\n    avctx->extradata = av_malloc(header_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (!avctx->extradata) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to allocate extradata.\\n\");\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    avctx->extradata_size = header_size;\n\n\n\n    opus->samples = av_mallocz(frame_size * avctx->channels *\n\n                               av_get_bytes_per_sample(avctx->sample_fmt));\n\n    if (!opus->samples) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to allocate samples buffer.\\n\");\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    ret = opus_multistream_encoder_ctl(enc, OPUS_GET_LOOKAHEAD(&avctx->delay));\n\n    if (ret != OPUS_OK)\n\n        av_log(avctx, AV_LOG_WARNING,\n\n               \"Unable to get number of lookahead samples: %s\\n\",\n\n               opus_strerror(ret));\n\n\n\n    libopus_write_header(avctx, opus->stream_count, coupled_stream_count,\n\n                         opus_vorbis_channel_map[avctx->channels - 1]);\n\n\n\n    ff_af_queue_init(avctx, &opus->afq);\n\n\n\n    opus->enc = enc;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    opus_multistream_encoder_destroy(enc);\n\n    av_freep(&avctx->extradata);\n\n    return ret;\n\n}\n", "idx": 12730, "_split": "test", "_hash": "df58a8a5332223abfab1c7b2fed10dcc"}
{"project": "FFmpeg", "commit_id": "221b804f3491638ecf2eec1302c669ad2d9ec799", "target": 1, "func": "static inline void yuv2packedXinC(SwsContext *c, int16_t *lumFilter, int16_t **lumSrc, int lumFilterSize,\n\n\t\t\t\t    int16_t *chrFilter, int16_t **chrSrc, int chrFilterSize,\n\n\t\t\t\t    uint8_t *dest, int dstW, int y)\n\n{\n\n\tint i;\n\n\tswitch(c->dstFormat)\n\n\t{\n\n\tcase PIX_FMT_BGR32:\n\n\tcase PIX_FMT_RGB32:\n\n\t\tYSCALE_YUV_2_RGBX_C(uint32_t)\n\n\t\t\t((uint32_t*)dest)[i2+0]= r[Y1] + g[Y1] + b[Y1];\n\n\t\t\t((uint32_t*)dest)[i2+1]= r[Y2] + g[Y2] + b[Y2];\n\n\t\t}\n\n\t\tbreak;\n\n\tcase PIX_FMT_RGB24:\n\n\t\tYSCALE_YUV_2_RGBX_C(uint8_t)\n\n\t\t\t((uint8_t*)dest)[0]= r[Y1];\n\n\t\t\t((uint8_t*)dest)[1]= g[Y1];\n\n\t\t\t((uint8_t*)dest)[2]= b[Y1];\n\n\t\t\t((uint8_t*)dest)[3]= r[Y2];\n\n\t\t\t((uint8_t*)dest)[4]= g[Y2];\n\n\t\t\t((uint8_t*)dest)[5]= b[Y2];\n\n\t\t\tdest+=6;\n\n\t\t}\n", "idx": 12809, "_split": "test", "_hash": "5eaf9663c2a285cae2865f1979c32e44"}
{"project": "FFmpeg", "commit_id": "2fc9a3eb7a8c606bd403dc9fbdb8463144b243cf", "target": 1, "func": "static int write_packet(AVFormatContext *s, AVPacket *pkt)\n{\n    int ret, did_split;\n    if (s->output_ts_offset) {\n        AVStream *st = s->streams[pkt->stream_index];\n        int64_t offset = av_rescale_q(s->output_ts_offset, AV_TIME_BASE_Q, st->time_base);\n        if (pkt->dts != AV_NOPTS_VALUE)\n            pkt->dts += offset;\n        if (pkt->pts != AV_NOPTS_VALUE)\n            pkt->pts += offset;\n    }\n    if (s->avoid_negative_ts > 0) {\n        AVStream *st = s->streams[pkt->stream_index];\n        int64_t offset = st->mux_ts_offset;\n        int64_t ts = s->internal->avoid_negative_ts_use_pts ? pkt->pts : pkt->dts;\n        if (s->internal->offset == AV_NOPTS_VALUE && ts != AV_NOPTS_VALUE &&\n            (ts < 0 || s->avoid_negative_ts == AVFMT_AVOID_NEG_TS_MAKE_ZERO)) {\n            s->internal->offset = -ts;\n            s->internal->offset_timebase = st->time_base;\n        }\n        if (s->internal->offset != AV_NOPTS_VALUE && !offset) {\n            offset = st->mux_ts_offset =\n                av_rescale_q_rnd(s->internal->offset,\n                                 s->internal->offset_timebase,\n                                 st->time_base,\n                                 AV_ROUND_UP);\n        }\n        if (pkt->dts != AV_NOPTS_VALUE)\n            pkt->dts += offset;\n        if (pkt->pts != AV_NOPTS_VALUE)\n            pkt->pts += offset;\n        if (s->internal->avoid_negative_ts_use_pts) {\n            if (pkt->pts != AV_NOPTS_VALUE && pkt->pts < 0) {\n                av_log(s, AV_LOG_WARNING, \"failed to avoid negative \"\n                    \"pts %s in stream %d.\\n\"\n                    \"Try -avoid_negative_ts 1 as a possible workaround.\\n\",\n                    av_ts2str(pkt->dts),\n                    pkt->stream_index\n                );\n            }\n        } else {\n            av_assert2(pkt->dts == AV_NOPTS_VALUE || pkt->dts >= 0 || s->max_interleave_delta > 0);\n            if (pkt->dts != AV_NOPTS_VALUE && pkt->dts < 0) {\n                av_log(s, AV_LOG_WARNING,\n                    \"Packets poorly interleaved, failed to avoid negative \"\n                    \"timestamp %s in stream %d.\\n\"\n                    \"Try -max_interleave_delta 0 as a possible workaround.\\n\",\n                    av_ts2str(pkt->dts),\n                    pkt->stream_index\n                );\n            }\n        }\n    }\n    did_split = av_packet_split_side_data(pkt);\n    if (!s->internal->header_written) {\n        ret = s->internal->write_header_ret ? s->internal->write_header_ret : write_header_internal(s);\n        if (ret < 0)\n            goto fail;\n    }\n    if ((pkt->flags & AV_PKT_FLAG_UNCODED_FRAME)) {\n        AVFrame *frame = (AVFrame *)pkt->data;\n        av_assert0(pkt->size == UNCODED_FRAME_PACKET_SIZE);\n        ret = s->oformat->write_uncoded_frame(s, pkt->stream_index, &frame, 0);\n        av_frame_free(&frame);\n    } else {\n        ret = s->oformat->write_packet(s, pkt);\n    }\n    if (s->pb && ret >= 0) {\n        if (s->flush_packets && s->flags & AVFMT_FLAG_FLUSH_PACKETS)\n            avio_flush(s->pb);\n        if (s->pb->error < 0)\n            ret = s->pb->error;\n    }\nfail:\n    if (did_split)\n        av_packet_merge_side_data(pkt);\n    if (ret < 0) {\n        pkt->pts = pts_backup;\n        pkt->dts = dts_backup;\n    }\n    return ret;\n}", "idx": 12810, "_split": "test", "_hash": "4096e54438f6a5dad257cc1440d4d04d"}
{"project": "FFmpeg", "commit_id": "568e18b15e2ddf494fd8926707d34ca08c8edce5", "target": 1, "func": "static void read_sgi_header(ByteIOContext *f, SGIInfo *info)\n{\n    info->magic = (unsigned short) get_be16(f);\n    info->rle = get_byte(f);\n    info->bytes_per_channel = get_byte(f);\n    info->dimension = (unsigned short)get_be16(f);\n    info->xsize = (unsigned short) get_be16(f);\n    info->ysize = (unsigned short) get_be16(f);\n    info->zsize = (unsigned short) get_be16(f);\n#ifdef DEBUG\n    printf(\"sgi header fields:\\n\");\n    printf(\"  magic: %d\\n\", info->magic);\n    printf(\"    rle: %d\\n\", info->rle);\n    printf(\"    bpc: %d\\n\", info->bytes_per_channel);\n    printf(\"    dim: %d\\n\", info->dimension);\n    printf(\"  xsize: %d\\n\", info->xsize);\n    printf(\"  ysize: %d\\n\", info->ysize);\n    printf(\"  zsize: %d\\n\", info->zsize);\n#endif\n    return;\n}", "idx": 12814, "_split": "test", "_hash": "6bc9fa51e6e553ff54c90fb628160433"}
{"project": "FFmpeg", "commit_id": "d68c05380cebf563915412182643a8be04ef890b", "target": 0, "func": "av_cold void ff_dct_init_x86(DCTContext *s)\n\n{\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (EXTERNAL_SSE(cpu_flags))\n\n        s->dct32 = ff_dct32_float_sse;\n\n    if (EXTERNAL_SSE2(cpu_flags))\n\n        s->dct32 = ff_dct32_float_sse2;\n\n    if (EXTERNAL_AVX(cpu_flags))\n\n        s->dct32 = ff_dct32_float_avx;\n\n}\n", "idx": 12927, "_split": "test", "_hash": "b166deecd0283355744b226ed299558c"}
{"project": "FFmpeg", "commit_id": "5ecabd3c54b7c802522dc338838c9a4c2dc42948", "target": 1, "func": "static int msrle_decode_pal4(AVCodecContext *avctx, AVPicture *pic,\n\n                             GetByteContext *gb)\n\n{\n\n    unsigned char rle_code;\n\n    unsigned char extra_byte, odd_pixel;\n\n    unsigned char stream_byte;\n\n    unsigned int pixel_ptr = 0;\n\n    int row_dec = pic->linesize[0];\n\n    int row_ptr = (avctx->height - 1) * row_dec;\n\n    int frame_size = row_dec * avctx->height;\n\n    int i;\n\n\n\n    while (row_ptr >= 0) {\n\n        if (bytestream2_get_bytes_left(gb) <= 0) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"MS RLE: bytestream overrun, %d rows left\\n\",\n\n                   row_ptr);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        rle_code = stream_byte = bytestream2_get_byteu(gb);\n\n        if (rle_code == 0) {\n\n            /* fetch the next byte to see how to handle escape code */\n\n            stream_byte = bytestream2_get_byte(gb);\n\n            if (stream_byte == 0) {\n\n                /* line is done, goto the next one */\n\n                row_ptr -= row_dec;\n\n                pixel_ptr = 0;\n\n            } else if (stream_byte == 1) {\n\n                /* decode is done */\n\n                return 0;\n\n            } else if (stream_byte == 2) {\n\n                /* reposition frame decode coordinates */\n\n                stream_byte = bytestream2_get_byte(gb);\n\n                pixel_ptr += stream_byte;\n\n                stream_byte = bytestream2_get_byte(gb);\n\n                row_ptr -= stream_byte * row_dec;\n\n            } else {\n\n                // copy pixels from encoded stream\n\n                odd_pixel =  stream_byte & 1;\n\n                rle_code = (stream_byte + 1) / 2;\n\n                extra_byte = rle_code & 0x01;\n\n                if (row_ptr + pixel_ptr + stream_byte > frame_size ||\n\n                    bytestream2_get_bytes_left(gb) < rle_code) {\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"MS RLE: frame/stream ptr just went out of bounds (copy)\\n\");\n\n                    return AVERROR_INVALIDDATA;\n\n                }\n\n\n\n                for (i = 0; i < rle_code; i++) {\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    stream_byte = bytestream2_get_byteu(gb);\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte >> 4;\n\n                    pixel_ptr++;\n\n                    if (i + 1 == rle_code && odd_pixel)\n\n                        break;\n\n                    if (pixel_ptr >= avctx->width)\n\n                        break;\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F;\n\n                    pixel_ptr++;\n\n                }\n\n\n\n                // if the RLE code is odd, skip a byte in the stream\n\n                if (extra_byte)\n\n                    bytestream2_skip(gb, 1);\n\n            }\n\n        } else {\n\n            // decode a run of data\n\n            if (row_ptr + pixel_ptr + stream_byte > frame_size) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"MS RLE: frame ptr just went out of bounds (run)\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            stream_byte = bytestream2_get_byte(gb);\n\n            for (i = 0; i < rle_code; i++) {\n\n                if (pixel_ptr >= avctx->width)\n\n                    break;\n\n                if ((i & 1) == 0)\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte >> 4;\n\n                else\n\n                    pic->data[0][row_ptr + pixel_ptr] = stream_byte & 0x0F;\n\n                pixel_ptr++;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* one last sanity check on the way out */\n\n    if (bytestream2_get_bytes_left(gb)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"MS RLE: ended frame decode with %d bytes left over\\n\",\n\n               bytestream2_get_bytes_left(gb));\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 12940, "_split": "test", "_hash": "71719eef559c9618eea456253fcbe362"}
{"project": "FFmpeg", "commit_id": "482ee63641f4fa50f017538af384aadbceee7a18", "target": 1, "func": "static int thp_read_header(AVFormatContext *s,\n\n                           AVFormatParameters *ap)\n\n{\n\n    ThpDemuxContext *thp = s->priv_data;\n\n    AVStream *st;\n\n    AVIOContext *pb = s->pb;\n\n    int i;\n\n\n\n    /* Read the file header.  */\n\n                           avio_rb32(pb); /* Skip Magic.  */\n\n    thp->version         = avio_rb32(pb);\n\n\n\n                           avio_rb32(pb); /* Max buf size.  */\n\n                           avio_rb32(pb); /* Max samples.  */\n\n\n\n    thp->fps             = av_d2q(av_int2float(avio_rb32(pb)), INT_MAX);\n\n    thp->framecnt        = avio_rb32(pb);\n\n    thp->first_framesz   = avio_rb32(pb);\n\n                           avio_rb32(pb); /* Data size.  */\n\n\n\n    thp->compoff         = avio_rb32(pb);\n\n                           avio_rb32(pb); /* offsetDataOffset.  */\n\n    thp->first_frame     = avio_rb32(pb);\n\n    thp->last_frame      = avio_rb32(pb);\n\n\n\n    thp->next_framesz    = thp->first_framesz;\n\n    thp->next_frame      = thp->first_frame;\n\n\n\n    /* Read the component structure.  */\n\n    avio_seek (pb, thp->compoff, SEEK_SET);\n\n    thp->compcount       = avio_rb32(pb);\n\n\n\n    /* Read the list of component types.  */\n\n    avio_read(pb, thp->components, 16);\n\n\n\n    for (i = 0; i < thp->compcount; i++) {\n\n        if (thp->components[i] == 0) {\n\n            if (thp->vst != 0)\n\n                break;\n\n\n\n            /* Video component.  */\n\n            st = avformat_new_stream(s, NULL);\n\n            if (!st)\n\n                return AVERROR(ENOMEM);\n\n\n\n            /* The denominator and numerator are switched because 1/fps\n\n               is required.  */\n\n            avpriv_set_pts_info(st, 64, thp->fps.den, thp->fps.num);\n\n            st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n            st->codec->codec_id = CODEC_ID_THP;\n\n            st->codec->codec_tag = 0;  /* no fourcc */\n\n            st->codec->width = avio_rb32(pb);\n\n            st->codec->height = avio_rb32(pb);\n\n            st->codec->sample_rate = av_q2d(thp->fps);\n\n            thp->vst = st;\n\n            thp->video_stream_index = st->index;\n\n\n\n            if (thp->version == 0x11000)\n\n                avio_rb32(pb); /* Unknown.  */\n\n        } else if (thp->components[i] == 1) {\n\n            if (thp->has_audio != 0)\n\n                break;\n\n\n\n            /* Audio component.  */\n\n            st = avformat_new_stream(s, NULL);\n\n            if (!st)\n\n                return AVERROR(ENOMEM);\n\n\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n            st->codec->codec_id = CODEC_ID_ADPCM_THP;\n\n            st->codec->codec_tag = 0;  /* no fourcc */\n\n            st->codec->channels    = avio_rb32(pb); /* numChannels.  */\n\n            st->codec->sample_rate = avio_rb32(pb); /* Frequency.  */\n\n\n\n            avpriv_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n\n\n            thp->audio_stream_index = st->index;\n\n            thp->has_audio = 1;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 12951, "_split": "test", "_hash": "19b0beef4f1c4ad6f88a1ab6a9929ae5"}
{"project": "FFmpeg", "commit_id": "5763f675024765df8f256d8b5b01926a5fbd997d", "target": 1, "func": "static int mov_read_trak(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    int ret;\n\n\n\n    st = avformat_new_stream(c->fc, NULL);\n\n    if (!st) return AVERROR(ENOMEM);\n\n    st->id = c->fc->nb_streams;\n\n    sc = av_mallocz(sizeof(MOVStreamContext));\n\n    if (!sc) return AVERROR(ENOMEM);\n\n\n\n    st->priv_data = sc;\n\n    st->codec->codec_type = AVMEDIA_TYPE_DATA;\n\n    sc->ffindex = st->index;\n\n\n\n    if ((ret = mov_read_default(c, pb, atom)) < 0)\n\n        return ret;\n\n\n\n    /* sanity checks */\n\n    if (sc->chunk_count && (!sc->stts_count || !sc->stsc_count ||\n\n                            (!sc->sample_size && !sc->sample_count))) {\n\n        av_log(c->fc, AV_LOG_ERROR, \"stream %d, missing mandatory atoms, broken header\\n\",\n\n               st->index);\n\n        return 0;\n\n    }\n\n\n\n    fix_timescale(c, sc);\n\n\n\n    avpriv_set_pts_info(st, 64, 1, sc->time_scale);\n\n\n\n    mov_build_index(c, st);\n\n\n\n    if (sc->dref_id-1 < sc->drefs_count && sc->drefs[sc->dref_id-1].path) {\n\n        MOVDref *dref = &sc->drefs[sc->dref_id - 1];\n\n        if (mov_open_dref(&sc->pb, c->fc->filename, dref, &c->fc->interrupt_callback,\n\n            c->use_absolute_path, c->fc) < 0)\n\n            av_log(c->fc, AV_LOG_ERROR,\n\n                   \"stream %d, error opening alias: path='%s', dir='%s', \"\n\n                   \"filename='%s', volume='%s', nlvl_from=%d, nlvl_to=%d\\n\",\n\n                   st->index, dref->path, dref->dir, dref->filename,\n\n                   dref->volume, dref->nlvl_from, dref->nlvl_to);\n\n    } else {\n\n        sc->pb = c->fc->pb;\n\n        sc->pb_is_copied = 1;\n\n    }\n\n\n\n    if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n        if (!st->sample_aspect_ratio.num &&\n\n            (st->codec->width != sc->width || st->codec->height != sc->height)) {\n\n            st->sample_aspect_ratio = av_d2q(((double)st->codec->height * sc->width) /\n\n                                             ((double)st->codec->width * sc->height), INT_MAX);\n\n        }\n\n\n\n#if FF_API_R_FRAME_RATE\n\n        if (sc->stts_count == 1 || (sc->stts_count == 2 && sc->stts_data[1].count == 1))\n\n            av_reduce(&st->r_frame_rate.num, &st->r_frame_rate.den,\n\n                      sc->time_scale, sc->stts_data[0].duration, INT_MAX);\n\n#endif\n\n    }\n\n\n\n    // done for ai5q, ai52, ai55, ai1q, ai12 and ai15.\n\n    if (!st->codec->extradata_size && st->codec->codec_id == AV_CODEC_ID_H264 &&\n\n        TAG_IS_AVCI(st->codec->codec_tag)) {\n\n        ret = ff_generate_avci_extradata(st);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n\n\n    switch (st->codec->codec_id) {\n\n#if CONFIG_H261_DECODER\n\n    case AV_CODEC_ID_H261:\n\n#endif\n\n#if CONFIG_H263_DECODER\n\n    case AV_CODEC_ID_H263:\n\n#endif\n\n#if CONFIG_MPEG4_DECODER\n\n    case AV_CODEC_ID_MPEG4:\n\n#endif\n\n        st->codec->width = 0; /* let decoder init width/height */\n\n        st->codec->height= 0;\n\n        break;\n\n    }\n\n\n\n    /* Do not need those anymore. */\n\n    av_freep(&sc->chunk_offsets);\n\n    av_freep(&sc->stsc_data);\n\n    av_freep(&sc->sample_sizes);\n\n    av_freep(&sc->keyframes);\n\n    av_freep(&sc->stts_data);\n\n    av_freep(&sc->stps_data);\n\n    av_freep(&sc->elst_data);\n\n    av_freep(&sc->rap_group);\n\n\n\n    return 0;\n\n}\n", "idx": 13024, "_split": "test", "_hash": "58bb9cb38424ccd4d1659ed9452f1b16"}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "void h263_encode_init(MpegEncContext *s)\n\n{\n\n    static int done = 0;\n\n\n\n    if (!done) {\n\n        done = 1;\n\n\n\n        init_uni_dc_tab();\n\n\n\n        init_rl(&rl_inter);\n\n        init_rl(&rl_intra);\n\n        init_rl(&rl_intra_aic);\n\n        \n\n        init_uni_mpeg4_rl_tab(&rl_intra, uni_mpeg4_intra_rl_bits, uni_mpeg4_intra_rl_len);\n\n        init_uni_mpeg4_rl_tab(&rl_inter, uni_mpeg4_inter_rl_bits, uni_mpeg4_inter_rl_len);\n\n\n\n        init_uni_h263_rl_tab(&rl_intra_aic, NULL, uni_h263_intra_aic_rl_len);\n\n        init_uni_h263_rl_tab(&rl_inter    , NULL, uni_h263_inter_rl_len);\n\n\n\n        init_mv_penalty_and_fcode(s);\n\n    }\n\n    s->me.mv_penalty= mv_penalty; //FIXME exact table for msmpeg4 & h263p\n\n    \n\n    s->intra_ac_vlc_length     =s->inter_ac_vlc_length     = uni_h263_inter_rl_len;\n\n    s->intra_ac_vlc_last_length=s->inter_ac_vlc_last_length= uni_h263_inter_rl_len + 128*64;\n\n    if(s->h263_aic){\n\n        s->intra_ac_vlc_length     = uni_h263_intra_aic_rl_len;\n\n        s->intra_ac_vlc_last_length= uni_h263_intra_aic_rl_len + 128*64;\n\n    }\n\n    s->ac_esc_length= 7+1+6+8;\n\n\n\n    // use fcodes >1 only for mpeg4 & h263 & h263p FIXME\n\n    switch(s->codec_id){\n\n    case CODEC_ID_MPEG4:\n\n        s->fcode_tab= fcode_tab;\n\n        s->min_qcoeff= -2048;\n\n        s->max_qcoeff=  2047;\n\n        s->intra_ac_vlc_length     = uni_mpeg4_intra_rl_len;\n\n        s->intra_ac_vlc_last_length= uni_mpeg4_intra_rl_len + 128*64;\n\n        s->inter_ac_vlc_length     = uni_mpeg4_inter_rl_len;\n\n        s->inter_ac_vlc_last_length= uni_mpeg4_inter_rl_len + 128*64;\n\n        s->luma_dc_vlc_length= uni_DCtab_lum_len;\n\n        s->chroma_dc_vlc_length= uni_DCtab_chrom_len;\n\n        s->ac_esc_length= 7+2+1+6+1+12+1;\n\n        s->y_dc_scale_table= ff_mpeg4_y_dc_scale_table;\n\n        s->c_dc_scale_table= ff_mpeg4_c_dc_scale_table;\n\n\n\n        if(s->flags & CODEC_FLAG_GLOBAL_HEADER){\n\n\n\n            s->avctx->extradata= av_malloc(1024);\n\n            init_put_bits(&s->pb, s->avctx->extradata, 1024);\n\n            \n\n            mpeg4_encode_visual_object_header(s);\n\n            mpeg4_encode_vol_header(s, 0, 0);\n\n\n\n//            ff_mpeg4_stuffing(&s->pb); ?\n\n            flush_put_bits(&s->pb);\n\n            s->avctx->extradata_size= (put_bits_count(&s->pb)+7)>>3;\n\n        }\n\n        \n\n        break;\n\n    case CODEC_ID_H263P:\n\n        if(s->umvplus)\n\n            s->fcode_tab= umv_fcode_tab;\n\n        if(s->modified_quant){\n\n            s->min_qcoeff= -2047;\n\n            s->max_qcoeff=  2047;\n\n        }else{\n\n            s->min_qcoeff= -127;\n\n            s->max_qcoeff=  127;\n\n        }\n\n        break;\n\n        //Note for mpeg4 & h263 the dc-scale table will be set per frame as needed later \n\n    case CODEC_ID_FLV1:\n\n        if (s->h263_flv > 1) {\n\n            s->min_qcoeff= -1023;\n\n            s->max_qcoeff=  1023;\n\n        } else {\n\n            s->min_qcoeff= -127;\n\n            s->max_qcoeff=  127;\n\n        }\n\n        s->y_dc_scale_table=\n\n        s->c_dc_scale_table= ff_mpeg1_dc_scale_table;\n\n        break;\n\n    default: //nothing needed default table allready set in mpegvideo.c\n\n        s->min_qcoeff= -127;\n\n        s->max_qcoeff=  127;\n\n        s->y_dc_scale_table=\n\n        s->c_dc_scale_table= ff_mpeg1_dc_scale_table;\n\n    }\n\n}\n", "idx": 13040, "_split": "test", "_hash": "f01086c15e708291522afea5d7e2c092"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(vu9_to_vu12)(const uint8_t *src1, const uint8_t *src2,\n\n\t\t\tuint8_t *dst1, uint8_t *dst2,\n\n\t\t\tlong width, long height,\n\n\t\t\tlong srcStride1, long srcStride2,\n\n\t\t\tlong dstStride1, long dstStride2)\n\n{\n\n    long y,x,w,h;\n\n    w=width/2; h=height/2;\n\n#ifdef HAVE_MMX\n\n    asm volatile(\n\n\tPREFETCH\" %0\\n\\t\"\n\n\tPREFETCH\" %1\\n\\t\"\n\n\t::\"m\"(*(src1+srcStride1)),\"m\"(*(src2+srcStride2)):\"memory\");\n\n#endif\n\n    for(y=0;y<h;y++){\n\n\tconst uint8_t* s1=src1+srcStride1*(y>>1);\n\n\tuint8_t* d=dst1+dstStride1*y;\n\n\tx=0;\n\n#ifdef HAVE_MMX\n\n\tfor(;x<w-31;x+=32)\n\n\t{\n\n\t    asm volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t        \"movq\t%1, %%mm0\\n\\t\"\n\n\t        \"movq\t8%1, %%mm2\\n\\t\"\n\n\t        \"movq\t16%1, %%mm4\\n\\t\"\n\n\t        \"movq\t24%1, %%mm6\\n\\t\"\n\n\t        \"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t        \"movq\t%%mm2, %%mm3\\n\\t\"\n\n\t        \"movq\t%%mm4, %%mm5\\n\\t\"\n\n\t        \"movq\t%%mm6, %%mm7\\n\\t\"\n\n\t\t\"punpcklbw %%mm0, %%mm0\\n\\t\"\n\n\t\t\"punpckhbw %%mm1, %%mm1\\n\\t\"\n\n\t\t\"punpcklbw %%mm2, %%mm2\\n\\t\"\n\n\t\t\"punpckhbw %%mm3, %%mm3\\n\\t\"\n\n\t\t\"punpcklbw %%mm4, %%mm4\\n\\t\"\n\n\t\t\"punpckhbw %%mm5, %%mm5\\n\\t\"\n\n\t\t\"punpcklbw %%mm6, %%mm6\\n\\t\"\n\n\t\t\"punpckhbw %%mm7, %%mm7\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm1, 8%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm2, 16%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm3, 24%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm4, 32%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm5, 40%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm6, 48%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm7, 56%0\"\n\n\t\t:\"=m\"(d[2*x])\n\n\t\t:\"m\"(s1[x])\n\n\t\t:\"memory\");\n\n\t}\n\n#endif\n\n\tfor(;x<w;x++) d[2*x]=d[2*x+1]=s1[x];\n\n    }\n\n    for(y=0;y<h;y++){\n\n\tconst uint8_t* s2=src2+srcStride2*(y>>1);\n\n\tuint8_t* d=dst2+dstStride2*y;\n\n\tx=0;\n\n#ifdef HAVE_MMX\n\n\tfor(;x<w-31;x+=32)\n\n\t{\n\n\t    asm volatile(\n\n\t\tPREFETCH\" 32%1\\n\\t\"\n\n\t        \"movq\t%1, %%mm0\\n\\t\"\n\n\t        \"movq\t8%1, %%mm2\\n\\t\"\n\n\t        \"movq\t16%1, %%mm4\\n\\t\"\n\n\t        \"movq\t24%1, %%mm6\\n\\t\"\n\n\t        \"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t        \"movq\t%%mm2, %%mm3\\n\\t\"\n\n\t        \"movq\t%%mm4, %%mm5\\n\\t\"\n\n\t        \"movq\t%%mm6, %%mm7\\n\\t\"\n\n\t\t\"punpcklbw %%mm0, %%mm0\\n\\t\"\n\n\t\t\"punpckhbw %%mm1, %%mm1\\n\\t\"\n\n\t\t\"punpcklbw %%mm2, %%mm2\\n\\t\"\n\n\t\t\"punpckhbw %%mm3, %%mm3\\n\\t\"\n\n\t\t\"punpcklbw %%mm4, %%mm4\\n\\t\"\n\n\t\t\"punpckhbw %%mm5, %%mm5\\n\\t\"\n\n\t\t\"punpcklbw %%mm6, %%mm6\\n\\t\"\n\n\t\t\"punpckhbw %%mm7, %%mm7\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm1, 8%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm2, 16%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm3, 24%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm4, 32%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm5, 40%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm6, 48%0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm7, 56%0\"\n\n\t\t:\"=m\"(d[2*x])\n\n\t\t:\"m\"(s2[x])\n\n\t\t:\"memory\");\n\n\t}\n\n#endif\n\n\tfor(;x<w;x++) d[2*x]=d[2*x+1]=s2[x];\n\n    }\n\n#ifdef HAVE_MMX\n\n\tasm(\n\n\t\tEMMS\" \\n\\t\"\n\n\t\tSFENCE\" \\n\\t\"\n\n\t\t::: \"memory\"\n\n\t\t);\n\n#endif\n\n}\n", "idx": 13068, "_split": "test", "_hash": "a87e74fb9d4251767b7592ef3b3e0e11"}
{"project": "FFmpeg", "commit_id": "caa845851d790f894a2ccbe12580934f75545f92", "target": 0, "func": "static int output_data_internal(MLPDecodeContext *m, unsigned int substr,\n\n                                uint8_t *data, unsigned int *data_size, int is32)\n\n{\n\n    SubStream *s = &m->substream[substr];\n\n    unsigned int i, out_ch = 0;\n\n    int32_t *data_32 = (int32_t*) data;\n\n    int16_t *data_16 = (int16_t*) data;\n\n\n\n    if (*data_size < (s->max_channel + 1) * s->blockpos * (is32 ? 4 : 2))\n\n        return -1;\n\n\n\n    for (i = 0; i < s->blockpos; i++) {\n\n        for (out_ch = 0; out_ch <= s->max_matrix_channel; out_ch++) {\n\n            int mat_ch = s->ch_assign[out_ch];\n\n            int32_t sample = m->sample_buffer[i][mat_ch]\n\n                          << s->output_shift[mat_ch];\n\n            s->lossless_check_data ^= (sample & 0xffffff) << mat_ch;\n\n            if (is32) *data_32++ = sample << 8;\n\n            else      *data_16++ = sample >> 8;\n\n        }\n\n    }\n\n\n\n    *data_size = i * out_ch * (is32 ? 4 : 2);\n\n\n\n    return 0;\n\n}\n", "idx": 13081, "_split": "test", "_hash": "7d327f5d1b72ac07ce1be33c11803e32"}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "inline static void RENAME(hcscale)(SwsContext *c, uint16_t *dst, int dstWidth, const uint8_t *src1, const uint8_t *src2,\n\n                                   int srcW, int xInc, const int16_t *hChrFilter,\n\n                                   const int16_t *hChrFilterPos, int hChrFilterSize,\n\n                                   uint8_t *formatConvBuffer,\n\n                                   uint32_t *pal)\n\n{\n\n\n\n    src1 += c->chrSrcOffset;\n\n    src2 += c->chrSrcOffset;\n\n\n\n    if (c->chrToYV12) {\n\n        c->chrToYV12(formatConvBuffer, formatConvBuffer+VOFW, src1, src2, srcW, pal);\n\n        src1= formatConvBuffer;\n\n        src2= formatConvBuffer+VOFW;\n\n    }\n\n\n\n    if (!c->hcscale_fast) {\n\n        c->hScale(dst     , dstWidth, src1, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n        c->hScale(dst+VOFW, dstWidth, src2, srcW, xInc, hChrFilter, hChrFilterPos, hChrFilterSize);\n\n    } else { // fast bilinear upscale / crap downscale\n\n        c->hcscale_fast(c, dst, dstWidth, src1, src2, srcW, xInc);\n\n    }\n\n\n\n    if (c->chrConvertRange)\n\n        c->chrConvertRange(dst, dstWidth);\n\n}\n", "idx": 13100, "_split": "test", "_hash": "31688e0504a54b5164fada7fa8c2b11b"}
{"project": "FFmpeg", "commit_id": "662234a9a22f1cd0f0ac83b8bb1ffadedca90c0a", "target": 0, "func": "static void avc_luma_midv_qrt_4w_msa(const uint8_t *src, int32_t src_stride,\n\n                                     uint8_t *dst, int32_t dst_stride,\n\n                                     int32_t height, uint8_t ver_offset)\n\n{\n\n    uint32_t loop_cnt;\n\n    v16i8 src0, src1, src2, src3, src4;\n\n    v16i8 mask0, mask1, mask2;\n\n    v8i16 hz_out0, hz_out1, hz_out2, hz_out3;\n\n    v8i16 hz_out4, hz_out5, hz_out6, hz_out7, hz_out8;\n\n    v8i16 dst0, dst1, dst2, dst3, dst4, dst5, dst6, dst7;\n\n\n\n    LD_SB3(&luma_mask_arr[48], 16, mask0, mask1, mask2);\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n\n\n    hz_out0 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src0, src1,\n\n                                                          mask0, mask1, mask2);\n\n    hz_out2 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src2, src3,\n\n                                                          mask0, mask1, mask2);\n\n\n\n    PCKOD_D2_SH(hz_out0, hz_out0, hz_out2, hz_out2, hz_out1, hz_out3);\n\n\n\n    hz_out4 = AVC_HORZ_FILTER_SH(src4, mask0, mask1, mask2);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src, src_stride, src0, src1, src2, src3);\n\n        src += (4 * src_stride);\n\n        XORI_B4_128_SB(src0, src1, src2, src3);\n\n\n\n        hz_out5 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src0, src1,\n\n                                                              mask0, mask1,\n\n                                                              mask2);\n\n        hz_out7 = AVC_XOR_VSHF_B_AND_APPLY_6TAP_HORIZ_FILT_SH(src2, src3,\n\n                                                              mask0, mask1,\n\n                                                              mask2);\n\n\n\n        PCKOD_D2_SH(hz_out5, hz_out5, hz_out7, hz_out7, hz_out6, hz_out8);\n\n\n\n        dst0 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out0, hz_out1, hz_out2,\n\n                                               hz_out3, hz_out4, hz_out5);\n\n        dst2 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out1, hz_out2, hz_out3,\n\n                                               hz_out4, hz_out5, hz_out6);\n\n        dst4 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out2, hz_out3, hz_out4,\n\n                                               hz_out5, hz_out6, hz_out7);\n\n        dst6 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out3, hz_out4, hz_out5,\n\n                                               hz_out6, hz_out7, hz_out8);\n\n\n\n        if (ver_offset) {\n\n            dst1 = __msa_srari_h(hz_out3, 5);\n\n            dst3 = __msa_srari_h(hz_out4, 5);\n\n            dst5 = __msa_srari_h(hz_out5, 5);\n\n            dst7 = __msa_srari_h(hz_out6, 5);\n\n        } else {\n\n            dst1 = __msa_srari_h(hz_out2, 5);\n\n            dst3 = __msa_srari_h(hz_out3, 5);\n\n            dst5 = __msa_srari_h(hz_out4, 5);\n\n            dst7 = __msa_srari_h(hz_out5, 5);\n\n        }\n\n\n\n        SAT_SH4_SH(dst1, dst3, dst5, dst7, 7);\n\n\n\n        dst0 = __msa_aver_s_h(dst0, dst1);\n\n        dst1 = __msa_aver_s_h(dst2, dst3);\n\n        dst2 = __msa_aver_s_h(dst4, dst5);\n\n        dst3 = __msa_aver_s_h(dst6, dst7);\n\n\n\n        PCKEV_B2_SB(dst1, dst0, dst3, dst2, src0, src1);\n\n        XORI_B2_128_SB(src0, src1);\n\n\n\n        ST4x4_UB(src0, src1, 0, 2, 0, 2, dst, dst_stride);\n\n\n\n        dst += (4 * dst_stride);\n\n        hz_out0 = hz_out4;\n\n        hz_out1 = hz_out5;\n\n        hz_out2 = hz_out6;\n\n        hz_out3 = hz_out7;\n\n        hz_out4 = hz_out8;\n\n    }\n\n}\n", "idx": 13137, "_split": "test", "_hash": "54e51be703fde6077248ddcee3170f57"}
{"project": "FFmpeg", "commit_id": "2df0c32ea12ddfa72ba88309812bfb13b674130f", "target": 0, "func": "static int amr_nb_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                               const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    AMRContext *s = avctx->priv_data;\n\n    int written, ret;\n\n    int16_t *flush_buf = NULL;\n\n    const int16_t *samples = frame ? (const int16_t *)frame->data[0] : NULL;\n\n\n\n    if (s->enc_bitrate != avctx->bit_rate) {\n\n        s->enc_mode    = get_bitrate_mode(avctx->bit_rate, avctx);\n\n        s->enc_bitrate = avctx->bit_rate;\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet(avpkt, 32))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n\n        return ret;\n\n    }\n\n\n\n    if (frame) {\n\n        if (frame->nb_samples < avctx->frame_size) {\n\n            flush_buf = av_mallocz(avctx->frame_size * sizeof(*flush_buf));\n\n            if (!flush_buf)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(flush_buf, samples, frame->nb_samples * sizeof(*flush_buf));\n\n            samples = flush_buf;\n\n            if (frame->nb_samples < avctx->frame_size - avctx->delay)\n\n                s->enc_last_frame = -1;\n\n        }\n\n        if ((ret = ff_af_queue_add(&s->afq, frame)) < 0) {\n\n            av_freep(&flush_buf);\n\n            return ret;\n\n        }\n\n    } else {\n\n        if (s->enc_last_frame < 0)\n\n            return 0;\n\n        flush_buf = av_mallocz(avctx->frame_size * sizeof(*flush_buf));\n\n        if (!flush_buf)\n\n            return AVERROR(ENOMEM);\n\n        samples = flush_buf;\n\n        s->enc_last_frame = -1;\n\n    }\n\n\n\n    written = Encoder_Interface_Encode(s->enc_state, s->enc_mode, samples,\n\n                                       avpkt->data, 0);\n\n    av_dlog(avctx, \"amr_nb_encode_frame encoded %u bytes, bitrate %u, first byte was %#02x\\n\",\n\n            written, s->enc_mode, frame[0]);\n\n\n\n    /* Get the next frame pts/duration */\n\n    ff_af_queue_remove(&s->afq, avctx->frame_size, &avpkt->pts,\n\n                       &avpkt->duration);\n\n\n\n    avpkt->size = written;\n\n    *got_packet_ptr = 1;\n\n    av_freep(&flush_buf);\n\n    return 0;\n\n}\n", "idx": 13163, "_split": "test", "_hash": "175a4bbb6fa9a7836058c627b8c64d3d"}
{"project": "FFmpeg", "commit_id": "9340a99588c2bf6209b5c396df15b893c4b576b5", "target": 1, "func": "static int RENAME(swScale)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,\n\n             int srcSliceH, uint8_t* dst[], int dstStride[]){\n\n\n\n\t/* load a few things into local vars to make the code more readable? and faster */\n\n\tconst int srcW= c->srcW;\n\n\tconst int dstW= c->dstW;\n\n\tconst int dstH= c->dstH;\n\n\tconst int chrDstW= c->chrDstW;\n\n\tconst int chrSrcW= c->chrSrcW;\n\n\tconst int lumXInc= c->lumXInc;\n\n\tconst int chrXInc= c->chrXInc;\n\n\tconst int dstFormat= c->dstFormat;\n\n\tconst int srcFormat= c->srcFormat;\n\n\tconst int flags= c->flags;\n\n\tconst int canMMX2BeUsed= c->canMMX2BeUsed;\n\n\tint16_t *vLumFilterPos= c->vLumFilterPos;\n\n\tint16_t *vChrFilterPos= c->vChrFilterPos;\n\n\tint16_t *hLumFilterPos= c->hLumFilterPos;\n\n\tint16_t *hChrFilterPos= c->hChrFilterPos;\n\n\tint16_t *vLumFilter= c->vLumFilter;\n\n\tint16_t *vChrFilter= c->vChrFilter;\n\n\tint16_t *hLumFilter= c->hLumFilter;\n\n\tint16_t *hChrFilter= c->hChrFilter;\n\n\tint32_t *lumMmxFilter= c->lumMmxFilter;\n\n\tint32_t *chrMmxFilter= c->chrMmxFilter;\n\n\tconst int vLumFilterSize= c->vLumFilterSize;\n\n\tconst int vChrFilterSize= c->vChrFilterSize;\n\n\tconst int hLumFilterSize= c->hLumFilterSize;\n\n\tconst int hChrFilterSize= c->hChrFilterSize;\n\n\tint16_t **lumPixBuf= c->lumPixBuf;\n\n\tint16_t **chrPixBuf= c->chrPixBuf;\n\n\tconst int vLumBufSize= c->vLumBufSize;\n\n\tconst int vChrBufSize= c->vChrBufSize;\n\n\tuint8_t *funnyYCode= c->funnyYCode;\n\n\tuint8_t *funnyUVCode= c->funnyUVCode;\n\n\tuint8_t *formatConvBuffer= c->formatConvBuffer;\n\n\tconst int chrSrcSliceY= srcSliceY >> c->chrSrcVSubSample;\n\n\tconst int chrSrcSliceH= -((-srcSliceH) >> c->chrSrcVSubSample);\n\n\tint lastDstY;\n\n        uint8_t *pal=NULL;\n\n\n\n\t/* vars whch will change and which we need to storw back in the context */\n\n\tint dstY= c->dstY;\n\n\tint lumBufIndex= c->lumBufIndex;\n\n\tint chrBufIndex= c->chrBufIndex;\n\n\tint lastInLumBuf= c->lastInLumBuf;\n\n\tint lastInChrBuf= c->lastInChrBuf;\n\n\t\n\n\tif(isPacked(c->srcFormat)){\n\n                pal= src[1];\n\n\t\tsrc[0]=\n\n\t\tsrc[1]=\n\n\t\tsrc[2]= src[0];\n\n\t\tsrcStride[0]=\n\n\t\tsrcStride[1]=\n\n\t\tsrcStride[2]= srcStride[0];\n\n\t}\n\n\tsrcStride[1]<<= c->vChrDrop;\n\n\tsrcStride[2]<<= c->vChrDrop;\n\n\n\n//\tprintf(\"swscale %X %X %X -> %X %X %X\\n\", (int)src[0], (int)src[1], (int)src[2],\n\n//\t\t(int)dst[0], (int)dst[1], (int)dst[2]);\n\n\n\n#if 0 //self test FIXME move to a vfilter or something\n\n{\n\nstatic volatile int i=0;\n\ni++;\n\nif(srcFormat==PIX_FMT_YUV420P && i==1 && srcSliceH>= c->srcH)\n\n\tselfTest(src, srcStride, c->srcW, c->srcH);\n\ni--;\n\n}\n\n#endif\n\n\n\n//printf(\"sws Strides:%d %d %d -> %d %d %d\\n\", srcStride[0],srcStride[1],srcStride[2],\n\n//dstStride[0],dstStride[1],dstStride[2]);\n\n\n\n\tif(dstStride[0]%8 !=0 || dstStride[1]%8 !=0 || dstStride[2]%8 !=0)\n\n\t{\n\n\t\tstatic int firstTime=1; //FIXME move this into the context perhaps\n\n\t\tif(flags & SWS_PRINT_INFO && firstTime)\n\n\t\t{\n\n\t\t\tav_log(c, AV_LOG_WARNING, \"SwScaler: Warning: dstStride is not aligned!\\n\"\n\n\t\t\t\t\t\"SwScaler:          ->cannot do aligned memory acesses anymore\\n\");\n\n\t\t\tfirstTime=0;\n\n\t\t}\n\n\t}\n\n\n\n\t/* Note the user might start scaling the picture in the middle so this will not get executed\n\n\t   this is not really intended but works currently, so ppl might do it */\n\n\tif(srcSliceY ==0){\n\n\t\tlumBufIndex=0;\n\n\t\tchrBufIndex=0;\n\n\t\tdstY=0;\t\n\n\t\tlastInLumBuf= -1;\n\n\t\tlastInChrBuf= -1;\n\n\t}\n\n\n\n\tlastDstY= dstY;\n\n\n\n\tfor(;dstY < dstH; dstY++){\n\n\t\tunsigned char *dest =dst[0]+dstStride[0]*dstY;\n\n\t\tconst int chrDstY= dstY>>c->chrDstVSubSample;\n\n\t\tunsigned char *uDest=dst[1]+dstStride[1]*chrDstY;\n\n\t\tunsigned char *vDest=dst[2]+dstStride[2]*chrDstY;\n\n\n\n\t\tconst int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n\t\tconst int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n\t\tconst int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n\t\tconst int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n\n\n//printf(\"dstY:%d dstH:%d firstLumSrcY:%d lastInLumBuf:%d vLumBufSize: %d vChrBufSize: %d slice: %d %d vLumFilterSize: %d firstChrSrcY: %d vChrFilterSize: %d c->chrSrcVSubSample: %d\\n\",\n\n// dstY, dstH, firstLumSrcY, lastInLumBuf, vLumBufSize, vChrBufSize, srcSliceY, srcSliceH, vLumFilterSize, firstChrSrcY, vChrFilterSize,  c->chrSrcVSubSample);\n\n\t\t//handle holes (FAST_BILINEAR & weird filters)\n\n\t\tif(firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n\t\tif(firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n//printf(\"%d %d %d\\n\", firstChrSrcY, lastInChrBuf, vChrBufSize);\n\n\t\tASSERT(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1)\n\n\t\tASSERT(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1)\n\n\n\n\t\t// Do we have enough lines in this slice to output the dstY line\n\n\t\tif(lastLumSrcY < srcSliceY + srcSliceH && lastChrSrcY < -((-srcSliceY - srcSliceH)>>c->chrSrcVSubSample))\n\n\t\t{\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf < lastLumSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *s= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n\t\t\t\tlumBufIndex++;\n\n//\t\t\t\tprintf(\"%d %d %d %d\\n\", lumBufIndex, vLumBufSize, lastInLumBuf,  lastLumSrcY);\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n//\t\t\t\tprintf(\"%d %d\\n\", lumBufIndex, vLumBufSize);\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, s, srcW, lumXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n\t\t\t\t\t\tfunnyYCode, c->srcFormat, formatConvBuffer, \n\n\t\t\t\t\t\tc->lumMmx2Filter, c->lumMmx2FilterPos, pal);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf < lastChrSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= src[1]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[1];\n\n\t\t\t\tuint8_t *src2= src[2]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - chrSrcSliceY < (chrSrcSliceH))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - chrSrcSliceY >= 0)\n\n\t\t\t\t//FIXME replace parameters through context struct (some at least)\n\n\n\n\t\t\t\tif(!(isGray(srcFormat) || isGray(dstFormat)))\n\n\t\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, chrSrcW, chrXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hChrFilter, hChrFilterPos, hChrFilterSize,\n\n\t\t\t\t\t\tfunnyUVCode, c->srcFormat, formatConvBuffer, \n\n\t\t\t\t\t\tc->chrMmx2Filter, c->chrMmx2FilterPos, pal);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t}\n\n\t\telse // not enough lines left in this slice -> load the rest in the buffer\n\n\t\t{\n\n/*\t\tprintf(\"%d %d Last:%d %d LastInBuf:%d %d Index:%d %d Y:%d FSize: %d %d BSize: %d %d\\n\",\n\n\t\t\tfirstChrSrcY,firstLumSrcY,lastChrSrcY,lastLumSrcY,\n\n\t\t\tlastInChrBuf,lastInLumBuf,chrBufIndex,lumBufIndex,dstY,vChrFilterSize,vLumFilterSize,\n\n\t\t\tvChrBufSize, vLumBufSize);*/\n\n\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf+1 < srcSliceY + srcSliceH)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *s= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n\t\t\t\tlumBufIndex++;\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, s, srcW, lumXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n\t\t\t\t\t\tfunnyYCode, c->srcFormat, formatConvBuffer, \n\n\t\t\t\t\t\tc->lumMmx2Filter, c->lumMmx2FilterPos, pal);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf+1 < (chrSrcSliceY + chrSrcSliceH))\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= src[1]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[1];\n\n\t\t\t\tuint8_t *src2= src[2]+(lastInChrBuf + 1 - chrSrcSliceY)*srcStride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - chrSrcSliceY < chrSrcSliceH)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - chrSrcSliceY >= 0)\n\n\n\n\t\t\t\tif(!(isGray(srcFormat) || isGray(dstFormat)))\n\n\t\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, chrSrcW, chrXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hChrFilter, hChrFilterPos, hChrFilterSize,\n\n\t\t\t\t\t\tfunnyUVCode, c->srcFormat, formatConvBuffer, \n\n\t\t\t\t\t\tc->chrMmx2Filter, c->chrMmx2FilterPos, pal);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t\tbreak; //we can't output a dstY line so let's try with the next slice\n\n\t\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t\tb5Dither= dither8[dstY&1];\n\n\t\tg6Dither= dither4[dstY&1];\n\n\t\tg5Dither= dither8[dstY&1];\n\n\t\tr5Dither= dither8[(dstY+1)&1];\n\n#endif\n\n\t    if(dstY < dstH-2)\n\n\t    {\n\n\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n#ifdef HAVE_MMX\n\n\t\tint i;\n\n            if(flags & SWS_ACCURATE_RND){\n\n                        for(i=0; i<vLumFilterSize; i+=2){\n\n                                lumMmxFilter[2*i+0]= (int32_t)lumSrcPtr[i  ];\n\n                                lumMmxFilter[2*i+1]= (int32_t)lumSrcPtr[i+(vLumFilterSize>1)];\n\n                                lumMmxFilter[2*i+2]=\n\n                                lumMmxFilter[2*i+3]= vLumFilter[dstY*vLumFilterSize + i    ]\n\n                                                + (vLumFilterSize>1 ? vLumFilter[dstY*vLumFilterSize + i + 1]<<16 : 0);\n\n                        }\n\n                        for(i=0; i<vChrFilterSize; i+=2){\n\n                                chrMmxFilter[2*i+0]= (int32_t)chrSrcPtr[i  ];\n\n                                chrMmxFilter[2*i+1]= (int32_t)chrSrcPtr[i+(vChrFilterSize>1)];\n\n                                chrMmxFilter[2*i+2]=\n\n                                chrMmxFilter[2*i+3]= vChrFilter[chrDstY*vChrFilterSize + i    ]\n\n                                                + (vChrFilterSize>1 ? vChrFilter[chrDstY*vChrFilterSize + i + 1]<<16 : 0);\n\n                        }\n\n            }else{\n\n\t\tfor(i=0; i<vLumFilterSize; i++)\n\n\t\t{\n\n\t\t\tlumMmxFilter[4*i+0]= (int32_t)lumSrcPtr[i];\n\n\t\t\tlumMmxFilter[4*i+1]= (uint64_t)lumSrcPtr[i] >> 32;\n\n\t\t\tlumMmxFilter[4*i+2]= \n\n\t\t\tlumMmxFilter[4*i+3]= \n\n\t\t\t\t((uint16_t)vLumFilter[dstY*vLumFilterSize + i])*0x10001;\n\n\t\t}\n\n\t\tfor(i=0; i<vChrFilterSize; i++)\n\n\t\t{\n\n\t\t\tchrMmxFilter[4*i+0]= (int32_t)chrSrcPtr[i];\n\n\n\t\t\tchrMmxFilter[4*i+2]= \n\n\t\t\tchrMmxFilter[4*i+3]= \n\n\t\t\t\t((uint16_t)vChrFilter[chrDstY*vChrFilterSize + i])*0x10001;\n\n\t\t}\n\n            }\n\n#endif\n\n\t\tif(dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21){\n\n\t\t\tconst int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n\t\t\tif(dstY&chrSkipMask) uDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tRENAME(yuv2nv12X)(c,\n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, uDest, dstW, chrDstW, dstFormat);\n\n\t\t}\n\n\t\telse if(isPlanarYUV(dstFormat) || isGray(dstFormat)) //YV12 like\n\n\t\t{\n\n\t\t\tconst int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n\t\t\tif((dstY&chrSkipMask) || isGray(dstFormat)) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 1) // Unscaled YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t *lumBuf = lumPixBuf[0];\n\n\t\t\t\tint16_t *chrBuf= chrPixBuf[0];\n\n\t\t\t\tRENAME(yuv2yuv1)(lumBuf, chrBuf, dest, uDest, vDest, dstW, chrDstW);\n\n\t\t\t}\n\n\t\t\telse //General YV12\n\n\t\t\t{\n\n\t\t\t\tRENAME(yuv2yuvX)(c,\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, uDest, vDest, dstW, chrDstW);\n\n\t\t\t}\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 2) //Unscaled RGB\n\n\t\t\t{\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\t\t\t\tRENAME(yuv2packed1)(c, *lumSrcPtr, *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, chrAlpha, dstFormat, flags, dstY);\n\n\t\t\t}\n\n\t\t\telse if(vLumFilterSize == 2 && vChrFilterSize == 2) //BiLinear Upscale RGB\n\n\t\t\t{\n\n\t\t\t\tint lumAlpha= vLumFilter[2*dstY+1];\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n                                lumMmxFilter[2]=\n\n                                lumMmxFilter[3]= vLumFilter[2*dstY   ]*0x10001;\n\n                                chrMmxFilter[2]=\n\n                                chrMmxFilter[3]= vChrFilter[2*chrDstY]*0x10001;\n\n\t\t\t\tRENAME(yuv2packed2)(c, *lumSrcPtr, *(lumSrcPtr+1), *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, lumAlpha, chrAlpha, dstY);\n\n\t\t\t}\n\n\t\t\telse //General RGB\n\n\t\t\t{\n\n\t\t\t\tRENAME(yuv2packedX)(c,\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, dstW, dstY);\n\n\t\t\t}\n\n\t\t}\n\n            }\n\n\t    else // hmm looks like we can't use MMX here without overwriting this array's tail\n\n\t    {\n\n\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\t\tif(dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21){\n\n\t\t\tconst int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n\t\t\tif(dstY&chrSkipMask) uDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tyuv2nv12XinC(\n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, uDest, dstW, chrDstW, dstFormat);\n\n\t\t}\n\n\t\telse if(isPlanarYUV(dstFormat) || isGray(dstFormat)) //YV12\n\n\t\t{\n\n\t\t\tconst int chrSkipMask= (1<<c->chrDstVSubSample)-1;\n\n\t\t\tif((dstY&chrSkipMask) || isGray(dstFormat)) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tyuv2yuvXinC(\n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize   , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+chrDstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, uDest, vDest, dstW, chrDstW);\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tyuv2packedXinC(c, \n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, dstW, dstY);\n\n\t\t}\n\n\t    }\n\n\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\t/* store changed local vars back in the context */\n\n\tc->dstY= dstY;\n\n\tc->lumBufIndex= lumBufIndex;\n\n\tc->chrBufIndex= chrBufIndex;\n\n\tc->lastInLumBuf= lastInLumBuf;\n\n\tc->lastInChrBuf= lastInChrBuf;\n\n\n\n\treturn dstY - lastDstY;\n\n}", "idx": 13204, "_split": "test", "_hash": "ce4f0a6023c4c2a163ed849225a310ae"}
{"project": "FFmpeg", "commit_id": "c3ab0004ae4dffc32494ae84dd15cfaa909a7884", "target": 1, "func": "static inline void RENAME(bgr24ToY)(uint8_t *dst, const uint8_t *src, int width, uint32_t *unused)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    RENAME(bgr24ToY_mmx)(dst, src, width, PIX_FMT_BGR24);\n\n#else\n\n    int i;\n\n    for (i=0; i<width; i++) {\n\n        int b= src[i*3+0];\n\n        int g= src[i*3+1];\n\n        int r= src[i*3+2];\n\n\n\n        dst[i]= ((RY*r + GY*g + BY*b + (33<<(RGB2YUV_SHIFT-1)))>>RGB2YUV_SHIFT);\n\n    }\n\n#endif /* COMPILE_TEMPLATE_MMX */\n\n}\n", "idx": 13205, "_split": "test", "_hash": "a399fcd312b793e770bc287d5524073c"}
{"project": "FFmpeg", "commit_id": "f78cd0c243b9149c7f604ecf1006d78e344aa6ca", "target": 1, "func": "void FUNC(ff_simple_idct)(DCTELEM *block)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 8; i++)\n\n        FUNC(idctRowCondDC)(block + i*8);\n\n\n\n    for (i = 0; i < 8; i++)\n\n        FUNC(idctSparseCol)(block + i);\n\n}\n", "idx": 13230, "_split": "test", "_hash": "e33344089d5abcfc1c288855937879bc"}
{"project": "FFmpeg", "commit_id": "fd0f45e58b010c0d7049914a392c3e96a2223107", "target": 1, "func": "static int av_encode(AVFormatContext **output_files,\n\n                     int nb_output_files,\n\n                     AVFormatContext **input_files,\n\n                     int nb_input_files,\n\n                     AVStreamMap *stream_maps, int nb_stream_maps)\n\n{\n\n    int ret, i, j, k, n, nb_istreams = 0, nb_ostreams = 0;\n\n    AVFormatContext *is, *os;\n\n    AVCodecContext *codec, *icodec;\n\n    AVOutputStream *ost, **ost_table = NULL;\n\n    AVInputStream *ist, **ist_table = NULL;\n\n    AVInputFile *file_table;\n\n    AVFormatContext *stream_no_data;\n\n    int key;\n\n\n\n    file_table= (AVInputFile*) av_mallocz(nb_input_files * sizeof(AVInputFile));\n\n    if (!file_table)\n\n        goto fail;\n\n\n\n    /* input stream init */\n\n    j = 0;\n\n    for(i=0;i<nb_input_files;i++) {\n\n        is = input_files[i];\n\n        file_table[i].ist_index = j;\n\n        file_table[i].nb_streams = is->nb_streams;\n\n        j += is->nb_streams;\n\n    }\n\n    nb_istreams = j;\n\n\n\n    ist_table = av_mallocz(nb_istreams * sizeof(AVInputStream *));\n\n    if (!ist_table)\n\n        goto fail;\n\n    \n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = av_mallocz(sizeof(AVInputStream));\n\n        if (!ist)\n\n            goto fail;\n\n        ist_table[i] = ist;\n\n    }\n\n    j = 0;\n\n    for(i=0;i<nb_input_files;i++) {\n\n        is = input_files[i];\n\n        for(k=0;k<is->nb_streams;k++) {\n\n            ist = ist_table[j++];\n\n            ist->st = is->streams[k];\n\n            ist->file_index = i;\n\n            ist->index = k;\n\n            ist->discard = 1; /* the stream is discarded by default\n\n                                 (changed later) */\n\n\n\n            if (ist->st->codec.rate_emu) {\n\n                ist->start = av_gettime();\n\n                ist->frame = 0;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* output stream init */\n\n    nb_ostreams = 0;\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        nb_ostreams += os->nb_streams;\n\n    }\n\n    if (nb_stream_maps > 0 && nb_stream_maps != nb_ostreams) {\n\n        fprintf(stderr, \"Number of stream maps must match number of output streams\\n\");\n\n        exit(1);\n\n    }\n\n\n\n    /* Sanity check the mapping args -- do the input files & streams exist? */\n\n    for(i=0;i<nb_stream_maps;i++) {\n\n        int fi = stream_maps[i].file_index;\n\n        int si = stream_maps[i].stream_index;\n\n        \n\n        if (fi < 0 || fi > nb_input_files - 1 ||\n\n            si < 0 || si > file_table[fi].nb_streams - 1) {\n\n            fprintf(stderr,\"Could not find input stream #%d.%d\\n\", fi, si);\n\n            exit(1);\n\n        }\n\n    }\n\n    \n\n    ost_table = av_mallocz(sizeof(AVOutputStream *) * nb_ostreams);\n\n    if (!ost_table)\n\n        goto fail;\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = av_mallocz(sizeof(AVOutputStream));\n\n        if (!ost)\n\n            goto fail;\n\n        ost_table[i] = ost;\n\n    }\n\n    \n\n    n = 0;\n\n    for(k=0;k<nb_output_files;k++) {\n\n        os = output_files[k];\n\n        for(i=0;i<os->nb_streams;i++) {\n\n            int found;\n\n            ost = ost_table[n++];\n\n            ost->file_index = k;\n\n            ost->index = i;\n\n            ost->st = os->streams[i];\n\n            if (nb_stream_maps > 0) {\n\n                ost->source_index = file_table[stream_maps[n-1].file_index].ist_index + \n\n                    stream_maps[n-1].stream_index;\n\n                    \n\n                /* Sanity check that the stream types match */\n\n                if (ist_table[ost->source_index]->st->codec.codec_type != ost->st->codec.codec_type) {\n\n                    fprintf(stderr, \"Codec type mismatch for mapping #%d.%d -> #%d.%d\\n\",\n\n                        stream_maps[n-1].file_index, stream_maps[n-1].stream_index,\n\n                        ost->file_index, ost->index);\n\n                    exit(1);\n\n                }\n\n                \n\n            } else {\n\n                /* get corresponding input stream index : we select the first one with the right type */\n\n                found = 0;\n\n                for(j=0;j<nb_istreams;j++) {\n\n                    ist = ist_table[j];\n\n                    if (ist->discard && \n\n                        ist->st->codec.codec_type == ost->st->codec.codec_type) {\n\n                        ost->source_index = j;\n\n                        found = 1;\n\n                    }\n\n                }\n\n                \n\n                if (!found) {\n\n                    /* try again and reuse existing stream */\n\n                    for(j=0;j<nb_istreams;j++) {\n\n                        ist = ist_table[j];\n\n                        if (ist->st->codec.codec_type == ost->st->codec.codec_type) {\n\n                            ost->source_index = j;\n\n                            found = 1;\n\n                        }\n\n                    }\n\n                    if (!found) {\n\n                        fprintf(stderr, \"Could not find input stream matching output stream #%d.%d\\n\",\n\n                                ost->file_index, ost->index);\n\n                        exit(1);\n\n                    }\n\n                }\n\n            }\n\n            ist = ist_table[ost->source_index];\n\n            ist->discard = 0;\n\n        }\n\n    }\n\n\n\n    /* for each output stream, we compute the right encoding parameters */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        ist = ist_table[ost->source_index];\n\n\n\n        codec = &ost->st->codec;\n\n        icodec = &ist->st->codec;\n\n\n\n        if (ost->st->stream_copy) {\n\n            /* if stream_copy is selected, no need to decode or encode */\n\n            codec->codec_id = icodec->codec_id;\n\n            codec->codec_type = icodec->codec_type;\n\n            codec->codec_tag = icodec->codec_tag;\n\n            codec->bit_rate = icodec->bit_rate;\n\n            switch(codec->codec_type) {\n\n            case CODEC_TYPE_AUDIO:\n\n                codec->sample_rate = icodec->sample_rate;\n\n                codec->channels = icodec->channels;\n\n                break;\n\n            case CODEC_TYPE_VIDEO:\n\n                codec->frame_rate = icodec->frame_rate;\n\n                codec->frame_rate_base = icodec->frame_rate_base;\n\n                codec->width = icodec->width;\n\n                codec->height = icodec->height;\n\n                break;\n\n            default:\n\n                av_abort();\n\n            }\n\n        } else {\n\n            switch(codec->codec_type) {\n\n            case CODEC_TYPE_AUDIO:\n\n                if (fifo_init(&ost->fifo, 2 * MAX_AUDIO_PACKET_SIZE))\n\n                    goto fail;\n\n                \n\n                if (codec->channels == icodec->channels &&\n\n                    codec->sample_rate == icodec->sample_rate) {\n\n                    ost->audio_resample = 0;\n\n                } else {\n\n                    if (codec->channels != icodec->channels &&\n\n                        icodec->codec_id == CODEC_ID_AC3) {\n\n                        /* Special case for 5:1 AC3 input */\n\n                        /* and mono or stereo output      */\n\n                        /* Request specific number of channels */\n\n                        icodec->channels = codec->channels;\n\n                        if (codec->sample_rate == icodec->sample_rate)\n\n                            ost->audio_resample = 0;\n\n                        else {\n\n                            ost->audio_resample = 1;\n\n                            ost->resample = audio_resample_init(codec->channels, icodec->channels,\n\n                                                        codec->sample_rate, \n\n                                                        icodec->sample_rate);\n\n\t\t\t    if(!ost->resample)\n\n\t\t\t      {\n\n\t\t\t\tprintf(\"Can't resample.  Aborting.\\n\");\n\n\t\t\t\tav_abort();\n\n\t\t\t      }\n\n                        }\n\n                        /* Request specific number of channels */\n\n                        icodec->channels = codec->channels;\n\n                    } else {\n\n                        ost->audio_resample = 1; \n\n                        ost->resample = audio_resample_init(codec->channels, icodec->channels,\n\n                                                        codec->sample_rate, \n\n                                                        icodec->sample_rate);\n\n\t\t\tif(!ost->resample)\n\n\t\t\t  {\n\n\t\t\t    printf(\"Can't resample.  Aborting.\\n\");\n\n\t\t\t    av_abort();\n\n\t\t\t  }\n\n                    }\n\n                }\n\n                ist->decoding_needed = 1;\n\n                ost->encoding_needed = 1;\n\n                break;\n\n            case CODEC_TYPE_VIDEO:\n\n                if (codec->width == icodec->width &&\n\n                    codec->height == icodec->height &&\n\n                    frame_topBand == 0 &&\n\n                    frame_bottomBand == 0 &&\n\n                    frame_leftBand == 0 &&\n\n                    frame_rightBand == 0)\n\n                {\n\n                    ost->video_resample = 0;\n\n                    ost->video_crop = 0;\n\n                } else if ((codec->width == icodec->width -\n\n                                (frame_leftBand + frame_rightBand)) &&\n\n                        (codec->height == icodec->height -\n\n                                (frame_topBand  + frame_bottomBand)))\n\n                {\n\n                    ost->video_resample = 0;\n\n                    ost->video_crop = 1;\n\n                    ost->topBand = frame_topBand;\n\n                    ost->leftBand = frame_leftBand;\n\n                } else {\n\n                    uint8_t *buf;\n\n                    ost->video_resample = 1;\n\n                    ost->video_crop = 0; // cropping is handled as part of resample\n\n                    buf = av_malloc((codec->width * codec->height * 3) / 2);\n\n                    if (!buf)\n\n                        goto fail;\n\n                    ost->pict_tmp.data[0] = buf;\n\n                    ost->pict_tmp.data[1] = ost->pict_tmp.data[0] + (codec->width * codec->height);\n\n                    ost->pict_tmp.data[2] = ost->pict_tmp.data[1] + (codec->width * codec->height) / 4;\n\n                    ost->pict_tmp.linesize[0] = codec->width;\n\n                    ost->pict_tmp.linesize[1] = codec->width / 2;\n\n                    ost->pict_tmp.linesize[2] = codec->width / 2;\n\n\n\n                    ost->img_resample_ctx = img_resample_full_init( \n\n                                      ost->st->codec.width, ost->st->codec.height,\n\n                                      ist->st->codec.width, ist->st->codec.height,\n\n                                      frame_topBand, frame_bottomBand,\n\n                                      frame_leftBand, frame_rightBand);\n\n                }\n\n                ost->encoding_needed = 1;\n\n                ist->decoding_needed = 1;\n\n                break;\n\n            default:\n\n                av_abort();\n\n            }\n\n            /* two pass mode */\n\n            if (ost->encoding_needed && \n\n                (codec->flags & (CODEC_FLAG_PASS1 | CODEC_FLAG_PASS2))) {\n\n                char logfilename[1024];\n\n                FILE *f;\n\n                int size;\n\n                char *logbuffer;\n\n                \n\n                snprintf(logfilename, sizeof(logfilename), \"%s-%d.log\", \n\n                         pass_logfilename ? \n\n                         pass_logfilename : DEFAULT_PASS_LOGFILENAME, i);\n\n                if (codec->flags & CODEC_FLAG_PASS1) {\n\n                    f = fopen(logfilename, \"w\");\n\n                    if (!f) {\n\n                        perror(logfilename);\n\n                        exit(1);\n\n                    }\n\n                    ost->logfile = f;\n\n                } else {\n\n                    /* read the log file */\n\n                    f = fopen(logfilename, \"r\");\n\n                    if (!f) {\n\n                        perror(logfilename);\n\n                        exit(1);\n\n                    }\n\n                    fseek(f, 0, SEEK_END);\n\n                    size = ftell(f);\n\n                    fseek(f, 0, SEEK_SET);\n\n                    logbuffer = av_malloc(size + 1);\n\n                    if (!logbuffer) {\n\n                        fprintf(stderr, \"Could not allocate log buffer\\n\");\n\n                        exit(1);\n\n                    }\n\n                    fread(logbuffer, 1, size, f);\n\n                    fclose(f);\n\n                    logbuffer[size] = '\\0';\n\n                    codec->stats_in = logbuffer;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    /* dump the file output parameters - cannot be done before in case\n\n       of stream copy */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        dump_format(output_files[i], i, output_files[i]->filename, 1);\n\n    }\n\n\n\n    /* dump the stream mapping */\n\n    fprintf(stderr, \"Stream mapping:\\n\");\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        fprintf(stderr, \"  Stream #%d.%d -> #%d.%d\\n\",\n\n                ist_table[ost->source_index]->file_index,\n\n                ist_table[ost->source_index]->index,\n\n                ost->file_index, \n\n                ost->index);\n\n    }\n\n\n\n    /* open each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            AVCodec *codec;\n\n            codec = avcodec_find_encoder(ost->st->codec.codec_id);\n\n            if (!codec) {\n\n                fprintf(stderr, \"Unsupported codec for output stream #%d.%d\\n\", \n\n                        ost->file_index, ost->index);\n\n                exit(1);\n\n            }\n\n            if (avcodec_open(&ost->st->codec, codec) < 0) {\n\n                fprintf(stderr, \"Error while opening codec for stream #%d.%d - maybe incorrect parameters such as bit_rate, rate, width or height\\n\", \n\n                        ost->file_index, ost->index);\n\n                exit(1);\n\n            }\n\n        }\n\n    }\n\n\n\n    /* open each decoder */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            AVCodec *codec;\n\n            codec = avcodec_find_decoder(ist->st->codec.codec_id);\n\n            if (!codec) {\n\n                fprintf(stderr, \"Unsupported codec (id=%d) for input stream #%d.%d\\n\", \n\n                        ist->st->codec.codec_id, ist->file_index, ist->index);\n\n                exit(1);\n\n            }\n\n            if (avcodec_open(&ist->st->codec, codec) < 0) {\n\n                fprintf(stderr, \"Error while opening codec for input stream #%d.%d\\n\", \n\n                        ist->file_index, ist->index);\n\n                exit(1);\n\n            }\n\n            //if (ist->st->codec.codec_type == CODEC_TYPE_VIDEO)\n\n            //    ist->st->codec.flags |= CODEC_FLAG_REPEAT_FIELD;\n\n            ist->frame_decoded = 1;\n\n        }\n\n    }\n\n\n\n    /* init pts */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n\tis = input_files[ist->file_index];\n\n        ist->pts = 0;\n\n        if (ist->decoding_needed) {\n\n            switch (ist->st->codec.codec_type) {\n\n            case CODEC_TYPE_AUDIO:\n\n                av_frac_init(&ist->next_pts, \n\n                             0, 0, is->pts_num * ist->st->codec.sample_rate);\n\n                break;\n\n            case CODEC_TYPE_VIDEO:\n\n                av_frac_init(&ist->next_pts, \n\n                             0, 0, is->pts_num * ist->st->codec.frame_rate);\n\n                break;\n\n            default:\n\n                break;\n\n            }\n\n        }\n\n    }\n\n    \n\n    /* compute buffer size max (should use a complete heuristic) */\n\n    for(i=0;i<nb_input_files;i++) {\n\n        file_table[i].buffer_size_max = 2048;\n\n    }\n\n\n\n    /* open files and write file headers */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        if (av_write_header(os) < 0) {\n\n            fprintf(stderr, \"Could not write header for output file #%d (incorrect codec paramters ?)\\n\", i);\n\n            ret = -EINVAL;\n\n            goto fail;\n\n        }\n\n    }\n\n\n\n#ifndef CONFIG_WIN32\n\n    if ( !using_stdin )\n\n        fprintf(stderr, \"Press [q] to stop encoding\\n\");\n\n#endif\n\n    term_init();\n\n\n\n    stream_no_data = 0;\n\n    key = -1;\n\n\n\n    for(; received_sigterm == 0;) {\n\n        int file_index, ist_index;\n\n        AVPacket pkt;\n\n        uint8_t *ptr;\n\n        int len;\n\n        uint8_t *data_buf;\n\n        int data_size, got_picture;\n\n        AVPicture picture;\n\n        short samples[AVCODEC_MAX_AUDIO_FRAME_SIZE / 2];\n\n        void *buffer_to_free;\n\n        double pts_min;\n\n        \n\n    redo:\n\n        /* if 'q' pressed, exits */\n\n        if (!using_stdin) {\n\n            /* read_key() returns 0 on EOF */\n\n            key = read_key();\n\n            if (key == 'q')\n\n                break;\n\n        }\n\n\n\n        /* select the stream that we must read now by looking at the\n\n           smallest output pts */\n\n        file_index = -1;\n\n        pts_min = 1e10;\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            double pts;\n\n            ost = ost_table[i];\n\n            os = output_files[ost->file_index];\n\n            ist = ist_table[ost->source_index];\n\n            pts = (double)ost->st->pts.val * os->pts_num / os->pts_den;\n\n            if (!file_table[ist->file_index].eof_reached && \n\n                pts < pts_min) {\n\n                pts_min = pts;\n\n                file_index = ist->file_index;\n\n            }\n\n        }\n\n        /* if none, if is finished */\n\n        if (file_index < 0) {\n\n            break;\n\n        }\n\n\n\n        /* finish if recording time exhausted */\n\n        if (recording_time > 0 && pts_min >= (recording_time / 1000000.0))\n\n            break;\n\n\n\n        /* read a packet from it and output it in the fifo */\n\n        is = input_files[file_index];\n\n        if (av_read_packet(is, &pkt) < 0) {\n\n            file_table[file_index].eof_reached = 1;\n\n            continue;\n\n        }\n\n        if (!pkt.size) {\n\n            stream_no_data = is;\n\n        } else {\n\n            stream_no_data = 0;\n\n        }\n\n        if (do_hex_dump) {\n\n            printf(\"stream #%d, size=%d:\\n\", pkt.stream_index, pkt.size);\n\n            av_hex_dump(pkt.data, pkt.size);\n\n        }\n\n        /* the following test is needed in case new streams appear\n\n           dynamically in stream : we ignore them */\n\n        if (pkt.stream_index >= file_table[file_index].nb_streams)\n\n            goto discard_packet;\n\n        ist_index = file_table[file_index].ist_index + pkt.stream_index;\n\n        ist = ist_table[ist_index];\n\n        if (ist->discard)\n\n            goto discard_packet;\n\n\n\n        // printf(\"read #%d.%d size=%d\\n\", ist->file_index, ist->index, pkt.size);\n\n\n\n        len = pkt.size;\n\n        ptr = pkt.data;\n\n        while (len > 0) {\n\n            /* decode the packet if needed */\n\n            data_buf = NULL; /* fail safe */\n\n            data_size = 0;\n\n            if (ist->decoding_needed) {\n\n                /* NOTE1: we only take into account the PTS if a new\n\n                   frame has begun (MPEG semantics) */\n\n                /* NOTE2: even if the fraction is not initialized,\n\n                   av_frac_set can be used to set the integer part */\n\n                if (ist->frame_decoded) { \n\n                    /* If pts is unavailable -- we have to use synthetic one */\n\n                    if( pkt.pts != AV_NOPTS_VALUE )\n\n                    {\n\n                        ist->pts = ist->next_pts.val = pkt.pts;\n\n                    }\n\n                    else\n\n                    {\n\n                        ist->pts = ist->next_pts.val;\n\n                    }\n\n                    ist->frame_decoded = 0;\n\n                }\n\n\n\n                switch(ist->st->codec.codec_type) {\n\n                case CODEC_TYPE_AUDIO:\n\n                    /* XXX: could avoid copy if PCM 16 bits with same\n\n                       endianness as CPU */\n\n                    ret = avcodec_decode_audio(&ist->st->codec, samples, &data_size,\n\n                                               ptr, len);\n\n                    if (ret < 0)\n\n                        goto fail_decode;\n\n                    /* Some bug in mpeg audio decoder gives */\n\n                    /* data_size < 0, it seems they are overflows */\n\n                    if (data_size <= 0) {\n\n                        /* no audio frame */\n\n                        ptr += ret;\n\n                        len -= ret;\n\n                        continue;\n\n                    }\n\n                    data_buf = (uint8_t *)samples;\n\n\t\t    av_frac_add(&ist->next_pts, \n\n\t\t\t        is->pts_den * data_size / (2 * ist->st->codec.channels));\n\n                    break;\n\n                case CODEC_TYPE_VIDEO:\n\n                    {\n\n                        AVFrame big_picture;\n\n\n\n                        data_size = (ist->st->codec.width * ist->st->codec.height * 3) / 2;\n\n                        ret = avcodec_decode_video(&ist->st->codec, \n\n                                                   &big_picture, &got_picture, ptr, len);\n\n                        picture= *(AVPicture*)&big_picture;\n\n                        ist->st->quality= big_picture.quality;\n\n                        if (ret < 0) {\n\n                        fail_decode:\n\n                            fprintf(stderr, \"Error while decoding stream #%d.%d\\n\",\n\n                                    ist->file_index, ist->index);\n\n                            av_free_packet(&pkt);\n\n                            goto redo;\n\n                        }\n\n                        if (!got_picture) {\n\n                            /* no picture yet */\n\n                            ptr += ret;\n\n                            len -= ret;\n\n                            continue;\n\n                        }\n\n                        av_frac_add(&ist->next_pts, \n\n\t\t\t            is->pts_den * ist->st->codec.frame_rate_base);          \n\n                    }\n\n                    break;\n\n                default:\n\n                    goto fail_decode;\n\n                }\n\n            } else {\n\n                data_buf = ptr;\n\n                data_size = len;\n\n                ret = len;\n\n            }\n\n            ptr += ret;\n\n            len -= ret;\n\n\n\n            buffer_to_free = 0;\n\n            if (ist->st->codec.codec_type == CODEC_TYPE_VIDEO) {\n\n                pre_process_video_frame(ist, &picture, &buffer_to_free);\n\n            }\n\n\n\n            ist->frame_decoded = 1;\n\n\n\n            /* frame rate emulation */\n\n            if (ist->st->codec.rate_emu) {\n\n                int64_t pts = av_rescale((int64_t) ist->frame * ist->st->codec.frame_rate_base, 1000000, ist->st->codec.frame_rate);\n\n                int64_t now = av_gettime() - ist->start;\n\n                if (pts > now)\n\n                    usleep(pts - now);\n\n\n\n                ist->frame++;\n\n            }\n\n\n\n#if 0\n\n            /* mpeg PTS deordering : if it is a P or I frame, the PTS\n\n               is the one of the next displayed one */\n\n            /* XXX: add mpeg4 too ? */\n\n            if (ist->st->codec.codec_id == CODEC_ID_MPEG1VIDEO) {\n\n                if (ist->st->codec.pict_type != B_TYPE) {\n\n                    int64_t tmp;\n\n                    tmp = ist->last_ip_pts;\n\n                    ist->last_ip_pts  = ist->frac_pts.val;\n\n                    ist->frac_pts.val = tmp;\n\n                }\n\n            }\n\n#endif\n\n            /* transcode raw format, encode packets and output them */\n\n\n\n            for(i=0;i<nb_ostreams;i++) {\n\n                int frame_size;\n\n\n\n                ost = ost_table[i];\n\n                if (ost->source_index == ist_index) {\n\n                    os = output_files[ost->file_index];\n\n\n\n#if 0\n\n                    printf(\"%d: got pts=%f %f\\n\", i, pkt.pts / 90000.0, \n\n                           (ist->pts - ost->st->pts.val) / 90000.0);\n\n#endif\n\n                    /* set the input output pts pairs */\n\n                    ost->sync_ipts = (double)ist->pts * is->pts_num / \n\n                        is->pts_den;\n\n                    /* XXX: take into account the various fifos,\n\n                       in particular for audio */\n\n                    ost->sync_opts = ost->st->pts.val;\n\n                    //printf(\"ipts=%lld sync_ipts=%f sync_opts=%lld pts.val=%lld pkt.pts=%lld\\n\", ist->pts, ost->sync_ipts, ost->sync_opts, ost->st->pts.val, pkt.pts); \n\n\n\n                    if (ost->encoding_needed) {\n\n                        switch(ost->st->codec.codec_type) {\n\n                        case CODEC_TYPE_AUDIO:\n\n                            do_audio_out(os, ost, ist, data_buf, data_size);\n\n                            break;\n\n                        case CODEC_TYPE_VIDEO:\n\n                            /* find an audio stream for synchro */\n\n                            {\n\n                                int i;\n\n                                AVOutputStream *audio_sync, *ost1;\n\n                                audio_sync = NULL;\n\n                                for(i=0;i<nb_ostreams;i++) {\n\n                                    ost1 = ost_table[i];\n\n                                    if (ost1->file_index == ost->file_index &&\n\n                                        ost1->st->codec.codec_type == CODEC_TYPE_AUDIO) {\n\n                                        audio_sync = ost1;\n\n                                        break;\n\n                                    }\n\n                                }\n\n\n\n                                do_video_out(os, ost, ist, &picture, &frame_size, audio_sync);\n\n                                if (do_vstats && frame_size)\n\n                                    do_video_stats(os, ost, frame_size);\n\n                            }\n\n                            break;\n\n                        default:\n\n                            av_abort();\n\n                        }\n\n                    } else {\n\n                        AVFrame avframe;\n\n                                                \n\n                        /* no reencoding needed : output the packet directly */\n\n                        /* force the input stream PTS */\n\n                        \n\n                        memset(&avframe, 0, sizeof(AVFrame));\n\n                        ost->st->codec.coded_frame= &avframe;\n\n\t\t\tavframe.key_frame = pkt.flags & PKT_FLAG_KEY; \n\n                        \n\n                        av_write_frame(os, ost->index, data_buf, data_size);\n\n\t\t\tost->st->codec.frame_number++;\n\n\t\t\tost->frame_number++;\n\n                    }\n\n                }\n\n            }\n\n            av_free(buffer_to_free);\n\n        }\n\n    discard_packet:\n\n        av_free_packet(&pkt);\n\n        \n\n        /* dump report by using the output first video and audio streams */\n\n        print_report(output_files, ost_table, nb_ostreams, 0);\n\n    }\n\n    term_exit();\n\n\n\n    /* dump report by using the first video and audio streams */\n\n    print_report(output_files, ost_table, nb_ostreams, 1);\n\n\n\n    /* close each encoder */\n\n    for(i=0;i<nb_ostreams;i++) {\n\n        ost = ost_table[i];\n\n        if (ost->encoding_needed) {\n\n            av_freep(&ost->st->codec.stats_in);\n\n            avcodec_close(&ost->st->codec);\n\n        }\n\n    }\n\n    \n\n    /* close each decoder */\n\n    for(i=0;i<nb_istreams;i++) {\n\n        ist = ist_table[i];\n\n        if (ist->decoding_needed) {\n\n            avcodec_close(&ist->st->codec);\n\n        }\n\n    }\n\n    \n\n\n\n    /* write the trailer if needed and close file */\n\n    for(i=0;i<nb_output_files;i++) {\n\n        os = output_files[i];\n\n        av_write_trailer(os);\n\n    }\n\n    /* finished ! */\n\n    \n\n    ret = 0;\n\n fail1:\n\n    av_free(file_table);\n\n\n\n    if (ist_table) {\n\n        for(i=0;i<nb_istreams;i++) {\n\n            ist = ist_table[i];\n\n            av_free(ist);\n\n        }\n\n        av_free(ist_table);\n\n    }\n\n    if (ost_table) {\n\n        for(i=0;i<nb_ostreams;i++) {\n\n            ost = ost_table[i];\n\n            if (ost) {\n\n                if (ost->logfile) {\n\n                    fclose(ost->logfile);\n\n                    ost->logfile = NULL;\n\n                }\n\n                fifo_free(&ost->fifo); /* works even if fifo is not\n\n                                          initialized but set to zero */\n\n                av_free(ost->pict_tmp.data[0]);\n\n                if (ost->video_resample)\n\n                    img_resample_close(ost->img_resample_ctx);\n\n                if (ost->audio_resample)\n\n                    audio_resample_close(ost->resample);\n\n                av_free(ost);\n\n            }\n\n        }\n\n        av_free(ost_table);\n\n    }\n\n    return ret;\n\n fail:\n\n    ret = -ENOMEM;\n\n    goto fail1;\n\n}\n", "idx": 13268, "_split": "test", "_hash": "543de905d3ad33c571116e8ab7a15e96"}
{"project": "FFmpeg", "commit_id": "f37b2d5a6884c7bea87a6c7454239381449bd637", "target": 1, "func": "int avpriv_mpeg4audio_get_config(MPEG4AudioConfig *c, const uint8_t *buf,\n                                 int bit_size, int sync_extension)\n{\n    GetBitContext gb;\n    int specific_config_bitindex;\n    init_get_bits(&gb, buf, bit_size);\n    c->object_type = get_object_type(&gb);\n    c->sample_rate = get_sample_rate(&gb, &c->sampling_index);\n    c->chan_config = get_bits(&gb, 4);\n    if (c->chan_config < FF_ARRAY_ELEMS(ff_mpeg4audio_channels))\n        c->channels = ff_mpeg4audio_channels[c->chan_config];\n    c->sbr = -1;\n    c->ps  = -1;\n    if (c->object_type == AOT_SBR || (c->object_type == AOT_PS &&\n        // check for W6132 Annex YYYY draft MP3onMP4\n        !(show_bits(&gb, 3) & 0x03 && !(show_bits(&gb, 9) & 0x3F)))) {\n        if (c->object_type == AOT_PS)\n            c->ps = 1;\n        c->ext_object_type = AOT_SBR;\n        c->sbr = 1;\n        c->ext_sample_rate = get_sample_rate(&gb, &c->ext_sampling_index);\n        c->object_type = get_object_type(&gb);\n        if (c->object_type == AOT_ER_BSAC)\n            c->ext_chan_config = get_bits(&gb, 4);\n    } else {\n        c->ext_object_type = AOT_NULL;\n        c->ext_sample_rate = 0;\n    }\n    specific_config_bitindex = get_bits_count(&gb);\n    if (c->object_type == AOT_ALS) {\n        skip_bits(&gb, 5);\n        if (show_bits_long(&gb, 24) != MKBETAG('\\0','A','L','S'))\n            skip_bits_long(&gb, 24);\n        specific_config_bitindex = get_bits_count(&gb);\n        if (parse_config_ALS(&gb, c))\n            return -1;\n    }\n    if (c->ext_object_type != AOT_SBR && sync_extension) {\n        while (get_bits_left(&gb) > 15) {\n            if (show_bits(&gb, 11) == 0x2b7) { // sync extension\n                get_bits(&gb, 11);\n                c->ext_object_type = get_object_type(&gb);\n                if (c->ext_object_type == AOT_SBR && (c->sbr = get_bits1(&gb)) == 1)\n                    c->ext_sample_rate = get_sample_rate(&gb, &c->ext_sampling_index);\n                if (get_bits_left(&gb) > 11 && get_bits(&gb, 11) == 0x548)\n                    c->ps = get_bits1(&gb);\n                break;\n            } else\n                get_bits1(&gb); // skip 1 bit\n        }\n    }\n    //PS requires SBR\n    if (!c->sbr)\n        c->ps = 0;\n    //Limit implicit PS to the HE-AACv2 Profile\n    if ((c->ps == -1 && c->object_type != AOT_AAC_LC) || c->channels & ~0x01)\n        c->ps = 0;\n    return specific_config_bitindex;\n}", "idx": 13273, "_split": "test", "_hash": "c849ab89feeadabaca7b52052f404557"}
{"project": "FFmpeg", "commit_id": "a52f443714b5c2a40ed272d8445f4c39220a4b69", "target": 1, "func": "static av_always_inline void vc1_apply_p_h_loop_filter(VC1Context *v, int block_num)\n\n{\n\n    MpegEncContext *s  = &v->s;\n\n    int mb_cbp         = v->cbp[s->mb_x - 1 - s->mb_stride],\n\n        block_cbp      = mb_cbp      >> (block_num * 4), right_cbp,\n\n        mb_is_intra    = v->is_intra[s->mb_x - 1 - s->mb_stride],\n\n        block_is_intra = mb_is_intra >> (block_num * 4), right_is_intra;\n\n    int idx, linesize  = block_num > 3 ? s->uvlinesize : s->linesize, ttblk;\n\n    uint8_t *dst;\n\n\n\n    if (block_num > 3) {\n\n        dst = s->dest[block_num - 3] - 8 * linesize;\n\n    } else {\n\n        dst = s->dest[0] + (block_num & 1) * 8 + ((block_num & 2) * 4 - 16) * linesize - 8;\n\n    }\n\n\n\n    if (s->mb_x != s->mb_width || !(block_num & 5)) {\n\n        int16_t (*mv)[2];\n\n\n\n        if (block_num > 3) {\n\n            right_cbp      = v->cbp[s->mb_x - s->mb_stride] >> (block_num * 4);\n\n            right_is_intra = v->is_intra[s->mb_x - s->mb_stride] >> (block_num * 4);\n\n            mv             = &v->luma_mv[s->mb_x - s->mb_stride - 1];\n\n        } else {\n\n            right_cbp      = (block_num & 1) ? (v->cbp[s->mb_x - s->mb_stride]      >> ((block_num - 1) * 4))\n\n                                             : (mb_cbp                              >> ((block_num + 1) * 4));\n\n            right_is_intra = (block_num & 1) ? (v->is_intra[s->mb_x - s->mb_stride] >> ((block_num - 1) * 4))\n\n                                             : (mb_is_intra                         >> ((block_num + 1) * 4));\n\n            mv             = &s->current_picture.motion_val[0][s->block_index[block_num] - s->b8_stride * 2 - 2];\n\n        }\n\n        if (block_is_intra & 1 || right_is_intra & 1 || mv[0][0] != mv[1][0] || mv[0][1] != mv[1][1]) {\n\n            v->vc1dsp.vc1_h_loop_filter8(dst, linesize, v->pq);\n\n        } else {\n\n            idx = ((right_cbp >> 1) | block_cbp) & 5; // FIXME check\n\n            if (idx == 5) {\n\n                v->vc1dsp.vc1_h_loop_filter8(dst, linesize, v->pq);\n\n            } else if (idx) {\n\n                if (idx == 1)\n\n                    v->vc1dsp.vc1_h_loop_filter4(dst + 4 * linesize, linesize, v->pq);\n\n                else\n\n                    v->vc1dsp.vc1_h_loop_filter4(dst,                linesize, v->pq);\n\n            }\n\n        }\n\n    }\n\n\n\n    dst -= 4;\n\n    ttblk = (v->ttblk[s->mb_x - s->mb_stride - 1] >> (block_num * 4)) & 0xf;\n\n    if (ttblk == TT_4X4 || ttblk == TT_4X8) {\n\n        idx = (block_cbp | (block_cbp >> 1)) & 5;\n\n        if (idx == 5) {\n\n            v->vc1dsp.vc1_h_loop_filter8(dst, linesize, v->pq);\n\n        } else if (idx) {\n\n            if (idx == 1)\n\n                v->vc1dsp.vc1_h_loop_filter4(dst + linesize * 4, linesize, v->pq);\n\n            else\n\n                v->vc1dsp.vc1_h_loop_filter4(dst,                linesize, v->pq);\n\n        }\n\n    }\n\n}\n", "idx": 13311, "_split": "test", "_hash": "c65533b32c538472961f118a230cee13"}
{"project": "FFmpeg", "commit_id": "5afe1d27912be9b643ffb4ddc21f6d920260dbb0", "target": 1, "func": "static int read_packet(AVFormatContext *s, uint8_t *buf, int raw_packet_size, uint8_t **data)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    int len;\n\n\n\n    for(;;) {\n\n        len = ffio_read_indirect(pb, buf, TS_PACKET_SIZE, data);\n\n        if (len != TS_PACKET_SIZE)\n\n            return len < 0 ? len : AVERROR_EOF;\n\n        /* check packet sync byte */\n\n        if ((*data)[0] != 0x47) {\n\n            /* find a new packet start */\n\n            avio_seek(pb, -TS_PACKET_SIZE, SEEK_CUR);\n\n            if (mpegts_resync(s) < 0)\n\n                return AVERROR(EAGAIN);\n\n            else\n\n                continue;\n\n        } else {\n\n            break;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 13316, "_split": "test", "_hash": "e8a59548ff67b8396760cf9eeff7684e"}
{"project": "FFmpeg", "commit_id": "4381bddc9f93da34a44e683bdc4c05c6f061244e", "target": 0, "func": "int ff_parse_sample_rate(unsigned *ret, const char *arg, void *log_ctx)\n\n{\n\n    char *tail;\n\n    double srate = av_strtod(arg, &tail);\n\n    if (*tail || srate < 1 || (int)srate != srate) {\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Invalid sample rate '%s'\\n\", arg);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    *ret = srate;\n\n    return 0;\n\n}\n", "idx": 13339, "_split": "test", "_hash": "855df489cde7bcb12feb0b20a1dc086e"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "static inline int decode_vui_parameters(H264Context *h, SPS *sps)\n\n{\n\n    int aspect_ratio_info_present_flag;\n\n    unsigned int aspect_ratio_idc;\n\n\n\n    aspect_ratio_info_present_flag = get_bits1(&h->gb);\n\n\n\n    if (aspect_ratio_info_present_flag) {\n\n        aspect_ratio_idc = get_bits(&h->gb, 8);\n\n        if (aspect_ratio_idc == EXTENDED_SAR) {\n\n            sps->sar.num = get_bits(&h->gb, 16);\n\n            sps->sar.den = get_bits(&h->gb, 16);\n\n        } else if (aspect_ratio_idc < FF_ARRAY_ELEMS(pixel_aspect)) {\n\n            sps->sar = pixel_aspect[aspect_ratio_idc];\n\n        } else {\n\n            av_log(h->avctx, AV_LOG_ERROR, \"illegal aspect ratio\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else {\n\n        sps->sar.num =\n\n        sps->sar.den = 0;\n\n    }\n\n\n\n    if (get_bits1(&h->gb))      /* overscan_info_present_flag */\n\n        get_bits1(&h->gb);      /* overscan_appropriate_flag */\n\n\n\n    sps->video_signal_type_present_flag = get_bits1(&h->gb);\n\n    if (sps->video_signal_type_present_flag) {\n\n        get_bits(&h->gb, 3);                 /* video_format */\n\n        sps->full_range = get_bits1(&h->gb); /* video_full_range_flag */\n\n\n\n        sps->colour_description_present_flag = get_bits1(&h->gb);\n\n        if (sps->colour_description_present_flag) {\n\n            sps->color_primaries = get_bits(&h->gb, 8); /* colour_primaries */\n\n            sps->color_trc       = get_bits(&h->gb, 8); /* transfer_characteristics */\n\n            sps->colorspace      = get_bits(&h->gb, 8); /* matrix_coefficients */\n\n            if (sps->color_primaries >= AVCOL_PRI_NB)\n\n                sps->color_primaries = AVCOL_PRI_UNSPECIFIED;\n\n            if (sps->color_trc >= AVCOL_TRC_NB)\n\n                sps->color_trc = AVCOL_TRC_UNSPECIFIED;\n\n            if (sps->colorspace >= AVCOL_SPC_NB)\n\n                sps->colorspace = AVCOL_SPC_UNSPECIFIED;\n\n        }\n\n    }\n\n\n\n    /* chroma_location_info_present_flag */\n\n    if (get_bits1(&h->gb)) {\n\n        /* chroma_sample_location_type_top_field */\n\n        h->avctx->chroma_sample_location = get_ue_golomb(&h->gb) + 1;\n\n        get_ue_golomb(&h->gb);  /* chroma_sample_location_type_bottom_field */\n\n    }\n\n\n\n    sps->timing_info_present_flag = get_bits1(&h->gb);\n\n    if (sps->timing_info_present_flag) {\n\n        sps->num_units_in_tick = get_bits_long(&h->gb, 32);\n\n        sps->time_scale        = get_bits_long(&h->gb, 32);\n\n        if (!sps->num_units_in_tick || !sps->time_scale) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"time_scale/num_units_in_tick invalid or unsupported (%\"PRIu32\"/%\"PRIu32\")\\n\",\n\n                   sps->time_scale, sps->num_units_in_tick);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        sps->fixed_frame_rate_flag = get_bits1(&h->gb);\n\n    }\n\n\n\n    sps->nal_hrd_parameters_present_flag = get_bits1(&h->gb);\n\n    if (sps->nal_hrd_parameters_present_flag)\n\n        if (decode_hrd_parameters(h, sps) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n    sps->vcl_hrd_parameters_present_flag = get_bits1(&h->gb);\n\n    if (sps->vcl_hrd_parameters_present_flag)\n\n        if (decode_hrd_parameters(h, sps) < 0)\n\n            return AVERROR_INVALIDDATA;\n\n    if (sps->nal_hrd_parameters_present_flag ||\n\n        sps->vcl_hrd_parameters_present_flag)\n\n        get_bits1(&h->gb);     /* low_delay_hrd_flag */\n\n    sps->pic_struct_present_flag = get_bits1(&h->gb);\n\n\n\n    sps->bitstream_restriction_flag = get_bits1(&h->gb);\n\n    if (sps->bitstream_restriction_flag) {\n\n        get_bits1(&h->gb);     /* motion_vectors_over_pic_boundaries_flag */\n\n        get_ue_golomb(&h->gb); /* max_bytes_per_pic_denom */\n\n        get_ue_golomb(&h->gb); /* max_bits_per_mb_denom */\n\n        get_ue_golomb(&h->gb); /* log2_max_mv_length_horizontal */\n\n        get_ue_golomb(&h->gb); /* log2_max_mv_length_vertical */\n\n        sps->num_reorder_frames = get_ue_golomb(&h->gb);\n\n        get_ue_golomb(&h->gb); /*max_dec_frame_buffering*/\n\n\n\n        if (get_bits_left(&h->gb) < 0) {\n\n            sps->num_reorder_frames         = 0;\n\n            sps->bitstream_restriction_flag = 0;\n\n        }\n\n\n\n        if (sps->num_reorder_frames > 16U\n\n            /* max_dec_frame_buffering || max_dec_frame_buffering > 16 */) {\n\n            av_log(h->avctx, AV_LOG_ERROR,\n\n                   \"Clipping illegal num_reorder_frames %d\\n\",\n\n                   sps->num_reorder_frames);\n\n            sps->num_reorder_frames = 16;\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n    if (get_bits_left(&h->gb) < 0) {\n\n        av_log(h->avctx, AV_LOG_ERROR,\n\n               \"Overread VUI by %d bits\\n\", -get_bits_left(&h->gb));\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 13388, "_split": "test", "_hash": "5da7010f36f79f9cdd168cd0d803b06d"}
{"project": "FFmpeg", "commit_id": "6abc56e892c2c2500d1fc2698fa6d580b72f721b", "target": 1, "func": "static int dshow_read_header(AVFormatContext *avctx)\n\n{\n\n    struct dshow_ctx *ctx = avctx->priv_data;\n\n    IGraphBuilder *graph = NULL;\n\n    ICreateDevEnum *devenum = NULL;\n\n    IMediaControl *control = NULL;\n\n    IMediaEvent *media_event = NULL;\n\n    HANDLE media_event_handle;\n\n    HANDLE proc;\n\n    int ret = AVERROR(EIO);\n\n    int r;\n\n\n\n    CoInitialize(0);\n\n\n\n    if (!ctx->list_devices && !parse_device_name(avctx)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Malformed dshow input string.\\n\");\n\n        goto error;\n\n    }\n\n\n\n    ctx->video_codec_id = avctx->video_codec_id ? avctx->video_codec_id\n\n                                                : AV_CODEC_ID_RAWVIDEO;\n\n    if (ctx->pixel_format != AV_PIX_FMT_NONE) {\n\n        if (ctx->video_codec_id != AV_CODEC_ID_RAWVIDEO) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Pixel format may only be set when \"\n\n                              \"video codec is not set or set to rawvideo\\n\");\n\n            ret = AVERROR(EINVAL);\n\n            goto error;\n\n        }\n\n    }\n\n    if (ctx->framerate) {\n\n        r = av_parse_video_rate(&ctx->requested_framerate, ctx->framerate);\n\n        if (r < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Could not parse framerate '%s'.\\n\", ctx->framerate);\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    r = CoCreateInstance(&CLSID_FilterGraph, NULL, CLSCTX_INPROC_SERVER,\n\n                         &IID_IGraphBuilder, (void **) &graph);\n\n    if (r != S_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not create capture graph.\\n\");\n\n        goto error;\n\n    }\n\n    ctx->graph = graph;\n\n\n\n    r = CoCreateInstance(&CLSID_SystemDeviceEnum, NULL, CLSCTX_INPROC_SERVER,\n\n                         &IID_ICreateDevEnum, (void **) &devenum);\n\n    if (r != S_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not enumerate system devices.\\n\");\n\n        goto error;\n\n    }\n\n\n\n    if (ctx->list_devices) {\n\n        av_log(avctx, AV_LOG_INFO, \"DirectShow video devices\\n\");\n\n        dshow_cycle_devices(avctx, devenum, VideoDevice, NULL);\n\n        av_log(avctx, AV_LOG_INFO, \"DirectShow audio devices\\n\");\n\n        dshow_cycle_devices(avctx, devenum, AudioDevice, NULL);\n\n        ret = AVERROR_EXIT;\n\n        goto error;\n\n    }\n\n    if (ctx->list_options) {\n\n        if (ctx->device_name[VideoDevice])\n\n            dshow_list_device_options(avctx, devenum, VideoDevice);\n\n        if (ctx->device_name[AudioDevice])\n\n            dshow_list_device_options(avctx, devenum, AudioDevice);\n\n        ret = AVERROR_EXIT;\n\n        goto error;\n\n    }\n\n\n\n    if (ctx->device_name[VideoDevice]) {\n\n        if ((r = dshow_open_device(avctx, devenum, VideoDevice)) < 0 ||\n\n            (r = dshow_add_device(avctx, VideoDevice)) < 0) {\n\n            ret = r;\n\n            goto error;\n\n        }\n\n    }\n\n    if (ctx->device_name[AudioDevice]) {\n\n        if ((r = dshow_open_device(avctx, devenum, AudioDevice)) < 0 ||\n\n            (r = dshow_add_device(avctx, AudioDevice)) < 0) {\n\n            ret = r;\n\n            goto error;\n\n        }\n\n    }\n\n\n\n    ctx->mutex = CreateMutex(NULL, 0, NULL);\n\n    if (!ctx->mutex) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not create Mutex\\n\");\n\n        goto error;\n\n    }\n\n    ctx->event[1] = CreateEvent(NULL, 1, 0, NULL);\n\n    if (!ctx->event[1]) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not create Event\\n\");\n\n        goto error;\n\n    }\n\n\n\n    r = IGraphBuilder_QueryInterface(graph, &IID_IMediaControl, (void **) &control);\n\n    if (r != S_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not get media control.\\n\");\n\n        goto error;\n\n    }\n\n    ctx->control = control;\n\n\n\n    r = IGraphBuilder_QueryInterface(graph, &IID_IMediaEvent, (void **) &media_event);\n\n    if (r != S_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not get media event.\\n\");\n\n        goto error;\n\n    }\n\n    ctx->media_event = media_event;\n\n\n\n    r = IMediaEvent_GetEventHandle(media_event, (void *) &media_event_handle);\n\n    if (r != S_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not get media event handle.\\n\");\n\n        goto error;\n\n    }\n\n    proc = GetCurrentProcess();\n\n    r = DuplicateHandle(proc, media_event_handle, proc, &ctx->event[0],\n\n                        0, 0, DUPLICATE_SAME_ACCESS);\n\n    if (!r) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not duplicate media event handle.\\n\");\n\n        goto error;\n\n    }\n\n\n\n    r = IMediaControl_Run(control);\n\n    if (r == S_FALSE) {\n\n        OAFilterState pfs;\n\n        r = IMediaControl_GetState(control, 0, &pfs);\n\n    }\n\n    if (r != S_OK) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Could not run filter\\n\");\n\n        goto error;\n\n    }\n\n\n\n    ret = 0;\n\n\n\nerror:\n\n\n\n    if (devenum)\n\n        ICreateDevEnum_Release(devenum);\n\n\n\n    if (ret < 0)\n\n        dshow_read_close(avctx);\n\n\n\n    return ret;\n\n}\n", "idx": 13429, "_split": "test", "_hash": "d17d9b8b96d221edb44ced36a81fb47b"}
{"project": "FFmpeg", "commit_id": "d86d7b2486cd5c31db8e820d8a89554abf19567e", "target": 0, "func": "static int ljpeg_decode_rgb_scan(MJpegDecodeContext *s, int nb_components, int predictor, int point_transform)\n\n{\n\n    int i, mb_x, mb_y;\n\n    uint16_t (*buffer)[4];\n\n    int left[4], top[4], topleft[4];\n\n    const int linesize = s->linesize[0];\n\n    const int mask     = ((1 << s->bits) - 1) << point_transform;\n\n    int resync_mb_y = 0;\n\n    int resync_mb_x = 0;\n\n\n\n    if (s->nb_components != 3 && s->nb_components != 4)\n\n        return AVERROR_INVALIDDATA;\n\n    if (s->v_max != 1 || s->h_max != 1 || !s->lossless)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n\n\n    s->restart_count = s->restart_interval;\n\n\n\n    av_fast_malloc(&s->ljpeg_buffer, &s->ljpeg_buffer_size,\n\n                   (unsigned)s->mb_width * 4 * sizeof(s->ljpeg_buffer[0][0]));\n\n    buffer = s->ljpeg_buffer;\n\n\n\n    for (i = 0; i < 4; i++)\n\n        buffer[0][i] = 1 << (s->bits - 1);\n\n\n\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n\n        uint8_t *ptr = s->picture_ptr->data[0] + (linesize * mb_y);\n\n\n\n        if (s->interlaced && s->bottom_field)\n\n            ptr += linesize >> 1;\n\n\n\n        for (i = 0; i < 4; i++)\n\n            top[i] = left[i] = topleft[i] = buffer[0][i];\n\n\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            int modified_predictor = predictor;\n\n\n\n            if (s->restart_interval && !s->restart_count){\n\n                s->restart_count = s->restart_interval;\n\n                resync_mb_x = mb_x;\n\n                resync_mb_y = mb_y;\n\n                for(i=0; i<4; i++)\n\n                    top[i] = left[i]= topleft[i]= 1 << (s->bits - 1);\n\n            }\n\n            if (mb_y == resync_mb_y || mb_y == resync_mb_y+1 && mb_x < resync_mb_x || !mb_x)\n\n                modified_predictor = 1;\n\n\n\n            for (i=0;i<nb_components;i++) {\n\n                int pred, dc;\n\n\n\n                topleft[i] = top[i];\n\n                top[i]     = buffer[mb_x][i];\n\n\n\n                PREDICT(pred, topleft[i], top[i], left[i], modified_predictor);\n\n\n\n                dc = mjpeg_decode_dc(s, s->dc_index[i]);\n\n                if(dc == 0xFFFFF)\n\n                    return -1;\n\n\n\n                left[i] = buffer[mb_x][i] =\n\n                    mask & (pred + (dc << point_transform));\n\n            }\n\n\n\n            if (s->restart_interval && !--s->restart_count) {\n\n                align_get_bits(&s->gb);\n\n                skip_bits(&s->gb, 16); /* skip RSTn */\n\n            }\n\n        }\n\n        if (s->rct && s->nb_components == 4) {\n\n            for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                ptr[4*mb_x + 2] = buffer[mb_x][0] - ((buffer[mb_x][1] + buffer[mb_x][2] - 0x200) >> 2);\n\n                ptr[4*mb_x + 1] = buffer[mb_x][1] + ptr[4*mb_x + 2];\n\n                ptr[4*mb_x + 3] = buffer[mb_x][2] + ptr[4*mb_x + 2];\n\n                ptr[4*mb_x + 0] = buffer[mb_x][3];\n\n            }\n\n        } else if (s->nb_components == 4) {\n\n            for(i=0; i<nb_components; i++) {\n\n                int c= s->comp_index[i];\n\n                if (s->bits <= 8) {\n\n                    for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                        ptr[4*mb_x+3-c] = buffer[mb_x][i];\n\n                    }\n\n                } else if(s->bits == 9) {\n\n                    return AVERROR_PATCHWELCOME;\n\n                } else {\n\n                    for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                        ((uint16_t*)ptr)[4*mb_x+c] = buffer[mb_x][i];\n\n                    }\n\n                }\n\n            }\n\n        } else if (s->rct) {\n\n            for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                ptr[3*mb_x + 1] = buffer[mb_x][0] - ((buffer[mb_x][1] + buffer[mb_x][2] - 0x200) >> 2);\n\n                ptr[3*mb_x + 0] = buffer[mb_x][1] + ptr[3*mb_x + 1];\n\n                ptr[3*mb_x + 2] = buffer[mb_x][2] + ptr[3*mb_x + 1];\n\n            }\n\n        } else if (s->pegasus_rct) {\n\n            for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                ptr[3*mb_x + 1] = buffer[mb_x][0] - ((buffer[mb_x][1] + buffer[mb_x][2]) >> 2);\n\n                ptr[3*mb_x + 0] = buffer[mb_x][1] + ptr[3*mb_x + 1];\n\n                ptr[3*mb_x + 2] = buffer[mb_x][2] + ptr[3*mb_x + 1];\n\n            }\n\n        } else {\n\n            for(i=0; i<nb_components; i++) {\n\n                int c= s->comp_index[i];\n\n                if (s->bits <= 8) {\n\n                    for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                        ptr[3*mb_x+2-c] = buffer[mb_x][i];\n\n                    }\n\n                } else if(s->bits == 9) {\n\n                    return AVERROR_PATCHWELCOME;\n\n                } else {\n\n                    for(mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n                        ((uint16_t*)ptr)[3*mb_x+2-c] = buffer[mb_x][i];\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 13442, "_split": "test", "_hash": "a3074b6e26ed9031898fbece23b24b07"}
{"project": "FFmpeg", "commit_id": "fe7547d69e6721d064c8604d0a6375a2d24b35ca", "target": 0, "func": "int ff_index_search_timestamp(const AVIndexEntry *entries, int nb_entries,\n\n                              int64_t wanted_timestamp, int flags)\n\n{\n\n    int a, b, m;\n\n    int64_t timestamp;\n\n\n\n    a = -1;\n\n    b = nb_entries;\n\n\n\n    // Optimize appending index entries at the end.\n\n    if (b && entries[b - 1].timestamp < wanted_timestamp)\n\n        a = b - 1;\n\n\n\n    while (b - a > 1) {\n\n        m         = (a + b) >> 1;\n\n\n\n        // Search for the next non-discarded packet.\n\n        while ((entries[m].flags & AVINDEX_DISCARD_FRAME) && m < b) {\n\n            m++;\n\n            if (m == b && entries[m].timestamp >= wanted_timestamp) {\n\n                m = b - 1;\n\n                break;\n\n            }\n\n        }\n\n\n\n        timestamp = entries[m].timestamp;\n\n        if (timestamp >= wanted_timestamp)\n\n            b = m;\n\n        if (timestamp <= wanted_timestamp)\n\n            a = m;\n\n    }\n\n    m = (flags & AVSEEK_FLAG_BACKWARD) ? a : b;\n\n\n\n    if (!(flags & AVSEEK_FLAG_ANY))\n\n        while (m >= 0 && m < nb_entries &&\n\n               !(entries[m].flags & AVINDEX_KEYFRAME))\n\n            m += (flags & AVSEEK_FLAG_BACKWARD) ? -1 : 1;\n\n\n\n    if (m == nb_entries)\n\n        return -1;\n\n    return m;\n\n}\n", "idx": 13462, "_split": "test", "_hash": "ab89c751445df4135483baa01b00d8ea"}
{"project": "FFmpeg", "commit_id": "668494acd8b20f974c7722895d4a6a14c1005f1e", "target": 1, "func": "static int codec_get_buffer(AVCodecContext *s, AVFrame *frame)\n{\n    InputStream *ist = s->opaque;\n    FrameBuffer *buf;\n    int ret, i;\n    if (!ist->buffer_pool && (ret = alloc_buffer(s, ist, &ist->buffer_pool)) < 0)\n        return ret;\n    buf              = ist->buffer_pool;\n    ist->buffer_pool = buf->next;\n    buf->next        = NULL;\n    if (buf->w != s->width || buf->h != s->height || buf->pix_fmt != s->pix_fmt) {\n        av_freep(&buf->base[0]);\n        av_free(buf);\n        ist->dr1 = 0;\n        if ((ret = alloc_buffer(s, ist, &buf)) < 0)\n            return ret;\n    }\n    buf->refcount++;\n    frame->opaque        = buf;\n    frame->type          = FF_BUFFER_TYPE_USER;\n    frame->extended_data = frame->data;\n    frame->pkt_pts       = s->pkt ? s->pkt->pts : AV_NOPTS_VALUE;\n    for (i = 0; i < FF_ARRAY_ELEMS(buf->data); i++) {\n        frame->base[i]     = buf->base[i];  // XXX h264.c uses base though it shouldn't\n        frame->data[i]     = buf->data[i];\n        frame->linesize[i] = buf->linesize[i];\n    }\n    return 0;\n}", "idx": 13468, "_split": "test", "_hash": "1134cd37a4ce5b9a9fd04c100d0a81a0"}
{"project": "FFmpeg", "commit_id": "b8edf91657ad9fa2f0c5175c9ca8fbe3c8b0c624", "target": 0, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *inpic)\n\n{\n\n    AVFilterContext   *ctx     = inlink->dst;\n\n    HisteqContext     *histeq  = ctx->priv;\n\n    AVFilterLink      *outlink = ctx->outputs[0];\n\n    int strength  = histeq->strength  * 1000;\n\n    int intensity = histeq->intensity * 1000;\n\n    int x, y, i, luthi, lutlo, lut, luma, oluma, m;\n\n    AVFrame *outpic;\n\n    unsigned int r, g, b, jran;\n\n    uint8_t *src, *dst;\n\n\n\n    outpic = ff_get_video_buffer(outlink, outlink->w, outlink->h);\n\n    if (!outpic) {\n\n        av_frame_free(&inpic);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    av_frame_copy_props(outpic, inpic);\n\n\n\n    /* Seed random generator for antibanding. */\n\n    jran = LCG_SEED;\n\n\n\n    /* Calculate and store the luminance and calculate the global histogram\n\n       based on the luminance. */\n\n    memset(histeq->in_histogram, 0, sizeof(histeq->in_histogram));\n\n    src = inpic->data[0];\n\n    dst = outpic->data[0];\n\n    for (y = 0; y < inlink->h; y++) {\n\n        for (x = 0; x < inlink->w * histeq->bpp; x += histeq->bpp) {\n\n            GET_RGB_VALUES(r, g, b, src, histeq->rgba_map);\n\n            luma = (55 * r + 182 * g + 19 * b) >> 8;\n\n            dst[x + histeq->rgba_map[A]] = luma;\n\n            histeq->in_histogram[luma]++;\n\n        }\n\n        src += inpic->linesize[0];\n\n        dst += outpic->linesize[0];\n\n    }\n\n\n\n#ifdef DEBUG\n\n    for (x = 0; x < 256; x++)\n\n        av_dlog(ctx, \"in[%d]: %u\\n\", x, histeq->in_histogram[x]);\n\n#endif\n\n\n\n    /* Calculate the lookup table. */\n\n    histeq->LUT[0] = histeq->in_histogram[0];\n\n    /* Accumulate */\n\n    for (x = 1; x < 256; x++)\n\n        histeq->LUT[x] = histeq->LUT[x-1] + histeq->in_histogram[x];\n\n\n\n    /* Normalize */\n\n    for (x = 0; x < 256; x++)\n\n        histeq->LUT[x] = (histeq->LUT[x] * intensity) / (inlink->h * inlink->w);\n\n\n\n    /* Adjust the LUT based on the selected strength. This is an alpha\n\n       mix of the calculated LUT and a linear LUT with gain 1. */\n\n    for (x = 0; x < 256; x++)\n\n        histeq->LUT[x] = (strength * histeq->LUT[x]) / 255 +\n\n                         ((255 - strength) * x)      / 255;\n\n\n\n    /* Output the equalized frame. */\n\n    memset(histeq->out_histogram, 0, sizeof(histeq->out_histogram));\n\n\n\n    src = inpic->data[0];\n\n    dst = outpic->data[0];\n\n    for (y = 0; y < inlink->h; y++) {\n\n        for (x = 0; x < inlink->w * histeq->bpp; x += histeq->bpp) {\n\n            luma = dst[x + histeq->rgba_map[A]];\n\n            if (luma == 0) {\n\n                for (i = 0; i < histeq->bpp; ++i)\n\n                    dst[x + i] = 0;\n\n                histeq->out_histogram[0]++;\n\n            } else {\n\n                lut = histeq->LUT[luma];\n\n                if (histeq->antibanding != HISTEQ_ANTIBANDING_NONE) {\n\n                    if (luma > 0) {\n\n                        lutlo = histeq->antibanding == HISTEQ_ANTIBANDING_WEAK ?\n\n                                (histeq->LUT[luma] + histeq->LUT[luma - 1]) / 2 :\n\n                                 histeq->LUT[luma - 1];\n\n                    } else\n\n                        lutlo = lut;\n\n\n\n                    if (luma < 255) {\n\n                        luthi = (histeq->antibanding == HISTEQ_ANTIBANDING_WEAK) ?\n\n                            (histeq->LUT[luma] + histeq->LUT[luma + 1]) / 2 :\n\n                             histeq->LUT[luma + 1];\n\n                    } else\n\n                        luthi = lut;\n\n\n\n                    if (lutlo != luthi) {\n\n                        jran = LCG(jran);\n\n                        lut = lutlo + ((luthi - lutlo + 1) * jran) / LCG_M;\n\n                    }\n\n                }\n\n\n\n                GET_RGB_VALUES(r, g, b, src, histeq->rgba_map);\n\n                if (((m = FFMAX3(r, g, b)) * lut) / luma > 255) {\n\n                    r = (r * 255) / m;\n\n                    g = (g * 255) / m;\n\n                    b = (b * 255) / m;\n\n                } else {\n\n                    r = (r * lut) / luma;\n\n                    g = (g * lut) / luma;\n\n                    b = (b * lut) / luma;\n\n                }\n\n                dst[x + histeq->rgba_map[R]] = r;\n\n                dst[x + histeq->rgba_map[G]] = g;\n\n                dst[x + histeq->rgba_map[B]] = b;\n\n                oluma = (55 * r + 182 * g + 19 * b) >> 8;\n\n                histeq->out_histogram[oluma]++;\n\n            }\n\n        }\n\n        src += inpic->linesize[0];\n\n        dst += outpic->linesize[0];\n\n    }\n\n#ifdef DEBUG\n\n    for (x = 0; x < 256; x++)\n\n        av_dlog(ctx, \"out[%d]: %u\\n\", x, histeq->out_histogram[x]);\n\n#endif\n\n\n\n    av_frame_free(&inpic);\n\n    return ff_filter_frame(outlink, outpic);\n\n}\n", "idx": 13488, "_split": "test", "_hash": "56a5b2888434620dc36bf83d60d2f62e"}
{"project": "FFmpeg", "commit_id": "6f1ec38ce2193d3d4cacd87edb452c6d7ba751ec", "target": 0, "func": "static void compute_antialias_float(MPADecodeContext *s,\n\n                              GranuleDef *g)\n\n{\n\n    float *ptr;\n\n    int n, i;\n\n\n\n    /* we antialias only \"long\" bands */\n\n    if (g->block_type == 2) {\n\n        if (!g->switch_point)\n\n            return;\n\n        /* XXX: check this for 8000Hz case */\n\n        n = 1;\n\n    } else {\n\n        n = SBLIMIT - 1;\n\n    }\n\n\n\n    ptr = g->sb_hybrid + 18;\n\n    for(i = n;i > 0;i--) {\n\n        float tmp0, tmp1;\n\n        float *csa = &csa_table_float[0][0];\n\n#define FLOAT_AA(j)\\\n\n        tmp0= ptr[-1-j];\\\n\n        tmp1= ptr[   j];\\\n\n        ptr[-1-j] = tmp0 * csa[0+4*j] - tmp1 * csa[1+4*j];\\\n\n        ptr[   j] = tmp0 * csa[1+4*j] + tmp1 * csa[0+4*j];\n\n\n\n        FLOAT_AA(0)\n\n        FLOAT_AA(1)\n\n        FLOAT_AA(2)\n\n        FLOAT_AA(3)\n\n        FLOAT_AA(4)\n\n        FLOAT_AA(5)\n\n        FLOAT_AA(6)\n\n        FLOAT_AA(7)\n\n\n\n        ptr += 18;\n\n    }\n\n}\n", "idx": 13524, "_split": "test", "_hash": "179870c4a6a567cf6f3d1b7b443ae186"}
{"project": "FFmpeg", "commit_id": "73789b85a759f3874112618120194e1712d7adcd", "target": 0, "func": "int ff_dca_core_parse(DCACoreDecoder *s, uint8_t *data, int size)\n\n{\n\n    int ret;\n\n\n\n    s->ext_audio_mask = 0;\n\n    s->xch_pos = s->xxch_pos = s->x96_pos = 0;\n\n\n\n    if ((ret = init_get_bits8(&s->gb, data, size)) < 0)\n\n        return ret;\n\n    s->gb_in = s->gb;\n\n\n\n    if ((ret = parse_frame_header(s)) < 0)\n\n        return ret;\n\n    if ((ret = alloc_sample_buffer(s)) < 0)\n\n        return ret;\n\n    if ((ret = parse_frame_data(s, HEADER_CORE, 0)) < 0)\n\n        return ret;\n\n    if ((ret = parse_optional_info(s)) < 0)\n\n        return ret;\n\n\n\n    // Workaround for DTS in WAV\n\n    if (s->frame_size > size && s->frame_size < size + 4)\n\n        s->frame_size = size;\n\n\n\n    if (ff_dca_seek_bits(&s->gb, s->frame_size * 8)) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Read past end of core frame\\n\");\n\n        if (s->avctx->err_recognition & AV_EF_EXPLODE)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 13555, "_split": "test", "_hash": "6568de90e20fe7ae3d05304bdeaf68ec"}
{"project": "FFmpeg", "commit_id": "5e53486545726987ab4482321d4dcf7e23e7652f", "target": 0, "func": "static int decode_init_mp3on4(AVCodecContext * avctx)\n\n{\n\n    MP3On4DecodeContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    if ((avctx->extradata_size < 2) || (avctx->extradata == NULL)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Codec extradata missing or too short.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    s->chan_cfg = (((unsigned char *)avctx->extradata)[1] >> 3) & 0x0f;\n\n    s->frames = mp3Frames[s->chan_cfg];\n\n    if(!s->frames) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid channel config number.\\n\");\n\n        return -1;\n\n    }\n\n    avctx->channels = mp3Channels[s->chan_cfg];\n\n\n\n    /* Init the first mp3 decoder in standard way, so that all tables get builded\n\n     * We replace avctx->priv_data with the context of the first decoder so that\n\n     * decode_init() does not have to be changed.\n\n     * Other decoders will be inited here copying data from the first context\n\n     */\n\n    // Allocate zeroed memory for the first decoder context\n\n    s->mp3decctx[0] = av_mallocz(sizeof(MPADecodeContext));\n\n    // Put decoder context in place to make init_decode() happy\n\n    avctx->priv_data = s->mp3decctx[0];\n\n    decode_init(avctx);\n\n    // Restore mp3on4 context pointer\n\n    avctx->priv_data = s;\n\n    s->mp3decctx[0]->adu_mode = 1; // Set adu mode\n\n\n\n    /* Create a separate codec/context for each frame (first is already ok).\n\n     * Each frame is 1 or 2 channels - up to 5 frames allowed\n\n     */\n\n    for (i = 1; i < s->frames; i++) {\n\n        s->mp3decctx[i] = av_mallocz(sizeof(MPADecodeContext));\n\n        s->mp3decctx[i]->compute_antialias = s->mp3decctx[0]->compute_antialias;\n\n        s->mp3decctx[i]->adu_mode = 1;\n\n        s->mp3decctx[i]->avctx = avctx;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 13571, "_split": "test", "_hash": "88f2bd334e03e1f233fb1bb3ae415a96"}
{"project": "FFmpeg", "commit_id": "3a83b2461e4ce9d48ad6ab037eb14569d0e53506", "target": 1, "func": "static int dnxhd_encode_rdo(AVCodecContext *avctx, DNXHDEncContext *ctx)\n\n{\n\n    int lambda, up_step, down_step;\n\n    int last_lower = INT_MAX, last_higher = 0;\n\n    int x, y, q;\n\n\n\n    for (q = 1; q < avctx->qmax; q++) {\n\n        ctx->qscale = q;\n\n        avctx->execute2(avctx, dnxhd_calc_bits_thread, NULL, NULL, ctx->m.mb_height);\n\n    }\n\n    up_step = down_step = 2<<LAMBDA_FRAC_BITS;\n\n    lambda = ctx->lambda;\n\n\n\n    for (;;) {\n\n        int bits = 0;\n\n        int end = 0;\n\n        if (lambda == last_higher) {\n\n            lambda++;\n\n            end = 1; // need to set final qscales/bits\n\n        }\n\n        for (y = 0; y < ctx->m.mb_height; y++) {\n\n            for (x = 0; x < ctx->m.mb_width; x++) {\n\n                unsigned min = UINT_MAX;\n\n                int qscale = 1;\n\n                int mb = y*ctx->m.mb_width+x;\n\n                for (q = 1; q < avctx->qmax; q++) {\n\n                    unsigned score = ctx->mb_rc[q][mb].bits*lambda+(ctx->mb_rc[q][mb].ssd<<LAMBDA_FRAC_BITS);\n\n                    if (score < min) {\n\n                        min = score;\n\n                        qscale = q;\n\n                    }\n\n                }\n\n                bits += ctx->mb_rc[qscale][mb].bits;\n\n                ctx->mb_qscale[mb] = qscale;\n\n                ctx->mb_bits[mb] = ctx->mb_rc[qscale][mb].bits;\n\n            }\n\n            bits = (bits+31)&~31; // padding\n\n            if (bits > ctx->frame_bits)\n\n                break;\n\n        }\n\n        //av_dlog(ctx->m.avctx, \"lambda %d, up %u, down %u, bits %d, frame %d\\n\",\n\n        //        lambda, last_higher, last_lower, bits, ctx->frame_bits);\n\n        if (end) {\n\n            if (bits > ctx->frame_bits)\n\n                return -1;\n\n            break;\n\n        }\n\n        if (bits < ctx->frame_bits) {\n\n            last_lower = FFMIN(lambda, last_lower);\n\n            if (last_higher != 0)\n\n                lambda = (lambda+last_higher)>>1;\n\n            else\n\n                lambda -= down_step;\n\n            down_step *= 5; // XXX tune ?\n\n            up_step = 1<<LAMBDA_FRAC_BITS;\n\n            lambda = FFMAX(1, lambda);\n\n            if (lambda == last_lower)\n\n                break;\n\n        } else {\n\n            last_higher = FFMAX(lambda, last_higher);\n\n            if (last_lower != INT_MAX)\n\n                lambda = (lambda+last_lower)>>1;\n\n            else if ((int64_t)lambda + up_step > INT_MAX)\n\n                return -1;\n\n            else\n\n                lambda += up_step;\n\n            up_step = FFMIN((int64_t)up_step*5, INT_MAX);\n\n            down_step = 1<<LAMBDA_FRAC_BITS;\n\n        }\n\n    }\n\n    //av_dlog(ctx->m.avctx, \"out lambda %d\\n\", lambda);\n\n    ctx->lambda = lambda;\n\n    return 0;\n\n}\n", "idx": 13635, "_split": "test", "_hash": "4b64536cd4d1f20cc394b7a37e14dda7"}
{"project": "FFmpeg", "commit_id": "5a2645cafeca1c2207ac55cc831c3349572a82ed", "target": 1, "func": "static int find_and_decode_index(NUTContext *nut)\n\n{\n\n    AVFormatContext *s = nut->avf;\n\n    AVIOContext *bc    = s->pb;\n\n    uint64_t tmp, end;\n\n    int i, j, syncpoint_count;\n\n    int64_t filesize = avio_size(bc);\n\n    int64_t *syncpoints;\n\n    int8_t *has_keyframe;\n\n    int ret = AVERROR_INVALIDDATA;\n\n\n\n    avio_seek(bc, filesize - 12, SEEK_SET);\n\n    avio_seek(bc, filesize - avio_rb64(bc), SEEK_SET);\n\n    if (avio_rb64(bc) != INDEX_STARTCODE) {\n\n        av_log(s, AV_LOG_ERROR, \"no index at the end\\n\");\n\n        return ret;\n\n    }\n\n\n\n    end  = get_packetheader(nut, bc, 1, INDEX_STARTCODE);\n\n    end += avio_tell(bc);\n\n\n\n    ffio_read_varlen(bc); // max_pts\n\n    GET_V(syncpoint_count, tmp < INT_MAX / 8 && tmp > 0);\n\n    syncpoints   = av_malloc(sizeof(int64_t) *  syncpoint_count);\n\n    has_keyframe = av_malloc(sizeof(int8_t)  * (syncpoint_count + 1));\n\n    if (!syncpoints || !has_keyframe)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < syncpoint_count; i++) {\n\n        syncpoints[i] = ffio_read_varlen(bc);\n\n        if (syncpoints[i] <= 0)\n\n            goto fail;\n\n        if (i)\n\n            syncpoints[i] += syncpoints[i - 1];\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        int64_t last_pts = -1;\n\n        for (j = 0; j < syncpoint_count;) {\n\n            uint64_t x = ffio_read_varlen(bc);\n\n            int type   = x & 1;\n\n            int n      = j;\n\n            x >>= 1;\n\n            if (type) {\n\n                int flag = x & 1;\n\n                x >>= 1;\n\n                if (n + x >= syncpoint_count + 1) {\n\n                    av_log(s, AV_LOG_ERROR, \"index overflow A\\n\");\n\n                    goto fail;\n\n                }\n\n                while (x--)\n\n                    has_keyframe[n++] = flag;\n\n                has_keyframe[n++] = !flag;\n\n            } else {\n\n                while (x != 1) {\n\n                    if (n >= syncpoint_count + 1) {\n\n                        av_log(s, AV_LOG_ERROR, \"index overflow B\\n\");\n\n                        goto fail;\n\n                    }\n\n                    has_keyframe[n++] = x & 1;\n\n                    x >>= 1;\n\n                }\n\n            }\n\n            if (has_keyframe[0]) {\n\n                av_log(s, AV_LOG_ERROR, \"keyframe before first syncpoint in index\\n\");\n\n                goto fail;\n\n            }\n\n            assert(n <= syncpoint_count + 1);\n\n            for (; j < n && j < syncpoint_count; j++) {\n\n                if (has_keyframe[j]) {\n\n                    uint64_t B, A = ffio_read_varlen(bc);\n\n                    if (!A) {\n\n                        A = ffio_read_varlen(bc);\n\n                        B = ffio_read_varlen(bc);\n\n                        // eor_pts[j][i] = last_pts + A + B\n\n                    } else\n\n                        B = 0;\n\n                    av_add_index_entry(s->streams[i], 16 * syncpoints[j - 1],\n\n                                       last_pts + A, 0, 0, AVINDEX_KEYFRAME);\n\n                    last_pts += A + B;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if (skip_reserved(bc, end) || ffio_get_checksum(bc)) {\n\n        av_log(s, AV_LOG_ERROR, \"index checksum mismatch\\n\");\n\n        goto fail;\n\n    }\n\n    ret = 0;\n\n\n\nfail:\n\n    av_free(syncpoints);\n\n    av_free(has_keyframe);\n\n    return ret;\n\n}\n", "idx": 13636, "_split": "test", "_hash": "b826e49e4beba79b69f6990993ef3465"}
{"project": "FFmpeg", "commit_id": "ca32f7f2083f9ededd1d9964ed065e0ad07a01e0", "target": 0, "func": "static void init_dequant8_coeff_table(H264Context *h){\n\n    int i,q,x;\n\n    const int transpose = (h->h264dsp.h264_idct8_add != ff_h264_idct8_add_c); //FIXME ugly\n\n    h->dequant8_coeff[0] = h->dequant8_buffer[0];\n\n    h->dequant8_coeff[1] = h->dequant8_buffer[1];\n\n\n\n    for(i=0; i<2; i++ ){\n\n        if(i && !memcmp(h->pps.scaling_matrix8[0], h->pps.scaling_matrix8[1], 64*sizeof(uint8_t))){\n\n            h->dequant8_coeff[1] = h->dequant8_buffer[0];\n\n            break;\n\n        }\n\n\n\n        for(q=0; q<52; q++){\n\n            int shift = div6[q];\n\n            int idx = rem6[q];\n\n            for(x=0; x<64; x++)\n\n                h->dequant8_coeff[i][q][transpose ? (x>>3)|((x&7)<<3) : x] =\n\n                    ((uint32_t)dequant8_coeff_init[idx][ dequant8_coeff_init_scan[((x>>1)&12) | (x&3)] ] *\n\n                    h->pps.scaling_matrix8[i][x]) << shift;\n\n        }\n\n    }\n\n}\n", "idx": 13712, "_split": "test", "_hash": "8fa164fc3c49c88f344e65830a24eede"}
{"project": "FFmpeg", "commit_id": "8d0a2180582005e91d9f14ae3dd219a882277c23", "target": 1, "func": "int ff_jni_exception_get_summary(JNIEnv *env, jthrowable exception, char **error, void *log_ctx)\n\n{\n\n    int ret = 0;\n\n\n\n    AVBPrint bp;\n\n\n\n    char *name = NULL;\n\n    char *message = NULL;\n\n\n\n    jclass class_class = NULL;\n\n    jmethodID get_name_id = NULL;\n\n\n\n    jclass exception_class = NULL;\n\n    jmethodID get_message_id = NULL;\n\n\n\n    jstring string;\n\n\n\n    av_bprint_init(&bp, 0, AV_BPRINT_SIZE_AUTOMATIC);\n\n\n\n    exception_class = (*env)->GetObjectClass(env, exception);\n\n    if ((*env)->ExceptionCheck(env)) {\n\n        (*env)->ExceptionClear(env);\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Could not find Throwable class\\n\");\n\n        ret = AVERROR_EXTERNAL;\n\n        goto done;\n\n    }\n\n\n\n    class_class = (*env)->GetObjectClass(env, exception_class);\n\n    if ((*env)->ExceptionCheck(env)) {\n\n        (*env)->ExceptionClear(env);\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Could not find Throwable class's class\\n\");\n\n        ret = AVERROR_EXTERNAL;\n\n        goto done;\n\n    }\n\n\n\n    get_name_id = (*env)->GetMethodID(env, class_class, \"getName\", \"()Ljava/lang/String;\");\n\n    if ((*env)->ExceptionCheck(env)) {\n\n        (*env)->ExceptionClear(env);\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Could not find method Class.getName()\\n\");\n\n        ret = AVERROR_EXTERNAL;\n\n        goto done;\n\n    }\n\n\n\n    string = (*env)->CallObjectMethod(env, exception_class, get_name_id);\n\n    if ((*env)->ExceptionCheck(env)) {\n\n        (*env)->ExceptionClear(env);\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Class.getName() threw an exception\\n\");\n\n        ret = AVERROR_EXTERNAL;\n\n        goto done;\n\n    }\n\n\n\n    if (string) {\n\n        name = ff_jni_jstring_to_utf_chars(env, string, log_ctx);\n\n        (*env)->DeleteLocalRef(env, string);\n\n        string = NULL;\n\n    }\n\n\n\n    get_message_id = (*env)->GetMethodID(env, exception_class, \"getMessage\", \"()Ljava/lang/String;\");\n\n    if ((*env)->ExceptionCheck(env)) {\n\n        (*env)->ExceptionClear(env);\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Could not find method java/lang/Throwable.getMessage()\\n\");\n\n        ret = AVERROR_EXTERNAL;\n\n        goto done;\n\n    }\n\n\n\n    string = (*env)->CallObjectMethod(env, exception, get_message_id);\n\n    if ((*env)->ExceptionCheck(env)) {\n\n        (*env)->ExceptionClear(env);\n\n        av_log(log_ctx, AV_LOG_ERROR, \"Throwable.getMessage() threw an exception\\n\");\n\n        ret = AVERROR_EXTERNAL;\n\n        goto done;\n\n    }\n\n\n\n    if (string) {\n\n        message = ff_jni_jstring_to_utf_chars(env, string, log_ctx);\n\n        (*env)->DeleteLocalRef(env, string);\n\n        string = NULL;\n\n    }\n\n\n\n    if (name && message) {\n\n        av_bprintf(&bp, \"%s: %s\", name, message);\n\n    } else if (name && !message) {\n\n        av_bprintf(&bp, \"%s occurred\", name);\n\n    } else if (!name && message) {\n\n        av_bprintf(&bp, \"Exception: %s\", message);\n\n    } else {\n\n        av_log(log_ctx, AV_LOG_WARNING, \"Could not retreive exception name and message\\n\");\n\n        av_bprintf(&bp, \"Exception occurred\");\n\n    }\n\n\n\n    ret = av_bprint_finalize(&bp, error);\n\ndone:\n\n\n\n    av_free(name);\n\n    av_free(message);\n\n\n\n    if (class_class) {\n\n        (*env)->DeleteLocalRef(env, class_class);\n\n    }\n\n\n\n    if (exception_class) {\n\n        (*env)->DeleteLocalRef(env, exception_class);\n\n    }\n\n\n\n    if (string) {\n\n        (*env)->DeleteLocalRef(env, string);\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 13740, "_split": "test", "_hash": "107bf8b18251dd104716b551389d0f59"}
{"project": "FFmpeg", "commit_id": "be00ec832c519427cd92218abac77dafdc1d5487", "target": 0, "func": "static av_cold int svc_encode_init(AVCodecContext *avctx)\n\n{\n\n    SVCContext *s = avctx->priv_data;\n\n    SEncParamExt param = { 0 };\n\n    int err = AVERROR_UNKNOWN;\n\n    int log_level;\n\n    WelsTraceCallback callback_function;\n\n    AVCPBProperties *props;\n\n\n\n    // Mingw GCC < 4.7 on x86_32 uses an incorrect/buggy ABI for the WelsGetCodecVersion\n\n    // function (for functions returning larger structs), thus skip the check in those\n\n    // configurations.\n\n#if !defined(_WIN32) || !defined(__GNUC__) || !ARCH_X86_32 || AV_GCC_VERSION_AT_LEAST(4, 7)\n\n    OpenH264Version libver = WelsGetCodecVersion();\n\n    if (memcmp(&libver, &g_stCodecVersion, sizeof(libver))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Incorrect library version loaded\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n#endif\n\n\n\n    if (WelsCreateSVCEncoder(&s->encoder)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unable to create encoder\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    // Pass all libopenh264 messages to our callback, to allow ourselves to filter them.\n\n    log_level = WELS_LOG_DETAIL;\n\n    (*s->encoder)->SetOption(s->encoder, ENCODER_OPTION_TRACE_LEVEL, &log_level);\n\n\n\n    // Set the logging callback function to one that uses av_log() (see implementation above).\n\n    callback_function = (WelsTraceCallback) libopenh264_trace_callback;\n\n    (*s->encoder)->SetOption(s->encoder, ENCODER_OPTION_TRACE_CALLBACK, (void *)&callback_function);\n\n\n\n    // Set the AVCodecContext as the libopenh264 callback context so that it can be passed to av_log().\n\n    (*s->encoder)->SetOption(s->encoder, ENCODER_OPTION_TRACE_CALLBACK_CONTEXT, (void *)&avctx);\n\n\n\n    (*s->encoder)->GetDefaultParams(s->encoder, &param);\n\n\n\n    param.fMaxFrameRate              = avctx->time_base.den / avctx->time_base.num;\n\n    param.iPicWidth                  = avctx->width;\n\n    param.iPicHeight                 = avctx->height;\n\n    param.iTargetBitrate             = avctx->bit_rate;\n\n    param.iMaxBitrate                = FFMAX(avctx->rc_max_rate, avctx->bit_rate);\n\n    param.iRCMode                    = RC_QUALITY_MODE;\n\n    param.iTemporalLayerNum          = 1;\n\n    param.iSpatialLayerNum           = 1;\n\n    param.bEnableDenoise             = 0;\n\n    param.bEnableBackgroundDetection = 1;\n\n    param.bEnableAdaptiveQuant       = 1;\n\n    param.bEnableFrameSkip           = s->skip_frames;\n\n    param.bEnableLongTermReference   = 0;\n\n    param.iLtrMarkPeriod             = 30;\n\n    param.uiIntraPeriod              = avctx->gop_size;\n\n#if OPENH264_VER_AT_LEAST(1, 4)\n\n    param.eSpsPpsIdStrategy          = CONSTANT_ID;\n\n#else\n\n    param.bEnableSpsPpsIdAddition    = 0;\n\n#endif\n\n    param.bPrefixNalAddingCtrl       = 0;\n\n    param.iLoopFilterDisableIdc      = !s->loopfilter;\n\n    param.iEntropyCodingModeFlag     = 0;\n\n    param.iMultipleThreadIdc         = avctx->thread_count;\n\n    if (s->profile && !strcmp(s->profile, \"main\"))\n\n        param.iEntropyCodingModeFlag = 1;\n\n    else if (!s->profile && avctx->coder_type == FF_CODER_TYPE_AC)\n\n        param.iEntropyCodingModeFlag = 1;\n\n\n\n    param.sSpatialLayers[0].iVideoWidth         = param.iPicWidth;\n\n    param.sSpatialLayers[0].iVideoHeight        = param.iPicHeight;\n\n    param.sSpatialLayers[0].fFrameRate          = param.fMaxFrameRate;\n\n    param.sSpatialLayers[0].iSpatialBitrate     = param.iTargetBitrate;\n\n    param.sSpatialLayers[0].iMaxSpatialBitrate  = param.iMaxBitrate;\n\n\n\n    if ((avctx->slices > 1) && (s->max_nal_size)){\n\n        av_log(avctx,AV_LOG_ERROR,\"Invalid combination -slices %d and -max_nal_size %d.\\n\",avctx->slices,s->max_nal_size);\n\n        goto fail;\n\n    }\n\n\n\n    if (avctx->slices > 1)\n\n        s->slice_mode = SM_FIXEDSLCNUM_SLICE;\n\n\n\n    if (s->max_nal_size)\n\n        s->slice_mode = SM_DYN_SLICE;\n\n\n\n    param.sSpatialLayers[0].sSliceCfg.uiSliceMode               = s->slice_mode;\n\n    param.sSpatialLayers[0].sSliceCfg.sSliceArgument.uiSliceNum = avctx->slices;\n\n\n\n    if (s->slice_mode == SM_DYN_SLICE) {\n\n        if (s->max_nal_size){\n\n            param.uiMaxNalSize = s->max_nal_size;\n\n            param.sSpatialLayers[0].sSliceCfg.sSliceArgument.uiSliceSizeConstraint = s->max_nal_size;\n\n        } else {\n\n            if (avctx->rtp_payload_size) {\n\n                av_log(avctx,AV_LOG_DEBUG,\"Using RTP Payload size for uiMaxNalSize\");\n\n                param.uiMaxNalSize = avctx->rtp_payload_size;\n\n                param.sSpatialLayers[0].sSliceCfg.sSliceArgument.uiSliceSizeConstraint = avctx->rtp_payload_size;\n\n            } else {\n\n                av_log(avctx,AV_LOG_ERROR,\"Invalid -max_nal_size, specify a valid max_nal_size to use -slice_mode dyn\\n\");\n\n                goto fail;\n\n            }\n\n        }\n\n    }\n\n\n\n    if ((*s->encoder)->InitializeExt(s->encoder, &param) != cmResultSuccess) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Initialize failed\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    if (avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) {\n\n        SFrameBSInfo fbi = { 0 };\n\n        int i, size = 0;\n\n        (*s->encoder)->EncodeParameterSets(s->encoder, &fbi);\n\n        for (i = 0; i < fbi.sLayerInfo[0].iNalCount; i++)\n\n            size += fbi.sLayerInfo[0].pNalLengthInByte[i];\n\n        avctx->extradata = av_mallocz(size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!avctx->extradata) {\n\n            err = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n        avctx->extradata_size = size;\n\n        memcpy(avctx->extradata, fbi.sLayerInfo[0].pBsBuf, size);\n\n    }\n\n\n\n    props = ff_add_cpb_side_data(avctx);\n\n    if (!props) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    props->max_bitrate = param.iMaxBitrate;\n\n    props->avg_bitrate = param.iTargetBitrate;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    svc_encode_close(avctx);\n\n    return err;\n\n}\n", "idx": 13809, "_split": "test", "_hash": "386452a706dfd0700f38418d80e66e91"}
{"project": "FFmpeg", "commit_id": "9b2c28e6edbb43e00e0b2d99b95567189cd46e91", "target": 0, "func": "void rgb15to16(const uint8_t *src,uint8_t *dst,uint32_t src_size)\n\n{\n\n#ifdef HAVE_MMX\n\n  register const char* s=src+src_size;\n\n  register char* d=dst+src_size;\n\n  register int offs=-src_size;\n\n  __asm __volatile(PREFETCH\"\t%0\"::\"m\"(*(s+offs)):\"memory\");\n\n  __asm __volatile(\n\n\t\"movq\t%0, %%mm4\\n\\t\"\n\n\t\"movq\t%1, %%mm5\"\n\n\t::\"m\"(mask15b), \"m\"(mask15rg):\"memory\");\n\n  while(offs<0)\n\n  {\n\n\t__asm __volatile(\n\n\t\tPREFETCH\"\t32%1\\n\\t\"\n\n\t\t\"movq\t%1, %%mm0\\n\\t\"\n\n\t\t\"movq\t8%1, %%mm2\\n\\t\"\n\n\t\t\"movq\t%%mm0, %%mm1\\n\\t\"\n\n\t\t\"movq\t%%mm2, %%mm3\\n\\t\"\n\n\t\t\"pand\t%%mm4, %%mm0\\n\\t\"\n\n\t\t\"pand\t%%mm5, %%mm1\\n\\t\"\n\n\t\t\"pand\t%%mm4, %%mm2\\n\\t\"\n\n\t\t\"pand\t%%mm5, %%mm3\\n\\t\"\n\n\t\t\"psllq\t$1, %%mm1\\n\\t\"\n\n\t\t\"psllq\t$1, %%mm3\\n\\t\"\n\n\t\t\"por\t%%mm1, %%mm0\\n\\t\"\n\n\t\t\"por\t%%mm3, %%mm2\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm0, %0\\n\\t\"\n\n\t\tMOVNTQ\"\t%%mm2, 8%0\"\n\n\t\t:\"=m\"(*(d+offs))\n\n\t\t:\"m\"(*(s+offs))\n\n\t\t:\"memory\");\n\n\toffs+=16;\n\n  }\n\n  __asm __volatile(SFENCE:::\"memory\");\n\n  __asm __volatile(EMMS:::\"memory\");\n\n#else\n\n   const uint16_t *s1=( uint16_t * )src;\n\n   uint16_t *d1=( uint16_t * )dst;\n\n   uint16_t *e=((uint8_t *)s1)+src_size;\n\n   while( s1<e ){\n\n     register int x=*( s1++ );\n\n     /* rrrrrggggggbbbbb\n\n        0rrrrrgggggbbbbb\n\n        0111 1111 1110 0000=0x7FE0\n\n        00000000000001 1111=0x001F */\n\n     *( d1++ )=( x&0x001F )|( ( x&0x7FE0 )<<1 );\n\n   }\n\n#endif\n\n}\n", "idx": 13855, "_split": "test", "_hash": "db013a573d265627e21f19c477804b16"}
{"project": "FFmpeg", "commit_id": "4749e074987d45cb98935a683a7ee8e1ee376d86", "target": 1, "func": "static int rle_unpack(const unsigned char *src, unsigned char *dest,\n\n    int src_len, int dest_len)\n\n{\n\n    const unsigned char *ps;\n\n    unsigned char *pd;\n\n    int i, l;\n\n    unsigned char *dest_end = dest + dest_len;\n\n\n\n    ps = src;\n\n    pd = dest;\n\n    if (src_len & 1)\n\n        *pd++ = *ps++;\n\n\n\n    src_len >>= 1;\n\n    i = 0;\n\n    do {\n\n        l = *ps++;\n\n        if (l & 0x80) {\n\n            l = (l & 0x7F) * 2;\n\n            if (pd + l > dest_end)\n\n                return ps - src;\n\n            memcpy(pd, ps, l);\n\n            ps += l;\n\n            pd += l;\n\n        } else {\n\n            if (pd + i > dest_end)\n\n                return ps - src;\n\n            for (i = 0; i < l; i++) {\n\n                *pd++ = ps[0];\n\n                *pd++ = ps[1];\n\n            }\n\n            ps += 2;\n\n        }\n\n        i += l;\n\n    } while (i < src_len);\n\n\n\n    return ps - src;\n\n}\n", "idx": 13859, "_split": "test", "_hash": "c5f2567830630c95d8383848ca196ec3"}
{"project": "FFmpeg", "commit_id": "1181d93231e9b807965724587d363c1cfd5a1d0d", "target": 0, "func": "void ff_avg_h264_qpel16_mc33_msa(uint8_t *dst, const uint8_t *src,\n\n                                 ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_and_aver_dst_16x16_msa(src + stride - 2,\n\n                                           src - (stride * 2) +\n\n                                           sizeof(uint8_t), stride,\n\n                                           dst, stride);\n\n}\n", "idx": 13867, "_split": "test", "_hash": "c2ca2c5b95eae4128147b13d175c9f14"}
{"project": "FFmpeg", "commit_id": "374c907fb35f8236547b24d792fbb9bed201e321", "target": 1, "func": "static int vorbis_parse(AVCodecParserContext *s1, AVCodecContext *avctx,\n\n                        const uint8_t **poutbuf, int *poutbuf_size,\n\n                        const uint8_t *buf, int buf_size)\n\n{\n\n    VorbisParseContext *s = s1->priv_data;\n\n    int duration;\n\n\n\n    if (!s->vp && avctx->extradata && avctx->extradata_size) {\n\n        s->vp = av_vorbis_parse_init(avctx->extradata, avctx->extradata_size);\n\n        if (!s->vp)\n\n            goto end;\n\n    }\n\n\n\n    if ((duration = av_vorbis_parse_frame(s->vp, buf, buf_size)) >= 0)\n\n        s1->duration = duration;\n\n\n\nend:\n\n    /* always return the full packet. this parser isn't doing any splitting or\n\n       combining, only packet analysis */\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return buf_size;\n\n}\n", "idx": 13888, "_split": "test", "_hash": "36a20987790bd322489b3f98610aff55"}
{"project": "FFmpeg", "commit_id": "2f6ec9fdd7808c8ed045ae0ca4134ab21fb785e6", "target": 1, "func": "static int alloc_sequence_buffers(DiracContext *s)\n\n{\n\n    int sbwidth  = DIVRNDUP(s->source.width,  4);\n\n    int sbheight = DIVRNDUP(s->source.height, 4);\n\n    int i, w, h, top_padding;\n\n\n\n    /* todo: think more about this / use or set Plane here */\n\n    for (i = 0; i < 3; i++) {\n\n        int max_xblen = MAX_BLOCKSIZE >> (i ? s->chroma_x_shift : 0);\n\n        int max_yblen = MAX_BLOCKSIZE >> (i ? s->chroma_y_shift : 0);\n\n        w = s->source.width  >> (i ? s->chroma_x_shift : 0);\n\n        h = s->source.height >> (i ? s->chroma_y_shift : 0);\n\n\n\n        /* we allocate the max we support here since num decompositions can\n\n         * change from frame to frame. Stride is aligned to 16 for SIMD, and\n\n         * 1<<MAX_DWT_LEVELS top padding to avoid if(y>0) in arith decoding\n\n         * MAX_BLOCKSIZE padding for MC: blocks can spill up to half of that\n\n         * on each side */\n\n        top_padding = FFMAX(1<<MAX_DWT_LEVELS, max_yblen/2);\n\n        w = FFALIGN(CALC_PADDING(w, MAX_DWT_LEVELS), 8); /* FIXME: Should this be 16 for SSE??? */\n\n        h = top_padding + CALC_PADDING(h, MAX_DWT_LEVELS) + max_yblen/2;\n\n\n\n        s->plane[i].idwt_buf_base = av_mallocz((w+max_xblen)*h * sizeof(IDWTELEM));\n\n        s->plane[i].idwt_tmp      = av_malloc((w+16) * sizeof(IDWTELEM));\n\n        s->plane[i].idwt_buf      = s->plane[i].idwt_buf_base + top_padding*w;\n\n        if (!s->plane[i].idwt_buf_base || !s->plane[i].idwt_tmp)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    w = s->source.width;\n\n    h = s->source.height;\n\n\n\n    /* fixme: allocate using real stride here */\n\n    s->sbsplit  = av_malloc(sbwidth * sbheight);\n\n    s->blmotion = av_malloc(sbwidth * sbheight * 16 * sizeof(*s->blmotion));\n\n    s->edge_emu_buffer_base = av_malloc((w+64)*MAX_BLOCKSIZE);\n\n\n\n    s->mctmp     = av_malloc((w+64+MAX_BLOCKSIZE) * (h*MAX_BLOCKSIZE) * sizeof(*s->mctmp));\n\n    s->mcscratch = av_malloc((w+64)*MAX_BLOCKSIZE);\n\n\n\n    if (!s->sbsplit || !s->blmotion)\n\n        return AVERROR(ENOMEM);\n\n    return 0;\n\n}\n", "idx": 13899, "_split": "test", "_hash": "a2faf5e654beb1901714ac62e38dd0fd"}
{"project": "FFmpeg", "commit_id": "bfeb83a8b7d3fcf09a54d8dbc9c521e10bb17530", "target": 1, "func": "static int hevc_handle_packet(AVFormatContext *ctx, PayloadContext *rtp_hevc_ctx,\n\n                              AVStream *st, AVPacket *pkt, uint32_t *timestamp,\n\n                              const uint8_t *buf, int len, uint16_t seq,\n\n                              int flags)\n\n{\n\n    const uint8_t *rtp_pl = buf;\n\n    int tid, lid, nal_type;\n\n    int first_fragment, last_fragment, fu_type;\n\n    uint8_t new_nal_header[2];\n\n    int res = 0;\n\n\n\n    /* sanity check for size of input packet: 1 byte payload at least */\n\n    if (len < RTP_HEVC_PAYLOAD_HEADER_SIZE + 1) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Too short RTP/HEVC packet, got %d bytes\\n\", len);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /*\n\n     * decode the HEVC payload header according to section 4 of draft version 6:\n\n     *\n\n     *    0                   1\n\n     *    0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5\n\n     *   +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n     *   |F|   Type    |  LayerId  | TID |\n\n     *   +-------------+-----------------+\n\n     *\n\n     *      Forbidden zero (F): 1 bit\n\n     *      NAL unit type (Type): 6 bits\n\n     *      NUH layer ID (LayerId): 6 bits\n\n     *      NUH temporal ID plus 1 (TID): 3 bits\n\n     */\n\n    nal_type =  (buf[0] >> 1) & 0x3f;\n\n    lid  = ((buf[0] << 5) & 0x20) | ((buf[1] >> 3) & 0x1f);\n\n    tid  =   buf[1] & 0x07;\n\n\n\n    /* sanity check for correct layer ID */\n\n    if (lid) {\n\n        /* future scalable or 3D video coding extensions */\n\n        avpriv_report_missing_feature(ctx, \"Multi-layer HEVC coding\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    /* sanity check for correct temporal ID */\n\n    if (!tid) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Illegal temporal ID in RTP/HEVC packet\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* sanity check for correct NAL unit type */\n\n    if (nal_type > 50) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Unsupported (HEVC) NAL type (%d)\\n\", nal_type);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (nal_type) {\n\n    /* video parameter set (VPS) */\n\n    case 32:\n\n    /* sequence parameter set (SPS) */\n\n    case 33:\n\n    /* picture parameter set (PPS) */\n\n    case 34:\n\n    /*  supplemental enhancement information (SEI) */\n\n    case 39:\n\n    /* single NAL unit packet */\n\n    default:\n\n        /* sanity check for size of input packet: 1 byte payload at least */\n\n        if (len < 1) {\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Too short RTP/HEVC packet, got %d bytes of NAL unit type %d\\n\",\n\n                   len, nal_type);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        /* create A/V packet */\n\n        if ((res = av_new_packet(pkt, sizeof(start_sequence) + len)) < 0)\n\n            return res;\n\n        /* A/V packet: copy start sequence */\n\n        memcpy(pkt->data, start_sequence, sizeof(start_sequence));\n\n        /* A/V packet: copy NAL unit data */\n\n        memcpy(pkt->data + sizeof(start_sequence), buf, len);\n\n\n\n        break;\n\n    /* aggregated packet (AP) - with two or more NAL units */\n\n    case 48:\n\n        /* pass the HEVC payload header */\n\n        buf += RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n        len -= RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n\n\n        /* pass the HEVC DONL field */\n\n        if (rtp_hevc_ctx->using_donl_field) {\n\n            buf += RTP_HEVC_DONL_FIELD_SIZE;\n\n            len -= RTP_HEVC_DONL_FIELD_SIZE;\n\n        }\n\n\n\n        res = ff_h264_handle_aggregated_packet(ctx, pkt, buf, len,\n\n                                               rtp_hevc_ctx->using_donl_field ?\n\n                                               RTP_HEVC_DOND_FIELD_SIZE : 0,\n\n                                               NULL, 0);\n\n        if (res < 0)\n\n            return res;\n\n        break;\n\n    /* fragmentation unit (FU) */\n\n    case 49:\n\n        /* pass the HEVC payload header */\n\n        buf += RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n        len -= RTP_HEVC_PAYLOAD_HEADER_SIZE;\n\n\n\n        /*\n\n         *    decode the FU header\n\n         *\n\n         *     0 1 2 3 4 5 6 7\n\n         *    +-+-+-+-+-+-+-+-+\n\n         *    |S|E|  FuType   |\n\n         *    +---------------+\n\n         *\n\n         *       Start fragment (S): 1 bit\n\n         *       End fragment (E): 1 bit\n\n         *       FuType: 6 bits\n\n         */\n\n        first_fragment = buf[0] & 0x80;\n\n        last_fragment  = buf[0] & 0x40;\n\n        fu_type        = buf[0] & 0x3f;\n\n\n\n        /* pass the HEVC FU header */\n\n        buf += RTP_HEVC_FU_HEADER_SIZE;\n\n        len -= RTP_HEVC_FU_HEADER_SIZE;\n\n\n\n        /* pass the HEVC DONL field */\n\n        if (rtp_hevc_ctx->using_donl_field) {\n\n            buf += RTP_HEVC_DONL_FIELD_SIZE;\n\n            len -= RTP_HEVC_DONL_FIELD_SIZE;\n\n        }\n\n\n\n        av_dlog(ctx, \" FU type %d with %d bytes\\n\", fu_type, len);\n\n\n\n        if (len <= 0) {\n\n            /* sanity check for size of input packet: 1 byte payload at least */\n\n            av_log(ctx, AV_LOG_ERROR,\n\n                   \"Too short RTP/HEVC packet, got %d bytes of NAL unit type %d\\n\",\n\n                   len, nal_type);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (first_fragment && last_fragment) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Illegal combination of S and E bit in RTP/HEVC packet\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        new_nal_header[0] = (rtp_pl[0] & 0x81) | (fu_type << 1);\n\n        new_nal_header[1] = rtp_pl[1];\n\n\n\n        res = ff_h264_handle_frag_packet(pkt, buf, len, first_fragment,\n\n                                         new_nal_header, sizeof(new_nal_header));\n\n\n\n        break;\n\n    /* PACI packet */\n\n    case 50:\n\n        /* Temporal scalability control information (TSCI) */\n\n        avpriv_report_missing_feature(ctx, \"PACI packets for RTP/HEVC\\n\");\n\n        res = AVERROR_PATCHWELCOME;\n\n        break;\n\n    }\n\n\n\n    pkt->stream_index = st->index;\n\n\n\n    return res;\n\n}\n", "idx": 13905, "_split": "test", "_hash": "98f138156dc5cf9ad9634b587ff527de"}
{"project": "FFmpeg", "commit_id": "a04c2c707de2ce850f79870e84ac9d7ec7aa9143", "target": 1, "func": "int avpriv_lock_avformat(void)\n\n{\n\n    if (lockmgr_cb) {\n\n        if ((*lockmgr_cb)(&avformat_mutex, AV_LOCK_OBTAIN))\n\n            return -1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 13906, "_split": "test", "_hash": "cdc6d0a880a4f3722d933577db964566"}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "static int libschroedinger_encode_close(AVCodecContext *avctx)\n\n{\n\n    SchroEncoderParams *p_schro_params = avctx->priv_data;\n\n\n\n    /* Close the encoder. */\n\n    schro_encoder_free(p_schro_params->encoder);\n\n\n\n    /* Free data in the output frame queue. */\n\n    ff_schro_queue_free(&p_schro_params->enc_frame_queue,\n\n                        libschroedinger_free_frame);\n\n\n\n\n\n    /* Free the encoder buffer. */\n\n    if (p_schro_params->enc_buf_size)\n\n        av_freep(&p_schro_params->enc_buf);\n\n\n\n    /* Free the video format structure. */\n\n    av_freep(&p_schro_params->format);\n\n\n\n    return 0;\n\n}\n", "idx": 13915, "_split": "test", "_hash": "419cfb7a118fca90146600f098ff767c"}
{"project": "FFmpeg", "commit_id": "121be310607879841d19a34d9f16d4fe9ba7f18c", "target": 0, "func": "static int cinepak_decode_frame(AVCodecContext *avctx,\n\n                                void *data, int *got_frame,\n\n                                AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int ret = 0, buf_size = avpkt->size;\n\n    CinepakContext *s = avctx->priv_data;\n\n\n\n    s->data = buf;\n\n    s->size = buf_size;\n\n\n\n    if ((ret = ff_reget_buffer(avctx, s->frame)) < 0)\n\n        return ret;\n\n\n\n    if (s->palette_video) {\n\n        const uint8_t *pal = av_packet_get_side_data(avpkt, AV_PKT_DATA_PALETTE, NULL);\n\n        if (pal) {\n\n            s->frame->palette_has_changed = 1;\n\n            memcpy(s->pal, pal, AVPALETTE_SIZE);\n\n        }\n\n    }\n\n\n\n    if ((ret = cinepak_decode(s)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"cinepak_decode failed\\n\");\n\n    }\n\n\n\n    if (s->palette_video)\n\n        memcpy (s->frame->data[1], s->pal, AVPALETTE_SIZE);\n\n\n\n    if ((ret = av_frame_ref(data, s->frame)) < 0)\n\n        return ret;\n\n\n\n    *got_frame = 1;\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 13943, "_split": "test", "_hash": "321cd8002397e999926b2848ed38bbc9"}
{"project": "FFmpeg", "commit_id": "ec4c48397641dbaf4ae8df36c32aaa5a311a11bf", "target": 1, "func": "static void *ff_avio_child_next(void *obj, void *prev)\n\n{\n\n    AVIOContext *s = obj;\n\n    AVIOInternal *internal = s->opaque;\n\n    return prev ? NULL : internal->h;\n\n}\n", "idx": 13969, "_split": "test", "_hash": "4e4d43e9fc44631e8cac6cbb5c91bb93"}
{"project": "FFmpeg", "commit_id": "4d87001096ff1d4e3ee6f88f8caddbd8ccb2c816", "target": 1, "func": "static int update_dimensions(VP8Context *s, int width, int height)\n\n{\n\n    if (width  != s->avctx->width ||\n\n        height != s->avctx->height) {\n\n        if (av_image_check_size(width, height, 0, s->avctx))\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        vp8_decode_flush_impl(s->avctx, 1, 0, 1);\n\n\n\n        avcodec_set_dimensions(s->avctx, width, height);\n\n    }\n\n\n\n    s->mb_width  = (s->avctx->coded_width +15) / 16;\n\n    s->mb_height = (s->avctx->coded_height+15) / 16;\n\n\n\n    s->macroblocks_base        = av_mallocz((s->mb_width+s->mb_height*2+1)*sizeof(*s->macroblocks));\n\n    s->filter_strength         = av_mallocz(s->mb_width*sizeof(*s->filter_strength));\n\n    s->intra4x4_pred_mode_top  = av_mallocz(s->mb_width*4);\n\n    s->top_nnz                 = av_mallocz(s->mb_width*sizeof(*s->top_nnz));\n\n    s->top_border              = av_mallocz((s->mb_width+1)*sizeof(*s->top_border));\n\n\n\n    if (!s->macroblocks_base || !s->filter_strength || !s->intra4x4_pred_mode_top ||\n\n        !s->top_nnz || !s->top_border)\n\n        return AVERROR(ENOMEM);\n\n\n\n    s->macroblocks        = s->macroblocks_base + 1;\n\n\n\n    return 0;\n\n}\n", "idx": 14014, "_split": "test", "_hash": "2b84503edb75236ca00d7d6a86ca33f6"}
{"project": "FFmpeg", "commit_id": "f264d336fe61c12ce9607c3060aa5d3dca947c61", "target": 1, "func": "static void truespeech_apply_twopoint_filter(TSContext *dec, int quart)\n\n{\n\n    int16_t tmp[146 + 60], *ptr0, *ptr1;\n\n    const int16_t *filter;\n\n    int i, t, off;\n\n\n\n    t = dec->offset2[quart];\n\n    if(t == 127){\n\n        memset(dec->newvec, 0, 60 * sizeof(*dec->newvec));\n\n        return;\n\n    }\n\n    for(i = 0; i < 146; i++)\n\n        tmp[i] = dec->filtbuf[i];\n\n    off = (t / 25) + dec->offset1[quart >> 1] + 18;\n\n\n    ptr0 = tmp + 145 - off;\n\n    ptr1 = tmp + 146;\n\n    filter = (const int16_t*)ts_order2_coeffs + (t % 25) * 2;\n\n    for(i = 0; i < 60; i++){\n\n        t = (ptr0[0] * filter[0] + ptr0[1] * filter[1] + 0x2000) >> 14;\n\n        ptr0++;\n\n        dec->newvec[i] = t;\n\n        ptr1[i] = t;\n\n    }\n\n}", "idx": 14024, "_split": "test", "_hash": "665210d1ca58dbcae7048f39e91d2d80"}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static int pnm_decode_header(AVCodecContext *avctx, PNMContext * const s){\n\n    char buf1[32], tuple_type[32];\n\n    int h, w, depth, maxval;;\n\n\n\n    pnm_get(s, buf1, sizeof(buf1));\n\n    if (!strcmp(buf1, \"P4\")) {\n\n        avctx->pix_fmt = PIX_FMT_MONOWHITE;\n\n    } else if (!strcmp(buf1, \"P5\")) {\n\n        if (avctx->codec_id == CODEC_ID_PGMYUV) \n\n            avctx->pix_fmt = PIX_FMT_YUV420P;\n\n        else\n\n            avctx->pix_fmt = PIX_FMT_GRAY8;\n\n    } else if (!strcmp(buf1, \"P6\")) {\n\n        avctx->pix_fmt = PIX_FMT_RGB24;\n\n    } else if (!strcmp(buf1, \"P7\")) {\n\n        w = -1;\n\n        h = -1;\n\n        maxval = -1;\n\n        depth = -1;\n\n        tuple_type[0] = '\\0';\n\n        for(;;) {\n\n            pnm_get(s, buf1, sizeof(buf1));\n\n            if (!strcmp(buf1, \"WIDTH\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                w = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"HEIGHT\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                h = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"DEPTH\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                depth = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"MAXVAL\")) {\n\n                pnm_get(s, buf1, sizeof(buf1));\n\n                maxval = strtol(buf1, NULL, 10);\n\n            } else if (!strcmp(buf1, \"TUPLETYPE\")) {\n\n                pnm_get(s, tuple_type, sizeof(tuple_type));\n\n            } else if (!strcmp(buf1, \"ENDHDR\")) {\n\n                break;\n\n            } else {\n\n                return -1;\n\n            }\n\n        }\n\n        /* check that all tags are present */\n\n        if (w <= 0 || h <= 0 || maxval <= 0 || depth <= 0 || tuple_type[0] == '\\0')\n\n            return -1;\n\n        avctx->width = w;\n\n        avctx->height = h;\n\n        if (depth == 1) {\n\n            if (maxval == 1)\n\n                avctx->pix_fmt = PIX_FMT_MONOWHITE;\n\n            else \n\n                avctx->pix_fmt = PIX_FMT_GRAY8;\n\n        } else if (depth == 3) {\n\n            avctx->pix_fmt = PIX_FMT_RGB24;\n\n        } else if (depth == 4) {\n\n            avctx->pix_fmt = PIX_FMT_RGBA32;\n\n        } else {\n\n            return -1;\n\n        }\n\n        return 0;\n\n    } else {\n\n        return -1;\n\n    }\n\n    pnm_get(s, buf1, sizeof(buf1));\n\n    avctx->width = atoi(buf1);\n\n    if (avctx->width <= 0)\n\n        return -1;\n\n    pnm_get(s, buf1, sizeof(buf1));\n\n    avctx->height = atoi(buf1);\n\n    if (avctx->height <= 0)\n\n        return -1;\n\n    if (avctx->pix_fmt != PIX_FMT_MONOWHITE) {\n\n        pnm_get(s, buf1, sizeof(buf1));\n\n    }\n\n\n\n    /* more check if YUV420 */\n\n    if (avctx->pix_fmt == PIX_FMT_YUV420P) {\n\n        if ((avctx->width & 1) != 0)\n\n            return -1;\n\n        h = (avctx->height * 2);\n\n        if ((h % 3) != 0)\n\n            return -1;\n\n        h /= 3;\n\n        avctx->height = h;\n\n    }\n\n    return 0;\n\n}\n", "idx": 14056, "_split": "test", "_hash": "5c1d85e6c04d35c0e975310bf975db42"}
{"project": "FFmpeg", "commit_id": "70143a3954e1c4412efb2bf1a3a818adea2d3abf", "target": 0, "func": "int dxva2_init(AVCodecContext *s)\n\n{\n\n    InputStream *ist = s->opaque;\n\n    int loglevel = (ist->hwaccel_id == HWACCEL_AUTO) ? AV_LOG_VERBOSE : AV_LOG_ERROR;\n\n    DXVA2Context *ctx;\n\n    int ret;\n\n\n\n    if (!ist->hwaccel_ctx) {\n\n        ret = dxva2_alloc(s);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    ctx = ist->hwaccel_ctx;\n\n\n\n    if (s->codec_id == AV_CODEC_ID_H264 &&\n\n        (s->profile & ~FF_PROFILE_H264_CONSTRAINED) > FF_PROFILE_H264_HIGH) {\n\n        av_log(NULL, loglevel, \"Unsupported H.264 profile for DXVA2 HWAccel: %d\\n\", s->profile);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (s->codec_id == AV_CODEC_ID_HEVC &&\n\n        s->profile != FF_PROFILE_HEVC_MAIN && s->profile != FF_PROFILE_HEVC_MAIN_10) {\n\n        av_log(NULL, loglevel, \"Unsupported HEVC profile for DXVA2 HWAccel: %d\\n\", s->profile);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    av_buffer_unref(&ctx->hw_frames_ctx);\n\n\n\n    ret = dxva2_create_decoder(s);\n\n    if (ret < 0) {\n\n        av_log(NULL, loglevel, \"Error creating the DXVA2 decoder\\n\");\n\n        return ret;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 14108, "_split": "test", "_hash": "a68a9d371637c42f8dd78f6425f28094"}
{"project": "FFmpeg", "commit_id": "50c466d609ec60a324a7a776dfdb57c8d38faa11", "target": 1, "func": "static av_cold int g726_encode_init(AVCodecContext *avctx)\n\n{\n\n    G726Context* c = avctx->priv_data;\n\n\n\n    if (avctx->strict_std_compliance > FF_COMPLIANCE_UNOFFICIAL &&\n\n        avctx->sample_rate != 8000) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Sample rates other than 8kHz are not \"\n\n               \"allowed when the compliance level is higher than unofficial. \"\n\n               \"Resample or reduce the compliance level.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if (avctx->sample_rate <= 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Samplerate is invalid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(avctx->channels != 1){\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono is supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if (avctx->bit_rate % avctx->sample_rate) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Bitrate - Samplerate combination is invalid\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    c->code_size = (avctx->bit_rate + avctx->sample_rate/2) / avctx->sample_rate;\n\n    if (c->code_size < 2 || c->code_size > 5) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid number of bits %d\\n\", c->code_size);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    avctx->bits_per_coded_sample = c->code_size;\n\n\n\n    g726_reset(c, c->code_size - 2);\n\n\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n    avctx->coded_frame->key_frame = 1;\n\n\n\n    /* select a frame size that will end on a byte boundary and have a size of\n\n       approximately 1024 bytes */\n\n    avctx->frame_size = ((int[]){ 4096, 2736, 2048, 1640 })[c->code_size - 2];\n\n\n\n    return 0;\n\n}\n", "idx": 14141, "_split": "test", "_hash": "12b1a98dd85d546b05b7fc94f11827c7"}
{"project": "FFmpeg", "commit_id": "8332321c5737cf24ebad504bf10a03818424718d", "target": 1, "func": "static int dv_read_seek(AVFormatContext *s, int stream_index,\n\n                       int64_t timestamp, int flags)\n\n{\n\n    RawDVContext *r   = s->priv_data;\n\n    DVDemuxContext *c = r->dv_demux;\n\n    int64_t offset    = dv_frame_offset(s, c, timestamp, flags);\n\n\n\n    dv_offset_reset(c, offset / c->sys->frame_size);\n\n\n\n    offset = avio_seek(s->pb, offset, SEEK_SET);\n\n    return (offset < 0) ? offset : 0;\n\n}\n", "idx": 14144, "_split": "test", "_hash": "5efb9c49a698e926d56dc52db20d7c5c"}
{"project": "FFmpeg", "commit_id": "70d54392f5015b9c6594fcae558f59f952501e3b", "target": 0, "func": "av_cold int ff_dvvideo_init(AVCodecContext *avctx)\n\n{\n\n    DVVideoContext *s = avctx->priv_data;\n\n    DSPContext dsp;\n\n    static int done = 0;\n\n    int i, j;\n\n\n\n    if (!done) {\n\n        VLC dv_vlc;\n\n        uint16_t new_dv_vlc_bits[NB_DV_VLC*2];\n\n        uint8_t  new_dv_vlc_len[NB_DV_VLC*2];\n\n        uint8_t  new_dv_vlc_run[NB_DV_VLC*2];\n\n        int16_t  new_dv_vlc_level[NB_DV_VLC*2];\n\n\n\n        done = 1;\n\n\n\n        /* it's faster to include sign bit in a generic VLC parsing scheme */\n\n        for (i = 0, j = 0; i < NB_DV_VLC; i++, j++) {\n\n            new_dv_vlc_bits[j]  = dv_vlc_bits[i];\n\n            new_dv_vlc_len[j]   = dv_vlc_len[i];\n\n            new_dv_vlc_run[j]   = dv_vlc_run[i];\n\n            new_dv_vlc_level[j] = dv_vlc_level[i];\n\n\n\n            if (dv_vlc_level[i]) {\n\n                new_dv_vlc_bits[j] <<= 1;\n\n                new_dv_vlc_len[j]++;\n\n\n\n                j++;\n\n                new_dv_vlc_bits[j]  = (dv_vlc_bits[i] << 1) | 1;\n\n                new_dv_vlc_len[j]   =  dv_vlc_len[i] + 1;\n\n                new_dv_vlc_run[j]   =  dv_vlc_run[i];\n\n                new_dv_vlc_level[j] = -dv_vlc_level[i];\n\n            }\n\n        }\n\n\n\n        /* NOTE: as a trick, we use the fact the no codes are unused\n\n           to accelerate the parsing of partial codes */\n\n        init_vlc(&dv_vlc, TEX_VLC_BITS, j,\n\n                 new_dv_vlc_len, 1, 1, new_dv_vlc_bits, 2, 2, 0);\n\n        assert(dv_vlc.table_size == 1184);\n\n\n\n        for (i = 0; i < dv_vlc.table_size; i++){\n\n            int code = dv_vlc.table[i][0];\n\n            int len  = dv_vlc.table[i][1];\n\n            int level, run;\n\n\n\n            if (len < 0){ //more bits needed\n\n                run   = 0;\n\n                level = code;\n\n            } else {\n\n                run   = new_dv_vlc_run  [code] + 1;\n\n                level = new_dv_vlc_level[code];\n\n            }\n\n            ff_dv_rl_vlc[i].len   = len;\n\n            ff_dv_rl_vlc[i].level = level;\n\n            ff_dv_rl_vlc[i].run   = run;\n\n        }\n\n        ff_free_vlc(&dv_vlc);\n\n    }\n\n\n\n    /* Generic DSP setup */\n\n    ff_dsputil_init(&dsp, avctx);\n\n    ff_set_cmp(&dsp, dsp.ildct_cmp, avctx->ildct_cmp);\n\n    s->get_pixels = dsp.get_pixels;\n\n    s->ildct_cmp = dsp.ildct_cmp[5];\n\n\n\n    /* 88DCT setup */\n\n    s->fdct[0]     = dsp.fdct;\n\n    s->idct_put[0] = dsp.idct_put;\n\n    for (i = 0; i < 64; i++)\n\n       s->dv_zigzag[0][i] = dsp.idct_permutation[ff_zigzag_direct[i]];\n\n\n\n    /* 248DCT setup */\n\n    s->fdct[1]     = dsp.fdct248;\n\n    s->idct_put[1] = ff_simple_idct248_put;  // FIXME: need to add it to DSP\n\n    memcpy(s->dv_zigzag[1], ff_zigzag248_direct, 64);\n\n\n\n    avctx->coded_frame = &s->picture;\n\n    s->avctx = avctx;\n\n    avctx->chroma_sample_location = AVCHROMA_LOC_TOPLEFT;\n\n\n\n    return 0;\n\n}\n", "idx": 14168, "_split": "test", "_hash": "e3684c03e117d7e015ecb20ce44c03a4"}
{"project": "FFmpeg", "commit_id": "4641ae352ec587355764ffd5c43dd0d0ebd47654", "target": 1, "func": "static int libquvi_read_header(AVFormatContext *s)\n\n{\n\n    int i, ret;\n\n    quvi_t q;\n\n    quvi_media_t m;\n\n    QUVIcode rc;\n\n    LibQuviContext *qc = s->priv_data;\n\n    char *media_url, *pagetitle;\n\n\n\n    rc = quvi_init(&q);\n\n    if (rc != QUVI_OK)\n\n        goto quvi_fail;\n\n\n\n    quvi_setopt(q, QUVIOPT_FORMAT, qc->format);\n\n\n\n    rc = quvi_parse(q, s->filename, &m);\n\n    if (rc != QUVI_OK)\n\n        goto quvi_fail;\n\n\n\n    rc = quvi_getprop(m, QUVIPROP_MEDIAURL, &media_url);\n\n    if (rc != QUVI_OK)\n\n        goto quvi_fail;\n\n\n\n    av_assert0(!qc->fmtctx->codec_whitelist && !qc->fmtctx->format_whitelist);\n\n    qc->fmtctx-> codec_whitelist = av_strdup(s->codec_whitelist);\n\n    qc->fmtctx->format_whitelist = av_strdup(s->format_whitelist);\n\n\n\n    ret = avformat_open_input(&qc->fmtctx, media_url, NULL, NULL);\n\n    if (ret < 0)\n\n        goto end;\n\n\n\n    rc = quvi_getprop(m, QUVIPROP_PAGETITLE, &pagetitle);\n\n    if (rc == QUVI_OK)\n\n        av_dict_set(&s->metadata, \"title\", pagetitle, 0);\n\n\n\n    for (i = 0; i < qc->fmtctx->nb_streams; i++) {\n\n        AVStream *st = avformat_new_stream(s, NULL);\n\n        AVStream *ist = qc->fmtctx->streams[i];\n\n        if (!st) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto end;\n\n        }\n\n        avpriv_set_pts_info(st, ist->pts_wrap_bits, ist->time_base.num, ist->time_base.den);\n\n        avcodec_copy_context(st->codec, qc->fmtctx->streams[i]->codec);\n\n    }\n\n\n\n    return 0;\n\n\n\nquvi_fail:\n\n    av_log(s, AV_LOG_ERROR, \"%s\\n\", quvi_strerror(q, rc));\n\n    ret = AVERROR_EXTERNAL;\n\n\n\nend:\n\n    quvi_parse_close(&m);\n\n    quvi_close(&q);\n\n    return ret;\n\n}\n", "idx": 14199, "_split": "test", "_hash": "3375567a64d2468cf2bd8e4050629392"}
{"project": "FFmpeg", "commit_id": "c0bc8b9afb7e4f39d84080870b9feedcd23ab5c9", "target": 1, "func": "LF_FUNC (h,  luma,         sse2)\n\nLF_IFUNC(h,  luma_intra,   sse2)\n\nLF_FUNC (v,  luma,         sse2)\n\nLF_IFUNC(v,  luma_intra,   sse2)\n\n\n\n/***********************************/\n\n/* weighted prediction */\n\n\n\n#define H264_WEIGHT(W, H, OPT) \\\n\nvoid ff_h264_weight_ ## W ## x ## H ## _ ## OPT(uint8_t *dst, \\\n\n    int stride, int log2_denom, int weight, int offset);\n\n\n\n#define H264_BIWEIGHT(W, H, OPT) \\\n\nvoid ff_h264_biweight_ ## W ## x ## H ## _ ## OPT(uint8_t *dst, \\\n\n    uint8_t *src, int stride, int log2_denom, int weightd, \\\n\n    int weights, int offset);\n\n\n\n#define H264_BIWEIGHT_MMX(W,H) \\\n\nH264_WEIGHT  (W, H, mmx2) \\\n\nH264_BIWEIGHT(W, H, mmx2)\n\n\n\n#define H264_BIWEIGHT_MMX_SSE(W,H) \\\n\nH264_BIWEIGHT_MMX(W, H) \\\n\nH264_WEIGHT      (W, H, sse2) \\\n\nH264_BIWEIGHT    (W, H, sse2) \\\n\nH264_BIWEIGHT    (W, H, ssse3)\n\n\n\nH264_BIWEIGHT_MMX_SSE(16, 16)\n\nH264_BIWEIGHT_MMX_SSE(16,  8)\n\nH264_BIWEIGHT_MMX_SSE( 8, 16)\n\nH264_BIWEIGHT_MMX_SSE( 8,  8)\n\nH264_BIWEIGHT_MMX_SSE( 8,  4)\n\nH264_BIWEIGHT_MMX    ( 4,  8)\n\nH264_BIWEIGHT_MMX    ( 4,  4)\n\nH264_BIWEIGHT_MMX    ( 4,  2)\n\n\n\nvoid ff_h264dsp_init_x86(H264DSPContext *c)\n\n{\n\n    int mm_flags = av_get_cpu_flags();\n\n\n\n    if (mm_flags & AV_CPU_FLAG_MMX2) {\n\n        c->h264_loop_filter_strength= h264_loop_filter_strength_mmx2;\n\n    }\n\n#if HAVE_YASM\n\n    if (mm_flags & AV_CPU_FLAG_MMX) {\n\n        c->h264_idct_dc_add=\n\n        c->h264_idct_add= ff_h264_idct_add_mmx;\n\n        c->h264_idct8_dc_add=\n\n        c->h264_idct8_add= ff_h264_idct8_add_mmx;\n\n\n\n        c->h264_idct_add16     = ff_h264_idct_add16_mmx;\n\n        c->h264_idct8_add4     = ff_h264_idct8_add4_mmx;\n\n        c->h264_idct_add8      = ff_h264_idct_add8_mmx;\n\n        c->h264_idct_add16intra= ff_h264_idct_add16intra_mmx;\n\n\n\n        if (mm_flags & AV_CPU_FLAG_MMX2) {\n\n            c->h264_idct_dc_add= ff_h264_idct_dc_add_mmx2;\n\n            c->h264_idct8_dc_add= ff_h264_idct8_dc_add_mmx2;\n\n            c->h264_idct_add16     = ff_h264_idct_add16_mmx2;\n\n            c->h264_idct8_add4     = ff_h264_idct8_add4_mmx2;\n\n            c->h264_idct_add8      = ff_h264_idct_add8_mmx2;\n\n            c->h264_idct_add16intra= ff_h264_idct_add16intra_mmx2;\n\n\n\n            c->h264_v_loop_filter_chroma= ff_x264_deblock_v_chroma_mmxext;\n\n            c->h264_h_loop_filter_chroma= ff_x264_deblock_h_chroma_mmxext;\n\n            c->h264_v_loop_filter_chroma_intra= ff_x264_deblock_v_chroma_intra_mmxext;\n\n            c->h264_h_loop_filter_chroma_intra= ff_x264_deblock_h_chroma_intra_mmxext;\n\n#if ARCH_X86_32\n\n            c->h264_v_loop_filter_luma= ff_x264_deblock_v_luma_mmxext;\n\n            c->h264_h_loop_filter_luma= ff_x264_deblock_h_luma_mmxext;\n\n            c->h264_v_loop_filter_luma_intra = ff_x264_deblock_v_luma_intra_mmxext;\n\n            c->h264_h_loop_filter_luma_intra = ff_x264_deblock_h_luma_intra_mmxext;\n\n\n            c->weight_h264_pixels_tab[0]= ff_h264_weight_16x16_mmx2;\n\n            c->weight_h264_pixels_tab[1]= ff_h264_weight_16x8_mmx2;\n\n            c->weight_h264_pixels_tab[2]= ff_h264_weight_8x16_mmx2;\n\n            c->weight_h264_pixels_tab[3]= ff_h264_weight_8x8_mmx2;\n\n            c->weight_h264_pixels_tab[4]= ff_h264_weight_8x4_mmx2;\n\n            c->weight_h264_pixels_tab[5]= ff_h264_weight_4x8_mmx2;\n\n            c->weight_h264_pixels_tab[6]= ff_h264_weight_4x4_mmx2;\n\n            c->weight_h264_pixels_tab[7]= ff_h264_weight_4x2_mmx2;\n\n\n\n            c->biweight_h264_pixels_tab[0]= ff_h264_biweight_16x16_mmx2;\n\n            c->biweight_h264_pixels_tab[1]= ff_h264_biweight_16x8_mmx2;\n\n            c->biweight_h264_pixels_tab[2]= ff_h264_biweight_8x16_mmx2;\n\n            c->biweight_h264_pixels_tab[3]= ff_h264_biweight_8x8_mmx2;\n\n            c->biweight_h264_pixels_tab[4]= ff_h264_biweight_8x4_mmx2;\n\n            c->biweight_h264_pixels_tab[5]= ff_h264_biweight_4x8_mmx2;\n\n            c->biweight_h264_pixels_tab[6]= ff_h264_biweight_4x4_mmx2;\n\n            c->biweight_h264_pixels_tab[7]= ff_h264_biweight_4x2_mmx2;\n\n\n\n            if (mm_flags&AV_CPU_FLAG_SSE2) {\n\n                c->h264_idct8_add = ff_h264_idct8_add_sse2;\n\n                c->h264_idct8_add4= ff_h264_idct8_add4_sse2;\n\n\n\n                c->weight_h264_pixels_tab[0]= ff_h264_weight_16x16_sse2;\n\n                c->weight_h264_pixels_tab[1]= ff_h264_weight_16x8_sse2;\n\n                c->weight_h264_pixels_tab[2]= ff_h264_weight_8x16_sse2;\n\n                c->weight_h264_pixels_tab[3]= ff_h264_weight_8x8_sse2;\n\n                c->weight_h264_pixels_tab[4]= ff_h264_weight_8x4_sse2;\n\n\n\n                c->biweight_h264_pixels_tab[0]= ff_h264_biweight_16x16_sse2;\n\n                c->biweight_h264_pixels_tab[1]= ff_h264_biweight_16x8_sse2;\n\n                c->biweight_h264_pixels_tab[2]= ff_h264_biweight_8x16_sse2;\n\n                c->biweight_h264_pixels_tab[3]= ff_h264_biweight_8x8_sse2;\n\n                c->biweight_h264_pixels_tab[4]= ff_h264_biweight_8x4_sse2;\n\n\n\n\n                c->h264_v_loop_filter_luma = ff_x264_deblock_v_luma_sse2;\n\n                c->h264_h_loop_filter_luma = ff_x264_deblock_h_luma_sse2;\n\n                c->h264_v_loop_filter_luma_intra = ff_x264_deblock_v_luma_intra_sse2;\n\n                c->h264_h_loop_filter_luma_intra = ff_x264_deblock_h_luma_intra_sse2;\n\n\n\n\n                c->h264_idct_add16 = ff_h264_idct_add16_sse2;\n\n                c->h264_idct_add8  = ff_h264_idct_add8_sse2;\n\n                c->h264_idct_add16intra = ff_h264_idct_add16intra_sse2;\n\n            }\n\n            if (mm_flags&AV_CPU_FLAG_SSSE3) {\n\n                c->biweight_h264_pixels_tab[0]= ff_h264_biweight_16x16_ssse3;\n\n                c->biweight_h264_pixels_tab[1]= ff_h264_biweight_16x8_ssse3;\n\n                c->biweight_h264_pixels_tab[2]= ff_h264_biweight_8x16_ssse3;\n\n                c->biweight_h264_pixels_tab[3]= ff_h264_biweight_8x8_ssse3;\n\n                c->biweight_h264_pixels_tab[4]= ff_h264_biweight_8x4_ssse3;\n\n            }\n\n        }\n\n    }\n\n\n}", "idx": 14248, "_split": "test", "_hash": "0ea1bf078474e9d51669600d63cd09a5"}
{"project": "FFmpeg", "commit_id": "6202e2fede75df92cbc374a3f7d6893d0c5ac721", "target": 0, "func": "static int decode_band_hdr(IVI45DecContext *ctx, IVIBandDesc *band,\n\n                           AVCodecContext *avctx)\n\n{\n\n    int plane, band_num, indx, transform_id, scan_indx;\n\n    int i;\n\n\n\n    plane    = get_bits(&ctx->gb, 2);\n\n    band_num = get_bits(&ctx->gb, 4);\n\n    if (band->plane != plane || band->band_num != band_num) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid band header sequence!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    band->is_empty = get_bits1(&ctx->gb);\n\n    if (!band->is_empty) {\n\n        int old_blk_size = band->blk_size;\n\n        /* skip header size\n\n         * If header size is not given, header size is 4 bytes. */\n\n        if (get_bits1(&ctx->gb))\n\n            skip_bits(&ctx->gb, 16);\n\n\n\n        band->is_halfpel = get_bits(&ctx->gb, 2);\n\n        if (band->is_halfpel >= 2) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid/unsupported mv resolution: %d!\\n\",\n\n                   band->is_halfpel);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n#if IVI4_STREAM_ANALYSER\n\n        if (!band->is_halfpel)\n\n            ctx->uses_fullpel = 1;\n\n#endif\n\n\n\n        band->checksum_present = get_bits1(&ctx->gb);\n\n        if (band->checksum_present)\n\n            band->checksum = get_bits(&ctx->gb, 16);\n\n\n\n        indx = get_bits(&ctx->gb, 2);\n\n        if (indx == 3) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid block size!\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        band->mb_size  = 16 >> indx;\n\n        band->blk_size = 8 >> (indx >> 1);\n\n\n\n        band->inherit_mv     = get_bits1(&ctx->gb);\n\n        band->inherit_qdelta = get_bits1(&ctx->gb);\n\n\n\n        band->glob_quant = get_bits(&ctx->gb, 5);\n\n\n\n        if (!get_bits1(&ctx->gb) || ctx->frame_type == IVI4_FRAMETYPE_INTRA) {\n\n            transform_id = get_bits(&ctx->gb, 5);\n\n            if (transform_id >= FF_ARRAY_ELEMS(transforms) ||\n\n                !transforms[transform_id].inv_trans) {\n\n                avpriv_request_sample(avctx, \"Transform %d\", transform_id);\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n            if ((transform_id >= 7 && transform_id <= 9) ||\n\n                 transform_id == 17) {\n\n                avpriv_request_sample(avctx, \"DCT transform\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n#if IVI4_STREAM_ANALYSER\n\n            if ((transform_id >= 0 && transform_id <= 2) || transform_id == 10)\n\n                ctx->uses_haar = 1;\n\n#endif\n\n\n\n            band->inv_transform = transforms[transform_id].inv_trans;\n\n            band->dc_transform  = transforms[transform_id].dc_trans;\n\n            band->is_2d_trans   = transforms[transform_id].is_2d_trans;\n\n            if (transform_id < 10)\n\n                band->transform_size = 8;\n\n            else\n\n                band->transform_size = 4;\n\n\n\n            if (band->blk_size != band->transform_size)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            scan_indx = get_bits(&ctx->gb, 4);\n\n            if (scan_indx == 15) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Custom scan pattern encountered!\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (scan_indx > 4 && scan_indx < 10) {\n\n                if (band->blk_size != 4)\n\n                    return AVERROR_INVALIDDATA;\n\n            } else if (band->blk_size != 8)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            band->scan = scan_index_to_tab[scan_indx];\n\n\n\n            band->quant_mat = get_bits(&ctx->gb, 5);\n\n            if (band->quant_mat >= FF_ARRAY_ELEMS(quant_index_to_tab)) {\n\n\n\n                if (band->quant_mat == 31)\n\n                    av_log(avctx, AV_LOG_ERROR,\n\n                           \"Custom quant matrix encountered!\\n\");\n\n                else\n\n                    avpriv_request_sample(avctx, \"Quantization matrix %d\",\n\n                                          band->quant_mat);\n\n                band->quant_mat = -1;\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        } else {\n\n            if (old_blk_size != band->blk_size) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"The band block size does not match the configuration \"\n\n                       \"inherited\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            if (band->quant_mat < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Invalid quant_mat inherited\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n\n\n        /* decode block huffman codebook */\n\n        if (!get_bits1(&ctx->gb))\n\n            band->blk_vlc.tab = ctx->blk_vlc.tab;\n\n        else\n\n            if (ff_ivi_dec_huff_desc(&ctx->gb, 1, IVI_BLK_HUFF,\n\n                                     &band->blk_vlc, avctx))\n\n                return AVERROR_INVALIDDATA;\n\n\n\n        /* select appropriate rvmap table for this band */\n\n        band->rvmap_sel = get_bits1(&ctx->gb) ? get_bits(&ctx->gb, 3) : 8;\n\n\n\n        /* decode rvmap probability corrections if any */\n\n        band->num_corr = 0; /* there is no corrections */\n\n        if (get_bits1(&ctx->gb)) {\n\n            band->num_corr = get_bits(&ctx->gb, 8); /* get number of correction pairs */\n\n            if (band->num_corr > 61) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Too many corrections: %d\\n\",\n\n                       band->num_corr);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            /* read correction pairs */\n\n            for (i = 0; i < band->num_corr * 2; i++)\n\n                band->corr[i] = get_bits(&ctx->gb, 8);\n\n        }\n\n    }\n\n\n\n    if (band->blk_size == 8) {\n\n        band->intra_base = &ivi4_quant_8x8_intra[quant_index_to_tab[band->quant_mat]][0];\n\n        band->inter_base = &ivi4_quant_8x8_inter[quant_index_to_tab[band->quant_mat]][0];\n\n    } else {\n\n        band->intra_base = &ivi4_quant_4x4_intra[quant_index_to_tab[band->quant_mat]][0];\n\n        band->inter_base = &ivi4_quant_4x4_inter[quant_index_to_tab[band->quant_mat]][0];\n\n    }\n\n\n\n    /* Indeo 4 doesn't use scale tables */\n\n    band->intra_scale = NULL;\n\n    band->inter_scale = NULL;\n\n\n\n    align_get_bits(&ctx->gb);\n\n\n\n    return 0;\n\n}\n", "idx": 14263, "_split": "test", "_hash": "84dfd7679dc5e805632960f46a9e5590"}
{"project": "FFmpeg", "commit_id": "f1ffb01ee9fd3a15c395c3cf6ff362ac5cd668d0", "target": 0, "func": "static int synchronize_audio(VideoState *is, short *samples,\n\n                             int samples_size1, double pts)\n\n{\n\n    int n, samples_size;\n\n    double ref_clock;\n\n\n\n    n = 2 * is->audio_st->codec->channels;\n\n    samples_size = samples_size1;\n\n\n\n    /* if not master, then we try to remove or add samples to correct the clock */\n\n    if (((is->av_sync_type == AV_SYNC_VIDEO_MASTER && is->video_st) ||\n\n         is->av_sync_type == AV_SYNC_EXTERNAL_CLOCK)) {\n\n        double diff, avg_diff;\n\n        int wanted_size, min_size, max_size, nb_samples;\n\n\n\n        ref_clock = get_master_clock(is);\n\n        diff = get_audio_clock(is) - ref_clock;\n\n\n\n        if (diff < AV_NOSYNC_THRESHOLD) {\n\n            is->audio_diff_cum = diff + is->audio_diff_avg_coef * is->audio_diff_cum;\n\n            if (is->audio_diff_avg_count < AUDIO_DIFF_AVG_NB) {\n\n                /* not enough measures to have a correct estimate */\n\n                is->audio_diff_avg_count++;\n\n            } else {\n\n                /* estimate the A-V difference */\n\n                avg_diff = is->audio_diff_cum * (1.0 - is->audio_diff_avg_coef);\n\n\n\n                if (fabs(avg_diff) >= is->audio_diff_threshold) {\n\n                    wanted_size = samples_size + ((int)(diff * is->audio_st->codec->sample_rate) * n);\n\n                    nb_samples = samples_size / n;\n\n\n\n                    min_size = ((nb_samples * (100 - SAMPLE_CORRECTION_PERCENT_MAX)) / 100) * n;\n\n                    max_size = ((nb_samples * (100 + SAMPLE_CORRECTION_PERCENT_MAX)) / 100) * n;\n\n                    if (wanted_size < min_size)\n\n                        wanted_size = min_size;\n\n                    else if (wanted_size > max_size)\n\n                        wanted_size = max_size;\n\n\n\n                    /* add or remove samples to correction the synchro */\n\n                    if (wanted_size < samples_size) {\n\n                        /* remove samples */\n\n                        samples_size = wanted_size;\n\n                    } else if (wanted_size > samples_size) {\n\n                        uint8_t *samples_end, *q;\n\n                        int nb;\n\n\n\n                        /* add samples */\n\n                        nb = (samples_size - wanted_size);\n\n                        samples_end = (uint8_t *)samples + samples_size - n;\n\n                        q = samples_end + n;\n\n                        while (nb > 0) {\n\n                            memcpy(q, samples_end, n);\n\n                            q += n;\n\n                            nb -= n;\n\n                        }\n\n                        samples_size = wanted_size;\n\n                    }\n\n                }\n\n                av_dlog(NULL, \"diff=%f adiff=%f sample_diff=%d apts=%0.3f vpts=%0.3f %f\\n\",\n\n                        diff, avg_diff, samples_size - samples_size1,\n\n                        is->audio_clock, is->video_clock, is->audio_diff_threshold);\n\n            }\n\n        } else {\n\n            /* too big difference : may be initial PTS errors, so\n\n               reset A-V filter */\n\n            is->audio_diff_avg_count = 0;\n\n            is->audio_diff_cum       = 0;\n\n        }\n\n    }\n\n\n\n    return samples_size;\n\n}\n", "idx": 14306, "_split": "test", "_hash": "10ab09f3aaaaf6050eb0cea2b15b465e"}
{"project": "FFmpeg", "commit_id": "a82468514048fb87d9bf38689866bc3b9aaccd02", "target": 1, "func": "av_cold int ff_ivi_init_planes(IVIPlaneDesc *planes, const IVIPicConfig *cfg,\n\n                               int is_indeo4)\n\n{\n\n    int p, b;\n\n    uint32_t b_width, b_height, align_fac, width_aligned,\n\n             height_aligned, buf_size;\n\n    IVIBandDesc *band;\n\n\n\n    ivi_free_buffers(planes);\n\n\n\n    if (av_image_check_size(cfg->pic_width, cfg->pic_height, 0, NULL) < 0 ||\n\n        cfg->luma_bands < 1 || cfg->chroma_bands < 1)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    /* fill in the descriptor of the luminance plane */\n\n    planes[0].width     = cfg->pic_width;\n\n    planes[0].height    = cfg->pic_height;\n\n    planes[0].num_bands = cfg->luma_bands;\n\n\n\n    /* fill in the descriptors of the chrominance planes */\n\n    planes[1].width     = planes[2].width     = (cfg->pic_width  + 3) >> 2;\n\n    planes[1].height    = planes[2].height    = (cfg->pic_height + 3) >> 2;\n\n    planes[1].num_bands = planes[2].num_bands = cfg->chroma_bands;\n\n\n\n    for (p = 0; p < 3; p++) {\n\n        planes[p].bands = av_mallocz_array(planes[p].num_bands, sizeof(IVIBandDesc));\n\n        if (!planes[p].bands)\n\n            return AVERROR(ENOMEM);\n\n\n\n        /* select band dimensions: if there is only one band then it\n\n         *  has the full size, if there are several bands each of them\n\n         *  has only half size */\n\n        b_width  = planes[p].num_bands == 1 ? planes[p].width\n\n                                            : (planes[p].width  + 1) >> 1;\n\n        b_height = planes[p].num_bands == 1 ? planes[p].height\n\n                                            : (planes[p].height + 1) >> 1;\n\n\n\n        /* luma   band buffers will be aligned on 16x16 (max macroblock size) */\n\n        /* chroma band buffers will be aligned on   8x8 (max macroblock size) */\n\n        align_fac       = p ? 8 : 16;\n\n        width_aligned   = FFALIGN(b_width , align_fac);\n\n        height_aligned  = FFALIGN(b_height, align_fac);\n\n        buf_size        = width_aligned * height_aligned * sizeof(int16_t);\n\n\n\n        for (b = 0; b < planes[p].num_bands; b++) {\n\n            band = &planes[p].bands[b]; /* select appropriate plane/band */\n\n            band->plane    = p;\n\n            band->band_num = b;\n\n            band->width    = b_width;\n\n            band->height   = b_height;\n\n            band->pitch    = width_aligned;\n\n            band->aheight  = height_aligned;\n\n            band->bufs[0]  = av_mallocz(buf_size);\n\n            band->bufs[1]  = av_mallocz(buf_size);\n\n            band->bufsize  = buf_size/2;\n\n            if (!band->bufs[0] || !band->bufs[1])\n\n                return AVERROR(ENOMEM);\n\n\n\n            /* allocate the 3rd band buffer for scalability mode */\n\n            if (cfg->luma_bands > 1) {\n\n                band->bufs[2] = av_mallocz(buf_size);\n\n                if (!band->bufs[2])\n\n                    return AVERROR(ENOMEM);\n\n            }\n\n            if (is_indeo4) {\n\n                band->bufs[3]  = av_mallocz(buf_size);\n\n                if (!band->bufs[3])\n\n                    return AVERROR(ENOMEM);\n\n            }\n\n            /* reset custom vlc */\n\n            planes[p].bands[0].blk_vlc.cust_desc.num_rows = 0;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 14308, "_split": "test", "_hash": "d5ba7902d7b834cacd396f2dd9c235f1"}
{"project": "FFmpeg", "commit_id": "ce551a3925a1cf9c7824e26a246b99b6773bda4b", "target": 1, "func": "static av_cold int seqvideo_decode_init(AVCodecContext *avctx)\n{\n    SeqVideoContext *seq = avctx->priv_data;\n    seq->avctx = avctx;\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n    seq->frame = av_frame_alloc();\n    if (!seq->frame)\n        return AVERROR(ENOMEM);\n    return 0;\n}", "idx": 14309, "_split": "test", "_hash": "fc000399d6f3cbb9d03b60a8d1d17754"}
{"project": "FFmpeg", "commit_id": "7cc84d241ba6ef8e27e4d057176a4ad385ad3d59", "target": 1, "func": "static int standard_decode_picture_secondary_header(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    int status = 0, index;\n\n\n\n    switch (v->s.pict_type)\n\n    {\n\n    case P_TYPE: status = decode_p_picture_secondary_header(v); break;\n\n    case B_TYPE: status = decode_b_picture_secondary_header(v); break;\n\n    case BI_TYPE:\n\n    case I_TYPE: break; //Nothing needed as it's done in the epilog\n\n    }\n\n    if (status < 0) return FRAME_SKIPED;\n\n\n\n    /* AC Syntax */\n\n    v->ac_table_level = decode012(gb);\n\n    if (v->s.pict_type == I_TYPE || v->s.pict_type == BI_TYPE)\n\n    {\n\n        v->ac2_table_level = decode012(gb);\n\n    }\n\n    /* DC Syntax */\n\n    index = decode012(gb);\n\n    v->luma_dc_vlc = &ff_msmp4_dc_luma_vlc[index];\n\n    v->chroma_dc_vlc = &ff_msmp4_dc_chroma_vlc[index];\n\n   \n\n    return 0;\n\n}\n", "idx": 14350, "_split": "test", "_hash": "f6b56c35494255c43ce1f8aab142d381"}
{"project": "FFmpeg", "commit_id": "7da9f4523159670d577a2808d4481e64008a8894", "target": 1, "func": "static int write_cvid_header(CinepakEncContext *s, unsigned char *buf, int num_strips, int data_size)\n\n{\n\n    buf[0] = 0;\n\n    AV_WB24(&buf[1], data_size + CVID_HEADER_SIZE);\n\n    AV_WB16(&buf[4], s->w);\n\n    AV_WB16(&buf[6], s->h);\n\n    AV_WB16(&buf[8], num_strips);\n\n\n\n    return CVID_HEADER_SIZE;\n\n}\n", "idx": 14359, "_split": "test", "_hash": "2adcda782578a2657ceca1f5444369d1"}
{"project": "FFmpeg", "commit_id": "f907615f0813e8499f06a7eebccf1c63fce87c8e", "target": 1, "func": "static av_cold int mpeg4video_parse_init(AVCodecParserContext *s)\n\n{\n\n    ParseContext1 *pc = s->priv_data;\n\n\n\n    pc->enc = av_mallocz(sizeof(MpegEncContext));\n\n    if (!pc->enc)\n\n        return -1;\n\n    pc->first_picture = 1;\n\n\n    return 0;\n\n}", "idx": 14362, "_split": "test", "_hash": "a2d6f10dcfa47f127bb0f05d50d85ad8"}
{"project": "FFmpeg", "commit_id": "a6d6b8a20072a5919d38258dd48cc612e2372f81", "target": 1, "func": "const AVOption *av_opt_next(void *obj, const AVOption *last)\n\n{\n\n    AVClass *class = *(AVClass**)obj;\n\n    if (!last && class->option[0].name) return class->option;\n\n    if (last && last[1].name)           return ++last;\n\n    return NULL;\n\n}\n", "idx": 14366, "_split": "test", "_hash": "a6296158e8f3114dec6c8fcbe6ad0ed8"}
{"project": "FFmpeg", "commit_id": "369cb092ecbbaff20bb0a2a1d60536c3bc04a8f0", "target": 1, "func": "static void do_audio_out(AVFormatContext *s, OutputStream *ost,\n\n                         InputStream *ist, AVFrame *decoded_frame)\n\n{\n\n    uint8_t *buftmp;\n\n\n\n    int size_out, frame_bytes, resample_changed, ret;\n\n    AVCodecContext *enc = ost->st->codec;\n\n    AVCodecContext *dec = ist->st->codec;\n\n    int osize = av_get_bytes_per_sample(enc->sample_fmt);\n\n    int isize = av_get_bytes_per_sample(dec->sample_fmt);\n\n    uint8_t *buf = decoded_frame->data[0];\n\n    int size     = decoded_frame->nb_samples * dec->channels * isize;\n\n    int out_linesize = 0;\n\n    int buf_linesize = decoded_frame->linesize[0];\n\n\n\n    get_default_channel_layouts(ost, ist);\n\n\n\n    if (alloc_audio_output_buf(dec, enc, decoded_frame->nb_samples, &out_linesize) < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"Error allocating audio buffer\\n\");\n\n        exit_program(1);\n\n    }\n\n\n\n    if (audio_sync_method > 1                      ||\n\n        enc->channels       != dec->channels       ||\n\n        enc->channel_layout != dec->channel_layout ||\n\n        enc->sample_rate    != dec->sample_rate    ||\n\n        dec->sample_fmt     != enc->sample_fmt)\n\n        ost->audio_resample = 1;\n\n\n\n    resample_changed = ost->resample_sample_fmt  != dec->sample_fmt ||\n\n                       ost->resample_channels    != dec->channels   ||\n\n                       ost->resample_channel_layout != dec->channel_layout ||\n\n                       ost->resample_sample_rate != dec->sample_rate;\n\n\n\n    if ((ost->audio_resample && !ost->avr) || resample_changed) {\n\n        if (resample_changed) {\n\n            av_log(NULL, AV_LOG_INFO, \"Input stream #%d:%d frame changed from rate:%d fmt:%s ch:%d chl:0x%\"PRIx64\" to rate:%d fmt:%s ch:%d chl:0x%\"PRIx64\"\\n\",\n\n                   ist->file_index, ist->st->index,\n\n                   ost->resample_sample_rate, av_get_sample_fmt_name(ost->resample_sample_fmt),\n\n                   ost->resample_channels, ost->resample_channel_layout,\n\n                   dec->sample_rate, av_get_sample_fmt_name(dec->sample_fmt),\n\n                   dec->channels, dec->channel_layout);\n\n            ost->resample_sample_fmt  = dec->sample_fmt;\n\n            ost->resample_channels    = dec->channels;\n\n            ost->resample_channel_layout = dec->channel_layout;\n\n            ost->resample_sample_rate = dec->sample_rate;\n\n            if (ost->avr)\n\n                avresample_close(ost->avr);\n\n        }\n\n        /* if audio_sync_method is >1 the resampler is needed for audio drift compensation */\n\n        if (audio_sync_method <= 1 &&\n\n            ost->resample_sample_fmt  == enc->sample_fmt &&\n\n            ost->resample_channels    == enc->channels   &&\n\n            ost->resample_channel_layout == enc->channel_layout &&\n\n            ost->resample_sample_rate == enc->sample_rate) {\n\n            ost->audio_resample = 0;\n\n        } else if (ost->audio_resample) {\n\n            if (!ost->avr) {\n\n                ost->avr = avresample_alloc_context();\n\n                if (!ost->avr) {\n\n                    av_log(NULL, AV_LOG_FATAL, \"Error allocating context for libavresample\\n\");\n\n                    exit_program(1);\n\n                }\n\n            }\n\n\n\n            av_opt_set_int(ost->avr, \"in_channel_layout\",  dec->channel_layout, 0);\n\n            av_opt_set_int(ost->avr, \"in_sample_fmt\",      dec->sample_fmt,     0);\n\n            av_opt_set_int(ost->avr, \"in_sample_rate\",     dec->sample_rate,    0);\n\n            av_opt_set_int(ost->avr, \"out_channel_layout\", enc->channel_layout, 0);\n\n            av_opt_set_int(ost->avr, \"out_sample_fmt\",     enc->sample_fmt,     0);\n\n            av_opt_set_int(ost->avr, \"out_sample_rate\",    enc->sample_rate,    0);\n\n            if (audio_sync_method > 1)\n\n                av_opt_set_int(ost->avr, \"force_resampling\", 1, 0);\n\n\n\n            /* if both the input and output formats are s16 or u8, use s16 as\n\n               the internal sample format */\n\n            if (av_get_bytes_per_sample(dec->sample_fmt) <= 2 &&\n\n                av_get_bytes_per_sample(enc->sample_fmt) <= 2) {\n\n                av_opt_set_int(ost->avr, \"internal_sample_fmt\", AV_SAMPLE_FMT_S16P, 0);\n\n            }\n\n\n\n            ret = avresample_open(ost->avr);\n\n            if (ret < 0) {\n\n                av_log(NULL, AV_LOG_FATAL, \"Error opening libavresample\\n\");\n\n                exit_program(1);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (audio_sync_method > 0) {\n\n        double delta = get_sync_ipts(ost, ist->last_dts) * enc->sample_rate - ost->sync_opts -\n\n                       av_fifo_size(ost->fifo) / (enc->channels * osize);\n\n        int idelta = delta * dec->sample_rate / enc->sample_rate;\n\n        int byte_delta = idelta * isize * dec->channels;\n\n\n\n        // FIXME resample delay\n\n        if (fabs(delta) > 50) {\n\n            if (ist->is_start || fabs(delta) > audio_drift_threshold*enc->sample_rate) {\n\n                if (byte_delta < 0) {\n\n                    byte_delta = FFMAX(byte_delta, -size);\n\n                    size += byte_delta;\n\n                    buf  -= byte_delta;\n\n                    av_log(NULL, AV_LOG_VERBOSE, \"discarding %d audio samples\\n\",\n\n                           -byte_delta / (isize * dec->channels));\n\n                    if (!size)\n\n                        return;\n\n                    ist->is_start = 0;\n\n                } else {\n\n                    av_fast_malloc(&async_buf, &allocated_async_buf_size,\n\n                                   byte_delta + size);\n\n                    if (!async_buf) {\n\n                        av_log(NULL, AV_LOG_FATAL, \"Out of memory in do_audio_out\\n\");\n\n                        exit_program(1);\n\n                    }\n\n\n\n                    if (alloc_audio_output_buf(dec, enc, decoded_frame->nb_samples + idelta, &out_linesize) < 0) {\n\n                        av_log(NULL, AV_LOG_FATAL, \"Error allocating audio buffer\\n\");\n\n                        exit_program(1);\n\n                    }\n\n                    ist->is_start = 0;\n\n\n\n                    generate_silence(async_buf, dec->sample_fmt, byte_delta);\n\n                    memcpy(async_buf + byte_delta, buf, size);\n\n                    buf = async_buf;\n\n                    size += byte_delta;\n\n                    buf_linesize = allocated_async_buf_size;\n\n                    av_log(NULL, AV_LOG_VERBOSE, \"adding %d audio samples of silence\\n\", idelta);\n\n                }\n\n            } else if (audio_sync_method > 1) {\n\n                int comp = av_clip(delta, -audio_sync_method, audio_sync_method);\n\n                av_log(NULL, AV_LOG_VERBOSE, \"compensating audio timestamp drift:%f compensation:%d in:%d\\n\",\n\n                       delta, comp, enc->sample_rate);\n\n//                fprintf(stderr, \"drift:%f len:%d opts:%\"PRId64\" ipts:%\"PRId64\" fifo:%d\\n\", delta, -1, ost->sync_opts, (int64_t)(get_sync_ipts(ost) * enc->sample_rate), av_fifo_size(ost->fifo)/(ost->st->codec->channels * 2));\n\n                avresample_set_compensation(ost->avr, comp, enc->sample_rate);\n\n            }\n\n        }\n\n    } else if (audio_sync_method == 0)\n\n        ost->sync_opts = lrintf(get_sync_ipts(ost, ist->last_dts) * enc->sample_rate) -\n\n                                av_fifo_size(ost->fifo) / (enc->channels * osize); // FIXME wrong\n\n\n\n    if (ost->audio_resample) {\n\n        buftmp = audio_buf;\n\n        size_out = avresample_convert(ost->avr, (void **)&buftmp,\n\n                                      allocated_audio_buf_size, out_linesize,\n\n                                      (void **)&buf, buf_linesize,\n\n                                      size / (dec->channels * isize));\n\n        size_out = size_out * enc->channels * osize;\n\n    } else {\n\n        buftmp = buf;\n\n        size_out = size;\n\n    }\n\n\n\n    /* now encode as many frames as possible */\n\n    if (!(enc->codec->capabilities & CODEC_CAP_VARIABLE_FRAME_SIZE)) {\n\n        /* output resampled raw samples */\n\n        if (av_fifo_realloc2(ost->fifo, av_fifo_size(ost->fifo) + size_out) < 0) {\n\n            av_log(NULL, AV_LOG_FATAL, \"av_fifo_realloc2() failed\\n\");\n\n            exit_program(1);\n\n        }\n\n        av_fifo_generic_write(ost->fifo, buftmp, size_out, NULL);\n\n\n\n        frame_bytes = enc->frame_size * osize * enc->channels;\n\n\n\n        while (av_fifo_size(ost->fifo) >= frame_bytes) {\n\n            av_fifo_generic_read(ost->fifo, audio_buf, frame_bytes, NULL);\n\n            encode_audio_frame(s, ost, audio_buf, frame_bytes);\n\n        }\n\n    } else {\n\n        encode_audio_frame(s, ost, buftmp, size_out);\n\n    }\n\n}\n", "idx": 14372, "_split": "test", "_hash": "0338bec9907324cd0d7bd352206c5d74"}
{"project": "FFmpeg", "commit_id": "1a3ed056c523b4670e192301be15dbc521ec8353", "target": 0, "func": "static int hls_decode_entry(AVCodecContext *avctxt, void *isFilterThread)\n\n{\n\n    HEVCContext *s  = avctxt->priv_data;\n\n    int ctb_size    = 1 << s->sps->log2_ctb_size;\n\n    int more_data   = 1;\n\n    int x_ctb       = 0;\n\n    int y_ctb       = 0;\n\n    int ctb_addr_ts = s->pps->ctb_addr_rs_to_ts[s->sh.slice_ctb_addr_rs];\n\n\n\n    if (!ctb_addr_ts && s->sh.dependent_slice_segment_flag) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Impossible initial tile.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->sh.dependent_slice_segment_flag) {\n\n        int prev_rs = s->pps->ctb_addr_ts_to_rs[ctb_addr_ts - 1];\n\n        if (s->tab_slice_address[prev_rs] == -1) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Previous slice segment missing\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    while (more_data && ctb_addr_ts < s->sps->ctb_size) {\n\n        int ctb_addr_rs = s->pps->ctb_addr_ts_to_rs[ctb_addr_ts];\n\n\n\n        x_ctb = (ctb_addr_rs % ((s->sps->width + ctb_size - 1) >> s->sps->log2_ctb_size)) << s->sps->log2_ctb_size;\n\n        y_ctb = (ctb_addr_rs / ((s->sps->width + ctb_size - 1) >> s->sps->log2_ctb_size)) << s->sps->log2_ctb_size;\n\n        hls_decode_neighbour(s, x_ctb, y_ctb, ctb_addr_ts);\n\n\n\n        ff_hevc_cabac_init(s, ctb_addr_ts);\n\n\n\n        hls_sao_param(s, x_ctb >> s->sps->log2_ctb_size, y_ctb >> s->sps->log2_ctb_size);\n\n\n\n        s->deblock[ctb_addr_rs].beta_offset = s->sh.beta_offset;\n\n        s->deblock[ctb_addr_rs].tc_offset   = s->sh.tc_offset;\n\n        s->filter_slice_edges[ctb_addr_rs]  = s->sh.slice_loop_filter_across_slices_enabled_flag;\n\n\n\n        more_data = hls_coding_quadtree(s, x_ctb, y_ctb, s->sps->log2_ctb_size, 0);\n\n        if (more_data < 0) {\n\n            s->tab_slice_address[ctb_addr_rs] = -1;\n\n            return more_data;\n\n        }\n\n\n\n\n\n        ctb_addr_ts++;\n\n        ff_hevc_save_states(s, ctb_addr_ts);\n\n        ff_hevc_hls_filters(s, x_ctb, y_ctb, ctb_size);\n\n    }\n\n\n\n    if (x_ctb + ctb_size >= s->sps->width &&\n\n        y_ctb + ctb_size >= s->sps->height)\n\n        ff_hevc_hls_filter(s, x_ctb, y_ctb);\n\n\n\n    return ctb_addr_ts;\n\n}\n", "idx": 14442, "_split": "test", "_hash": "057e30c34c63791d3d988d33acb1ad75"}
{"project": "FFmpeg", "commit_id": "8155233413540c63e53a620ff5734fb4b0635611", "target": 1, "func": "static int decode_header(MPADecodeContext *s, UINT32 header)\n\n{\n\n    int sample_rate, frame_size, mpeg25, padding;\n\n    int sample_rate_index, bitrate_index;\n\n    if (header & (1<<20)) {\n\n        s->lsf = (header & (1<<19)) ? 0 : 1;\n\n        mpeg25 = 0;\n\n    } else {\n\n        s->lsf = 1;\n\n        mpeg25 = 1;\n\n    }\n\n    \n\n    s->layer = 4 - ((header >> 17) & 3);\n\n    /* extract frequency */\n\n    sample_rate_index = (header >> 10) & 3;\n\n    sample_rate = mpa_freq_tab[sample_rate_index] >> (s->lsf + mpeg25);\n\n    if (sample_rate == 0)\n\n        return 1;\n\n    sample_rate_index += 3 * (s->lsf + mpeg25);\n\n    s->sample_rate_index = sample_rate_index;\n\n    s->error_protection = ((header >> 16) & 1) ^ 1;\n\n\n\n    bitrate_index = (header >> 12) & 0xf;\n\n    padding = (header >> 9) & 1;\n\n    //extension = (header >> 8) & 1;\n\n    s->mode = (header >> 6) & 3;\n\n    s->mode_ext = (header >> 4) & 3;\n\n    //copyright = (header >> 3) & 1;\n\n    //original = (header >> 2) & 1;\n\n    //emphasis = header & 3;\n\n\n\n    if (s->mode == MPA_MONO)\n\n        s->nb_channels = 1;\n\n    else\n\n        s->nb_channels = 2;\n\n    \n\n    if (bitrate_index != 0) {\n\n        frame_size = mpa_bitrate_tab[s->lsf][s->layer - 1][bitrate_index];\n\n        s->bit_rate = frame_size * 1000;\n\n        switch(s->layer) {\n\n        case 1:\n\n            frame_size = (frame_size * 12000) / sample_rate;\n\n            frame_size = (frame_size + padding) * 4;\n\n            break;\n\n        case 2:\n\n            frame_size = (frame_size * 144000) / sample_rate;\n\n            frame_size += padding;\n\n            break;\n\n        default:\n\n        case 3:\n\n            frame_size = (frame_size * 144000) / (sample_rate << s->lsf);\n\n            frame_size += padding;\n\n            break;\n\n        }\n\n        s->frame_size = frame_size;\n\n    } else {\n\n        /* if no frame size computed, signal it */\n\n        if (!s->free_format_frame_size)\n\n            return 1;\n\n        /* free format: compute bitrate and real frame size from the\n\n           frame size we extracted by reading the bitstream */\n\n        s->frame_size = s->free_format_frame_size;\n\n        switch(s->layer) {\n\n        case 1:\n\n            s->frame_size += padding  * 4;\n\n            s->bit_rate = (s->frame_size * sample_rate) / 48000;\n\n            break;\n\n        case 2:\n\n            s->frame_size += padding;\n\n            s->bit_rate = (s->frame_size * sample_rate) / 144000;\n\n            break;\n\n        default:\n\n        case 3:\n\n            s->frame_size += padding;\n\n            s->bit_rate = (s->frame_size * (sample_rate << s->lsf)) / 144000;\n\n            break;\n\n        }\n\n    }\n\n    s->sample_rate = sample_rate;\n\n    \n\n#if defined(DEBUG)\n\n    printf(\"layer%d, %d Hz, %d kbits/s, \",\n\n           s->layer, s->sample_rate, s->bit_rate);\n\n    if (s->nb_channels == 2) {\n\n        if (s->layer == 3) {\n\n            if (s->mode_ext & MODE_EXT_MS_STEREO)\n\n                printf(\"ms-\");\n\n            if (s->mode_ext & MODE_EXT_I_STEREO)\n\n                printf(\"i-\");\n\n        }\n\n        printf(\"stereo\");\n\n    } else {\n\n        printf(\"mono\");\n\n    }\n\n    printf(\"\\n\");\n\n#endif\n\n    return 0;\n\n}\n", "idx": 14459, "_split": "test", "_hash": "8c5d1719da3643be0bed09d49294130c"}
{"project": "FFmpeg", "commit_id": "2d66fc543b01995d6146fc132a778d3e722ca665", "target": 1, "func": "static av_cold int init(AVFilterContext *ctx, const char *args)\n\n{\n\n    GradFunContext *gf = ctx->priv;\n\n    float thresh = 1.2;\n\n    int radius = 16;\n\n\n\n    if (args)\n\n        sscanf(args, \"%f:%d\", &thresh, &radius);\n\n\n\n    thresh = av_clipf(thresh, 0.51, 255);\n\n    gf->thresh = (1 << 15) / thresh;\n\n    gf->radius = av_clip((radius + 1) & ~1, 4, 32);\n\n\n\n    gf->blur_line = ff_gradfun_blur_line_c;\n\n    gf->filter_line = ff_gradfun_filter_line_c;\n\n\n\n    if (ARCH_X86)\n\n        ff_gradfun_init_x86(gf);\n\n\n\n    av_log(ctx, AV_LOG_VERBOSE, \"threshold:%.2f radius:%d\\n\", thresh, gf->radius);\n\n\n\n    return 0;\n\n}\n", "idx": 14469, "_split": "test", "_hash": "bd16e22914bce6e97fa65516aec47140"}
{"project": "FFmpeg", "commit_id": "fc8fa007fb6099643a1f742a162e5e5eda760fd6", "target": 0, "func": "static int64_t rtmp_read_seek(URLContext *s, int stream_index,\n\n                              int64_t timestamp, int flags)\n\n{\n\n    RTMP *r = s->priv_data;\n\n\n\n    if (flags & AVSEEK_FLAG_BYTE)\n\n        return AVERROR(ENOSYS);\n\n\n\n    /* seeks are in milliseconds */\n\n    timestamp = av_rescale(timestamp, AV_TIME_BASE, 1000);\n\n    if (!RTMP_SendSeek(r, timestamp))\n\n        return -1;\n\n    return timestamp;\n\n}\n", "idx": 14499, "_split": "test", "_hash": "ee39fd5f6e5115905837791c44d566f3"}
{"project": "FFmpeg", "commit_id": "6df1cfa7e4d488051d7b5033c0c69df970db9f82", "target": 0, "func": "static av_cold int mace_decode_init(AVCodecContext * avctx)\n\n{\n\n    MACEContext *ctx = avctx->priv_data;\n\n\n\n    if (avctx->channels > 2)\n\n        return -1;\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S16;\n\n\n\n    avcodec_get_frame_defaults(&ctx->frame);\n\n    avctx->coded_frame = &ctx->frame;\n\n\n\n    return 0;\n\n}\n", "idx": 14508, "_split": "test", "_hash": "d3d72f7e9610160565500fe538a30e98"}
{"project": "FFmpeg", "commit_id": "bcaf64b605442e1622d16da89d4ec0e7730b8a8c", "target": 0, "func": "static int g722_encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                             const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    G722Context *c = avctx->priv_data;\n\n    const int16_t *samples = (const int16_t *)frame->data[0];\n\n    int nb_samples, out_size, ret;\n\n\n\n    out_size = (frame->nb_samples + 1) / 2;\n\n    if ((ret = ff_alloc_packet2(avctx, avpkt, out_size)))\n\n        return ret;\n\n\n\n    nb_samples = frame->nb_samples - (frame->nb_samples & 1);\n\n\n\n    if (avctx->trellis)\n\n        g722_encode_trellis(c, avctx->trellis, avpkt->data, nb_samples, samples);\n\n    else\n\n        g722_encode_no_trellis(c, avpkt->data, nb_samples, samples);\n\n\n\n    /* handle last frame with odd frame_size */\n\n    if (nb_samples < frame->nb_samples) {\n\n        int16_t last_samples[2] = { samples[nb_samples], samples[nb_samples] };\n\n        encode_byte(c, &avpkt->data[nb_samples >> 1], last_samples);\n\n    }\n\n\n\n    if (frame->pts != AV_NOPTS_VALUE)\n\n        avpkt->pts = frame->pts - ff_samples_to_time_base(avctx, avctx->delay);\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 14566, "_split": "test", "_hash": "8031b163d28bff5a3de103522efbb3f9"}
{"project": "FFmpeg", "commit_id": "03d83ba34b2070878909eae18dfac0f519503777", "target": 0, "func": "static int gif_image_write_image(AVCodecContext *avctx,\n\n                                 uint8_t **bytestream, uint8_t *end,\n\n                                 const uint32_t *palette,\n\n                                 const uint8_t *buf, const int linesize,\n\n                                 AVPacket *pkt)\n\n{\n\n    GIFContext *s = avctx->priv_data;\n\n    int len = 0, height = avctx->height, width = avctx->width, x, y;\n\n    int x_start = 0, y_start = 0, trans = s->transparent_index;\n\n    int honor_transparency = (s->flags & GF_TRANSDIFF) && s->last_frame;\n\n    const uint8_t *ptr;\n\n\n\n    /* Crop image */\n\n    if ((s->flags & GF_OFFSETTING) && s->last_frame && !palette) {\n\n        const uint8_t *ref = s->last_frame->data[0];\n\n        const int ref_linesize = s->last_frame->linesize[0];\n\n        int x_end = avctx->width  - 1,\n\n            y_end = avctx->height - 1;\n\n\n\n        /* skip common lines */\n\n        while (y_start < y_end) {\n\n            if (memcmp(ref + y_start*ref_linesize, buf + y_start*linesize, width))\n\n                break;\n\n            y_start++;\n\n        }\n\n        while (y_end > y_start) {\n\n            if (memcmp(ref + y_end*ref_linesize, buf + y_end*linesize, width))\n\n                break;\n\n            y_end--;\n\n        }\n\n        height = y_end + 1 - y_start;\n\n\n\n        /* skip common columns */\n\n        while (x_start < x_end) {\n\n            int same_column = 1;\n\n            for (y = y_start; y <= y_end; y++) {\n\n                if (ref[y*ref_linesize + x_start] != buf[y*linesize + x_start]) {\n\n                    same_column = 0;\n\n                    break;\n\n                }\n\n            }\n\n            if (!same_column)\n\n                break;\n\n            x_start++;\n\n        }\n\n        while (x_end > x_start) {\n\n            int same_column = 1;\n\n            for (y = y_start; y <= y_end; y++) {\n\n                if (ref[y*ref_linesize + x_end] != buf[y*linesize + x_end]) {\n\n                    same_column = 0;\n\n                    break;\n\n                }\n\n            }\n\n            if (!same_column)\n\n                break;\n\n            x_end--;\n\n        }\n\n        width = x_end + 1 - x_start;\n\n\n\n        av_log(avctx, AV_LOG_DEBUG,\"%dx%d image at pos (%d;%d) [area:%dx%d]\\n\",\n\n               width, height, x_start, y_start, avctx->width, avctx->height);\n\n    }\n\n\n\n    /* image block */\n\n    bytestream_put_byte(bytestream, GIF_IMAGE_SEPARATOR);\n\n    bytestream_put_le16(bytestream, x_start);\n\n    bytestream_put_le16(bytestream, y_start);\n\n    bytestream_put_le16(bytestream, width);\n\n    bytestream_put_le16(bytestream, height);\n\n\n\n    if (!palette) {\n\n        bytestream_put_byte(bytestream, 0x00); /* flags */\n\n    } else {\n\n        unsigned i;\n\n        bytestream_put_byte(bytestream, 1<<7 | 0x7); /* flags */\n\n        for (i = 0; i < AVPALETTE_COUNT; i++) {\n\n            const uint32_t v = palette[i];\n\n            bytestream_put_be24(bytestream, v);\n\n        }\n\n    }\n\n\n\n    if (honor_transparency && trans < 0) {\n\n        trans = pick_palette_entry(buf + y_start*linesize + x_start,\n\n                                   linesize, width, height);\n\n        if (trans < 0) { // TODO, patch welcome\n\n            av_log(avctx, AV_LOG_DEBUG, \"No available color, can not use transparency\\n\");\n\n        } else {\n\n            uint8_t *pal_exdata = s->pal_exdata;\n\n            if (!pal_exdata)\n\n                pal_exdata = av_packet_new_side_data(pkt, AV_PKT_DATA_PALETTE, AVPALETTE_SIZE);\n\n            if (!pal_exdata)\n\n                return AVERROR(ENOMEM);\n\n            memcpy(pal_exdata, s->palette, AVPALETTE_SIZE);\n\n            pal_exdata[trans*4 + 3*!HAVE_BIGENDIAN] = 0x00;\n\n        }\n\n    }\n\n    if (trans < 0)\n\n        honor_transparency = 0;\n\n\n\n    bytestream_put_byte(bytestream, 0x08);\n\n\n\n    ff_lzw_encode_init(s->lzw, s->buf, 2 * width * height,\n\n                       12, FF_LZW_GIF, put_bits);\n\n\n\n    ptr = buf + y_start*linesize + x_start;\n\n    if (honor_transparency) {\n\n        const int ref_linesize = s->last_frame->linesize[0];\n\n        const uint8_t *ref = s->last_frame->data[0] + y_start*ref_linesize + x_start;\n\n\n\n        for (y = 0; y < height; y++) {\n\n            memcpy(s->tmpl, ptr, width);\n\n            for (x = 0; x < width; x++)\n\n                if (ref[x] == ptr[x])\n\n                    s->tmpl[x] = trans;\n\n            len += ff_lzw_encode(s->lzw, s->tmpl, width);\n\n            ptr += linesize;\n\n            ref += ref_linesize;\n\n        }\n\n    } else {\n\n        for (y = 0; y < height; y++) {\n\n            len += ff_lzw_encode(s->lzw, ptr, width);\n\n            ptr += linesize;\n\n        }\n\n    }\n\n    len += ff_lzw_encode_flush(s->lzw, flush_put_bits);\n\n\n\n    ptr = s->buf;\n\n    while (len > 0) {\n\n        int size = FFMIN(255, len);\n\n        bytestream_put_byte(bytestream, size);\n\n        if (end - *bytestream < size)\n\n            return -1;\n\n        bytestream_put_buffer(bytestream, ptr, size);\n\n        ptr += size;\n\n        len -= size;\n\n    }\n\n    bytestream_put_byte(bytestream, 0x00); /* end of image block */\n\n    return 0;\n\n}\n", "idx": 14588, "_split": "test", "_hash": "538b86458d8d536147944ee87505e690"}
{"project": "FFmpeg", "commit_id": "290e7eb77bee5a54182fb3d5fb122c1e117190da", "target": 1, "func": "void ff_clear_fixed_vector(float *out, const AMRFixed *in, int size)\n\n{\n\n    int i;\n\n\n\n    for (i=0; i < in->n; i++) {\n\n        int x  = in->x[i], repeats = !((in->no_repeat_mask >> i) & 1);\n\n\n\n\n        do {\n\n            out[x] = 0.0;\n\n            x += in->pitch_lag;\n\n        } while (x < size && repeats);\n\n    }\n\n}", "idx": 14599, "_split": "test", "_hash": "6fa7a87eb4441037c10fa20cd09a099c"}
{"project": "FFmpeg", "commit_id": "c58d45e00489e07fd4606b64ad4095660494185b", "target": 1, "func": "static int film_read_header(AVFormatContext *s,\n\n                            AVFormatParameters *ap)\n\n{\n\n    FilmDemuxContext *film = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    unsigned char scratch[256];\n\n    int i;\n\n    unsigned int data_offset;\n\n    unsigned int audio_frame_counter;\n\n\n\n    film->sample_table = NULL;\n\n    film->stereo_buffer = NULL;\n\n    film->stereo_buffer_size = 0;\n\n\n\n    /* load the main FILM header */\n\n    if (avio_read(pb, scratch, 16) != 16)\n\n        return AVERROR(EIO);\n\n    data_offset = AV_RB32(&scratch[4]);\n\n    film->version = AV_RB32(&scratch[8]);\n\n\n\n    /* load the FDSC chunk */\n\n    if (film->version == 0) {\n\n        /* special case for Lemmings .film files; 20-byte header */\n\n        if (avio_read(pb, scratch, 20) != 20)\n\n            return AVERROR(EIO);\n\n        /* make some assumptions about the audio parameters */\n\n        film->audio_type = CODEC_ID_PCM_S8;\n\n        film->audio_samplerate = 22050;\n\n        film->audio_channels = 1;\n\n        film->audio_bits = 8;\n\n    } else {\n\n        /* normal Saturn .cpk files; 32-byte header */\n\n        if (avio_read(pb, scratch, 32) != 32)\n\n            return AVERROR(EIO);\n\n        film->audio_samplerate = AV_RB16(&scratch[24]);\n\n        film->audio_channels = scratch[21];\n\n        film->audio_bits = scratch[22];\n\n        if (scratch[23] == 2)\n\n            film->audio_type = CODEC_ID_ADPCM_ADX;\n\n        else if (film->audio_bits == 8)\n\n            film->audio_type = CODEC_ID_PCM_S8;\n\n        else if (film->audio_bits == 16)\n\n            film->audio_type = CODEC_ID_PCM_S16BE;\n\n        else\n\n            film->audio_type = CODEC_ID_NONE;\n\n    }\n\n\n\n    if (AV_RB32(&scratch[0]) != FDSC_TAG)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (AV_RB32(&scratch[8]) == CVID_TAG) {\n\n        film->video_type = CODEC_ID_CINEPAK;\n\n    } else\n\n        film->video_type = CODEC_ID_NONE;\n\n\n\n    /* initialize the decoder streams */\n\n    if (film->video_type) {\n\n        st = av_new_stream(s, 0);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        film->video_stream_index = st->index;\n\n        st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        st->codec->codec_id = film->video_type;\n\n        st->codec->codec_tag = 0;  /* no fourcc */\n\n        st->codec->width = AV_RB32(&scratch[16]);\n\n        st->codec->height = AV_RB32(&scratch[12]);\n\n    }\n\n\n\n    if (film->audio_type) {\n\n        st = av_new_stream(s, 0);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        film->audio_stream_index = st->index;\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_id = film->audio_type;\n\n        st->codec->codec_tag = 1;\n\n        st->codec->channels = film->audio_channels;\n\n        st->codec->sample_rate = film->audio_samplerate;\n\n\n\n        if (film->audio_type == CODEC_ID_ADPCM_ADX) {\n\n            st->codec->bits_per_coded_sample = 18 * 8 / 32;\n\n            st->codec->block_align = st->codec->channels * 18;\n\n        } else {\n\n            st->codec->bits_per_coded_sample = film->audio_bits;\n\n            st->codec->block_align = st->codec->channels *\n\n                st->codec->bits_per_coded_sample / 8;\n\n        }\n\n\n\n        st->codec->bit_rate = st->codec->channels * st->codec->sample_rate *\n\n            st->codec->bits_per_coded_sample;\n\n    }\n\n\n\n    /* load the sample table */\n\n    if (avio_read(pb, scratch, 16) != 16)\n\n        return AVERROR(EIO);\n\n    if (AV_RB32(&scratch[0]) != STAB_TAG)\n\n        return AVERROR_INVALIDDATA;\n\n    film->base_clock = AV_RB32(&scratch[8]);\n\n    film->sample_count = AV_RB32(&scratch[12]);\n\n    if(film->sample_count >= UINT_MAX / sizeof(film_sample))\n\n        return -1;\n\n    film->sample_table = av_malloc(film->sample_count * sizeof(film_sample));\n\n    if (!film->sample_table)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for(i=0; i<s->nb_streams; i++)\n\n        av_set_pts_info(s->streams[i], 33, 1, film->base_clock);\n\n\n\n    audio_frame_counter = 0;\n\n    for (i = 0; i < film->sample_count; i++) {\n\n        /* load the next sample record and transfer it to an internal struct */\n\n        if (avio_read(pb, scratch, 16) != 16) {\n\n            av_free(film->sample_table);\n\n            return AVERROR(EIO);\n\n        }\n\n        film->sample_table[i].sample_offset =\n\n            data_offset + AV_RB32(&scratch[0]);\n\n        film->sample_table[i].sample_size = AV_RB32(&scratch[4]);\n\n        if (AV_RB32(&scratch[8]) == 0xFFFFFFFF) {\n\n            film->sample_table[i].stream = film->audio_stream_index;\n\n            film->sample_table[i].pts = audio_frame_counter;\n\n            film->sample_table[i].pts *= film->base_clock;\n\n            film->sample_table[i].pts /= film->audio_samplerate;\n\n\n\n            if (film->audio_type == CODEC_ID_ADPCM_ADX)\n\n                audio_frame_counter += (film->sample_table[i].sample_size * 32 /\n\n                    (18 * film->audio_channels));\n\n            else\n\n                audio_frame_counter += (film->sample_table[i].sample_size /\n\n                    (film->audio_channels * film->audio_bits / 8));\n\n        } else {\n\n            film->sample_table[i].stream = film->video_stream_index;\n\n            film->sample_table[i].pts = AV_RB32(&scratch[8]) & 0x7FFFFFFF;\n\n            film->sample_table[i].keyframe = (scratch[8] & 0x80) ? 0 : 1;\n\n        }\n\n    }\n\n\n\n    film->current_sample = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 14612, "_split": "test", "_hash": "50f1b2953720287378389b2e2ef2da26"}
{"project": "FFmpeg", "commit_id": "d9051f8f3e60768f68867c3e3116e980d855215a", "target": 1, "func": "static int vlc_decode_block(MimicContext *ctx, int num_coeffs, int qscale)\n\n{\n\n    int16_t *block = ctx->dct_block;\n\n    unsigned int pos;\n\n\n\n    ctx->bdsp.clear_block(block);\n\n\n\n    block[0] = get_bits(&ctx->gb, 8) << 3;\n\n\n\n    for (pos = 1; pos < num_coeffs; pos++) {\n\n        uint32_t vlc, num_bits;\n\n        int value;\n\n        int coeff;\n\n\n\n        vlc = get_vlc2(&ctx->gb, ctx->vlc.table, ctx->vlc.bits, 3);\n\n        if (!vlc) /* end-of-block code */\n\n            return 0;\n\n        if (vlc == -1)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        /* pos_add and num_bits are coded in the vlc code */\n\n        pos     += vlc & 15; // pos_add\n\n        num_bits = vlc >> 4; // num_bits\n\n\n\n        if (pos >= 64)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        value = get_bits(&ctx->gb, num_bits);\n\n\n\n        /* FFmpeg's IDCT behaves somewhat different from the original code, so\n\n         * a factor of 4 was added to the input */\n\n\n\n        coeff = vlcdec_lookup[num_bits][value];\n\n        if (pos < 3)\n\n            coeff *= 16;\n\n        else /* TODO Use >> 10 instead of / 1001 */\n\n            coeff = (coeff * qscale) / 1001;\n\n\n\n        block[ctx->scantable.permutated[pos]] = coeff;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 14639, "_split": "test", "_hash": "9a4f92158e23dcd6dcdc0fd49dc3e94e"}
{"project": "FFmpeg", "commit_id": "87e302bfd8ffbc6cdb20920029013956b10ace63", "target": 0, "func": "static int svq3_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MpegEncContext *const s = avctx->priv_data;\n\n    H264Context *const h = avctx->priv_data;\n\n    int m, mb_type;\n\n\n\n    /* special case for last picture */\n\n    if (buf_size == 0) {\n\n        if (s->next_picture_ptr && !s->low_delay) {\n\n            *(AVFrame *) data = *(AVFrame *) &s->next_picture;\n\n            s->next_picture_ptr = NULL;\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    init_get_bits (&s->gb, buf, 8*buf_size);\n\n\n\n    s->mb_x = s->mb_y = h->mb_xy = 0;\n\n\n\n    if (svq3_decode_slice_header(h))\n\n        return -1;\n\n\n\n    s->pict_type = h->slice_type;\n\n    s->picture_number = h->slice_num;\n\n\n\n    if (avctx->debug&FF_DEBUG_PICT_INFO){\n\n        av_log(h->s.avctx, AV_LOG_DEBUG, \"%c hpel:%d, tpel:%d aqp:%d qp:%d, slice_num:%02X\\n\",\n\n               av_get_pict_type_char(s->pict_type), h->halfpel_flag, h->thirdpel_flag,\n\n               s->adaptive_quant, s->qscale, h->slice_num);\n\n    }\n\n\n\n    /* for hurry_up == 5 */\n\n    s->current_picture.pict_type = s->pict_type;\n\n    s->current_picture.key_frame = (s->pict_type == FF_I_TYPE);\n\n\n\n    /* Skip B-frames if we do not have reference frames. */\n\n    if (s->last_picture_ptr == NULL && s->pict_type == FF_B_TYPE)\n\n        return 0;\n\n    /* Skip B-frames if we are in a hurry. */\n\n    if (avctx->hurry_up && s->pict_type == FF_B_TYPE)\n\n        return 0;\n\n    /* Skip everything if we are in a hurry >= 5. */\n\n    if (avctx->hurry_up >= 5)\n\n        return 0;\n\n    if (  (avctx->skip_frame >= AVDISCARD_NONREF && s->pict_type == FF_B_TYPE)\n\n        ||(avctx->skip_frame >= AVDISCARD_NONKEY && s->pict_type != FF_I_TYPE)\n\n        || avctx->skip_frame >= AVDISCARD_ALL)\n\n        return 0;\n\n\n\n    if (s->next_p_frame_damaged) {\n\n        if (s->pict_type == FF_B_TYPE)\n\n            return 0;\n\n        else\n\n            s->next_p_frame_damaged = 0;\n\n    }\n\n\n\n    if (frame_start(h) < 0)\n\n        return -1;\n\n\n\n    if (s->pict_type == FF_B_TYPE) {\n\n        h->frame_num_offset = (h->slice_num - h->prev_frame_num);\n\n\n\n        if (h->frame_num_offset < 0) {\n\n            h->frame_num_offset += 256;\n\n        }\n\n        if (h->frame_num_offset == 0 || h->frame_num_offset >= h->prev_frame_num_offset) {\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"error in B-frame picture id\\n\");\n\n            return -1;\n\n        }\n\n    } else {\n\n        h->prev_frame_num = h->frame_num;\n\n        h->frame_num = h->slice_num;\n\n        h->prev_frame_num_offset = (h->frame_num - h->prev_frame_num);\n\n\n\n        if (h->prev_frame_num_offset < 0) {\n\n            h->prev_frame_num_offset += 256;\n\n        }\n\n    }\n\n\n\n    for (m = 0; m < 2; m++){\n\n        int i;\n\n        for (i = 0; i < 4; i++){\n\n            int j;\n\n            for (j = -1; j < 4; j++)\n\n                h->ref_cache[m][scan8[0] + 8*i + j]= 1;\n\n            if (i < 3)\n\n                h->ref_cache[m][scan8[0] + 8*i + j]= PART_NOT_AVAILABLE;\n\n        }\n\n    }\n\n\n\n    for (s->mb_y = 0; s->mb_y < s->mb_height; s->mb_y++) {\n\n        for (s->mb_x = 0; s->mb_x < s->mb_width; s->mb_x++) {\n\n            h->mb_xy = s->mb_x + s->mb_y*s->mb_stride;\n\n\n\n            if ( (get_bits_count(&s->gb) + 7) >= s->gb.size_in_bits &&\n\n                ((get_bits_count(&s->gb) & 7) == 0 || show_bits(&s->gb, (-get_bits_count(&s->gb) & 7)) == 0)) {\n\n\n\n                skip_bits(&s->gb, h->next_slice_index - get_bits_count(&s->gb));\n\n                s->gb.size_in_bits = 8*buf_size;\n\n\n\n                if (svq3_decode_slice_header(h))\n\n                    return -1;\n\n\n\n                /* TODO: support s->mb_skip_run */\n\n            }\n\n\n\n            mb_type = svq3_get_ue_golomb(&s->gb);\n\n\n\n            if (s->pict_type == FF_I_TYPE) {\n\n                mb_type += 8;\n\n            } else if (s->pict_type == FF_B_TYPE && mb_type >= 4) {\n\n                mb_type += 4;\n\n            }\n\n            if (mb_type > 33 || svq3_decode_mb(h, mb_type)) {\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"error while decoding MB %d %d\\n\", s->mb_x, s->mb_y);\n\n                return -1;\n\n            }\n\n\n\n            if (mb_type != 0) {\n\n                hl_decode_mb (h);\n\n            }\n\n\n\n            if (s->pict_type != FF_B_TYPE && !s->low_delay) {\n\n                s->current_picture.mb_type[s->mb_x + s->mb_y*s->mb_stride] =\n\n                    (s->pict_type == FF_P_TYPE && mb_type < 8) ? (mb_type - 1) : -1;\n\n            }\n\n        }\n\n\n\n        ff_draw_horiz_band(s, 16*s->mb_y, 16);\n\n    }\n\n\n\n    MPV_frame_end(s);\n\n\n\n    if (s->pict_type == FF_B_TYPE || s->low_delay) {\n\n        *(AVFrame *) data = *(AVFrame *) &s->current_picture;\n\n    } else {\n\n        *(AVFrame *) data = *(AVFrame *) &s->last_picture;\n\n    }\n\n\n\n    avctx->frame_number = s->picture_number - 1;\n\n\n\n    /* Do not output the last pic after seeking. */\n\n    if (s->last_picture_ptr || s->low_delay) {\n\n        *data_size = sizeof(AVFrame);\n\n    }\n\n\n\n    return buf_size;\n\n}\n", "idx": 14654, "_split": "test", "_hash": "c807ce247ea914300e92e3ce2db54633"}
{"project": "FFmpeg", "commit_id": "b12d92efd6c0d48665383a9baecc13e7ebbd8a22", "target": 1, "func": "static av_cold int rl2_decode_init(AVCodecContext *avctx)\n\n{\n\n    Rl2Context *s = avctx->priv_data;\n\n    int back_size;\n\n    int i;\n\n    s->avctx = avctx;\n\n    avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n    avcodec_get_frame_defaults(&s->frame);\n\n\n\n    /** parse extra data */\n\n    if(!avctx->extradata || avctx->extradata_size < EXTRADATA1_SIZE){\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid extradata size\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /** get frame_offset */\n\n    s->video_base = AV_RL16(&avctx->extradata[0]);\n\n    s->clr_count = AV_RL32(&avctx->extradata[2]);\n\n\n\n    if(s->video_base >= avctx->width * avctx->height){\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid video_base\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /** initialize palette */\n\n    for(i=0;i<AVPALETTE_COUNT;i++)\n\n        s->palette[i] = 0xFF << 24 | AV_RB24(&avctx->extradata[6 + i * 3]);\n\n\n\n    /** decode background frame if present */\n\n    back_size = avctx->extradata_size - EXTRADATA1_SIZE;\n\n\n\n    if(back_size > 0){\n\n        unsigned char* back_frame = av_mallocz(avctx->width*avctx->height);\n\n        if(!back_frame)\n\n            return -1;\n\n        rl2_rle_decode(s,avctx->extradata + EXTRADATA1_SIZE,back_size,\n\n                           back_frame,avctx->width,0);\n\n        s->back_frame = back_frame;\n\n    }\n\n    return 0;\n\n}\n", "idx": 14658, "_split": "test", "_hash": "1933415353632f971194ff3b9f406c34"}
{"project": "FFmpeg", "commit_id": "01a33b835f7a9e135eb8c7b7dd98c8b89f15dea1", "target": 1, "func": "static void picmemset(PicContext *s, AVFrame *frame, int value, int run,\n\n                      int *x, int *y, int *plane, int bits_per_plane)\n\n{\n\n    uint8_t *d;\n\n    int shift = *plane * bits_per_plane;\n\n    int mask  = ((1 << bits_per_plane) - 1) << shift;\n\n    value   <<= shift;\n\n\n\n    while (run > 0) {\n\n        int j;\n\n        for (j = 8-bits_per_plane; j >= 0; j -= bits_per_plane) {\n\n            d = frame->data[0] + *y * frame->linesize[0];\n\n            d[*x] |= (value >> j) & mask;\n\n            *x += 1;\n\n            if (*x == s->width) {\n\n                *y -= 1;\n\n                *x = 0;\n\n                if (*y < 0) {\n\n                   *y = s->height - 1;\n\n                   *plane += 1;\n\n                   if (*plane >= s->nb_planes)\n\n                       return;\n\n                   value <<= bits_per_plane;\n\n                   mask  <<= bits_per_plane;\n\n                }\n\n            }\n\n        }\n\n        run--;\n\n    }\n\n}\n", "idx": 14665, "_split": "test", "_hash": "975b07ce68aaba833deecf341911e4b7"}
{"project": "FFmpeg", "commit_id": "f61d44b74aaae1d306d8a0d38b7b3d4292c89ced", "target": 0, "func": "static inline void silk_stabilize_lsf(int16_t nlsf[16], int order, const uint16_t min_delta[17])\n\n{\n\n    int pass, i;\n\n    for (pass = 0; pass < 20; pass++) {\n\n        int k, min_diff = 0;\n\n        for (i = 0; i < order+1; i++) {\n\n            int low  = i != 0     ? nlsf[i-1] : 0;\n\n            int high = i != order ? nlsf[i]   : 32768;\n\n            int diff = (high - low) - (min_delta[i]);\n\n\n\n            if (diff < min_diff) {\n\n                min_diff = diff;\n\n                k = i;\n\n\n\n                if (pass == 20)\n\n                    break;\n\n            }\n\n        }\n\n        if (min_diff == 0) /* no issues; stabilized */\n\n            return;\n\n\n\n        /* wiggle one or two LSFs */\n\n        if (k == 0) {\n\n            /* repel away from lower bound */\n\n            nlsf[0] = min_delta[0];\n\n        } else if (k == order) {\n\n            /* repel away from higher bound */\n\n            nlsf[order-1] = 32768 - min_delta[order];\n\n        } else {\n\n            /* repel away from current position */\n\n            int min_center = 0, max_center = 32768, center_val;\n\n\n\n            /* lower extent */\n\n            for (i = 0; i < k; i++)\n\n                min_center += min_delta[i];\n\n            min_center += min_delta[k] >> 1;\n\n\n\n            /* upper extent */\n\n            for (i = order; i > k; i--)\n\n                max_center -= min_delta[k];\n\n            max_center -= min_delta[k] >> 1;\n\n\n\n            /* move apart */\n\n            center_val = nlsf[k - 1] + nlsf[k];\n\n            center_val = (center_val >> 1) + (center_val & 1); // rounded divide by 2\n\n            center_val = FFMIN(max_center, FFMAX(min_center, center_val));\n\n\n\n            nlsf[k - 1] = center_val - (min_delta[k] >> 1);\n\n            nlsf[k]     = nlsf[k - 1] + min_delta[k];\n\n        }\n\n    }\n\n\n\n    /* resort to the fall-back method, the standard method for LSF stabilization */\n\n\n\n    /* sort; as the LSFs should be nearly sorted, use insertion sort */\n\n    for (i = 1; i < order; i++) {\n\n        int j, value = nlsf[i];\n\n        for (j = i - 1; j >= 0 && nlsf[j] > value; j--)\n\n            nlsf[j + 1] = nlsf[j];\n\n        nlsf[j + 1] = value;\n\n    }\n\n\n\n    /* push forwards to increase distance */\n\n    if (nlsf[0] < min_delta[0])\n\n        nlsf[0] = min_delta[0];\n\n    for (i = 1; i < order; i++)\n\n        if (nlsf[i] < nlsf[i - 1] + min_delta[i])\n\n            nlsf[i] = nlsf[i - 1] + min_delta[i];\n\n\n\n    /* push backwards to increase distance */\n\n    if (nlsf[order-1] > 32768 - min_delta[order])\n\n        nlsf[order-1] = 32768 - min_delta[order];\n\n    for (i = order-2; i >= 0; i--)\n\n        if (nlsf[i] > nlsf[i + 1] - min_delta[i+1])\n\n            nlsf[i] = nlsf[i + 1] - min_delta[i+1];\n\n\n\n    return;\n\n}\n", "idx": 14673, "_split": "test", "_hash": "bc93c40ee6babbf53c18d7df929318fb"}
{"project": "FFmpeg", "commit_id": "e7843db3df0224cafcc1af9da103a3a7286ae2ba", "target": 1, "func": "void ff_get_unscaled_swscale(SwsContext *c)\n\n{\n\n    const enum PixelFormat srcFormat = c->srcFormat;\n\n    const enum PixelFormat dstFormat = c->dstFormat;\n\n    const int flags = c->flags;\n\n    const int dstH = c->dstH;\n\n    int needsDither;\n\n\n\n    needsDither = isAnyRGB(dstFormat) &&\n\n            c->dstFormatBpp < 24 &&\n\n           (c->dstFormatBpp < c->srcFormatBpp || (!isAnyRGB(srcFormat)));\n\n\n\n    /* yv12_to_nv12 */\n\n    if ((srcFormat == PIX_FMT_YUV420P || srcFormat == PIX_FMT_YUVA420P) &&\n\n        (dstFormat == PIX_FMT_NV12 || dstFormat == PIX_FMT_NV21)) {\n\n        c->swScale = planarToNv12Wrapper;\n\n    }\n\n    /* yuv2bgr */\n\n    if ((srcFormat == PIX_FMT_YUV420P || srcFormat == PIX_FMT_YUV422P ||\n\n         srcFormat == PIX_FMT_YUVA420P) && isAnyRGB(dstFormat) &&\n\n        !(flags & SWS_ACCURATE_RND) && !(dstH & 1)) {\n\n        c->swScale = ff_yuv2rgb_get_func_ptr(c);\n\n    }\n\n\n\n    if (srcFormat == PIX_FMT_YUV410P &&\n\n        (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P) &&\n\n        !(flags & SWS_BITEXACT)) {\n\n        c->swScale = yvu9ToYv12Wrapper;\n\n    }\n\n\n\n    /* bgr24toYV12 */\n\n    if (srcFormat == PIX_FMT_BGR24 &&\n\n        (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P) &&\n\n        !(flags & SWS_ACCURATE_RND))\n\n        c->swScale = bgr24ToYv12Wrapper;\n\n\n\n    /* RGB/BGR -> RGB/BGR (no dither needed forms) */\n\n    if (   isAnyRGB(srcFormat)\n\n        && isAnyRGB(dstFormat)\n\n        && srcFormat != PIX_FMT_BGR8      && dstFormat != PIX_FMT_BGR8\n\n        && srcFormat != PIX_FMT_RGB8      && dstFormat != PIX_FMT_RGB8\n\n        && srcFormat != PIX_FMT_BGR4      && dstFormat != PIX_FMT_BGR4\n\n        && srcFormat != PIX_FMT_RGB4      && dstFormat != PIX_FMT_RGB4\n\n        && srcFormat != PIX_FMT_BGR4_BYTE && dstFormat != PIX_FMT_BGR4_BYTE\n\n        && srcFormat != PIX_FMT_RGB4_BYTE && dstFormat != PIX_FMT_RGB4_BYTE\n\n        && srcFormat != PIX_FMT_MONOBLACK && dstFormat != PIX_FMT_MONOBLACK\n\n        && srcFormat != PIX_FMT_MONOWHITE && dstFormat != PIX_FMT_MONOWHITE\n\n        && srcFormat != PIX_FMT_RGB48LE   && dstFormat != PIX_FMT_RGB48LE\n\n        && srcFormat != PIX_FMT_RGB48BE   && dstFormat != PIX_FMT_RGB48BE\n\n        && srcFormat != PIX_FMT_BGR48LE   && dstFormat != PIX_FMT_BGR48LE\n\n        && srcFormat != PIX_FMT_BGR48BE   && dstFormat != PIX_FMT_BGR48BE\n\n        && (!needsDither || (c->flags&(SWS_FAST_BILINEAR|SWS_POINT))))\n\n        c->swScale= rgbToRgbWrapper;\n\n\n\n    /* bswap 16 bits per pixel/component packed formats */\n\n    if (IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_BGR444) ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_BGR48)  ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_BGR555) ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_BGR565) ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_GRAY16) ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_RGB444) ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_RGB48)  ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_RGB555) ||\n\n        IS_DIFFERENT_ENDIANESS(srcFormat, dstFormat, PIX_FMT_RGB565))\n\n        c->swScale = packed_16bpc_bswap;\n\n\n\n    if ((usePal(srcFormat) && (\n\n        dstFormat == PIX_FMT_RGB32   ||\n\n        dstFormat == PIX_FMT_RGB32_1 ||\n\n        dstFormat == PIX_FMT_RGB24   ||\n\n        dstFormat == PIX_FMT_BGR32   ||\n\n        dstFormat == PIX_FMT_BGR32_1 ||\n\n        dstFormat == PIX_FMT_BGR24)))\n\n        c->swScale = palToRgbWrapper;\n\n\n\n    if (srcFormat == PIX_FMT_YUV422P) {\n\n        if (dstFormat == PIX_FMT_YUYV422)\n\n            c->swScale = yuv422pToYuy2Wrapper;\n\n        else if (dstFormat == PIX_FMT_UYVY422)\n\n            c->swScale = yuv422pToUyvyWrapper;\n\n    }\n\n\n\n    /* LQ converters if -sws 0 or -sws 4*/\n\n    if (c->flags&(SWS_FAST_BILINEAR|SWS_POINT)) {\n\n        /* yv12_to_yuy2 */\n\n        if (srcFormat == PIX_FMT_YUV420P || srcFormat == PIX_FMT_YUVA420P) {\n\n            if (dstFormat == PIX_FMT_YUYV422)\n\n                c->swScale = planarToYuy2Wrapper;\n\n            else if (dstFormat == PIX_FMT_UYVY422)\n\n                c->swScale = planarToUyvyWrapper;\n\n        }\n\n    }\n\n    if (srcFormat == PIX_FMT_YUYV422 &&\n\n       (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P))\n\n        c->swScale = yuyvToYuv420Wrapper;\n\n    if (srcFormat == PIX_FMT_UYVY422 &&\n\n       (dstFormat == PIX_FMT_YUV420P || dstFormat == PIX_FMT_YUVA420P))\n\n        c->swScale = uyvyToYuv420Wrapper;\n\n    if (srcFormat == PIX_FMT_YUYV422 && dstFormat == PIX_FMT_YUV422P)\n\n        c->swScale = yuyvToYuv422Wrapper;\n\n    if (srcFormat == PIX_FMT_UYVY422 && dstFormat == PIX_FMT_YUV422P)\n\n        c->swScale = uyvyToYuv422Wrapper;\n\n\n\n    /* simple copy */\n\n    if ( srcFormat == dstFormat ||\n\n        (srcFormat == PIX_FMT_YUVA420P && dstFormat == PIX_FMT_YUV420P) ||\n\n        (srcFormat == PIX_FMT_YUV420P && dstFormat == PIX_FMT_YUVA420P) ||\n\n        (isPlanarYUV(srcFormat) && isGray(dstFormat)) ||\n\n        (isPlanarYUV(dstFormat) && isGray(srcFormat)) ||\n\n        (isGray(dstFormat) && isGray(srcFormat)) ||\n\n        (isPlanarYUV(srcFormat) && isPlanarYUV(dstFormat) &&\n\n         c->chrDstHSubSample == c->chrSrcHSubSample &&\n\n         c->chrDstVSubSample == c->chrSrcVSubSample &&\n\n         dstFormat != PIX_FMT_NV12 && dstFormat != PIX_FMT_NV21 &&\n\n         srcFormat != PIX_FMT_NV12 && srcFormat != PIX_FMT_NV21))\n\n    {\n\n        if (isPacked(c->srcFormat))\n\n            c->swScale = packedCopyWrapper;\n\n        else /* Planar YUV or gray */\n\n            c->swScale = planarCopyWrapper;\n\n    }\n\n\n\n    if (ARCH_BFIN)\n\n        ff_bfin_get_unscaled_swscale(c);\n\n    if (HAVE_ALTIVEC)\n\n        ff_swscale_get_unscaled_altivec(c);\n\n}\n", "idx": 14694, "_split": "test", "_hash": "2787c5bbefba8c8f559828f64646a034"}
{"project": "FFmpeg", "commit_id": "e22ebd04bcab7f86548794556c28ecca46d9c2ac", "target": 0, "func": "static void hls_transform_tree(HEVCContext *s, int x0, int y0,\n\n                               int xBase, int yBase, int cb_xBase, int cb_yBase,\n\n                               int log2_cb_size, int log2_trafo_size,\n\n                               int trafo_depth, int blk_idx)\n\n{\n\n    HEVCLocalContext *lc = &s->HEVClc;\n\n    uint8_t split_transform_flag;\n\n\n\n    if (trafo_depth > 0 && log2_trafo_size == 2) {\n\n        SAMPLE_CBF(lc->tt.cbf_cb[trafo_depth], x0, y0) =\n\n            SAMPLE_CBF(lc->tt.cbf_cb[trafo_depth - 1], xBase, yBase);\n\n        SAMPLE_CBF(lc->tt.cbf_cr[trafo_depth], x0, y0) =\n\n            SAMPLE_CBF(lc->tt.cbf_cr[trafo_depth - 1], xBase, yBase);\n\n    } else {\n\n        SAMPLE_CBF(lc->tt.cbf_cb[trafo_depth], x0, y0) =\n\n        SAMPLE_CBF(lc->tt.cbf_cr[trafo_depth], x0, y0) = 0;\n\n    }\n\n\n\n    if (lc->cu.intra_split_flag) {\n\n        if (trafo_depth == 1)\n\n            lc->tu.cur_intra_pred_mode = lc->pu.intra_pred_mode[blk_idx];\n\n    } else {\n\n        lc->tu.cur_intra_pred_mode = lc->pu.intra_pred_mode[0];\n\n    }\n\n\n\n    lc->tt.cbf_luma = 1;\n\n\n\n    lc->tt.inter_split_flag = s->sps->max_transform_hierarchy_depth_inter == 0 &&\n\n                              lc->cu.pred_mode == MODE_INTER &&\n\n                              lc->cu.part_mode != PART_2Nx2N &&\n\n                              trafo_depth == 0;\n\n\n\n    if (log2_trafo_size <= s->sps->log2_max_trafo_size &&\n\n        log2_trafo_size >  s->sps->log2_min_tb_size    &&\n\n        trafo_depth     < lc->cu.max_trafo_depth       &&\n\n        !(lc->cu.intra_split_flag && trafo_depth == 0)) {\n\n        split_transform_flag = ff_hevc_split_transform_flag_decode(s, log2_trafo_size);\n\n    } else {\n\n        split_transform_flag = log2_trafo_size > s->sps->log2_max_trafo_size ||\n\n                               (lc->cu.intra_split_flag && trafo_depth == 0) ||\n\n                               lc->tt.inter_split_flag;\n\n    }\n\n\n\n    if (log2_trafo_size > 2) {\n\n        if (trafo_depth == 0 ||\n\n            SAMPLE_CBF(lc->tt.cbf_cb[trafo_depth - 1], xBase, yBase)) {\n\n            SAMPLE_CBF(lc->tt.cbf_cb[trafo_depth], x0, y0) =\n\n                ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n\n        }\n\n\n\n        if (trafo_depth == 0 ||\n\n            SAMPLE_CBF(lc->tt.cbf_cr[trafo_depth - 1], xBase, yBase)) {\n\n            SAMPLE_CBF(lc->tt.cbf_cr[trafo_depth], x0, y0) =\n\n                ff_hevc_cbf_cb_cr_decode(s, trafo_depth);\n\n        }\n\n    }\n\n\n\n    if (split_transform_flag) {\n\n        int x1 = x0 + ((1 << log2_trafo_size) >> 1);\n\n        int y1 = y0 + ((1 << log2_trafo_size) >> 1);\n\n\n\n        hls_transform_tree(s, x0, y0, x0, y0, cb_xBase, cb_yBase, log2_cb_size,\n\n                           log2_trafo_size - 1, trafo_depth + 1, 0);\n\n        hls_transform_tree(s, x1, y0, x0, y0, cb_xBase, cb_yBase, log2_cb_size,\n\n                           log2_trafo_size - 1, trafo_depth + 1, 1);\n\n        hls_transform_tree(s, x0, y1, x0, y0, cb_xBase, cb_yBase, log2_cb_size,\n\n                           log2_trafo_size - 1, trafo_depth + 1, 2);\n\n        hls_transform_tree(s, x1, y1, x0, y0, cb_xBase, cb_yBase, log2_cb_size,\n\n                           log2_trafo_size - 1, trafo_depth + 1, 3);\n\n    } else {\n\n        int min_tu_size      = 1 << s->sps->log2_min_tb_size;\n\n        int log2_min_tu_size = s->sps->log2_min_tb_size;\n\n        int min_tu_width     = s->sps->min_tb_width;\n\n\n\n        if (lc->cu.pred_mode == MODE_INTRA || trafo_depth != 0 ||\n\n            SAMPLE_CBF(lc->tt.cbf_cb[trafo_depth], x0, y0) ||\n\n            SAMPLE_CBF(lc->tt.cbf_cr[trafo_depth], x0, y0)) {\n\n            lc->tt.cbf_luma = ff_hevc_cbf_luma_decode(s, trafo_depth);\n\n        }\n\n\n\n        hls_transform_unit(s, x0, y0, xBase, yBase, cb_xBase, cb_yBase,\n\n                           log2_cb_size, log2_trafo_size, trafo_depth, blk_idx);\n\n\n\n        // TODO: store cbf_luma somewhere else\n\n        if (lc->tt.cbf_luma) {\n\n            int i, j;\n\n            for (i = 0; i < (1 << log2_trafo_size); i += min_tu_size)\n\n                for (j = 0; j < (1 << log2_trafo_size); j += min_tu_size) {\n\n                    int x_tu = (x0 + j) >> log2_min_tu_size;\n\n                    int y_tu = (y0 + i) >> log2_min_tu_size;\n\n                    s->cbf_luma[y_tu * min_tu_width + x_tu] = 1;\n\n                }\n\n        }\n\n        if (!s->sh.disable_deblocking_filter_flag) {\n\n            ff_hevc_deblocking_boundary_strengths(s, x0, y0, log2_trafo_size,\n\n                                                  lc->slice_or_tiles_up_boundary,\n\n                                                  lc->slice_or_tiles_left_boundary);\n\n            if (s->pps->transquant_bypass_enable_flag &&\n\n                lc->cu.cu_transquant_bypass_flag)\n\n                set_deblocking_bypass(s, x0, y0, log2_trafo_size);\n\n        }\n\n    }\n\n}\n", "idx": 14723, "_split": "test", "_hash": "224c705d454d1a293fe19c4d70dc87c0"}
{"project": "FFmpeg", "commit_id": "ba3f07d0611d9a6c10eaa90b3c058ecdffe76676", "target": 1, "func": "static void aw_pulse_set2(WMAVoiceContext *s, GetBitContext *gb,\n\n                          int block_idx, AMRFixed *fcb)\n\n{\n\n    uint16_t use_mask_mem[9]; // only 5 are used, rest is padding\n\n    uint16_t *use_mask = use_mask_mem + 2;\n\n    /* in this function, idx is the index in the 80-bit (+ padding) use_mask\n\n     * bit-array. Since use_mask consists of 16-bit values, the lower 4 bits\n\n     * of idx are the position of the bit within a particular item in the\n\n     * array (0 being the most significant bit, and 15 being the least\n\n     * significant bit), and the remainder (>> 4) is the index in the\n\n     * use_mask[]-array. This is faster and uses less memory than using a\n\n     * 80-byte/80-int array. */\n\n    int pulse_off = s->aw_first_pulse_off[block_idx],\n\n        pulse_start, n, idx, range, aidx, start_off = 0;\n\n\n\n    /* set offset of first pulse to within this block */\n\n    if (s->aw_n_pulses[block_idx] > 0)\n\n        while (pulse_off + s->aw_pulse_range < 1)\n\n            pulse_off += fcb->pitch_lag;\n\n\n\n    /* find range per pulse */\n\n    if (s->aw_n_pulses[0] > 0) {\n\n        if (block_idx == 0) {\n\n            range = 32;\n\n        } else /* block_idx = 1 */ {\n\n            range = 8;\n\n            if (s->aw_n_pulses[block_idx] > 0)\n\n                pulse_off = s->aw_next_pulse_off_cache;\n\n        }\n\n    } else\n\n        range = 16;\n\n    pulse_start = s->aw_n_pulses[block_idx] > 0 ? pulse_off - range / 2 : 0;\n\n\n\n    /* aw_pulse_set1() already applies pulses around pulse_off (to be exactly,\n\n     * in the range of [pulse_off, pulse_off + s->aw_pulse_range], and thus\n\n     * we exclude that range from being pulsed again in this function. */\n\n    memset(&use_mask[-2], 0, 2 * sizeof(use_mask[0]));\n\n    memset( use_mask,   -1, 5 * sizeof(use_mask[0]));\n\n    memset(&use_mask[5], 0, 2 * sizeof(use_mask[0]));\n\n    if (s->aw_n_pulses[block_idx] > 0)\n\n        for (idx = pulse_off; idx < MAX_FRAMESIZE / 2; idx += fcb->pitch_lag) {\n\n            int excl_range         = s->aw_pulse_range; // always 16 or 24\n\n            uint16_t *use_mask_ptr = &use_mask[idx >> 4];\n\n            int first_sh           = 16 - (idx & 15);\n\n            *use_mask_ptr++       &= 0xFFFF << first_sh;\n\n            excl_range            -= first_sh;\n\n            if (excl_range >= 16) {\n\n                *use_mask_ptr++    = 0;\n\n                *use_mask_ptr     &= 0xFFFF >> (excl_range - 16);\n\n            } else\n\n                *use_mask_ptr     &= 0xFFFF >> excl_range;\n\n        }\n\n\n\n    /* find the 'aidx'th offset that is not excluded */\n\n    aidx = get_bits(gb, s->aw_n_pulses[0] > 0 ? 5 - 2 * block_idx : 4);\n\n    for (n = 0; n <= aidx; pulse_start++) {\n\n        for (idx = pulse_start; idx < 0; idx += fcb->pitch_lag) ;\n\n        if (idx >= MAX_FRAMESIZE / 2) { // find from zero\n\n            if (use_mask[0])      idx = 0x0F;\n\n            else if (use_mask[1]) idx = 0x1F;\n\n            else if (use_mask[2]) idx = 0x2F;\n\n            else if (use_mask[3]) idx = 0x3F;\n\n            else if (use_mask[4]) idx = 0x4F;\n\n            else                  return;\n\n            idx -= av_log2_16bit(use_mask[idx >> 4]);\n\n        }\n\n        if (use_mask[idx >> 4] & (0x8000 >> (idx & 15))) {\n\n            use_mask[idx >> 4] &= ~(0x8000 >> (idx & 15));\n\n            n++;\n\n            start_off = idx;\n\n        }\n\n    }\n\n\n\n    fcb->x[fcb->n] = start_off;\n\n    fcb->y[fcb->n] = get_bits1(gb) ? -1.0 : 1.0;\n\n    fcb->n++;\n\n\n\n    /* set offset for next block, relative to start of that block */\n\n    n = (MAX_FRAMESIZE / 2 - start_off) % fcb->pitch_lag;\n\n    s->aw_next_pulse_off_cache = n ? fcb->pitch_lag - n : 0;\n\n}\n", "idx": 14741, "_split": "test", "_hash": "c60b4d3c6150db4db378b347658646ed"}
{"project": "FFmpeg", "commit_id": "0ebb523f072322972ea446616676fff32e9603c6", "target": 1, "func": "static void asf_build_simple_index(AVFormatContext *s, int stream_index)\n\n{\n\n    ff_asf_guid g;\n\n    ASFContext *asf     = s->priv_data;\n\n    int64_t current_pos = avio_tell(s->pb);\n\n    int i;\n\n\n\n    avio_seek(s->pb, asf->data_object_offset + asf->data_object_size, SEEK_SET);\n\n    ff_get_guid(s->pb, &g);\n\n\n\n    /* the data object can be followed by other top-level objects,\n\n     * skip them until the simple index object is reached */\n\n    while (ff_guidcmp(&g, &index_guid)) {\n\n        int64_t gsize = avio_rl64(s->pb);\n\n        if (gsize < 24 || s->pb->eof_reached) {\n\n            avio_seek(s->pb, current_pos, SEEK_SET);\n\n            return;\n\n        }\n\n        avio_skip(s->pb, gsize - 24);\n\n        ff_get_guid(s->pb, &g);\n\n    }\n\n\n\n    {\n\n        int64_t itime, last_pos = -1;\n\n        int pct, ict;\n\n        int64_t av_unused gsize = avio_rl64(s->pb);\n\n        ff_get_guid(s->pb, &g);\n\n        itime = avio_rl64(s->pb);\n\n        pct   = avio_rl32(s->pb);\n\n        ict   = avio_rl32(s->pb);\n\n        av_log(s, AV_LOG_DEBUG,\n\n               \"itime:0x%\"PRIx64\", pct:%d, ict:%d\\n\", itime, pct, ict);\n\n\n\n        for (i = 0; i < ict; i++) {\n\n            int pktnum        = avio_rl32(s->pb);\n\n            int pktct         = avio_rl16(s->pb);\n\n            int64_t pos       = s->data_offset + s->packet_size * (int64_t)pktnum;\n\n            int64_t index_pts = FFMAX(av_rescale(itime, i, 10000) - asf->hdr.preroll, 0);\n\n\n\n            if (pos != last_pos) {\n\n                av_log(s, AV_LOG_DEBUG, \"pktnum:%d, pktct:%d  pts: %\"PRId64\"\\n\",\n\n                       pktnum, pktct, index_pts);\n\n                av_add_index_entry(s->streams[stream_index], pos, index_pts,\n\n                                   s->packet_size, 0, AVINDEX_KEYFRAME);\n\n                last_pos = pos;\n\n            }\n\n        }\n\n        asf->index_read = ict > 0;\n\n    }\n\n    avio_seek(s->pb, current_pos, SEEK_SET);\n\n}\n", "idx": 14745, "_split": "test", "_hash": "09f0ea8aea060c385da278af15ffd824"}
{"project": "FFmpeg", "commit_id": "3c5cf2a31b4b29a8e4282cbe6a3f0617c14698b8", "target": 0, "func": "static int screenpresso_decode_frame(AVCodecContext *avctx, void *data,\n\n                                     int *got_frame, AVPacket *avpkt)\n\n{\n\n    ScreenpressoContext *ctx = avctx->priv_data;\n\n    AVFrame *frame = data;\n\n    int keyframe;\n\n    int ret;\n\n\n\n    /* Size check */\n\n    if (avpkt->size < 3) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Packet too small (%d)\\n\", avpkt->size);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* Basic sanity check, but not really harmful */\n\n    if ((avpkt->data[0] != 0x73 && avpkt->data[0] != 0x72) ||\n\n        avpkt->data[1] != 8) { // bpp probably\n\n        av_log(avctx, AV_LOG_WARNING, \"Unknown header 0x%02X%02X\\n\",\n\n               avpkt->data[0], avpkt->data[1]);\n\n    }\n\n    keyframe = (avpkt->data[0] == 0x73);\n\n\n\n    /* Resize deflate buffer and frame on resolution change */\n\n    if (ctx->inflated_size != avctx->width * avctx->height * 3) {\n\n        av_frame_unref(ctx->current);\n\n        ret = ff_get_buffer(avctx, ctx->current, AV_GET_BUFFER_FLAG_REF);\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        /* If malloc fails, reset len to avoid preserving an invalid value */\n\n        ctx->inflated_size = avctx->width * avctx->height * 3;\n\n        ret = av_reallocp(&ctx->inflated_buf, ctx->inflated_size);\n\n        if (ret < 0) {\n\n            ctx->inflated_size = 0;\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    /* Inflate the frame after the 2 byte header */\n\n    ret = uncompress(ctx->inflated_buf, &ctx->inflated_size,\n\n                     avpkt->data + 2, avpkt->size - 2);\n\n    if (ret) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Deflate error %d.\\n\", ret);\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    /* When a keyframe is found, copy it (flipped) */\n\n    if (keyframe)\n\n        av_image_copy_plane(ctx->current->data[0] +\n\n                            ctx->current->linesize[0] * (avctx->height - 1),\n\n                            -1 * ctx->current->linesize[0],\n\n                            ctx->inflated_buf, avctx->width * 3,\n\n                            avctx->width * 3, avctx->height);\n\n    /* Otherwise sum the delta on top of the current frame */\n\n    else\n\n        sum_delta_flipped(ctx->current->data[0], ctx->current->linesize[0],\n\n                          ctx->inflated_buf, avctx->width * 3,\n\n                          avctx->width * 3, avctx->height);\n\n\n\n    /* Frame is ready to be output */\n\n    ret = av_frame_ref(frame, ctx->current);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* Usual properties */\n\n    if (keyframe) {\n\n        frame->pict_type = AV_PICTURE_TYPE_I;\n\n        frame->key_frame = 1;\n\n    } else {\n\n        frame->pict_type = AV_PICTURE_TYPE_P;\n\n    }\n\n    *got_frame = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 14813, "_split": "test", "_hash": "d9245b83d9d4e16f0d0faf0a52292af5"}
{"project": "FFmpeg", "commit_id": "850c6db97d1f78e7607952ab8b854a93a185319e", "target": 0, "func": "static int decode_plane(UtvideoContext *c, int plane_no,\n\n                        uint8_t *dst, int step, ptrdiff_t stride,\n\n                        int width, int height,\n\n                        const uint8_t *src, int use_pred)\n\n{\n\n    int i, j, slice, pix;\n\n    int sstart, send;\n\n    VLC vlc;\n\n    GetBitContext gb;\n\n    int prev, fsym;\n\n    const int cmask = c->interlaced ? ~(1 + 2 * (!plane_no && c->avctx->pix_fmt == AV_PIX_FMT_YUV420P)) : ~(!plane_no && c->avctx->pix_fmt == AV_PIX_FMT_YUV420P);\n\n\n\n    if (build_huff(src, &vlc, &fsym)) {\n\n        av_log(c->avctx, AV_LOG_ERROR, \"Cannot build Huffman codes\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (fsym >= 0) { // build_huff reported a symbol to fill slices with\n\n        send = 0;\n\n        for (slice = 0; slice < c->slices; slice++) {\n\n            uint8_t *dest;\n\n\n\n            sstart = send;\n\n            send   = (height * (slice + 1) / c->slices) & cmask;\n\n            dest   = dst + sstart * stride;\n\n\n\n            prev = 0x80;\n\n            for (j = sstart; j < send; j++) {\n\n                for (i = 0; i < width * step; i += step) {\n\n                    pix = fsym;\n\n                    if (use_pred) {\n\n                        prev += pix;\n\n                        pix   = prev;\n\n                    }\n\n                    dest[i] = pix;\n\n                }\n\n                dest += stride;\n\n            }\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    src      += 256;\n\n\n\n    send = 0;\n\n    for (slice = 0; slice < c->slices; slice++) {\n\n        uint8_t *dest;\n\n        int slice_data_start, slice_data_end, slice_size;\n\n\n\n        sstart = send;\n\n        send   = (height * (slice + 1) / c->slices) & cmask;\n\n        dest   = dst + sstart * stride;\n\n\n\n        // slice offset and size validation was done earlier\n\n        slice_data_start = slice ? AV_RL32(src + slice * 4 - 4) : 0;\n\n        slice_data_end   = AV_RL32(src + slice * 4);\n\n        slice_size       = slice_data_end - slice_data_start;\n\n\n\n        if (!slice_size) {\n\n            av_log(c->avctx, AV_LOG_ERROR, \"Plane has more than one symbol \"\n\n                   \"yet a slice has a length of zero.\\n\");\n\n            goto fail;\n\n        }\n\n\n\n        memset(c->slice_bits + slice_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n\n        c->bdsp.bswap_buf((uint32_t *) c->slice_bits,\n\n                          (uint32_t *)(src + slice_data_start + c->slices * 4),\n\n                          (slice_data_end - slice_data_start + 3) >> 2);\n\n        init_get_bits(&gb, c->slice_bits, slice_size * 8);\n\n\n\n        prev = 0x80;\n\n        for (j = sstart; j < send; j++) {\n\n            for (i = 0; i < width * step; i += step) {\n\n                pix = get_vlc2(&gb, vlc.table, VLC_BITS, 3);\n\n                if (pix < 0) {\n\n                    av_log(c->avctx, AV_LOG_ERROR, \"Decoding error\\n\");\n\n                    goto fail;\n\n                }\n\n                if (use_pred) {\n\n                    prev += pix;\n\n                    pix   = prev;\n\n                }\n\n                dest[i] = pix;\n\n            }\n\n            if (get_bits_left(&gb) < 0) {\n\n                av_log(c->avctx, AV_LOG_ERROR,\n\n                        \"Slice decoding ran out of bits\\n\");\n\n                goto fail;\n\n            }\n\n            dest += stride;\n\n        }\n\n        if (get_bits_left(&gb) > 32)\n\n            av_log(c->avctx, AV_LOG_WARNING,\n\n                   \"%d bits left after decoding slice\\n\", get_bits_left(&gb));\n\n    }\n\n\n\n    ff_free_vlc(&vlc);\n\n\n\n    return 0;\n\nfail:\n\n    ff_free_vlc(&vlc);\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 14848, "_split": "test", "_hash": "58bb55ddb93bf2cde7c2bff469acf629"}
{"project": "FFmpeg", "commit_id": "81a8701eb52d2b6469ae16ef442ce425388141b7", "target": 0, "func": "static int ogg_buffer_data(AVFormatContext *s, AVStream *st,\n\n                           uint8_t *data, unsigned size, int64_t granule,\n\n                           int header)\n\n{\n\n    OGGStreamContext *oggstream = st->priv_data;\n\n    OGGContext *ogg = s->priv_data;\n\n    int total_segments = size / 255 + 1;\n\n    uint8_t *p = data;\n\n    int i, segments, len, flush = 0;\n\n\n\n    // Handles VFR by flushing page because this frame needs to have a timestamp\n\n    // For theora, keyframes also need to have a timestamp to correctly mark\n\n    // them as such, otherwise seeking will not work correctly at the very\n\n    // least with old libogg versions.\n\n    // Do not try to flush header packets though, that will create broken files.\n\n    if (st->codec->codec_id == AV_CODEC_ID_THEORA && !header &&\n\n        (ogg_granule_to_timestamp(oggstream, granule) >\n\n         ogg_granule_to_timestamp(oggstream, oggstream->last_granule) + 1 ||\n\n         ogg_key_granule(oggstream, granule))) {\n\n        if (oggstream->page.granule != -1)\n\n            ogg_buffer_page(s, oggstream);\n\n        flush = 1;\n\n    }\n\n\n\n    // avoid a continued page\n\n    if (!header && oggstream->page.size > 0 &&\n\n        MAX_PAGE_SIZE - oggstream->page.size < size) {\n\n        ogg_buffer_page(s, oggstream);\n\n    }\n\n\n\n    for (i = 0; i < total_segments; ) {\n\n        OGGPage *page = &oggstream->page;\n\n\n\n        segments = FFMIN(total_segments - i, 255 - page->segments_count);\n\n\n\n        if (i && !page->segments_count)\n\n            page->flags |= 1; // continued packet\n\n\n\n        memset(page->segments+page->segments_count, 255, segments - 1);\n\n        page->segments_count += segments - 1;\n\n\n\n        len = FFMIN(size, segments*255);\n\n        page->segments[page->segments_count++] = len - (segments-1)*255;\n\n        memcpy(page->data+page->size, p, len);\n\n        p += len;\n\n        size -= len;\n\n        i += segments;\n\n        page->size += len;\n\n\n\n        if (i == total_segments)\n\n            page->granule = granule;\n\n\n\n        if (!header) {\n\n            AVStream *st = s->streams[page->stream_index];\n\n\n\n            int64_t start = av_rescale_q(page->start_granule, st->time_base,\n\n                                         AV_TIME_BASE_Q);\n\n            int64_t next  = av_rescale_q(page->granule, st->time_base,\n\n                                         AV_TIME_BASE_Q);\n\n\n\n            if (page->segments_count == 255 ||\n\n                (ogg->pref_size     > 0 && page->size   >= ogg->pref_size) ||\n\n                (ogg->pref_duration > 0 && next - start >= ogg->pref_duration)) {\n\n                ogg_buffer_page(s, oggstream);\n\n            }\n\n        }\n\n    }\n\n\n\n    if (flush && oggstream->page.granule != -1)\n\n        ogg_buffer_page(s, oggstream);\n\n\n\n    return 0;\n\n}\n", "idx": 14865, "_split": "test", "_hash": "3473637e95761d96e6783a3a02868f47"}
{"project": "FFmpeg", "commit_id": "38bb5a5434f913451aa512624a92b12b9925690f", "target": 0, "func": "void mpeg4_encode_picture_header(MpegEncContext * s, int picture_number)\n\n{\n\n    int time_incr;\n\n    int time_div, time_mod;\n\n\n\n    if(s->pict_type==AV_PICTURE_TYPE_I){\n\n        if(!(s->flags&CODEC_FLAG_GLOBAL_HEADER)){\n\n            if(s->strict_std_compliance < FF_COMPLIANCE_VERY_STRICT) //HACK, the reference sw is buggy\n\n                mpeg4_encode_visual_object_header(s);\n\n            if(s->strict_std_compliance < FF_COMPLIANCE_VERY_STRICT || picture_number==0) //HACK, the reference sw is buggy\n\n                mpeg4_encode_vol_header(s, 0, 0);\n\n        }\n\n        if(!(s->workaround_bugs & FF_BUG_MS))\n\n            mpeg4_encode_gop_header(s);\n\n    }\n\n\n\n    s->partitioned_frame= s->data_partitioning && s->pict_type!=AV_PICTURE_TYPE_B;\n\n\n\n    put_bits(&s->pb, 16, 0);                /* vop header */\n\n    put_bits(&s->pb, 16, VOP_STARTCODE);    /* vop header */\n\n    put_bits(&s->pb, 2, s->pict_type - 1);  /* pict type: I = 0 , P = 1 */\n\n\n\n    assert(s->time>=0);\n\n    time_div= s->time/s->avctx->time_base.den;\n\n    time_mod= s->time%s->avctx->time_base.den;\n\n    time_incr= time_div - s->last_time_base;\n\n    assert(time_incr >= 0);\n\n    while(time_incr--)\n\n        put_bits(&s->pb, 1, 1);\n\n\n\n    put_bits(&s->pb, 1, 0);\n\n\n\n    put_bits(&s->pb, 1, 1);                             /* marker */\n\n    put_bits(&s->pb, s->time_increment_bits, time_mod); /* time increment */\n\n    put_bits(&s->pb, 1, 1);                             /* marker */\n\n    put_bits(&s->pb, 1, 1);                             /* vop coded */\n\n    if (    s->pict_type == AV_PICTURE_TYPE_P\n\n        || (s->pict_type == AV_PICTURE_TYPE_S && s->vol_sprite_usage==GMC_SPRITE)) {\n\n        put_bits(&s->pb, 1, s->no_rounding);    /* rounding type */\n\n    }\n\n    put_bits(&s->pb, 3, 0);     /* intra dc VLC threshold */\n\n    if(!s->progressive_sequence){\n\n         put_bits(&s->pb, 1, s->current_picture_ptr->top_field_first);\n\n         put_bits(&s->pb, 1, s->alternate_scan);\n\n    }\n\n    //FIXME sprite stuff\n\n\n\n    put_bits(&s->pb, 5, s->qscale);\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_I)\n\n        put_bits(&s->pb, 3, s->f_code); /* fcode_for */\n\n    if (s->pict_type == AV_PICTURE_TYPE_B)\n\n        put_bits(&s->pb, 3, s->b_code); /* fcode_back */\n\n}\n", "idx": 14872, "_split": "test", "_hash": "7b6dd40399cf8f1749f4e2d65ed612f4"}
{"project": "FFmpeg", "commit_id": "0273ceebbd01f9fd5238558e6151e0b9aa3305ab", "target": 0, "func": "static void build_vlc(VLC *vlc, const uint8_t *bits_table, const uint8_t *val_table, \n\n                      int nb_codes)\n\n{\n\n    uint8_t huff_size[256];\n\n    uint16_t huff_code[256];\n\n\n\n    memset(huff_size, 0, sizeof(huff_size));\n\n    build_huffman_codes(huff_size, huff_code, bits_table, val_table);\n\n    \n\n    init_vlc(vlc, 9, nb_codes, huff_size, 1, 1, huff_code, 2, 2);\n\n}\n", "idx": 14884, "_split": "test", "_hash": "6acb1337be991489e714b26fe8005f57"}
{"project": "FFmpeg", "commit_id": "e0c6cce44729d94e2a5507a4b6d031f23e8bd7b6", "target": 0, "func": "av_cold void ff_vp56dsp_init_x86(VP56DSPContext* c, enum AVCodecID codec)\n\n{\n\n#if HAVE_YASM\n\n    int mm_flags = av_get_cpu_flags();\n\n\n\n    if (CONFIG_VP6_DECODER && codec == AV_CODEC_ID_VP6) {\n\n#if ARCH_X86_32\n\n        if (mm_flags & AV_CPU_FLAG_MMX) {\n\n            c->vp6_filter_diag4 = ff_vp6_filter_diag4_mmx;\n\n        }\n\n#endif\n\n\n\n        if (mm_flags & AV_CPU_FLAG_SSE2) {\n\n            c->vp6_filter_diag4 = ff_vp6_filter_diag4_sse2;\n\n        }\n\n    }\n\n#endif\n\n}\n", "idx": 14913, "_split": "test", "_hash": "fd598e795cf36f0a3b6676260f89e53b"}
{"project": "FFmpeg", "commit_id": "13705b69ebe9e375fdb52469760a0fbb5f593cc1", "target": 1, "func": "static void spatial_decompose53i(DWTELEM *buffer, int width, int height, int stride){\n\n    int y;\n\n    DWTELEM *b0= buffer + mirror(-2-1, height-1)*stride;\n\n    DWTELEM *b1= buffer + mirror(-2  , height-1)*stride;\n\n\n\n    for(y=-2; y<height; y+=2){\n\n        DWTELEM *b2= buffer + mirror(y+1, height-1)*stride;\n\n        DWTELEM *b3= buffer + mirror(y+2, height-1)*stride;\n\n\n\n{START_TIMER\n\n        if(b1 <= b3)     horizontal_decompose53i(b2, width);\n\n        if(y+2 < height) horizontal_decompose53i(b3, width);\n\nSTOP_TIMER(\"horizontal_decompose53i\")}\n\n\n\n{START_TIMER\n\n        if(b1 <= b3) vertical_decompose53iH0(b1, b2, b3, width);\n\n        if(b0 <= b2) vertical_decompose53iL0(b0, b1, b2, width);\n\nSTOP_TIMER(\"vertical_decompose53i*\")}\n\n\n\n        b0=b2;\n\n        b1=b3;\n\n    }\n\n}\n", "idx": 14942, "_split": "test", "_hash": "d4c02ef3e87300ddb71b2d5d9bfa2a62"}
{"project": "FFmpeg", "commit_id": "ec4c48397641dbaf4ae8df36c32aaa5a311a11bf", "target": 1, "func": "static int sap_write_header(AVFormatContext *s)\n\n{\n\n    struct SAPState *sap = s->priv_data;\n\n    char host[1024], path[1024], url[1024], announce_addr[50] = \"\";\n\n    char *option_list;\n\n    int port = 9875, base_port = 5004, i, pos = 0, same_port = 0, ttl = 255;\n\n    AVFormatContext **contexts = NULL;\n\n    int ret = 0;\n\n    struct sockaddr_storage localaddr;\n\n    socklen_t addrlen = sizeof(localaddr);\n\n    int udp_fd;\n\n    AVDictionaryEntry* title = av_dict_get(s->metadata, \"title\", NULL, 0);\n\n\n\n    if (!ff_network_init())\n\n        return AVERROR(EIO);\n\n\n\n    /* extract hostname and port */\n\n    av_url_split(NULL, 0, NULL, 0, host, sizeof(host), &base_port,\n\n                 path, sizeof(path), s->filename);\n\n    if (base_port < 0)\n\n        base_port = 5004;\n\n\n\n    /* search for options */\n\n    option_list = strrchr(path, '?');\n\n    if (option_list) {\n\n        char buf[50];\n\n        if (av_find_info_tag(buf, sizeof(buf), \"announce_port\", option_list)) {\n\n            port = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"same_port\", option_list)) {\n\n            same_port = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"ttl\", option_list)) {\n\n            ttl = strtol(buf, NULL, 10);\n\n        }\n\n        if (av_find_info_tag(buf, sizeof(buf), \"announce_addr\", option_list)) {\n\n            av_strlcpy(announce_addr, buf, sizeof(announce_addr));\n\n        }\n\n    }\n\n\n\n    if (!announce_addr[0]) {\n\n        struct addrinfo hints = { 0 }, *ai = NULL;\n\n        hints.ai_family = AF_UNSPEC;\n\n        if (getaddrinfo(host, NULL, &hints, &ai)) {\n\n            av_log(s, AV_LOG_ERROR, \"Unable to resolve %s\\n\", host);\n\n            ret = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n        if (ai->ai_family == AF_INET) {\n\n            /* Also known as sap.mcast.net */\n\n            av_strlcpy(announce_addr, \"224.2.127.254\", sizeof(announce_addr));\n\n#if HAVE_STRUCT_SOCKADDR_IN6\n\n        } else if (ai->ai_family == AF_INET6) {\n\n            /* With IPv6, you can use the same destination in many different\n\n             * multicast subnets, to choose how far you want it routed.\n\n             * This one is intended to be routed globally. */\n\n            av_strlcpy(announce_addr, \"ff0e::2:7ffe\", sizeof(announce_addr));\n\n#endif\n\n        } else {\n\n            freeaddrinfo(ai);\n\n            av_log(s, AV_LOG_ERROR, \"Host %s resolved to unsupported \"\n\n                                    \"address family\\n\", host);\n\n            ret = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n        freeaddrinfo(ai);\n\n    }\n\n\n\n    sap->protocols = ffurl_get_protocols(NULL, NULL);\n\n    if (!sap->protocols) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    contexts = av_mallocz(sizeof(AVFormatContext*) * s->nb_streams);\n\n    if (!contexts) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    s->start_time_realtime = av_gettime();\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        URLContext *fd;\n\n\n\n        ff_url_join(url, sizeof(url), \"rtp\", NULL, host, base_port,\n\n                    \"?ttl=%d\", ttl);\n\n        if (!same_port)\n\n            base_port += 2;\n\n        ret = ffurl_open(&fd, url, AVIO_FLAG_WRITE, &s->interrupt_callback, NULL,\n\n                         sap->protocols);\n\n        if (ret) {\n\n            ret = AVERROR(EIO);\n\n            goto fail;\n\n        }\n\n        ret = ff_rtp_chain_mux_open(&contexts[i], s, s->streams[i], fd, 0, i);\n\n        if (ret < 0)\n\n            goto fail;\n\n        s->streams[i]->priv_data = contexts[i];\n\n        s->streams[i]->time_base = contexts[i]->streams[0]->time_base;\n\n        av_strlcpy(contexts[i]->filename, url, sizeof(contexts[i]->filename));\n\n    }\n\n\n\n    if (s->nb_streams > 0 && title)\n\n        av_dict_set(&contexts[0]->metadata, \"title\", title->value, 0);\n\n\n\n    ff_url_join(url, sizeof(url), \"udp\", NULL, announce_addr, port,\n\n                \"?ttl=%d&connect=1\", ttl);\n\n    ret = ffurl_open(&sap->ann_fd, url, AVIO_FLAG_WRITE,\n\n                     &s->interrupt_callback, NULL, sap->protocols);\n\n    if (ret) {\n\n        ret = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n\n\n    udp_fd = ffurl_get_file_handle(sap->ann_fd);\n\n    if (getsockname(udp_fd, (struct sockaddr*) &localaddr, &addrlen)) {\n\n        ret = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n    if (localaddr.ss_family != AF_INET\n\n#if HAVE_STRUCT_SOCKADDR_IN6\n\n        && localaddr.ss_family != AF_INET6\n\n#endif\n\n        ) {\n\n        av_log(s, AV_LOG_ERROR, \"Unsupported protocol family\\n\");\n\n        ret = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n    sap->ann_size = 8192;\n\n    sap->ann = av_mallocz(sap->ann_size);\n\n    if (!sap->ann) {\n\n        ret = AVERROR(EIO);\n\n        goto fail;\n\n    }\n\n    sap->ann[pos] = (1 << 5);\n\n#if HAVE_STRUCT_SOCKADDR_IN6\n\n    if (localaddr.ss_family == AF_INET6)\n\n        sap->ann[pos] |= 0x10;\n\n#endif\n\n    pos++;\n\n    sap->ann[pos++] = 0; /* Authentication length */\n\n    AV_WB16(&sap->ann[pos], av_get_random_seed());\n\n    pos += 2;\n\n    if (localaddr.ss_family == AF_INET) {\n\n        memcpy(&sap->ann[pos], &((struct sockaddr_in*)&localaddr)->sin_addr,\n\n               sizeof(struct in_addr));\n\n        pos += sizeof(struct in_addr);\n\n#if HAVE_STRUCT_SOCKADDR_IN6\n\n    } else {\n\n        memcpy(&sap->ann[pos], &((struct sockaddr_in6*)&localaddr)->sin6_addr,\n\n               sizeof(struct in6_addr));\n\n        pos += sizeof(struct in6_addr);\n\n#endif\n\n    }\n\n\n\n    av_strlcpy(&sap->ann[pos], \"application/sdp\", sap->ann_size - pos);\n\n    pos += strlen(&sap->ann[pos]) + 1;\n\n\n\n    if (av_sdp_create(contexts, s->nb_streams, &sap->ann[pos],\n\n                      sap->ann_size - pos)) {\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n    av_freep(&contexts);\n\n    av_log(s, AV_LOG_VERBOSE, \"SDP:\\n%s\\n\", &sap->ann[pos]);\n\n    pos += strlen(&sap->ann[pos]);\n\n    sap->ann_size = pos;\n\n\n\n    if (sap->ann_size > sap->ann_fd->max_packet_size) {\n\n        av_log(s, AV_LOG_ERROR, \"Announcement too large to send in one \"\n\n                                \"packet\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_free(contexts);\n\n    sap_write_close(s);\n\n    return ret;\n\n}\n", "idx": 15001, "_split": "test", "_hash": "2d2544c63684962cdd7eadbdaf452570"}
{"project": "FFmpeg", "commit_id": "ef23bd939d955f53bc58696bbb68960784066894", "target": 1, "func": "static void hls_prediction_unit(HEVCContext *s, int x0, int y0,\n\n                                int nPbW, int nPbH,\n\n                                int log2_cb_size, int partIdx, int idx)\n\n{\n\n#define POS(c_idx, x, y)                                                              \\\n\n    &s->frame->data[c_idx][((y) >> s->sps->vshift[c_idx]) * s->frame->linesize[c_idx] + \\\n\n                           (((x) >> s->sps->hshift[c_idx]) << s->sps->pixel_shift)]\n\n    HEVCLocalContext *lc = s->HEVClc;\n\n    int merge_idx = 0;\n\n    struct MvField current_mv = {{{ 0 }}};\n\n\n\n    int min_pu_width = s->sps->min_pu_width;\n\n\n\n    MvField *tab_mvf = s->ref->tab_mvf;\n\n    RefPicList  *refPicList = s->ref->refPicList;\n\n    HEVCFrame *ref0, *ref1;\n\n    uint8_t *dst0 = POS(0, x0, y0);\n\n    uint8_t *dst1 = POS(1, x0, y0);\n\n    uint8_t *dst2 = POS(2, x0, y0);\n\n    int log2_min_cb_size = s->sps->log2_min_cb_size;\n\n    int min_cb_width     = s->sps->min_cb_width;\n\n    int x_cb             = x0 >> log2_min_cb_size;\n\n    int y_cb             = y0 >> log2_min_cb_size;\n\n    int x_pu, y_pu;\n\n    int i, j;\n\n\n\n    int skip_flag = SAMPLE_CTB(s->skip_flag, x_cb, y_cb);\n\n\n\n    if (!skip_flag)\n\n        lc->pu.merge_flag = ff_hevc_merge_flag_decode(s);\n\n\n\n    if (skip_flag || lc->pu.merge_flag) {\n\n        if (s->sh.max_num_merge_cand > 1)\n\n            merge_idx = ff_hevc_merge_idx_decode(s);\n\n        else\n\n            merge_idx = 0;\n\n\n\n        ff_hevc_luma_mv_merge_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n\n                                   partIdx, merge_idx, &current_mv);\n\n    } else {\n\n        hevc_luma_mv_mpv_mode(s, x0, y0, nPbW, nPbH, log2_cb_size,\n\n                              partIdx, merge_idx, &current_mv);\n\n    }\n\n\n\n    x_pu = x0 >> s->sps->log2_min_pu_size;\n\n    y_pu = y0 >> s->sps->log2_min_pu_size;\n\n\n\n    for (j = 0; j < nPbH >> s->sps->log2_min_pu_size; j++)\n\n        for (i = 0; i < nPbW >> s->sps->log2_min_pu_size; i++)\n\n            tab_mvf[(y_pu + j) * min_pu_width + x_pu + i] = current_mv;\n\n\n\n    if (current_mv.pred_flag & PF_L0) {\n\n        ref0 = refPicList[0].ref[current_mv.ref_idx[0]];\n\n        if (!ref0)\n\n            return;\n\n        hevc_await_progress(s, ref0, &current_mv.mv[0], y0, nPbH);\n\n    }\n\n    if (current_mv.pred_flag & PF_L1) {\n\n        ref1 = refPicList[1].ref[current_mv.ref_idx[1]];\n\n        if (!ref1)\n\n            return;\n\n        hevc_await_progress(s, ref1, &current_mv.mv[1], y0, nPbH);\n\n    }\n\n\n\n    if (current_mv.pred_flag == PF_L0) {\n\n        int x0_c = x0 >> s->sps->hshift[1];\n\n        int y0_c = y0 >> s->sps->vshift[1];\n\n        int nPbW_c = nPbW >> s->sps->hshift[1];\n\n        int nPbH_c = nPbH >> s->sps->vshift[1];\n\n\n\n        luma_mc_uni(s, dst0, s->frame->linesize[0], ref0->frame,\n\n                    &current_mv.mv[0], x0, y0, nPbW, nPbH,\n\n                    s->sh.luma_weight_l0[current_mv.ref_idx[0]],\n\n                    s->sh.luma_offset_l0[current_mv.ref_idx[0]]);\n\n\n\n        chroma_mc_uni(s, dst1, s->frame->linesize[1], ref0->frame->data[1], ref0->frame->linesize[1],\n\n                      0, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n\n                      s->sh.chroma_weight_l0[current_mv.ref_idx[0]][0], s->sh.chroma_offset_l0[current_mv.ref_idx[0]][0]);\n\n        chroma_mc_uni(s, dst2, s->frame->linesize[2], ref0->frame->data[2], ref0->frame->linesize[2],\n\n                      0, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n\n                      s->sh.chroma_weight_l0[current_mv.ref_idx[0]][1], s->sh.chroma_offset_l0[current_mv.ref_idx[0]][1]);\n\n    } else if (current_mv.pred_flag == PF_L1) {\n\n        int x0_c = x0 >> s->sps->hshift[1];\n\n        int y0_c = y0 >> s->sps->vshift[1];\n\n        int nPbW_c = nPbW >> s->sps->hshift[1];\n\n        int nPbH_c = nPbH >> s->sps->vshift[1];\n\n\n\n        luma_mc_uni(s, dst0, s->frame->linesize[0], ref1->frame,\n\n                    &current_mv.mv[1], x0, y0, nPbW, nPbH,\n\n                    s->sh.luma_weight_l1[current_mv.ref_idx[1]],\n\n                    s->sh.luma_offset_l1[current_mv.ref_idx[1]]);\n\n\n\n        chroma_mc_uni(s, dst1, s->frame->linesize[1], ref1->frame->data[1], ref1->frame->linesize[1],\n\n                      1, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n\n                      s->sh.chroma_weight_l1[current_mv.ref_idx[1]][0], s->sh.chroma_offset_l1[current_mv.ref_idx[1]][0]);\n\n\n\n        chroma_mc_uni(s, dst2, s->frame->linesize[2], ref1->frame->data[2], ref1->frame->linesize[2],\n\n                      1, x0_c, y0_c, nPbW_c, nPbH_c, &current_mv,\n\n                      s->sh.chroma_weight_l1[current_mv.ref_idx[1]][1], s->sh.chroma_offset_l1[current_mv.ref_idx[1]][1]);\n\n    } else if (current_mv.pred_flag == PF_BI) {\n\n        int x0_c = x0 >> s->sps->hshift[1];\n\n        int y0_c = y0 >> s->sps->vshift[1];\n\n        int nPbW_c = nPbW >> s->sps->hshift[1];\n\n        int nPbH_c = nPbH >> s->sps->vshift[1];\n\n\n\n        luma_mc_bi(s, dst0, s->frame->linesize[0], ref0->frame,\n\n                   &current_mv.mv[0], x0, y0, nPbW, nPbH,\n\n                   ref1->frame, &current_mv.mv[1], &current_mv);\n\n\n\n        chroma_mc_bi(s, dst1, s->frame->linesize[1], ref0->frame, ref1->frame,\n\n                     x0_c, y0_c, nPbW_c, nPbH_c, &current_mv, 0);\n\n\n\n        chroma_mc_bi(s, dst2, s->frame->linesize[2], ref0->frame, ref1->frame,\n\n                     x0_c, y0_c, nPbW_c, nPbH_c, &current_mv, 1);\n\n    }\n\n}\n", "idx": 15002, "_split": "test", "_hash": "bc9ef036ca5d9a7060e8c0b541dee22e"}
{"project": "FFmpeg", "commit_id": "0c32e19d584ba6ddbc27f0a796260404daaf4b6a", "target": 0, "func": "static void av_noinline filter_mb_edgeh( uint8_t *pix, int stride, int16_t bS[4], unsigned int qp, H264Context *h ) {\n\n    const unsigned int index_a = 52 + qp + h->slice_alpha_c0_offset;\n\n    const int alpha = alpha_table[index_a];\n\n    const int beta  = (beta_table+52)[qp + h->slice_beta_offset];\n\n    if (alpha ==0 || beta == 0) return;\n\n\n\n    if( bS[0] < 4 ) {\n\n        int8_t tc[4];\n\n        tc[0] = tc0_table[index_a][bS[0]];\n\n        tc[1] = tc0_table[index_a][bS[1]];\n\n        tc[2] = tc0_table[index_a][bS[2]];\n\n        tc[3] = tc0_table[index_a][bS[3]];\n\n        h->s.dsp.h264_v_loop_filter_luma(pix, stride, alpha, beta, tc);\n\n    } else {\n\n        h->s.dsp.h264_v_loop_filter_luma_intra(pix, stride, alpha, beta);\n\n    }\n\n}\n", "idx": 15051, "_split": "test", "_hash": "bb597a3cc99ab6cca19e78ca9858f1ac"}
{"project": "FFmpeg", "commit_id": "a443a2530d00b7019269202ac0f5ca8ba0a021c7", "target": 1, "func": "static int vmd_read_header(AVFormatContext *s,\n\n                           AVFormatParameters *ap)\n\n{\n\n    VmdDemuxContext *vmd = (VmdDemuxContext *)s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    AVStream *st;\n\n    unsigned int toc_offset;\n\n    unsigned char *raw_frame_table;\n\n    int raw_frame_table_size;\n\n    offset_t current_offset;\n\n    int i, j;\n\n    unsigned int total_frames;\n\n    int64_t video_pts_inc = 0;\n\n    int64_t current_video_pts = 0;\n\n    unsigned char chunk[BYTES_PER_FRAME_RECORD];\n\n    int lastframe = 0;\n\n\n\n    /* fetch the main header, including the 2 header length bytes */\n\n    url_fseek(pb, 0, SEEK_SET);\n\n    if (get_buffer(pb, vmd->vmd_header, VMD_HEADER_SIZE) != VMD_HEADER_SIZE)\n\n        return AVERROR_IO;\n\n\n\n    vmd->audio_sample_counter = 0;\n\n    vmd->audio_frame_divisor = 1;\n\n    vmd->audio_block_align = 1;\n\n\n\n    /* start up the decoders */\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR_NOMEM;\n\n    av_set_pts_info(st, 33, 1, 90000);\n\n    vmd->video_stream_index = st->index;\n\n    st->codec->codec_type = CODEC_TYPE_VIDEO;\n\n    st->codec->codec_id = CODEC_ID_VMDVIDEO;\n\n    st->codec->codec_tag = 0;  /* no fourcc */\n\n    st->codec->width = LE_16(&vmd->vmd_header[12]);\n\n    st->codec->height = LE_16(&vmd->vmd_header[14]);\n\n    st->codec->time_base.num = 1;\n\n    st->codec->time_base.den = 10;\n\n    st->codec->extradata_size = VMD_HEADER_SIZE;\n\n    st->codec->extradata = av_mallocz(VMD_HEADER_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    memcpy(st->codec->extradata, vmd->vmd_header, VMD_HEADER_SIZE);\n\n\n\n    /* if sample rate is 0, assume no audio */\n\n    vmd->sample_rate = LE_16(&vmd->vmd_header[804]);\n\n    if (vmd->sample_rate) {\n\n        st = av_new_stream(s, 0);\n\n        if (!st)\n\n            return AVERROR_NOMEM;\n\n        av_set_pts_info(st, 33, 1, 90000);\n\n        vmd->audio_stream_index = st->index;\n\n        st->codec->codec_type = CODEC_TYPE_AUDIO;\n\n        st->codec->codec_id = CODEC_ID_VMDAUDIO;\n\n        st->codec->codec_tag = 0;  /* no fourcc */\n\n        st->codec->channels = vmd->audio_channels = (vmd->vmd_header[811] & 0x80) ? 2 : 1;\n\n        st->codec->sample_rate = vmd->sample_rate;\n\n        st->codec->block_align = vmd->audio_block_align =\n\n            LE_16(&vmd->vmd_header[806]);\n\n        if (st->codec->block_align & 0x8000) {\n\n            st->codec->bits_per_sample = 16;\n\n            st->codec->block_align = -(st->codec->block_align - 0x10000);\n\n            vmd->audio_block_align = -(vmd->audio_block_align - 0x10000);\n\n        } else {\n\n            st->codec->bits_per_sample = 8;\n\n\n        st->codec->bit_rate = st->codec->sample_rate *\n\n            st->codec->bits_per_sample * st->codec->channels;\n\n\n\n        /* for calculating pts */\n\n        vmd->audio_frame_divisor = st->codec->channels;\n\n\n\n        video_pts_inc = 90000;\n\n        video_pts_inc *= st->codec->block_align;\n\n        video_pts_inc /= st->codec->sample_rate;\n\n        video_pts_inc /= st->codec->channels;\n\n    } else {\n\n        /* if no audio, assume 10 frames/second */\n\n        video_pts_inc = 90000 / 10;\n\n\n\n\n    toc_offset = LE_32(&vmd->vmd_header[812]);\n\n    vmd->frame_count = LE_16(&vmd->vmd_header[6]);\n\n    vmd->frames_per_block = LE_16(&vmd->vmd_header[18]);\n\n    url_fseek(pb, toc_offset, SEEK_SET);\n\n\n\n    raw_frame_table = NULL;\n\n    vmd->frame_table = NULL;\n\n    raw_frame_table_size = vmd->frame_count * 6;\n\n    raw_frame_table = av_malloc(raw_frame_table_size);\n\n\n\n\n\n    vmd->frame_table = av_malloc(vmd->frame_count * vmd->frames_per_block * sizeof(vmd_frame_t));\n\n    if (!raw_frame_table || !vmd->frame_table) {\n\n        av_free(raw_frame_table);\n\n        av_free(vmd->frame_table);\n\n        return AVERROR_NOMEM;\n\n\n    if (get_buffer(pb, raw_frame_table, raw_frame_table_size) !=\n\n        raw_frame_table_size) {\n\n        av_free(raw_frame_table);\n\n        av_free(vmd->frame_table);\n\n        return AVERROR_IO;\n\n\n\n\n    total_frames = 0;\n\n    for (i = 0; i < vmd->frame_count; i++) {\n\n\n\n        current_offset = LE_32(&raw_frame_table[6 * i + 2]);\n\n\n\n        /* handle each entry in index block */\n\n        for (j = 0; j < vmd->frames_per_block; j++) {\n\n            int type;\n\n            uint32_t size;\n\n\n\n            get_buffer(pb, chunk, BYTES_PER_FRAME_RECORD);\n\n            type = chunk[0];\n\n            size = LE_32(&chunk[2]);\n\n            if(!size)\n\n                continue;\n\n            switch(type) {\n\n            case 1: /* Audio Chunk */\n\n                vmd->frame_table[total_frames].frame_offset = current_offset;\n\n                vmd->frame_table[total_frames].stream_index = vmd->audio_stream_index;\n\n                vmd->frame_table[total_frames].frame_size = size;\n\n                memcpy(vmd->frame_table[total_frames].frame_record, chunk, BYTES_PER_FRAME_RECORD);\n\n                total_frames++;\n\n                break;\n\n            case 2: /* Video Chunk */\n\n                vmd->frame_table[total_frames].frame_offset = current_offset;\n\n                vmd->frame_table[total_frames].frame_size = size;\n\n                vmd->frame_table[total_frames].stream_index = vmd->video_stream_index;\n\n                memcpy(vmd->frame_table[total_frames].frame_record, chunk, BYTES_PER_FRAME_RECORD);\n\n                vmd->frame_table[total_frames].pts = current_video_pts;\n\n                if (lastframe) {\n\n                    vmd->frame_table[lastframe].pts = current_video_pts - video_pts_inc;\n\n\n                lastframe = total_frames;\n\n                total_frames++;\n\n                break;\n\n\n            current_offset += size;\n\n\n        current_video_pts += video_pts_inc;\n\n\n\n\n    av_free(raw_frame_table);\n\n\n\n    vmd->current_frame = 0;\n\n    vmd->frame_count = total_frames;\n\n\n\n    return 0;\n", "idx": 15094, "_split": "test", "_hash": "a8b2d90b9456631e75892c990e7424ce"}
{"project": "FFmpeg", "commit_id": "99e5a9d1ea2a61ac9429427431e5b9c2fefb76a5", "target": 0, "func": "void dsputil_init_arm(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n    int idct_algo= avctx->idct_algo;\n\n\n\n    ff_put_pixels_clamped = c->put_pixels_clamped;\n\n    ff_add_pixels_clamped = c->add_pixels_clamped;\n\n\n\n    if (avctx->lowres == 0) {\n\n        if(idct_algo == FF_IDCT_AUTO){\n\n#if   HAVE_IPP\n\n            idct_algo = FF_IDCT_IPP;\n\n#elif HAVE_NEON\n\n            idct_algo = FF_IDCT_SIMPLENEON;\n\n#elif HAVE_ARMV6\n\n            idct_algo = FF_IDCT_SIMPLEARMV6;\n\n#elif HAVE_ARMV5TE\n\n            idct_algo = FF_IDCT_SIMPLEARMV5TE;\n\n#else\n\n            idct_algo = FF_IDCT_ARM;\n\n#endif\n\n        }\n\n\n\n        if(idct_algo==FF_IDCT_ARM){\n\n            c->idct_put= j_rev_dct_ARM_put;\n\n            c->idct_add= j_rev_dct_ARM_add;\n\n            c->idct    = j_rev_dct_ARM;\n\n            c->idct_permutation_type= FF_LIBMPEG2_IDCT_PERM;\n\n        } else if (idct_algo==FF_IDCT_SIMPLEARM){\n\n            c->idct_put= simple_idct_ARM_put;\n\n            c->idct_add= simple_idct_ARM_add;\n\n            c->idct    = simple_idct_ARM;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n#if HAVE_ARMV6\n\n        } else if (idct_algo==FF_IDCT_SIMPLEARMV6){\n\n            c->idct_put= ff_simple_idct_put_armv6;\n\n            c->idct_add= ff_simple_idct_add_armv6;\n\n            c->idct    = ff_simple_idct_armv6;\n\n            c->idct_permutation_type= FF_LIBMPEG2_IDCT_PERM;\n\n#endif\n\n#if HAVE_ARMV5TE\n\n        } else if (idct_algo==FF_IDCT_SIMPLEARMV5TE){\n\n            c->idct_put= simple_idct_put_armv5te;\n\n            c->idct_add= simple_idct_add_armv5te;\n\n            c->idct    = simple_idct_armv5te;\n\n            c->idct_permutation_type = FF_NO_IDCT_PERM;\n\n#endif\n\n#if HAVE_IPP\n\n        } else if (idct_algo==FF_IDCT_IPP){\n\n            c->idct_put= simple_idct_ipp_put;\n\n            c->idct_add= simple_idct_ipp_add;\n\n            c->idct    = simple_idct_ipp;\n\n            c->idct_permutation_type= FF_NO_IDCT_PERM;\n\n#endif\n\n#if HAVE_NEON\n\n        } else if (idct_algo==FF_IDCT_SIMPLENEON){\n\n            c->idct_put= ff_simple_idct_put_neon;\n\n            c->idct_add= ff_simple_idct_add_neon;\n\n            c->idct    = ff_simple_idct_neon;\n\n            c->idct_permutation_type = FF_PARTTRANS_IDCT_PERM;\n\n        } else if ((CONFIG_VP3_DECODER || CONFIG_VP5_DECODER || CONFIG_VP6_DECODER || CONFIG_THEORA_DECODER) &&\n\n                   idct_algo==FF_IDCT_VP3){\n\n            c->idct_put= ff_vp3_idct_put_neon;\n\n            c->idct_add= ff_vp3_idct_add_neon;\n\n            c->idct    = ff_vp3_idct_neon;\n\n            c->idct_permutation_type = FF_TRANSPOSE_IDCT_PERM;\n\n#endif\n\n        }\n\n    }\n\n\n\n    c->put_pixels_tab[0][0] = put_pixels16_arm;\n\n    c->put_pixels_tab[0][1] = put_pixels16_x2_arm;\n\n    c->put_pixels_tab[0][2] = put_pixels16_y2_arm;\n\n    c->put_pixels_tab[0][3] = put_pixels16_xy2_arm;\n\n    c->put_no_rnd_pixels_tab[0][0] = put_pixels16_arm;\n\n    c->put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_arm;\n\n    c->put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_arm;\n\n    c->put_no_rnd_pixels_tab[0][3] = put_no_rnd_pixels16_xy2_arm;\n\n    c->put_pixels_tab[1][0] = put_pixels8_arm;\n\n    c->put_pixels_tab[1][1] = put_pixels8_x2_arm;\n\n    c->put_pixels_tab[1][2] = put_pixels8_y2_arm;\n\n    c->put_pixels_tab[1][3] = put_pixels8_xy2_arm;\n\n    c->put_no_rnd_pixels_tab[1][0] = put_pixels8_arm;\n\n    c->put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels8_x2_arm;\n\n    c->put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels8_y2_arm;\n\n    c->put_no_rnd_pixels_tab[1][3] = put_no_rnd_pixels8_xy2_arm;\n\n\n\n#if HAVE_ARMV5TE\n\n    c->prefetch = ff_prefetch_arm;\n\n#endif\n\n\n\n#if HAVE_IWMMXT\n\n    dsputil_init_iwmmxt(c, avctx);\n\n#endif\n\n#if HAVE_ARMVFP\n\n    ff_float_init_arm_vfp(c, avctx);\n\n#endif\n\n#if HAVE_NEON\n\n    ff_dsputil_init_neon(c, avctx);\n\n#endif\n\n}\n", "idx": 15106, "_split": "test", "_hash": "0ac459ae5c1a845eed0f3e00e7b3ddbc"}
{"project": "FFmpeg", "commit_id": "7a4f74eed51f914e9bbfebaffd4a92ac6791f819", "target": 0, "func": "av_cold void ff_h264_free_context(H264Context *h)\n\n{\n\n    int i;\n\n\n\n    ff_h264_free_tables(h);\n\n\n\n    if (h->DPB) {\n\n        for (i = 0; i < H264_MAX_PICTURE_COUNT; i++)\n\n            ff_h264_unref_picture(h, &h->DPB[i]);\n\n        av_freep(&h->DPB);\n\n    }\n\n\n\n    h->cur_pic_ptr = NULL;\n\n\n\n    for (i = 0; i < h->nb_slice_ctx; i++)\n\n        av_freep(&h->slice_ctx[i].rbsp_buffer);\n\n    av_freep(&h->slice_ctx);\n\n    h->nb_slice_ctx = 0;\n\n\n\n    for (i = 0; i < MAX_SPS_COUNT; i++)\n\n        av_freep(h->sps_buffers + i);\n\n\n\n    for (i = 0; i < MAX_PPS_COUNT; i++)\n\n        av_freep(h->pps_buffers + i);\n\n}\n", "idx": 15108, "_split": "test", "_hash": "390a8281c1b70bac2d8301e6a01ffea0"}
{"project": "FFmpeg", "commit_id": "252c0bfdc014c1fb6ad4fe06242c7beca58a6b41", "target": 1, "func": "int avcodec_default_reget_buffer(AVCodecContext *s, AVFrame *pic)\n\n{\n\n    av_assert0(0);\n\n\n}", "idx": 15124, "_split": "test", "_hash": "d62754b48281c8fc9f2f4b3db217afef"}
{"project": "FFmpeg", "commit_id": "d1a58afb95f68c5375b4a7556317d835108509ed", "target": 1, "func": "static int latm_write_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    PutBitContext bs;\n\n    int i, len;\n\n    uint8_t loas_header[] = \"\\x56\\xe0\\x00\";\n\n    uint8_t *buf = NULL;\n\n\n\n    if (s->streams[0]->codec->codec_id == CODEC_ID_AAC_LATM)\n\n        return ff_raw_write_packet(s, pkt);\n\n\n\n    if (pkt->size > 2 && pkt->data[0] == 0xff && (pkt->data[1] >> 4) == 0xf) {\n\n        av_log(s, AV_LOG_ERROR, \"ADTS header detected - ADTS will not be incorrectly muxed into LATM\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (pkt->size > 0x1fff)\n\n        goto too_large;\n\n\n\n    buf = av_malloc(pkt->size+1024);\n\n    if (!buf)\n\n        return AVERROR(ENOMEM);\n\n\n\n    init_put_bits(&bs, buf, pkt->size+1024);\n\n\n\n    latm_write_frame_header(s, &bs);\n\n\n\n    /* PayloadLengthInfo() */\n\n    for (i = 0; i <= pkt->size-255; i+=255)\n\n        put_bits(&bs, 8, 255);\n\n\n\n    put_bits(&bs, 8, pkt->size-i);\n\n\n\n    /* The LATM payload is written unaligned */\n\n\n\n    /* PayloadMux() */\n\n    if (pkt->size && (pkt->data[0] & 0xe1) == 0x81) {\n\n        // Convert byte-aligned DSE to non-aligned.\n\n        // Due to the input format encoding we know that\n\n        // it is naturally byte-aligned in the input stream,\n\n        // so there are no padding bits to account for.\n\n        // To avoid having to add padding bits and rearrange\n\n        // the whole stream we just remove the byte-align flag.\n\n        // This allows us to remux our FATE AAC samples into latm\n\n        // files that are still playable with minimal effort.\n\n        put_bits(&bs, 8, pkt->data[0] & 0xfe);\n\n        avpriv_copy_bits(&bs, pkt->data + 1, 8*pkt->size - 8);\n\n    } else\n\n        avpriv_copy_bits(&bs, pkt->data, 8*pkt->size);\n\n\n\n    avpriv_align_put_bits(&bs);\n\n    flush_put_bits(&bs);\n\n\n\n    len = put_bits_count(&bs) >> 3;\n\n\n\n    if (len > 0x1fff)\n\n        goto too_large;\n\n\n\n    loas_header[1] |= (len >> 8) & 0x1f;\n\n    loas_header[2] |= len & 0xff;\n\n\n\n    avio_write(pb, loas_header, 3);\n\n    avio_write(pb, buf, len);\n\n\n\n    av_free(buf);\n\n\n\n    return 0;\n\n\n\ntoo_large:\n\n    av_log(s, AV_LOG_ERROR, \"LATM packet size larger than maximum size 0x1fff\\n\");\n\n    av_free(buf);\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 15125, "_split": "test", "_hash": "51dd9393e4856a489d4cda01c60e661e"}
{"project": "FFmpeg", "commit_id": "3a54c221d574ec944db1eddf9df895808f32bf9e", "target": 1, "func": "static const char *read_ts(const char *buf, int *ts_start, int *ts_end,\n\n                           int *x1, int *y1, int *x2, int *y2)\n\n{\n\n    int i, hs, ms, ss, he, me, se;\n\n\n\n    for (i=0; i<2; i++) {\n\n        /* try to read timestamps in either the first or second line */\n\n        int c = sscanf(buf, \"%d:%2d:%2d%*1[,.]%3d --> %d:%2d:%2d%*1[,.]%3d\"\n\n                       \"%*[ ]X1:%u X2:%u Y1:%u Y2:%u\",\n\n                       &hs, &ms, &ss, ts_start, &he, &me, &se, ts_end,\n\n                       x1, x2, y1, y2);\n\n        buf += strcspn(buf, \"\\n\") + 1;\n\n        if (c >= 8) {\n\n            *ts_start = 100*(ss + 60*(ms + 60*hs)) + *ts_start/10;\n\n            *ts_end   = 100*(se + 60*(me + 60*he)) + *ts_end  /10;\n\n            return buf;\n\n        }\n\n    }\n\n    return NULL;\n\n}\n", "idx": 15133, "_split": "test", "_hash": "c511b5f4bf3092b2fb1738fc35e8a1d2"}
{"project": "FFmpeg", "commit_id": "c571424c7f6276a6374e1784ce2a33d4b6a4292d", "target": 1, "func": "static int asf_read_picture(AVFormatContext *s, int len)\n\n{\n\n    ASFContext *asf       = s->priv_data;\n\n    AVPacket pkt          = { 0 };\n\n    const CodecMime *mime = ff_id3v2_mime_tags;\n\n    enum  AVCodecID id    = AV_CODEC_ID_NONE;\n\n    char mimetype[64];\n\n    uint8_t  *desc = NULL;\n\n    AVStream   *st = NULL;\n\n    int ret, type, picsize, desc_len;\n\n    ASFStream *asf_st;\n\n\n\n    /* type + picsize + mime + desc */\n\n    if (len < 1 + 4 + 2 + 2) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid attached picture size: %d.\\n\", len);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* picture type */\n\n    type = avio_r8(s->pb);\n\n    len--;\n\n    if (type >= FF_ARRAY_ELEMS(ff_id3v2_picture_types) || type < 0) {\n\n        av_log(s, AV_LOG_WARNING, \"Unknown attached picture type: %d.\\n\", type);\n\n        type = 0;\n\n    }\n\n\n\n    /* picture data size */\n\n    picsize = avio_rl32(s->pb);\n\n    len    -= 4;\n\n\n\n    /* picture MIME type */\n\n    len -= avio_get_str16le(s->pb, len, mimetype, sizeof(mimetype));\n\n    while (mime->id != AV_CODEC_ID_NONE) {\n\n        if (!strncmp(mime->str, mimetype, sizeof(mimetype))) {\n\n            id = mime->id;\n\n            break;\n\n        }\n\n        mime++;\n\n    }\n\n    if (id == AV_CODEC_ID_NONE) {\n\n        av_log(s, AV_LOG_ERROR, \"Unknown attached picture mimetype: %s.\\n\",\n\n               mimetype);\n\n        return 0;\n\n    }\n\n\n\n    if (picsize >= len) {\n\n        av_log(s, AV_LOG_ERROR, \"Invalid attached picture data size: %d >= %d.\\n\",\n\n               picsize, len);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* picture description */\n\n    desc_len = (len - picsize) * 2 + 1;\n\n    desc     = av_malloc(desc_len);\n\n    if (!desc)\n\n        return AVERROR(ENOMEM);\n\n    len -= avio_get_str16le(s->pb, len - picsize, desc, desc_len);\n\n\n\n    ret = av_get_packet(s->pb, &pkt, picsize);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    st  = avformat_new_stream(s, NULL);\n\n    if (!st) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    asf->asf_st[asf->nb_streams] = av_mallocz(sizeof(*asf_st));\n\n    asf_st = asf->asf_st[asf->nb_streams];\n\n    if (!asf_st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->disposition              |= AV_DISPOSITION_ATTACHED_PIC;\n\n    st->codec->codec_type         = asf_st->type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id           = id;\n\n    st->attached_pic              = pkt;\n\n    st->attached_pic.stream_index = asf_st->index = st->index;\n\n    st->attached_pic.flags       |= AV_PKT_FLAG_KEY;\n\n\n\n    asf->nb_streams++;\n\n\n\n    if (*desc) {\n\n        if (av_dict_set(&st->metadata, \"title\", desc, AV_DICT_DONT_STRDUP_VAL) < 0)\n\n            av_log(s, AV_LOG_WARNING, \"av_dict_set failed.\\n\");\n\n    } else\n\n        av_freep(&desc);\n\n\n\n    if (av_dict_set(&st->metadata, \"comment\", ff_id3v2_picture_types[type], 0) < 0)\n\n        av_log(s, AV_LOG_WARNING, \"av_dict_set failed.\\n\");\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_freep(&desc);\n\n    av_free_packet(&pkt);\n\n    return ret;\n\n}\n", "idx": 15206, "_split": "test", "_hash": "cba2288f693f32f1c6f81ebba8523e7c"}
{"project": "FFmpeg", "commit_id": "5e65f5df0e0cd91eed74cce87c5d65b19e176595", "target": 0, "func": "static int eval_lpc_coeffs(const float *in, float *tgt, int n)\n\n{\n\n    int x, y;\n\n    double f0, f1, f2;\n\n\n\n    if (in[n] == 0)\n\n        return 0;\n\n\n\n    if ((f0 = *in) <= 0)\n\n        return 0;\n\n\n\n    in--; // To avoid a -1 subtraction in the inner loop\n\n\n\n    for (x=1; x <= n; x++) {\n\n        f1 = in[x+1];\n\n\n\n        for (y=0; y < x - 1; y++)\n\n            f1 += in[x-y]*tgt[y];\n\n\n\n        tgt[x-1] = f2 = -f1/f0;\n\n        for (y=0; y < x >> 1; y++) {\n\n            float temp = tgt[y] + tgt[x-y-2]*f2;\n\n            tgt[x-y-2] += tgt[y]*f2;\n\n            tgt[y] = temp;\n\n        }\n\n        if ((f0 += f1*f2) < 0)\n\n            return 0;\n\n    }\n\n\n\n    return 1;\n\n}\n", "idx": 15249, "_split": "test", "_hash": "74a755592f40a2952250b4dcf7009b7e"}
{"project": "FFmpeg", "commit_id": "71a1f76d3cc937fc1a47f501fc4866f95b74d0b0", "target": 0, "func": "int swr_init(struct SwrContext *s){\n\n    s->in_buffer_index= 0;\n\n    s->in_buffer_count= 0;\n\n    s->resample_in_constraint= 0;\n\n    free_temp(&s->postin);\n\n    free_temp(&s->midbuf);\n\n    free_temp(&s->preout);\n\n    free_temp(&s->in_buffer);\n\n    free_temp(&s->dither);\n\n    swri_audio_convert_free(&s-> in_convert);\n\n    swri_audio_convert_free(&s->out_convert);\n\n    swri_audio_convert_free(&s->full_convert);\n\n    swri_rematrix_free(s);\n\n\n\n    s->flushed = 0;\n\n\n\n    if(s-> in_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested input sample format %d is invalid\\n\", s->in_sample_fmt);\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if(s->out_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested output sample format %d is invalid\\n\", s->out_sample_fmt);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    //FIXME should we allow/support using FLT on material that doesnt need it ?\n\n    if(av_get_planar_sample_fmt(s->in_sample_fmt) <= AV_SAMPLE_FMT_S16P || s->int_sample_fmt==AV_SAMPLE_FMT_S16P){\n\n        s->int_sample_fmt= AV_SAMPLE_FMT_S16P;\n\n    }else\n\n        s->int_sample_fmt= AV_SAMPLE_FMT_FLTP;\n\n\n\n    if(   s->int_sample_fmt != AV_SAMPLE_FMT_S16P\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_S32P\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_FLTP){\n\n        av_log(s, AV_LOG_ERROR, \"Requested sample format %s is not supported internally, S16/S32/FLT is supported\\n\", av_get_sample_fmt_name(s->int_sample_fmt));\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    set_audiodata_fmt(&s-> in, s-> in_sample_fmt);\n\n    set_audiodata_fmt(&s->out, s->out_sample_fmt);\n\n\n\n    if (s->out_sample_rate!=s->in_sample_rate || (s->flags & SWR_FLAG_RESAMPLE)){\n\n        s->resample = swri_resample_init(s->resample, s->out_sample_rate, s->in_sample_rate, s->filter_size, s->phase_shift, s->linear_interp, s->cutoff, s->int_sample_fmt);\n\n    }else\n\n        swri_resample_free(&s->resample);\n\n    if(    s->int_sample_fmt != AV_SAMPLE_FMT_S16P\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_S32P\n\n        && s->int_sample_fmt != AV_SAMPLE_FMT_FLTP\n\n        && s->resample){\n\n        av_log(s, AV_LOG_ERROR, \"Resampling only supported with internal s16/s32/flt\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n\n\n    if(s->used_ch_count && s-> in_ch_layout && s->used_ch_count != av_get_channel_layout_nb_channels(s-> in_ch_layout)){\n\n        av_log(s, AV_LOG_WARNING, \"Input channel layout has a different number of channels than the number of used channels, ignoring layout\\n\");\n\n        s-> in_ch_layout= 0;\n\n    }\n\n\n\n    if(!s-> in_ch_layout)\n\n        s-> in_ch_layout= av_get_default_channel_layout(s->used_ch_count);\n\n    if(!s->out_ch_layout)\n\n        s->out_ch_layout= av_get_default_channel_layout(s->out.ch_count);\n\n\n\n    s->rematrix= s->out_ch_layout  !=s->in_ch_layout || s->rematrix_volume!=1.0 ||\n\n                 s->rematrix_custom;\n\n\n\n#define RSC 1 //FIXME finetune\n\n    if(!s-> in.ch_count)\n\n        s-> in.ch_count= av_get_channel_layout_nb_channels(s-> in_ch_layout);\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n    if(!s->out.ch_count)\n\n        s->out.ch_count= av_get_channel_layout_nb_channels(s->out_ch_layout);\n\n\n\n    if(!s-> in.ch_count){\n\n        av_assert0(!s->in_ch_layout);\n\n        av_log(s, AV_LOG_ERROR, \"Input channel count and layout are unset\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if ((!s->out_ch_layout || !s->in_ch_layout) && s->used_ch_count != s->out.ch_count && !s->rematrix_custom) {\n\n        av_log(s, AV_LOG_ERROR, \"Rematrix is needed but there is not enough information to do it\\n\");\n\n        return -1;\n\n    }\n\n\n\nav_assert0(s->used_ch_count);\n\nav_assert0(s->out.ch_count);\n\n    s->resample_first= RSC*s->out.ch_count/s->in.ch_count - RSC < s->out_sample_rate/(float)s-> in_sample_rate - 1.0;\n\n\n\n    s->in_buffer= s->in;\n\n\n\n    if(!s->resample && !s->rematrix && !s->channel_map && !s->dither_method){\n\n        s->full_convert = swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                                   s-> in_sample_fmt, s-> in.ch_count, NULL, 0);\n\n        return 0;\n\n    }\n\n\n\n    s->in_convert = swri_audio_convert_alloc(s->int_sample_fmt,\n\n                                             s-> in_sample_fmt, s->used_ch_count, s->channel_map, 0);\n\n    s->out_convert= swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                             s->int_sample_fmt, s->out.ch_count, NULL, 0);\n\n\n\n\n\n    s->postin= s->in;\n\n    s->preout= s->out;\n\n    s->midbuf= s->in;\n\n\n\n    if(s->channel_map){\n\n        s->postin.ch_count=\n\n        s->midbuf.ch_count= s->used_ch_count;\n\n        if(s->resample)\n\n            s->in_buffer.ch_count= s->used_ch_count;\n\n    }\n\n    if(!s->resample_first){\n\n        s->midbuf.ch_count= s->out.ch_count;\n\n        if(s->resample)\n\n            s->in_buffer.ch_count = s->out.ch_count;\n\n    }\n\n\n\n    set_audiodata_fmt(&s->postin, s->int_sample_fmt);\n\n    set_audiodata_fmt(&s->midbuf, s->int_sample_fmt);\n\n    set_audiodata_fmt(&s->preout, s->int_sample_fmt);\n\n\n\n    if(s->resample){\n\n        set_audiodata_fmt(&s->in_buffer, s->int_sample_fmt);\n\n    }\n\n\n\n    s->dither = s->preout;\n\n\n\n    if(s->rematrix || s->dither_method)\n\n        return swri_rematrix_init(s);\n\n\n\n    return 0;\n\n}\n", "idx": 15252, "_split": "test", "_hash": "8c2995ba823a008d77142461272861a3"}
{"project": "FFmpeg", "commit_id": "00b3ca3c7a779e3b062d6ef0c5067c60c8f8a357", "target": 1, "func": "static int parse_inputs(const char **buf, AVFilterInOut **curr_inputs,\n\n                        AVFilterInOut **open_outputs, AVClass *log_ctx)\n\n{\n\n    int pad = 0;\n\n\n\n    while (**buf == '[') {\n\n        char *name = parse_link_name(buf, log_ctx);\n\n        AVFilterInOut *match;\n\n\n\n        if (!name)\n\n            return AVERROR(EINVAL);\n\n\n\n        /* First check if the label is not in the open_outputs list */\n\n        match = extract_inout(name, open_outputs);\n\n\n\n        if (match) {\n\n            av_free(name);\n\n        } else {\n\n            /* Not in the list, so add it as an input */\n\n            match = av_mallocz(sizeof(AVFilterInOut));\n\n            match->name    = name;\n\n            match->pad_idx = pad;\n\n        }\n\n\n\n        insert_inout(curr_inputs, match);\n\n\n\n        *buf += strspn(*buf, WHITESPACES);\n\n        pad++;\n\n    }\n\n\n\n    return pad;\n\n}\n", "idx": 15290, "_split": "test", "_hash": "bd97c37c52ba99c0eea3043a9226c185"}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "void vp8_mc_chroma(VP8Context *s, VP8ThreadData *td, uint8_t *dst1, uint8_t *dst2,\n\n                   ThreadFrame *ref, const VP56mv *mv, int x_off, int y_off,\n\n                   int block_w, int block_h, int width, int height, int linesize,\n\n                   vp8_mc_func mc_func[3][3])\n\n{\n\n    uint8_t *src1 = ref->f->data[1], *src2 = ref->f->data[2];\n\n\n\n    if (AV_RN32A(mv)) {\n\n        int mx = mv->x&7, mx_idx = subpel_idx[0][mx];\n\n        int my = mv->y&7, my_idx = subpel_idx[0][my];\n\n\n\n        x_off += mv->x >> 3;\n\n        y_off += mv->y >> 3;\n\n\n\n        // edge emulation\n\n        src1 += y_off * linesize + x_off;\n\n        src2 += y_off * linesize + x_off;\n\n        ff_thread_await_progress(ref, (3 + y_off + block_h + subpel_idx[2][my]) >> 3, 0);\n\n        if (x_off < mx_idx || x_off >= width  - block_w - subpel_idx[2][mx] ||\n\n            y_off < my_idx || y_off >= height - block_h - subpel_idx[2][my]) {\n\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer, src1 - my_idx * linesize - mx_idx, linesize,\n\n                                     block_w + subpel_idx[1][mx], block_h + subpel_idx[1][my],\n\n                                     x_off - mx_idx, y_off - my_idx, width, height);\n\n            src1 = td->edge_emu_buffer + mx_idx + linesize * my_idx;\n\n            mc_func[my_idx][mx_idx](dst1, linesize, src1, linesize, block_h, mx, my);\n\n\n\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer, src2 - my_idx * linesize - mx_idx, linesize,\n\n                                     block_w + subpel_idx[1][mx], block_h + subpel_idx[1][my],\n\n                                     x_off - mx_idx, y_off - my_idx, width, height);\n\n            src2 = td->edge_emu_buffer + mx_idx + linesize * my_idx;\n\n            mc_func[my_idx][mx_idx](dst2, linesize, src2, linesize, block_h, mx, my);\n\n        } else {\n\n            mc_func[my_idx][mx_idx](dst1, linesize, src1, linesize, block_h, mx, my);\n\n            mc_func[my_idx][mx_idx](dst2, linesize, src2, linesize, block_h, mx, my);\n\n        }\n\n    } else {\n\n        ff_thread_await_progress(ref, (3 + y_off + block_h) >> 3, 0);\n\n        mc_func[0][0](dst1, linesize, src1 + y_off * linesize + x_off, linesize, block_h, 0, 0);\n\n        mc_func[0][0](dst2, linesize, src2 + y_off * linesize + x_off, linesize, block_h, 0, 0);\n\n    }\n\n}\n", "idx": 15301, "_split": "test", "_hash": "a2c68295411028b579b5879694ad1c67"}
{"project": "FFmpeg", "commit_id": "7e7e59409294af9caa63808e56c5cc824c98b4fc", "target": 0, "func": "static void rgb24_to_yuv444p(AVPicture *dst, AVPicture *src,\n\n                             int width, int height)\n\n{\n\n    int src_wrap, x, y;\n\n    int r, g, b;\n\n    uint8_t *lum, *cb, *cr;\n\n    const uint8_t *p;\n\n\n\n    lum = dst->data[0];\n\n    cb = dst->data[1];\n\n    cr = dst->data[2];\n\n\n\n    src_wrap = src->linesize[0] - width * BPP;\n\n    p = src->data[0];\n\n    for(y=0;y<height;y++) {\n\n        for(x=0;x<width;x++) {\n\n            RGB_IN(r, g, b, p);\n\n            lum[0] = RGB_TO_Y_CCIR(r, g, b);\n\n            cb[0] = RGB_TO_U_CCIR(r, g, b, 0);\n\n            cr[0] = RGB_TO_V_CCIR(r, g, b, 0);\n\n            cb++;\n\n            cr++;\n\n            lum++;\n\n        }\n\n        p += src_wrap;\n\n        lum += dst->linesize[0] - width;\n\n        cb += dst->linesize[1] - width;\n\n        cr += dst->linesize[2] - width;\n\n    }\n\n}\n", "idx": 15321, "_split": "test", "_hash": "2f81fdc6763e6ea02e001cc95d9127e6"}
{"project": "FFmpeg", "commit_id": "ddbcc48b646737c8bff7f8e28e0a69dca65509cf", "target": 0, "func": "static int ftp_current_dir(FTPContext *s)\n\n{\n\n    char *res = NULL, *start = NULL, *end = NULL;\n\n    int i;\n\n    const char *command = \"PWD\\r\\n\";\n\n    const int pwd_codes[] = {257, 0};\n\n\n\n    if (!ftp_send_command(s, command, pwd_codes, &res))\n\n        goto fail;\n\n\n\n    for (i = 0; res[i]; ++i) {\n\n        if (res[i] == '\"') {\n\n            if (!start) {\n\n                start = res + i + 1;\n\n                continue;\n\n            }\n\n            end = res + i;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (!end)\n\n        goto fail;\n\n\n\n    if (end > res && end[-1] == '/') {\n\n        end[-1] = '\\0';\n\n    } else\n\n        *end = '\\0';\n\n    av_strlcpy(s->path, start, sizeof(s->path));\n\n\n\n    av_free(res);\n\n    return 0;\n\n\n\n  fail:\n\n    av_free(res);\n\n    return AVERROR(EIO);\n\n}\n", "idx": 15401, "_split": "test", "_hash": "c4e5c699923163dcad4503c62e253cf9"}
{"project": "FFmpeg", "commit_id": "fe448cd28d674c3eff3072552eae366d0b659ce9", "target": 0, "func": "static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,\n\n                                AVFrame *picture)\n\n{\n\n    int compno, reslevelno, bandno;\n\n    int x, y;\n\n\n\n    uint8_t *line;\n\n    Jpeg2000T1Context t1;\n\n\n\n    /* Loop on tile components */\n\n    for (compno = 0; compno < s->ncomponents; compno++) {\n\n        Jpeg2000Component *comp     = tile->comp + compno;\n\n        Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n\n\n        /* Loop on resolution levels */\n\n        for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) {\n\n            Jpeg2000ResLevel *rlevel = comp->reslevel + reslevelno;\n\n            /* Loop on bands */\n\n            for (bandno = 0; bandno < rlevel->nbands; bandno++) {\n\n                int nb_precincts, precno;\n\n                Jpeg2000Band *band = rlevel->band + bandno;\n\n                int cblkno = 0, bandpos;\n\n\n\n                bandpos = bandno + (reslevelno > 0);\n\n\n\n                if (band->coord[0][0] == band->coord[0][1] ||\n\n                    band->coord[1][0] == band->coord[1][1])\n\n                    continue;\n\n\n\n                nb_precincts = rlevel->num_precincts_x * rlevel->num_precincts_y;\n\n                /* Loop on precincts */\n\n                for (precno = 0; precno < nb_precincts; precno++) {\n\n                    Jpeg2000Prec *prec = band->prec + precno;\n\n\n\n                    /* Loop on codeblocks */\n\n                    for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) {\n\n                        int x, y;\n\n                        Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n\n                        decode_cblk(s, codsty, &t1, cblk,\n\n                                    cblk->coord[0][1] - cblk->coord[0][0],\n\n                                    cblk->coord[1][1] - cblk->coord[1][0],\n\n                                    bandpos);\n\n\n\n                        x = cblk->coord[0][0];\n\n                        y = cblk->coord[1][0];\n\n\n\n                        if (codsty->transform == FF_DWT97)\n\n                            dequantization_float(x, y, cblk, comp, &t1, band);\n\n                        else\n\n                            dequantization_int(x, y, cblk, comp, &t1, band);\n\n                   } /* end cblk */\n\n                } /*end prec */\n\n            } /* end band */\n\n        } /* end reslevel */\n\n\n\n        /* inverse DWT */\n\n        ff_dwt_decode(&comp->dwt, codsty->transform == FF_DWT97 ? (void*)comp->f_data : (void*)comp->i_data);\n\n    } /*end comp */\n\n\n\n    /* inverse MCT transformation */\n\n    if (tile->codsty[0].mct)\n\n        mct_decode(s, tile);\n\n\n\n    if (s->cdef[0] < 0) {\n\n        for (x = 0; x < s->ncomponents; x++)\n\n            s->cdef[x] = x + 1;\n\n        if ((s->ncomponents & 1) == 0)\n\n            s->cdef[s->ncomponents-1] = 0;\n\n    }\n\n\n\n    if (s->precision <= 8) {\n\n        for (compno = 0; compno < s->ncomponents; compno++) {\n\n            Jpeg2000Component *comp = tile->comp + compno;\n\n            Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n            float *datap = comp->f_data;\n\n            int32_t *i_datap = comp->i_data;\n\n            int cbps = s->cbps[compno];\n\n            int w = tile->comp[compno].coord[0][1] - s->image_offset_x;\n\n            int planar = !!picture->data[2];\n\n            int pixelsize = planar ? 1 : s->ncomponents;\n\n            int plane = 0;\n\n\n\n            if (planar)\n\n                plane = s->cdef[compno] ? s->cdef[compno]-1 : (s->ncomponents-1);\n\n\n\n\n\n            y    = tile->comp[compno].coord[1][0] - s->image_offset_y;\n\n            line = picture->data[plane] + y * picture->linesize[plane];\n\n            for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) {\n\n                uint8_t *dst;\n\n\n\n                x   = tile->comp[compno].coord[0][0] - s->image_offset_x;\n\n                dst = line + x * pixelsize + compno*!planar;\n\n\n\n                if (codsty->transform == FF_DWT97) {\n\n                    for (; x < w; x += s->cdx[compno]) {\n\n                        int val = lrintf(*datap) + (1 << (cbps - 1));\n\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n\n                        *dst = val << (8 - cbps);\n\n                        datap++;\n\n                        dst += pixelsize;\n\n                    }\n\n                } else {\n\n                    for (; x < w; x += s->cdx[compno]) {\n\n                        int val = *i_datap + (1 << (cbps - 1));\n\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n\n                        *dst = val << (8 - cbps);\n\n                        i_datap++;\n\n                        dst += pixelsize;\n\n                    }\n\n                }\n\n                line += picture->linesize[plane];\n\n            }\n\n        }\n\n    } else {\n\n        for (compno = 0; compno < s->ncomponents; compno++) {\n\n            Jpeg2000Component *comp = tile->comp + compno;\n\n            Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n            float *datap = comp->f_data;\n\n            int32_t *i_datap = comp->i_data;\n\n            uint16_t *linel;\n\n            int cbps = s->cbps[compno];\n\n            int w = tile->comp[compno].coord[0][1] - s->image_offset_x;\n\n            int planar = !!picture->data[2];\n\n            int pixelsize = planar ? 1 : s->ncomponents;\n\n            int plane = 0;\n\n\n\n            if (planar)\n\n                plane = s->cdef[compno] ? s->cdef[compno]-1 : (s->ncomponents-1);\n\n\n\n            y     = tile->comp[compno].coord[1][0] - s->image_offset_y;\n\n            linel = (uint16_t *)picture->data[plane] + y * (picture->linesize[plane] >> 1);\n\n            for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) {\n\n                uint16_t *dst;\n\n\n\n                x   = tile->comp[compno].coord[0][0] - s->image_offset_x;\n\n                dst = linel + (x * pixelsize + compno*!planar);\n\n                if (codsty->transform == FF_DWT97) {\n\n                    for (; x < w; x += s-> cdx[compno]) {\n\n                        int  val = lrintf(*datap) + (1 << (cbps - 1));\n\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n\n                        /* align 12 bit values in little-endian mode */\n\n                        *dst = val << (16 - cbps);\n\n                        datap++;\n\n                        dst += pixelsize;\n\n                    }\n\n                } else {\n\n                    for (; x < w; x += s-> cdx[compno]) {\n\n                        int val = *i_datap + (1 << (cbps - 1));\n\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n\n                        /* align 12 bit values in little-endian mode */\n\n                        *dst = val << (16 - cbps);\n\n                        i_datap++;\n\n                        dst += pixelsize;\n\n                    }\n\n                }\n\n                linel += picture->linesize[plane] >> 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 15420, "_split": "test", "_hash": "da3185615ae5608b2068e150176b3037"}
{"project": "FFmpeg", "commit_id": "d208d1eba3799c58fd6d3602d31de3e686f14aec", "target": 1, "func": "void ff_hevc_luma_mv_merge_mode(HEVCContext *s, int x0, int y0, int nPbW,\n\n                                int nPbH, int log2_cb_size, int part_idx,\n\n                                int merge_idx, MvField *mv)\n\n{\n\n    int singleMCLFlag = 0;\n\n    int nCS = 1 << log2_cb_size;\n\n    LOCAL_ALIGNED(4, MvField, mergecand_list, [MRG_MAX_NUM_CANDS]);\n\n    int nPbW2 = nPbW;\n\n    int nPbH2 = nPbH;\n\n    HEVCLocalContext *lc = &s->HEVClc;\n\n\n\n    memset(mergecand_list, 0, MRG_MAX_NUM_CANDS * sizeof(*mergecand_list));\n\n\n\n    if (s->pps->log2_parallel_merge_level > 2 && nCS == 8) {\n\n        singleMCLFlag = 1;\n\n        x0            = lc->cu.x;\n\n        y0            = lc->cu.y;\n\n        nPbW          = nCS;\n\n        nPbH          = nCS;\n\n        part_idx      = 0;\n\n    }\n\n\n\n    ff_hevc_set_neighbour_available(s, x0, y0, nPbW, nPbH);\n\n    derive_spatial_merge_candidates(s, x0, y0, nPbW, nPbH, log2_cb_size,\n\n                                    singleMCLFlag, part_idx,\n\n                                    merge_idx, mergecand_list);\n\n\n\n    if (mergecand_list[merge_idx].pred_flag[0] == 1 &&\n\n        mergecand_list[merge_idx].pred_flag[1] == 1 &&\n\n        (nPbW2 + nPbH2) == 12) {\n\n        mergecand_list[merge_idx].ref_idx[1]   = -1;\n\n        mergecand_list[merge_idx].pred_flag[1] = 0;\n\n    }\n\n\n\n    *mv = mergecand_list[merge_idx];\n\n}\n", "idx": 15515, "_split": "test", "_hash": "5041001b0ed1118af32e5ba06f399090"}
{"project": "FFmpeg", "commit_id": "f1e173049ecc9de03817385ba8962d14cba779db", "target": 0, "func": "static void encode_clnpass(Jpeg2000T1Context *t1, int width, int height, int bandno, int *nmsedec, int bpno)\n\n{\n\n    int y0, x, y, mask = 1 << (bpno + NMSEDEC_FRACBITS);\n\n    for (y0 = 0; y0 < height; y0 += 4)\n\n        for (x = 0; x < width; x++){\n\n            if (y0 + 3 < height && !(\n\n            (t1->flags[y0+1][x+1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG)) ||\n\n            (t1->flags[y0+2][x+1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG)) ||\n\n            (t1->flags[y0+3][x+1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG)) ||\n\n            (t1->flags[y0+4][x+1] & (JPEG2000_T1_SIG_NB | JPEG2000_T1_VIS | JPEG2000_T1_SIG))))\n\n            {\n\n                // aggregation mode\n\n                int rlen;\n\n                for (rlen = 0; rlen < 4; rlen++)\n\n                    if (t1->data[y0+rlen][x] & mask)\n\n                        break;\n\n                ff_mqc_encode(&t1->mqc, t1->mqc.cx_states + MQC_CX_RL, rlen != 4);\n\n                if (rlen == 4)\n\n                    continue;\n\n                ff_mqc_encode(&t1->mqc, t1->mqc.cx_states + MQC_CX_UNI, rlen >> 1);\n\n                ff_mqc_encode(&t1->mqc, t1->mqc.cx_states + MQC_CX_UNI, rlen & 1);\n\n                for (y = y0 + rlen; y < y0 + 4; y++){\n\n                    if (!(t1->flags[y+1][x+1] & (JPEG2000_T1_SIG | JPEG2000_T1_VIS))){\n\n                        int ctxno = ff_jpeg2000_getsigctxno(t1->flags[y+1][x+1], bandno);\n\n                        if (y > y0 + rlen)\n\n                            ff_mqc_encode(&t1->mqc, t1->mqc.cx_states + ctxno, t1->data[y][x] & mask ? 1:0);\n\n                        if (t1->data[y][x] & mask){ // newly significant\n\n                            int xorbit;\n\n                            int ctxno = ff_jpeg2000_getsgnctxno(t1->flags[y+1][x+1], &xorbit);\n\n                            *nmsedec += getnmsedec_sig(t1->data[y][x], bpno + NMSEDEC_FRACBITS);\n\n                            ff_mqc_encode(&t1->mqc, t1->mqc.cx_states + ctxno, (t1->flags[y+1][x+1] >> 15) ^ xorbit);\n\n                            ff_jpeg2000_set_significance(t1, x, y, t1->flags[y+1][x+1] >> 15);\n\n                        }\n\n                    }\n\n                    t1->flags[y+1][x+1] &= ~JPEG2000_T1_VIS;\n\n                }\n\n            } else{\n\n                for (y = y0; y < y0 + 4 && y < height; y++){\n\n                    if (!(t1->flags[y+1][x+1] & (JPEG2000_T1_SIG | JPEG2000_T1_VIS))){\n\n                        int ctxno = ff_jpeg2000_getsigctxno(t1->flags[y+1][x+1], bandno);\n\n                        ff_mqc_encode(&t1->mqc, t1->mqc.cx_states + ctxno, t1->data[y][x] & mask ? 1:0);\n\n                        if (t1->data[y][x] & mask){ // newly significant\n\n                            int xorbit;\n\n                            int ctxno = ff_jpeg2000_getsgnctxno(t1->flags[y+1][x+1], &xorbit);\n\n                            *nmsedec += getnmsedec_sig(t1->data[y][x], bpno + NMSEDEC_FRACBITS);\n\n                            ff_mqc_encode(&t1->mqc, t1->mqc.cx_states + ctxno, (t1->flags[y+1][x+1] >> 15) ^ xorbit);\n\n                            ff_jpeg2000_set_significance(t1, x, y, t1->flags[y+1][x+1] >> 15);\n\n                        }\n\n                    }\n\n                    t1->flags[y+1][x+1] &= ~JPEG2000_T1_VIS;\n\n                }\n\n            }\n\n        }\n\n}\n", "idx": 15520, "_split": "test", "_hash": "558259b9846fb3def95a36f00b885464"}
{"project": "FFmpeg", "commit_id": "68900bf16bb4dda35cf5f2801ce72c15056f1939", "target": 0, "func": "static int cook_parse(AVCodecParserContext *s1, AVCodecContext *avctx,\n\n                      const uint8_t **poutbuf, int *poutbuf_size,\n\n                      const uint8_t *buf, int buf_size)\n\n{\n\n    CookParseContext *s = s1->priv_data;\n\n\n\n    if (s->duration)\n\n        s1->duration = s->duration;\n\n    else if (avctx->extradata && avctx->extradata_size >= 8 && avctx->channels)\n\n        s->duration = AV_RB16(avctx->extradata + 4) / avctx->channels;\n\n\n\n    /* always return the full packet. this parser isn't doing any splitting or\n\n       combining, only setting packet duration */\n\n    *poutbuf      = buf;\n\n    *poutbuf_size = buf_size;\n\n    return buf_size;\n\n}\n", "idx": 15552, "_split": "test", "_hash": "5aab696f4881b46382a7c14055e89417"}
{"project": "FFmpeg", "commit_id": "2f4233614a7fbe176b81de0ef14bf38bad8e6693", "target": 0, "func": "static void add_codec(FFServerStream *stream, AVCodecContext *av,\n\n                      FFServerConfig *config)\n\n{\n\n    AVStream *st;\n\n    AVDictionary **opts, *recommended = NULL;\n\n    char *enc_config;\n\n\n\n    if(stream->nb_streams >= FF_ARRAY_ELEMS(stream->streams))\n\n        return;\n\n\n\n    opts = av->codec_type == AVMEDIA_TYPE_AUDIO ?\n\n           &config->audio_opts : &config->video_opts;\n\n    av_dict_copy(&recommended, *opts, 0);\n\n    av_opt_set_dict2(av->priv_data, opts, AV_OPT_SEARCH_CHILDREN);\n\n    av_opt_set_dict2(av, opts, AV_OPT_SEARCH_CHILDREN);\n\n    if (av_dict_count(*opts))\n\n        av_log(NULL, AV_LOG_WARNING,\n\n               \"Something is wrong, %d options are not set!\\n\", av_dict_count(*opts));\n\n\n\n    if (config->stream_use_defaults) {\n\n    //TODO: reident\n\n    /* compute default parameters */\n\n    switch(av->codec_type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        if (av->bit_rate == 0) {\n\n            av->bit_rate = 64000;\n\n            av_dict_set_int(&recommended, \"ab\", av->bit_rate, 0);\n\n        }\n\n        if (av->sample_rate == 0) {\n\n            av->sample_rate = 22050;\n\n            av_dict_set_int(&recommended, \"ar\", av->sample_rate, 0);\n\n        }\n\n        if (av->channels == 0) {\n\n            av->channels = 1;\n\n            av_dict_set_int(&recommended, \"ac\", av->channels, 0);\n\n        }\n\n        break;\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        if (av->bit_rate == 0) {\n\n            av->bit_rate = 64000;\n\n            av_dict_set_int(&recommended, \"b\", av->bit_rate, 0);\n\n        }\n\n        if (av->time_base.num == 0){\n\n            av->time_base.den = 5;\n\n            av->time_base.num = 1;\n\n            av_dict_set(&recommended, \"time_base\", \"1/5\", 0);\n\n        }\n\n        if (av->width == 0 || av->height == 0) {\n\n            av->width = 160;\n\n            av->height = 128;\n\n            av_dict_set(&recommended, \"video_size\", \"160x128\", 0);\n\n        }\n\n        /* Bitrate tolerance is less for streaming */\n\n        if (av->bit_rate_tolerance == 0) {\n\n            av->bit_rate_tolerance = FFMAX(av->bit_rate / 4,\n\n                      (int64_t)av->bit_rate*av->time_base.num/av->time_base.den);\n\n            av_dict_set_int(&recommended, \"bt\", av->bit_rate_tolerance, 0);\n\n        }\n\n\n\n        if (!av->rc_eq) {\n\n            av->rc_eq = av_strdup(\"tex^qComp\");\n\n            av_dict_set(&recommended, \"rc_eq\", \"tex^qComp\", 0);\n\n        }\n\n        if (!av->rc_max_rate) {\n\n            av->rc_max_rate = av->bit_rate * 2;\n\n            av_dict_set_int(&recommended, \"maxrate\", av->rc_max_rate, 0);\n\n        }\n\n\n\n        if (av->rc_max_rate && !av->rc_buffer_size) {\n\n            av->rc_buffer_size = av->rc_max_rate;\n\n            av_dict_set_int(&recommended, \"bufsize\", av->rc_buffer_size, 0);\n\n        }\n\n        break;\n\n    default:\n\n        abort();\n\n    }\n\n    } else {\n\n        switch(av->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            if (av->bit_rate == 0)\n\n                report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n\n                                    &config->errors, \"audio bit rate is not set\\n\");\n\n            if (av->sample_rate == 0)\n\n                report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n\n                                    &config->errors, \"audio sample rate is not set\\n\");\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if (av->width == 0 || av->height == 0)\n\n                report_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n\n                                    &config->errors, \"video size is not set\\n\");\n\n            break;\n\n        default:\n\n            av_assert0(0);\n\n        }\n\n    }\n\n\n\n    st = av_mallocz(sizeof(AVStream));\n\n    if (!st)\n\n        return;\n\n    av_dict_get_string(recommended, &enc_config, '=', ',');\n\n    av_dict_free(&recommended);\n\n    av_stream_set_recommended_encoder_configuration(st, enc_config);\n\n    st->codec = av;\n\n    stream->streams[stream->nb_streams++] = st;\n\n}\n", "idx": 15555, "_split": "test", "_hash": "5a0af2737d20bac3a390fea547079b4c"}
{"project": "FFmpeg", "commit_id": "ae4c9ddebc32eaacbd62681d776881e59ca6e6f7", "target": 1, "func": "void compute_images_mse_16bit(PSNRContext *s,\n\n                        const uint8_t *main_data[4], const int main_linesizes[4],\n\n                        const uint8_t *ref_data[4], const int ref_linesizes[4],\n\n                        int w, int h, double mse[4])\n\n{\n\n    int i, c, j;\n\n\n\n    for (c = 0; c < s->nb_components; c++) {\n\n        const int outw = s->planewidth[c];\n\n        const int outh = s->planeheight[c];\n\n        const uint16_t *main_line = (uint16_t *)main_data[c];\n\n        const uint16_t *ref_line = (uint16_t *)ref_data[c];\n\n        const int ref_linesize = ref_linesizes[c] / 2;\n\n        const int main_linesize = main_linesizes[c] / 2;\n\n        uint64_t m = 0;\n\n\n\n        for (i = 0; i < outh; i++) {\n\n            for (j = 0; j < outw; j++)\n\n                m += pow2(main_line[j] - ref_line[j]);\n\n            ref_line += ref_linesize;\n\n            main_line += main_linesize;\n\n        }\n\n        mse[c] = m / (double)(outw * outh);\n\n    }\n\n}\n", "idx": 15589, "_split": "test", "_hash": "13f2fee4518287929dfce549d71f1c1f"}
{"project": "FFmpeg", "commit_id": "17dc7c7a60798d3e1f78bad97423fb49c8dc1c1d", "target": 0, "func": "void ff_h264_pred_init_x86(H264PredContext *h, int codec_id)\n\n{\n\n    mm_flags = mm_support();\n\n\n\n#if HAVE_YASM\n\n    if (mm_flags & FF_MM_MMX) {\n\n        h->pred16x16[VERT_PRED8x8] = ff_pred16x16_vertical_mmx;\n\n        h->pred16x16[HOR_PRED8x8 ] = ff_pred16x16_horizontal_mmx;\n\n        h->pred8x8  [VERT_PRED8x8] = ff_pred8x8_vertical_mmx;\n\n        h->pred8x8  [HOR_PRED8x8 ] = ff_pred8x8_horizontal_mmx;\n\n        if (codec_id == CODEC_ID_VP8) {\n\n            h->pred16x16[PLANE_PRED8x8] = ff_pred16x16_tm_vp8_mmx;\n\n            h->pred8x8  [PLANE_PRED8x8] = ff_pred8x8_tm_vp8_mmx;\n\n            h->pred4x4  [TM_VP8_PRED  ] = ff_pred4x4_tm_vp8_mmx;\n\n        }\n\n    }\n\n\n\n    if (mm_flags & FF_MM_MMX2) {\n\n        h->pred16x16[HOR_PRED8x8 ] = ff_pred16x16_horizontal_mmxext;\n\n        h->pred16x16[DC_PRED8x8  ] = ff_pred16x16_dc_mmxext;\n\n        h->pred8x8  [HOR_PRED8x8 ] = ff_pred8x8_horizontal_mmxext;\n\n        h->pred4x4  [DC_PRED     ] = ff_pred4x4_dc_mmxext;\n\n        if (codec_id == CODEC_ID_VP8) {\n\n            h->pred16x16[PLANE_PRED8x8] = ff_pred16x16_tm_vp8_mmxext;\n\n            h->pred8x8  [DC_PRED8x8   ] = ff_pred8x8_dc_rv40_mmxext;\n\n            h->pred8x8  [PLANE_PRED8x8] = ff_pred8x8_tm_vp8_mmxext;\n\n            h->pred4x4  [TM_VP8_PRED  ] = ff_pred4x4_tm_vp8_mmxext;\n\n            h->pred4x4  [VERT_PRED    ] = ff_pred4x4_vertical_vp8_mmxext;\n\n        }\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE) {\n\n        h->pred16x16[VERT_PRED8x8] = ff_pred16x16_vertical_sse;\n\n        h->pred16x16[DC_PRED8x8  ] = ff_pred16x16_dc_sse;\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSE2) {\n\n        h->pred16x16[DC_PRED8x8  ] = ff_pred16x16_dc_sse2;\n\n        if (codec_id == CODEC_ID_VP8) {\n\n            h->pred16x16[PLANE_PRED8x8] = ff_pred16x16_tm_vp8_sse2;\n\n            h->pred8x8  [PLANE_PRED8x8] = ff_pred8x8_tm_vp8_sse2;\n\n        }\n\n    }\n\n\n\n    if (mm_flags & FF_MM_SSSE3) {\n\n        h->pred16x16[HOR_PRED8x8 ] = ff_pred16x16_horizontal_ssse3;\n\n        h->pred16x16[DC_PRED8x8  ] = ff_pred16x16_dc_ssse3;\n\n        h->pred8x8  [HOR_PRED8x8 ] = ff_pred8x8_horizontal_ssse3;\n\n        if (codec_id == CODEC_ID_VP8) {\n\n            h->pred8x8  [PLANE_PRED8x8] = ff_pred8x8_tm_vp8_ssse3;\n\n            h->pred4x4  [TM_VP8_PRED  ] = ff_pred4x4_tm_vp8_ssse3;\n\n        }\n\n    }\n\n#endif\n\n}\n", "idx": 15679, "_split": "test", "_hash": "ec293f3a26688b68b24ea7c2ea251389"}
{"project": "FFmpeg", "commit_id": "51a1c1c6ac98d1d0d0a654f066782707af092fed", "target": 0, "func": "static void decode_delta_l(uint8_t *dst,\n\n                           const uint8_t *buf, const uint8_t *buf_end,\n\n                           int w, int flag, int bpp, int dst_size)\n\n{\n\n    GetByteContext off0, off1, dgb, ogb;\n\n    PutByteContext pb;\n\n    unsigned poff0, poff1;\n\n    int i, k, dstpitch;\n\n    int planepitch_byte = (w + 7) / 8;\n\n    int planepitch = ((w + 15) / 16) * 2;\n\n    int pitch = planepitch * bpp;\n\n\n\n    if (buf_end - buf <= 64)\n\n        return;\n\n\n\n    bytestream2_init(&off0, buf, buf_end - buf);\n\n    bytestream2_init(&off1, buf + 32, buf_end - (buf + 32));\n\n    bytestream2_init_writer(&pb, dst, dst_size);\n\n\n\n    dstpitch = flag ? (((w + 7) / 8) * bpp): 2;\n\n\n\n    for (k = 0; k < bpp; k++) {\n\n        poff0 = bytestream2_get_be32(&off0);\n\n        poff1 = bytestream2_get_be32(&off1);\n\n\n\n        if (!poff0)\n\n            continue;\n\n\n\n        if (2LL * poff0 >= buf_end - buf)\n\n            return;\n\n\n\n        if (2LL * poff1 >= buf_end - buf)\n\n            return;\n\n\n\n        bytestream2_init(&dgb, buf + 2 * poff0, buf_end - (buf + 2 * poff0));\n\n        bytestream2_init(&ogb, buf + 2 * poff1, buf_end - (buf + 2 * poff1));\n\n\n\n        while ((bytestream2_peek_be16(&ogb)) != 0xFFFF) {\n\n            uint32_t offset = bytestream2_get_be16(&ogb);\n\n            int16_t cnt = bytestream2_get_be16(&ogb);\n\n            uint16_t data;\n\n\n\n            offset = ((2 * offset) / planepitch_byte) * pitch + ((2 * offset) % planepitch_byte) + k * planepitch;\n\n            if (cnt < 0) {\n\n                bytestream2_seek_p(&pb, offset, SEEK_SET);\n\n                cnt = -cnt;\n\n                data = bytestream2_get_be16(&dgb);\n\n                for (i = 0; i < cnt; i++) {\n\n                    bytestream2_put_be16(&pb, data);\n\n                    bytestream2_skip_p(&pb, dstpitch - 2);\n\n                }\n\n            } else {\n\n                bytestream2_seek_p(&pb, offset, SEEK_SET);\n\n                for (i = 0; i < cnt; i++) {\n\n                    data = bytestream2_get_be16(&dgb);\n\n                    bytestream2_put_be16(&pb, data);\n\n                    bytestream2_skip_p(&pb, dstpitch - 2);\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 15723, "_split": "test", "_hash": "008a052a5fecc2163aed2663c6398955"}
{"project": "FFmpeg", "commit_id": "659d4ba5af5d72716ee370bb367c741bd15e75b4", "target": 0, "func": "static void h263_h_loop_filter_mmx(uint8_t *src, int stride, int qscale)\n\n{\n\n    if (CONFIG_H263_DECODER || CONFIG_H263_ENCODER) {\n\n        const int strength = ff_h263_loop_filter_strength[qscale];\n\n        DECLARE_ALIGNED(8, uint64_t, temp)[4];\n\n        uint8_t *btemp = (uint8_t*)temp;\n\n\n\n        src -= 2;\n\n\n\n        transpose4x4(btemp,     src,              8, stride);\n\n        transpose4x4(btemp + 4, src + 4 * stride, 8, stride);\n\n        __asm__ volatile (\n\n            H263_LOOP_FILTER // 5 3 4 6\n\n\n\n            : \"+m\"(temp[0]),\n\n              \"+m\"(temp[1]),\n\n              \"+m\"(temp[2]),\n\n              \"+m\"(temp[3])\n\n            : \"g\"(2 * strength), \"m\"(ff_pb_FC)\n\n            );\n\n\n\n        __asm__ volatile (\n\n            \"movq      %%mm5, %%mm1         \\n\\t\"\n\n            \"movq      %%mm4, %%mm0         \\n\\t\"\n\n            \"punpcklbw %%mm3, %%mm5         \\n\\t\"\n\n            \"punpcklbw %%mm6, %%mm4         \\n\\t\"\n\n            \"punpckhbw %%mm3, %%mm1         \\n\\t\"\n\n            \"punpckhbw %%mm6, %%mm0         \\n\\t\"\n\n            \"movq      %%mm5, %%mm3         \\n\\t\"\n\n            \"movq      %%mm1, %%mm6         \\n\\t\"\n\n            \"punpcklwd %%mm4, %%mm5         \\n\\t\"\n\n            \"punpcklwd %%mm0, %%mm1         \\n\\t\"\n\n            \"punpckhwd %%mm4, %%mm3         \\n\\t\"\n\n            \"punpckhwd %%mm0, %%mm6         \\n\\t\"\n\n            \"movd      %%mm5, (%0)          \\n\\t\"\n\n            \"punpckhdq %%mm5, %%mm5         \\n\\t\"\n\n            \"movd      %%mm5, (%0, %2)      \\n\\t\"\n\n            \"movd      %%mm3, (%0, %2, 2)   \\n\\t\"\n\n            \"punpckhdq %%mm3, %%mm3         \\n\\t\"\n\n            \"movd      %%mm3, (%0, %3)      \\n\\t\"\n\n            \"movd      %%mm1, (%1)          \\n\\t\"\n\n            \"punpckhdq %%mm1, %%mm1         \\n\\t\"\n\n            \"movd      %%mm1, (%1, %2)      \\n\\t\"\n\n            \"movd      %%mm6, (%1, %2, 2)   \\n\\t\"\n\n            \"punpckhdq %%mm6, %%mm6         \\n\\t\"\n\n            \"movd      %%mm6, (%1, %3)      \\n\\t\"\n\n            :: \"r\"(src),\n\n               \"r\"(src + 4 * stride),\n\n               \"r\"((x86_reg)stride),\n\n               \"r\"((x86_reg)(3 * stride))\n\n            );\n\n    }\n\n}\n", "idx": 15804, "_split": "test", "_hash": "790c359bd13c0061edf35e33f345ac23"}
{"project": "FFmpeg", "commit_id": "02055b6d40d0cff867a9e41cad48edcaf6e10f2f", "target": 0, "func": "static void create_map(vorbis_context *vc, unsigned floor_number)\n\n{\n\n    vorbis_floor *floors = vc->floors;\n\n    vorbis_floor0 *vf;\n\n    int idx;\n\n    int blockflag, n;\n\n    int32_t *map;\n\n\n\n    for (blockflag = 0; blockflag < 2; ++blockflag) {\n\n        n = vc->blocksize[blockflag] / 2;\n\n        floors[floor_number].data.t0.map[blockflag] =\n\n            av_malloc((n + 1) * sizeof(int32_t)); // n + sentinel\n\n\n\n        map =  floors[floor_number].data.t0.map[blockflag];\n\n        vf  = &floors[floor_number].data.t0;\n\n\n\n        for (idx = 0; idx < n; ++idx) {\n\n            map[idx] = floor(BARK((vf->rate * idx) / (2.0f * n)) *\n\n                             (vf->bark_map_size / BARK(vf->rate / 2.0f)));\n\n            if (vf->bark_map_size-1 < map[idx])\n\n                map[idx] = vf->bark_map_size - 1;\n\n        }\n\n        map[n] = -1;\n\n        vf->map_size[blockflag] = n;\n\n    }\n\n\n\n    for (idx = 0; idx <= n; ++idx) {\n\n        av_dlog(NULL, \"floor0 map: map at pos %d is %d\\n\", idx, map[idx]);\n\n    }\n\n}\n", "idx": 15906, "_split": "test", "_hash": "10db8e64b34de7148612b2fee9b298be"}
{"project": "FFmpeg", "commit_id": "88ddcfa37f0067aae7457b44f433982f4c6d72ee", "target": 1, "func": "static av_cold int tdsc_init(AVCodecContext *avctx)\n\n{\n\n    TDSCContext *ctx = avctx->priv_data;\n\n    const AVCodec *codec;\n\n    int ret;\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_BGR24;\n\n\n\n    /* These needs to be set to estimate buffer and frame size */\n\n    if (!(avctx->width && avctx->height)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Video size not set.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* This value should be large enough for a RAW-only frame plus headers */\n\n    ctx->deflatelen = avctx->width * avctx->height * (3 + 1);\n\n    ret = av_reallocp(&ctx->deflatebuffer, ctx->deflatelen);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* Allocate reference and JPEG frame */\n\n    ctx->refframe = av_frame_alloc();\n\n    ctx->jpgframe = av_frame_alloc();\n\n    if (!ctx->refframe || !ctx->jpgframe)\n\n        return AVERROR(ENOMEM);\n\n\n\n    /* Prepare everything needed for JPEG decoding */\n\n    codec = avcodec_find_decoder(AV_CODEC_ID_MJPEG);\n\n    if (!codec)\n\n        return AVERROR_BUG;\n\n    ctx->jpeg_avctx = avcodec_alloc_context3(codec);\n\n    if (!ctx->jpeg_avctx)\n\n        return AVERROR(ENOMEM);\n\n    ctx->jpeg_avctx->flags = avctx->flags;\n\n    ctx->jpeg_avctx->flags2 = avctx->flags2;\n\n    ctx->jpeg_avctx->dct_algo = avctx->dct_algo;\n\n    ctx->jpeg_avctx->idct_algo = avctx->idct_algo;;\n\n    ret = avcodec_open2(ctx->jpeg_avctx, codec, NULL);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    /* Set the output pixel format on the reference frame */\n\n    ctx->refframe->format = avctx->pix_fmt;\n\n\n\n    return 0;\n\n}\n", "idx": 15987, "_split": "test", "_hash": "22c0d5843784ecb51fa199145c6a093b"}
{"project": "FFmpeg", "commit_id": "332f9ac4e31ce5e6d0c42ac9e0229d7d1b2b4d60", "target": 0, "func": "int intel_h263_decode_picture_header(MpegEncContext *s)\n\n{\n\n    int format;\n\n\n\n    /* picture header */\n\n    if (get_bits_long(&s->gb, 22) != 0x20) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Bad picture start code\\n\");\n\n        return -1;\n\n    }\n\n    s->picture_number = get_bits(&s->gb, 8); /* picture timestamp */\n\n\n\n    if (get_bits1(&s->gb) != 1) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Bad marker\\n\");\n\n        return -1;\t/* marker */\n\n    }\n\n    if (get_bits1(&s->gb) != 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Bad H263 id\\n\");\n\n        return -1;\t/* h263 id */\n\n    }\n\n    skip_bits1(&s->gb);\t/* split screen off */\n\n    skip_bits1(&s->gb);\t/* camera  off */\n\n    skip_bits1(&s->gb);\t/* freeze picture release off */\n\n\n\n    format = get_bits(&s->gb, 3);\n\n    if (format != 7) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Intel H263 free format not supported\\n\");\n\n        return -1;\n\n    }\n\n    s->h263_plus = 0;\n\n\n\n    s->pict_type = I_TYPE + get_bits1(&s->gb);\n\n    \n\n    s->unrestricted_mv = get_bits1(&s->gb); \n\n    s->h263_long_vectors = s->unrestricted_mv;\n\n\n\n    if (get_bits1(&s->gb) != 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"SAC not supported\\n\");\n\n        return -1;\t/* SAC: off */\n\n    }\n\n    if (get_bits1(&s->gb) != 0) {\n\n        s->obmc= 1;\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Advanced Prediction Mode not supported\\n\");\n\n//        return -1;\t/* advanced prediction mode: off */\n\n    }\n\n    if (get_bits1(&s->gb) != 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"PB frame mode no supported\\n\");\n\n        return -1;\t/* PB frame mode */\n\n    }\n\n\n\n    /* skip unknown header garbage */\n\n    skip_bits(&s->gb, 41);\n\n\n\n    s->qscale = get_bits(&s->gb, 5);\n\n    skip_bits1(&s->gb);\t/* Continuous Presence Multipoint mode: off */\n\n\n\n    /* PEI */\n\n    while (get_bits1(&s->gb) != 0) {\n\n        skip_bits(&s->gb, 8);\n\n    }\n\n    s->f_code = 1;\n\n\n\n    s->y_dc_scale_table=\n\n    s->c_dc_scale_table= ff_mpeg1_dc_scale_table;\n\n\n\n    return 0;\n\n}\n", "idx": 16020, "_split": "test", "_hash": "79fc886186d40f4d139314f7215738b9"}
{"project": "FFmpeg", "commit_id": "f4aaf987a588fcf5978e636edf2193df35b3e83b", "target": 1, "func": "int ff_thread_video_encode_frame(AVCodecContext *avctx, AVPacket *pkt, const AVFrame *frame, int *got_packet_ptr){\n\n    ThreadContext *c = avctx->internal->frame_thread_encoder;\n\n    Task task;\n\n    int ret;\n\n\n\n    av_assert1(!*got_packet_ptr);\n\n\n\n    if(frame){\n\n        if(!(avctx->flags & CODEC_FLAG_INPUT_PRESERVED)){\n\n            AVFrame *new = avcodec_alloc_frame();\n\n            if(!new)\n\n                return AVERROR(ENOMEM);\n\n            pthread_mutex_lock(&c->buffer_mutex);\n\n            ret = c->parent_avctx->get_buffer(c->parent_avctx, new);\n\n            pthread_mutex_unlock(&c->buffer_mutex);\n\n            if(ret<0)\n\n                return ret;\n\n            new->pts = frame->pts;\n\n            new->quality = frame->quality;\n\n            new->pict_type = frame->pict_type;\n\n            av_image_copy(new->data, new->linesize, (const uint8_t **)frame->data, frame->linesize,\n\n                          avctx->pix_fmt, avctx->width, avctx->height);\n\n            frame = new;\n\n        }\n\n\n\n        task.index = c->task_index;\n\n        task.indata = (void*)frame;\n\n        pthread_mutex_lock(&c->task_fifo_mutex);\n\n        av_fifo_generic_write(c->task_fifo, &task, sizeof(task), NULL);\n\n        pthread_cond_signal(&c->task_fifo_cond);\n\n        pthread_mutex_unlock(&c->task_fifo_mutex);\n\n\n\n        c->task_index = (c->task_index+1) % BUFFER_SIZE;\n\n\n\n        if(!c->finished_tasks[c->finished_task_index].outdata && (c->task_index - c->finished_task_index) % BUFFER_SIZE <= avctx->thread_count)\n\n            return 0;\n\n    }\n\n\n\n    if(c->task_index == c->finished_task_index)\n\n        return 0;\n\n\n\n    pthread_mutex_lock(&c->finished_task_mutex);\n\n    while (!c->finished_tasks[c->finished_task_index].outdata) {\n\n        pthread_cond_wait(&c->finished_task_cond, &c->finished_task_mutex);\n\n    }\n\n    task = c->finished_tasks[c->finished_task_index];\n\n    *pkt = *(AVPacket*)(task.outdata);\n\n    av_freep(&c->finished_tasks[c->finished_task_index].outdata);\n\n    c->finished_task_index = (c->finished_task_index+1) % BUFFER_SIZE;\n\n    pthread_mutex_unlock(&c->finished_task_mutex);\n\n\n\n    *got_packet_ptr = 1;\n\n\n\n    return task.return_code;\n\n}\n", "idx": 16135, "_split": "test", "_hash": "025ffb13f79c98a4b58592dec538cd2a"}
{"project": "FFmpeg", "commit_id": "afa982fdae1b49a8aee00a27da876bba10ba1073", "target": 1, "func": "static void compute_scale_factors(unsigned char scale_code[SBLIMIT],\n\n                                  unsigned char scale_factors[SBLIMIT][3], \n\n                                  int sb_samples[3][12][SBLIMIT],\n\n                                  int sblimit)\n\n{\n\n    int *p, vmax, v, n, i, j, k, code;\n\n    int index, d1, d2;\n\n    unsigned char *sf = &scale_factors[0][0];\n\n    \n\n    for(j=0;j<sblimit;j++) {\n\n        for(i=0;i<3;i++) {\n\n            /* find the max absolute value */\n\n            p = &sb_samples[i][0][j];\n\n            vmax = abs(*p);\n\n            for(k=1;k<12;k++) {\n\n                p += SBLIMIT;\n\n                v = abs(*p);\n\n                if (v > vmax)\n\n                    vmax = v;\n\n            }\n\n            /* compute the scale factor index using log 2 computations */\n\n            if (vmax > 0) {\n\n                n = av_log2(vmax);\n\n                /* n is the position of the MSB of vmax. now \n\n                   use at most 2 compares to find the index */\n\n                index = (21 - n) * 3 - 3;\n\n                if (index >= 0) {\n\n                    while (vmax <= scale_factor_table[index+1])\n\n                        index++;\n\n                } else {\n\n                    index = 0; /* very unlikely case of overflow */\n\n                }\n\n            } else {\n\n                index = 63;\n\n            }\n\n            \n\n#if 0\n\n            printf(\"%2d:%d in=%x %x %d\\n\", \n\n                   j, i, vmax, scale_factor_table[index], index);\n\n#endif\n\n            /* store the scale factor */\n\n            assert(index >=0 && index <= 63);\n\n            sf[i] = index;\n\n        }\n\n\n\n        /* compute the transmission factor : look if the scale factors\n\n           are close enough to each other */\n\n        d1 = scale_diff_table[sf[0] - sf[1] + 64];\n\n        d2 = scale_diff_table[sf[1] - sf[2] + 64];\n\n        \n\n        /* handle the 25 cases */\n\n        switch(d1 * 5 + d2) {\n\n        case 0*5+0:\n\n        case 0*5+4:\n\n        case 3*5+4:\n\n        case 4*5+0:\n\n        case 4*5+4:\n\n            code = 0;\n\n            break;\n\n        case 0*5+1:\n\n        case 0*5+2:\n\n        case 4*5+1:\n\n        case 4*5+2:\n\n            code = 3;\n\n            sf[2] = sf[1];\n\n            break;\n\n        case 0*5+3:\n\n        case 4*5+3:\n\n            code = 3;\n\n            sf[1] = sf[2];\n\n            break;\n\n        case 1*5+0:\n\n        case 1*5+4:\n\n        case 2*5+4:\n\n            code = 1;\n\n            sf[1] = sf[0];\n\n            break;\n\n        case 1*5+1:\n\n        case 1*5+2:\n\n        case 2*5+0:\n\n        case 2*5+1:\n\n        case 2*5+2:\n\n            code = 2;\n\n            sf[1] = sf[2] = sf[0];\n\n            break;\n\n        case 2*5+3:\n\n        case 3*5+3:\n\n            code = 2;\n\n            sf[0] = sf[1] = sf[2];\n\n            break;\n\n        case 3*5+0:\n\n        case 3*5+1:\n\n        case 3*5+2:\n\n            code = 2;\n\n            sf[0] = sf[2] = sf[1];\n\n            break;\n\n        case 1*5+3:\n\n            code = 2;\n\n            if (sf[0] > sf[2])\n\n              sf[0] = sf[2];\n\n            sf[1] = sf[2] = sf[0];\n\n            break;\n\n        default:\n\n            abort();\n\n        }\n\n        \n\n#if 0\n\n        printf(\"%d: %2d %2d %2d %d %d -> %d\\n\", j, \n\n               sf[0], sf[1], sf[2], d1, d2, code);\n\n#endif\n\n        scale_code[j] = code;\n\n        sf += 3;\n\n    }\n\n}\n", "idx": 16177, "_split": "test", "_hash": "2e79aadc083111030cdc24b7b671b248"}
{"project": "FFmpeg", "commit_id": "b926b6282d3b9fc8115660ae013f74f4f8c06d30", "target": 0, "func": "static void opt_new_stream(const char *opt, const char *arg)\n\n{\n\n    AVFormatContext *oc;\n\n    if (nb_output_files <= 0) {\n\n        fprintf(stderr, \"At least one output file must be specified\\n\");\n\n        ffmpeg_exit(1);\n\n    }\n\n    oc = output_files[nb_output_files - 1];\n\n\n\n    if      (!strcmp(opt, \"newvideo\"   )) new_video_stream   (oc);\n\n    else if (!strcmp(opt, \"newaudio\"   )) new_audio_stream   (oc);\n\n    else if (!strcmp(opt, \"newsubtitle\")) new_subtitle_stream(oc);\n\n    else assert(0);\n\n}\n", "idx": 16183, "_split": "test", "_hash": "2a3bc394a29f6904c8b0722464d3afe9"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(yuy2toyv12)(const uint8_t *src, uint8_t *ydst, uint8_t *udst, uint8_t *vdst,\n\n\tunsigned int width, unsigned int height,\n\n\tint lumStride, int chromStride, int srcStride)\n\n{\n\n\tunsigned y;\n\n\tconst unsigned chromWidth= width>>1;\n\n\tfor(y=0; y<height; y+=2)\n\n\t{\n\n#ifdef HAVE_MMX\n\n\t\tasm volatile(\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\n\n\t\t\t\"pcmpeqw %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"psrlw $8, %%mm7\t\t\\n\\t\" // FF,00,FF,00...\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%0, %%\"REG_a\", 4)\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%\"REG_a\", 4), %%mm0\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"movq 8(%0, %%\"REG_a\", 4), %%mm1\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"psrlw $8, %%mm0\t\t\\n\\t\" // U0V0 U0V0(0)\n\n\t\t\t\"psrlw $8, %%mm1\t\t\\n\\t\" // U0V0 U0V0(4)\n\n\t\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\" // Y0Y0 Y0Y0(0)\n\n\t\t\t\"pand %%mm7, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(4)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // YYYY YYYY(0)\n\n\n\n\t\t\tMOVNTQ\" %%mm2, (%1, %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\t\"movq 16(%0, %%\"REG_a\", 4), %%mm1\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"movq 24(%0, %%\"REG_a\", 4), %%mm2\\n\\t\" // YUYV YUYV(12)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"movq %%mm2, %%mm4\t\t\\n\\t\" // YUYV YUYV(12)\n\n\t\t\t\"psrlw $8, %%mm1\t\t\\n\\t\" // U0V0 U0V0(8)\n\n\t\t\t\"psrlw $8, %%mm2\t\t\\n\\t\" // U0V0 U0V0(12)\n\n\t\t\t\"pand %%mm7, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(8)\n\n\t\t\t\"pand %%mm7, %%mm4\t\t\\n\\t\" // Y0Y0 Y0Y0(12)\n\n\t\t\t\"packuswb %%mm2, %%mm1\t\t\\n\\t\" // UVUV UVUV(8)\n\n\t\t\t\"packuswb %%mm4, %%mm3\t\t\\n\\t\" // YYYY YYYY(8)\n\n\n\n\t\t\tMOVNTQ\" %%mm3, 8(%1, %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\t\"movq %%mm0, %%mm2\t\t\\n\\t\" // UVUV UVUV(0)\n\n\t\t\t\"movq %%mm1, %%mm3\t\t\\n\\t\" // UVUV UVUV(8)\n\n\t\t\t\"psrlw $8, %%mm0\t\t\\n\\t\" // V0V0 V0V0(0)\n\n\t\t\t\"psrlw $8, %%mm1\t\t\\n\\t\" // V0V0 V0V0(8)\n\n\t\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\" // U0U0 U0U0(0)\n\n\t\t\t\"pand %%mm7, %%mm3\t\t\\n\\t\" // U0U0 U0U0(8)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // VVVV VVVV(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // UUUU UUUU(0)\n\n\n\n\t\t\tMOVNTQ\" %%mm0, (%3, %%\"REG_a\")\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm2, (%2, %%\"REG_a\")\t\\n\\t\"\n\n\n\n\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"cmp %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\t\t\t::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" ((long)chromWidth)\n\n\t\t\t: \"memory\", \"%\"REG_a\n\n\t\t);\n\n\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\n\n\t\tasm volatile(\n\n\t\t\t\"xor %%\"REG_a\", %%\"REG_a\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\tPREFETCH\" 64(%0, %%\"REG_a\", 4)\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%\"REG_a\", 4), %%mm0\t\\n\\t\" // YUYV YUYV(0)\n\n\t\t\t\"movq 8(%0, %%\"REG_a\", 4), %%mm1\\n\\t\" // YUYV YUYV(4)\n\n\t\t\t\"movq 16(%0, %%\"REG_a\", 4), %%mm2\\n\\t\" // YUYV YUYV(8)\n\n\t\t\t\"movq 24(%0, %%\"REG_a\", 4), %%mm3\\n\\t\" // YUYV YUYV(12)\n\n\t\t\t\"pand %%mm7, %%mm0\t\t\\n\\t\" // Y0Y0 Y0Y0(0)\n\n\t\t\t\"pand %%mm7, %%mm1\t\t\\n\\t\" // Y0Y0 Y0Y0(4)\n\n\t\t\t\"pand %%mm7, %%mm2\t\t\\n\\t\" // Y0Y0 Y0Y0(8)\n\n\t\t\t\"pand %%mm7, %%mm3\t\t\\n\\t\" // Y0Y0 Y0Y0(12)\n\n\t\t\t\"packuswb %%mm1, %%mm0\t\t\\n\\t\" // YYYY YYYY(0)\n\n\t\t\t\"packuswb %%mm3, %%mm2\t\t\\n\\t\" // YYYY YYYY(8)\n\n\n\n\t\t\tMOVNTQ\" %%mm0, (%1, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm2, 8(%1, %%\"REG_a\", 2)\\n\\t\"\n\n\n\n\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"cmp %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" jb 1b\t\t\t\t\\n\\t\"\n\n\n\n\t\t\t::\"r\"(src), \"r\"(ydst), \"r\"(udst), \"r\"(vdst), \"g\" ((long)chromWidth)\n\n\t\t\t: \"memory\", \"%\"REG_a\n\n\t\t);\n\n#else\n\n\t\tunsigned i;\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tydst[2*i+0] \t= src[4*i+0];\n\n\t\t\tudst[i] \t= src[4*i+1];\n\n\t\t\tydst[2*i+1] \t= src[4*i+2];\n\n\t\t\tvdst[i] \t= src[4*i+3];\n\n\t\t}\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\n\n\t\tfor(i=0; i<chromWidth; i++)\n\n\t\t{\n\n\t\t\tydst[2*i+0] \t= src[4*i+0];\n\n\t\t\tydst[2*i+1] \t= src[4*i+2];\n\n\t\t}\n\n#endif\n\n\t\tudst += chromStride;\n\n\t\tvdst += chromStride;\n\n\t\tydst += lumStride;\n\n\t\tsrc  += srcStride;\n\n\t}\n\n#ifdef HAVE_MMX\n\nasm volatile(   EMMS\" \\n\\t\"\n\n        \tSFENCE\" \\n\\t\"\n\n        \t:::\"memory\");\n\n#endif\n\n}\n", "idx": 16190, "_split": "test", "_hash": "04e3af8fcf72b9a32e43cf74afd51880"}
{"project": "FFmpeg", "commit_id": "80b1e1c03d26ade05b0f53d0731aa7398d4ef6f9", "target": 1, "func": "static int huf_uncompress(GetByteContext *gb,\n\n                          uint16_t *dst, int dst_size)\n\n{\n\n    int32_t src_size, im, iM;\n\n    uint32_t nBits;\n\n    uint64_t *freq;\n\n    HufDec *hdec;\n\n    int ret, i;\n\n\n\n    src_size = bytestream2_get_le32(gb);\n\n    im = bytestream2_get_le32(gb);\n\n    iM = bytestream2_get_le32(gb);\n\n    bytestream2_skip(gb, 4);\n\n    nBits = bytestream2_get_le32(gb);\n\n    if (im < 0 || im >= HUF_ENCSIZE ||\n\n        iM < 0 || iM >= HUF_ENCSIZE ||\n\n        src_size < 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    bytestream2_skip(gb, 4);\n\n\n\n    freq = av_calloc(HUF_ENCSIZE, sizeof(*freq));\n\n    hdec = av_calloc(HUF_DECSIZE, sizeof(*hdec));\n\n    if (!freq || !hdec) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n\n\n    if ((ret = huf_unpack_enc_table(gb, im, iM, freq)) < 0)\n\n        goto fail;\n\n\n\n    if (nBits > 8 * bytestream2_get_bytes_left(gb)) {\n\n        ret = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n    if ((ret = huf_build_dec_table(freq, im, iM, hdec)) < 0)\n\n        goto fail;\n\n    ret = huf_decode(freq, hdec, gb, nBits, iM, dst_size, dst);\n\n\n\nfail:\n\n    for (i = 0; i < HUF_DECSIZE; i++) {\n\n        if (hdec[i].p)\n\n            av_freep(&hdec[i].p);\n\n    }\n\n\n\n    av_free(freq);\n\n    av_free(hdec);\n\n\n\n    return ret;\n\n}\n", "idx": 16197, "_split": "test", "_hash": "aa7a804608894cea5ef4ede3a15e85ac"}
{"project": "FFmpeg", "commit_id": "b25e84b7399bd91605596b67d761d3464dbe8a6e", "target": 1, "func": "static int hevc_frame_start(HEVCContext *s)\n\n{\n\n    HEVCLocalContext *lc = &s->HEVClc;\n\n    int ret;\n\n\n\n    memset(s->horizontal_bs, 0, 2 * s->bs_width * (s->bs_height + 1));\n\n    memset(s->vertical_bs,   0, 2 * s->bs_width * (s->bs_height + 1));\n\n    memset(s->cbf_luma,      0, s->sps->min_tb_width * s->sps->min_tb_height);\n\n    memset(s->is_pcm,        0, s->sps->min_pu_width * s->sps->min_pu_height);\n\n\n\n    lc->start_of_tiles_x = 0;\n\n    s->is_decoded        = 0;\n\n\n\n\n    if (s->pps->tiles_enabled_flag)\n\n        lc->end_of_tiles_x = s->pps->column_width[0] << s->sps->log2_ctb_size;\n\n\n\n    ret = ff_hevc_set_new_ref(s, s->sps->sao_enabled ? &s->sao_frame : &s->frame,\n\n                              s->poc);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    ret = ff_hevc_frame_rps(s);\n\n    if (ret < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Error constructing the frame RPS.\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    ret = set_side_data(s);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    av_frame_unref(s->output_frame);\n\n    ret = ff_hevc_output_frame(s, s->output_frame, 0);\n\n    if (ret < 0)\n\n        goto fail;\n\n\n\n    ff_thread_finish_setup(s->avctx);\n\n\n\n    return 0;\n\n\n\nfail:\n\n    if (s->ref)\n\n        ff_thread_report_progress(&s->ref->tf, INT_MAX, 0);\n\n    s->ref = NULL;\n\n    return ret;\n\n}", "idx": 16203, "_split": "test", "_hash": "f75a60eeab62470c1844b84a4a432fc8"}
{"project": "FFmpeg", "commit_id": "63d6a6b91e4997737905bbd2cf5970ad90a31869", "target": 1, "func": "static void fix_coding_method_array (int sb, int channels, sb_int8_array coding_method)\n\n{\n\n    int j,k;\n\n    int ch;\n\n    int run, case_val;\n\n    int switchtable[23] = {0,5,1,5,5,5,5,5,2,5,5,5,5,5,5,5,3,5,5,5,5,5,4};\n\n\n\n    for (ch = 0; ch < channels; ch++) {\n\n        for (j = 0; j < 64; ) {\n\n            if((coding_method[ch][sb][j] - 8) > 22) {\n\n                run = 1;\n\n                case_val = 8;\n\n            } else {\n\n                switch (switchtable[coding_method[ch][sb][j]]) {\n\n                    case 0: run = 10; case_val = 10; break;\n\n                    case 1: run = 1; case_val = 16; break;\n\n                    case 2: run = 5; case_val = 24; break;\n\n                    case 3: run = 3; case_val = 30; break;\n\n                    case 4: run = 1; case_val = 30; break;\n\n                    case 5: run = 1; case_val = 8; break;\n\n                    default: run = 1; case_val = 8; break;\n\n                }\n\n            }\n\n            for (k = 0; k < run; k++)\n\n                if (j + k < 128)\n\n                    if (coding_method[ch][sb + (j + k) / 64][(j + k) % 64] > coding_method[ch][sb][j])\n\n                        if (k > 0) {\n\n                           SAMPLES_NEEDED\n\n                            //not debugged, almost never used\n\n                            memset(&coding_method[ch][sb][j + k], case_val, k * sizeof(int8_t));\n\n                            memset(&coding_method[ch][sb][j + k], case_val, 3 * sizeof(int8_t));\n\n                        }\n\n            j += run;\n\n        }\n\n    }\n\n}\n", "idx": 16205, "_split": "test", "_hash": "a22b16d39e62eafd5aa4938dea65dd74"}
{"project": "FFmpeg", "commit_id": "3e1507a9547ac09b6ff4372123cde09f19218f3d", "target": 0, "func": "void ff_mjpeg_encode_mb(MpegEncContext *s, int16_t block[12][64])\n\n{\n\n    int i;\n\n    if (s->chroma_format == CHROMA_444) {\n\n        encode_block(s, block[0], 0);\n\n        encode_block(s, block[2], 2);\n\n        encode_block(s, block[4], 4);\n\n        encode_block(s, block[8], 8);\n\n        encode_block(s, block[5], 5);\n\n        encode_block(s, block[9], 9);\n\n\n\n        if (16*s->mb_x+8 < s->width) {\n\n            encode_block(s, block[1], 1);\n\n            encode_block(s, block[3], 3);\n\n            encode_block(s, block[6], 6);\n\n            encode_block(s, block[10], 10);\n\n            encode_block(s, block[7], 7);\n\n            encode_block(s, block[11], 11);\n\n        }\n\n    } else {\n\n        for(i=0;i<5;i++) {\n\n            encode_block(s, block[i], i);\n\n        }\n\n        if (s->chroma_format == CHROMA_420) {\n\n            encode_block(s, block[5], 5);\n\n        } else {\n\n            encode_block(s, block[6], 6);\n\n            encode_block(s, block[5], 5);\n\n            encode_block(s, block[7], 7);\n\n        }\n\n    }\n\n}\n", "idx": 16227, "_split": "test", "_hash": "c55ac7516ad5ed5f5a64793983105797"}
{"project": "FFmpeg", "commit_id": "72dbc610be3272ba36603f78a39cc2d2d8fe0cc3", "target": 0, "func": "void ff_avg_h264_qpel16_mc12_msa(uint8_t *dst, const uint8_t *src,\n\n                                 ptrdiff_t stride)\n\n{\n\n    avc_luma_midh_qrt_and_aver_dst_16w_msa(src - (2 * stride) - 2,\n\n                                           stride, dst, stride, 16, 0);\n\n}\n", "idx": 16255, "_split": "test", "_hash": "a44d7876a4d9fffcf101cb5b2f63ed5e"}
{"project": "FFmpeg", "commit_id": "6221e2478c593a0ce1183eed929cb2101dbf5265", "target": 0, "func": "int av_parse_color(uint8_t *rgba_color, const char *color_string, int slen,\n\n                   void *log_ctx)\n\n{\n\n    char *tail, color_string2[128];\n\n    const ColorEntry *entry;\n\n    int len, hex_offset = 0;\n\n\n\n    if (color_string[0] == '#') {\n\n        hex_offset = 1;\n\n    } else if (!strncmp(color_string, \"0x\", 2))\n\n        hex_offset = 2;\n\n\n\n    if (slen < 0)\n\n        slen = strlen(color_string);\n\n    av_strlcpy(color_string2, color_string + hex_offset,\n\n               FFMIN(slen-hex_offset+1, sizeof(color_string2)));\n\n    if ((tail = strchr(color_string2, ALPHA_SEP)))\n\n        *tail++ = 0;\n\n    len = strlen(color_string2);\n\n    rgba_color[3] = 255;\n\n\n\n    if (!av_strcasecmp(color_string2, \"random\") || !av_strcasecmp(color_string2, \"bikeshed\")) {\n\n        int rgba = av_get_random_seed();\n\n        rgba_color[0] = rgba >> 24;\n\n        rgba_color[1] = rgba >> 16;\n\n        rgba_color[2] = rgba >> 8;\n\n        rgba_color[3] = rgba;\n\n    } else if (hex_offset ||\n\n               strspn(color_string2, \"0123456789ABCDEFabcdef\") == len) {\n\n        char *tail;\n\n        unsigned int rgba = strtoul(color_string2, &tail, 16);\n\n\n\n        if (*tail || (len != 6 && len != 8)) {\n\n            av_log(log_ctx, AV_LOG_ERROR, \"Invalid 0xRRGGBB[AA] color string: '%s'\\n\", color_string2);\n\n            return AVERROR(EINVAL);\n\n        }\n\n        if (len == 8) {\n\n            rgba_color[3] = rgba;\n\n            rgba >>= 8;\n\n        }\n\n        rgba_color[0] = rgba >> 16;\n\n        rgba_color[1] = rgba >> 8;\n\n        rgba_color[2] = rgba;\n\n    } else {\n\n        entry = bsearch(color_string2,\n\n                        color_table,\n\n                        FF_ARRAY_ELEMS(color_table),\n\n                        sizeof(ColorEntry),\n\n                        color_table_compare);\n\n        if (!entry) {\n\n            av_log(log_ctx, AV_LOG_ERROR, \"Cannot find color '%s'\\n\", color_string2);\n\n            return AVERROR(EINVAL);\n\n        }\n\n        memcpy(rgba_color, entry->rgb_color, 3);\n\n    }\n\n\n\n    if (tail) {\n\n        unsigned long int alpha;\n\n        const char *alpha_string = tail;\n\n        if (!strncmp(alpha_string, \"0x\", 2)) {\n\n            alpha = strtoul(alpha_string, &tail, 16);\n\n        } else {\n\n            alpha = 255 * strtod(alpha_string, &tail);\n\n        }\n\n\n\n        if (tail == alpha_string || *tail || alpha > 255) {\n\n            av_log(log_ctx, AV_LOG_ERROR, \"Invalid alpha value specifier '%s' in '%s'\\n\",\n\n                   alpha_string, color_string);\n\n            return AVERROR(EINVAL);\n\n        }\n\n        rgba_color[3] = alpha;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 16256, "_split": "test", "_hash": "4b05e37c0ba33faff99a54b49499e4cc"}
{"project": "FFmpeg", "commit_id": "7cf22c79706d23d40d16cee37eb32d5797adcc2c", "target": 0, "func": "yuv2rgba64_full_X_c_template(SwsContext *c, const int16_t *lumFilter,\n\n                       const int32_t **lumSrc, int lumFilterSize,\n\n                       const int16_t *chrFilter, const int32_t **chrUSrc,\n\n                       const int32_t **chrVSrc, int chrFilterSize,\n\n                       const int32_t **alpSrc, uint16_t *dest, int dstW,\n\n                       int y, enum AVPixelFormat target, int hasAlpha, int eightbytes)\n\n{\n\n    int i;\n\n    int A = 0xffff<<14;\n\n\n\n    for (i = 0; i < dstW; i++) {\n\n        int j;\n\n        int Y  = -0x40000000;\n\n        int U  = -128 << 23; // 19\n\n        int V  = -128 << 23;\n\n        int R, G, B;\n\n\n\n        for (j = 0; j < lumFilterSize; j++) {\n\n            Y += lumSrc[j][i]  * (unsigned)lumFilter[j];\n\n        }\n\n        for (j = 0; j < chrFilterSize; j++) {;\n\n            U += chrUSrc[j][i] * (unsigned)chrFilter[j];\n\n            V += chrVSrc[j][i] * (unsigned)chrFilter[j];\n\n        }\n\n\n\n        if (hasAlpha) {\n\n            A = -0x40000000;\n\n            for (j = 0; j < lumFilterSize; j++) {\n\n                A += alpSrc[j][i] * (unsigned)lumFilter[j];\n\n            }\n\n            A >>= 1;\n\n            A += 0x20002000;\n\n        }\n\n\n\n        // 8bit: 12+15=27; 16-bit: 12+19=31\n\n        Y  >>= 14; // 10\n\n        Y += 0x10000;\n\n        U  >>= 14;\n\n        V  >>= 14;\n\n\n\n        // 8bit: 27 -> 17bit, 16bit: 31 - 14 = 17bit\n\n        Y -= c->yuv2rgb_y_offset;\n\n        Y *= c->yuv2rgb_y_coeff;\n\n        Y += 1 << 13; // 21\n\n        // 8bit: 17 + 13bit = 30bit, 16bit: 17 + 13bit = 30bit\n\n\n\n        R = V * c->yuv2rgb_v2r_coeff;\n\n        G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n        B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n        // 8bit: 30 - 22 = 8bit, 16bit: 30bit - 14 = 16bit\n\n        output_pixel(&dest[0], av_clip_uintp2(R_B + Y, 30) >> 14);\n\n        output_pixel(&dest[1], av_clip_uintp2(  G + Y, 30) >> 14);\n\n        output_pixel(&dest[2], av_clip_uintp2(B_R + Y, 30) >> 14);\n\n        if (eightbytes) {\n\n            output_pixel(&dest[3], av_clip_uintp2(A, 30) >> 14);\n\n            dest += 4;\n\n        } else {\n\n            dest += 3;\n\n        }\n\n    }\n\n}\n", "idx": 16335, "_split": "test", "_hash": "45737f4f2335007cb844b067c50acc4d"}
{"project": "FFmpeg", "commit_id": "e1fb3143bb3a6006612fe0e1d1a15c8eb4955802", "target": 1, "func": "static int ftp_abort(URLContext *h)\n\n{\n\n    static const char *command = \"ABOR\\r\\n\";\n\n    int err;\n\n    static const int abor_codes[] = {225, 226, 0};\n\n    FTPContext *s = h->priv_data;\n\n\n\n    /* According to RCF 959:\n\n       \"ABOR command tells the server to abort the previous FTP\n\n       service command and any associated transfer of data.\"\n\n\n\n       There are FTP server implementations that don't response\n\n       to any commands during data transfer in passive mode (including ABOR).\n\n\n\n       This implementation closes data connection by force.\n\n    */\n\n\n\n    if (ftp_send_command(s, command, NULL, NULL) < 0) {\n\n        ftp_close_both_connections(s);\n\n        if ((err = ftp_connect_control_connection(h)) < 0) {\n\n            av_log(h, AV_LOG_ERROR, \"Reconnect failed.\\n\");\n\n            return err;\n\n        }\n\n    } else {\n\n        ftp_close_data_connection(s);\n\n    }\n\n\n\n    if (ftp_status(s, NULL, abor_codes) < 225) {\n\n        /* wu-ftpd also closes control connection after data connection closing */\n\n        ffurl_closep(&s->conn_control);\n\n        if ((err = ftp_connect_control_connection(h)) < 0) {\n\n            av_log(h, AV_LOG_ERROR, \"Reconnect failed.\\n\");\n\n            return err;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 16370, "_split": "test", "_hash": "7dfa903bdcb5bbd9423d6aad528048ab"}
{"project": "FFmpeg", "commit_id": "a4fec9a7eab842ea5eea1b1ee98624356cb31422", "target": 1, "func": "static int rtmp_packet_read_one_chunk(URLContext *h, RTMPPacket *p,\n                                      int chunk_size, RTMPPacket **prev_pkt_ptr,\n                                      int *nb_prev_pkt, uint8_t hdr)\n{\n    uint8_t buf[16];\n    int channel_id, timestamp, size;\n    uint32_t ts_field; // non-extended timestamp or delta field\n    uint32_t extra = 0;\n    enum RTMPPacketType type;\n    int written = 0;\n    int ret, toread;\n    RTMPPacket *prev_pkt;\n    written++;\n    channel_id = hdr & 0x3F;\n    if (channel_id < 2) { //special case for channel number >= 64\n        buf[1] = 0;\n        if (ffurl_read_complete(h, buf, channel_id + 1) != channel_id + 1)\n            return AVERROR(EIO);\n        written += channel_id + 1;\n        channel_id = AV_RL16(buf) + 64;\n    if ((ret = ff_rtmp_check_alloc_array(prev_pkt_ptr, nb_prev_pkt,\n                                         channel_id)) < 0)\n        return ret;\n    prev_pkt = *prev_pkt_ptr;\n    size  = prev_pkt[channel_id].size;\n    type  = prev_pkt[channel_id].type;\n    extra = prev_pkt[channel_id].extra;\n    hdr >>= 6; // header size indicator\n    if (hdr == RTMP_PS_ONEBYTE) {\n        ts_field = prev_pkt[channel_id].ts_field;\n    } else {\n        if (ffurl_read_complete(h, buf, 3) != 3)\n            return AVERROR(EIO);\n        written += 3;\n        ts_field = AV_RB24(buf);\n        if (hdr != RTMP_PS_FOURBYTES) {\n            if (ffurl_read_complete(h, buf, 3) != 3)\n                return AVERROR(EIO);\n            written += 3;\n            size = AV_RB24(buf);\n            if (ffurl_read_complete(h, buf, 1) != 1)\n                return AVERROR(EIO);\n            written++;\n            type = buf[0];\n            if (hdr == RTMP_PS_TWELVEBYTES) {\n                if (ffurl_read_complete(h, buf, 4) != 4)\n                    return AVERROR(EIO);\n                written += 4;\n                extra = AV_RL32(buf);\n    if (ts_field == 0xFFFFFF) {\n        if (ffurl_read_complete(h, buf, 4) != 4)\n            return AVERROR(EIO);\n        timestamp = AV_RB32(buf);\n    } else {\n        timestamp = ts_field;\n    if (hdr != RTMP_PS_TWELVEBYTES)\n        timestamp += prev_pkt[channel_id].timestamp;\n    if (!prev_pkt[channel_id].read) {\n        if ((ret = ff_rtmp_packet_create(p, channel_id, type, timestamp,\n                                         size)) < 0)\n            return ret;\n        p->read = written;\n        p->offset = 0;\n        prev_pkt[channel_id].ts_field   = ts_field;\n        prev_pkt[channel_id].timestamp  = timestamp;\n    } else {\n        // previous packet in this channel hasn't completed reading\n        RTMPPacket *prev = &prev_pkt[channel_id];\n        p->data          = prev->data;\n        p->size          = prev->size;\n        p->channel_id    = prev->channel_id;\n        p->type          = prev->type;\n        p->ts_field      = prev->ts_field;\n        p->extra         = prev->extra;\n        p->offset        = prev->offset;\n        p->read          = prev->read + written;\n        p->timestamp     = prev->timestamp;\n        prev->data       = NULL;\n    p->extra = extra;\n    // save history\n    prev_pkt[channel_id].channel_id = channel_id;\n    prev_pkt[channel_id].type       = type;\n    prev_pkt[channel_id].size       = size;\n    prev_pkt[channel_id].extra      = extra;\n    size = size - p->offset;\n    toread = FFMIN(size, chunk_size);\n    if (ffurl_read_complete(h, p->data + p->offset, toread) != toread) {\n        ff_rtmp_packet_destroy(p);\n        return AVERROR(EIO);\n    size      -= toread;\n    p->read   += toread;\n    p->offset += toread;\n    if (size > 0) {\n       RTMPPacket *prev = &prev_pkt[channel_id];\n       prev->data = p->data;\n       prev->read = p->read;\n       prev->offset = p->offset;\n       return AVERROR(EAGAIN);\n    prev_pkt[channel_id].read = 0; // read complete; reset if needed\n    return p->read;", "idx": 16385, "_split": "test", "_hash": "ef7f82169bcaf1cd7c16220982db1eba"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int encode_close(AVCodecContext *avctx)\n\n{\n\n    av_frame_free(&avctx->coded_frame);\n\n    return 0;\n\n}\n", "idx": 16412, "_split": "test", "_hash": "9bb6709187e9f5379ba62a5e821e0fb8"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "void ff_xvmc_field_end(MpegEncContext *s)\n\n{\n\n    struct xvmc_pix_fmt *render = (struct xvmc_pix_fmt*)s->current_picture.f.data[2];\n\n    assert(render);\n\n\n\n    if (render->filled_mv_blocks_num > 0)\n\n        ff_mpeg_draw_horiz_band(s, 0, 0);\n\n}\n", "idx": 16437, "_split": "test", "_hash": "671a14d144f36ece5ab14671ae9d6ecb"}
{"project": "FFmpeg", "commit_id": "c96f3750c22ef1576a46140f3101e3585041f41f", "target": 0, "func": "pp_mode *pp_get_mode_by_name_and_quality(const char *name, int quality)\n\n{\n\n    char temp[GET_MODE_BUFFER_SIZE];\n\n    char *p= temp;\n\n    static const char filterDelimiters[] = \",/\";\n\n    static const char optionDelimiters[] = \":\";\n\n    struct PPMode *ppMode;\n\n    char *filterToken;\n\n\n\n    ppMode= av_malloc(sizeof(PPMode));\n\n\n\n    ppMode->lumMode= 0;\n\n    ppMode->chromMode= 0;\n\n    ppMode->maxTmpNoise[0]= 700;\n\n    ppMode->maxTmpNoise[1]= 1500;\n\n    ppMode->maxTmpNoise[2]= 3000;\n\n    ppMode->maxAllowedY= 234;\n\n    ppMode->minAllowedY= 16;\n\n    ppMode->baseDcDiff= 256/8;\n\n    ppMode->flatnessThreshold= 56-16-1;\n\n    ppMode->maxClippedThreshold= 0.01;\n\n    ppMode->error=0;\n\n\n\n    memset(temp, 0, GET_MODE_BUFFER_SIZE);\n\n    av_strlcpy(temp, name, GET_MODE_BUFFER_SIZE - 1);\n\n\n\n    av_log(NULL, AV_LOG_DEBUG, \"pp: %s\\n\", name);\n\n\n\n    for(;;){\n\n        char *filterName;\n\n        int q= 1000000; //PP_QUALITY_MAX;\n\n        int chrom=-1;\n\n        int luma=-1;\n\n        char *option;\n\n        char *options[OPTIONS_ARRAY_SIZE];\n\n        int i;\n\n        int filterNameOk=0;\n\n        int numOfUnknownOptions=0;\n\n        int enable=1; //does the user want us to enabled or disabled the filter\n\n\n\n        filterToken= strtok(p, filterDelimiters);\n\n        if(filterToken == NULL) break;\n\n        p+= strlen(filterToken) + 1; // p points to next filterToken\n\n        filterName= strtok(filterToken, optionDelimiters);\n\n        av_log(NULL, AV_LOG_DEBUG, \"pp: %s::%s\\n\", filterToken, filterName);\n\n\n\n        if(*filterName == '-'){\n\n            enable=0;\n\n            filterName++;\n\n        }\n\n\n\n        for(;;){ //for all options\n\n            option= strtok(NULL, optionDelimiters);\n\n            if(option == NULL) break;\n\n\n\n            av_log(NULL, AV_LOG_DEBUG, \"pp: option: %s\\n\", option);\n\n            if(!strcmp(\"autoq\", option) || !strcmp(\"a\", option)) q= quality;\n\n            else if(!strcmp(\"nochrom\", option) || !strcmp(\"y\", option)) chrom=0;\n\n            else if(!strcmp(\"chrom\", option) || !strcmp(\"c\", option)) chrom=1;\n\n            else if(!strcmp(\"noluma\", option) || !strcmp(\"n\", option)) luma=0;\n\n            else{\n\n                options[numOfUnknownOptions] = option;\n\n                numOfUnknownOptions++;\n\n            }\n\n            if(numOfUnknownOptions >= OPTIONS_ARRAY_SIZE-1) break;\n\n        }\n\n        options[numOfUnknownOptions] = NULL;\n\n\n\n        /* replace stuff from the replace Table */\n\n        for(i=0; replaceTable[2*i]!=NULL; i++){\n\n            if(!strcmp(replaceTable[2*i], filterName)){\n\n                int newlen= strlen(replaceTable[2*i + 1]);\n\n                int plen;\n\n                int spaceLeft;\n\n\n\n                if(p==NULL) p= temp, *p=0;      //last filter\n\n                else p--, *p=',';               //not last filter\n\n\n\n                plen= strlen(p);\n\n                spaceLeft= p - temp + plen;\n\n                if(spaceLeft + newlen  >= GET_MODE_BUFFER_SIZE - 1){\n\n                    ppMode->error++;\n\n                    break;\n\n                }\n\n                memmove(p + newlen, p, plen+1);\n\n                memcpy(p, replaceTable[2*i + 1], newlen);\n\n                filterNameOk=1;\n\n            }\n\n        }\n\n\n\n        for(i=0; filters[i].shortName!=NULL; i++){\n\n            if(   !strcmp(filters[i].longName, filterName)\n\n               || !strcmp(filters[i].shortName, filterName)){\n\n                ppMode->lumMode &= ~filters[i].mask;\n\n                ppMode->chromMode &= ~filters[i].mask;\n\n\n\n                filterNameOk=1;\n\n                if(!enable) break; // user wants to disable it\n\n\n\n                if(q >= filters[i].minLumQuality && luma)\n\n                    ppMode->lumMode|= filters[i].mask;\n\n                if(chrom==1 || (chrom==-1 && filters[i].chromDefault))\n\n                    if(q >= filters[i].minChromQuality)\n\n                            ppMode->chromMode|= filters[i].mask;\n\n\n\n                if(filters[i].mask == LEVEL_FIX){\n\n                    int o;\n\n                    ppMode->minAllowedY= 16;\n\n                    ppMode->maxAllowedY= 234;\n\n                    for(o=0; options[o]!=NULL; o++){\n\n                        if(  !strcmp(options[o],\"fullyrange\")\n\n                           ||!strcmp(options[o],\"f\")){\n\n                            ppMode->minAllowedY= 0;\n\n                            ppMode->maxAllowedY= 255;\n\n                            numOfUnknownOptions--;\n\n                        }\n\n                    }\n\n                }\n\n                else if(filters[i].mask == TEMP_NOISE_FILTER)\n\n                {\n\n                    int o;\n\n                    int numOfNoises=0;\n\n\n\n                    for(o=0; options[o]!=NULL; o++){\n\n                        char *tail;\n\n                        ppMode->maxTmpNoise[numOfNoises]=\n\n                            strtol(options[o], &tail, 0);\n\n                        if(tail!=options[o]){\n\n                            numOfNoises++;\n\n                            numOfUnknownOptions--;\n\n                            if(numOfNoises >= 3) break;\n\n                        }\n\n                    }\n\n                }\n\n                else if(filters[i].mask == V_DEBLOCK   || filters[i].mask == H_DEBLOCK\n\n                     || filters[i].mask == V_A_DEBLOCK || filters[i].mask == H_A_DEBLOCK){\n\n                    int o;\n\n\n\n                    for(o=0; options[o]!=NULL && o<2; o++){\n\n                        char *tail;\n\n                        int val= strtol(options[o], &tail, 0);\n\n                        if(tail==options[o]) break;\n\n\n\n                        numOfUnknownOptions--;\n\n                        if(o==0) ppMode->baseDcDiff= val;\n\n                        else ppMode->flatnessThreshold= val;\n\n                    }\n\n                }\n\n                else if(filters[i].mask == FORCE_QUANT){\n\n                    int o;\n\n                    ppMode->forcedQuant= 15;\n\n\n\n                    for(o=0; options[o]!=NULL && o<1; o++){\n\n                        char *tail;\n\n                        int val= strtol(options[o], &tail, 0);\n\n                        if(tail==options[o]) break;\n\n\n\n                        numOfUnknownOptions--;\n\n                        ppMode->forcedQuant= val;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        if(!filterNameOk) ppMode->error++;\n\n        ppMode->error += numOfUnknownOptions;\n\n    }\n\n\n\n    av_log(NULL, AV_LOG_DEBUG, \"pp: lumMode=%X, chromMode=%X\\n\", ppMode->lumMode, ppMode->chromMode);\n\n    if(ppMode->error){\n\n        av_log(NULL, AV_LOG_ERROR, \"%d errors in postprocess string \\\"%s\\\"\\n\", ppMode->error, name);\n\n        av_free(ppMode);\n\n        return NULL;\n\n    }\n\n    return ppMode;\n\n}\n", "idx": 16452, "_split": "test", "_hash": "4a45d274d4eb0e8ba54bc42779f04e6d"}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "static void avc_biwgt_4x4multiple_msa(uint8_t *src,\n\n                                      int32_t src_stride,\n\n                                      uint8_t *dst,\n\n                                      int32_t dst_stride,\n\n                                      int32_t height,\n\n                                      int32_t log2_denom,\n\n                                      int32_t src_weight,\n\n                                      int32_t dst_weight,\n\n                                      int32_t offset_in)\n\n{\n\n    uint8_t cnt;\n\n    uint32_t load0, load1, load2, load3;\n\n    v16i8 src_wgt, dst_wgt, wgt;\n\n    v16i8 src0, src1, src2, src3;\n\n    v16i8 dst0, dst1, dst2, dst3;\n\n    v8i16 temp0, temp1, temp2, temp3;\n\n    v8i16 denom, offset, add_val;\n\n    int32_t val = 128 * (src_weight + dst_weight);\n\n\n\n    offset_in = ((offset_in + 1) | 1) << log2_denom;\n\n\n\n    src_wgt = __msa_fill_b(src_weight);\n\n    dst_wgt = __msa_fill_b(dst_weight);\n\n    offset = __msa_fill_h(offset_in);\n\n    denom = __msa_fill_h(log2_denom + 1);\n\n    add_val = __msa_fill_h(val);\n\n    offset += add_val;\n\n\n\n    wgt = __msa_ilvev_b(dst_wgt, src_wgt);\n\n\n\n    for (cnt = height / 4; cnt--;) {\n\n        LOAD_4WORDS_WITH_STRIDE(src, src_stride, load0, load1, load2, load3);\n\n        src += (4 * src_stride);\n\n\n\n        src0 = (v16i8) __msa_fill_w(load0);\n\n        src1 = (v16i8) __msa_fill_w(load1);\n\n        src2 = (v16i8) __msa_fill_w(load2);\n\n        src3 = (v16i8) __msa_fill_w(load3);\n\n\n\n        LOAD_4WORDS_WITH_STRIDE(dst, dst_stride, load0, load1, load2, load3);\n\n\n\n        dst0 = (v16i8) __msa_fill_w(load0);\n\n        dst1 = (v16i8) __msa_fill_w(load1);\n\n        dst2 = (v16i8) __msa_fill_w(load2);\n\n        dst3 = (v16i8) __msa_fill_w(load3);\n\n\n\n        XORI_B_4VECS_SB(src0, src1, src2, src3, src0, src1, src2, src3, 128);\n\n\n\n        XORI_B_4VECS_SB(dst0, dst1, dst2, dst3, dst0, dst1, dst2, dst3, 128);\n\n\n\n        ILVR_B_4VECS_SH(src0, src1, src2, src3, dst0, dst1, dst2, dst3,\n\n                        temp0, temp1, temp2, temp3);\n\n\n\n        temp0 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp0);\n\n        temp1 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp1);\n\n        temp2 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp2);\n\n        temp3 = __msa_dpadd_s_h(offset, wgt, (v16i8) temp3);\n\n\n\n        SRA_4VECS(temp0, temp1, temp2, temp3,\n\n                  temp0, temp1, temp2, temp3, denom);\n\n\n\n        temp0 = CLIP_UNSIGNED_CHAR_H(temp0);\n\n        temp1 = CLIP_UNSIGNED_CHAR_H(temp1);\n\n        temp2 = CLIP_UNSIGNED_CHAR_H(temp2);\n\n        temp3 = CLIP_UNSIGNED_CHAR_H(temp3);\n\n\n\n        PCKEV_B_STORE_4_BYTES_4(temp0, temp1, temp2, temp3, dst, dst_stride);\n\n        dst += (4 * dst_stride);\n\n    }\n\n}\n", "idx": 16498, "_split": "test", "_hash": "fbd879d2899aaafdf686632f9b7cb803"}
{"project": "FFmpeg", "commit_id": "e45a2872fafe631c14aee9f79d0963d68c4fc1fd", "target": 0, "func": "void avg_pixels16_altivec(uint8_t *block, const uint8_t *pixels, int line_size, int h)\n\n{\n\nPOWERPC_TBL_DECLARE(altivec_avg_pixels16_num, 1);\n\n#ifdef ALTIVEC_USE_REFERENCE_C_CODE\n\n    int i;\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_avg_pixels16_num, 1);\n\n\n\n    for(i=0; i<h; i++) {\n\n      op_avg(*((uint32_t*)(block)),(((const struct unaligned_32 *)(pixels))->l));\n\n      op_avg(*((uint32_t*)(block+4)),(((const struct unaligned_32 *)(pixels+4))->l));\n\n      op_avg(*((uint32_t*)(block+8)),(((const struct unaligned_32 *)(pixels+8))->l));\n\n      op_avg(*((uint32_t*)(block+12)),(((const struct unaligned_32 *)(pixels+12))->l));\n\n      pixels+=line_size;\n\n      block +=line_size;\n\n    }\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_avg_pixels16_num, 1);\n\n\n\n#else /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n    register vector unsigned char pixelsv1, pixelsv2, pixelsv, blockv;\n\n    register vector unsigned char perm = vec_lvsl(0, pixels);\n\n    int i;\n\n\n\nPOWERPC_TBL_START_COUNT(altivec_avg_pixels16_num, 1);\n\n\n\n    for(i=0; i<h; i++) {\n\n      pixelsv1 = vec_ld(0, (unsigned char*)pixels);\n\n      pixelsv2 = vec_ld(16, (unsigned char*)pixels);\n\n      blockv = vec_ld(0, block);\n\n      pixelsv = vec_perm(pixelsv1, pixelsv2, perm);\n\n      blockv = vec_avg(blockv,pixelsv);\n\n      vec_st(blockv, 0, (unsigned char*)block);\n\n      pixels+=line_size;\n\n      block +=line_size;\n\n    }\n\n\n\nPOWERPC_TBL_STOP_COUNT(altivec_avg_pixels16_num, 1);\n\n\n\n#endif /* ALTIVEC_USE_REFERENCE_C_CODE */\n\n}\n", "idx": 16536, "_split": "test", "_hash": "c3a3b1b02d2099fba471962b1de2e05f"}
{"project": "FFmpeg", "commit_id": "cf6914e27f14cf2b5a66e25f5cf3549ceabb1648", "target": 0, "func": "static int cdxl_decode_frame(AVCodecContext *avctx, void *data,\n\n                             int *data_size, AVPacket *pkt)\n\n{\n\n    CDXLVideoContext *c = avctx->priv_data;\n\n    AVFrame * const p = &c->frame;\n\n    int ret, w, h, encoding, format, buf_size = pkt->size;\n\n    const uint8_t *buf = pkt->data;\n\n\n\n    if (buf_size < 32)\n\n        return AVERROR_INVALIDDATA;\n\n    encoding        = buf[1] & 7;\n\n    format          = buf[1] & 0xE0;\n\n    w               = AV_RB16(&buf[14]);\n\n    h               = AV_RB16(&buf[16]);\n\n    c->bpp          = buf[19];\n\n    c->palette_size = AV_RB16(&buf[20]);\n\n    c->palette      = buf + 32;\n\n    c->video        = c->palette + c->palette_size;\n\n    c->video_size   = buf_size - c->palette_size - 32;\n\n\n\n    if (c->palette_size > 512)\n\n        return AVERROR_INVALIDDATA;\n\n    if (buf_size < c->palette_size + 32)\n\n        return AVERROR_INVALIDDATA;\n\n    if (c->bpp < 1)\n\n        return AVERROR_INVALIDDATA;\n\n    if (c->bpp > 8) {\n\n        av_log_ask_for_sample(avctx, \"unsupported pixel size: %d\\n\", c->bpp);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n    if (format) {\n\n        av_log_ask_for_sample(avctx, \"unsupported pixel format: %d\\n\", format);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if ((ret = av_image_check_size(w, h, 0, avctx)) < 0)\n\n        return ret;\n\n    if (w != avctx->width || h != avctx->height)\n\n        avcodec_set_dimensions(avctx, w, h);\n\n\n\n    if (c->video_size < FFALIGN(avctx->width, 16) * avctx->height * c->bpp / 8)\n\n        return AVERROR_INVALIDDATA;\n\n    if (!encoding && c->palette_size && c->bpp <= 8) {\n\n        avctx->pix_fmt = PIX_FMT_PAL8;\n\n    } else if (encoding == 1 && (c->bpp == 6 || c->bpp == 8)) {\n\n        if (c->palette_size != (1 << (c->bpp - 1)))\n\n            return AVERROR_INVALIDDATA;\n\n        avctx->pix_fmt = PIX_FMT_BGR24;\n\n    } else {\n\n        av_log_ask_for_sample(avctx, \"unsupported encoding %d and bpp %d\\n\",\n\n                              encoding, c->bpp);\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    if (p->data[0])\n\n        avctx->release_buffer(avctx, p);\n\n\n\n    p->reference = 0;\n\n    if ((ret = avctx->get_buffer(avctx, p)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    if (encoding) {\n\n        av_fast_padded_malloc(&c->new_video, &c->new_video_size,\n\n                              h * w + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!c->new_video)\n\n            return AVERROR(ENOMEM);\n\n        if (c->bpp == 8)\n\n            cdxl_decode_ham8(c);\n\n        else\n\n            cdxl_decode_ham6(c);\n\n    } else {\n\n        cdxl_decode_rgb(c);\n\n    }\n\n    *data_size      = sizeof(AVFrame);\n\n    *(AVFrame*)data = c->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 16602, "_split": "test", "_hash": "effb397f7918e657513a6f4a914670f7"}
{"project": "FFmpeg", "commit_id": "9c85329cd02e9284892bf263ce6133b2fc479792", "target": 1, "func": "static int decode_0(PAFVideoDecContext *c, uint8_t *pkt, uint8_t code)\n\n{\n\n    uint32_t opcode_size, offset;\n\n    uint8_t *dst, *dend, mask = 0, color = 0;\n\n    const uint8_t *src, *send, *opcodes;\n\n    int i, j, op = 0;\n\n\n\n    i = bytestream2_get_byte(&c->gb);\n\n    if (i) {\n\n        if (code & 0x10) {\n\n            int align;\n\n\n\n            align = bytestream2_tell(&c->gb) & 3;\n\n            if (align)\n\n                bytestream2_skip(&c->gb, 4 - align);\n\n        }\n\n        do {\n\n            int page, val, x, y;\n\n            val    = bytestream2_get_be16(&c->gb);\n\n            page   = val >> 14;\n\n            x      = (val & 0x7F) * 2;\n\n            y      = ((val >> 7) & 0x7F) * 2;\n\n            dst    = c->frame[page] + x + y * c->width;\n\n            dend   = c->frame[page] + c->frame_size;\n\n            offset = (x & 0x7F) * 2;\n\n            j      = bytestream2_get_le16(&c->gb) + offset;\n\n            do {\n\n                offset++;\n\n                if (dst + 3 * c->width + 4 > dend)\n\n                    return AVERROR_INVALIDDATA;\n\n                read4x4block(c, dst, c->width);\n\n                if ((offset & 0x3F) == 0)\n\n                    dst += c->width * 3;\n\n                dst += 4;\n\n            } while (offset < j);\n\n        } while (--i);\n\n    }\n\n\n\n    dst  = c->frame[c->current_frame];\n\n    dend = c->frame[c->current_frame] + c->frame_size;\n\n    do {\n\n        set_src_position(c, &src, &send);\n\n        if ((src + 3 * c->width + 4 > send) ||\n\n            (dst + 3 * c->width + 4 > dend))\n\n            return AVERROR_INVALIDDATA;\n\n        copy_block4(dst, src, c->width, c->width, 4);\n\n        i++;\n\n        if ((i & 0x3F) == 0)\n\n            dst += c->width * 3;\n\n        dst += 4;\n\n    } while (i < c->video_size / 16);\n\n\n\n    opcode_size = bytestream2_get_le16(&c->gb);\n\n    bytestream2_skip(&c->gb, 2);\n\n\n\n    if (bytestream2_get_bytes_left(&c->gb) < opcode_size)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    opcodes = pkt + bytestream2_tell(&c->gb);\n\n    bytestream2_skipu(&c->gb, opcode_size);\n\n\n\n    dst = c->frame[c->current_frame];\n\n\n\n    for (i = 0; i < c->height; i += 4, dst += c->width * 3)\n\n        for (j = 0; j < c->width; j += 4, dst += 4) {\n\n            int opcode, k = 0;\n\n            if (op > opcode_size)\n\n                return AVERROR_INVALIDDATA;\n\n            if (j & 4) {\n\n                opcode = opcodes[op] & 15;\n\n                op++;\n\n            } else {\n\n                opcode = opcodes[op] >> 4;\n\n            }\n\n\n\n            while (block_sequences[opcode][k]) {\n\n                offset = c->width * 2;\n\n                code   = block_sequences[opcode][k++];\n\n\n\n                switch (code) {\n\n                case 2:\n\n                    offset = 0;\n\n                case 3:\n\n                    color = bytestream2_get_byte(&c->gb);\n\n                case 4:\n\n                    mask = bytestream2_get_byte(&c->gb);\n\n                    copy_color_mask(dst + offset, c->width, mask, color);\n\n                    break;\n\n                case 5:\n\n                    offset = 0;\n\n                case 6:\n\n                    set_src_position(c, &src, &send);\n\n                case 7:\n\n                    if (src + offset + c->width + 4 > send)\n\n                        return AVERROR_INVALIDDATA;\n\n                    mask = bytestream2_get_byte(&c->gb);\n\n                    copy_src_mask(dst + offset, c->width, mask, src + offset);\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n\n\n    return 0;\n\n}\n", "idx": 16614, "_split": "test", "_hash": "20623031c3a7748aca2b40c11d2ffb0a"}
{"project": "FFmpeg", "commit_id": "5dbb63feefb9070d6fbb5fc16406813f14aa7f9b", "target": 0, "func": "static int decode_thread(void *arg)\n\n{\n\n    VideoState *is = arg;\n\n    AVFormatContext *ic;\n\n    int err, i, ret, video_index, audio_index, subtitle_index;\n\n    AVPacket pkt1, *pkt = &pkt1;\n\n    AVFormatParameters params, *ap = &params;\n\n\n\n    video_index = -1;\n\n    audio_index = -1;\n\n    subtitle_index = -1;\n\n    is->video_stream = -1;\n\n    is->audio_stream = -1;\n\n    is->subtitle_stream = -1;\n\n\n\n    global_video_state = is;\n\n    url_set_interrupt_cb(decode_interrupt_cb);\n\n\n\n    memset(ap, 0, sizeof(*ap));\n\n\n\n    ap->width = frame_width;\n\n    ap->height= frame_height;\n\n    ap->time_base= (AVRational){1, 25};\n\n    ap->pix_fmt = frame_pix_fmt;\n\n\n\n    err = av_open_input_file(&ic, is->filename, is->iformat, 0, ap);\n\n    if (err < 0) {\n\n        print_error(is->filename, err);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n    is->ic = ic;\n\n\n\n    if(genpts)\n\n        ic->flags |= AVFMT_FLAG_GENPTS;\n\n\n\n    err = av_find_stream_info(ic);\n\n    if (err < 0) {\n\n        fprintf(stderr, \"%s: could not find codec parameters\\n\", is->filename);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n    if(ic->pb)\n\n        ic->pb->eof_reached= 0; //FIXME hack, ffplay maybe should not use url_feof() to test for the end\n\n\n\n    /* if seeking requested, we execute it */\n\n    if (start_time != AV_NOPTS_VALUE) {\n\n        int64_t timestamp;\n\n\n\n        timestamp = start_time;\n\n        /* add the stream start time */\n\n        if (ic->start_time != AV_NOPTS_VALUE)\n\n            timestamp += ic->start_time;\n\n        ret = av_seek_frame(ic, -1, timestamp, AVSEEK_FLAG_BACKWARD);\n\n        if (ret < 0) {\n\n            fprintf(stderr, \"%s: could not seek to position %0.3f\\n\",\n\n                    is->filename, (double)timestamp / AV_TIME_BASE);\n\n        }\n\n    }\n\n\n\n    for(i = 0; i < ic->nb_streams; i++) {\n\n        AVCodecContext *enc = ic->streams[i]->codec;\n\n        ic->streams[i]->discard = AVDISCARD_ALL;\n\n        switch(enc->codec_type) {\n\n        case CODEC_TYPE_AUDIO:\n\n            if ((audio_index < 0 || wanted_audio_stream-- > 0) && !audio_disable)\n\n                audio_index = i;\n\n            break;\n\n        case CODEC_TYPE_VIDEO:\n\n            if ((video_index < 0 || wanted_video_stream-- > 0) && !video_disable)\n\n                video_index = i;\n\n            break;\n\n        case CODEC_TYPE_SUBTITLE:\n\n            if (wanted_subtitle_stream-- >= 0 && !video_disable)\n\n                subtitle_index = i;\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n    }\n\n    if (show_status) {\n\n        dump_format(ic, 0, is->filename, 0);\n\n        dump_stream_info(ic);\n\n    }\n\n\n\n    /* open the streams */\n\n    if (audio_index >= 0) {\n\n        stream_component_open(is, audio_index);\n\n    }\n\n\n\n    if (video_index >= 0) {\n\n        stream_component_open(is, video_index);\n\n    } else {\n\n        if (!display_disable)\n\n            is->show_audio = 1;\n\n    }\n\n\n\n    if (subtitle_index >= 0) {\n\n        stream_component_open(is, subtitle_index);\n\n    }\n\n\n\n    if (is->video_stream < 0 && is->audio_stream < 0) {\n\n        fprintf(stderr, \"%s: could not open codecs\\n\", is->filename);\n\n        ret = -1;\n\n        goto fail;\n\n    }\n\n\n\n    for(;;) {\n\n        if (is->abort_request)\n\n            break;\n\n        if (is->paused != is->last_paused) {\n\n            is->last_paused = is->paused;\n\n            if (is->paused)\n\n                av_read_pause(ic);\n\n            else\n\n                av_read_play(ic);\n\n        }\n\n#if CONFIG_RTSP_DEMUXER\n\n        if (is->paused && !strcmp(ic->iformat->name, \"rtsp\")) {\n\n            /* wait 10 ms to avoid trying to get another packet */\n\n            /* XXX: horrible */\n\n            SDL_Delay(10);\n\n            continue;\n\n        }\n\n#endif\n\n        if (is->seek_req) {\n\n            int stream_index= -1;\n\n            int64_t seek_target= is->seek_pos;\n\n\n\n            if     (is->   video_stream >= 0) stream_index= is->   video_stream;\n\n            else if(is->   audio_stream >= 0) stream_index= is->   audio_stream;\n\n            else if(is->subtitle_stream >= 0) stream_index= is->subtitle_stream;\n\n\n\n            if(stream_index>=0){\n\n                seek_target= av_rescale_q(seek_target, AV_TIME_BASE_Q, ic->streams[stream_index]->time_base);\n\n            }\n\n\n\n            ret = av_seek_frame(is->ic, stream_index, seek_target, is->seek_flags);\n\n            if (ret < 0) {\n\n                fprintf(stderr, \"%s: error while seeking\\n\", is->ic->filename);\n\n            }else{\n\n                if (is->audio_stream >= 0) {\n\n                    packet_queue_flush(&is->audioq);\n\n                    packet_queue_put(&is->audioq, &flush_pkt);\n\n                }\n\n                if (is->subtitle_stream >= 0) {\n\n                    packet_queue_flush(&is->subtitleq);\n\n                    packet_queue_put(&is->subtitleq, &flush_pkt);\n\n                }\n\n                if (is->video_stream >= 0) {\n\n                    packet_queue_flush(&is->videoq);\n\n                    packet_queue_put(&is->videoq, &flush_pkt);\n\n                }\n\n            }\n\n            is->seek_req = 0;\n\n        }\n\n\n\n        /* if the queue are full, no need to read more */\n\n        if (is->audioq.size > MAX_AUDIOQ_SIZE ||\n\n            is->videoq.size > MAX_VIDEOQ_SIZE ||\n\n            is->subtitleq.size > MAX_SUBTITLEQ_SIZE) {\n\n            /* wait 10 ms */\n\n            SDL_Delay(10);\n\n            continue;\n\n        }\n\n        if(url_feof(ic->pb)) {\n\n            av_init_packet(pkt);\n\n            pkt->data=NULL;\n\n            pkt->size=0;\n\n            pkt->stream_index= is->video_stream;\n\n            packet_queue_put(&is->videoq, pkt);\n\n            continue;\n\n        }\n\n        ret = av_read_frame(ic, pkt);\n\n        if (ret < 0) {\n\n            if (ret != AVERROR_EOF && url_ferror(ic->pb) == 0) {\n\n                SDL_Delay(100); /* wait for user event */\n\n                continue;\n\n            } else\n\n                break;\n\n        }\n\n        if (pkt->stream_index == is->audio_stream) {\n\n            packet_queue_put(&is->audioq, pkt);\n\n        } else if (pkt->stream_index == is->video_stream) {\n\n            packet_queue_put(&is->videoq, pkt);\n\n        } else if (pkt->stream_index == is->subtitle_stream) {\n\n            packet_queue_put(&is->subtitleq, pkt);\n\n        } else {\n\n            av_free_packet(pkt);\n\n        }\n\n    }\n\n    /* wait until the end */\n\n    while (!is->abort_request) {\n\n        SDL_Delay(100);\n\n    }\n\n\n\n    ret = 0;\n\n fail:\n\n    /* disable interrupting */\n\n    global_video_state = NULL;\n\n\n\n    /* close each stream */\n\n    if (is->audio_stream >= 0)\n\n        stream_component_close(is, is->audio_stream);\n\n    if (is->video_stream >= 0)\n\n        stream_component_close(is, is->video_stream);\n\n    if (is->subtitle_stream >= 0)\n\n        stream_component_close(is, is->subtitle_stream);\n\n    if (is->ic) {\n\n        av_close_input_file(is->ic);\n\n        is->ic = NULL; /* safety */\n\n    }\n\n    url_set_interrupt_cb(NULL);\n\n\n\n    if (ret != 0) {\n\n        SDL_Event event;\n\n\n\n        event.type = FF_QUIT_EVENT;\n\n        event.user.data1 = is;\n\n        SDL_PushEvent(&event);\n\n    }\n\n    return 0;\n\n}\n", "idx": 16651, "_split": "test", "_hash": "a9d050892d4a2e77ff70efc2351c73fd"}
{"project": "FFmpeg", "commit_id": "608708009f69ba4cecebf05120c696167494c897", "target": 1, "func": "static int adpcm_decode_frame(AVCodecContext *avctx, void *data,\n                              int *got_frame_ptr, AVPacket *avpkt)\n{\n    const uint8_t *buf = avpkt->data;\n    int buf_size = avpkt->size;\n    ADPCMDecodeContext *c = avctx->priv_data;\n    ADPCMChannelStatus *cs;\n    int n, m, channel, i;\n    short *samples;\n    const uint8_t *src;\n    int st; /* stereo */\n    int count1, count2;\n    int nb_samples, coded_samples, ret;\n    nb_samples = get_nb_samples(avctx, buf, buf_size, &coded_samples);\n    if (nb_samples <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid number of samples in packet\\n\");\n    }\n    /* get output buffer */\n    c->frame.nb_samples = nb_samples;\n    if ((ret = avctx->get_buffer(avctx, &c->frame)) < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n        return ret;\n    }\n    samples = (short *)c->frame.data[0];\n    /* use coded_samples when applicable */\n    /* it is always <= nb_samples, so the output buffer will be large enough */\n    if (coded_samples) {\n        if (coded_samples != nb_samples)\n            av_log(avctx, AV_LOG_WARNING, \"mismatch in coded sample count\\n\");\n        c->frame.nb_samples = nb_samples = coded_samples;\n    }\n    src = buf;\n    st = avctx->channels == 2 ? 1 : 0;\n    switch(avctx->codec->id) {\n    case CODEC_ID_ADPCM_IMA_QT:\n        /* In QuickTime, IMA is encoded by chunks of 34 bytes (=64 samples).\n           Channel data is interleaved per-chunk. */\n        for (channel = 0; channel < avctx->channels; channel++) {\n            int16_t predictor;\n            int step_index;\n            cs = &(c->status[channel]);\n            /* (pppppp) (piiiiiii) */\n            /* Bits 15-7 are the _top_ 9 bits of the 16-bit initial predictor value */\n            predictor = AV_RB16(src);\n            step_index = predictor & 0x7F;\n            predictor &= 0xFF80;\n            src += 2;\n            if (cs->step_index == step_index) {\n                int diff = (int)predictor - cs->predictor;\n                if (diff < 0)\n                    diff = - diff;\n                if (diff > 0x7f)\n                    goto update;\n            } else {\n            update:\n                cs->step_index = step_index;\n                cs->predictor = predictor;\n            }\n            if (cs->step_index > 88){\n                av_log(avctx, AV_LOG_ERROR, \"ERROR: step_index = %i\\n\", cs->step_index);\n                cs->step_index = 88;\n            }\n            samples = (short *)c->frame.data[0] + channel;\n            for (m = 0; m < 32; m++) {\n                *samples = adpcm_ima_qt_expand_nibble(cs, src[0] & 0x0F, 3);\n                samples += avctx->channels;\n                *samples = adpcm_ima_qt_expand_nibble(cs, src[0] >> 4  , 3);\n                samples += avctx->channels;\n                src ++;\n            }\n        }\n        break;\n    case CODEC_ID_ADPCM_IMA_WAV:\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n            buf_size = avctx->block_align;\n        for(i=0; i<avctx->channels; i++){\n            cs = &(c->status[i]);\n            cs->predictor = *samples++ = (int16_t)bytestream_get_le16(&src);\n            cs->step_index = *src++;\n            if (cs->step_index > 88){\n                av_log(avctx, AV_LOG_ERROR, \"ERROR: step_index = %i\\n\", cs->step_index);\n                cs->step_index = 88;\n            }\n            if (*src++) av_log(avctx, AV_LOG_ERROR, \"unused byte should be null but is %d!!\\n\", src[-1]); /* unused */\n        }\n        for (n = (nb_samples - 1) / 8; n > 0; n--) {\n            for (i = 0; i < avctx->channels; i++) {\n                cs = &c->status[i];\n                for (m = 0; m < 4; m++) {\n                    uint8_t v = *src++;\n                    *samples = adpcm_ima_expand_nibble(cs, v & 0x0F, 3);\n                    samples += avctx->channels;\n                    *samples = adpcm_ima_expand_nibble(cs, v >> 4  , 3);\n                    samples += avctx->channels;\n                }\n                samples -= 8 * avctx->channels - 1;\n            }\n            samples += 7 * avctx->channels;\n        }\n        break;\n    case CODEC_ID_ADPCM_4XM:\n        for (i = 0; i < avctx->channels; i++)\n            c->status[i].predictor= (int16_t)bytestream_get_le16(&src);\n        for (i = 0; i < avctx->channels; i++) {\n            c->status[i].step_index= (int16_t)bytestream_get_le16(&src);\n            c->status[i].step_index = av_clip(c->status[i].step_index, 0, 88);\n        }\n        for (i = 0; i < avctx->channels; i++) {\n            samples = (short *)c->frame.data[0] + i;\n            cs = &c->status[i];\n            for (n = nb_samples >> 1; n > 0; n--, src++) {\n                uint8_t v = *src;\n                *samples = adpcm_ima_expand_nibble(cs, v & 0x0F, 4);\n                samples += avctx->channels;\n                *samples = adpcm_ima_expand_nibble(cs, v >> 4  , 4);\n                samples += avctx->channels;\n            }\n        }\n        break;\n    case CODEC_ID_ADPCM_MS:\n    {\n        int block_predictor;\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n            buf_size = avctx->block_align;\n        block_predictor = av_clip(*src++, 0, 6);\n        c->status[0].coeff1 = ff_adpcm_AdaptCoeff1[block_predictor];\n        c->status[0].coeff2 = ff_adpcm_AdaptCoeff2[block_predictor];\n        if (st) {\n            block_predictor = av_clip(*src++, 0, 6);\n            c->status[1].coeff1 = ff_adpcm_AdaptCoeff1[block_predictor];\n            c->status[1].coeff2 = ff_adpcm_AdaptCoeff2[block_predictor];\n        }\n        c->status[0].idelta = (int16_t)bytestream_get_le16(&src);\n        if (st){\n            c->status[1].idelta = (int16_t)bytestream_get_le16(&src);\n        }\n        c->status[0].sample1 = bytestream_get_le16(&src);\n        if (st) c->status[1].sample1 = bytestream_get_le16(&src);\n        c->status[0].sample2 = bytestream_get_le16(&src);\n        if (st) c->status[1].sample2 = bytestream_get_le16(&src);\n        *samples++ = c->status[0].sample2;\n        if (st) *samples++ = c->status[1].sample2;\n        *samples++ = c->status[0].sample1;\n        if (st) *samples++ = c->status[1].sample1;\n        for(n = (nb_samples - 2) >> (1 - st); n > 0; n--, src++) {\n            *samples++ = adpcm_ms_expand_nibble(&c->status[0 ], src[0] >> 4  );\n            *samples++ = adpcm_ms_expand_nibble(&c->status[st], src[0] & 0x0F);\n        }\n        break;\n    }\n    case CODEC_ID_ADPCM_IMA_DK4:\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n            buf_size = avctx->block_align;\n        for (channel = 0; channel < avctx->channels; channel++) {\n            cs = &c->status[channel];\n            cs->predictor  = (int16_t)bytestream_get_le16(&src);\n            cs->step_index = *src++;\n            src++;\n            *samples++ = cs->predictor;\n        }\n        for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n            uint8_t v = *src;\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0 ], v >> 4  , 3);\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v & 0x0F, 3);\n        }\n        break;\n    case CODEC_ID_ADPCM_IMA_DK3:\n    {\n        unsigned char last_byte = 0;\n        unsigned char nibble;\n        int decode_top_nibble_next = 0;\n        int end_of_packet = 0;\n        int diff_channel;\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n            buf_size = avctx->block_align;\n        c->status[0].predictor  = (int16_t)AV_RL16(src + 10);\n        c->status[1].predictor  = (int16_t)AV_RL16(src + 12);\n        c->status[0].step_index = src[14];\n        c->status[1].step_index = src[15];\n        /* sign extend the predictors */\n        src += 16;\n        diff_channel = c->status[1].predictor;\n        /* the DK3_GET_NEXT_NIBBLE macro issues the break statement when\n         * the buffer is consumed */\n        while (1) {\n            /* for this algorithm, c->status[0] is the sum channel and\n             * c->status[1] is the diff channel */\n            /* process the first predictor of the sum channel */\n            DK3_GET_NEXT_NIBBLE();\n            adpcm_ima_expand_nibble(&c->status[0], nibble, 3);\n            /* process the diff channel predictor */\n            DK3_GET_NEXT_NIBBLE();\n            adpcm_ima_expand_nibble(&c->status[1], nibble, 3);\n            /* process the first pair of stereo PCM samples */\n            diff_channel = (diff_channel + c->status[1].predictor) / 2;\n            *samples++ = c->status[0].predictor + c->status[1].predictor;\n            *samples++ = c->status[0].predictor - c->status[1].predictor;\n            /* process the second predictor of the sum channel */\n            DK3_GET_NEXT_NIBBLE();\n            adpcm_ima_expand_nibble(&c->status[0], nibble, 3);\n            /* process the second pair of stereo PCM samples */\n            diff_channel = (diff_channel + c->status[1].predictor) / 2;\n            *samples++ = c->status[0].predictor + c->status[1].predictor;\n            *samples++ = c->status[0].predictor - c->status[1].predictor;\n        }\n        break;\n    }\n    case CODEC_ID_ADPCM_IMA_ISS:\n        for (channel = 0; channel < avctx->channels; channel++) {\n            cs = &c->status[channel];\n            cs->predictor  = (int16_t)bytestream_get_le16(&src);\n            cs->step_index = *src++;\n            src++;\n        }\n        for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n            uint8_t v1, v2;\n            uint8_t v = *src;\n            /* nibbles are swapped for mono */\n            if (st) {\n                v1 = v >> 4;\n                v2 = v & 0x0F;\n            } else {\n                v2 = v >> 4;\n                v1 = v & 0x0F;\n            }\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0 ], v1, 3);\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v2, 3);\n        }\n        break;\n    case CODEC_ID_ADPCM_IMA_WS:\n        while (src < buf + buf_size) {\n            uint8_t v = *src++;\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],  v >> 4  , 3);\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v & 0x0F, 3);\n        }\n        break;\n    case CODEC_ID_ADPCM_XA:\n        while (buf_size >= 128) {\n            xa_decode(samples, src, &c->status[0], &c->status[1],\n                avctx->channels);\n            src += 128;\n            samples += 28 * 8;\n            buf_size -= 128;\n        }\n        break;\n    case CODEC_ID_ADPCM_IMA_EA_EACS:\n        src += 4; // skip sample count (already read)\n        for (i=0; i<=st; i++)\n            c->status[i].step_index = bytestream_get_le32(&src);\n        for (i=0; i<=st; i++)\n            c->status[i].predictor  = bytestream_get_le32(&src);\n        for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],  *src>>4,   3);\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], *src&0x0F, 3);\n        }\n        break;\n    case CODEC_ID_ADPCM_IMA_EA_SEAD:\n        for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0], src[0] >> 4, 6);\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st],src[0]&0x0F, 6);\n        }\n        break;\n    case CODEC_ID_ADPCM_EA:\n    {\n        int32_t previous_left_sample, previous_right_sample;\n        int32_t current_left_sample, current_right_sample;\n        int32_t next_left_sample, next_right_sample;\n        int32_t coeff1l, coeff2l, coeff1r, coeff2r;\n        uint8_t shift_left, shift_right;\n        /* Each EA ADPCM frame has a 12-byte header followed by 30-byte pieces,\n           each coding 28 stereo samples. */\n        src += 4; // skip sample count (already read)\n        current_left_sample   = (int16_t)bytestream_get_le16(&src);\n        previous_left_sample  = (int16_t)bytestream_get_le16(&src);\n        current_right_sample  = (int16_t)bytestream_get_le16(&src);\n        previous_right_sample = (int16_t)bytestream_get_le16(&src);\n        for (count1 = 0; count1 < nb_samples / 28; count1++) {\n            coeff1l = ea_adpcm_table[ *src >> 4       ];\n            coeff2l = ea_adpcm_table[(*src >> 4  ) + 4];\n            coeff1r = ea_adpcm_table[*src & 0x0F];\n            coeff2r = ea_adpcm_table[(*src & 0x0F) + 4];\n            src++;\n            shift_left  = 20 - (*src >> 4);\n            shift_right = 20 - (*src & 0x0F);\n            src++;\n            for (count2 = 0; count2 < 28; count2++) {\n                next_left_sample  = sign_extend(*src >> 4, 4) << shift_left;\n                next_right_sample = sign_extend(*src,      4) << shift_right;\n                src++;\n                next_left_sample = (next_left_sample +\n                    (current_left_sample * coeff1l) +\n                    (previous_left_sample * coeff2l) + 0x80) >> 8;\n                next_right_sample = (next_right_sample +\n                    (current_right_sample * coeff1r) +\n                    (previous_right_sample * coeff2r) + 0x80) >> 8;\n                previous_left_sample = current_left_sample;\n                current_left_sample = av_clip_int16(next_left_sample);\n                previous_right_sample = current_right_sample;\n                current_right_sample = av_clip_int16(next_right_sample);\n                *samples++ = (unsigned short)current_left_sample;\n                *samples++ = (unsigned short)current_right_sample;\n            }\n        }\n        if (src - buf == buf_size - 2)\n            src += 2; // Skip terminating 0x0000\n        break;\n    }\n    case CODEC_ID_ADPCM_EA_MAXIS_XA:\n    {\n        int coeff[2][2], shift[2];\n        for(channel = 0; channel < avctx->channels; channel++) {\n            for (i=0; i<2; i++)\n                coeff[channel][i] = ea_adpcm_table[(*src >> 4) + 4*i];\n            shift[channel] = 20 - (*src & 0x0F);\n            src++;\n        }\n        for (count1 = 0; count1 < nb_samples / 2; count1++) {\n            for(i = 4; i >= 0; i-=4) { /* Pairwise samples LL RR (st) or LL LL (mono) */\n                for(channel = 0; channel < avctx->channels; channel++) {\n                    int32_t sample = sign_extend(src[channel] >> i, 4) << shift[channel];\n                    sample = (sample +\n                             c->status[channel].sample1 * coeff[channel][0] +\n                             c->status[channel].sample2 * coeff[channel][1] + 0x80) >> 8;\n                    c->status[channel].sample2 = c->status[channel].sample1;\n                    c->status[channel].sample1 = av_clip_int16(sample);\n                    *samples++ = c->status[channel].sample1;\n                }\n            }\n            src+=avctx->channels;\n        }\n        /* consume whole packet */\n        src = buf + buf_size;\n        break;\n    }\n    case CODEC_ID_ADPCM_EA_R1:\n    case CODEC_ID_ADPCM_EA_R2:\n    case CODEC_ID_ADPCM_EA_R3: {\n        /* channel numbering\n           2chan: 0=fl, 1=fr\n           4chan: 0=fl, 1=rl, 2=fr, 3=rr\n           6chan: 0=fl, 1=c,  2=fr, 3=rl,  4=rr, 5=sub */\n        const int big_endian = avctx->codec->id == CODEC_ID_ADPCM_EA_R3;\n        int32_t previous_sample, current_sample, next_sample;\n        int32_t coeff1, coeff2;\n        uint8_t shift;\n        unsigned int channel;\n        uint16_t *samplesC;\n        const uint8_t *srcC;\n        const uint8_t *src_end = buf + buf_size;\n        int count = 0;\n        src += 4; // skip sample count (already read)\n        for (channel=0; channel<avctx->channels; channel++) {\n            int32_t offset = (big_endian ? bytestream_get_be32(&src)\n                                         : bytestream_get_le32(&src))\n                           + (avctx->channels-channel-1) * 4;\n            if ((offset < 0) || (offset >= src_end - src - 4)) break;\n            srcC  = src + offset;\n            samplesC = samples + channel;\n            if (avctx->codec->id == CODEC_ID_ADPCM_EA_R1) {\n                current_sample  = (int16_t)bytestream_get_le16(&srcC);\n                previous_sample = (int16_t)bytestream_get_le16(&srcC);\n            } else {\n                current_sample  = c->status[channel].predictor;\n                previous_sample = c->status[channel].prev_sample;\n            }\n            for (count1 = 0; count1 < nb_samples / 28; count1++) {\n                if (*srcC == 0xEE) {  /* only seen in R2 and R3 */\n                    srcC++;\n                    if (srcC > src_end - 30*2) break;\n                    current_sample  = (int16_t)bytestream_get_be16(&srcC);\n                    previous_sample = (int16_t)bytestream_get_be16(&srcC);\n                    for (count2=0; count2<28; count2++) {\n                        *samplesC = (int16_t)bytestream_get_be16(&srcC);\n                        samplesC += avctx->channels;\n                    }\n                } else {\n                    coeff1 = ea_adpcm_table[ *srcC>>4     ];\n                    coeff2 = ea_adpcm_table[(*srcC>>4) + 4];\n                    shift = 20 - (*srcC++ & 0x0F);\n                    if (srcC > src_end - 14) break;\n                    for (count2=0; count2<28; count2++) {\n                        if (count2 & 1)\n                            next_sample = sign_extend(*srcC++,    4) << shift;\n                        else\n                            next_sample = sign_extend(*srcC >> 4, 4) << shift;\n                        next_sample += (current_sample  * coeff1) +\n                                       (previous_sample * coeff2);\n                        next_sample = av_clip_int16(next_sample >> 8);\n                        previous_sample = current_sample;\n                        current_sample  = next_sample;\n                        *samplesC = current_sample;\n                        samplesC += avctx->channels;\n                    }\n                }\n            }\n            if (!count) {\n                count = count1;\n            } else if (count != count1) {\n                av_log(avctx, AV_LOG_WARNING, \"per-channel sample count mismatch\\n\");\n                count = FFMAX(count, count1);\n            }\n            if (avctx->codec->id != CODEC_ID_ADPCM_EA_R1) {\n                c->status[channel].predictor   = current_sample;\n                c->status[channel].prev_sample = previous_sample;\n            }\n        }\n        c->frame.nb_samples = count * 28;\n        src = src_end;\n        break;\n    }\n    case CODEC_ID_ADPCM_EA_XAS:\n        for (channel=0; channel<avctx->channels; channel++) {\n            int coeff[2][4], shift[4];\n            short *s2, *s = &samples[channel];\n            for (n=0; n<4; n++, s+=32*avctx->channels) {\n                for (i=0; i<2; i++)\n                    coeff[i][n] = ea_adpcm_table[(src[0]&0x0F)+4*i];\n                shift[n] = 20 - (src[2] & 0x0F);\n                for (s2=s, i=0; i<2; i++, src+=2, s2+=avctx->channels)\n                    s2[0] = (src[0]&0xF0) + (src[1]<<8);\n            }\n            for (m=2; m<32; m+=2) {\n                s = &samples[m*avctx->channels + channel];\n                for (n=0; n<4; n++, src++, s+=32*avctx->channels) {\n                    for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) {\n                        int level = sign_extend(*src >> (4 - i), 4) << shift[n];\n                        int pred  = s2[-1*avctx->channels] * coeff[0][n]\n                                  + s2[-2*avctx->channels] * coeff[1][n];\n                        s2[0] = av_clip_int16((level + pred + 0x80) >> 8);\n                    }\n                }\n            }\n        }\n        break;\n    case CODEC_ID_ADPCM_IMA_AMV:\n    case CODEC_ID_ADPCM_IMA_SMJPEG:\n        c->status[0].predictor = (int16_t)bytestream_get_le16(&src);\n        c->status[0].step_index = bytestream_get_le16(&src);\n        if (avctx->codec->id == CODEC_ID_ADPCM_IMA_AMV)\n            src+=4;\n        for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n            char hi, lo;\n            lo = *src & 0x0F;\n            hi = *src >> 4;\n            if (avctx->codec->id == CODEC_ID_ADPCM_IMA_AMV)\n                FFSWAP(char, hi, lo);\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],\n                lo, 3);\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],\n                hi, 3);\n        }\n        break;\n    case CODEC_ID_ADPCM_CT:\n        for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n            uint8_t v = *src;\n            *samples++ = adpcm_ct_expand_nibble(&c->status[0 ], v >> 4  );\n            *samples++ = adpcm_ct_expand_nibble(&c->status[st], v & 0x0F);\n        }\n        break;\n    case CODEC_ID_ADPCM_SBPRO_4:\n    case CODEC_ID_ADPCM_SBPRO_3:\n    case CODEC_ID_ADPCM_SBPRO_2:\n        if (!c->status[0].step_index) {\n            /* the first byte is a raw sample */\n            *samples++ = 128 * (*src++ - 0x80);\n            if (st)\n              *samples++ = 128 * (*src++ - 0x80);\n            c->status[0].step_index = 1;\n            nb_samples--;\n        }\n        if (avctx->codec->id == CODEC_ID_ADPCM_SBPRO_4) {\n            for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n                    src[0] >> 4, 4, 0);\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n                    src[0] & 0x0F, 4, 0);\n            }\n        } else if (avctx->codec->id == CODEC_ID_ADPCM_SBPRO_3) {\n            for (n = nb_samples / 3; n > 0; n--, src++) {\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n                     src[0] >> 5        , 3, 0);\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n                    (src[0] >> 2) & 0x07, 3, 0);\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n                    src[0] & 0x03, 2, 0);\n            }\n        } else {\n            for (n = nb_samples >> (2 - st); n > 0; n--, src++) {\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n                     src[0] >> 6        , 2, 2);\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n                    (src[0] >> 4) & 0x03, 2, 2);\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n                    (src[0] >> 2) & 0x03, 2, 2);\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n                    src[0] & 0x03, 2, 2);\n            }\n        }\n        break;\n    case CODEC_ID_ADPCM_SWF:\n    {\n        GetBitContext gb;\n        const int *table;\n        int k0, signmask, nb_bits, count;\n        int size = buf_size*8;\n        init_get_bits(&gb, buf, size);\n        //read bits & initial values\n        nb_bits = get_bits(&gb, 2)+2;\n        //av_log(NULL,AV_LOG_INFO,\"nb_bits: %d\\n\", nb_bits);\n        table = swf_index_tables[nb_bits-2];\n        k0 = 1 << (nb_bits-2);\n        signmask = 1 << (nb_bits-1);\n        while (get_bits_count(&gb) <= size - 22*avctx->channels) {\n            for (i = 0; i < avctx->channels; i++) {\n                *samples++ = c->status[i].predictor = get_sbits(&gb, 16);\n                c->status[i].step_index = get_bits(&gb, 6);\n            }\n            for (count = 0; get_bits_count(&gb) <= size - nb_bits*avctx->channels && count < 4095; count++) {\n                int i;\n                for (i = 0; i < avctx->channels; i++) {\n                    // similar to IMA adpcm\n                    int delta = get_bits(&gb, nb_bits);\n                    int step = ff_adpcm_step_table[c->status[i].step_index];\n                    long vpdiff = 0; // vpdiff = (delta+0.5)*step/4\n                    int k = k0;\n                    do {\n                        if (delta & k)\n                            vpdiff += step;\n                        step >>= 1;\n                        k >>= 1;\n                    } while(k);\n                    vpdiff += step;\n                    if (delta & signmask)\n                        c->status[i].predictor -= vpdiff;\n                    else\n                        c->status[i].predictor += vpdiff;\n                    c->status[i].step_index += table[delta & (~signmask)];\n                    c->status[i].step_index = av_clip(c->status[i].step_index, 0, 88);\n                    c->status[i].predictor = av_clip_int16(c->status[i].predictor);\n                    *samples++ = c->status[i].predictor;\n                }\n            }\n        }\n        src += buf_size;\n        break;\n    }\n    case CODEC_ID_ADPCM_YAMAHA:\n        for (n = nb_samples >> (1 - st); n > 0; n--, src++) {\n            uint8_t v = *src;\n            *samples++ = adpcm_yamaha_expand_nibble(&c->status[0 ], v & 0x0F);\n            *samples++ = adpcm_yamaha_expand_nibble(&c->status[st], v >> 4  );\n        }\n        break;\n    case CODEC_ID_ADPCM_THP:\n    {\n        int table[2][16];\n        int prev[2][2];\n        int ch;\n        src += 4; // skip channel size\n        src += 4; // skip number of samples (already read)\n        for (i = 0; i < 32; i++)\n            table[0][i] = (int16_t)bytestream_get_be16(&src);\n        /* Initialize the previous sample.  */\n        for (i = 0; i < 4; i++)\n            prev[0][i] = (int16_t)bytestream_get_be16(&src);\n        for (ch = 0; ch <= st; ch++) {\n            samples = (short *)c->frame.data[0] + ch;\n            /* Read in every sample for this channel.  */\n            for (i = 0; i < nb_samples / 14; i++) {\n                int index = (*src >> 4) & 7;\n                unsigned int exp = *src++ & 15;\n                int factor1 = table[ch][index * 2];\n                int factor2 = table[ch][index * 2 + 1];\n                /* Decode 14 samples.  */\n                for (n = 0; n < 14; n++) {\n                    int32_t sampledat;\n                    if(n&1) sampledat = sign_extend(*src++, 4);\n                    else    sampledat = sign_extend(*src >> 4, 4);\n                    sampledat = ((prev[ch][0]*factor1\n                                + prev[ch][1]*factor2) >> 11) + (sampledat << exp);\n                    *samples = av_clip_int16(sampledat);\n                    prev[ch][1] = prev[ch][0];\n                    prev[ch][0] = *samples++;\n                    /* In case of stereo, skip one sample, this sample\n                       is for the other channel.  */\n                    samples += st;\n                }\n            }\n        }\n        break;\n    }\n    default:\n        return -1;\n    }\n    *got_frame_ptr   = 1;\n    *(AVFrame *)data = c->frame;\n    return src - buf;\n}", "idx": 16664, "_split": "test", "_hash": "e6dcb4e8389015a9ac88e2926c0c9c48"}
{"project": "FFmpeg", "commit_id": "fc49f22c3b735db5aaac5f98e40b7124a2be13b8", "target": 1, "func": "static char *choose_pixel_fmts(OutputStream *ost)\n\n{\n\n    if (ost->keep_pix_fmt) {\n\n        if (ost->filter)\n\n            avfilter_graph_set_auto_convert(ost->filter->graph->graph,\n\n                                            AVFILTER_AUTO_CONVERT_NONE);\n\n        if (ost->st->codec->pix_fmt == PIX_FMT_NONE)\n\n            return NULL;\n\n        ost->pix_fmts[0] = ost->st->codec->pix_fmt;\n\n        return ost->pix_fmts;\n\n    }\n\n    if (ost->st->codec->pix_fmt != PIX_FMT_NONE) {\n\n        return av_strdup(av_get_pix_fmt_name(choose_pixel_fmt(ost->st, ost->enc, ost->st->codec->pix_fmt)));\n\n    } else if (ost->enc->pix_fmts) {\n\n        const enum PixelFormat *p;\n\n        AVIOContext *s = NULL;\n\n        uint8_t *ret;\n\n        int len;\n\n\n\n        if (avio_open_dyn_buf(&s) < 0)\n\n            exit_program(1);\n\n\n\n        p = ost->enc->pix_fmts;\n\n        if (ost->st->codec->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL) {\n\n            if (ost->st->codec->codec_id == CODEC_ID_MJPEG) {\n\n                p = (const enum PixelFormat[]) { PIX_FMT_YUVJ420P, PIX_FMT_YUVJ422P, PIX_FMT_YUV420P, PIX_FMT_YUV422P, PIX_FMT_NONE };\n\n            } else if (ost->st->codec->codec_id == CODEC_ID_LJPEG) {\n\n                p = (const enum PixelFormat[]) { PIX_FMT_YUVJ420P, PIX_FMT_YUVJ422P, PIX_FMT_YUVJ444P, PIX_FMT_YUV420P,\n\n                                                    PIX_FMT_YUV422P, PIX_FMT_YUV444P, PIX_FMT_BGRA, PIX_FMT_NONE };\n\n            }\n\n        }\n\n\n\n        for (; *p != PIX_FMT_NONE; p++)\n\n            avio_printf(s, \"%s:\", av_get_pix_fmt_name(*p));\n\n        len = avio_close_dyn_buf(s, &ret);\n\n        ret[len - 1] = 0;\n\n        return ret;\n\n    } else\n\n        return NULL;\n\n}\n", "idx": 16693, "_split": "test", "_hash": "7764ad5fcbf00c9b548d522df43bd6ab"}
{"project": "FFmpeg", "commit_id": "5e2202d6f3ac2f3afd714a62437ca6b24f75c09f", "target": 1, "func": "static void mov_metadata_creation_time(AVMetadata **metadata, time_t time)\n\n{\n\n    char buffer[32];\n\n    if (time) {\n\n        time -= 2082844800;  /* seconds between 1904-01-01 and Epoch */\n\n        strftime(buffer, sizeof(buffer), \"%Y-%m-%d %H:%M:%S\", gmtime(&time));\n\n        av_metadata_set2(metadata, \"creation_time\", buffer, 0);\n\n    }\n\n}\n", "idx": 16700, "_split": "test", "_hash": "6516f854a51902ee024855302565b77b"}
{"project": "FFmpeg", "commit_id": "7cf22c79706d23d40d16cee37eb32d5797adcc2c", "target": 0, "func": "yuv2rgba64_full_1_c_template(SwsContext *c, const int32_t *buf0,\n\n                       const int32_t *ubuf[2], const int32_t *vbuf[2],\n\n                       const int32_t *abuf0, uint16_t *dest, int dstW,\n\n                       int uvalpha, int y, enum AVPixelFormat target, int hasAlpha, int eightbytes)\n\n{\n\n    const int32_t *ubuf0 = ubuf[0], *vbuf0 = vbuf[0];\n\n    int i;\n\n    int A = 0xffff<<14;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < dstW; i++) {\n\n            int Y  = (buf0[i]) >> 2;\n\n            int U  = (ubuf0[i] + (-128 << 11)) >> 2;\n\n            int V  = (vbuf0[i] + (-128 << 11)) >> 2;\n\n            int R, G, B;\n\n\n\n            Y -= c->yuv2rgb_y_offset;\n\n            Y *= c->yuv2rgb_y_coeff;\n\n            Y += 1 << 13;\n\n\n\n            if (hasAlpha) {\n\n                A = abuf0[i] << 11;\n\n\n\n                A += 1 << 13;\n\n            }\n\n\n\n            R = V * c->yuv2rgb_v2r_coeff;\n\n            G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n            B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n            output_pixel(&dest[0], av_clip_uintp2(R_B + Y, 30) >> 14);\n\n            output_pixel(&dest[1], av_clip_uintp2(  G + Y, 30) >> 14);\n\n            output_pixel(&dest[2], av_clip_uintp2(B_R + Y, 30) >> 14);\n\n            if (eightbytes) {\n\n                output_pixel(&dest[3], av_clip_uintp2(A, 30) >> 14);\n\n                dest += 4;\n\n            } else {\n\n                dest += 3;\n\n            }\n\n        }\n\n    } else {\n\n        const int32_t *ubuf1 = ubuf[1], *vbuf1 = vbuf[1];\n\n        int A = 0xffff<<14;\n\n        for (i = 0; i < dstW; i++) {\n\n            int Y  = (buf0[i]    ) >> 2;\n\n            int U  = (ubuf0[i] + ubuf1[i] + (-128 << 12)) >> 3;\n\n            int V  = (vbuf0[i] + vbuf1[i] + (-128 << 12)) >> 3;\n\n            int R, G, B;\n\n\n\n            Y -= c->yuv2rgb_y_offset;\n\n            Y *= c->yuv2rgb_y_coeff;\n\n            Y += 1 << 13;\n\n\n\n            if (hasAlpha) {\n\n                A = abuf0[i] << 11;\n\n\n\n                A += 1 << 13;\n\n            }\n\n\n\n            R = V * c->yuv2rgb_v2r_coeff;\n\n            G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n            B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n            output_pixel(&dest[0], av_clip_uintp2(R_B + Y, 30) >> 14);\n\n            output_pixel(&dest[1], av_clip_uintp2(  G + Y, 30) >> 14);\n\n            output_pixel(&dest[2], av_clip_uintp2(B_R + Y, 30) >> 14);\n\n            if (eightbytes) {\n\n                output_pixel(&dest[3], av_clip_uintp2(A, 30) >> 14);\n\n                dest += 4;\n\n            } else {\n\n                dest += 3;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 16727, "_split": "test", "_hash": "202b55b3e8325eed8f933b573d763f1c"}
{"project": "FFmpeg", "commit_id": "d0dce15da34c0e4eee6c683be299de0221db00d3", "target": 1, "func": "static int parse_palette(AVCodecContext *avctx, GetByteContext *gbc,\n\n                         uint32_t *pal, int colors)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i <= colors; i++) {\n\n        uint8_t r, g, b;\n\n        unsigned int idx = bytestream2_get_be16(gbc); /* color index */\n\n        if (idx > 255) {\n\n            av_log(avctx, AV_LOG_WARNING,\n\n                   \"Palette index out of range: %u\\n\", idx);\n\n            bytestream2_skip(gbc, 6);\n\n            continue;\n\n        }\n\n        r = bytestream2_get_byte(gbc);\n\n        bytestream2_skip(gbc, 1);\n\n        g = bytestream2_get_byte(gbc);\n\n        bytestream2_skip(gbc, 1);\n\n        b = bytestream2_get_byte(gbc);\n\n        bytestream2_skip(gbc, 1);\n\n        pal[idx] = (r << 16) | (g << 8) | b;\n\n    }\n\n    return 0;\n\n}\n", "idx": 16755, "_split": "test", "_hash": "3dc4138df2c239008164261215b80eb6"}
{"project": "FFmpeg", "commit_id": "92e483f8ed70d88d4f64337f65bae212502735d4", "target": 1, "func": "static int compare_int64(const void *a, const void *b)\n\n{\n\n    int64_t va = *(int64_t *)a, vb = *(int64_t *)b;\n\n    return va < vb ? -1 : va > vb ? +1 : 0;\n\n}\n", "idx": 16767, "_split": "test", "_hash": "bbad7b66df2efcaa146c568e4381e9db"}
{"project": "FFmpeg", "commit_id": "f6687bf5f8989d397cdef6d9d05bcb13a7ef8c4f", "target": 0, "func": "void av_xtea_crypt(AVXTEA *ctx, uint8_t *dst, const uint8_t *src, int count,\n\n                   uint8_t *iv, int decrypt)\n\n{\n\n    int i;\n\n\n\n    while (count > 0) {\n\n        if (decrypt) {\n\n            xtea_crypt_ecb(ctx, dst, src, decrypt);\n\n\n\n            if (iv) {\n\n                for (i = 0; i < 8; i++)\n\n                    dst[i] = dst[i] ^ iv[i];\n\n                memcpy(iv, src, 8);\n\n            }\n\n        } else {\n\n            if (iv) {\n\n                for (i = 0; i < 8; i++)\n\n                    dst[i] = src[i] ^ iv[i];\n\n                xtea_crypt_ecb(ctx, dst, dst, decrypt);\n\n                memcpy(iv, dst, 8);\n\n            } else {\n\n                xtea_crypt_ecb(ctx, dst, src, decrypt);\n\n            }\n\n        }\n\n\n\n        src   += 8;\n\n        dst   += 8;\n\n        count -= 8;\n\n    }\n\n}\n", "idx": 16795, "_split": "test", "_hash": "89448cec055a7fbf7090230e719c00b3"}
{"project": "FFmpeg", "commit_id": "6241e8a3821d971755217652dff01f3a45580820", "target": 0, "func": "static void read_chapter(AVFormatContext *s, AVIOContext *pb, int len, char *ttag, ID3v2ExtraMeta **extra_meta)\n\n{\n\n    AVRational time_base = {1, 1000};\n\n    uint32_t start, end;\n\n    AVChapter *chapter;\n\n    uint8_t *dst = NULL;\n\n    int taglen;\n\n    char tag[5];\n\n\n\n    decode_str(s, pb, 0, &dst, &len);\n\n    if (len < 16)\n\n        return;\n\n\n\n    start = avio_rb32(pb);\n\n    end   = avio_rb32(pb);\n\n    avio_skip(pb, 8);\n\n\n\n    chapter = avpriv_new_chapter(s, s->nb_chapters + 1, time_base, start, end, dst);\n\n    if (!chapter) {\n\n        av_free(dst);\n\n        return;\n\n    }\n\n\n\n    len -= 16;\n\n    while (len > 10) {\n\n        avio_read(pb, tag, 4);\n\n        tag[4] = 0;\n\n        taglen = avio_rb32(pb);\n\n        avio_skip(pb, 2);\n\n        len -= 10;\n\n        if (taglen < 0 || taglen > len) {\n\n            av_free(dst);\n\n            return;\n\n        }\n\n        if (tag[0] == 'T')\n\n            read_ttag(s, pb, taglen, &chapter->metadata, tag);\n\n        else\n\n            avio_skip(pb, taglen);\n\n        len -= taglen;\n\n    }\n\n\n\n    ff_metadata_conv(&chapter->metadata, NULL, ff_id3v2_34_metadata_conv);\n\n    ff_metadata_conv(&chapter->metadata, NULL, ff_id3v2_4_metadata_conv);\n\n    av_free(dst);\n\n}\n", "idx": 16808, "_split": "test", "_hash": "7ca159143f876546b2ea6339c84ffafe"}
{"project": "FFmpeg", "commit_id": "b00fb157bae79f9735910064585fd95b8c123003", "target": 0, "func": "static int decode_sgirle8(AVCodecContext *avctx, uint8_t *dst, const uint8_t *src, int src_size, int width, int height, int linesize)\n\n{\n\n    const uint8_t *src_end = src + src_size;\n\n    int x = 0, y = 0;\n\n\n\n#define INC_XY(n) \\\n\n    x += n; \\\n\n    if (x >= width) { \\\n\n        y++; \\\n\n        if (y >= height) \\\n\n            return 0; \\\n\n        x = 0; \\\n\n    }\n\n\n\n    while (src_end - src >= 2) {\n\n        uint8_t v = *src++;\n\n        if (v > 0 && v < 0xC0) {\n\n            do {\n\n                int length = FFMIN(v, width - x);\n\n                memset(dst + y*linesize + x, RGB332_TO_BGR8(*src), length);\n\n                INC_XY(length);\n\n                v   -= length;\n\n            } while (v > 0);\n\n            src++;\n\n        } else if (v >= 0xC1) {\n\n            v -= 0xC0;\n\n            do {\n\n                int length = FFMIN3(v, width - x, src_end - src);\n\n                if (src_end - src < length)\n\n                    break;\n\n                memcpy_rgb332_to_bgr8(dst + y*linesize + x, src, length);\n\n                INC_XY(length);\n\n                src += length;\n\n                v   -= length;\n\n            } while (v > 0);\n\n        } else {\n\n            avpriv_request_sample(avctx, \"opcode %d\", v);\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 16984, "_split": "test", "_hash": "972e236a9e69416a2747c7ea8de9fd90"}
{"project": "FFmpeg", "commit_id": "9aa0606e87a221eba935ed675c1cd5ca94832e28", "target": 0, "func": "static int hls_read_seek(AVFormatContext *s, int stream_index,\n\n                               int64_t timestamp, int flags)\n\n{\n\n    HLSContext *c = s->priv_data;\n\n    int i;\n\n    int64_t seek_timestamp;\n\n    int valid_for = -1;\n\n\n\n    if ((flags & AVSEEK_FLAG_BYTE) || !c->variants[0]->playlists[0]->finished)\n\n        return AVERROR(ENOSYS);\n\n\n\n    seek_timestamp = stream_index < 0 ? timestamp :\n\n                     av_rescale_rnd(timestamp, AV_TIME_BASE,\n\n                                    s->streams[stream_index]->time_base.den,\n\n                                    flags & AVSEEK_FLAG_BACKWARD ?\n\n                                    AV_ROUND_DOWN : AV_ROUND_UP);\n\n\n\n    if (s->duration < seek_timestamp)\n\n        return AVERROR(EIO);\n\n\n\n    for (i = 0; i < c->n_playlists; i++) {\n\n        /* check first that the timestamp is valid for some playlist */\n\n        struct playlist *pls = c->playlists[i];\n\n        int seq_no;\n\n        if (find_timestamp_in_playlist(c, pls, seek_timestamp, &seq_no)) {\n\n            /* set segment now so we do not need to search again below */\n\n            pls->cur_seq_no = seq_no;\n\n            valid_for = i;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (valid_for < 0)\n\n        return AVERROR(EIO);\n\n\n\n    for (i = 0; i < c->n_playlists; i++) {\n\n        /* Reset reading */\n\n        struct playlist *pls = c->playlists[i];\n\n        if (pls->input) {\n\n            ffurl_close(pls->input);\n\n            pls->input = NULL;\n\n        }\n\n        av_free_packet(&pls->pkt);\n\n        reset_packet(&pls->pkt);\n\n        pls->pb.eof_reached = 0;\n\n        /* Clear any buffered data */\n\n        pls->pb.buf_end = pls->pb.buf_ptr = pls->pb.buffer;\n\n        /* Reset the pos, to let the mpegts demuxer know we've seeked. */\n\n        pls->pb.pos = 0;\n\n\n\n        pls->seek_timestamp = seek_timestamp;\n\n        pls->seek_flags = flags;\n\n\n\n        /* set closest segment seq_no for playlists not handled above */\n\n        if (valid_for != i)\n\n            find_timestamp_in_playlist(c, pls, seek_timestamp, &pls->cur_seq_no);\n\n    }\n\n\n\n    c->cur_timestamp = seek_timestamp;\n\n\n\n    return 0;\n\n}\n", "idx": 16986, "_split": "test", "_hash": "fd4ee5d86db3145f7271a35c7eaa02b4"}
{"project": "FFmpeg", "commit_id": "1e901ffc619459944ae7102428f48972cd899caa", "target": 0, "func": "static int64_t wrap_timestamp(AVStream *st, int64_t timestamp)\n\n{\n\n    if (st->pts_wrap_behavior != AV_PTS_WRAP_IGNORE && st->pts_wrap_bits < 64 &&\n\n        st->pts_wrap_reference != AV_NOPTS_VALUE && timestamp != AV_NOPTS_VALUE) {\n\n        if (st->pts_wrap_behavior == AV_PTS_WRAP_ADD_OFFSET &&\n\n            timestamp < st->pts_wrap_reference)\n\n            return timestamp + (1ULL<<st->pts_wrap_bits);\n\n        else if (st->pts_wrap_behavior == AV_PTS_WRAP_SUB_OFFSET &&\n\n            timestamp >= st->pts_wrap_reference)\n\n            return timestamp - (1ULL<<st->pts_wrap_bits);\n\n    }\n\n    return timestamp;\n\n}\n", "idx": 17009, "_split": "test", "_hash": "f527ea7e8c7585e2ebe0cd4722434244"}
{"project": "FFmpeg", "commit_id": "bb6f51aeab88a252cf08f5a0ec26ab41ae2d74a2", "target": 1, "func": "static void mpeg1_encode_sequence_header(MpegEncContext *s)\n\n{\n\n        unsigned int vbv_buffer_size;\n\n        unsigned int fps, v;\n\n        int n;\n\n        UINT64 time_code;\n\n        \n\n        if ((s->picture_number % s->gop_size) == 0) {\n\n            /* mpeg1 header repeated every gop */\n\n            put_header(s, SEQ_START_CODE);\n\n            \n\n            /* search closest frame rate */\n\n            {\n\n                int i, dmin, d;\n\n                s->frame_rate_index = 0;\n\n                dmin = 0x7fffffff;\n\n                for(i=1;i<9;i++) {\n\n                    d = abs(s->frame_rate - frame_rate_tab[i]);\n\n                    if (d < dmin) {\n\n                        dmin = d;\n\n                        s->frame_rate_index = i;\n\n                    }\n\n                }\n\n            }\n\n \n\n            put_bits(&s->pb, 12, s->width);\n\n            put_bits(&s->pb, 12, s->height);\n\n            put_bits(&s->pb, 4, 1); /* 1/1 aspect ratio */\n\n            put_bits(&s->pb, 4, s->frame_rate_index);\n\n            v = s->bit_rate / 400;\n\n            if (v > 0x3ffff)\n\n                v = 0x3ffff;\n\n            put_bits(&s->pb, 18, v);\n\n            put_bits(&s->pb, 1, 1); /* marker */\n\n            /* vbv buffer size: slightly greater than an I frame. We add\n\n               some margin just in case */\n\n            vbv_buffer_size = (3 * s->I_frame_bits) / (2 * 8);\n\n            put_bits(&s->pb, 10, (vbv_buffer_size + 16383) / 16384); \n\n            put_bits(&s->pb, 1, 1); /* constrained parameter flag */\n\n            put_bits(&s->pb, 1, 0); /* no custom intra matrix */\n\n            put_bits(&s->pb, 1, 0); /* no custom non intra matrix */\n\n\n\n            put_header(s, GOP_START_CODE);\n\n            put_bits(&s->pb, 1, 0); /* do drop frame */\n\n            /* time code : we must convert from the real frame rate to a\n\n               fake mpeg frame rate in case of low frame rate */\n\n            fps = frame_rate_tab[s->frame_rate_index];\n\n            time_code = s->fake_picture_number * FRAME_RATE_BASE;\n\n            s->gop_picture_number = s->fake_picture_number;\n\n            put_bits(&s->pb, 5, (UINT32)((time_code / (fps * 3600)) % 24));\n\n            put_bits(&s->pb, 6, (UINT32)((time_code / (fps * 60)) % 60));\n\n            put_bits(&s->pb, 1, 1);\n\n            put_bits(&s->pb, 6, (UINT32)((time_code / fps) % 60));\n\n            put_bits(&s->pb, 6, (UINT32)((time_code % fps) / FRAME_RATE_BASE));\n\n            put_bits(&s->pb, 1, 1); /* closed gop */\n\n            put_bits(&s->pb, 1, 0); /* broken link */\n\n        }\n\n\n\n        if (s->frame_rate < (24 * FRAME_RATE_BASE) && s->picture_number > 0) {\n\n            /* insert empty P pictures to slow down to the desired\n\n               frame rate. Each fake pictures takes about 20 bytes */\n\n            fps = frame_rate_tab[s->frame_rate_index];\n\n            n = ((s->picture_number * fps) / s->frame_rate) - 1;\n\n            while (s->fake_picture_number < n) {\n\n                mpeg1_skip_picture(s, s->fake_picture_number - \n\n                                   s->gop_picture_number); \n\n                s->fake_picture_number++;\n\n            }\n\n\n\n        }\n\n        s->fake_picture_number++;\n\n}\n", "idx": 17113, "_split": "test", "_hash": "95c91dc78c7c7e62627a95bfd5b198c5"}
{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "void ff_put_h264_qpel4_mc33_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_4w_msa(src + stride - 2,\n\n                           src - (stride * 2) +\n\n                           sizeof(uint8_t), stride, dst, stride, 4);\n\n}\n", "idx": 17118, "_split": "test", "_hash": "d09fc674048e9ff756ceb7662274c6c7"}
{"project": "FFmpeg", "commit_id": "57cd2f7777a316a447301a7d4b5d1c01da200661", "target": 0, "func": "static av_cold int mpeg_mux_init(AVFormatContext *ctx)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    int bitrate, i, mpa_id, mpv_id, h264_id, mps_id, ac3_id, dts_id, lpcm_id, j;\n\n    AVStream *st;\n\n    StreamInfo *stream;\n\n    int audio_bitrate;\n\n    int video_bitrate;\n\n\n\n    s->packet_number = 0;\n\n    s->is_vcd   =  (CONFIG_MPEG1VCD_MUXER  && ctx->oformat == &ff_mpeg1vcd_muxer);\n\n    s->is_svcd  =  (CONFIG_MPEG2SVCD_MUXER && ctx->oformat == &ff_mpeg2svcd_muxer);\n\n    s->is_mpeg2 = ((CONFIG_MPEG2VOB_MUXER  && ctx->oformat == &ff_mpeg2vob_muxer) ||\n\n                   (CONFIG_MPEG2DVD_MUXER  && ctx->oformat == &ff_mpeg2dvd_muxer) ||\n\n                   (CONFIG_MPEG2SVCD_MUXER && ctx->oformat == &ff_mpeg2svcd_muxer));\n\n    s->is_dvd   =  (CONFIG_MPEG2DVD_MUXER  && ctx->oformat == &ff_mpeg2dvd_muxer);\n\n\n\n    if (ctx->packet_size) {\n\n        if (ctx->packet_size < 20 || ctx->packet_size > (1 << 23) + 10) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Invalid packet size %d\\n\",\n\n                   ctx->packet_size);\n\n            goto fail;\n\n        }\n\n        s->packet_size = ctx->packet_size;\n\n    } else\n\n        s->packet_size = 2048;\n\n    if (ctx->max_delay < 0)     /* Not set by the caller */\n\n        ctx->max_delay = AV_TIME_BASE*7/10;\n\n\n\n    s->vcd_padding_bytes_written = 0;\n\n    s->vcd_padding_bitrate_num   = 0;\n\n\n\n    s->audio_bound = 0;\n\n    s->video_bound = 0;\n\n\n\n    mpa_id  = AUDIO_ID;\n\n    ac3_id  = AC3_ID;\n\n    dts_id  = DTS_ID;\n\n    mpv_id  = VIDEO_ID;\n\n    h264_id = H264_ID;\n\n    mps_id  = SUB_ID;\n\n    lpcm_id = LPCM_ID;\n\n\n\n    for (i = 0; i < ctx->nb_streams; i++) {\n\n        st     = ctx->streams[i];\n\n        stream = av_mallocz(sizeof(StreamInfo));\n\n        if (!stream)\n\n            goto fail;\n\n        st->priv_data = stream;\n\n\n\n        avpriv_set_pts_info(st, 64, 1, 90000);\n\n\n\n        switch (st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            if (!s->is_mpeg2 &&\n\n                (st->codec->codec_id == AV_CODEC_ID_AC3 ||\n\n                 st->codec->codec_id == AV_CODEC_ID_DTS ||\n\n                 st->codec->codec_id == AV_CODEC_ID_PCM_S16BE))\n\n                 av_log(ctx, AV_LOG_WARNING,\n\n                        \"%s in MPEG-1 system streams is not widely supported, \"\n\n                        \"consider using the vob or the dvd muxer \"\n\n                        \"to force a MPEG-2 program stream.\\n\",\n\n                        avcodec_get_name(st->codec->codec_id));\n\n            if (st->codec->codec_id == AV_CODEC_ID_AC3) {\n\n                stream->id = ac3_id++;\n\n            } else if (st->codec->codec_id == AV_CODEC_ID_DTS) {\n\n                stream->id = dts_id++;\n\n            } else if (st->codec->codec_id == AV_CODEC_ID_PCM_S16BE) {\n\n                stream->id = lpcm_id++;\n\n                for (j = 0; j < 4; j++) {\n\n                    if (lpcm_freq_tab[j] == st->codec->sample_rate)\n\n                        break;\n\n                }\n\n                if (j == 4)\n\n                    goto fail;\n\n                if (st->codec->channels > 8)\n\n                    return -1;\n\n                stream->lpcm_header[0] = 0x0c;\n\n                stream->lpcm_header[1] = (st->codec->channels - 1) | (j << 4);\n\n                stream->lpcm_header[2] = 0x80;\n\n                stream->lpcm_align     = st->codec->channels * 2;\n\n            } else {\n\n                stream->id = mpa_id++;\n\n            }\n\n\n\n            /* This value HAS to be used for VCD (see VCD standard, p. IV-7).\n\n             * Right now it is also used for everything else. */\n\n            stream->max_buffer_size = 4 * 1024;\n\n            s->audio_bound++;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if (st->codec->codec_id == AV_CODEC_ID_H264)\n\n                stream->id = h264_id++;\n\n            else\n\n                stream->id = mpv_id++;\n\n            if (st->codec->rc_buffer_size)\n\n                stream->max_buffer_size = 6 * 1024 + st->codec->rc_buffer_size / 8;\n\n            else {\n\n                av_log(ctx, AV_LOG_WARNING,\n\n                       \"VBV buffer size not set, using default size of 130KB\\n\"\n\n                       \"If you want the mpeg file to be compliant to some specification\\n\"\n\n                       \"Like DVD, VCD or others, make sure you set the correct buffer size\\n\");\n\n                // FIXME: this is probably too small as default\n\n                stream->max_buffer_size = 230 * 1024;\n\n            }\n\n            if (stream->max_buffer_size > 1024 * 8191) {\n\n                av_log(ctx, AV_LOG_WARNING, \"buffer size %d, too large\\n\", stream->max_buffer_size);\n\n                stream->max_buffer_size = 1024 * 8191;\n\n            }\n\n            s->video_bound++;\n\n            break;\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            stream->id              = mps_id++;\n\n            stream->max_buffer_size = 16 * 1024;\n\n            break;\n\n        default:\n\n            return -1;\n\n        }\n\n        stream->fifo = av_fifo_alloc(16);\n\n        if (!stream->fifo)\n\n            goto fail;\n\n    }\n\n    bitrate       = 0;\n\n    audio_bitrate = 0;\n\n    video_bitrate = 0;\n\n    for (i = 0; i < ctx->nb_streams; i++) {\n\n        int codec_rate;\n\n        st     = ctx->streams[i];\n\n        stream = (StreamInfo *)st->priv_data;\n\n\n\n        if (st->codec->rc_max_rate ||\n\n            st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            codec_rate = st->codec->rc_max_rate;\n\n        else\n\n            codec_rate = st->codec->bit_rate;\n\n\n\n        if (!codec_rate)\n\n            codec_rate = (1 << 21) * 8 * 50 / ctx->nb_streams;\n\n\n\n        bitrate += codec_rate;\n\n\n\n        if ((stream->id & 0xe0) == AUDIO_ID)\n\n            audio_bitrate += codec_rate;\n\n        else if (st->codec->codec_type == AVMEDIA_TYPE_VIDEO)\n\n            video_bitrate += codec_rate;\n\n    }\n\n\n\n    if (s->user_mux_rate) {\n\n        s->mux_rate = (s->user_mux_rate + (8 * 50) - 1) / (8 * 50);\n\n    } else {\n\n        /* we increase slightly the bitrate to take into account the\n\n         * headers. XXX: compute it exactly */\n\n        bitrate    += bitrate / 20;\n\n        bitrate    += 10000;\n\n        s->mux_rate = (bitrate + (8 * 50) - 1) / (8 * 50);\n\n        if (s->mux_rate >= (1<<22)) {\n\n            av_log(ctx, AV_LOG_WARNING, \"mux rate %d is too large\\n\", s->mux_rate);\n\n            s->mux_rate = (1<<22) - 1;\n\n        }\n\n    }\n\n\n\n    if (s->is_vcd) {\n\n        int64_t overhead_rate;\n\n\n\n        /* The VCD standard mandates that the mux_rate field is 3528\n\n         * (see standard p. IV-6).\n\n         * The value is actually \"wrong\", i.e. if you calculate\n\n         * it using the normal formula and the 75 sectors per second transfer\n\n         * rate you get a different value because the real pack size is 2324,\n\n         * not 2352. But the standard explicitly specifies that the mux_rate\n\n         * field in the header must have this value. */\n\n        // s->mux_rate = 2352 * 75 / 50;    /* = 3528 */\n\n\n\n        /* The VCD standard states that the muxed stream must be\n\n         * exactly 75 packs / second (the data rate of a single speed cdrom).\n\n         * Since the video bitrate (probably 1150000 bits/sec) will be below\n\n         * the theoretical maximum we have to add some padding packets\n\n         * to make up for the lower data rate.\n\n         * (cf. VCD standard p. IV-6 ) */\n\n\n\n        /* Add the header overhead to the data rate.\n\n         * 2279 data bytes per audio pack, 2294 data bytes per video pack */\n\n        overhead_rate  = audio_bitrate * 2294LL * (2324 - 2279);\n\n        overhead_rate += video_bitrate * 2279LL * (2324 - 2294);\n\n\n\n        /* Add padding so that the full bitrate is 2324*75 bytes/sec */\n\n        s->vcd_padding_bitrate_num = (2324LL * 75 * 8 - bitrate) * 2279 * 2294 - overhead_rate;\n\n#define VCD_PADDING_BITRATE_DEN (2279 * 2294)\n\n    }\n\n\n\n    if (s->is_vcd || s->is_mpeg2)\n\n        /* every packet */\n\n        s->pack_header_freq = 1;\n\n    else\n\n        /* every 2 seconds */\n\n        s->pack_header_freq = 2 * bitrate / s->packet_size / 8;\n\n\n\n    /* the above seems to make pack_header_freq zero sometimes */\n\n    if (s->pack_header_freq == 0)\n\n        s->pack_header_freq = 1;\n\n\n\n    if (s->is_mpeg2)\n\n        /* every 200 packets. Need to look at the spec.  */\n\n        s->system_header_freq = s->pack_header_freq * 40;\n\n    else if (s->is_vcd)\n\n        /* the standard mandates that there are only two system headers\n\n         * in the whole file: one in the first packet of each stream.\n\n         * (see standard p. IV-7 and IV-8) */\n\n        s->system_header_freq = 0x7fffffff;\n\n    else\n\n        s->system_header_freq = s->pack_header_freq * 5;\n\n\n\n    for (i = 0; i < ctx->nb_streams; i++) {\n\n        stream                = ctx->streams[i]->priv_data;\n\n        stream->packet_number = 0;\n\n    }\n\n    s->system_header_size = get_system_header_size(ctx);\n\n    s->last_scr           = AV_NOPTS_VALUE;\n\n    return 0;\n\n\n\nfail:\n\n    for (i = 0; i < ctx->nb_streams; i++)\n\n        av_freep(&ctx->streams[i]->priv_data);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 17120, "_split": "test", "_hash": "ecfd055cd7e3fa028435b877722dd5ea"}
{"project": "FFmpeg", "commit_id": "28f9ab7029bd1a02f659995919f899f84ee7361b", "target": 0, "func": "static void dsputil_init_mmx2(DSPContext *c, AVCodecContext *avctx,\n\n                              int mm_flags)\n\n{\n\n    const int bit_depth      = avctx->bits_per_raw_sample;\n\n    const int high_bit_depth = bit_depth > 8;\n\n\n\n    c->prefetch = prefetch_mmx2;\n\n\n\n    if (!high_bit_depth) {\n\n        c->put_pixels_tab[0][1] = put_pixels16_x2_mmx2;\n\n        c->put_pixels_tab[0][2] = put_pixels16_y2_mmx2;\n\n\n\n        c->avg_pixels_tab[0][0] = avg_pixels16_mmx2;\n\n        c->avg_pixels_tab[0][1] = avg_pixels16_x2_mmx2;\n\n        c->avg_pixels_tab[0][2] = avg_pixels16_y2_mmx2;\n\n\n\n        c->put_pixels_tab[1][1] = put_pixels8_x2_mmx2;\n\n        c->put_pixels_tab[1][2] = put_pixels8_y2_mmx2;\n\n\n\n        c->avg_pixels_tab[1][0] = avg_pixels8_mmx2;\n\n        c->avg_pixels_tab[1][1] = avg_pixels8_x2_mmx2;\n\n        c->avg_pixels_tab[1][2] = avg_pixels8_y2_mmx2;\n\n    }\n\n\n\n    if (!(avctx->flags & CODEC_FLAG_BITEXACT)) {\n\n        if (!high_bit_depth) {\n\n            c->put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_mmx2;\n\n            c->put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_mmx2;\n\n            c->put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels8_x2_mmx2;\n\n            c->put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels8_y2_mmx2;\n\n\n\n            c->avg_pixels_tab[0][3] = avg_pixels16_xy2_mmx2;\n\n            c->avg_pixels_tab[1][3] = avg_pixels8_xy2_mmx2;\n\n        }\n\n\n\n        if (CONFIG_VP3_DECODER && HAVE_YASM) {\n\n            c->vp3_v_loop_filter = ff_vp3_v_loop_filter_mmx2;\n\n            c->vp3_h_loop_filter = ff_vp3_h_loop_filter_mmx2;\n\n        }\n\n    }\n\n    if (CONFIG_VP3_DECODER && HAVE_YASM)\n\n        c->vp3_idct_dc_add = ff_vp3_idct_dc_add_mmx2;\n\n\n\n    if (CONFIG_VP3_DECODER && (avctx->codec_id == CODEC_ID_VP3 ||\n\n                               avctx->codec_id == CODEC_ID_THEORA)) {\n\n        c->put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels8_x2_exact_mmx2;\n\n        c->put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels8_y2_exact_mmx2;\n\n    }\n\n\n\n    if (CONFIG_H264QPEL) {\n\n        SET_QPEL_FUNCS(put_qpel,        0, 16, mmx2, );\n\n        SET_QPEL_FUNCS(put_qpel,        1,  8, mmx2, );\n\n        SET_QPEL_FUNCS(put_no_rnd_qpel, 0, 16, mmx2, );\n\n        SET_QPEL_FUNCS(put_no_rnd_qpel, 1,  8, mmx2, );\n\n        SET_QPEL_FUNCS(avg_qpel,        0, 16, mmx2, );\n\n        SET_QPEL_FUNCS(avg_qpel,        1,  8, mmx2, );\n\n\n\n        if (!high_bit_depth) {\n\n            SET_QPEL_FUNCS(put_h264_qpel, 0, 16, mmx2, );\n\n            SET_QPEL_FUNCS(put_h264_qpel, 1,  8, mmx2, );\n\n            SET_QPEL_FUNCS(put_h264_qpel, 2,  4, mmx2, );\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 0, 16, mmx2, );\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 1,  8, mmx2, );\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 2,  4, mmx2, );\n\n        } else if (bit_depth == 10) {\n\n#if HAVE_YASM\n\n#if !ARCH_X86_64\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 0, 16, 10_mmxext, ff_);\n\n            SET_QPEL_FUNCS(put_h264_qpel, 0, 16, 10_mmxext, ff_);\n\n            SET_QPEL_FUNCS(put_h264_qpel, 1,  8, 10_mmxext, ff_);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 1,  8, 10_mmxext, ff_);\n\n#endif\n\n            SET_QPEL_FUNCS(put_h264_qpel, 2, 4,  10_mmxext, ff_);\n\n            SET_QPEL_FUNCS(avg_h264_qpel, 2, 4,  10_mmxext, ff_);\n\n#endif\n\n        }\n\n\n\n        SET_QPEL_FUNCS(put_2tap_qpel, 0, 16, mmx2, );\n\n        SET_QPEL_FUNCS(put_2tap_qpel, 1,  8, mmx2, );\n\n        SET_QPEL_FUNCS(avg_2tap_qpel, 0, 16, mmx2, );\n\n        SET_QPEL_FUNCS(avg_2tap_qpel, 1,  8, mmx2, );\n\n    }\n\n\n\n#if HAVE_YASM\n\n    if (!high_bit_depth && CONFIG_H264CHROMA) {\n\n        c->avg_h264_chroma_pixels_tab[0] = ff_avg_h264_chroma_mc8_mmx2_rnd;\n\n        c->avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_mmx2;\n\n        c->avg_h264_chroma_pixels_tab[2] = ff_avg_h264_chroma_mc2_mmx2;\n\n        c->put_h264_chroma_pixels_tab[2] = ff_put_h264_chroma_mc2_mmx2;\n\n    }\n\n    if (bit_depth == 10 && CONFIG_H264CHROMA) {\n\n        c->put_h264_chroma_pixels_tab[2] = ff_put_h264_chroma_mc2_10_mmxext;\n\n        c->avg_h264_chroma_pixels_tab[2] = ff_avg_h264_chroma_mc2_10_mmxext;\n\n        c->put_h264_chroma_pixels_tab[1] = ff_put_h264_chroma_mc4_10_mmxext;\n\n        c->avg_h264_chroma_pixels_tab[1] = ff_avg_h264_chroma_mc4_10_mmxext;\n\n    }\n\n\n\n    c->add_hfyu_median_prediction   = ff_add_hfyu_median_prediction_mmx2;\n\n\n\n    c->scalarproduct_int16          = ff_scalarproduct_int16_mmx2;\n\n    c->scalarproduct_and_madd_int16 = ff_scalarproduct_and_madd_int16_mmx2;\n\n\n\n    if (avctx->flags & CODEC_FLAG_BITEXACT) {\n\n        c->apply_window_int16 = ff_apply_window_int16_mmxext_ba;\n\n    } else {\n\n        c->apply_window_int16 = ff_apply_window_int16_mmxext;\n\n    }\n\n#endif\n\n}\n", "idx": 17124, "_split": "test", "_hash": "1741b57158df1adb655f656bed1fcd5f"}
{"project": "FFmpeg", "commit_id": "c8241e730f116f1c9cfc0b34110aa7f052e05332", "target": 0, "func": "static int vaapi_encode_h264_init_sequence_params(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext                 *ctx = avctx->priv_data;\n\n    VAEncSequenceParameterBufferH264  *vseq = ctx->codec_sequence_params;\n\n    VAEncPictureParameterBufferH264   *vpic = ctx->codec_picture_params;\n\n    VAAPIEncodeH264Context            *priv = ctx->priv_data;\n\n    VAAPIEncodeH264MiscSequenceParams *mseq = &priv->misc_sequence_params;\n\n    int i;\n\n\n\n    {\n\n        vseq->seq_parameter_set_id = 0;\n\n\n\n        vseq->level_idc = avctx->level;\n\n\n\n        vseq->max_num_ref_frames = 2;\n\n\n\n        vseq->picture_width_in_mbs  = priv->mb_width;\n\n        vseq->picture_height_in_mbs = priv->mb_height;\n\n\n\n        vseq->seq_fields.bits.chroma_format_idc = 1;\n\n        vseq->seq_fields.bits.frame_mbs_only_flag = 1;\n\n        vseq->seq_fields.bits.direct_8x8_inference_flag = 1;\n\n        vseq->seq_fields.bits.log2_max_frame_num_minus4 = 4;\n\n        vseq->seq_fields.bits.pic_order_cnt_type = 0;\n\n\n\n        if (ctx->input_width  != ctx->aligned_width ||\n\n            ctx->input_height != ctx->aligned_height) {\n\n            vseq->frame_cropping_flag = 1;\n\n\n\n            vseq->frame_crop_left_offset   = 0;\n\n            vseq->frame_crop_right_offset  =\n\n                (ctx->aligned_width - ctx->input_width) / 2;\n\n            vseq->frame_crop_top_offset    = 0;\n\n            vseq->frame_crop_bottom_offset =\n\n                (ctx->aligned_height - ctx->input_height) / 2;\n\n        } else {\n\n            vseq->frame_cropping_flag = 0;\n\n        }\n\n\n\n        vseq->vui_parameters_present_flag = 1;\n\n        if (avctx->sample_aspect_ratio.num != 0) {\n\n            vseq->vui_fields.bits.aspect_ratio_info_present_flag = 1;\n\n            // There is a large enum of these which we could support\n\n            // individually rather than using the generic X/Y form?\n\n            if (avctx->sample_aspect_ratio.num ==\n\n                avctx->sample_aspect_ratio.den) {\n\n                vseq->aspect_ratio_idc = 1;\n\n            } else {\n\n                vseq->aspect_ratio_idc = 255; // Extended SAR.\n\n                vseq->sar_width  = avctx->sample_aspect_ratio.num;\n\n                vseq->sar_height = avctx->sample_aspect_ratio.den;\n\n            }\n\n        }\n\n        if (avctx->color_primaries != AVCOL_PRI_UNSPECIFIED ||\n\n            avctx->color_trc       != AVCOL_TRC_UNSPECIFIED ||\n\n            avctx->colorspace      != AVCOL_SPC_UNSPECIFIED) {\n\n            mseq->video_signal_type_present_flag = 1;\n\n            mseq->video_format             = 5; // Unspecified.\n\n            mseq->video_full_range_flag    = 0;\n\n            mseq->colour_description_present_flag = 1;\n\n            // These enums are derived from the standard and hence\n\n            // we can just use the values directly.\n\n            mseq->colour_primaries         = avctx->color_primaries;\n\n            mseq->transfer_characteristics = avctx->color_trc;\n\n            mseq->matrix_coefficients      = avctx->colorspace;\n\n        }\n\n\n\n        vseq->bits_per_second = avctx->bit_rate;\n\n\n\n        vseq->vui_fields.bits.timing_info_present_flag = 1;\n\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0) {\n\n            vseq->num_units_in_tick = avctx->framerate.num;\n\n            vseq->time_scale        = 2 * avctx->framerate.den;\n\n            mseq->fixed_frame_rate_flag = 1;\n\n        } else {\n\n            vseq->num_units_in_tick = avctx->time_base.num;\n\n            vseq->time_scale        = 2 * avctx->time_base.den;\n\n            mseq->fixed_frame_rate_flag = 0;\n\n        }\n\n\n\n        if (ctx->va_rc_mode == VA_RC_CBR) {\n\n            priv->send_timing_sei = 1;\n\n            mseq->nal_hrd_parameters_present_flag = 1;\n\n\n\n            mseq->cpb_cnt_minus1 = 0;\n\n\n\n            // Try to scale these to a sensible range so that the\n\n            // golomb encode of the value is not overlong.\n\n            mseq->bit_rate_scale =\n\n                av_clip_uintp2(av_log2(avctx->bit_rate) - 15 - 6, 4);\n\n            mseq->bit_rate_value_minus1[0] =\n\n                (avctx->bit_rate >> mseq->bit_rate_scale + 6) - 1;\n\n\n\n            mseq->cpb_size_scale =\n\n                av_clip_uintp2(av_log2(priv->hrd_params.hrd.buffer_size) - 15 - 4, 4);\n\n            mseq->cpb_size_value_minus1[0] =\n\n                (priv->hrd_params.hrd.buffer_size >> mseq->cpb_size_scale + 4) - 1;\n\n\n\n            // CBR mode isn't actually available here, despite naming.\n\n            mseq->cbr_flag[0] = 0;\n\n\n\n            mseq->initial_cpb_removal_delay_length_minus1 = 23;\n\n            mseq->cpb_removal_delay_length_minus1         = 23;\n\n            mseq->dpb_output_delay_length_minus1          = 7;\n\n            mseq->time_offset_length = 0;\n\n\n\n            // This calculation can easily overflow 32 bits.\n\n            mseq->initial_cpb_removal_delay = 90000 *\n\n                (uint64_t)priv->hrd_params.hrd.initial_buffer_fullness /\n\n                priv->hrd_params.hrd.buffer_size;\n\n\n\n            mseq->initial_cpb_removal_delay_offset = 0;\n\n        } else {\n\n            priv->send_timing_sei = 0;\n\n            mseq->nal_hrd_parameters_present_flag = 0;\n\n        }\n\n\n\n        vseq->intra_period     = ctx->p_per_i * (ctx->b_per_p + 1);\n\n        vseq->intra_idr_period = vseq->intra_period;\n\n        vseq->ip_period        = ctx->b_per_p + 1;\n\n    }\n\n\n\n    {\n\n        vpic->CurrPic.picture_id = VA_INVALID_ID;\n\n        vpic->CurrPic.flags      = VA_PICTURE_H264_INVALID;\n\n\n\n        for (i = 0; i < FF_ARRAY_ELEMS(vpic->ReferenceFrames); i++) {\n\n            vpic->ReferenceFrames[i].picture_id = VA_INVALID_ID;\n\n            vpic->ReferenceFrames[i].flags      = VA_PICTURE_H264_INVALID;\n\n        }\n\n\n\n        vpic->coded_buf = VA_INVALID_ID;\n\n\n\n        vpic->pic_parameter_set_id = 0;\n\n        vpic->seq_parameter_set_id = 0;\n\n\n\n        vpic->num_ref_idx_l0_active_minus1 = 0;\n\n        vpic->num_ref_idx_l1_active_minus1 = 0;\n\n\n\n        vpic->pic_fields.bits.entropy_coding_mode_flag =\n\n            ((avctx->profile & 0xff) != 66);\n\n        vpic->pic_fields.bits.weighted_pred_flag = 0;\n\n        vpic->pic_fields.bits.weighted_bipred_idc = 0;\n\n        vpic->pic_fields.bits.transform_8x8_mode_flag =\n\n            ((avctx->profile & 0xff) >= 100);\n\n\n\n        vpic->pic_init_qp = priv->fixed_qp_idr;\n\n    }\n\n\n\n    {\n\n        mseq->profile_idc = avctx->profile & 0xff;\n\n\n\n        if (avctx->profile & FF_PROFILE_H264_CONSTRAINED)\n\n            mseq->constraint_set1_flag = 1;\n\n        if (avctx->profile & FF_PROFILE_H264_INTRA)\n\n            mseq->constraint_set3_flag = 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 17128, "_split": "test", "_hash": "fb371c79f0407defbafeacef855d63ff"}
{"project": "FFmpeg", "commit_id": "e62ef8f2dbf1ac0a197310f2be69c93b89f838c2", "target": 0, "func": "static av_cold void set_bandwidth(AC3EncodeContext *s, int cutoff)\n\n{\n\n    int ch, bw_code;\n\n\n\n    if (cutoff) {\n\n        /* calculate bandwidth based on user-specified cutoff frequency */\n\n        int fbw_coeffs;\n\n        cutoff         = av_clip(cutoff, 1, s->sample_rate >> 1);\n\n        fbw_coeffs     = cutoff * 2 * AC3_MAX_COEFS / s->sample_rate;\n\n        bw_code        = av_clip((fbw_coeffs - 73) / 3, 0, 60);\n\n    } else {\n\n        /* use default bandwidth setting */\n\n        /* XXX: should compute the bandwidth according to the frame\n\n           size, so that we avoid annoying high frequency artifacts */\n\n        bw_code = 50;\n\n    }\n\n\n\n    /* set number of coefficients for each channel */\n\n    for (ch = 0; ch < s->fbw_channels; ch++) {\n\n        s->bandwidth_code[ch] = bw_code;\n\n        s->nb_coefs[ch]       = bw_code * 3 + 73;\n\n    }\n\n    if (s->lfe_on)\n\n        s->nb_coefs[s->lfe_channel] = 7; /* LFE channel always has 7 coefs */\n\n}\n", "idx": 17203, "_split": "test", "_hash": "9f3ca52246271613d23d66ec6562c858"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuy2ToUV)(uint8_t *dstU, uint8_t *dstV, const uint8_t *src1, const uint8_t *src2, long width, uint32_t *unused)\n\n{\n\n#if COMPILE_TEMPLATE_MMX\n\n    __asm__ volatile(\n\n        \"movq \"MANGLE(bm01010101)\", %%mm4           \\n\\t\"\n\n        \"mov                    %0, %%\"REG_a\"       \\n\\t\"\n\n        \"1:                                         \\n\\t\"\n\n        \"movq    (%1, %%\"REG_a\",4), %%mm0           \\n\\t\"\n\n        \"movq   8(%1, %%\"REG_a\",4), %%mm1           \\n\\t\"\n\n        \"psrlw                  $8, %%mm0           \\n\\t\"\n\n        \"psrlw                  $8, %%mm1           \\n\\t\"\n\n        \"packuswb            %%mm1, %%mm0           \\n\\t\"\n\n        \"movq                %%mm0, %%mm1           \\n\\t\"\n\n        \"psrlw                  $8, %%mm0           \\n\\t\"\n\n        \"pand                %%mm4, %%mm1           \\n\\t\"\n\n        \"packuswb            %%mm0, %%mm0           \\n\\t\"\n\n        \"packuswb            %%mm1, %%mm1           \\n\\t\"\n\n        \"movd                %%mm0, (%3, %%\"REG_a\") \\n\\t\"\n\n        \"movd                %%mm1, (%2, %%\"REG_a\") \\n\\t\"\n\n        \"add                    $4, %%\"REG_a\"       \\n\\t\"\n\n        \" js                    1b                  \\n\\t\"\n\n        : : \"g\" ((x86_reg)-width), \"r\" (src1+width*4), \"r\" (dstU+width), \"r\" (dstV+width)\n\n        : \"%\"REG_a\n\n    );\n\n#else\n\n    int i;\n\n    for (i=0; i<width; i++) {\n\n        dstU[i]= src1[4*i + 1];\n\n        dstV[i]= src1[4*i + 3];\n\n    }\n\n#endif\n\n    assert(src1 == src2);\n\n}\n", "idx": 17206, "_split": "test", "_hash": "ac32f2e9cf890b6255bc50621e702ee8"}
{"project": "FFmpeg", "commit_id": "435535e41159fbe7423a12078d684329a554776d", "target": 1, "func": "static int read_header(AVFormatContext *s,\n\n                       AVFormatParameters *ap)\n\n{\n\n    JVDemuxContext *jv = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *vst, *ast;\n\n    int64_t audio_pts = 0;\n\n    int64_t offset;\n\n    int i;\n\n\n\n    avio_skip(pb, 80);\n\n\n\n    ast = av_new_stream(s, 0);\n\n    vst = av_new_stream(s, 1);\n\n    if (!ast || !vst)\n\n        return AVERROR(ENOMEM);\n\n\n\n    vst->codec->codec_type  = CODEC_TYPE_VIDEO;\n\n    vst->codec->codec_id    = CODEC_ID_JV;\n\n    vst->codec->codec_tag   = 0; /* no fourcc */\n\n    vst->codec->width       = avio_rl16(pb);\n\n    vst->codec->height      = avio_rl16(pb);\n\n    vst->nb_frames          =\n\n    ast->nb_index_entries   = avio_rl16(pb);\n\n    av_set_pts_info(vst, 64, avio_rl16(pb), 1000);\n\n\n\n    avio_skip(pb, 4);\n\n\n\n    ast->codec->codec_type  = CODEC_TYPE_AUDIO;\n\n    ast->codec->codec_id    = CODEC_ID_PCM_U8;\n\n    ast->codec->codec_tag   = 0; /* no fourcc */\n\n    ast->codec->sample_rate = avio_rl16(pb);\n\n    ast->codec->channels    = 1;\n\n    av_set_pts_info(ast, 64, 1, ast->codec->sample_rate);\n\n\n\n    avio_skip(pb, 10);\n\n\n\n    ast->index_entries = av_malloc(ast->nb_index_entries * sizeof(*ast->index_entries));\n\n    if (!ast->index_entries)\n\n        return AVERROR(ENOMEM);\n\n\n\n    jv->frames = av_malloc(ast->nb_index_entries * sizeof(JVFrame));\n\n    if (!jv->frames)\n\n        return AVERROR(ENOMEM);\n\n\n\n    offset = 0x68 + ast->nb_index_entries * 16;\n\n    for(i = 0; i < ast->nb_index_entries; i++) {\n\n        AVIndexEntry *e   = ast->index_entries + i;\n\n        JVFrame      *jvf = jv->frames + i;\n\n\n\n        /* total frame size including audio, video, palette data and padding */\n\n        e->size         = avio_rl32(pb);\n\n        e->timestamp    = i;\n\n        e->pos          = offset;\n\n        offset         += e->size;\n\n\n\n        jvf->audio_size = avio_rl32(pb);\n\n        jvf->video_size = avio_rl32(pb);\n\n        jvf->palette_size = avio_r8(pb) ? 768 : 0;\n\n\n\n        if (avio_r8(pb))\n\n             av_log(s, AV_LOG_WARNING, \"unsupported audio codec\\n\");\n\n        jvf->video_type = avio_r8(pb);\n\n        avio_skip(pb, 1);\n\n\n\n        e->timestamp = jvf->audio_size ? audio_pts : AV_NOPTS_VALUE;\n\n        audio_pts += jvf->audio_size;\n\n\n\n        e->flags = jvf->video_type != 1 ? AVINDEX_KEYFRAME : 0;\n\n    }\n\n\n\n    jv->state = JV_AUDIO;\n\n    return 0;\n\n}", "idx": 17280, "_split": "test", "_hash": "4fbb109215f5a7970e4d2f3fe1816013"}
{"project": "FFmpeg", "commit_id": "4fb3efd2c17c419cb7a170e5438b35453ceaaf30", "target": 0, "func": "static int mov_write_colr_tag(AVIOContext *pb, MOVTrack *track)\n\n{\n\n    // Ref (MOV): https://developer.apple.com/library/mac/technotes/tn2162/_index.html#//apple_ref/doc/uid/DTS40013070-CH1-TNTAG9\n\n    // Ref (MP4): ISO/IEC 14496-12:2012\n\n\n\n    if (track->enc->color_primaries == AVCOL_PRI_UNSPECIFIED &&\n\n        track->enc->color_trc == AVCOL_TRC_UNSPECIFIED &&\n\n        track->enc->colorspace == AVCOL_SPC_UNSPECIFIED) {\n\n        if ((track->enc->width >= 1920 && track->enc->height >= 1080)\n\n          || (track->enc->width == 1280 && track->enc->height == 720)) {\n\n            av_log(NULL, AV_LOG_WARNING, \"color primaries unspecified, assuming bt709\\n\");\n\n            track->enc->color_primaries = AVCOL_PRI_BT709;\n\n        } else if (track->enc->width == 720 && track->height == 576) {\n\n            av_log(NULL, AV_LOG_WARNING, \"color primaries unspecified, assuming bt470bg\\n\");\n\n            track->enc->color_primaries = AVCOL_PRI_BT470BG;\n\n        } else if (track->enc->width == 720 &&\n\n                   (track->height == 486 || track->height == 480)) {\n\n            av_log(NULL, AV_LOG_WARNING, \"color primaries unspecified, assuming smpte170\\n\");\n\n            track->enc->color_primaries = AVCOL_PRI_SMPTE170M;\n\n        } else {\n\n            av_log(NULL, AV_LOG_WARNING, \"color primaries unspecified, unable to assume anything\\n\");\n\n        }\n\n        switch (track->enc->color_primaries) {\n\n        case AVCOL_PRI_BT709:\n\n            track->enc->color_trc = AVCOL_TRC_BT709;\n\n            track->enc->colorspace = AVCOL_SPC_BT709;\n\n            break;\n\n        case AVCOL_PRI_SMPTE170M:\n\n        case AVCOL_PRI_BT470BG:\n\n            track->enc->color_trc = AVCOL_TRC_BT709;\n\n            track->enc->colorspace = AVCOL_SPC_SMPTE170M;\n\n            break;\n\n        }\n\n    }\n\n\n\n    /* We should only ever be called by MOV or MP4. */\n\n    av_assert0(track->mode == MODE_MOV || track->mode == MODE_MP4);\n\n\n\n    avio_wb32(pb, 18 + (track->mode == MODE_MP4));\n\n    ffio_wfourcc(pb, \"colr\");\n\n    if (track->mode == MODE_MP4)\n\n        ffio_wfourcc(pb, \"nclx\");\n\n    else\n\n        ffio_wfourcc(pb, \"nclc\");\n\n    switch (track->enc->color_primaries) {\n\n    case AVCOL_PRI_BT709:     avio_wb16(pb, 1); break;\n\n    case AVCOL_PRI_SMPTE170M:\n\n    case AVCOL_PRI_SMPTE240M: avio_wb16(pb, 6); break;\n\n    case AVCOL_PRI_BT470BG:   avio_wb16(pb, 5); break;\n\n    default:                  avio_wb16(pb, 2);\n\n    }\n\n    switch (track->enc->color_trc) {\n\n    case AVCOL_TRC_BT709:     avio_wb16(pb, 1); break;\n\n    case AVCOL_TRC_SMPTE170M: avio_wb16(pb, 1); break; // remapped\n\n    case AVCOL_TRC_SMPTE240M: avio_wb16(pb, 7); break;\n\n    default:                  avio_wb16(pb, 2);\n\n    }\n\n    switch (track->enc->colorspace) {\n\n    case AVCOL_TRC_BT709:     avio_wb16(pb, 1); break;\n\n    case AVCOL_SPC_BT470BG:\n\n    case AVCOL_PRI_SMPTE170M: avio_wb16(pb, 6); break;\n\n    case AVCOL_PRI_SMPTE240M: avio_wb16(pb, 7); break;\n\n    default:                  avio_wb16(pb, 2);\n\n    }\n\n\n\n    if (track->mode == MODE_MP4) {\n\n        int full_range = track->enc->color_range == AVCOL_RANGE_JPEG;\n\n        avio_w8(pb, full_range << 7);\n\n        return 19;\n\n    } else {\n\n        return 18;\n\n    }\n\n}\n", "idx": 17288, "_split": "test", "_hash": "f7c00a586aefb9727bb8c6e069bac048"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int get_last_needed_nal(H264Context *h, const uint8_t *buf, int buf_size)\n\n{\n\n    int next_avc    = h->is_avc ? 0 : buf_size;\n\n    int nal_index   = 0;\n\n    int buf_index   = 0;\n\n    int nals_needed = 0;\n\n\n\n    while(1) {\n\n        int nalsize = 0;\n\n        int dst_length, bit_length, consumed;\n\n        const uint8_t *ptr;\n\n\n\n        if (buf_index >= next_avc) {\n\n            nalsize = get_avc_nalsize(h, buf, buf_size, &buf_index);\n\n            if (nalsize < 0)\n\n                break;\n\n            next_avc = buf_index + nalsize;\n\n        } else {\n\n            buf_index = find_start_code(buf, buf_size, buf_index, next_avc);\n\n            if (buf_index >= buf_size)\n\n                break;\n\n        }\n\n\n\n        ptr = ff_h264_decode_nal(h, buf + buf_index, &dst_length, &consumed,\n\n                                 next_avc - buf_index);\n\n\n\n        if (ptr == NULL || dst_length < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        buf_index += consumed;\n\n\n\n        bit_length = get_bit_length(h, buf, ptr, dst_length,\n\n                                    buf_index, next_avc);\n\n        nal_index++;\n\n\n\n        /* packets can sometimes contain multiple PPS/SPS,\n\n         * e.g. two PAFF field pictures in one packet, or a demuxer\n\n         * which splits NALs strangely if so, when frame threading we\n\n         * can't start the next thread until we've read all of them */\n\n        switch (h->nal_unit_type) {\n\n        case NAL_SPS:\n\n        case NAL_PPS:\n\n            nals_needed = nal_index;\n\n            break;\n\n        case NAL_DPA:\n\n        case NAL_IDR_SLICE:\n\n        case NAL_SLICE:\n\n            init_get_bits(&h->gb, ptr, bit_length);\n\n            if (!get_ue_golomb(&h->gb))\n\n                nals_needed = nal_index;\n\n        }\n\n    }\n\n\n\n    return nals_needed;\n\n}\n", "idx": 17308, "_split": "test", "_hash": "1f20ffa241673efd497cc65697d2b1a3"}
{"project": "FFmpeg", "commit_id": "cf818be4f2f1e06bf63da3a6b55a4c3620952070", "target": 1, "func": "static int make_cdt24_entry(int p1, int p2, int16_t *cdt)\n\n{\n\n    int r, b;\n\n\n\n    b = cdt[p2];\n\n    r = cdt[p1]<<16;\n\n    return (b+r) << 1;\n\n}\n", "idx": 17341, "_split": "test", "_hash": "02519346cba73b1906cda7f82334acbb"}
{"project": "FFmpeg", "commit_id": "ae4c9ddebc32eaacbd62681d776881e59ca6e6f7", "target": 1, "func": "static AVFrame *do_psnr(AVFilterContext *ctx, AVFrame *main,\n\n                        const AVFrame *ref)\n\n{\n\n    PSNRContext *s = ctx->priv;\n\n    double comp_mse[4], mse = 0;\n\n    int j, c;\n\n    AVDictionary **metadata = avpriv_frame_get_metadatap(main);\n\n\n\n    s->compute_mse(s, (const uint8_t **)main->data, main->linesize,\n\n                      (const uint8_t **)ref->data, ref->linesize,\n\n                       main->width, main->height, comp_mse);\n\n\n\n    for (j = 0; j < s->nb_components; j++)\n\n        mse += comp_mse[j] * s->planeweight[j];\n\n\n\n    s->min_mse = FFMIN(s->min_mse, mse);\n\n    s->max_mse = FFMAX(s->max_mse, mse);\n\n\n\n    s->mse += mse;\n\n    for (j = 0; j < s->nb_components; j++)\n\n        s->mse_comp[j] += comp_mse[j];\n\n    s->nb_frames++;\n\n\n\n    for (j = 0; j < s->nb_components; j++) {\n\n        c = s->is_rgb ? s->rgba_map[j] : j;\n\n        set_meta(metadata, \"lavfi.psnr.mse.\", s->comps[j], comp_mse[c]);\n\n        set_meta(metadata, \"lavfi.psnr.psnr.\", s->comps[j], get_psnr(comp_mse[c], 1, s->max[c]));\n\n    }\n\n    set_meta(metadata, \"lavfi.psnr.mse_avg\", 0, mse);\n\n    set_meta(metadata, \"lavfi.psnr.psnr_avg\", 0, get_psnr(mse, 1, s->average_max));\n\n\n\n    if (s->stats_file) {\n\n        fprintf(s->stats_file, \"n:%\"PRId64\" mse_avg:%0.2f \", s->nb_frames, mse);\n\n        for (j = 0; j < s->nb_components; j++) {\n\n            c = s->is_rgb ? s->rgba_map[j] : j;\n\n            fprintf(s->stats_file, \"mse_%c:%0.2f \", s->comps[j], comp_mse[c]);\n\n        }\n\n        for (j = 0; j < s->nb_components; j++) {\n\n            c = s->is_rgb ? s->rgba_map[j] : j;\n\n            fprintf(s->stats_file, \"psnr_%c:%0.2f \", s->comps[j],\n\n                    get_psnr(comp_mse[c], 1, s->max[c]));\n\n        }\n\n        fprintf(s->stats_file, \"\\n\");\n\n    }\n\n\n\n    return main;\n\n}\n", "idx": 17350, "_split": "test", "_hash": "ae8b45bced9945dd0f6889f8f0bfb68f"}
{"project": "FFmpeg", "commit_id": "eb9fb508b0e09d85d234fe694333b2005e1d7a7e", "target": 1, "func": "static void matroska_add_index_entries(MatroskaDemuxContext *matroska)\n\n{\n\n    EbmlList *index_list;\n\n    MatroskaIndex *index;\n\n    int index_scale = 1;\n\n    int i, j;\n\n\n\n    if (matroska->ctx->flags & AVFMT_FLAG_IGNIDX)\n\n        return;\n\n\n\n    index_list = &matroska->index;\n\n    index      = index_list->elem;\n\n    if (index_list->nb_elem &&\n\n        index[0].time > 1E14 / matroska->time_scale) {\n\n        av_log(matroska->ctx, AV_LOG_WARNING, \"Working around broken index.\\n\");\n\n        index_scale = matroska->time_scale;\n\n    }\n\n    for (i = 0; i < index_list->nb_elem; i++) {\n\n        EbmlList *pos_list    = &index[i].pos;\n\n        MatroskaIndexPos *pos = pos_list->elem;\n\n        for (j = 0; j < pos_list->nb_elem; j++) {\n\n            MatroskaTrack *track = matroska_find_track_by_num(matroska,\n\n                                                              pos[j].track);\n\n            if (track && track->stream)\n\n                av_add_index_entry(track->stream,\n\n                                   pos[j].pos + matroska->segment_start,\n\n                                   index[i].time / index_scale, 0, 0,\n\n                                   AVINDEX_KEYFRAME);\n\n        }\n\n    }\n\n}\n", "idx": 17353, "_split": "test", "_hash": "a99c64f0ec98ed9e57a81022c1af492a"}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_3f_2r_to_mono(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += (samples[i + 256] + samples[i + 512] + samples[i + 768] + samples[i + 1024]);\n\n        samples[i + 256] = samples[i + 512] = samples[i + 768] = samples[i + 1024] = 0;\n\n    }\n\n}\n", "idx": 17357, "_split": "test", "_hash": "ea330087268ffd4ebabfb60fb45d2a9d"}
{"project": "FFmpeg", "commit_id": "fe6eea99efac66839052af547426518efd970b24", "target": 1, "func": "static int nsv_read_chunk(AVFormatContext *s, int fill_header)\n\n{\n\n    NSVContext *nsv = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st[2] = {NULL, NULL};\n\n    NSVStream *nst;\n\n    AVPacket *pkt;\n\n    int i, err = 0;\n\n    uint8_t auxcount; /* number of aux metadata, also 4 bits of vsize */\n\n    uint32_t vsize;\n\n    uint16_t asize;\n\n    uint16_t auxsize;\n\n\n\n    if (nsv->ahead[0].data || nsv->ahead[1].data)\n\n        return 0; //-1; /* hey! eat what you've in your plate first! */\n\n\n\nnull_chunk_retry:\n\n    if (pb->eof_reached)\n\n        return -1;\n\n\n\n    for (i = 0; i < NSV_MAX_RESYNC_TRIES && nsv->state < NSV_FOUND_NSVS && !err; i++)\n\n        err = nsv_resync(s);\n\n    if (err < 0)\n\n        return err;\n\n    if (nsv->state == NSV_FOUND_NSVS)\n\n        err = nsv_parse_NSVs_header(s);\n\n    if (err < 0)\n\n        return err;\n\n    if (nsv->state != NSV_HAS_READ_NSVS && nsv->state != NSV_FOUND_BEEF)\n\n        return -1;\n\n\n\n    auxcount = avio_r8(pb);\n\n    vsize = avio_rl16(pb);\n\n    asize = avio_rl16(pb);\n\n    vsize = (vsize << 4) | (auxcount >> 4);\n\n    auxcount &= 0x0f;\n\n    av_log(s, AV_LOG_TRACE, \"NSV CHUNK %\"PRIu8\" aux, %\"PRIu32\" bytes video, %\"PRIu16\" bytes audio\\n\",\n\n           auxcount, vsize, asize);\n\n    /* skip aux stuff */\n\n    for (i = 0; i < auxcount; i++) {\n\n        uint32_t av_unused auxtag;\n\n        auxsize = avio_rl16(pb);\n\n        auxtag = avio_rl32(pb);\n\n        avio_skip(pb, auxsize);\n\n        vsize -= auxsize + sizeof(uint16_t) + sizeof(uint32_t); /* that's becoming brain-dead */\n\n    }\n\n\n\n    if (pb->eof_reached)\n\n        return -1;\n\n    if (!vsize && !asize) {\n\n        nsv->state = NSV_UNSYNC;\n\n        goto null_chunk_retry;\n\n    }\n\n\n\n    /* map back streams to v,a */\n\n    if (s->nb_streams > 0)\n\n        st[s->streams[0]->id] = s->streams[0];\n\n    if (s->nb_streams > 1)\n\n        st[s->streams[1]->id] = s->streams[1];\n\n\n\n    if (vsize && st[NSV_ST_VIDEO]) {\n\n        nst = st[NSV_ST_VIDEO]->priv_data;\n\n        pkt = &nsv->ahead[NSV_ST_VIDEO];\n\n        av_get_packet(pb, pkt, vsize);\n\n        pkt->stream_index = st[NSV_ST_VIDEO]->index;//NSV_ST_VIDEO;\n\n        pkt->dts = nst->frame_offset;\n\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n\n        for (i = 0; i < FFMIN(8, vsize); i++)\n\n            av_log(s, AV_LOG_TRACE, \"NSV video: [%d] = %02\"PRIx8\"\\n\",\n\n                   i, pkt->data[i]);\n\n    }\n\n    if(st[NSV_ST_VIDEO])\n\n        ((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset++;\n\n\n\n    if (asize && st[NSV_ST_AUDIO]) {\n\n        nst = st[NSV_ST_AUDIO]->priv_data;\n\n        pkt = &nsv->ahead[NSV_ST_AUDIO];\n\n        /* read raw audio specific header on the first audio chunk... */\n\n        /* on ALL audio chunks ?? seems so! */\n\n        if (asize && st[NSV_ST_AUDIO]->codecpar->codec_tag == MKTAG('P', 'C', 'M', ' ')/* && fill_header*/) {\n\n            uint8_t bps;\n\n            uint8_t channels;\n\n            uint16_t samplerate;\n\n            bps = avio_r8(pb);\n\n            channels = avio_r8(pb);\n\n            samplerate = avio_rl16(pb);\n\n            if (!channels || !samplerate)\n\n                return AVERROR_INVALIDDATA;\n\n            asize-=4;\n\n            av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n\n                   bps, channels, samplerate);\n\n            if (fill_header) {\n\n                st[NSV_ST_AUDIO]->need_parsing = AVSTREAM_PARSE_NONE; /* we know everything */\n\n                if (bps != 16) {\n\n                    av_log(s, AV_LOG_TRACE, \"NSV AUDIO bit/sample != 16 (%\"PRIu8\")!!!\\n\", bps);\n\n                }\n\n                bps /= channels; // ???\n\n                if (bps == 8)\n\n                    st[NSV_ST_AUDIO]->codecpar->codec_id = AV_CODEC_ID_PCM_U8;\n\n                samplerate /= 4;/* UGH ??? XXX */\n\n                channels = 1;\n\n                st[NSV_ST_AUDIO]->codecpar->channels = channels;\n\n                st[NSV_ST_AUDIO]->codecpar->sample_rate = samplerate;\n\n                av_log(s, AV_LOG_TRACE, \"NSV RAWAUDIO: bps %\"PRIu8\", nchan %\"PRIu8\", srate %\"PRIu16\"\\n\",\n\n                       bps, channels, samplerate);\n\n            }\n\n        }\n\n        av_get_packet(pb, pkt, asize);\n\n        pkt->stream_index = st[NSV_ST_AUDIO]->index;//NSV_ST_AUDIO;\n\n        pkt->flags |= nsv->state == NSV_HAS_READ_NSVS ? AV_PKT_FLAG_KEY : 0; /* keyframe only likely on a sync frame */\n\n        if( nsv->state == NSV_HAS_READ_NSVS && st[NSV_ST_VIDEO] ) {\n\n            /* on a nsvs frame we have new information on a/v sync */\n\n            pkt->dts = (((NSVStream*)st[NSV_ST_VIDEO]->priv_data)->frame_offset-1);\n\n            pkt->dts *= (int64_t)1000        * nsv->framerate.den;\n\n            pkt->dts += (int64_t)nsv->avsync * nsv->framerate.num;\n\n            av_log(s, AV_LOG_TRACE, \"NSV AUDIO: sync:%\"PRId16\", dts:%\"PRId64,\n\n                   nsv->avsync, pkt->dts);\n\n        }\n\n        nst->frame_offset++;\n\n    }\n\n\n\n    nsv->state = NSV_UNSYNC;\n\n    return 0;\n\n}\n", "idx": 17381, "_split": "test", "_hash": "b616346ebd637ebc847b8bf377a17729"}
{"project": "FFmpeg", "commit_id": "51e1cc16d3e89a785f3231065c4eb898a0401a93", "target": 1, "func": "matroska_parse_block(MatroskaDemuxContext *matroska, uint8_t *data, int size,\n                     int64_t pos, uint64_t cluster_time, uint64_t duration,\n                     int is_keyframe, int is_bframe)\n{\n    int res = 0;\n    int track;\n    AVStream *st;\n    AVPacket *pkt;\n    uint8_t *origdata = data;\n    int16_t block_time;\n    uint32_t *lace_size = NULL;\n    int n, flags, laces = 0;\n    uint64_t num;\n    int stream_index;\n    /* first byte(s): tracknum */\n    if ((n = matroska_ebmlnum_uint(data, size, &num)) < 0) {\n        av_log(matroska->ctx, AV_LOG_ERROR, \"EBML block data error\\n\");\n        av_free(origdata);\n        return res;\n    }\n    data += n;\n    size -= n;\n    /* fetch track from num */\n    track = matroska_find_track_by_num(matroska, num);\n    if (size <= 3 || track < 0 || track >= matroska->num_tracks) {\n        av_log(matroska->ctx, AV_LOG_INFO,\n               \"Invalid stream %d or size %u\\n\", track, size);\n        av_free(origdata);\n        return res;\n    }\n    stream_index = matroska->tracks[track]->stream_index;\n    if (stream_index < 0 || stream_index >= matroska->ctx->nb_streams) {\n        av_free(origdata);\n        return res;\n    }\n    st = matroska->ctx->streams[stream_index];\n    if (st->discard >= AVDISCARD_ALL) {\n        av_free(origdata);\n        return res;\n    }\n    if (duration == AV_NOPTS_VALUE)\n        duration = matroska->tracks[track]->default_duration / matroska->time_scale;\n    /* block_time (relative to cluster time) */\n    block_time = AV_RB16(data);\n    data += 2;\n    flags = *data++;\n    size -= 3;\n    if (is_keyframe == -1)\n        is_keyframe = flags & 0x80 ? PKT_FLAG_KEY : 0;\n    if (matroska->skip_to_keyframe) {\n        if (!is_keyframe || st != matroska->skip_to_stream) {\n            av_free(origdata);\n            return res;\n        }\n        matroska->skip_to_keyframe = 0;\n    }\n    switch ((flags & 0x06) >> 1) {\n        case 0x0: /* no lacing */\n            laces = 1;\n            lace_size = av_mallocz(sizeof(int));\n            lace_size[0] = size;\n            break;\n        case 0x1: /* xiph lacing */\n        case 0x2: /* fixed-size lacing */\n        case 0x3: /* EBML lacing */\n            assert(size>0); // size <=3 is checked before size-=3 above\n            laces = (*data) + 1;\n            data += 1;\n            size -= 1;\n            lace_size = av_mallocz(laces * sizeof(int));\n            switch ((flags & 0x06) >> 1) {\n                case 0x1: /* xiph lacing */ {\n                    uint8_t temp;\n                    uint32_t total = 0;\n                    for (n = 0; res == 0 && n < laces - 1; n++) {\n                        while (1) {\n                            if (size == 0) {\n                                res = -1;\n                                break;\n                            }\n                            temp = *data;\n                            lace_size[n] += temp;\n                            data += 1;\n                            size -= 1;\n                            if (temp != 0xff)\n                                break;\n                        }\n                        total += lace_size[n];\n                    }\n                    lace_size[n] = size - total;\n                    break;\n                }\n                case 0x2: /* fixed-size lacing */\n                    for (n = 0; n < laces; n++)\n                        lace_size[n] = size / laces;\n                    break;\n                case 0x3: /* EBML lacing */ {\n                    uint32_t total;\n                    n = matroska_ebmlnum_uint(data, size, &num);\n                    if (n < 0) {\n                        av_log(matroska->ctx, AV_LOG_INFO,\n                               \"EBML block data error\\n\");\n                        break;\n                    }\n                    data += n;\n                    size -= n;\n                    total = lace_size[0] = num;\n                    for (n = 1; res == 0 && n < laces - 1; n++) {\n                        int64_t snum;\n                        int r;\n                        r = matroska_ebmlnum_sint (data, size, &snum);\n                        if (r < 0) {\n                            av_log(matroska->ctx, AV_LOG_INFO,\n                                   \"EBML block data error\\n\");\n                            break;\n                        }\n                        data += r;\n                        size -= r;\n                        lace_size[n] = lace_size[n - 1] + snum;\n                        total += lace_size[n];\n                    }\n                    lace_size[n] = size - total;\n                    break;\n                }\n            }\n            break;\n    }\n    if (res == 0) {\n        uint64_t timecode = AV_NOPTS_VALUE;\n        if (cluster_time != (uint64_t)-1\n            && (block_time >= 0 || cluster_time >= -block_time))\n            timecode = cluster_time + block_time;\n        for (n = 0; n < laces; n++) {\n            if (st->codec->codec_id == CODEC_ID_RA_288 ||\n                st->codec->codec_id == CODEC_ID_COOK ||\n                st->codec->codec_id == CODEC_ID_ATRAC3) {\n                MatroskaAudioTrack *audiotrack = (MatroskaAudioTrack *)matroska->tracks[track];\n                int a = st->codec->block_align;\n                int sps = audiotrack->sub_packet_size;\n                int cfs = audiotrack->coded_framesize;\n                int h = audiotrack->sub_packet_h;\n                int y = audiotrack->sub_packet_cnt;\n                int w = audiotrack->frame_size;\n                int x;\n                if (!audiotrack->pkt_cnt) {\n                    if (st->codec->codec_id == CODEC_ID_RA_288)\n                        for (x=0; x<h/2; x++)\n                            memcpy(audiotrack->buf+x*2*w+y*cfs,\n                                   data+x*cfs, cfs);\n                    else\n                        for (x=0; x<w/sps; x++)\n                            memcpy(audiotrack->buf+sps*(h*x+((h+1)/2)*(y&1)+(y>>1)), data+x*sps, sps);\n                    if (++audiotrack->sub_packet_cnt >= h) {\n                        audiotrack->sub_packet_cnt = 0;\n                        audiotrack->pkt_cnt = h*w / a;\n                    }\n                }\n                while (audiotrack->pkt_cnt) {\n                    pkt = av_mallocz(sizeof(AVPacket));\n                    av_new_packet(pkt, a);\n                    memcpy(pkt->data, audiotrack->buf\n                           + a * (h*w / a - audiotrack->pkt_cnt--), a);\n                    pkt->pos = pos;\n                    pkt->stream_index = stream_index;\n                    matroska_queue_packet(matroska, pkt);\n                }\n            } else {\n                int result, offset = 0, ilen, olen, pkt_size = lace_size[n];\n                uint8_t *pkt_data = data;\n                if (matroska->tracks[track]->encoding_scope & 1) {\n                    switch (matroska->tracks[track]->encoding_algo) {\n                    case MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP:\n                        offset = matroska->tracks[track]->encoding_settings_len;\n                        break;\n                    case MATROSKA_TRACK_ENCODING_COMP_LZO:\n                        pkt_data = NULL;\n                        do {\n                            ilen = lace_size[n];\n                            olen = pkt_size *= 3;\n                            pkt_data = av_realloc(pkt_data,\n                                                  pkt_size+LZO_OUTPUT_PADDING);\n                            result = lzo1x_decode(pkt_data, &olen, data, &ilen);\n                        } while (result==LZO_OUTPUT_FULL && pkt_size<10000000);\n                        if (result) {\n                            continue;\n                        }\n                        pkt_size -= olen;\n                        break;\n#ifdef CONFIG_ZLIB\n                    case MATROSKA_TRACK_ENCODING_COMP_ZLIB: {\n                        z_stream zstream = {0};\n                        pkt_data = NULL;\n                        if (inflateInit(&zstream) != Z_OK)\n                            continue;\n                        zstream.next_in = data;\n                        zstream.avail_in = lace_size[n];\n                        do {\n                            pkt_size *= 3;\n                            pkt_data = av_realloc(pkt_data, pkt_size);\n                            zstream.avail_out = pkt_size - zstream.total_out;\n                            zstream.next_out = pkt_data + zstream.total_out;\n                            result = inflate(&zstream, Z_NO_FLUSH);\n                        } while (result==Z_OK && pkt_size<10000000);\n                        pkt_size = zstream.total_out;\n                        inflateEnd(&zstream);\n                        if (result != Z_STREAM_END) {\n                            continue;\n                        }\n                        break;\n                    }\n#endif\n#ifdef CONFIG_BZLIB\n                    case MATROSKA_TRACK_ENCODING_COMP_BZLIB: {\n                        bz_stream bzstream = {0};\n                        pkt_data = NULL;\n                        if (BZ2_bzDecompressInit(&bzstream, 0, 0) != BZ_OK)\n                            continue;\n                        bzstream.next_in = data;\n                        bzstream.avail_in = lace_size[n];\n                        do {\n                            pkt_size *= 3;\n                            pkt_data = av_realloc(pkt_data, pkt_size);\n                            bzstream.avail_out = pkt_size - bzstream.total_out_lo32;\n                            bzstream.next_out = pkt_data + bzstream.total_out_lo32;\n                            result = BZ2_bzDecompress(&bzstream);\n                        } while (result==BZ_OK && pkt_size<10000000);\n                        pkt_size = bzstream.total_out_lo32;\n                        BZ2_bzDecompressEnd(&bzstream);\n                        if (result != BZ_STREAM_END) {\n                            continue;\n                        }\n                        break;\n                    }\n#endif\n                    }\n                }\n                pkt = av_mallocz(sizeof(AVPacket));\n                /* XXX: prevent data copy... */\n                if (av_new_packet(pkt, pkt_size+offset) < 0) {\n                    av_free(pkt);\n                    res = AVERROR(ENOMEM);\n                    n = laces-1;\n                    break;\n                }\n                if (offset)\n                    memcpy (pkt->data, matroska->tracks[track]->encoding_settings, offset);\n                memcpy (pkt->data+offset, pkt_data, pkt_size);\n                if (n == 0)\n                    pkt->flags = is_keyframe;\n                pkt->stream_index = stream_index;\n                pkt->pts = timecode;\n                pkt->pos = pos;\n                pkt->duration = duration;\n                matroska_queue_packet(matroska, pkt);\n            }\n            if (timecode != AV_NOPTS_VALUE)\n                timecode = duration ? timecode + duration : AV_NOPTS_VALUE;\n            data += lace_size[n];\n        }\n    }\n    av_free(lace_size);\n    av_free(origdata);\n    return res;\n}", "idx": 17412, "_split": "test", "_hash": "186b68591d29eb5a8478f1284928a06c"}
{"project": "FFmpeg", "commit_id": "55d7371fe0c44c025eb0e75215e0685870f31874", "target": 1, "func": "void ff_vp56_init_range_decoder(VP56RangeCoder *c, const uint8_t *buf, int buf_size)\n\n{\n\n    c->high = 255;\n\n    c->bits = -16;\n\n    c->buffer = buf;\n\n    c->end = buf + buf_size;\n\n    c->code_word = bytestream_get_be24(&c->buffer);\n\n}\n", "idx": 17413, "_split": "test", "_hash": "15749d7c21435caa113fe72b885175d5"}
{"project": "FFmpeg", "commit_id": "bc29acdc76fdbf70700cdc2f85fc2afb46e19e47", "target": 0, "func": "static int ftp_connect_control_connection(URLContext *h)\n\n{\n\n    char buf[CONTROL_BUFFER_SIZE], opts_format[20];\n\n    int err;\n\n    AVDictionary *opts = NULL;\n\n    FTPContext *s = h->priv_data;\n\n    const int connect_codes[] = {220, 0};\n\n\n\n    s->conn_control_block_flag = 0;\n\n\n\n    if (!s->conn_control) {\n\n        ff_url_join(buf, sizeof(buf), \"tcp\", NULL,\n\n                    s->hostname, s->server_control_port, NULL);\n\n        if (s->rw_timeout != -1) {\n\n            snprintf(opts_format, sizeof(opts_format), \"%d\", s->rw_timeout);\n\n            av_dict_set(&opts, \"timeout\", opts_format, 0);\n\n        } /* if option is not given, don't pass it and let tcp use its own default */\n\n        err = ffurl_open(&s->conn_control, buf, AVIO_FLAG_READ_WRITE,\n\n                         &s->conn_control_interrupt_cb, &opts);\n\n        av_dict_free(&opts);\n\n        if (err < 0) {\n\n            av_log(h, AV_LOG_ERROR, \"Cannot open control connection\\n\");\n\n            return err;\n\n        }\n\n\n\n        /* consume all messages from server */\n\n        if (!ftp_status(s, NULL, connect_codes)) {\n\n            av_log(h, AV_LOG_ERROR, \"FTP server not ready for new users\\n\");\n\n            err = AVERROR(EACCES);\n\n            return err;\n\n        }\n\n\n\n        if ((err = ftp_auth(s)) < 0) {\n\n            av_log(h, AV_LOG_ERROR, \"FTP authentication failed\\n\");\n\n            return err;\n\n        }\n\n\n\n        if ((err = ftp_type(s)) < 0) {\n\n            av_dlog(h, \"Set content type failed\\n\");\n\n            return err;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 17439, "_split": "test", "_hash": "ff5e18a6faafc86c4ae19bc7110552da"}
{"project": "FFmpeg", "commit_id": "cf1e0786ed64e69614760bfb4ecd7adbde8e6094", "target": 0, "func": "static int is_intra_more_likely(ERContext *s)\n\n{\n\n    int is_intra_likely, i, j, undamaged_count, skip_amount, mb_x, mb_y;\n\n\n\n    if (!s->last_pic.f || !s->last_pic.f->data[0])\n\n        return 1; // no previous frame available -> use spatial prediction\n\n\n\n    undamaged_count = 0;\n\n    for (i = 0; i < s->mb_num; i++) {\n\n        const int mb_xy = s->mb_index2xy[i];\n\n        const int error = s->error_status_table[mb_xy];\n\n        if (!((error & ER_DC_ERROR) && (error & ER_MV_ERROR)))\n\n            undamaged_count++;\n\n    }\n\n\n\n    if (s->avctx->codec_id == AV_CODEC_ID_H264 && s->ref_count <= 0)\n\n        return 1;\n\n\n\n    if (undamaged_count < 5)\n\n        return 0; // almost all MBs damaged -> use temporal prediction\n\n\n\n#if FF_API_XVMC\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    // prevent dsp.sad() check, that requires access to the image\n\n    if (CONFIG_MPEG_XVMC_DECODER    &&\n\n        s->avctx->xvmc_acceleration &&\n\n        s->cur_pic.f->pict_type == AV_PICTURE_TYPE_I)\n\n        return 1;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif /* FF_API_XVMC */\n\n\n\n    skip_amount     = FFMAX(undamaged_count / 50, 1); // check only up to 50 MBs\n\n    is_intra_likely = 0;\n\n\n\n    j = 0;\n\n    for (mb_y = 0; mb_y < s->mb_height - 1; mb_y++) {\n\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++) {\n\n            int error;\n\n            const int mb_xy = mb_x + mb_y * s->mb_stride;\n\n\n\n            error = s->error_status_table[mb_xy];\n\n            if ((error & ER_DC_ERROR) && (error & ER_MV_ERROR))\n\n                continue; // skip damaged\n\n\n\n            j++;\n\n            // skip a few to speed things up\n\n            if ((j % skip_amount) != 0)\n\n                continue;\n\n\n\n            if (s->cur_pic.f->pict_type == AV_PICTURE_TYPE_I) {\n\n                int *linesize = s->cur_pic.f->linesize;\n\n                uint8_t *mb_ptr      = s->cur_pic.f->data[0] +\n\n                                       mb_x * 16 + mb_y * 16 * linesize[0];\n\n                uint8_t *last_mb_ptr = s->last_pic.f->data[0] +\n\n                                       mb_x * 16 + mb_y * 16 * linesize[0];\n\n\n\n                if (s->avctx->codec_id == AV_CODEC_ID_H264) {\n\n                    // FIXME\n\n                } else {\n\n                    ff_thread_await_progress(s->last_pic.tf, mb_y, 0);\n\n                }\n\n                is_intra_likely += s->mecc->sad[0](NULL, last_mb_ptr, mb_ptr,\n\n                                                   linesize[0], 16);\n\n                is_intra_likely -= s->mecc->sad[0](NULL, last_mb_ptr,\n\n                                                   last_mb_ptr + linesize[0] * 16,\n\n                                                   linesize[0], 16);\n\n            } else {\n\n                if (IS_INTRA(s->cur_pic.mb_type[mb_xy]))\n\n                   is_intra_likely++;\n\n                else\n\n                   is_intra_likely--;\n\n            }\n\n        }\n\n    }\n\n    return is_intra_likely > 0;\n\n}\n", "idx": 17452, "_split": "test", "_hash": "f824661b1c7fd9e9f62599d9c727dde3"}
{"project": "FFmpeg", "commit_id": "4d321bff85cf1e9b6a18b915af185494b5ea94b6", "target": 1, "func": "void Release(void *ctx)\n\n{\n\n    ContextInfo *ci;\n\n    ci = (ContextInfo *) ctx;\n\n\n\n    if (ci->cache) {\n\n        imlib_context_set_image(ci->cache->image);\n\n        imlib_free_image();\n\n        av_free(ci->cache);\n\n    }\n\n    if (ctx) {\n\n        if (ci->imageOverlaid) {\n\n            imlib_context_set_image(ci->imageOverlaid);\n\n            imlib_free_image();\n\n        }\n\n        ff_eval_free(ci->expr_x);\n\n        ff_eval_free(ci->expr_y);\n\n        ff_eval_free(ci->expr_R);\n\n        ff_eval_free(ci->expr_G);\n\n        ff_eval_free(ci->expr_B);\n\n        sws_freeContext(ci->toRGB_convert_ctx);\n\n        sws_freeContext(ci->fromRGB_convert_ctx);\n\n        av_free(ctx);\n\n    }\n\n}\n", "idx": 17480, "_split": "test", "_hash": "d3b3fb427795b506d8157e040eaa3dde"}
{"project": "FFmpeg", "commit_id": "01ecb7172b684f1c4b3e748f95c5a9a494ca36ec", "target": 1, "func": "static void quantize_and_encode_band_cost_ZERO_mips(struct AACEncContext *s,\n\n                                                         PutBitContext *pb, const float *in, float *out,\n\n                                                         const float *scaled, int size, int scale_idx,\n\n                                                         int cb, const float lambda, const float uplim,\n\n                                                         int *bits, const float ROUNDING) {\n\n    int i;\n\n    if (bits)\n\n        *bits = 0;\n\n    if (out) {\n\n        for (i = 0; i < size; i += 4) {\n\n           out[i  ] = 0.0f;\n\n           out[i+1] = 0.0f;\n\n           out[i+2] = 0.0f;\n\n           out[i+3] = 0.0f;\n\n        }\n\n    }\n\n}\n", "idx": 17513, "_split": "test", "_hash": "df1658ca2d0a44b33787c39215c7e681"}
{"project": "FFmpeg", "commit_id": "b6db385922b79939b0dc124d53ddb4824afac040", "target": 0, "func": "static void mmap_release_buffer(AVPacket *pkt)\n\n{\n\n    struct v4l2_buffer buf;\n\n    int res, fd;\n\n    struct buff_data *buf_descriptor = pkt->priv;\n\n\n\n    if (pkt->data == NULL)\n\n        return;\n\n\n\n    memset(&buf, 0, sizeof(struct v4l2_buffer));\n\n    buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;\n\n    buf.memory = V4L2_MEMORY_MMAP;\n\n    buf.index = buf_descriptor->index;\n\n    fd = buf_descriptor->fd;\n\n    av_free(buf_descriptor);\n\n\n\n    res = ioctl(fd, VIDIOC_QBUF, &buf);\n\n    if (res < 0)\n\n        av_log(NULL, AV_LOG_ERROR, \"ioctl(VIDIOC_QBUF): %s\\n\",\n\n               strerror(errno));\n\n\n\n    pkt->data = NULL;\n\n    pkt->size = 0;\n\n}\n", "idx": 17534, "_split": "test", "_hash": "a8daaeec3b63b92fde2b1030d53d2b14"}
{"project": "FFmpeg", "commit_id": "f0ca6ffa0ae5d5564516ee7a18aa1e234751444a", "target": 1, "func": "static void show_packets(AVFormatContext *fmt_ctx)\n\n{\n\n    AVPacket pkt;\n\n\n\n    av_init_packet(&pkt);\n\n    probe_array_header(\"packets\", 0);\n\n    while (!av_read_frame(fmt_ctx, &pkt))\n\n        show_packet(fmt_ctx, &pkt);\n\n    probe_array_footer(\"packets\", 0);\n\n}\n", "idx": 17554, "_split": "test", "_hash": "1d936a572c5805d286c54a8b813086ce"}
{"project": "FFmpeg", "commit_id": "570a4a0189946c2c983da41d37fdd67fa13266e7", "target": 0, "func": "static int get_riff(AVFormatContext *s, AVIOContext *pb)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    char header[8];\n\n    int i;\n\n\n\n    /* check RIFF header */\n\n    avio_read(pb, header, 4);\n\n    avi->riff_end = avio_rl32(pb);  /* RIFF chunk size */\n\n    avi->riff_end += avio_tell(pb); /* RIFF chunk end */\n\n    avio_read(pb, header+4, 4);\n\n\n\n    for(i=0; avi_headers[i][0]; i++)\n\n        if(!memcmp(header, avi_headers[i], 8))\n\n            break;\n\n    if(!avi_headers[i][0])\n\n        return -1;\n\n\n\n    if(header[7] == 0x19)\n\n        av_log(s, AV_LOG_INFO, \"This file has been generated by a totally broken muxer.\\n\");\n\n\n\n    return 0;\n\n}\n", "idx": 17597, "_split": "test", "_hash": "884b944b78c342988d0a8f90daceb45f"}
{"project": "FFmpeg", "commit_id": "582552fb56ba6559cb1d094a7e7ae5dde3073c5c", "target": 0, "func": "static int altivec_uyvy_rgb32 (SwsContext *c,\n\n\t\t\t       unsigned char **in, int *instrides,\n\n\t\t\t       int srcSliceY,\tint srcSliceH,\n\n\t\t\t       unsigned char **oplanes, int *outstrides)\n\n{\n\n  int w = c->srcW;\n\n  int h = srcSliceH;\n\n  int i,j;\n\n  vector unsigned char uyvy;\n\n  vector signed   short Y,U,V;\n\n  vector signed   short vx,ux,uvx;\n\n  vector signed   short R0,G0,B0,R1,G1,B1;\n\n  vector unsigned char  R,G,B;\n\n  vector unsigned char *out;\n\n  ubyte *img;\n\n\n\n  img = in[0];\n\n  out = (vector unsigned char *)(oplanes[0]+srcSliceY*outstrides[0]);\n\n\n\n  for (i=0;i<h;i++) {\n\n    for (j=0;j<w/16;j++) {\n\n      uyvy = vec_ld (0, img);\n\n      U = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)(0), demux_u);\n\n\n\n      V = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)(0), demux_v);\n\n\n\n      Y = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)(0), demux_y);\n\n\n\n      cvtyuvtoRGB (c, Y,U,V,&R0,&G0,&B0);\n\n\n\n      uyvy = vec_ld (16, img);\n\n      U = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)(0), demux_u);\n\n\n\n      V = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)(0), demux_v);\n\n\n\n      Y = (vector signed short)\n\n\tvec_perm (uyvy, (vector unsigned char)(0), demux_y);\n\n\n\n      cvtyuvtoRGB (c, Y,U,V,&R1,&G1,&B1);\n\n\n\n      R  = vec_packclp (R0,R1);\n\n      G  = vec_packclp (G0,G1);\n\n      B  = vec_packclp (B0,B1);\n\n\n\n      //      vec_mstbgr24 (R,G,B, out);\n\n      out_rgba (R,G,B,out);\n\n\n\n      img += 32;\n\n    }\n\n  }\n\n  return srcSliceH;\n\n}\n", "idx": 17615, "_split": "test", "_hash": "f07728b2d7b60efebbe8953fe7009ff0"}
{"project": "FFmpeg", "commit_id": "202a6697ba54293235ce2d7bd5724f4f461e417f", "target": 0, "func": "rdt_free_extradata (PayloadContext *rdt)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < MAX_STREAMS; i++)\n\n        if (rdt->rmst[i]) {\n\n            ff_rm_free_rmstream(rdt->rmst[i]);\n\n            av_freep(&rdt->rmst[i]);\n\n        }\n\n    if (rdt->rmctx)\n\n        av_close_input_stream(rdt->rmctx);\n\n    av_freep(&rdt->mlti_data);\n\n    av_free(rdt);\n\n}\n", "idx": 17678, "_split": "test", "_hash": "9029bb5e8b85d3958964028ba456e3e4"}
{"project": "FFmpeg", "commit_id": "3dfbdb328ed9e88cebc6462c56cfe61e55850b2e", "target": 0, "func": "static int read_quant_table(RangeCoder *c, int16_t *quant_table, int scale)\n\n{\n\n    int v;\n\n    int i = 0;\n\n    uint8_t state[CONTEXT_SIZE];\n\n\n\n    memset(state, 128, sizeof(state));\n\n\n\n    for (v = 0; i < 128; v++) {\n\n        unsigned len = get_symbol(c, state, 0) + 1;\n\n\n\n        if (len > 128 - i)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        while (len--) {\n\n            quant_table[i] = scale * v;\n\n            i++;\n\n        }\n\n    }\n\n\n\n    for (i = 1; i < 128; i++)\n\n        quant_table[256 - i] = -quant_table[i];\n\n    quant_table[128] = -quant_table[127];\n\n\n\n    return 2 * v - 1;\n\n}\n", "idx": 17723, "_split": "test", "_hash": "c337a7fc9c127b8f0331e84fe79cfd51"}
{"project": "FFmpeg", "commit_id": "1eb57e1d9b59db0aa63348c21bf3290bd3f5efcb", "target": 0, "func": "static int tb_unreliable(AVCodecContext *c)\n\n{\n\n    if (c->time_base.den >= 101L * c->time_base.num ||\n\n        c->time_base.den <    5L * c->time_base.num ||\n\n        // c->codec_tag == AV_RL32(\"DIVX\") ||\n\n        // c->codec_tag == AV_RL32(\"XVID\") ||\n\n        c->codec_id == AV_CODEC_ID_MPEG2VIDEO ||\n\n        c->codec_id == AV_CODEC_ID_H264)\n\n        return 1;\n\n    return 0;\n\n}\n", "idx": 17735, "_split": "test", "_hash": "31c54ed53d0435de4608d8ff9af3a141"}
{"project": "FFmpeg", "commit_id": "0232f788b6b0855db1771dbf8d7174e2eda2ff45", "target": 1, "func": "int swr_init(struct SwrContext *s){\n\n    s->in_buffer_index= 0;\n\n    s->in_buffer_count= 0;\n\n    s->resample_in_constraint= 0;\n\n    free_temp(&s->postin);\n\n    free_temp(&s->midbuf);\n\n    free_temp(&s->preout);\n\n    free_temp(&s->in_buffer);\n\n    swri_audio_convert_free(&s-> in_convert);\n\n    swri_audio_convert_free(&s->out_convert);\n\n    swri_audio_convert_free(&s->full_convert);\n\n\n\n    s-> in.planar= av_sample_fmt_is_planar(s-> in_sample_fmt);\n\n    s->out.planar= av_sample_fmt_is_planar(s->out_sample_fmt);\n\n    s-> in_sample_fmt= av_get_alt_sample_fmt(s-> in_sample_fmt, 0);\n\n    s->out_sample_fmt= av_get_alt_sample_fmt(s->out_sample_fmt, 0);\n\n\n\n    if(s-> in_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested sample format %s is invalid\\n\", av_get_sample_fmt_name(s->in_sample_fmt));\n\n        return AVERROR(EINVAL);\n\n    }\n\n    if(s->out_sample_fmt >= AV_SAMPLE_FMT_NB){\n\n        av_log(s, AV_LOG_ERROR, \"Requested sample format %s is invalid\\n\", av_get_sample_fmt_name(s->out_sample_fmt));\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if(   s->int_sample_fmt != AV_SAMPLE_FMT_S16\n\n        &&s->int_sample_fmt != AV_SAMPLE_FMT_FLT){\n\n        av_log(s, AV_LOG_ERROR, \"Requested sample format %s is not supported internally, only float & S16 is supported\\n\", av_get_sample_fmt_name(s->int_sample_fmt));\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    //FIXME should we allow/support using FLT on material that doesnt need it ?\n\n    if(s->in_sample_fmt <= AV_SAMPLE_FMT_S16 || s->int_sample_fmt==AV_SAMPLE_FMT_S16){\n\n        s->int_sample_fmt= AV_SAMPLE_FMT_S16;\n\n    }else\n\n        s->int_sample_fmt= AV_SAMPLE_FMT_FLT;\n\n\n\n\n\n    if (s->out_sample_rate!=s->in_sample_rate || (s->flags & SWR_FLAG_RESAMPLE)){\n\n        s->resample = swri_resample_init(s->resample, s->out_sample_rate, s->in_sample_rate, 16, 10, 0, 0.8);\n\n    }else\n\n        swri_resample_free(&s->resample);\n\n    if(s->int_sample_fmt != AV_SAMPLE_FMT_S16 && s->resample){\n\n        av_log(s, AV_LOG_ERROR, \"Resampling only supported with internal s16 currently\\n\"); //FIXME\n\n        return -1;\n\n    }\n\n\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n\n\n    if(s->used_ch_count && s-> in_ch_layout && s->used_ch_count != av_get_channel_layout_nb_channels(s-> in_ch_layout)){\n\n        av_log(s, AV_LOG_WARNING, \"Input channel layout has a different number of channels than the number of used channels, ignoring layout\\n\");\n\n        s-> in_ch_layout= 0;\n\n    }\n\n\n\n    if(!s-> in_ch_layout)\n\n        s-> in_ch_layout= av_get_default_channel_layout(s->used_ch_count);\n\n    if(!s->out_ch_layout)\n\n        s->out_ch_layout= av_get_default_channel_layout(s->out.ch_count);\n\n\n\n    s->rematrix= s->out_ch_layout  !=s->in_ch_layout || s->rematrix_volume!=1.0;\n\n\n\n#define RSC 1 //FIXME finetune\n\n    if(!s-> in.ch_count)\n\n        s-> in.ch_count= av_get_channel_layout_nb_channels(s-> in_ch_layout);\n\n    if(!s->used_ch_count)\n\n        s->used_ch_count= s->in.ch_count;\n\n    if(!s->out.ch_count)\n\n        s->out.ch_count= av_get_channel_layout_nb_channels(s->out_ch_layout);\n\n\n\nav_assert0(s-> in.ch_count);\n\nav_assert0(s->used_ch_count);\n\nav_assert0(s->out.ch_count);\n\n    s->resample_first= RSC*s->out.ch_count/s->in.ch_count - RSC < s->out_sample_rate/(float)s-> in_sample_rate - 1.0;\n\n\n\n    s-> in.bps= av_get_bytes_per_sample(s-> in_sample_fmt);\n\n    s->int_bps= av_get_bytes_per_sample(s->int_sample_fmt);\n\n    s->out.bps= av_get_bytes_per_sample(s->out_sample_fmt);\n\n\n\n    if(!s->resample && !s->rematrix && !s->channel_map){\n\n        s->full_convert = swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                                   s-> in_sample_fmt, s-> in.ch_count, NULL, 0);\n\n        return 0;\n\n    }\n\n\n\n    s->in_convert = swri_audio_convert_alloc(s->int_sample_fmt,\n\n                                             s-> in_sample_fmt, s->used_ch_count, s->channel_map, 0);\n\n    s->out_convert= swri_audio_convert_alloc(s->out_sample_fmt,\n\n                                             s->int_sample_fmt, s->out.ch_count, NULL, 0);\n\n\n\n\n\n    s->postin= s->in;\n\n    s->preout= s->out;\n\n    s->midbuf= s->in;\n\n    s->in_buffer= s->in;\n\n    if(s->channel_map){\n\n        s->postin.ch_count=\n\n        s->midbuf.ch_count=\n\n        s->in_buffer.ch_count= s->used_ch_count;\n\n    }\n\n    if(!s->resample_first){\n\n        s->midbuf.ch_count= s->out.ch_count;\n\n        s->in_buffer.ch_count = s->out.ch_count;\n\n    }\n\n\n\n    s->in_buffer.bps = s->postin.bps = s->midbuf.bps = s->preout.bps =  s->int_bps;\n\n    s->in_buffer.planar = s->postin.planar = s->midbuf.planar = s->preout.planar =  1;\n\n\n\n\n\n    if(s->rematrix)\n\n        return swri_rematrix_init(s);\n\n\n\n    return 0;\n\n}\n", "idx": 17737, "_split": "test", "_hash": "1da3ae77b7731c3660be627c4782613a"}
{"project": "FFmpeg", "commit_id": "073c2593c9f0aa4445a6fc1b9b24e6e52a8cc2c1", "target": 1, "func": "static int svq1_decode_init(AVCodecContext *avctx)\n\n{\n\n    MpegEncContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    MPV_decode_defaults(s);\n\n\n\n    s->avctx = avctx;\n\n    s->width = (avctx->width+3)&~3;\n\n    s->height = (avctx->height+3)&~3;\n\n    s->codec_id= avctx->codec->id;\n\n    avctx->pix_fmt = PIX_FMT_YUV410P;\n\n    avctx->has_b_frames= 1; // not true, but DP frames and these behave like unidirectional b frames\n\n    s->flags= avctx->flags;\n\n    if (MPV_common_init(s) < 0) return -1;\n\n\n\n    init_vlc(&svq1_block_type, 2, 4,\n\n        &svq1_block_type_vlc[0][1], 2, 1,\n\n        &svq1_block_type_vlc[0][0], 2, 1);\n\n\n\n    init_vlc(&svq1_motion_component, 7, 33,\n\n        &mvtab[0][1], 2, 1,\n\n        &mvtab[0][0], 2, 1);\n\n\n\n    for (i = 0; i < 6; i++) {\n\n        init_vlc(&svq1_intra_multistage[i], 3, 8,\n\n            &svq1_intra_multistage_vlc[i][0][1], 2, 1,\n\n            &svq1_intra_multistage_vlc[i][0][0], 2, 1);\n\n        init_vlc(&svq1_inter_multistage[i], 3, 8,\n\n            &svq1_inter_multistage_vlc[i][0][1], 2, 1,\n\n            &svq1_inter_multistage_vlc[i][0][0], 2, 1);\n\n    }\n\n\n\n    init_vlc(&svq1_intra_mean, 8, 256,\n\n        &svq1_intra_mean_vlc[0][1], 4, 2,\n\n        &svq1_intra_mean_vlc[0][0], 4, 2);\n\n\n\n    init_vlc(&svq1_inter_mean, 9, 512,\n\n        &svq1_inter_mean_vlc[0][1], 4, 2,\n\n        &svq1_inter_mean_vlc[0][0], 4, 2);\n\n\n\n    return 0;\n\n}\n", "idx": 17742, "_split": "test", "_hash": "0d11445776d1d718a5d1c3785542ce21"}
{"project": "FFmpeg", "commit_id": "bf87908cd8da31e8f8fe75c06577170928ea70a8", "target": 1, "func": "static int rm_read_audio_stream_info(AVFormatContext *s, AVIOContext *pb,\n\n                                     AVStream *st, RMStream *ast, int read_all)\n\n{\n\n    char buf[256];\n\n    uint32_t version;\n\n    int ret;\n\n\n\n    /* ra type header */\n\n    version = avio_rb16(pb); /* version */\n\n    if (version == 3) {\n\n        unsigned bytes_per_minute;\n\n        int header_size = avio_rb16(pb);\n\n        int64_t startpos = avio_tell(pb);\n\n        avio_skip(pb, 8);\n\n        bytes_per_minute = avio_rb16(pb);\n\n        avio_skip(pb, 4);\n\n        rm_read_metadata(s, 0);\n\n        if ((startpos + header_size) >= avio_tell(pb) + 2) {\n\n            // fourcc (should always be \"lpcJ\")\n\n            avio_r8(pb);\n\n            get_str8(pb, buf, sizeof(buf));\n\n        }\n\n        // Skip extra header crap (this should never happen)\n\n        if ((startpos + header_size) > avio_tell(pb))\n\n            avio_skip(pb, header_size + startpos - avio_tell(pb));\n\n        if (bytes_per_minute)\n\n            st->codec->bit_rate = 8LL * bytes_per_minute / 60;\n\n        st->codec->sample_rate = 8000;\n\n        st->codec->channels = 1;\n\n        st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_id = AV_CODEC_ID_RA_144;\n\n        ast->deint_id = DEINT_ID_INT0;\n\n    } else {\n\n        int flavor, sub_packet_h, coded_framesize, sub_packet_size;\n\n        int codecdata_length;\n\n        unsigned bytes_per_minute;\n\n        /* old version (4) */\n\n        avio_skip(pb, 2); /* unused */\n\n        avio_rb32(pb); /* .ra4 */\n\n        avio_rb32(pb); /* data size */\n\n        avio_rb16(pb); /* version2 */\n\n        avio_rb32(pb); /* header size */\n\n        flavor= avio_rb16(pb); /* add codec info / flavor */\n\n        ast->coded_framesize = coded_framesize = avio_rb32(pb); /* coded frame size */\n\n        avio_rb32(pb); /* ??? */\n\n        bytes_per_minute = avio_rb32(pb);\n\n        if (version == 4) {\n\n            if (bytes_per_minute)\n\n                st->codec->bit_rate = 8LL * bytes_per_minute / 60;\n\n        }\n\n        avio_rb32(pb); /* ??? */\n\n        ast->sub_packet_h = sub_packet_h = avio_rb16(pb); /* 1 */\n\n        st->codec->block_align= avio_rb16(pb); /* frame size */\n\n        ast->sub_packet_size = sub_packet_size = avio_rb16(pb); /* sub packet size */\n\n        avio_rb16(pb); /* ??? */\n\n        if (version == 5) {\n\n            avio_rb16(pb); avio_rb16(pb); avio_rb16(pb);\n\n        }\n\n        st->codec->sample_rate = avio_rb16(pb);\n\n        avio_rb32(pb);\n\n        st->codec->channels = avio_rb16(pb);\n\n        if (version == 5) {\n\n            ast->deint_id = avio_rl32(pb);\n\n            avio_read(pb, buf, 4);\n\n            buf[4] = 0;\n\n        } else {\n\n            get_str8(pb, buf, sizeof(buf)); /* desc */\n\n            ast->deint_id = AV_RL32(buf);\n\n            get_str8(pb, buf, sizeof(buf)); /* desc */\n\n        }\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_tag  = AV_RL32(buf);\n\n        st->codec->codec_id   = ff_codec_get_id(ff_rm_codec_tags,\n\n                                                st->codec->codec_tag);\n\n\n\n        switch (st->codec->codec_id) {\n\n        case AV_CODEC_ID_AC3:\n\n            st->need_parsing = AVSTREAM_PARSE_FULL;\n\n            break;\n\n        case AV_CODEC_ID_RA_288:\n\n            st->codec->extradata_size= 0;\n\n            ast->audio_framesize = st->codec->block_align;\n\n            st->codec->block_align = coded_framesize;\n\n            break;\n\n        case AV_CODEC_ID_COOK:\n\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n        case AV_CODEC_ID_ATRAC3:\n\n        case AV_CODEC_ID_SIPR:\n\n            if (read_all) {\n\n                codecdata_length = 0;\n\n            } else {\n\n                avio_rb16(pb); avio_r8(pb);\n\n                if (version == 5)\n\n                    avio_r8(pb);\n\n                codecdata_length = avio_rb32(pb);\n\n                if(codecdata_length + FF_INPUT_BUFFER_PADDING_SIZE <= (unsigned)codecdata_length){\n\n                    av_log(s, AV_LOG_ERROR, \"codecdata_length too large\\n\");\n\n                    return -1;\n\n                }\n\n            }\n\n\n\n            ast->audio_framesize = st->codec->block_align;\n\n            if (st->codec->codec_id == AV_CODEC_ID_SIPR) {\n\n                if (flavor > 3) {\n\n                    av_log(s, AV_LOG_ERROR, \"bad SIPR file flavor %d\\n\",\n\n                           flavor);\n\n                    return -1;\n\n                }\n\n                st->codec->block_align = ff_sipr_subpk_size[flavor];\n\n            } else {\n\n                if(sub_packet_size <= 0){\n\n                    av_log(s, AV_LOG_ERROR, \"sub_packet_size is invalid\\n\");\n\n                    return -1;\n\n                }\n\n                st->codec->block_align = ast->sub_packet_size;\n\n            }\n\n            if ((ret = rm_read_extradata(pb, st->codec, codecdata_length)) < 0)\n\n                return ret;\n\n\n\n            break;\n\n        case AV_CODEC_ID_AAC:\n\n            avio_rb16(pb); avio_r8(pb);\n\n            if (version == 5)\n\n                avio_r8(pb);\n\n            codecdata_length = avio_rb32(pb);\n\n            if(codecdata_length + FF_INPUT_BUFFER_PADDING_SIZE <= (unsigned)codecdata_length){\n\n                av_log(s, AV_LOG_ERROR, \"codecdata_length too large\\n\");\n\n                return -1;\n\n            }\n\n            if (codecdata_length >= 1) {\n\n                avio_r8(pb);\n\n                if ((ret = rm_read_extradata(pb, st->codec, codecdata_length - 1)) < 0)\n\n                    return ret;\n\n            }\n\n            break;\n\n        default:\n\n            av_strlcpy(st->codec->codec_name, buf, sizeof(st->codec->codec_name));\n\n        }\n\n        if (ast->deint_id == DEINT_ID_INT4 ||\n\n            ast->deint_id == DEINT_ID_GENR ||\n\n            ast->deint_id == DEINT_ID_SIPR) {\n\n            if (st->codec->block_align <= 0 ||\n\n                ast->audio_framesize * sub_packet_h > (unsigned)INT_MAX ||\n\n                ast->audio_framesize * sub_packet_h < st->codec->block_align)\n\n                return AVERROR_INVALIDDATA;\n\n            if (av_new_packet(&ast->pkt, ast->audio_framesize * sub_packet_h) < 0)\n\n                return AVERROR(ENOMEM);\n\n        }\n\n        switch (ast->deint_id) {\n\n        case DEINT_ID_INT4:\n\n            if (ast->coded_framesize > ast->audio_framesize ||\n\n                sub_packet_h <= 1 ||\n\n                ast->coded_framesize * sub_packet_h > (2 + (sub_packet_h & 1)) * ast->audio_framesize)\n\n                return AVERROR_INVALIDDATA;\n\n            break;\n\n        case DEINT_ID_GENR:\n\n            if (ast->sub_packet_size <= 0 ||\n\n                ast->sub_packet_size > ast->audio_framesize)\n\n                return AVERROR_INVALIDDATA;\n\n            break;\n\n        case DEINT_ID_SIPR:\n\n        case DEINT_ID_INT0:\n\n        case DEINT_ID_VBRS:\n\n        case DEINT_ID_VBRF:\n\n            break;\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"Unknown interleaver %X\\n\", ast->deint_id);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        if (read_all) {\n\n            avio_r8(pb);\n\n            avio_r8(pb);\n\n            avio_r8(pb);\n\n            rm_read_metadata(s, 0);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 17752, "_split": "test", "_hash": "32f56be8d8a4a88ce77d1f16602fc906"}
{"project": "FFmpeg", "commit_id": "c5be6192f0a50eb8a2134c32b7d57f1d88736adf", "target": 1, "func": "int show_license(void *optctx, const char *opt, const char *arg)\n\n{\n\n    printf(\n\n#if CONFIG_NONFREE\n\n    \"This version of %s has nonfree parts compiled in.\\n\"\n\n    \"Therefore it is not legally redistributable.\\n\",\n\n    program_name\n\n#elif CONFIG_GPLV3\n\n    \"%s is free software; you can redistribute it and/or modify\\n\"\n\n    \"it under the terms of the GNU General Public License as published by\\n\"\n\n    \"the Free Software Foundation; either version 3 of the License, or\\n\"\n\n    \"(at your option) any later version.\\n\"\n\n    \"\\n\"\n\n    \"%s is distributed in the hope that it will be useful,\\n\"\n\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n\"\n\n    \"GNU General Public License for more details.\\n\"\n\n    \"\\n\"\n\n    \"You should have received a copy of the GNU General Public License\\n\"\n\n    \"along with %s.  If not, see <http://www.gnu.org/licenses/>.\\n\",\n\n    program_name, program_name, program_name\n\n#elif CONFIG_GPL\n\n    \"%s is free software; you can redistribute it and/or modify\\n\"\n\n    \"it under the terms of the GNU General Public License as published by\\n\"\n\n    \"the Free Software Foundation; either version 2 of the License, or\\n\"\n\n    \"(at your option) any later version.\\n\"\n\n    \"\\n\"\n\n    \"%s is distributed in the hope that it will be useful,\\n\"\n\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n\"\n\n    \"GNU General Public License for more details.\\n\"\n\n    \"\\n\"\n\n    \"You should have received a copy of the GNU General Public License\\n\"\n\n    \"along with %s; if not, write to the Free Software\\n\"\n\n    \"Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\\n\",\n\n    program_name, program_name, program_name\n\n#elif CONFIG_LGPLV3\n\n    \"%s is free software; you can redistribute it and/or modify\\n\"\n\n    \"it under the terms of the GNU Lesser General Public License as published by\\n\"\n\n    \"the Free Software Foundation; either version 3 of the License, or\\n\"\n\n    \"(at your option) any later version.\\n\"\n\n    \"\\n\"\n\n    \"%s is distributed in the hope that it will be useful,\\n\"\n\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\\n\"\n\n    \"GNU Lesser General Public License for more details.\\n\"\n\n    \"\\n\"\n\n    \"You should have received a copy of the GNU Lesser General Public License\\n\"\n\n    \"along with %s.  If not, see <http://www.gnu.org/licenses/>.\\n\",\n\n    program_name, program_name, program_name\n\n#else\n\n    \"%s is free software; you can redistribute it and/or\\n\"\n\n    \"modify it under the terms of the GNU Lesser General Public\\n\"\n\n    \"License as published by the Free Software Foundation; either\\n\"\n\n    \"version 2.1 of the License, or (at your option) any later version.\\n\"\n\n    \"\\n\"\n\n    \"%s is distributed in the hope that it will be useful,\\n\"\n\n    \"but WITHOUT ANY WARRANTY; without even the implied warranty of\\n\"\n\n    \"MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\\n\"\n\n    \"Lesser General Public License for more details.\\n\"\n\n    \"\\n\"\n\n    \"You should have received a copy of the GNU Lesser General Public\\n\"\n\n    \"License along with %s; if not, write to the Free Software\\n\"\n\n    \"Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\\n\",\n\n    program_name, program_name, program_name\n\n#endif\n\n    );\n\n\n\n    return 0;\n\n}\n", "idx": 17765, "_split": "test", "_hash": "acb1e7bd9e68802bb026d638ed7d92ef"}
{"project": "FFmpeg", "commit_id": "62c3c8ca78ee2da7dc20c2d6371866266c82966d", "target": 1, "func": "int ff_rtsp_make_setup_request(AVFormatContext *s, const char *host, int port,\n\n                              int lower_transport, const char *real_challenge)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    int rtx = 0, j, i, err, interleave = 0, port_off;\n\n    RTSPStream *rtsp_st;\n\n    RTSPMessageHeader reply1, *reply = &reply1;\n\n    char cmd[2048];\n\n    const char *trans_pref;\n\n\n\n    if (rt->transport == RTSP_TRANSPORT_RDT)\n\n        trans_pref = \"x-pn-tng\";\n\n    else\n\n        trans_pref = \"RTP/AVP\";\n\n\n\n    /* default timeout: 1 minute */\n\n    rt->timeout = 60;\n\n\n\n    /* for each stream, make the setup request */\n\n    /* XXX: we assume the same server is used for the control of each\n\n     * RTSP stream */\n\n\n\n    /* Choose a random starting offset within the first half of the\n\n     * port range, to allow for a number of ports to try even if the offset\n\n     * happens to be at the end of the random range. */\n\n    port_off = av_get_random_seed() % ((rt->rtp_port_max - rt->rtp_port_min)/2);\n\n    /* even random offset */\n\n    port_off -= port_off & 0x01;\n\n\n\n    for (j = rt->rtp_port_min + port_off, i = 0; i < rt->nb_rtsp_streams; ++i) {\n\n        char transport[2048];\n\n\n\n        /*\n\n         * WMS serves all UDP data over a single connection, the RTX, which\n\n         * isn't necessarily the first in the SDP but has to be the first\n\n         * to be set up, else the second/third SETUP will fail with a 461.\n\n         */\n\n        if (lower_transport == RTSP_LOWER_TRANSPORT_UDP &&\n\n             rt->server_type == RTSP_SERVER_WMS) {\n\n            if (i == 0) {\n\n                /* rtx first */\n\n                for (rtx = 0; rtx < rt->nb_rtsp_streams; rtx++) {\n\n                    int len = strlen(rt->rtsp_streams[rtx]->control_url);\n\n                    if (len >= 4 &&\n\n                        !strcmp(rt->rtsp_streams[rtx]->control_url + len - 4,\n\n                                \"/rtx\"))\n\n                        break;\n\n                }\n\n                if (rtx == rt->nb_rtsp_streams)\n\n                    return -1; /* no RTX found */\n\n                rtsp_st = rt->rtsp_streams[rtx];\n\n            } else\n\n                rtsp_st = rt->rtsp_streams[i > rtx ? i : i - 1];\n\n        } else\n\n            rtsp_st = rt->rtsp_streams[i];\n\n\n\n        /* RTP/UDP */\n\n        if (lower_transport == RTSP_LOWER_TRANSPORT_UDP) {\n\n            char buf[256];\n\n\n\n            if (rt->server_type == RTSP_SERVER_WMS && i > 1) {\n\n                port = reply->transports[0].client_port_min;\n\n                goto have_port;\n\n            }\n\n\n\n            /* first try in specified port range */\n\n            while (j <= rt->rtp_port_max) {\n\n                ff_url_join(buf, sizeof(buf), \"rtp\", NULL, host, -1,\n\n                            \"?localport=%d\", j);\n\n                /* we will use two ports per rtp stream (rtp and rtcp) */\n\n                j += 2;\n\n                if (!ffurl_open(&rtsp_st->rtp_handle, buf, AVIO_FLAG_READ_WRITE,\n\n                               &s->interrupt_callback, NULL))\n\n                    goto rtp_opened;\n\n            }\n\n\n\n            av_log(s, AV_LOG_ERROR, \"Unable to open an input RTP port\\n\");\n\n            err = AVERROR(EIO);\n\n            goto fail;\n\n\n\n        rtp_opened:\n\n            port = ff_rtp_get_local_rtp_port(rtsp_st->rtp_handle);\n\n        have_port:\n\n            snprintf(transport, sizeof(transport) - 1,\n\n                     \"%s/UDP;\", trans_pref);\n\n            if (rt->server_type != RTSP_SERVER_REAL)\n\n                av_strlcat(transport, \"unicast;\", sizeof(transport));\n\n            av_strlcatf(transport, sizeof(transport),\n\n                     \"client_port=%d\", port);\n\n            if (rt->transport == RTSP_TRANSPORT_RTP &&\n\n                !(rt->server_type == RTSP_SERVER_WMS && i > 0))\n\n                av_strlcatf(transport, sizeof(transport), \"-%d\", port + 1);\n\n        }\n\n\n\n        /* RTP/TCP */\n\n        else if (lower_transport == RTSP_LOWER_TRANSPORT_TCP) {\n\n            /* For WMS streams, the application streams are only used for\n\n             * UDP. When trying to set it up for TCP streams, the server\n\n             * will return an error. Therefore, we skip those streams. */\n\n            if (rt->server_type == RTSP_SERVER_WMS &&\n\n                (rtsp_st->stream_index < 0 ||\n\n                 s->streams[rtsp_st->stream_index]->codec->codec_type ==\n\n                    AVMEDIA_TYPE_DATA))\n\n                continue;\n\n            snprintf(transport, sizeof(transport) - 1,\n\n                     \"%s/TCP;\", trans_pref);\n\n            if (rt->transport != RTSP_TRANSPORT_RDT)\n\n                av_strlcat(transport, \"unicast;\", sizeof(transport));\n\n            av_strlcatf(transport, sizeof(transport),\n\n                        \"interleaved=%d-%d\",\n\n                        interleave, interleave + 1);\n\n            interleave += 2;\n\n        }\n\n\n\n        else if (lower_transport == RTSP_LOWER_TRANSPORT_UDP_MULTICAST) {\n\n            snprintf(transport, sizeof(transport) - 1,\n\n                     \"%s/UDP;multicast\", trans_pref);\n\n        }\n\n        if (s->oformat) {\n\n            av_strlcat(transport, \";mode=receive\", sizeof(transport));\n\n        } else if (rt->server_type == RTSP_SERVER_REAL ||\n\n                   rt->server_type == RTSP_SERVER_WMS)\n\n            av_strlcat(transport, \";mode=play\", sizeof(transport));\n\n        snprintf(cmd, sizeof(cmd),\n\n                 \"Transport: %s\\r\\n\",\n\n                 transport);\n\n        if (rt->accept_dynamic_rate)\n\n            av_strlcat(cmd, \"x-Dynamic-Rate: 0\\r\\n\", sizeof(cmd));\n\n        if (i == 0 && rt->server_type == RTSP_SERVER_REAL && CONFIG_RTPDEC) {\n\n            char real_res[41], real_csum[9];\n\n            ff_rdt_calc_response_and_checksum(real_res, real_csum,\n\n                                              real_challenge);\n\n            av_strlcatf(cmd, sizeof(cmd),\n\n                        \"If-Match: %s\\r\\n\"\n\n                        \"RealChallenge2: %s, sd=%s\\r\\n\",\n\n                        rt->session_id, real_res, real_csum);\n\n        }\n\n        ff_rtsp_send_cmd(s, \"SETUP\", rtsp_st->control_url, cmd, reply, NULL);\n\n        if (reply->status_code == 461 /* Unsupported protocol */ && i == 0) {\n\n            err = 1;\n\n            goto fail;\n\n        } else if (reply->status_code != RTSP_STATUS_OK ||\n\n                   reply->nb_transports != 1) {\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        /* XXX: same protocol for all streams is required */\n\n        if (i > 0) {\n\n            if (reply->transports[0].lower_transport != rt->lower_transport ||\n\n                reply->transports[0].transport != rt->transport) {\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n        } else {\n\n            rt->lower_transport = reply->transports[0].lower_transport;\n\n            rt->transport = reply->transports[0].transport;\n\n        }\n\n\n\n        /* Fail if the server responded with another lower transport mode\n\n         * than what we requested. */\n\n        if (reply->transports[0].lower_transport != lower_transport) {\n\n            av_log(s, AV_LOG_ERROR, \"Nonmatching transport in server reply\\n\");\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        switch(reply->transports[0].lower_transport) {\n\n        case RTSP_LOWER_TRANSPORT_TCP:\n\n            rtsp_st->interleaved_min = reply->transports[0].interleaved_min;\n\n            rtsp_st->interleaved_max = reply->transports[0].interleaved_max;\n\n            break;\n\n\n\n        case RTSP_LOWER_TRANSPORT_UDP: {\n\n            char url[1024], options[30] = \"\";\n\n\n\n            if (rt->rtsp_flags & RTSP_FLAG_FILTER_SRC)\n\n                av_strlcpy(options, \"?connect=1\", sizeof(options));\n\n            /* Use source address if specified */\n\n            if (reply->transports[0].source[0]) {\n\n                ff_url_join(url, sizeof(url), \"rtp\", NULL,\n\n                            reply->transports[0].source,\n\n                            reply->transports[0].server_port_min, \"%s\", options);\n\n            } else {\n\n                ff_url_join(url, sizeof(url), \"rtp\", NULL, host,\n\n                            reply->transports[0].server_port_min, \"%s\", options);\n\n            }\n\n            if (!(rt->server_type == RTSP_SERVER_WMS && i > 1) &&\n\n                ff_rtp_set_remote_url(rtsp_st->rtp_handle, url) < 0) {\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            /* Try to initialize the connection state in a\n\n             * potential NAT router by sending dummy packets.\n\n             * RTP/RTCP dummy packets are used for RDT, too.\n\n             */\n\n            if (!(rt->server_type == RTSP_SERVER_WMS && i > 1) && s->iformat &&\n\n                CONFIG_RTPDEC)\n\n                ff_rtp_send_punch_packets(rtsp_st->rtp_handle);\n\n            break;\n\n        }\n\n        case RTSP_LOWER_TRANSPORT_UDP_MULTICAST: {\n\n            char url[1024], namebuf[50], optbuf[20] = \"\";\n\n            struct sockaddr_storage addr;\n\n            int port, ttl;\n\n\n\n            if (reply->transports[0].destination.ss_family) {\n\n                addr      = reply->transports[0].destination;\n\n                port      = reply->transports[0].port_min;\n\n                ttl       = reply->transports[0].ttl;\n\n            } else {\n\n                addr      = rtsp_st->sdp_ip;\n\n                port      = rtsp_st->sdp_port;\n\n                ttl       = rtsp_st->sdp_ttl;\n\n            }\n\n            if (ttl > 0)\n\n                snprintf(optbuf, sizeof(optbuf), \"?ttl=%d\", ttl);\n\n            getnameinfo((struct sockaddr*) &addr, sizeof(addr),\n\n                        namebuf, sizeof(namebuf), NULL, 0, NI_NUMERICHOST);\n\n            ff_url_join(url, sizeof(url), \"rtp\", NULL, namebuf,\n\n                        port, \"%s\", optbuf);\n\n            if (ffurl_open(&rtsp_st->rtp_handle, url, AVIO_FLAG_READ_WRITE,\n\n                           &s->interrupt_callback, NULL) < 0) {\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            break;\n\n        }\n\n        }\n\n\n\n        if ((err = rtsp_open_transport_ctx(s, rtsp_st)))\n\n            goto fail;\n\n    }\n\n\n\n    if (reply->timeout > 0)\n\n        rt->timeout = reply->timeout;\n\n\n\n    if (rt->server_type == RTSP_SERVER_REAL)\n\n        rt->need_subscription = 1;\n\n\n\n    return 0;\n\n\n\nfail:\n\n    ff_rtsp_undo_setup(s);\n\n    return err;\n\n}\n", "idx": 17766, "_split": "test", "_hash": "6f0d80251d21e9634b89dc05a9595fb2"}
{"project": "FFmpeg", "commit_id": "24130234cd9dd733116d17b724ea4c8e12ce097a", "target": 0, "func": "static int parse_fmtp(AVFormatContext *s,\n\n                      AVStream *stream, PayloadContext *data,\n\n                      const char *attr, const char *value)\n\n{\n\n    AVCodecParameters *par = stream->codecpar;\n\n    int res, i;\n\n\n\n    if (!strcmp(attr, \"config\")) {\n\n        res = parse_fmtp_config(par, value);\n\n\n\n        if (res < 0)\n\n            return res;\n\n    }\n\n\n\n    if (par->codec_id == AV_CODEC_ID_AAC) {\n\n        /* Looking for a known attribute */\n\n        for (i = 0; attr_names[i].str; ++i) {\n\n            if (!av_strcasecmp(attr, attr_names[i].str)) {\n\n                if (attr_names[i].type == ATTR_NAME_TYPE_INT) {\n\n                    *(int *)((char *)data+\n\n                        attr_names[i].offset) = atoi(value);\n\n                } else if (attr_names[i].type == ATTR_NAME_TYPE_STR)\n\n                    *(char **)((char *)data+\n\n                        attr_names[i].offset) = av_strdup(value);\n\n            }\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 17786, "_split": "test", "_hash": "51a0ea20895adfddcd7b4980131e76e8"}
{"project": "FFmpeg", "commit_id": "4c8ca76965b1c29758246624940cbc529e7141f0", "target": 0, "func": "static int ffserver_set_int_param(int *dest, const char *value, int factor,\n\n                                  int min, int max, FFServerConfig *config,\n\n                                  const char *error_msg, ...)\n\n{\n\n    int tmp;\n\n    char *tailp;\n\n    if (!value || !value[0])\n\n        goto error;\n\n    errno = 0;\n\n    tmp = strtol(value, &tailp, 0);\n\n    if (tmp < min || tmp > max)\n\n        goto error;\n\n    if (factor) {\n\n        if (FFABS(tmp) > INT_MAX / FFABS(factor))\n\n            goto error;\n\n        tmp *= factor;\n\n    }\n\n    if (tailp[0] || errno)\n\n        goto error;\n\n    if (dest)\n\n        *dest = tmp;\n\n    return 0;\n\n  error:\n\n    if (config) {\n\n        va_list vl;\n\n        va_start(vl, error_msg);\n\n        vreport_config_error(config->filename, config->line_num, AV_LOG_ERROR,\n\n                &config->errors, error_msg, vl);\n\n        va_end(vl);\n\n    }\n\n    return AVERROR(EINVAL);\n\n}\n", "idx": 17787, "_split": "test", "_hash": "d3f178583b892b1955a3b765873ae22f"}
{"project": "FFmpeg", "commit_id": "dc2e4c2e532b80565f5fbacd3a24a6db7567c257", "target": 0, "func": "static int64_t find_tag(AVIOContext *pb, uint32_t tag1)\n\n{\n\n    unsigned int tag;\n\n    int64_t size;\n\n\n\n    for (;;) {\n\n        if (url_feof(pb))\n\n            return AVERROR_EOF;\n\n        size = next_tag(pb, &tag);\n\n        if (tag == tag1)\n\n            break;\n\n        wav_seek_tag(pb, size, SEEK_CUR);\n\n    }\n\n    return size;\n\n}\n", "idx": 17792, "_split": "test", "_hash": "201a363a78ab80d3c348b7077ebd48cb"}
{"project": "FFmpeg", "commit_id": "d68c05380cebf563915412182643a8be04ef890b", "target": 0, "func": "av_cold void ff_float_dsp_init_x86(AVFloatDSPContext *fdsp)\n\n{\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n#if HAVE_6REGS && HAVE_INLINE_ASM\n\n    if (INLINE_AMD3DNOWEXT(cpu_flags)) {\n\n        fdsp->vector_fmul_window  = vector_fmul_window_3dnowext;\n\n    }\n\n    if (INLINE_SSE(cpu_flags)) {\n\n        fdsp->vector_fmul_window = vector_fmul_window_sse;\n\n    }\n\n#endif\n\n    if (EXTERNAL_SSE(cpu_flags)) {\n\n        fdsp->vector_fmul = ff_vector_fmul_sse;\n\n        fdsp->vector_fmac_scalar = ff_vector_fmac_scalar_sse;\n\n        fdsp->vector_fmul_scalar = ff_vector_fmul_scalar_sse;\n\n        fdsp->vector_fmul_add    = ff_vector_fmul_add_sse;\n\n        fdsp->vector_fmul_reverse = ff_vector_fmul_reverse_sse;\n\n        fdsp->scalarproduct_float = ff_scalarproduct_float_sse;\n\n        fdsp->butterflies_float   = ff_butterflies_float_sse;\n\n    }\n\n    if (EXTERNAL_SSE2(cpu_flags)) {\n\n        fdsp->vector_dmul_scalar = ff_vector_dmul_scalar_sse2;\n\n    }\n\n    if (EXTERNAL_AVX(cpu_flags)) {\n\n        fdsp->vector_fmul = ff_vector_fmul_avx;\n\n        fdsp->vector_fmac_scalar = ff_vector_fmac_scalar_avx;\n\n        fdsp->vector_dmul_scalar = ff_vector_dmul_scalar_avx;\n\n        fdsp->vector_fmul_add    = ff_vector_fmul_add_avx;\n\n        fdsp->vector_fmul_reverse = ff_vector_fmul_reverse_avx;\n\n    }\n\n}\n", "idx": 17803, "_split": "test", "_hash": "a5fed1dc2488e2b943b3b5748a191660"}
{"project": "FFmpeg", "commit_id": "ebbcdc9ac0ea190748a1605bda86ce84466c8b4e", "target": 0, "func": "static inline void get_limits(MpegEncContext *s, int *range, int *xmin, int *ymin, int *xmax, int *ymax, int f_code)\n\n{\n\n    *range = 8 * (1 << (f_code - 1));\n\n    /* XXX: temporary kludge to avoid overflow for msmpeg4 */\n\n    if (s->out_format == FMT_H263 && !s->h263_msmpeg4)\n\n\t*range *= 2;\n\n\n\n    if (s->unrestricted_mv) {\n\n        *xmin = -16;\n\n        *ymin = -16;\n\n        if (s->h263_plus)\n\n            *range *= 2;\n\n        if(s->avctx->codec->id!=CODEC_ID_MPEG4){\n\n            *xmax = s->mb_width*16;\n\n            *ymax = s->mb_height*16;\n\n        }else {\n\n            *xmax = s->width;\n\n            *ymax = s->height;\n\n        }\n\n    } else {\n\n        *xmin = 0;\n\n        *ymin = 0;\n\n        *xmax = s->mb_width*16 - 16;\n\n        *ymax = s->mb_height*16 - 16;\n\n    }\n\n}\n", "idx": 17807, "_split": "test", "_hash": "143149caaae0e6f5e5867fa2c48193ed"}
{"project": "FFmpeg", "commit_id": "931da6a5e9dd54563fe5d4d30b7bd4d0a0218c87", "target": 0, "func": "static int device_try_init(AVFormatContext *ctx,\n\n                           enum AVPixelFormat pix_fmt,\n\n                           int *width,\n\n                           int *height,\n\n                           uint32_t *desired_format,\n\n                           enum AVCodecID *codec_id)\n\n{\n\n    int ret, i;\n\n\n\n    *desired_format = avpriv_fmt_ff2v4l(pix_fmt, ctx->video_codec_id);\n\n\n\n    if (*desired_format) {\n\n        ret = device_init(ctx, width, height, *desired_format);\n\n        if (ret < 0) {\n\n            *desired_format = 0;\n\n            if (ret != AVERROR(EINVAL))\n\n                return ret;\n\n        }\n\n    }\n\n\n\n    if (!*desired_format) {\n\n        for (i = 0; avpriv_fmt_conversion_table[i].codec_id != AV_CODEC_ID_NONE; i++) {\n\n            if (ctx->video_codec_id == AV_CODEC_ID_NONE ||\n\n                avpriv_fmt_conversion_table[i].codec_id == ctx->video_codec_id) {\n\n                av_log(ctx, AV_LOG_DEBUG, \"Trying to set codec:%s pix_fmt:%s\\n\",\n\n                       avcodec_get_name(avpriv_fmt_conversion_table[i].codec_id),\n\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avpriv_fmt_conversion_table[i].ff_fmt), \"none\"));\n\n\n\n                *desired_format = avpriv_fmt_conversion_table[i].v4l2_fmt;\n\n                ret = device_init(ctx, width, height, *desired_format);\n\n                if (ret >= 0)\n\n                    break;\n\n                else if (ret != AVERROR(EINVAL))\n\n                    return ret;\n\n                *desired_format = 0;\n\n            }\n\n        }\n\n\n\n        if (*desired_format == 0) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Cannot find a proper format for \"\n\n                   \"codec '%s' (id %d), pixel format '%s' (id %d)\\n\",\n\n                   avcodec_get_name(ctx->video_codec_id), ctx->video_codec_id,\n\n                   (char *)av_x_if_null(av_get_pix_fmt_name(pix_fmt), \"none\"), pix_fmt);\n\n            ret = AVERROR(EINVAL);\n\n        }\n\n    }\n\n\n\n    *codec_id = avpriv_fmt_v4l2codec(*desired_format);\n\n    av_assert0(*codec_id != AV_CODEC_ID_NONE);\n\n    return ret;\n\n}\n", "idx": 17808, "_split": "test", "_hash": "9b8db4703a5bdc5ed548e96c3f0f18c6"}
{"project": "FFmpeg", "commit_id": "bacc4b6e8173fa944c24f297435dc507a60efb10", "target": 1, "func": "static void mclms_predict(WmallDecodeCtx *s, int icoef, int *pred)\n\n{\n\n    int ich, i;\n\n    int order        = s->mclms_order;\n\n    int num_channels = s->num_channels;\n\n\n\n    for (ich = 0; ich < num_channels; ich++) {\n\n        pred[ich] = 0;\n\n        if (!s->is_channel_coded[ich])\n\n            continue;\n\n        for (i = 0; i < order * num_channels; i++)\n\n            pred[ich] += s->mclms_prevvalues[i + s->mclms_recent] *\n\n                         s->mclms_coeffs[i + order * num_channels * ich];\n\n        for (i = 0; i < ich; i++)\n\n            pred[ich] += s->channel_residues[i][icoef] *\n\n                         s->mclms_coeffs_cur[i + num_channels * ich];\n\n        pred[ich] += 1 << s->mclms_scaling - 1;\n\n        pred[ich] >>= s->mclms_scaling;\n\n        s->channel_residues[ich][icoef] += pred[ich];\n\n    }\n\n}\n", "idx": 17877, "_split": "test", "_hash": "0673a306c9797074b65123454b2a02e8"}
{"project": "FFmpeg", "commit_id": "4691a77db4672026d62d524fd292fb17db6514b4", "target": 1, "func": "static inline int get_chroma_qp(H264Context *h, int qscale){\n\n    return h->pps.chroma_qp_table[qscale & 0xff];\n\n}\n", "idx": 17893, "_split": "test", "_hash": "f341f59b52823bf5a8a1f76a588ed102"}
{"project": "FFmpeg", "commit_id": "fe8c9420dd5bbc7a0c545e479da9118bcf311dd2", "target": 1, "func": "int AAC_RENAME(ff_ps_read_data)(AVCodecContext *avctx, GetBitContext *gb_host, PSContext *ps, int bits_left)\n\n{\n\n    int e;\n\n    int bit_count_start = get_bits_count(gb_host);\n\n    int header;\n\n    int bits_consumed;\n\n    GetBitContext gbc = *gb_host, *gb = &gbc;\n\n\n\n    header = get_bits1(gb);\n\n    if (header) {     //enable_ps_header\n\n        ps->enable_iid = get_bits1(gb);\n\n        if (ps->enable_iid) {\n\n            int iid_mode = get_bits(gb, 3);\n\n            if (iid_mode > 5) {\n\n                av_log(avctx, AV_LOG_ERROR, \"iid_mode %d is reserved.\\n\",\n\n                       iid_mode);\n\n                goto err;\n\n            }\n\n            ps->nr_iid_par    = nr_iidicc_par_tab[iid_mode];\n\n            ps->iid_quant     = iid_mode > 2;\n\n            ps->nr_ipdopd_par = nr_iidopd_par_tab[iid_mode];\n\n        }\n\n        ps->enable_icc = get_bits1(gb);\n\n        if (ps->enable_icc) {\n\n            ps->icc_mode = get_bits(gb, 3);\n\n            if (ps->icc_mode > 5) {\n\n                av_log(avctx, AV_LOG_ERROR, \"icc_mode %d is reserved.\\n\",\n\n                       ps->icc_mode);\n\n                goto err;\n\n            }\n\n            ps->nr_icc_par = nr_iidicc_par_tab[ps->icc_mode];\n\n        }\n\n        ps->enable_ext = get_bits1(gb);\n\n    }\n\n\n\n    ps->frame_class = get_bits1(gb);\n\n    ps->num_env_old = ps->num_env;\n\n    ps->num_env     = num_env_tab[ps->frame_class][get_bits(gb, 2)];\n\n\n\n    ps->border_position[0] = -1;\n\n    if (ps->frame_class) {\n\n        for (e = 1; e <= ps->num_env; e++)\n\n            ps->border_position[e] = get_bits(gb, 5);\n\n    } else\n\n        for (e = 1; e <= ps->num_env; e++)\n\n            ps->border_position[e] = (e * numQMFSlots >> ff_log2_tab[ps->num_env]) - 1;\n\n\n\n    if (ps->enable_iid) {\n\n        for (e = 0; e < ps->num_env; e++) {\n\n            int dt = get_bits1(gb);\n\n            if (read_iid_data(avctx, gb, ps, ps->iid_par, huff_iid[2*dt+ps->iid_quant], e, dt))\n\n                goto err;\n\n        }\n\n    } else\n\n        memset(ps->iid_par, 0, sizeof(ps->iid_par));\n\n\n\n    if (ps->enable_icc)\n\n        for (e = 0; e < ps->num_env; e++) {\n\n            int dt = get_bits1(gb);\n\n            if (read_icc_data(avctx, gb, ps, ps->icc_par, dt ? huff_icc_dt : huff_icc_df, e, dt))\n\n                goto err;\n\n        }\n\n    else\n\n        memset(ps->icc_par, 0, sizeof(ps->icc_par));\n\n\n\n    if (ps->enable_ext) {\n\n        int cnt = get_bits(gb, 4);\n\n        if (cnt == 15) {\n\n            cnt += get_bits(gb, 8);\n\n        }\n\n        cnt *= 8;\n\n        while (cnt > 7) {\n\n            int ps_extension_id = get_bits(gb, 2);\n\n            cnt -= 2 + ps_read_extension_data(gb, ps, ps_extension_id);\n\n        }\n\n        if (cnt < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"ps extension overflow %d\\n\", cnt);\n\n            goto err;\n\n        }\n\n        skip_bits(gb, cnt);\n\n    }\n\n\n\n    ps->enable_ipdopd &= !PS_BASELINE;\n\n\n\n    //Fix up envelopes\n\n    if (!ps->num_env || ps->border_position[ps->num_env] < numQMFSlots - 1) {\n\n        //Create a fake envelope\n\n        int source = ps->num_env ? ps->num_env - 1 : ps->num_env_old - 1;\n\n        int b;\n\n        if (source >= 0 && source != ps->num_env) {\n\n            if (ps->enable_iid) {\n\n                memcpy(ps->iid_par+ps->num_env, ps->iid_par+source, sizeof(ps->iid_par[0]));\n\n            }\n\n            if (ps->enable_icc) {\n\n                memcpy(ps->icc_par+ps->num_env, ps->icc_par+source, sizeof(ps->icc_par[0]));\n\n            }\n\n            if (ps->enable_ipdopd) {\n\n                memcpy(ps->ipd_par+ps->num_env, ps->ipd_par+source, sizeof(ps->ipd_par[0]));\n\n                memcpy(ps->opd_par+ps->num_env, ps->opd_par+source, sizeof(ps->opd_par[0]));\n\n            }\n\n        }\n\n        if (ps->enable_iid){\n\n            for (b = 0; b < ps->nr_iid_par; b++) {\n\n                if (FFABS(ps->iid_par[ps->num_env][b]) > 7 + 8 * ps->iid_quant) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"iid_par invalid\\n\");\n\n                    goto err;\n\n                }\n\n            }\n\n        }\n\n        if (ps->enable_icc){\n\n            for (b = 0; b < ps->nr_iid_par; b++) {\n\n                if (ps->icc_par[ps->num_env][b] > 7U) {\n\n                    av_log(avctx, AV_LOG_ERROR, \"icc_par invalid\\n\");\n\n                    goto err;\n\n                }\n\n            }\n\n        }\n\n        ps->num_env++;\n\n        ps->border_position[ps->num_env] = numQMFSlots - 1;\n\n    }\n\n\n\n\n\n    ps->is34bands_old = ps->is34bands;\n\n    if (!PS_BASELINE && (ps->enable_iid || ps->enable_icc))\n\n        ps->is34bands = (ps->enable_iid && ps->nr_iid_par == 34) ||\n\n                        (ps->enable_icc && ps->nr_icc_par == 34);\n\n\n\n    //Baseline\n\n    if (!ps->enable_ipdopd) {\n\n        memset(ps->ipd_par, 0, sizeof(ps->ipd_par));\n\n        memset(ps->opd_par, 0, sizeof(ps->opd_par));\n\n    }\n\n\n\n    if (header)\n\n        ps->start = 1;\n\n\n\n    bits_consumed = get_bits_count(gb) - bit_count_start;\n\n    if (bits_consumed <= bits_left) {\n\n        skip_bits_long(gb_host, bits_consumed);\n\n        return bits_consumed;\n\n    }\n\n    av_log(avctx, AV_LOG_ERROR, \"Expected to read %d PS bits actually read %d.\\n\", bits_left, bits_consumed);\n\nerr:\n\n    ps->start = 0;\n\n    skip_bits_long(gb_host, bits_left);\n\n    memset(ps->iid_par, 0, sizeof(ps->iid_par));\n\n    memset(ps->icc_par, 0, sizeof(ps->icc_par));\n\n    memset(ps->ipd_par, 0, sizeof(ps->ipd_par));\n\n    memset(ps->opd_par, 0, sizeof(ps->opd_par));\n\n    return bits_left;\n\n}\n", "idx": 17904, "_split": "test", "_hash": "8be459e56992c2fb3a991ca34bd0e49f"}
{"project": "FFmpeg", "commit_id": "4641ae352ec587355764ffd5c43dd0d0ebd47654", "target": 1, "func": "static int read_gab2_sub(AVFormatContext *s, AVStream *st, AVPacket *pkt)\n\n{\n\n    if (pkt->size >= 7 &&\n\n        pkt->size < INT_MAX - AVPROBE_PADDING_SIZE &&\n\n        !strcmp(pkt->data, \"GAB2\") && AV_RL16(pkt->data + 5) == 2) {\n\n        uint8_t desc[256];\n\n        int score      = AVPROBE_SCORE_EXTENSION, ret;\n\n        AVIStream *ast = st->priv_data;\n\n        AVInputFormat *sub_demuxer;\n\n        AVRational time_base;\n\n        int size;\n\n        AVIOContext *pb = avio_alloc_context(pkt->data + 7,\n\n                                             pkt->size - 7,\n\n                                             0, NULL, NULL, NULL, NULL);\n\n        AVProbeData pd;\n\n        unsigned int desc_len = avio_rl32(pb);\n\n\n\n        if (desc_len > pb->buf_end - pb->buf_ptr)\n\n            goto error;\n\n\n\n        ret = avio_get_str16le(pb, desc_len, desc, sizeof(desc));\n\n        avio_skip(pb, desc_len - ret);\n\n        if (*desc)\n\n            av_dict_set(&st->metadata, \"title\", desc, 0);\n\n\n\n        avio_rl16(pb);   /* flags? */\n\n        avio_rl32(pb);   /* data size */\n\n\n\n        size = pb->buf_end - pb->buf_ptr;\n\n        pd = (AVProbeData) { .buf      = av_mallocz(size + AVPROBE_PADDING_SIZE),\n\n                             .buf_size = size };\n\n        if (!pd.buf)\n\n            goto error;\n\n        memcpy(pd.buf, pb->buf_ptr, size);\n\n        sub_demuxer = av_probe_input_format2(&pd, 1, &score);\n\n        av_freep(&pd.buf);\n\n        if (!sub_demuxer)\n\n            goto error;\n\n\n\n        if (!(ast->sub_ctx = avformat_alloc_context()))\n\n            goto error;\n\n\n\n        ast->sub_ctx->pb = pb;\n\n\n\n        av_assert0(!ast->sub_ctx->codec_whitelist && !ast->sub_ctx->format_whitelist);\n\n        ast->sub_ctx-> codec_whitelist = av_strdup(s->codec_whitelist);\n\n        ast->sub_ctx->format_whitelist = av_strdup(s->format_whitelist);\n\n\n\n        if (!avformat_open_input(&ast->sub_ctx, \"\", sub_demuxer, NULL)) {\n\n            ff_read_packet(ast->sub_ctx, &ast->sub_pkt);\n\n            *st->codec = *ast->sub_ctx->streams[0]->codec;\n\n            ast->sub_ctx->streams[0]->codec->extradata = NULL;\n\n            time_base = ast->sub_ctx->streams[0]->time_base;\n\n            avpriv_set_pts_info(st, 64, time_base.num, time_base.den);\n\n        }\n\n        ast->sub_buffer = pkt->data;\n\n        memset(pkt, 0, sizeof(*pkt));\n\n        return 1;\n\n\n\nerror:\n\n        av_freep(&pb);\n\n    }\n\n    return 0;\n\n}\n", "idx": 17908, "_split": "test", "_hash": "ff0cb0831a6e608d1a17efae3f7f764a"}
{"project": "FFmpeg", "commit_id": "ac726a4f0cd2fb8619b478af51312a4282215f0e", "target": 0, "func": "static int movie_request_frame(AVFilterLink *outlink)\n\n{\n\n    AVFilterBufferRef *outpicref;\n\n    MovieContext *movie = outlink->src->priv;\n\n    int ret;\n\n\n\n    if (movie->is_done)\n\n        return AVERROR_EOF;\n\n    if ((ret = movie_get_frame(outlink)) < 0)\n\n        return ret;\n\n\n\n    outpicref = avfilter_ref_buffer(movie->picref, ~0);\n\n    ff_start_frame(outlink, outpicref);\n\n    ff_draw_slice(outlink, 0, outlink->h, 1);\n\n    ff_end_frame(outlink);\n\n    avfilter_unref_buffer(movie->picref);\n\n    movie->picref = NULL;\n\n\n\n    return 0;\n\n}\n", "idx": 17913, "_split": "test", "_hash": "b3f0c4f54699ee481ac469a4c0a18c84"}
{"project": "FFmpeg", "commit_id": "89d4d7d759a59e8535b267b7f5af757f731da712", "target": 1, "func": "static void process_client(AVIOContext *client, const char *in_uri)\n\n{\n\n    AVIOContext *input = NULL;\n\n    uint8_t buf[1024];\n\n    int ret, n, reply_code;\n\n    uint8_t *resource = NULL;\n\n    while ((ret = avio_handshake(client)) > 0) {\n\n        av_opt_get(client, \"resource\", AV_OPT_SEARCH_CHILDREN, &resource);\n\n        // check for strlen(resource) is necessary, because av_opt_get()\n\n        // may return empty string.\n\n        if (resource && strlen(resource))\n\n            break;\n\n\n    }\n\n    if (ret < 0)\n\n        goto end;\n\n    av_log(client, AV_LOG_TRACE, \"resource=%p\\n\", resource);\n\n    if (resource && resource[0] == '/' && !strcmp((resource + 1), in_uri)) {\n\n        reply_code = 200;\n\n    } else {\n\n        reply_code = AVERROR_HTTP_NOT_FOUND;\n\n    }\n\n    if ((ret = av_opt_set_int(client, \"reply_code\", reply_code, AV_OPT_SEARCH_CHILDREN)) < 0) {\n\n        av_log(client, AV_LOG_ERROR, \"Failed to set reply_code: %s.\\n\", av_err2str(ret));\n\n        goto end;\n\n    }\n\n    av_log(client, AV_LOG_TRACE, \"Set reply code to %d\\n\", reply_code);\n\n\n\n    while ((ret = avio_handshake(client)) > 0);\n\n\n\n    if (ret < 0)\n\n        goto end;\n\n\n\n    fprintf(stderr, \"Handshake performed.\\n\");\n\n    if (reply_code != 200)\n\n        goto end;\n\n    fprintf(stderr, \"Opening input file.\\n\");\n\n    if ((ret = avio_open2(&input, in_uri, AVIO_FLAG_READ, NULL, NULL)) < 0) {\n\n        av_log(input, AV_LOG_ERROR, \"Failed to open input: %s: %s.\\n\", in_uri,\n\n               av_err2str(ret));\n\n        goto end;\n\n    }\n\n    for(;;) {\n\n        n = avio_read(input, buf, sizeof(buf));\n\n        if (n < 0) {\n\n            if (n == AVERROR_EOF)\n\n                break;\n\n            av_log(input, AV_LOG_ERROR, \"Error reading from input: %s.\\n\",\n\n                   av_err2str(n));\n\n            break;\n\n        }\n\n        avio_write(client, buf, n);\n\n        avio_flush(client);\n\n    }\n\nend:\n\n    fprintf(stderr, \"Flushing client\\n\");\n\n    avio_flush(client);\n\n    fprintf(stderr, \"Closing client\\n\");\n\n    avio_close(client);\n\n    fprintf(stderr, \"Closing input\\n\");\n\n    avio_close(input);\n\n\n}", "idx": 17929, "_split": "test", "_hash": "8a778fad39a417bb60619353e7250ab0"}
{"project": "FFmpeg", "commit_id": "cec939597722663f322941b4c12e00a583e63504", "target": 1, "func": "static inline void pred_direct_motion(H264Context * const h, int *mb_type){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy =   s->mb_x +   s->mb_y*s->mb_stride;\n\n    const int b8_xy = 2*s->mb_x + 2*s->mb_y*h->b8_stride;\n\n    const int b4_xy = 4*s->mb_x + 4*s->mb_y*h->b_stride;\n\n    const int mb_type_col = h->ref_list[1][0].mb_type[mb_xy];\n\n    const int16_t (*l1mv0)[2] = (const int16_t (*)[2]) &h->ref_list[1][0].motion_val[0][b4_xy];\n\n    const int16_t (*l1mv1)[2] = (const int16_t (*)[2]) &h->ref_list[1][0].motion_val[1][b4_xy];\n\n    const int8_t *l1ref0 = &h->ref_list[1][0].ref_index[0][b8_xy];\n\n    const int8_t *l1ref1 = &h->ref_list[1][0].ref_index[1][b8_xy];\n\n    const int is_b8x8 = IS_8X8(*mb_type);\n\n    int sub_mb_type;\n\n    int i8, i4;\n\n\n\n    if(IS_8X8(mb_type_col) && !h->sps.direct_8x8_inference_flag){\n\n        /* FIXME save sub mb types from previous frames (or derive from MVs)\n\n         * so we know exactly what block size to use */\n\n        sub_mb_type = MB_TYPE_8x8|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_4x4 */\n\n        *mb_type =    MB_TYPE_8x8|MB_TYPE_L0L1;\n\n    }else if(!is_b8x8 && (IS_16X16(mb_type_col) || IS_INTRA(mb_type_col))){\n\n        sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n        *mb_type =    MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_16x16 */\n\n    }else{\n\n        sub_mb_type = MB_TYPE_16x16|MB_TYPE_P0L0|MB_TYPE_P0L1|MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n        *mb_type =    MB_TYPE_8x8|MB_TYPE_L0L1;\n\n    }\n\n    if(!is_b8x8)\n\n        *mb_type |= MB_TYPE_DIRECT2;\n\n\n\n    tprintf(\"mb_type = %08x, sub_mb_type = %08x, is_b8x8 = %d, mb_type_col = %08x\\n\", *mb_type, sub_mb_type, is_b8x8, mb_type_col);\n\n\n\n    if(h->direct_spatial_mv_pred){\n\n        int ref[2];\n\n        int mv[2][2];\n\n        int list;\n\n\n\n        /* ref = min(neighbors) */\n\n        for(list=0; list<2; list++){\n\n            int refa = h->ref_cache[list][scan8[0] - 1];\n\n            int refb = h->ref_cache[list][scan8[0] - 8];\n\n            int refc = h->ref_cache[list][scan8[0] - 8 + 4];\n\n            if(refc == -2)\n\n                refc = h->ref_cache[list][scan8[0] - 8 - 1];\n\n            ref[list] = refa;\n\n            if(ref[list] < 0 || (refb < ref[list] && refb >= 0))\n\n                ref[list] = refb;\n\n            if(ref[list] < 0 || (refc < ref[list] && refc >= 0))\n\n                ref[list] = refc;\n\n            if(ref[list] < 0)\n\n                ref[list] = -1;\n\n        }\n\n\n\n        if(ref[0] < 0 && ref[1] < 0){\n\n            ref[0] = ref[1] = 0;\n\n            mv[0][0] = mv[0][1] =\n\n            mv[1][0] = mv[1][1] = 0;\n\n        }else{\n\n            for(list=0; list<2; list++){\n\n                if(ref[list] >= 0)\n\n                    pred_motion(h, 0, 4, list, ref[list], &mv[list][0], &mv[list][1]);\n\n                else\n\n                    mv[list][0] = mv[list][1] = 0;\n\n            }\n\n        }\n\n\n\n        if(ref[1] < 0){\n\n            *mb_type &= ~MB_TYPE_P0L1;\n\n            sub_mb_type &= ~MB_TYPE_P0L1;\n\n        }else if(ref[0] < 0){\n\n            *mb_type &= ~MB_TYPE_P0L0;\n\n            sub_mb_type &= ~MB_TYPE_P0L0;\n\n        }\n\n\n\n        if(IS_16X16(*mb_type)){\n\n            fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, ref[0], 1);\n\n            fill_rectangle(&h->ref_cache[1][scan8[0]], 4, 4, 8, ref[1], 1);\n\n            if(!IS_INTRA(mb_type_col)\n\n               && (   (l1ref0[0] == 0 && ABS(l1mv0[0][0]) <= 1 && ABS(l1mv0[0][1]) <= 1)\n\n                   || (l1ref0[0]  < 0 && l1ref1[0] == 0 && ABS(l1mv1[0][0]) <= 1 && ABS(l1mv1[0][1]) <= 1\n\n                       && (h->x264_build>33 || !h->x264_build)))){\n\n                if(ref[0] > 0)\n\n                    fill_rectangle(&h->mv_cache[0][scan8[0]], 4, 4, 8, pack16to32(mv[0][0],mv[0][1]), 4);\n\n                else\n\n                    fill_rectangle(&h->mv_cache[0][scan8[0]], 4, 4, 8, 0, 4);\n\n                if(ref[1] > 0)\n\n                    fill_rectangle(&h->mv_cache[1][scan8[0]], 4, 4, 8, pack16to32(mv[1][0],mv[1][1]), 4);\n\n                else\n\n                    fill_rectangle(&h->mv_cache[1][scan8[0]], 4, 4, 8, 0, 4);\n\n            }else{\n\n                fill_rectangle(&h->mv_cache[0][scan8[0]], 4, 4, 8, pack16to32(mv[0][0],mv[0][1]), 4);\n\n                fill_rectangle(&h->mv_cache[1][scan8[0]], 4, 4, 8, pack16to32(mv[1][0],mv[1][1]), 4);\n\n            }\n\n        }else{\n\n            for(i8=0; i8<4; i8++){\n\n                const int x8 = i8&1;\n\n                const int y8 = i8>>1;\n\n\n\n                if(is_b8x8 && !IS_DIRECT(h->sub_mb_type[i8]))\n\n                    continue;\n\n                h->sub_mb_type[i8] = sub_mb_type;\n\n\n\n                fill_rectangle(&h->mv_cache[0][scan8[i8*4]], 2, 2, 8, pack16to32(mv[0][0],mv[0][1]), 4);\n\n                fill_rectangle(&h->mv_cache[1][scan8[i8*4]], 2, 2, 8, pack16to32(mv[1][0],mv[1][1]), 4);\n\n                fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, ref[0], 1);\n\n                fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, ref[1], 1);\n\n\n\n                /* col_zero_flag */\n\n                if(!IS_INTRA(mb_type_col) && (   l1ref0[x8 + y8*h->b8_stride] == 0\n\n                                              || (l1ref0[x8 + y8*h->b8_stride] < 0 && l1ref1[x8 + y8*h->b8_stride] == 0\n\n                                                  && (h->x264_build>33 || !h->x264_build)))){\n\n                    const int16_t (*l1mv)[2]= l1ref0[x8 + y8*h->b8_stride] == 0 ? l1mv0 : l1mv1;\n\n                    for(i4=0; i4<4; i4++){\n\n                        const int16_t *mv_col = l1mv[x8*2 + (i4&1) + (y8*2 + (i4>>1))*h->b_stride];\n\n                        if(ABS(mv_col[0]) <= 1 && ABS(mv_col[1]) <= 1){\n\n                            if(ref[0] == 0)\n\n                                *(uint32_t*)h->mv_cache[0][scan8[i8*4+i4]] = 0;\n\n                            if(ref[1] == 0)\n\n                                *(uint32_t*)h->mv_cache[1][scan8[i8*4+i4]] = 0;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }else{ /* direct temporal mv pred */\n\n        if(IS_16X16(*mb_type)){\n\n            fill_rectangle(&h->ref_cache[1][scan8[0]], 4, 4, 8, 0, 1);\n\n            if(IS_INTRA(mb_type_col)){\n\n                fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, 0, 1);\n\n                fill_rectangle(&h-> mv_cache[0][scan8[0]], 4, 4, 8, 0, 4);\n\n                fill_rectangle(&h-> mv_cache[1][scan8[0]], 4, 4, 8, 0, 4);\n\n            }else{\n\n                const int ref0 = l1ref0[0] >= 0 ? h->map_col_to_list0[0][l1ref0[0]]\n\n                                                : h->map_col_to_list0[1][l1ref1[0]];\n\n                const int dist_scale_factor = h->dist_scale_factor[ref0];\n\n                const int16_t *mv_col = l1ref0[0] >= 0 ? l1mv0[0] : l1mv1[0];\n\n                int mv_l0[2];\n\n                mv_l0[0] = (dist_scale_factor * mv_col[0] + 128) >> 8;\n\n                mv_l0[1] = (dist_scale_factor * mv_col[1] + 128) >> 8;\n\n                fill_rectangle(&h->ref_cache[0][scan8[0]], 4, 4, 8, ref0, 1);\n\n                fill_rectangle(&h-> mv_cache[0][scan8[0]], 4, 4, 8, pack16to32(mv_l0[0],mv_l0[1]), 4);\n\n                fill_rectangle(&h-> mv_cache[1][scan8[0]], 4, 4, 8, pack16to32(mv_l0[0]-mv_col[0],mv_l0[1]-mv_col[1]), 4);\n\n            }\n\n        }else{\n\n            for(i8=0; i8<4; i8++){\n\n                const int x8 = i8&1;\n\n                const int y8 = i8>>1;\n\n                int ref0, dist_scale_factor;\n\n                const int16_t (*l1mv)[2]= l1mv0;\n\n\n\n                if(is_b8x8 && !IS_DIRECT(h->sub_mb_type[i8]))\n\n                    continue;\n\n                h->sub_mb_type[i8] = sub_mb_type;\n\n                if(IS_INTRA(mb_type_col)){\n\n                    fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, 0, 1);\n\n                    fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, 0, 1);\n\n                    fill_rectangle(&h-> mv_cache[0][scan8[i8*4]], 2, 2, 8, 0, 4);\n\n                    fill_rectangle(&h-> mv_cache[1][scan8[i8*4]], 2, 2, 8, 0, 4);\n\n                    continue;\n\n                }\n\n\n\n                ref0 = l1ref0[x8 + y8*h->b8_stride];\n\n                if(ref0 >= 0)\n\n                    ref0 = h->map_col_to_list0[0][ref0];\n\n                else{\n\n                    ref0 = h->map_col_to_list0[1][l1ref1[x8 + y8*h->b8_stride]];\n\n                    l1mv= l1mv1;\n\n                }\n\n                dist_scale_factor = h->dist_scale_factor[ref0];\n\n\n\n                fill_rectangle(&h->ref_cache[0][scan8[i8*4]], 2, 2, 8, ref0, 1);\n\n                fill_rectangle(&h->ref_cache[1][scan8[i8*4]], 2, 2, 8, 0, 1);\n\n                for(i4=0; i4<4; i4++){\n\n                    const int16_t *mv_col = l1mv[x8*2 + (i4&1) + (y8*2 + (i4>>1))*h->b_stride];\n\n                    int16_t *mv_l0 = h->mv_cache[0][scan8[i8*4+i4]];\n\n                    mv_l0[0] = (dist_scale_factor * mv_col[0] + 128) >> 8;\n\n                    mv_l0[1] = (dist_scale_factor * mv_col[1] + 128) >> 8;\n\n                    *(uint32_t*)h->mv_cache[1][scan8[i8*4+i4]] =\n\n                        pack16to32(mv_l0[0]-mv_col[0],mv_l0[1]-mv_col[1]);\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 17932, "_split": "test", "_hash": "6d34752520e26e8add9a8942aaf15849"}
{"project": "FFmpeg", "commit_id": "2aab7c2dfaca4386c38e5d565cd2bf73096bcc86", "target": 0, "func": "void ff_put_h264_qpel8_mc31_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_8w_msa(src - 2,\n\n                           src - (stride * 2) +\n\n                           sizeof(uint8_t), stride, dst, stride, 8);\n\n}\n", "idx": 17954, "_split": "test", "_hash": "df80cd036a86d1c6a2c2fabfd2385e52"}
{"project": "FFmpeg", "commit_id": "ddd86a2924b9bc67c406cd66ebb1fc8915cd60f7", "target": 1, "func": "static int output_packet(InputStream *ist,\n\n                         OutputStream *ost_table, int nb_ostreams,\n\n                         const AVPacket *pkt)\n\n{\n\n    int ret = 0, i;\n\n    int got_output;\n\n    int64_t pkt_pts = AV_NOPTS_VALUE;\n\n\n\n    AVPacket avpkt;\n\n\n\n    if (ist->next_dts == AV_NOPTS_VALUE)\n\n        ist->next_dts = ist->dts;\n\n    if (ist->next_pts == AV_NOPTS_VALUE)\n\n        ist->next_pts = ist->pts;\n\n\n\n    if (pkt == NULL) {\n\n        /* EOF handling */\n\n        av_init_packet(&avpkt);\n\n        avpkt.data = NULL;\n\n        avpkt.size = 0;\n\n        goto handle_eof;\n\n    } else {\n\n        avpkt = *pkt;\n\n    }\n\n\n\n    if (pkt->dts != AV_NOPTS_VALUE) {\n\n        ist->next_dts = ist->dts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n        if (ist->st->codec->codec_type != AVMEDIA_TYPE_VIDEO || !ist->decoding_needed)\n\n            ist->next_pts = ist->pts = av_rescale_q(pkt->dts, ist->st->time_base, AV_TIME_BASE_Q);\n\n    }\n\n    if(pkt->pts != AV_NOPTS_VALUE)\n\n        pkt_pts = av_rescale_q(pkt->pts, ist->st->time_base, AV_TIME_BASE_Q);\n\n\n\n    // while we have more to decode or while the decoder did output something on EOF\n\n    while (ist->decoding_needed && (avpkt.size > 0 || (!pkt && got_output))) {\n\n        int duration;\n\n    handle_eof:\n\n\n\n        ist->pts = ist->next_pts;\n\n        ist->dts = ist->next_dts;\n\n\n\n        if (avpkt.size && avpkt.size != pkt->size) {\n\n            av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING,\n\n                   \"Multiple frames in a packet from stream %d\\n\", pkt->stream_index);\n\n            ist->showed_multi_packet_warning = 1;\n\n        }\n\n\n\n        switch (ist->st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ret = transcode_audio    (ist, &avpkt, &got_output);\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            ret = transcode_video    (ist, &avpkt, &got_output, &pkt_pts);\n\n            if (avpkt.duration) {\n\n                duration = av_rescale_q(avpkt.duration, ist->st->time_base, AV_TIME_BASE_Q);\n\n            } else if(ist->st->codec->time_base.num != 0) {\n\n                int ticks= ist->st->parser ? ist->st->parser->repeat_pict+1 : ist->st->codec->ticks_per_frame;\n\n                duration = ((int64_t)AV_TIME_BASE *\n\n                                ist->st->codec->time_base.num * ticks) /\n\n                                ist->st->codec->time_base.den;\n\n            } else\n\n                duration = 0;\n\n\n\n            if(ist->dts != AV_NOPTS_VALUE && duration) {\n\n                ist->next_dts += duration;\n\n            }else\n\n                ist->next_dts = AV_NOPTS_VALUE;\n\n\n\n            if (got_output)\n\n                ist->next_pts += duration; //FIXME the duration is not correct in some cases\n\n            break;\n\n        case AVMEDIA_TYPE_SUBTITLE:\n\n            ret = transcode_subtitles(ist, &avpkt, &got_output);\n\n            break;\n\n        default:\n\n            return -1;\n\n        }\n\n\n\n        if (ret < 0)\n\n            return ret;\n\n\n\n        avpkt.dts=\n\n        avpkt.pts= AV_NOPTS_VALUE;\n\n\n\n        // touch data and size only if not EOF\n\n        if (pkt) {\n\n            if(ist->st->codec->codec_type != AVMEDIA_TYPE_AUDIO)\n\n                ret = avpkt.size;\n\n            avpkt.data += ret;\n\n            avpkt.size -= ret;\n\n        }\n\n        if (!got_output) {\n\n            continue;\n\n        }\n\n    }\n\n\n\n    /* handle stream copy */\n\n    if (!ist->decoding_needed) {\n\n        rate_emu_sleep(ist);\n\n        ist->dts = ist->next_dts;\n\n        switch (ist->st->codec->codec_type) {\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            ist->next_dts += ((int64_t)AV_TIME_BASE * ist->st->codec->frame_size) /\n\n                             ist->st->codec->sample_rate;\n\n            break;\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            if (pkt->duration) {\n\n                ist->next_dts += av_rescale_q(pkt->duration, ist->st->time_base, AV_TIME_BASE_Q);\n\n            } else if(ist->st->codec->time_base.num != 0) {\n\n                int ticks= ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->st->codec->ticks_per_frame;\n\n                ist->next_dts += ((int64_t)AV_TIME_BASE *\n\n                                  ist->st->codec->time_base.num * ticks) /\n\n                                  ist->st->codec->time_base.den;\n\n            }\n\n            break;\n\n        }\n\n        ist->pts = ist->dts;\n\n        ist->next_pts = ist->next_dts;\n\n    }\n\n    for (i = 0; pkt && i < nb_ostreams; i++) {\n\n        OutputStream *ost = &ost_table[i];\n\n\n\n        if (!check_output_constraints(ist, ost) || ost->encoding_needed)\n\n            continue;\n\n\n\n        do_streamcopy(ist, ost, pkt);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 18077, "_split": "test", "_hash": "9b9470d48720254be8dd0335f8d6d1d6"}
{"project": "FFmpeg", "commit_id": "af2ee6fc4921a81133c0915985e05781505c2ff8", "target": 0, "func": "static void search_for_quantizers_anmr(AVCodecContext *avctx, AACEncContext *s,\n\n                                       SingleChannelElement *sce,\n\n                                       const float lambda)\n\n{\n\n    int q, w, w2, g, start = 0;\n\n    int i, j;\n\n    int idx;\n\n    TrellisPath paths[TRELLIS_STAGES][TRELLIS_STATES];\n\n    int bandaddr[TRELLIS_STAGES];\n\n    int minq;\n\n    float mincost;\n\n    float q0f = FLT_MAX, q1f = 0.0f, qnrgf = 0.0f;\n\n    int q0, q1, qcnt = 0;\n\n\n\n    for (i = 0; i < 1024; i++) {\n\n        float t = fabsf(sce->coeffs[i]);\n\n        if (t > 0.0f) {\n\n            q0f = FFMIN(q0f, t);\n\n            q1f = FFMAX(q1f, t);\n\n            qnrgf += t*t;\n\n            qcnt++;\n\n        }\n\n    }\n\n\n\n    if (!qcnt) {\n\n        memset(sce->sf_idx, 0, sizeof(sce->sf_idx));\n\n        memset(sce->zeroes, 1, sizeof(sce->zeroes));\n\n        return;\n\n    }\n\n\n\n    //minimum scalefactor index is when minimum nonzero coefficient after quantizing is not clipped\n\n    q0 = av_clip_uint8(log2(q0f)*4 - 69 + SCALE_ONE_POS - SCALE_DIV_512);\n\n    //maximum scalefactor index is when maximum coefficient after quantizing is still not zero\n\n    q1 = av_clip_uint8(log2(q1f)*4 +  6 + SCALE_ONE_POS - SCALE_DIV_512);\n\n    //av_log(NULL, AV_LOG_ERROR, \"q0 %d, q1 %d\\n\", q0, q1);\n\n    if (q1 - q0 > 60) {\n\n        int q0low  = q0;\n\n        int q1high = q1;\n\n        //minimum scalefactor index is when maximum nonzero coefficient after quantizing is not clipped\n\n        int qnrg = av_clip_uint8(log2(sqrt(qnrgf/qcnt))*4 - 31 + SCALE_ONE_POS - SCALE_DIV_512);\n\n        q1 = qnrg + 30;\n\n        q0 = qnrg - 30;\n\n    //av_log(NULL, AV_LOG_ERROR, \"q0 %d, q1 %d\\n\", q0, q1);\n\n        if (q0 < q0low) {\n\n            q1 += q0low - q0;\n\n            q0  = q0low;\n\n        } else if (q1 > q1high) {\n\n            q0 -= q1 - q1high;\n\n            q1  = q1high;\n\n        }\n\n    }\n\n    //av_log(NULL, AV_LOG_ERROR, \"q0 %d, q1 %d\\n\", q0, q1);\n\n\n\n    for (i = 0; i < TRELLIS_STATES; i++) {\n\n        paths[0][i].cost    = 0.0f;\n\n        paths[0][i].prev    = -1;\n\n    }\n\n    for (j = 1; j < TRELLIS_STAGES; j++) {\n\n        for (i = 0; i < TRELLIS_STATES; i++) {\n\n            paths[j][i].cost    = INFINITY;\n\n            paths[j][i].prev    = -2;\n\n        }\n\n    }\n\n    idx = 1;\n\n    abs_pow34_v(s->scoefs, sce->coeffs, 1024);\n\n    for (w = 0; w < sce->ics.num_windows; w += sce->ics.group_len[w]) {\n\n        start = w*128;\n\n        for (g = 0; g < sce->ics.num_swb; g++) {\n\n            const float *coefs = sce->coeffs + start;\n\n            float qmin, qmax;\n\n            int nz = 0;\n\n\n\n            bandaddr[idx] = w * 16 + g;\n\n            qmin = INT_MAX;\n\n            qmax = 0.0f;\n\n            for (w2 = 0; w2 < sce->ics.group_len[w]; w2++) {\n\n                FFPsyBand *band = &s->psy.psy_bands[s->cur_channel*PSY_MAX_BANDS+(w+w2)*16+g];\n\n                if (band->energy <= band->threshold || band->threshold == 0.0f) {\n\n                    sce->zeroes[(w+w2)*16+g] = 1;\n\n                    continue;\n\n                }\n\n                sce->zeroes[(w+w2)*16+g] = 0;\n\n                nz = 1;\n\n                for (i = 0; i < sce->ics.swb_sizes[g]; i++) {\n\n                    float t = fabsf(coefs[w2*128+i]);\n\n                    if (t > 0.0f)\n\n                        qmin = FFMIN(qmin, t);\n\n                    qmax = FFMAX(qmax, t);\n\n                }\n\n            }\n\n            if (nz) {\n\n                int minscale, maxscale;\n\n                float minrd = INFINITY;\n\n                //minimum scalefactor index is when minimum nonzero coefficient after quantizing is not clipped\n\n                minscale = av_clip_uint8(log2(qmin)*4 - 69 + SCALE_ONE_POS - SCALE_DIV_512);\n\n                //maximum scalefactor index is when maximum coefficient after quantizing is still not zero\n\n                maxscale = av_clip_uint8(log2(qmax)*4 +  6 + SCALE_ONE_POS - SCALE_DIV_512);\n\n                minscale = av_clip(minscale - q0, 0, TRELLIS_STATES - 1);\n\n                maxscale = av_clip(maxscale - q0, 0, TRELLIS_STATES);\n\n                for (q = minscale; q < maxscale; q++) {\n\n                    float dist = 0;\n\n                    int cb = find_min_book(sce->sf_idx[w*16+g], sce->ics.group_len[w], sce->ics.swb_sizes[g], s->scoefs+start);\n\n                    for (w2 = 0; w2 < sce->ics.group_len[w]; w2++) {\n\n                        FFPsyBand *band = &s->psy.psy_bands[s->cur_channel*PSY_MAX_BANDS+(w+w2)*16+g];\n\n                        dist += quantize_band_cost(s, coefs + w2*128, s->scoefs + start + w2*128, sce->ics.swb_sizes[g],\n\n                                                            q + q0, cb, lambda / band->threshold, INFINITY, NULL);\n\n                    }\n\n                    minrd = FFMIN(minrd, dist);\n\n\n\n                    for (i = 0; i < q1 - q0; i++) {\n\n                        float cost;\n\n                        if (isinf(paths[idx - 1][i].cost))\n\n                            continue;\n\n                        cost = paths[idx - 1][i].cost + dist\n\n                               + ff_aac_scalefactor_bits[q - i + SCALE_DIFF_ZERO];\n\n                        if (cost < paths[idx][q].cost) {\n\n                            paths[idx][q].cost    = cost;\n\n                            paths[idx][q].prev    = i;\n\n                        }\n\n                    }\n\n                }\n\n            } else {\n\n                for (q = 0; q < q1 - q0; q++) {\n\n                    if (!isinf(paths[idx - 1][q].cost)) {\n\n                        paths[idx][q].cost = paths[idx - 1][q].cost + 1;\n\n                        paths[idx][q].prev = q;\n\n                        continue;\n\n                    }\n\n                    for (i = 0; i < q1 - q0; i++) {\n\n                        float cost;\n\n                        if (isinf(paths[idx - 1][i].cost))\n\n                            continue;\n\n                        cost = paths[idx - 1][i].cost + ff_aac_scalefactor_bits[q - i + SCALE_DIFF_ZERO];\n\n                        if (cost < paths[idx][q].cost) {\n\n                            paths[idx][q].cost    = cost;\n\n                            paths[idx][q].prev    = i;\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n            sce->zeroes[w*16+g] = !nz;\n\n            start += sce->ics.swb_sizes[g];\n\n            idx++;\n\n        }\n\n    }\n\n    idx--;\n\n    mincost = paths[idx][0].cost;\n\n    minq    = 0;\n\n    for (i = 1; i < TRELLIS_STATES; i++) {\n\n        if (paths[idx][i].cost < mincost) {\n\n            mincost = paths[idx][i].cost;\n\n            minq = i;\n\n        }\n\n    }\n\n    while (idx) {\n\n        sce->sf_idx[bandaddr[idx]] = minq + q0;\n\n        minq = paths[idx][minq].prev;\n\n        idx--;\n\n    }\n\n    //set the same quantizers inside window groups\n\n    for (w = 0; w < sce->ics.num_windows; w += sce->ics.group_len[w])\n\n        for (g = 0;  g < sce->ics.num_swb; g++)\n\n            for (w2 = 1; w2 < sce->ics.group_len[w]; w2++)\n\n                sce->sf_idx[(w+w2)*16+g] = sce->sf_idx[w*16+g];\n\n}\n", "idx": 18095, "_split": "test", "_hash": "2a42463c3548b91c0d8dbc4390efbf87"}
{"project": "FFmpeg", "commit_id": "daa7a1d4431b6acf1f93c4a98b3de123abf4ca18", "target": 0, "func": "void ff_slice_thread_free(AVCodecContext *avctx)\n\n{\n\n    ThreadContext *c = avctx->thread_opaque;\n\n    int i;\n\n\n\n    pthread_mutex_lock(&c->current_job_lock);\n\n    c->done = 1;\n\n    pthread_cond_broadcast(&c->current_job_cond);\n\n    pthread_mutex_unlock(&c->current_job_lock);\n\n\n\n    for (i=0; i<avctx->thread_count; i++)\n\n         pthread_join(c->workers[i], NULL);\n\n\n\n    pthread_mutex_destroy(&c->current_job_lock);\n\n    pthread_cond_destroy(&c->current_job_cond);\n\n    pthread_cond_destroy(&c->last_job_cond);\n\n    av_free(c->workers);\n\n    av_freep(&avctx->thread_opaque);\n\n}\n", "idx": 18171, "_split": "test", "_hash": "04e9a868d65108fbc463d108f6348988"}
{"project": "FFmpeg", "commit_id": "e5dd4ae7284bb290d8dc8e9cd3f2e035d1d77cd0", "target": 1, "func": "static int ass_decode_frame(AVCodecContext *avctx, void *data, int *got_sub_ptr,\n\n                            AVPacket *avpkt)\n\n{\n\n    const char *ptr = avpkt->data;\n\n    int len, size = avpkt->size;\n\n\n\n    while (size > 0) {\n\n        ASSDialog *dialog = ff_ass_split_dialog(avctx->priv_data, ptr, 0, NULL);\n\n        int duration = dialog->end - dialog->start;\n\n        len = ff_ass_add_rect(data, ptr, 0, duration, 1);\n\n        if (len < 0)\n\n            return len;\n\n        ptr  += len;\n\n        size -= len;\n\n    }\n\n\n\n    *got_sub_ptr = avpkt->size > 0;\n\n    return avpkt->size;\n\n}\n", "idx": 18175, "_split": "test", "_hash": "cecd7d34d650c057e252fadba3709c0e"}
{"project": "FFmpeg", "commit_id": "b754978a3b0aa17e7794f64c69bf4491762797fd", "target": 0, "func": "static void add_index_entry(AVStream *st,\n\n                            int64_t pos, int64_t timestamp, int flags)\n\n{\n\n    AVIndexEntry *entries, *ie;\n\n    \n\n    entries = av_fast_realloc(st->index_entries,\n\n                              &st->index_entries_allocated_size,\n\n                              (st->nb_index_entries + 1) * \n\n                              sizeof(AVIndexEntry));\n\n    if (entries) {\n\n        st->index_entries = entries;\n\n        ie = &entries[st->nb_index_entries++];\n\n        ie->pos = pos;\n\n        ie->timestamp = timestamp;\n\n        ie->flags = flags;\n\n    }\n\n}\n", "idx": 18200, "_split": "test", "_hash": "fb89d929ee5751a8ded689e84e6b97c1"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "static int rv10_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    MpegEncContext *s = avctx->priv_data;\n\n    AVFrame *pict = data;\n\n    int i, ret;\n\n    int slice_count;\n\n    const uint8_t *slices_hdr = NULL;\n\n\n\n    av_dlog(avctx, \"*****frame %d size=%d\\n\", avctx->frame_number, buf_size);\n\n\n\n    /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        return 0;\n\n    }\n\n\n\n    if (!avctx->slice_count) {\n\n        slice_count = (*buf++) + 1;\n\n        buf_size--;\n\n\n\n        if (!slice_count || buf_size <= 8 * slice_count) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Invalid slice count: %d.\\n\",\n\n                   slice_count);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        slices_hdr = buf + 4;\n\n        buf       += 8 * slice_count;\n\n        buf_size  -= 8 * slice_count;\n\n    } else\n\n        slice_count = avctx->slice_count;\n\n\n\n    for (i = 0; i < slice_count; i++) {\n\n        unsigned offset = get_slice_offset(avctx, slices_hdr, i);\n\n        int size, size2;\n\n\n\n        if (offset >= buf_size)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        if (i + 1 == slice_count)\n\n            size = buf_size - offset;\n\n        else\n\n            size = get_slice_offset(avctx, slices_hdr, i + 1) - offset;\n\n\n\n        if (i + 2 >= slice_count)\n\n            size2 = buf_size - offset;\n\n        else\n\n            size2 = get_slice_offset(avctx, slices_hdr, i + 2) - offset;\n\n\n\n        if (size <= 0 || size2 <= 0 ||\n\n            offset + FFMAX(size, size2) > buf_size)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        if ((ret = rv10_decode_packet(avctx, buf + offset, size, size2)) < 0)\n\n            return ret;\n\n\n\n        if (ret > 8 * size)\n\n            i++;\n\n    }\n\n\n\n    if (s->current_picture_ptr != NULL && s->mb_y >= s->mb_height) {\n\n        ff_er_frame_end(&s->er);\n\n        ff_MPV_frame_end(s);\n\n\n\n        if (s->pict_type == AV_PICTURE_TYPE_B || s->low_delay) {\n\n            if ((ret = av_frame_ref(pict, &s->current_picture_ptr->f)) < 0)\n\n                return ret;\n\n            ff_print_debug_info(s, s->current_picture_ptr);\n\n        } else if (s->last_picture_ptr != NULL) {\n\n            if ((ret = av_frame_ref(pict, &s->last_picture_ptr->f)) < 0)\n\n                return ret;\n\n            ff_print_debug_info(s, s->last_picture_ptr);\n\n        }\n\n\n\n        if (s->last_picture_ptr || s->low_delay) {\n\n            *got_frame = 1;\n\n        }\n\n\n\n        // so we can detect if frame_end was not called (find some nicer solution...)\n\n        s->current_picture_ptr = NULL;\n\n    }\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 18202, "_split": "test", "_hash": "d90a08255a69bf9816a4dd3ef42cfa4b"}
{"project": "FFmpeg", "commit_id": "aba232cfa9b193604ed98f3fa505378d006b1b3b", "target": 1, "func": "ff_rm_read_mdpr_codecdata (AVFormatContext *s, AVIOContext *pb,\n\n                           AVStream *st, RMStream *rst, int codec_data_size)\n\n{\n\n    unsigned int v;\n\n    int size;\n\n    int64_t codec_pos;\n\n    int ret;\n\n\n\n    avpriv_set_pts_info(st, 64, 1, 1000);\n\n    codec_pos = avio_tell(pb);\n\n    v = avio_rb32(pb);\n\n    if (v == MKTAG(0xfd, 'a', 'r', '.')) {\n\n        /* ra type header */\n\n        if (rm_read_audio_stream_info(s, pb, st, rst, 0))\n\n            return -1;\n\n    } else if (v == MKBETAG('L', 'S', 'D', ':')) {\n\n        avio_seek(pb, -4, SEEK_CUR);\n\n        if ((ret = rm_read_extradata(pb, st->codec, codec_data_size)) < 0)\n\n            return ret;\n\n\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        st->codec->codec_tag  = AV_RL32(st->codec->extradata);\n\n        st->codec->codec_id   = ff_codec_get_id(ff_rm_codec_tags,\n\n                                                st->codec->codec_tag);\n\n    } else {\n\n        int fps;\n\n        if (avio_rl32(pb) != MKTAG('V', 'I', 'D', 'O')) {\n\n        fail1:\n\n            av_log(st->codec, AV_LOG_ERROR, \"Unsupported video codec\\n\");\n\n            goto skip;\n\n        }\n\n        st->codec->codec_tag = avio_rl32(pb);\n\n        st->codec->codec_id  = ff_codec_get_id(ff_rm_codec_tags,\n\n                                               st->codec->codec_tag);\n\n//        av_log(s, AV_LOG_DEBUG, \"%X %X\\n\", st->codec->codec_tag, MKTAG('R', 'V', '2', '0'));\n\n        if (st->codec->codec_id == CODEC_ID_NONE)\n\n            goto fail1;\n\n        st->codec->width  = avio_rb16(pb);\n\n        st->codec->height = avio_rb16(pb);\n\n        avio_skip(pb, 2); // looks like bits per sample\n\n        avio_skip(pb, 4); // always zero?\n\n        st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n        st->need_parsing = AVSTREAM_PARSE_TIMESTAMPS;\n\n        fps = avio_rb32(pb);\n\n\n\n        if ((ret = rm_read_extradata(pb, st->codec, codec_data_size - (avio_tell(pb) - codec_pos))) < 0)\n\n            return ret;\n\n\n\n        av_reduce(&st->r_frame_rate.den, &st->r_frame_rate.num,\n\n                  0x10000, fps, (1 << 30) - 1);\n\n        st->avg_frame_rate = st->r_frame_rate;\n\n    }\n\n\n\nskip:\n\n    /* skip codec info */\n\n    size = avio_tell(pb) - codec_pos;\n\n    avio_skip(pb, codec_data_size - size);\n\n\n\n    return 0;\n\n}\n", "idx": 18203, "_split": "test", "_hash": "9017cd286701b5ad6cb3379d58703088"}
{"project": "FFmpeg", "commit_id": "5e5f75cf8abd76ada3011790a9b4f0762a72e41a", "target": 0, "func": "static void ffm_write_data(AVFormatContext *s,\n\n                           const uint8_t *buf, int size,\n\n                           int64_t pts, int header)\n\n{\n\n    FFMContext *ffm = s->priv_data;\n\n    int len;\n\n\n\n    if (header && ffm->frame_offset == 0) {\n\n        ffm->frame_offset = ffm->packet_ptr - ffm->packet + FFM_HEADER_SIZE;\n\n        ffm->pts = pts;\n\n    }\n\n\n\n    /* write as many packets as needed */\n\n    while (size > 0) {\n\n        len = ffm->packet_end - ffm->packet_ptr;\n\n        if (len > size)\n\n            len = size;\n\n        memcpy(ffm->packet_ptr, buf, len);\n\n\n\n        ffm->packet_ptr += len;\n\n        buf += len;\n\n        size -= len;\n\n        if (ffm->packet_ptr >= ffm->packet_end) {\n\n            /* special case : no pts in packet : we leave the current one */\n\n            if (ffm->pts == 0)\n\n                ffm->pts = pts;\n\n\n\n            flush_packet(s);\n\n        }\n\n    }\n\n}\n", "idx": 18268, "_split": "test", "_hash": "dd0347c9daf3772ffedd96c1a6cfff90"}
{"project": "FFmpeg", "commit_id": "1acd7d594c15aa491729c837ad3519d3469e620a", "target": 0, "func": "static void FUNCC(pred4x4_horizontal_add)(uint8_t *_pix, const int16_t *_block,\n\n                                          ptrdiff_t stride)\n\n{\n\n    int i;\n\n    pixel *pix = (pixel*)_pix;\n\n    const dctcoef *block = (const dctcoef*)_block;\n\n    stride >>= sizeof(pixel)-1;\n\n    for(i=0; i<4; i++){\n\n        pixel v = pix[-1];\n\n        pix[0]= v += block[0];\n\n        pix[1]= v += block[1];\n\n        pix[2]= v += block[2];\n\n        pix[3]= v +  block[3];\n\n        pix+= stride;\n\n        block+= 4;\n\n    }\n\n}\n", "idx": 18279, "_split": "test", "_hash": "63590ca494b79134f9c7af8a621d61f9"}
{"project": "FFmpeg", "commit_id": "57d77b3963ce1023eaf5ada8cba58b9379405cc8", "target": 0, "func": "int av_opencl_buffer_read(uint8_t *dst_buf, cl_mem src_cl_buf, size_t buf_size)\n\n{\n\n    cl_int status;\n\n    void *mapped = clEnqueueMapBuffer(gpu_env.command_queue, src_cl_buf,\n\n                                      CL_TRUE,CL_MAP_READ, 0, buf_size,\n\n                                      0, NULL, NULL, &status);\n\n\n\n    if (status != CL_SUCCESS) {\n\n        av_log(&openclutils, AV_LOG_ERROR, \"Could not map OpenCL buffer: %s\\n\", opencl_errstr(status));\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n    memcpy(dst_buf, mapped, buf_size);\n\n\n\n    status = clEnqueueUnmapMemObject(gpu_env.command_queue, src_cl_buf, mapped, 0, NULL, NULL);\n\n    if (status != CL_SUCCESS) {\n\n        av_log(&openclutils, AV_LOG_ERROR, \"Could not unmap OpenCL buffer: %s\\n\", opencl_errstr(status));\n\n        return AVERROR_EXTERNAL;\n\n    }\n\n    return 0;\n\n}\n", "idx": 18304, "_split": "test", "_hash": "c0c83afeab3894aa40b06221e8d29c8f"}
{"project": "FFmpeg", "commit_id": "ed9b2a5178d7a7c5a95694da3a808af327f36aff", "target": 1, "func": "static int mov_read_stsc(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    unsigned int i, entries;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n    sc = st->priv_data;\n\n\n\n    avio_r8(pb); /* version */\n\n    avio_rb24(pb); /* flags */\n\n\n\n    entries = avio_rb32(pb);\n\n\n\n    av_log(c->fc, AV_LOG_TRACE, \"track[%i].stsc.entries = %i\\n\", c->fc->nb_streams-1, entries);\n\n\n\n    if (!entries)\n\n        return 0;\n\n    if (entries >= UINT_MAX / sizeof(*sc->stsc_data))\n\n        return AVERROR_INVALIDDATA;\n\n    sc->stsc_data = av_malloc(entries * sizeof(*sc->stsc_data));\n\n    if (!sc->stsc_data)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < entries && !pb->eof_reached; i++) {\n\n        sc->stsc_data[i].first = avio_rb32(pb);\n\n        sc->stsc_data[i].count = avio_rb32(pb);\n\n        sc->stsc_data[i].id = avio_rb32(pb);\n\n        if (sc->stsc_data[i].id > sc->stsd_count)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    sc->stsc_count = i;\n\n\n\n    if (pb->eof_reached)\n\n        return AVERROR_EOF;\n\n\n\n    return 0;\n\n}\n", "idx": 18311, "_split": "test", "_hash": "221443c887bbf2b596b27a4b7f906359"}
{"project": "FFmpeg", "commit_id": "8c013a9e55d9065793ef7ca6459d1178927a2b35", "target": 0, "func": "static int avi_read_tag(AVFormatContext *s, AVStream *st, uint32_t tag,\n\n                        uint32_t size)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    char key[5]     = { 0 };\n\n    char *value;\n\n\n\n    size += (size & 1);\n\n\n\n    if (size == UINT_MAX)\n\n        return AVERROR(EINVAL);\n\n    value = av_malloc(size + 1);\n\n    if (!value)\n\n        return AVERROR(ENOMEM);\n\n    avio_read(pb, value, size);\n\n    value[size] = 0;\n\n\n\n    AV_WL32(key, tag);\n\n\n\n    return av_dict_set(st ? &st->metadata : &s->metadata, key, value,\n\n                       AV_DICT_DONT_STRDUP_VAL);\n\n}\n", "idx": 18323, "_split": "test", "_hash": "1374205be759b38e72528147e369abab"}
{"project": "FFmpeg", "commit_id": "bf1945af301aff54c33352e75f17aec6cb5269d7", "target": 0, "func": "static void hybrid_analysis(float out[91][32][2], float in[5][44][2], float L[2][38][64], int is34, int len)\n\n{\n\n    int i, j;\n\n    for (i = 0; i < 5; i++) {\n\n        for (j = 0; j < 38; j++) {\n\n            in[i][j+6][0] = L[0][j][i];\n\n            in[i][j+6][1] = L[1][j][i];\n\n        }\n\n    }\n\n    if (is34) {\n\n        hybrid4_8_12_cx(in[0], out,    f34_0_12, 12, len);\n\n        hybrid4_8_12_cx(in[1], out+12, f34_1_8,   8, len);\n\n        hybrid4_8_12_cx(in[2], out+20, f34_2_4,   4, len);\n\n        hybrid4_8_12_cx(in[3], out+24, f34_2_4,   4, len);\n\n        hybrid4_8_12_cx(in[4], out+28, f34_2_4,   4, len);\n\n        for (i = 0; i < 59; i++) {\n\n            for (j = 0; j < len; j++) {\n\n                out[i+32][j][0] = L[0][j][i+5];\n\n                out[i+32][j][1] = L[1][j][i+5];\n\n            }\n\n        }\n\n    } else {\n\n        hybrid6_cx(in[0], out, f20_0_8, len);\n\n        hybrid2_re(in[1], out+6, g1_Q2, len, 1);\n\n        hybrid2_re(in[2], out+8, g1_Q2, len, 0);\n\n        for (i = 0; i < 61; i++) {\n\n            for (j = 0; j < len; j++) {\n\n                out[i+10][j][0] = L[0][j][i+3];\n\n                out[i+10][j][1] = L[1][j][i+3];\n\n            }\n\n        }\n\n    }\n\n    //update in_buf\n\n    for (i = 0; i < 5; i++) {\n\n        memcpy(in[i], in[i]+32, 6 * sizeof(in[i][0]));\n\n    }\n\n}\n", "idx": 18324, "_split": "test", "_hash": "c6dc7c8a63a4c5a7613797653065097f"}
{"project": "FFmpeg", "commit_id": "5602a464c9f9e3c0922f5cfeccaf2fa1c40b2401", "target": 0, "func": "static av_cold int vorbis_decode_init(AVCodecContext *avccontext)\n\n{\n\n    vorbis_context *vc = avccontext->priv_data;\n\n    uint8_t *headers   = avccontext->extradata;\n\n    int headers_len    = avccontext->extradata_size;\n\n    uint8_t *header_start[3];\n\n    int header_len[3];\n\n    GetBitContext *gb = &vc->gb;\n\n    int hdr_type, ret;\n\n\n\n    vc->avccontext = avccontext;\n\n    ff_dsputil_init(&vc->dsp, avccontext);\n\n    ff_fmt_convert_init(&vc->fmt_conv, avccontext);\n\n\n\n    if (avccontext->request_sample_fmt == AV_SAMPLE_FMT_FLT) {\n\n        avccontext->sample_fmt = AV_SAMPLE_FMT_FLT;\n\n        vc->scale_bias = 1.0f;\n\n    } else {\n\n        avccontext->sample_fmt = AV_SAMPLE_FMT_S16;\n\n        vc->scale_bias = 32768.0f;\n\n    }\n\n\n\n    if (!headers_len) {\n\n        av_log(avccontext, AV_LOG_ERROR, \"Extradata missing.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((ret = avpriv_split_xiph_headers(headers, headers_len, 30, header_start, header_len)) < 0) {\n\n        av_log(avccontext, AV_LOG_ERROR, \"Extradata corrupt.\\n\");\n\n        return ret;\n\n    }\n\n\n\n    init_get_bits(gb, header_start[0], header_len[0]*8);\n\n    hdr_type = get_bits(gb, 8);\n\n    if (hdr_type != 1) {\n\n        av_log(avccontext, AV_LOG_ERROR, \"First header is not the id header.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if ((ret = vorbis_parse_id_hdr(vc))) {\n\n        av_log(avccontext, AV_LOG_ERROR, \"Id header corrupt.\\n\");\n\n        vorbis_free(vc);\n\n        return ret;\n\n    }\n\n\n\n    init_get_bits(gb, header_start[2], header_len[2]*8);\n\n    hdr_type = get_bits(gb, 8);\n\n    if (hdr_type != 5) {\n\n        av_log(avccontext, AV_LOG_ERROR, \"Third header is not the setup header.\\n\");\n\n        vorbis_free(vc);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if ((ret = vorbis_parse_setup_hdr(vc))) {\n\n        av_log(avccontext, AV_LOG_ERROR, \"Setup header corrupt.\\n\");\n\n        vorbis_free(vc);\n\n        return ret;\n\n    }\n\n\n\n    if (vc->audio_channels > 8)\n\n        avccontext->channel_layout = 0;\n\n    else\n\n        avccontext->channel_layout = ff_vorbis_channel_layouts[vc->audio_channels - 1];\n\n\n\n    avccontext->channels    = vc->audio_channels;\n\n    avccontext->sample_rate = vc->audio_samplerate;\n\n    avccontext->frame_size  = FFMIN(vc->blocksize[0], vc->blocksize[1]) >> 2;\n\n\n\n    avcodec_get_frame_defaults(&vc->frame);\n\n    avccontext->coded_frame = &vc->frame;\n\n\n\n    return 0;\n\n}\n", "idx": 18371, "_split": "test", "_hash": "49fe18336f501975f6c32c3b2e984979"}
{"project": "FFmpeg", "commit_id": "5ff998a233d759d0de83ea6f95c383d03d25d88e", "target": 1, "func": "static uint32_t calc_optimal_rice_params(RiceContext *rc, int porder,\n\n                                         uint32_t *sums, int n, int pred_order)\n\n{\n\n    int i;\n\n    int k, cnt, part;\n\n    uint32_t all_bits;\n\n\n\n    part     = (1 << porder);\n\n    all_bits = 4 * part;\n\n\n\n    cnt = (n >> porder) - pred_order;\n\n    for (i = 0; i < part; i++) {\n\n        k = find_optimal_param(sums[i], cnt);\n\n        rc->params[i] = k;\n\n        all_bits += rice_encode_count(sums[i], cnt, k);\n\n        cnt = n >> porder;\n\n    }\n\n\n\n    rc->porder = porder;\n\n\n\n    return all_bits;\n\n}\n", "idx": 18426, "_split": "test", "_hash": "aec51991d8e5002551daae89fb185864"}
{"project": "FFmpeg", "commit_id": "38d553322891c8e47182f05199d19888422167dc", "target": 1, "func": "int av_image_alloc(uint8_t *pointers[4], int linesizes[4],\n\n                   int w, int h, enum PixelFormat pix_fmt, int align)\n\n{\n\n    int i, ret;\n\n    uint8_t *buf;\n\n\n\n    if ((ret = av_image_check_size(w, h, 0, NULL)) < 0)\n\n        return ret;\n\n    if ((ret = av_image_fill_linesizes(linesizes, pix_fmt, w)) < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < 4; i++)\n\n        linesizes[i] = FFALIGN(linesizes[i], align);\n\n\n\n    if ((ret = av_image_fill_pointers(pointers, pix_fmt, h, NULL, linesizes)) < 0)\n\n        return ret;\n\n    buf = av_malloc(ret + align);\n\n    if (!buf)\n\n        return AVERROR(ENOMEM);\n\n    if ((ret = av_image_fill_pointers(pointers, pix_fmt, h, buf, linesizes)) < 0) {\n\n        av_free(buf);\n\n        return ret;\n\n    }\n\n    if (av_pix_fmt_descriptors[pix_fmt].flags & PIX_FMT_PAL)\n\n        ff_set_systematic_pal2((uint32_t*)pointers[1], pix_fmt);\n\n\n\n    return ret;\n\n}\n", "idx": 18438, "_split": "test", "_hash": "e010fdf9284e648ad5b317cf0b8e148d"}
{"project": "FFmpeg", "commit_id": "98b377004d9c6fa1c1756c814efe9882b65f96b9", "target": 0, "func": "static av_cold int twin_decode_init(AVCodecContext *avctx)\n\n{\n\n    int ret;\n\n    TwinContext *tctx = avctx->priv_data;\n\n    int isampf, ibps;\n\n\n\n    tctx->avctx       = avctx;\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_FLTP;\n\n\n\n    if (!avctx->extradata || avctx->extradata_size < 12) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Missing or incomplete extradata\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avctx->channels = AV_RB32(avctx->extradata    ) + 1;\n\n    avctx->bit_rate = AV_RB32(avctx->extradata + 4) * 1000;\n\n    isampf          = AV_RB32(avctx->extradata + 8);\n\n\n\n    if (isampf < 8 || isampf > 44) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported sample rate\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    switch (isampf) {\n\n    case 44: avctx->sample_rate = 44100;         break;\n\n    case 22: avctx->sample_rate = 22050;         break;\n\n    case 11: avctx->sample_rate = 11025;         break;\n\n    default: avctx->sample_rate = isampf * 1000; break;\n\n    }\n\n\n\n    if (avctx->channels <= 0 || avctx->channels > CHANNELS_MAX) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported number of channels: %i\\n\",\n\n               avctx->channels);\n\n        return -1;\n\n    }\n\n    avctx->channel_layout = avctx->channels == 1 ? AV_CH_LAYOUT_MONO :\n\n                                                   AV_CH_LAYOUT_STEREO;\n\n\n\n    ibps = avctx->bit_rate / (1000 * avctx->channels);\n\n\n\n    if (ibps > 255) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported per channel bitrate %dkbps\\n\", ibps);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch ((isampf << 8) +  ibps) {\n\n    case (8 <<8) +  8: tctx->mtab = &mode_08_08; break;\n\n    case (11<<8) +  8: tctx->mtab = &mode_11_08; break;\n\n    case (11<<8) + 10: tctx->mtab = &mode_11_10; break;\n\n    case (16<<8) + 16: tctx->mtab = &mode_16_16; break;\n\n    case (22<<8) + 20: tctx->mtab = &mode_22_20; break;\n\n    case (22<<8) + 24: tctx->mtab = &mode_22_24; break;\n\n    case (22<<8) + 32: tctx->mtab = &mode_22_32; break;\n\n    case (44<<8) + 40: tctx->mtab = &mode_44_40; break;\n\n    case (44<<8) + 48: tctx->mtab = &mode_44_48; break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"This version does not support %d kHz - %d kbit/s/ch mode.\\n\", isampf, isampf);\n\n        return -1;\n\n    }\n\n\n\n    ff_dsputil_init(&tctx->dsp, avctx);\n\n    avpriv_float_dsp_init(&tctx->fdsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n    if ((ret = init_mdct_win(tctx))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing MDCT\\n\");\n\n        twin_decode_close(avctx);\n\n        return ret;\n\n    }\n\n    init_bitstream_params(tctx);\n\n\n\n    memset_float(tctx->bark_hist[0][0], 0.1, FF_ARRAY_ELEMS(tctx->bark_hist));\n\n\n\n    avcodec_get_frame_defaults(&tctx->frame);\n\n    avctx->coded_frame = &tctx->frame;\n\n\n\n    return 0;\n\n}\n", "idx": 18462, "_split": "test", "_hash": "803900cba7ea11b81600a0d0330e2d41"}
{"project": "FFmpeg", "commit_id": "18ff4d20201ae69fdeb2da2c90bdcbd33f7ac025", "target": 1, "func": "static int copy_chapters(InputFile *ifile, OutputFile *ofile, int copy_metadata)\n\n{\n\n    AVFormatContext *is = ifile->ctx;\n\n    AVFormatContext *os = ofile->ctx;\n\n    int i;\n\n\n\n    for (i = 0; i < is->nb_chapters; i++) {\n\n        AVChapter *in_ch = is->chapters[i], *out_ch;\n\n        int64_t ts_off   = av_rescale_q(ofile->start_time - ifile->ts_offset,\n\n                                       AV_TIME_BASE_Q, in_ch->time_base);\n\n        int64_t rt       = (ofile->recording_time == INT64_MAX) ? INT64_MAX :\n\n                           av_rescale_q(ofile->recording_time, AV_TIME_BASE_Q, in_ch->time_base);\n\n\n\n\n\n        if (in_ch->end < ts_off)\n\n            continue;\n\n        if (rt != INT64_MAX && in_ch->start > rt + ts_off)\n\n            break;\n\n\n\n        out_ch = av_mallocz(sizeof(AVChapter));\n\n        if (!out_ch)\n\n            return AVERROR(ENOMEM);\n\n\n\n        out_ch->id        = in_ch->id;\n\n        out_ch->time_base = in_ch->time_base;\n\n        out_ch->start     = FFMAX(0,  in_ch->start - ts_off);\n\n        out_ch->end       = FFMIN(rt, in_ch->end   - ts_off);\n\n\n\n        if (copy_metadata)\n\n            av_dict_copy(&out_ch->metadata, in_ch->metadata, 0);\n\n\n\n        os->nb_chapters++;\n\n        os->chapters = av_realloc(os->chapters, sizeof(AVChapter) * os->nb_chapters);\n\n        if (!os->chapters)\n\n            return AVERROR(ENOMEM);\n\n        os->chapters[os->nb_chapters - 1] = out_ch;\n\n    }\n\n    return 0;\n\n}\n", "idx": 18474, "_split": "test", "_hash": "803da9ffd90be5eec217de5e34c2b5d1"}
{"project": "FFmpeg", "commit_id": "64e105e051ca3e5088b0db64551244482b2836b4", "target": 0, "func": "static void dyn_buf_write(void *opaque, UINT8 *buf, int buf_size)\n\n{\n\n    DynBuffer *d = opaque;\n\n    int new_size, new_allocated_size;\n\n    UINT8 *new_buffer;\n\n    \n\n    /* reallocate buffer if needed */\n\n    new_size = d->pos + buf_size;\n\n    new_allocated_size = d->allocated_size;\n\n    while (new_size > new_allocated_size) {\n\n        if (!new_allocated_size)\n\n            new_allocated_size = new_size;\n\n        else\n\n            new_allocated_size = (new_allocated_size * 3) / 2;\n\n    }\n\n    \n\n    if (new_allocated_size > d->allocated_size) {\n\n        new_buffer = av_malloc(new_allocated_size);\n\n        if (!new_buffer)\n\n            return;\n\n        memcpy(new_buffer, d->buffer, d->size);\n\n        av_free(d->buffer);\n\n        d->buffer = new_buffer;\n\n        d->allocated_size = new_allocated_size;\n\n    }\n\n    memcpy(d->buffer + d->pos, buf, buf_size);\n\n    d->pos = new_size;\n\n    if (d->pos > d->size)\n\n        d->size = d->pos;\n\n}\n", "idx": 18518, "_split": "test", "_hash": "46a9083234b8d1a6a5ebec6f60dac077"}
{"project": "FFmpeg", "commit_id": "20da77449d4427a7152b80e4f9acce6a8c93ee7d", "target": 0, "func": "static inline int RENAME(yuv420_rgb24)(SwsContext *c, uint8_t* src[], int srcStride[], int srcSliceY,\n\n             int srcSliceH, uint8_t* dst[], int dstStride[]){\n\n    int y, h_size;\n\n\n\n    if(c->srcFormat == PIX_FMT_YUV422P){\n\n\tsrcStride[1] *= 2;\n\n\tsrcStride[2] *= 2;\n\n    }\n\n\n\n    h_size= (c->dstW+7)&~7;\n\n    if(h_size*3 > dstStride[0]) h_size-=8;\n\n    \n\n    __asm__ __volatile__ (\"pxor %mm4, %mm4;\" /* zero mm4 */ );\n\n\n\n    for (y= 0; y<srcSliceH; y++ ) {\n\n\tuint8_t *_image = dst[0] + (y+srcSliceY)*dstStride[0];\n\n\tuint8_t *_py = src[0] + y*srcStride[0];\n\n\tuint8_t *_pu = src[1] + (y>>1)*srcStride[1];\n\n\tuint8_t *_pv = src[2] + (y>>1)*srcStride[2];\n\n\tlong index= -h_size/2;\n\n\n\n\t    /* this mmx assembly code deals with SINGLE scan line at a time, it convert 8\n\n\t       pixels in each iteration */\n\n\t    __asm__ __volatile__ (\n\n\t/* load data for start of next scan line */\n\n\t\t     \"movd (%2, %0), %%mm0;\" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\n\n\t\t     \"movd (%3, %0), %%mm1;\" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\n\n\t\t     \"movq (%5, %0, 2), %%mm6;\" /* Load 8  Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\n\n//\t\t    \".balign 16\t\t\t\\n\\t\"\n\n\t\t    \"1:\t\t\t\t\\n\\t\"\n\nYUV2RGB\n\n\t/* mm0=B, %%mm2=G, %%mm1=R */\n\n#ifdef HAVE_MMX2\n\n\t\t\t\"movq \"MANGLE(M24A)\", %%mm4\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(M24C)\", %%mm7\t\\n\\t\"\n\n\t\t\t\"pshufw $0x50, %%mm0, %%mm5\t\\n\\t\" /* B3 B2 B3 B2  B1 B0 B1 B0 */\n\n\t\t\t\"pshufw $0x50, %%mm2, %%mm3\t\\n\\t\" /* G3 G2 G3 G2  G1 G0 G1 G0 */\n\n\t\t\t\"pshufw $0x00, %%mm1, %%mm6\t\\n\\t\" /* R1 R0 R1 R0  R1 R0 R1 R0 */\n\n\n\n\t\t\t\"pand %%mm4, %%mm5\t\t\\n\\t\" /*    B2        B1       B0 */\n\n\t\t\t\"pand %%mm4, %%mm3\t\t\\n\\t\" /*    G2        G1       G0 */\n\n\t\t\t\"pand %%mm7, %%mm6\t\t\\n\\t\" /*       R1        R0       */\n\n\n\n\t\t\t\"psllq $8, %%mm3\t\t\\n\\t\" /* G2        G1       G0    */\n\n\t\t\t\"por %%mm5, %%mm6\t\t\\n\\t\"\n\n\t\t\t\"por %%mm3, %%mm6\t\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, (%1)\t\t\\n\\t\"\n\n\n\n\t\t\t\"psrlq $8, %%mm2\t\t\\n\\t\" /* 00 G7 G6 G5  G4 G3 G2 G1 */\n\n\t\t\t\"pshufw $0xA5, %%mm0, %%mm5\t\\n\\t\" /* B5 B4 B5 B4  B3 B2 B3 B2 */\n\n\t\t\t\"pshufw $0x55, %%mm2, %%mm3\t\\n\\t\" /* G4 G3 G4 G3  G4 G3 G4 G3 */\n\n\t\t\t\"pshufw $0xA5, %%mm1, %%mm6\t\\n\\t\" /* R5 R4 R5 R4  R3 R2 R3 R2 */\n\n\n\n\t\t\t\"pand \"MANGLE(M24B)\", %%mm5\t\\n\\t\" /* B5       B4        B3    */\n\n\t\t\t\"pand %%mm7, %%mm3\t\t\\n\\t\" /*       G4        G3       */\n\n\t\t\t\"pand %%mm4, %%mm6\t\t\\n\\t\" /*    R4        R3       R2 */\n\n\n\n\t\t\t\"por %%mm5, %%mm3\t\t\\n\\t\" /* B5    G4 B4     G3 B3    */\n\n\t\t\t\"por %%mm3, %%mm6\t\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, 8(%1)\t\t\\n\\t\"\n\n\n\n\t\t\t\"pshufw $0xFF, %%mm0, %%mm5\t\\n\\t\" /* B7 B6 B7 B6  B7 B6 B6 B7 */\n\n\t\t\t\"pshufw $0xFA, %%mm2, %%mm3\t\\n\\t\" /* 00 G7 00 G7  G6 G5 G6 G5 */\n\n\t\t\t\"pshufw $0xFA, %%mm1, %%mm6\t\\n\\t\" /* R7 R6 R7 R6  R5 R4 R5 R4 */\n\n\t\t\t\"movd 4 (%2, %0), %%mm0;\" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\n\n\n\n\t\t\t\"pand %%mm7, %%mm5\t\t\\n\\t\" /*       B7        B6       */\n\n\t\t\t\"pand %%mm4, %%mm3\t\t\\n\\t\" /*    G7        G6       G5 */\n\n\t\t\t\"pand \"MANGLE(M24B)\", %%mm6\t\\n\\t\" /* R7       R6        R5    */\n\n\t\t\t\"movd 4 (%3, %0), %%mm1;\" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\n\n\\\n\n\t\t\t\"por %%mm5, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"por %%mm3, %%mm6\t\t\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, 16(%1)\t\t\\n\\t\"\n\n\t\t\t\"movq 8 (%5, %0, 2), %%mm6;\" /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\n\n\t\t\t\"pxor %%mm4, %%mm4\t\t\\n\\t\"\n\n\n\n#else\n\n\n\n\t\t\t\"pxor %%mm4, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm0, %%mm5\t\t\\n\\t\" /* B */\n\n\t\t\t\"movq %%mm1, %%mm6\t\t\\n\\t\" /* R */\n\n\t\t\t\"punpcklbw %%mm2, %%mm0\t\t\\n\\t\" /* GBGBGBGB 0 */\n\n\t\t\t\"punpcklbw %%mm4, %%mm1\t\t\\n\\t\" /* 0R0R0R0R 0 */\n\n\t\t\t\"punpckhbw %%mm2, %%mm5\t\t\\n\\t\" /* GBGBGBGB 2 */\n\n\t\t\t\"punpckhbw %%mm4, %%mm6\t\t\\n\\t\" /* 0R0R0R0R 2 */\n\n\t\t\t\"movq %%mm0, %%mm7\t\t\\n\\t\" /* GBGBGBGB 0 */\n\n\t\t\t\"movq %%mm5, %%mm3\t\t\\n\\t\" /* GBGBGBGB 2 */\n\n\t\t\t\"punpcklwd %%mm1, %%mm7\t\t\\n\\t\" /* 0RGB0RGB 0 */\n\n\t\t\t\"punpckhwd %%mm1, %%mm0\t\t\\n\\t\" /* 0RGB0RGB 1 */\n\n\t\t\t\"punpcklwd %%mm6, %%mm5\t\t\\n\\t\" /* 0RGB0RGB 2 */\n\n\t\t\t\"punpckhwd %%mm6, %%mm3\t\t\\n\\t\" /* 0RGB0RGB 3 */\n\n\n\n\t\t\t\"movq %%mm7, %%mm2\t\t\\n\\t\" /* 0RGB0RGB 0 */\n\n\t\t\t\"movq %%mm0, %%mm6\t\t\\n\\t\" /* 0RGB0RGB 1 */\n\n\t\t\t\"movq %%mm5, %%mm1\t\t\\n\\t\" /* 0RGB0RGB 2 */\n\n\t\t\t\"movq %%mm3, %%mm4\t\t\\n\\t\" /* 0RGB0RGB 3 */\n\n\n\n\t\t\t\"psllq $40, %%mm7\t\t\\n\\t\" /* RGB00000 0 */\n\n\t\t\t\"psllq $40, %%mm0\t\t\\n\\t\" /* RGB00000 1 */\n\n\t\t\t\"psllq $40, %%mm5\t\t\\n\\t\" /* RGB00000 2 */\n\n\t\t\t\"psllq $40, %%mm3\t\t\\n\\t\" /* RGB00000 3 */\n\n\n\n\t\t\t\"punpckhdq %%mm2, %%mm7\t\t\\n\\t\" /* 0RGBRGB0 0 */\n\n\t\t\t\"punpckhdq %%mm6, %%mm0\t\t\\n\\t\" /* 0RGBRGB0 1 */\n\n\t\t\t\"punpckhdq %%mm1, %%mm5\t\t\\n\\t\" /* 0RGBRGB0 2 */\n\n\t\t\t\"punpckhdq %%mm4, %%mm3\t\t\\n\\t\" /* 0RGBRGB0 3 */\n\n\n\n\t\t\t\"psrlq $8, %%mm7\t\t\\n\\t\" /* 00RGBRGB 0 */\n\n\t\t\t\"movq %%mm0, %%mm6\t\t\\n\\t\" /* 0RGBRGB0 1 */\n\n\t\t\t\"psllq $40, %%mm0\t\t\\n\\t\" /* GB000000 1 */\n\n\t\t\t\"por %%mm0, %%mm7\t\t\\n\\t\" /* GBRGBRGB 0 */\n\n\t\t\tMOVNTQ\" %%mm7, (%1)\t\t\\n\\t\"\n\n\n\n\t\t\t\"movd 4 (%2, %0), %%mm0;\" /* Load 4 Cb 00 00 00 00 u3 u2 u1 u0 */\n\n\n\n\t\t\t\"psrlq $24, %%mm6\t\t\\n\\t\" /* 0000RGBR 1 */\n\n\t\t\t\"movq %%mm5, %%mm1\t\t\\n\\t\" /* 0RGBRGB0 2 */\n\n\t\t\t\"psllq $24, %%mm5\t\t\\n\\t\" /* BRGB0000 2 */\n\n\t\t\t\"por %%mm5, %%mm6\t\t\\n\\t\" /* BRGBRGBR 1 */\n\n\t\t\tMOVNTQ\" %%mm6, 8(%1)\t\t\\n\\t\"\n\n\n\n\t\t\t\"movq 8 (%5, %0, 2), %%mm6;\" /* Load 8 Y Y7 Y6 Y5 Y4 Y3 Y2 Y1 Y0 */\n\n\n\n\t\t\t\"psrlq $40, %%mm1\t\t\\n\\t\" /* 000000RG 2 */\n\n\t\t\t\"psllq $8, %%mm3\t\t\\n\\t\" /* RGBRGB00 3 */\n\n\t\t\t\"por %%mm3, %%mm1\t\t\\n\\t\" /* RGBRGBRG 2 */\n\n\t\t\tMOVNTQ\" %%mm1, 16(%1)\t\t\\n\\t\"\n\n\n\n\t\t\t\"movd 4 (%3, %0), %%mm1;\" /* Load 4 Cr 00 00 00 00 v3 v2 v1 v0 */\n\n\t\t\t\"pxor %%mm4, %%mm4\t\t\\n\\t\"\n\n#endif\n\n\t\t     \n\n\t\t     \"add $24, %1\t\t\t\\n\\t\"\n\n\t\t     \"add $4, %0\t\t\t\\n\\t\"\n\n\t\t     \" js 1b\t\t\t\t\\n\\t\"\n\n\t\t     \n\n\t\t     : \"+r\" (index), \"+r\" (_image)\n\n\t\t     : \"r\" (_pu - index), \"r\" (_pv - index), \"r\"(&c->redDither), \"r\" (_py - 2*index)\n\n\t\t     );\n\n    }\n\n\n\n    __asm__ __volatile__ (EMMS);\n\n    return srcSliceH;\n\n}\n", "idx": 18523, "_split": "test", "_hash": "7d8052df7ed7fbc43c446f7b1a725206"}
{"project": "FFmpeg", "commit_id": "c89658008705d949c319df3fa6f400c481ad73e1", "target": 0, "func": "static int hex_to_data(uint8_t *data, const char *p)\n\n{\n\n    int c, len, v;\n\n\n\n    len = 0;\n\n    v = 1;\n\n    for(;;) {\n\n        skip_spaces(&p);\n\n        if (*p == '\\0')\n\n            break;\n\n        c = toupper((unsigned char)*p++);\n\n        if (c >= '0' && c <= '9')\n\n            c = c - '0';\n\n        else if (c >= 'A' && c <= 'F')\n\n            c = c - 'A' + 10;\n\n        else\n\n            break;\n\n        v = (v << 4) | c;\n\n        if (v & 0x100) {\n\n            if (data)\n\n                data[len] = v;\n\n            len++;\n\n            v = 1;\n\n        }\n\n    }\n\n    return len;\n\n}\n", "idx": 18529, "_split": "test", "_hash": "1e7d3f1448c23e440175637282ebbb00"}
{"project": "FFmpeg", "commit_id": "fa30a0a54854cd291008c065dfaf45d610e3cd04", "target": 0, "func": "static int RENAME(dct_quantize)(MpegEncContext *s,\n\n                            int16_t *block, int n,\n\n                            int qscale, int *overflow)\n\n{\n\n    x86_reg last_non_zero_p1;\n\n    int level=0, q; //=0 is because gcc says uninitialized ...\n\n    const uint16_t *qmat, *bias;\n\n    LOCAL_ALIGNED_16(int16_t, temp_block, [64]);\n\n\n\n    av_assert2((7&(int)(&temp_block[0])) == 0); //did gcc align it correctly?\n\n\n\n    //s->fdct (block);\n\n    RENAME_FDCT(ff_fdct)(block); // cannot be anything else ...\n\n\n\n    if(s->dct_error_sum)\n\n        s->denoise_dct(s, block);\n\n\n\n    if (s->mb_intra) {\n\n        int dummy;\n\n        if (n < 4){\n\n            q = s->y_dc_scale;\n\n            bias = s->q_intra_matrix16[qscale][1];\n\n            qmat = s->q_intra_matrix16[qscale][0];\n\n        }else{\n\n            q = s->c_dc_scale;\n\n            bias = s->q_chroma_intra_matrix16[qscale][1];\n\n            qmat = s->q_chroma_intra_matrix16[qscale][0];\n\n        }\n\n        /* note: block[0] is assumed to be positive */\n\n        if (!s->h263_aic) {\n\n        __asm__ volatile (\n\n                \"mul %%ecx                \\n\\t\"\n\n                : \"=d\" (level), \"=a\"(dummy)\n\n                : \"a\" ((block[0]>>2) + q), \"c\" (ff_inverse[q<<1])\n\n        );\n\n        } else\n\n            /* For AIC we skip quant/dequant of INTRADC */\n\n            level = (block[0] + 4)>>3;\n\n\n\n        block[0]=0; //avoid fake overflow\n\n//        temp_block[0] = (block[0] + (q >> 1)) / q;\n\n        last_non_zero_p1 = 1;\n\n    } else {\n\n        last_non_zero_p1 = 0;\n\n        bias = s->q_inter_matrix16[qscale][1];\n\n        qmat = s->q_inter_matrix16[qscale][0];\n\n    }\n\n\n\n    if((s->out_format == FMT_H263 || s->out_format == FMT_H261) && s->mpeg_quant==0){\n\n\n\n        __asm__ volatile(\n\n            \"movd %%\"FF_REG_a\", \"MM\"3           \\n\\t\" // last_non_zero_p1\n\n            SPREADW(MM\"3\")\n\n            \"pxor \"MM\"7, \"MM\"7                  \\n\\t\" // 0\n\n            \"pxor \"MM\"4, \"MM\"4                  \\n\\t\" // 0\n\n            MOVQ\" (%2), \"MM\"5                   \\n\\t\" // qmat[0]\n\n            \"pxor \"MM\"6, \"MM\"6                  \\n\\t\"\n\n            \"psubw (%3), \"MM\"6                  \\n\\t\" // -bias[0]\n\n            \"mov $-128, %%\"FF_REG_a\"            \\n\\t\"\n\n            \".p2align 4                         \\n\\t\"\n\n            \"1:                                 \\n\\t\"\n\n            MOVQ\" (%1, %%\"FF_REG_a\"), \"MM\"0     \\n\\t\" // block[i]\n\n            SAVE_SIGN(MM\"1\", MM\"0\")                   // ABS(block[i])\n\n            \"psubusw \"MM\"6, \"MM\"0               \\n\\t\" // ABS(block[i]) + bias[0]\n\n            \"pmulhw \"MM\"5, \"MM\"0                \\n\\t\" // (ABS(block[i])*qmat[0] - bias[0]*qmat[0])>>16\n\n            \"por \"MM\"0, \"MM\"4                   \\n\\t\"\n\n            RESTORE_SIGN(MM\"1\", MM\"0\")                // out=((ABS(block[i])*qmat[0] - bias[0]*qmat[0])>>16)*sign(block[i])\n\n            MOVQ\" \"MM\"0, (%5, %%\"FF_REG_a\")     \\n\\t\"\n\n            \"pcmpeqw \"MM\"7, \"MM\"0               \\n\\t\" // out==0 ? 0xFF : 0x00\n\n            MOVQ\" (%4, %%\"FF_REG_a\"), \"MM\"1     \\n\\t\"\n\n            MOVQ\" \"MM\"7, (%1, %%\"FF_REG_a\")     \\n\\t\" // 0\n\n            \"pandn \"MM\"1, \"MM\"0                 \\n\\t\"\n\n            PMAXW(MM\"0\", MM\"3\")\n\n            \"add $\"MMREG_WIDTH\", %%\"FF_REG_a\"   \\n\\t\"\n\n            \" js 1b                             \\n\\t\"\n\n            PMAX(MM\"3\", MM\"0\")\n\n            \"movd \"MM\"3, %%\"FF_REG_a\"           \\n\\t\"\n\n            \"movzbl %%al, %%eax                 \\n\\t\" // last_non_zero_p1\n\n            : \"+a\" (last_non_zero_p1)\n\n            : \"r\" (block+64), \"r\" (qmat), \"r\" (bias),\n\n              \"r\" (inv_zigzag_direct16 + 64), \"r\" (temp_block + 64)\n\n              XMM_CLOBBERS_ONLY(\"%xmm0\", \"%xmm1\", \"%xmm2\", \"%xmm3\",\n\n                                \"%xmm4\", \"%xmm5\", \"%xmm6\", \"%xmm7\")\n\n        );\n\n    }else{ // FMT_H263\n\n        __asm__ volatile(\n\n            \"movd %%\"FF_REG_a\", \"MM\"3           \\n\\t\" // last_non_zero_p1\n\n            SPREADW(MM\"3\")\n\n            \"pxor \"MM\"7, \"MM\"7                  \\n\\t\" // 0\n\n            \"pxor \"MM\"4, \"MM\"4                  \\n\\t\" // 0\n\n            \"mov $-128, %%\"FF_REG_a\"            \\n\\t\"\n\n            \".p2align 4                         \\n\\t\"\n\n            \"1:                                 \\n\\t\"\n\n            MOVQ\" (%1, %%\"FF_REG_a\"), \"MM\"0     \\n\\t\" // block[i]\n\n            SAVE_SIGN(MM\"1\", MM\"0\")                   // ABS(block[i])\n\n            MOVQ\" (%3, %%\"FF_REG_a\"), \"MM\"6     \\n\\t\" // bias[0]\n\n            \"paddusw \"MM\"6, \"MM\"0               \\n\\t\" // ABS(block[i]) + bias[0]\n\n            MOVQ\" (%2, %%\"FF_REG_a\"), \"MM\"5     \\n\\t\" // qmat[i]\n\n            \"pmulhw \"MM\"5, \"MM\"0                \\n\\t\" // (ABS(block[i])*qmat[0] + bias[0]*qmat[0])>>16\n\n            \"por \"MM\"0, \"MM\"4                   \\n\\t\"\n\n            RESTORE_SIGN(MM\"1\", MM\"0\")                // out=((ABS(block[i])*qmat[0] - bias[0]*qmat[0])>>16)*sign(block[i])\n\n            MOVQ\" \"MM\"0, (%5, %%\"FF_REG_a\")     \\n\\t\"\n\n            \"pcmpeqw \"MM\"7, \"MM\"0               \\n\\t\" // out==0 ? 0xFF : 0x00\n\n            MOVQ\" (%4, %%\"FF_REG_a\"), \"MM\"1     \\n\\t\"\n\n            MOVQ\" \"MM\"7, (%1, %%\"FF_REG_a\")     \\n\\t\" // 0\n\n            \"pandn \"MM\"1, \"MM\"0                 \\n\\t\"\n\n            PMAXW(MM\"0\", MM\"3\")\n\n            \"add $\"MMREG_WIDTH\", %%\"FF_REG_a\"   \\n\\t\"\n\n            \" js 1b                             \\n\\t\"\n\n            PMAX(MM\"3\", MM\"0\")\n\n            \"movd \"MM\"3, %%\"FF_REG_a\"           \\n\\t\"\n\n            \"movzbl %%al, %%eax                 \\n\\t\" // last_non_zero_p1\n\n            : \"+a\" (last_non_zero_p1)\n\n            : \"r\" (block+64), \"r\" (qmat+64), \"r\" (bias+64),\n\n              \"r\" (inv_zigzag_direct16 + 64), \"r\" (temp_block + 64)\n\n              XMM_CLOBBERS_ONLY(\"%xmm0\", \"%xmm1\", \"%xmm2\", \"%xmm3\",\n\n                                \"%xmm4\", \"%xmm5\", \"%xmm6\", \"%xmm7\")\n\n        );\n\n    }\n\n    __asm__ volatile(\n\n        \"movd %1, \"MM\"1                     \\n\\t\" // max_qcoeff\n\n        SPREADW(MM\"1\")\n\n        \"psubusw \"MM\"1, \"MM\"4               \\n\\t\"\n\n        \"packuswb \"MM\"4, \"MM\"4              \\n\\t\"\n\n#if COMPILE_TEMPLATE_SSE2\n\n        \"packsswb \"MM\"4, \"MM\"4              \\n\\t\"\n\n#endif\n\n        \"movd \"MM\"4, %0                     \\n\\t\" // *overflow\n\n        : \"=g\" (*overflow)\n\n        : \"g\" (s->max_qcoeff)\n\n    );\n\n\n\n    if(s->mb_intra) block[0]= level;\n\n    else            block[0]= temp_block[0];\n\n\n\n    if (s->idsp.perm_type == FF_IDCT_PERM_SIMPLE) {\n\n        if(last_non_zero_p1 <= 1) goto end;\n\n        block[0x08] = temp_block[0x01]; block[0x10] = temp_block[0x08];\n\n        block[0x20] = temp_block[0x10];\n\n        if(last_non_zero_p1 <= 4) goto end;\n\n        block[0x18] = temp_block[0x09]; block[0x04] = temp_block[0x02];\n\n        block[0x09] = temp_block[0x03];\n\n        if(last_non_zero_p1 <= 7) goto end;\n\n        block[0x14] = temp_block[0x0A]; block[0x28] = temp_block[0x11];\n\n        block[0x12] = temp_block[0x18]; block[0x02] = temp_block[0x20];\n\n        if(last_non_zero_p1 <= 11) goto end;\n\n        block[0x1A] = temp_block[0x19]; block[0x24] = temp_block[0x12];\n\n        block[0x19] = temp_block[0x0B]; block[0x01] = temp_block[0x04];\n\n        block[0x0C] = temp_block[0x05];\n\n        if(last_non_zero_p1 <= 16) goto end;\n\n        block[0x11] = temp_block[0x0C]; block[0x29] = temp_block[0x13];\n\n        block[0x16] = temp_block[0x1A]; block[0x0A] = temp_block[0x21];\n\n        block[0x30] = temp_block[0x28]; block[0x22] = temp_block[0x30];\n\n        block[0x38] = temp_block[0x29]; block[0x06] = temp_block[0x22];\n\n        if(last_non_zero_p1 <= 24) goto end;\n\n        block[0x1B] = temp_block[0x1B]; block[0x21] = temp_block[0x14];\n\n        block[0x1C] = temp_block[0x0D]; block[0x05] = temp_block[0x06];\n\n        block[0x0D] = temp_block[0x07]; block[0x15] = temp_block[0x0E];\n\n        block[0x2C] = temp_block[0x15]; block[0x13] = temp_block[0x1C];\n\n        if(last_non_zero_p1 <= 32) goto end;\n\n        block[0x0B] = temp_block[0x23]; block[0x34] = temp_block[0x2A];\n\n        block[0x2A] = temp_block[0x31]; block[0x32] = temp_block[0x38];\n\n        block[0x3A] = temp_block[0x39]; block[0x26] = temp_block[0x32];\n\n        block[0x39] = temp_block[0x2B]; block[0x03] = temp_block[0x24];\n\n        if(last_non_zero_p1 <= 40) goto end;\n\n        block[0x1E] = temp_block[0x1D]; block[0x25] = temp_block[0x16];\n\n        block[0x1D] = temp_block[0x0F]; block[0x2D] = temp_block[0x17];\n\n        block[0x17] = temp_block[0x1E]; block[0x0E] = temp_block[0x25];\n\n        block[0x31] = temp_block[0x2C]; block[0x2B] = temp_block[0x33];\n\n        if(last_non_zero_p1 <= 48) goto end;\n\n        block[0x36] = temp_block[0x3A]; block[0x3B] = temp_block[0x3B];\n\n        block[0x23] = temp_block[0x34]; block[0x3C] = temp_block[0x2D];\n\n        block[0x07] = temp_block[0x26]; block[0x1F] = temp_block[0x1F];\n\n        block[0x0F] = temp_block[0x27]; block[0x35] = temp_block[0x2E];\n\n        if(last_non_zero_p1 <= 56) goto end;\n\n        block[0x2E] = temp_block[0x35]; block[0x33] = temp_block[0x3C];\n\n        block[0x3E] = temp_block[0x3D]; block[0x27] = temp_block[0x36];\n\n        block[0x3D] = temp_block[0x2F]; block[0x2F] = temp_block[0x37];\n\n        block[0x37] = temp_block[0x3E]; block[0x3F] = temp_block[0x3F];\n\n    }else if(s->idsp.perm_type == FF_IDCT_PERM_LIBMPEG2){\n\n        if(last_non_zero_p1 <= 1) goto end;\n\n        block[0x04] = temp_block[0x01];\n\n        block[0x08] = temp_block[0x08]; block[0x10] = temp_block[0x10];\n\n        if(last_non_zero_p1 <= 4) goto end;\n\n        block[0x0C] = temp_block[0x09]; block[0x01] = temp_block[0x02];\n\n        block[0x05] = temp_block[0x03];\n\n        if(last_non_zero_p1 <= 7) goto end;\n\n        block[0x09] = temp_block[0x0A]; block[0x14] = temp_block[0x11];\n\n        block[0x18] = temp_block[0x18]; block[0x20] = temp_block[0x20];\n\n        if(last_non_zero_p1 <= 11) goto end;\n\n        block[0x1C] = temp_block[0x19];\n\n        block[0x11] = temp_block[0x12]; block[0x0D] = temp_block[0x0B];\n\n        block[0x02] = temp_block[0x04]; block[0x06] = temp_block[0x05];\n\n        if(last_non_zero_p1 <= 16) goto end;\n\n        block[0x0A] = temp_block[0x0C]; block[0x15] = temp_block[0x13];\n\n        block[0x19] = temp_block[0x1A]; block[0x24] = temp_block[0x21];\n\n        block[0x28] = temp_block[0x28]; block[0x30] = temp_block[0x30];\n\n        block[0x2C] = temp_block[0x29]; block[0x21] = temp_block[0x22];\n\n        if(last_non_zero_p1 <= 24) goto end;\n\n        block[0x1D] = temp_block[0x1B]; block[0x12] = temp_block[0x14];\n\n        block[0x0E] = temp_block[0x0D]; block[0x03] = temp_block[0x06];\n\n        block[0x07] = temp_block[0x07]; block[0x0B] = temp_block[0x0E];\n\n        block[0x16] = temp_block[0x15]; block[0x1A] = temp_block[0x1C];\n\n        if(last_non_zero_p1 <= 32) goto end;\n\n        block[0x25] = temp_block[0x23]; block[0x29] = temp_block[0x2A];\n\n        block[0x34] = temp_block[0x31]; block[0x38] = temp_block[0x38];\n\n        block[0x3C] = temp_block[0x39]; block[0x31] = temp_block[0x32];\n\n        block[0x2D] = temp_block[0x2B]; block[0x22] = temp_block[0x24];\n\n        if(last_non_zero_p1 <= 40) goto end;\n\n        block[0x1E] = temp_block[0x1D]; block[0x13] = temp_block[0x16];\n\n        block[0x0F] = temp_block[0x0F]; block[0x17] = temp_block[0x17];\n\n        block[0x1B] = temp_block[0x1E]; block[0x26] = temp_block[0x25];\n\n        block[0x2A] = temp_block[0x2C]; block[0x35] = temp_block[0x33];\n\n        if(last_non_zero_p1 <= 48) goto end;\n\n        block[0x39] = temp_block[0x3A]; block[0x3D] = temp_block[0x3B];\n\n        block[0x32] = temp_block[0x34]; block[0x2E] = temp_block[0x2D];\n\n            block[0x23] = temp_block[0x26]; block[0x1F] = temp_block[0x1F];\n\n        block[0x27] = temp_block[0x27]; block[0x2B] = temp_block[0x2E];\n\n        if(last_non_zero_p1 <= 56) goto end;\n\n        block[0x36] = temp_block[0x35]; block[0x3A] = temp_block[0x3C];\n\n        block[0x3E] = temp_block[0x3D]; block[0x33] = temp_block[0x36];\n\n        block[0x2F] = temp_block[0x2F]; block[0x37] = temp_block[0x37];\n\n        block[0x3B] = temp_block[0x3E]; block[0x3F] = temp_block[0x3F];\n\n    }else{\n\n        if(last_non_zero_p1 <= 1) goto end;\n\n        block[0x01] = temp_block[0x01];\n\n        block[0x08] = temp_block[0x08]; block[0x10] = temp_block[0x10];\n\n        if(last_non_zero_p1 <= 4) goto end;\n\n        block[0x09] = temp_block[0x09]; block[0x02] = temp_block[0x02];\n\n        block[0x03] = temp_block[0x03];\n\n        if(last_non_zero_p1 <= 7) goto end;\n\n        block[0x0A] = temp_block[0x0A]; block[0x11] = temp_block[0x11];\n\n        block[0x18] = temp_block[0x18]; block[0x20] = temp_block[0x20];\n\n        if(last_non_zero_p1 <= 11) goto end;\n\n        block[0x19] = temp_block[0x19];\n\n        block[0x12] = temp_block[0x12]; block[0x0B] = temp_block[0x0B];\n\n        block[0x04] = temp_block[0x04]; block[0x05] = temp_block[0x05];\n\n        if(last_non_zero_p1 <= 16) goto end;\n\n        block[0x0C] = temp_block[0x0C]; block[0x13] = temp_block[0x13];\n\n        block[0x1A] = temp_block[0x1A]; block[0x21] = temp_block[0x21];\n\n        block[0x28] = temp_block[0x28]; block[0x30] = temp_block[0x30];\n\n        block[0x29] = temp_block[0x29]; block[0x22] = temp_block[0x22];\n\n        if(last_non_zero_p1 <= 24) goto end;\n\n        block[0x1B] = temp_block[0x1B]; block[0x14] = temp_block[0x14];\n\n        block[0x0D] = temp_block[0x0D]; block[0x06] = temp_block[0x06];\n\n        block[0x07] = temp_block[0x07]; block[0x0E] = temp_block[0x0E];\n\n        block[0x15] = temp_block[0x15]; block[0x1C] = temp_block[0x1C];\n\n        if(last_non_zero_p1 <= 32) goto end;\n\n        block[0x23] = temp_block[0x23]; block[0x2A] = temp_block[0x2A];\n\n        block[0x31] = temp_block[0x31]; block[0x38] = temp_block[0x38];\n\n        block[0x39] = temp_block[0x39]; block[0x32] = temp_block[0x32];\n\n        block[0x2B] = temp_block[0x2B]; block[0x24] = temp_block[0x24];\n\n        if(last_non_zero_p1 <= 40) goto end;\n\n        block[0x1D] = temp_block[0x1D]; block[0x16] = temp_block[0x16];\n\n        block[0x0F] = temp_block[0x0F]; block[0x17] = temp_block[0x17];\n\n        block[0x1E] = temp_block[0x1E]; block[0x25] = temp_block[0x25];\n\n        block[0x2C] = temp_block[0x2C]; block[0x33] = temp_block[0x33];\n\n        if(last_non_zero_p1 <= 48) goto end;\n\n        block[0x3A] = temp_block[0x3A]; block[0x3B] = temp_block[0x3B];\n\n        block[0x34] = temp_block[0x34]; block[0x2D] = temp_block[0x2D];\n\n        block[0x26] = temp_block[0x26]; block[0x1F] = temp_block[0x1F];\n\n        block[0x27] = temp_block[0x27]; block[0x2E] = temp_block[0x2E];\n\n        if(last_non_zero_p1 <= 56) goto end;\n\n        block[0x35] = temp_block[0x35]; block[0x3C] = temp_block[0x3C];\n\n        block[0x3D] = temp_block[0x3D]; block[0x36] = temp_block[0x36];\n\n        block[0x2F] = temp_block[0x2F]; block[0x37] = temp_block[0x37];\n\n        block[0x3E] = temp_block[0x3E]; block[0x3F] = temp_block[0x3F];\n\n    }\n\n    end:\n\n    return last_non_zero_p1 - 1;\n\n}\n", "idx": 18545, "_split": "test", "_hash": "cba59de5f1d9e4240307f28487534368"}
{"project": "FFmpeg", "commit_id": "491eaf35ae1f9b619441314bec33766e31580184", "target": 1, "func": "static void qdm2_fft_decode_tones (QDM2Context *q, int duration, GetBitContext *gb, int b)\n\n{\n\n    int channel, stereo, phase, exp;\n\n    int local_int_4,  local_int_8,  stereo_phase,  local_int_10;\n\n    int local_int_14, stereo_exp, local_int_20, local_int_28;\n\n    int n, offset;\n\n\n\n    local_int_4 = 0;\n\n    local_int_28 = 0;\n\n    local_int_20 = 2;\n\n    local_int_8 = (4 - duration);\n\n    local_int_10 = 1 << (q->group_order - duration - 1);\n\n    offset = 1;\n\n\n\n    while (1) {\n\n        if (q->superblocktype_2_3) {\n\n            while ((n = qdm2_get_vlc(gb, &vlc_tab_fft_tone_offset[local_int_8], 1, 2)) < 2) {\n\n                offset = 1;\n\n                if (n == 0) {\n\n                    local_int_4 += local_int_10;\n\n                    local_int_28 += (1 << local_int_8);\n\n                } else {\n\n                    local_int_4 += 8*local_int_10;\n\n                    local_int_28 += (8 << local_int_8);\n\n                }\n\n            }\n\n            offset += (n - 2);\n\n        } else {\n\n            offset += qdm2_get_vlc(gb, &vlc_tab_fft_tone_offset[local_int_8], 1, 2);\n\n            while (offset >= (local_int_10 - 1)) {\n\n                offset += (1 - (local_int_10 - 1));\n\n                local_int_4  += local_int_10;\n\n                local_int_28 += (1 << local_int_8);\n\n            }\n\n        }\n\n\n\n        if (local_int_4 >= q->group_size)\n\n\n\n\n        local_int_14 = (offset >> local_int_8);\n\n\n\n\n\n        if (q->nb_channels > 1) {\n\n            channel = get_bits1(gb);\n\n            stereo = get_bits1(gb);\n\n        } else {\n\n            channel = 0;\n\n            stereo = 0;\n\n        }\n\n\n\n        exp = qdm2_get_vlc(gb, (b ? &fft_level_exp_vlc : &fft_level_exp_alt_vlc), 0, 2);\n\n        exp += q->fft_level_exp[fft_level_index_table[local_int_14]];\n\n        exp = (exp < 0) ? 0 : exp;\n\n\n\n        phase = get_bits(gb, 3);\n\n        stereo_exp = 0;\n\n        stereo_phase = 0;\n\n\n\n        if (stereo) {\n\n            stereo_exp = (exp - qdm2_get_vlc(gb, &fft_stereo_exp_vlc, 0, 1));\n\n            stereo_phase = (phase - qdm2_get_vlc(gb, &fft_stereo_phase_vlc, 0, 1));\n\n            if (stereo_phase < 0)\n\n                stereo_phase += 8;\n\n        }\n\n\n\n        if (q->frequency_range > (local_int_14 + 1)) {\n\n            int sub_packet = (local_int_20 + local_int_28);\n\n\n\n            qdm2_fft_init_coefficient(q, sub_packet, offset, duration, channel, exp, phase);\n\n            if (stereo)\n\n                qdm2_fft_init_coefficient(q, sub_packet, offset, duration, (1 - channel), stereo_exp, stereo_phase);\n\n        }\n\n\n\n        offset++;\n\n    }\n\n}", "idx": 18556, "_split": "test", "_hash": "537aea774aba31a3f38178b1e605cb43"}
{"project": "FFmpeg", "commit_id": "513a3494396d0a20233273b3cadcb5ee86485d5c", "target": 1, "func": "static int vp6_parse_coeff(VP56Context *s)\n\n{\n\n    VP56RangeCoder *c = s->ccp;\n\n    VP56Model *model = s->modelp;\n\n    uint8_t *permute = s->idct_scantable;\n\n    uint8_t *model1, *model2, *model3;\n\n    int coeff, sign, coeff_idx;\n\n    int b, i, cg, idx, ctx;\n\n    int pt = 0;    /* plane type (0 for Y, 1 for U or V) */\n\n\n\n    if (c->end >= c->buffer && c->bits >= 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"End of AC stream reached in vp6_parse_coeff\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    for (b=0; b<6; b++) {\n\n        int ct = 1;    /* code type */\n\n        int run = 1;\n\n\n\n        if (b > 3) pt = 1;\n\n\n\n        ctx = s->left_block[ff_vp56_b6to4[b]].not_null_dc\n\n              + s->above_blocks[s->above_block_idx[b]].not_null_dc;\n\n        model1 = model->coeff_dccv[pt];\n\n        model2 = model->coeff_dcct[pt][ctx];\n\n\n\n        coeff_idx = 0;\n\n        for (;;) {\n\n            if ((coeff_idx>1 && ct==0) || vp56_rac_get_prob_branchy(c, model2[0])) {\n\n                /* parse a coeff */\n\n                if (vp56_rac_get_prob_branchy(c, model2[2])) {\n\n                    if (vp56_rac_get_prob_branchy(c, model2[3])) {\n\n                        idx = vp56_rac_get_tree(c, ff_vp56_pc_tree, model1);\n\n                        coeff = ff_vp56_coeff_bias[idx+5];\n\n                        for (i=ff_vp56_coeff_bit_length[idx]; i>=0; i--)\n\n                            coeff += vp56_rac_get_prob(c, ff_vp56_coeff_parse_table[idx][i]) << i;\n\n                    } else {\n\n                        if (vp56_rac_get_prob_branchy(c, model2[4]))\n\n                            coeff = 3 + vp56_rac_get_prob(c, model1[5]);\n\n                        else\n\n                            coeff = 2;\n\n                    }\n\n                    ct = 2;\n\n                } else {\n\n                    ct = 1;\n\n                    coeff = 1;\n\n                }\n\n                sign = vp56_rac_get(c);\n\n                coeff = (coeff ^ -sign) + sign;\n\n                if (coeff_idx)\n\n                    coeff *= s->dequant_ac;\n\n                idx = model->coeff_index_to_pos[coeff_idx];\n\n                s->block_coeff[b][permute[idx]] = coeff;\n\n                run = 1;\n\n            } else {\n\n                /* parse a run */\n\n                ct = 0;\n\n                if (coeff_idx > 0) {\n\n                    if (!vp56_rac_get_prob_branchy(c, model2[1]))\n\n                        break;\n\n\n\n                    model3 = model->coeff_runv[coeff_idx >= 6];\n\n                    run = vp56_rac_get_tree(c, vp6_pcr_tree, model3);\n\n                    if (!run)\n\n                        for (run=9, i=0; i<6; i++)\n\n                            run += vp56_rac_get_prob(c, model3[i+8]) << i;\n\n                }\n\n            }\n\n            coeff_idx += run;\n\n            if (coeff_idx >= 64)\n\n                break;\n\n            cg = vp6_coeff_groups[coeff_idx];\n\n            model1 = model2 = model->coeff_ract[pt][ct][cg];\n\n        }\n\n\n\n        s->left_block[ff_vp56_b6to4[b]].not_null_dc =\n\n        s->above_blocks[s->above_block_idx[b]].not_null_dc = !!s->block_coeff[b][0];\n\n    }\n\n    return 0;\n\n}\n", "idx": 18578, "_split": "test", "_hash": "2bfa5594e34161be285e3ab7737213fa"}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int ftp_passive_mode_epsv(FTPContext *s)\n\n{\n\n    char *res = NULL, *start = NULL, *end = NULL;\n\n    int i;\n\n    static const char d = '|';\n\n    static const char *command = \"EPSV\\r\\n\";\n\n    static const int epsv_codes[] = {229, 0};\n\n\n\n    if (ftp_send_command(s, command, epsv_codes, &res) != 229 || !res)\n\n        goto fail;\n\n\n\n    for (i = 0; res[i]; ++i) {\n\n        if (res[i] == '(') {\n\n            start = res + i + 1;\n\n        } else if (res[i] == ')') {\n\n            end = res + i;\n\n            break;\n\n        }\n\n    }\n\n    if (!start || !end)\n\n        goto fail;\n\n\n\n    *end = '\\0';\n\n    if (strlen(start) < 5)\n\n        goto fail;\n\n    if (start[0] != d || start[1] != d || start[2] != d || end[-1] != d)\n\n        goto fail;\n\n    start += 3;\n\n    end[-1] = '\\0';\n\n\n\n    s->server_data_port = atoi(start);\n\n    av_dlog(s, \"Server data port: %d\\n\", s->server_data_port);\n\n\n\n    av_free(res);\n\n    return 0;\n\n\n\n  fail:\n\n    av_free(res);\n\n    s->server_data_port = -1;\n\n    return AVERROR(ENOSYS);\n\n}\n", "idx": 18583, "_split": "test", "_hash": "7239a42e5d0a17ce3190b62a3de1f080"}
{"project": "FFmpeg", "commit_id": "d1916d13e28b87f4b1b214231149e12e1d536b4b", "target": 1, "func": "static void add_bytes_l2_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w)\n\n{\n\n    long i;\n\n    for (i = 0; i <= w - sizeof(long); i += sizeof(long)) {\n\n        long a = *(long *)(src1 + i);\n\n        long b = *(long *)(src2 + i);\n\n        *(long *)(dst + i) = ((a & pb_7f) + (b & pb_7f)) ^ ((a ^ b) & pb_80);\n\n    }\n\n    for (; i < w; i++)\n\n        dst[i] = src1[i] + src2[i];\n\n}\n", "idx": 18624, "_split": "test", "_hash": "5973e0f9980d314173e0d9b8ceebfcbc"}
{"project": "FFmpeg", "commit_id": "0a359cf157957f3eb37760f731fa75dd320fd659", "target": 0, "func": "static int vc1_filter_line(uint8_t* src, int stride, int pq){\n\n    int a0, a1, a2, a3, d, clip, filt3 = 0;\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    a0     = (2*(src[-2*stride] - src[ 1*stride]) - 5*(src[-1*stride] - src[ 0*stride]) + 4) >> 3;\n\n    if(FFABS(a0) < pq){\n\n        a1 = (2*(src[-4*stride] - src[-1*stride]) - 5*(src[-3*stride] - src[-2*stride]) + 4) >> 3;\n\n        a2 = (2*(src[ 0*stride] - src[ 3*stride]) - 5*(src[ 1*stride] - src[ 2*stride]) + 4) >> 3;\n\n        a3 = FFMIN(FFABS(a1), FFABS(a2));\n\n        if(a3 < FFABS(a0)){\n\n            d = 5 * ((a0 >=0 ? a3 : -a3) - a0) / 8;\n\n            clip = (src[-1*stride] - src[ 0*stride])/2;\n\n            if(clip){\n\n                filt3 = 1;\n\n                if(clip > 0)\n\n                    d = av_clip(d, 0, clip);\n\n                else\n\n                    d = av_clip(d, clip, 0);\n\n                src[-1*stride] = cm[src[-1*stride] - d];\n\n                src[ 0*stride] = cm[src[ 0*stride] + d];\n\n            }\n\n        }\n\n    }\n\n    return filt3;\n\n}\n", "idx": 18646, "_split": "test", "_hash": "6cd880533eaf3dd30c788af152abc6d2"}
{"project": "FFmpeg", "commit_id": "c1f2c4c3b49277d65b71ccdd3b6b2878f1b593eb", "target": 0, "func": "static int rle_unpack(const unsigned char *src, unsigned char *dest,\n\n                      int src_count, int src_size, int dest_len)\n\n{\n\n    unsigned char *pd;\n\n    int i, l;\n\n    unsigned char *dest_end = dest + dest_len;\n\n    GetByteContext gb;\n\n\n\n    bytestream2_init(&gb, src, src_size);\n\n    pd = dest;\n\n    if (src_count & 1) {\n\n        if (bytestream2_get_bytes_left(&gb) < 1)\n\n            return 0;\n\n        *pd++ = bytestream2_get_byteu(&gb);\n\n    }\n\n\n\n    src_count >>= 1;\n\n    i = 0;\n\n    do {\n\n        if (bytestream2_get_bytes_left(&gb) < 1)\n\n            break;\n\n        l = bytestream2_get_byteu(&gb);\n\n        if (l & 0x80) {\n\n            l = (l & 0x7F) * 2;\n\n            if (dest_end - pd < l || bytestream2_get_bytes_left(&gb) < l)\n\n                return bytestream2_tell(&gb);\n\n            bytestream2_get_bufferu(&gb, pd, l);\n\n            pd += l;\n\n        } else {\n\n            if (dest_end - pd < i || bytestream2_get_bytes_left(&gb) < 2)\n\n                return bytestream2_tell(&gb);\n\n            for (i = 0; i < l; i++) {\n\n                *pd++ = bytestream2_get_byteu(&gb);\n\n                *pd++ = bytestream2_get_byteu(&gb);\n\n            }\n\n            bytestream2_skip(&gb, 2);\n\n        }\n\n        i += l;\n\n    } while (i < src_count);\n\n\n\n    return bytestream2_tell(&gb);\n\n}\n", "idx": 18648, "_split": "test", "_hash": "dcf96adc56990beddac5d9161b1ebd20"}
{"project": "FFmpeg", "commit_id": "1dff9adcb934175fe1beb14ee139ad0636daa29d", "target": 0, "func": "static int recheck_discard_flags(AVFormatContext *s, int first)\n\n{\n\n    HLSContext *c = s->priv_data;\n\n    int i, changed = 0;\n\n\n\n    /* Check if any new streams are needed */\n\n    for (i = 0; i < c->n_playlists; i++)\n\n        c->playlists[i]->cur_needed = 0;\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVStream *st = s->streams[i];\n\n        struct playlist *pls = c->playlists[s->streams[i]->id];\n\n        if (st->discard < AVDISCARD_ALL)\n\n            pls->cur_needed = 1;\n\n    }\n\n    for (i = 0; i < c->n_playlists; i++) {\n\n        struct playlist *pls = c->playlists[i];\n\n        if (pls->cur_needed && !pls->needed) {\n\n            pls->needed = 1;\n\n            changed = 1;\n\n            pls->cur_seq_no = select_cur_seq_no(c, pls);\n\n            pls->pb.eof_reached = 0;\n\n            if (c->cur_timestamp != AV_NOPTS_VALUE) {\n\n                /* catch up */\n\n                pls->seek_timestamp = c->cur_timestamp;\n\n                pls->seek_flags = AVSEEK_FLAG_ANY;\n\n                pls->seek_stream_index = -1;\n\n            }\n\n            av_log(s, AV_LOG_INFO, \"Now receiving playlist %d, segment %d\\n\", i, pls->cur_seq_no);\n\n        } else if (first && !pls->cur_needed && pls->needed) {\n\n            if (pls->input)\n\n                ff_format_io_close(pls->parent, &pls->input);\n\n            pls->needed = 0;\n\n            changed = 1;\n\n            av_log(s, AV_LOG_INFO, \"No longer receiving playlist %d\\n\", i);\n\n        }\n\n    }\n\n    return changed;\n\n}\n", "idx": 18649, "_split": "test", "_hash": "266a1fe700f0a10f3f35dd811a39abda"}
{"project": "FFmpeg", "commit_id": "e70fcf075b8f92c4e410b80c703fbdc1d531d42d", "target": 1, "func": "AVStream *add_audio_stream(AVFormatContext *oc, int codec_id)\n\n{\n\n    AVCodec *codec;\n\n    AVCodecContext *c;\n\n    AVStream *st;\n\n\n\n    st = av_new_stream(oc, 1);\n\n    if (!st) {\n\n        fprintf(stderr, \"Could not alloc stream\\n\");\n\n        exit(1);\n\n    }\n\n\n\n    /* find the MP2 encoder */\n\n    codec = avcodec_find_encoder(codec_id);\n\n    if (!codec) {\n\n        fprintf(stderr, \"codec not found\\n\");\n\n        exit(1);\n\n    }\n\n    c = &st->codec;\n\n    c->codec_type = CODEC_TYPE_AUDIO;\n\n\n\n    /* put sample parameters */\n\n    c->bit_rate = 64000;\n\n    c->sample_rate = 44100;\n\n    c->channels = 2;\n\n\n\n    /* open it */\n\n    if (avcodec_open(c, codec) < 0) {\n\n        fprintf(stderr, \"could not open codec\\n\");\n\n        exit(1);\n\n    }\n\n\n\n    /* init signal generator */\n\n    t = 0;\n\n    tincr = 2 * M_PI * 440.0 / c->sample_rate;\n\n\n\n    audio_outbuf_size = 10000;\n\n    audio_outbuf = malloc(audio_outbuf_size);\n\n\n\n    /* ugly hack for PCM codecs (will be removed ASAP with new PCM\n\n       support to compute the input frame size in samples */\n\n    if (c->frame_size <= 1) {\n\n        audio_input_frame_size = audio_outbuf_size / c->channels;\n\n        switch(st->codec.codec_id) {\n\n        case CODEC_ID_PCM_S16LE:\n\n        case CODEC_ID_PCM_S16BE:\n\n        case CODEC_ID_PCM_U16LE:\n\n        case CODEC_ID_PCM_U16BE:\n\n            audio_input_frame_size >>= 1;\n\n            break;\n\n        default:\n\n            break;\n\n        }\n\n    } else {\n\n        audio_input_frame_size = c->frame_size;\n\n    }\n\n    samples = malloc(audio_input_frame_size * 2 * c->channels);\n\n\n\n    return st;\n\n}\n", "idx": 18700, "_split": "test", "_hash": "1372b0abbd31bf2f090ecbc6b7cdf99f"}
{"project": "FFmpeg", "commit_id": "ecc92ee717eac18540e236ee27e9052cd2917800", "target": 1, "func": "static av_cold int libopenjpeg_encode_init(AVCodecContext *avctx)\n\n{\n\n    LibOpenJPEGContext *ctx = avctx->priv_data;\n\n    int err = AVERROR(ENOMEM);\n\n\n\n    opj_set_default_encoder_parameters(&ctx->enc_params);\n\n\n\n    ctx->enc_params.cp_rsiz = ctx->profile;\n\n    ctx->enc_params.mode = !!avctx->global_quality;\n\n    ctx->enc_params.cp_cinema = ctx->cinema_mode;\n\n    ctx->enc_params.prog_order = ctx->prog_order;\n\n    ctx->enc_params.numresolution = ctx->numresolution;\n\n    ctx->enc_params.cp_disto_alloc = ctx->disto_alloc;\n\n    ctx->enc_params.cp_fixed_alloc = ctx->fixed_alloc;\n\n    ctx->enc_params.cp_fixed_quality = ctx->fixed_quality;\n\n    ctx->enc_params.tcp_numlayers = ctx->numlayers;\n\n    ctx->enc_params.tcp_rates[0] = FFMAX(avctx->compression_level, 0) * 2;\n\n\n\n    if (ctx->cinema_mode > 0) {\n\n        cinema_parameters(&ctx->enc_params);\n\n    }\n\n\n\n    ctx->compress = opj_create_compress(ctx->format);\n\n    if (!ctx->compress) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error creating the compressor\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    ctx->image = mj2_create_image(avctx, &ctx->enc_params);\n\n    if (!ctx->image) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error creating the mj2 image\\n\");\n\n        err = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    avctx->coded_frame = av_frame_alloc();\n\n    if (!avctx->coded_frame) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error allocating coded frame\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    memset(&ctx->event_mgr, 0, sizeof(opj_event_mgr_t));\n\n    ctx->event_mgr.info_handler    = info_callback;\n\n    ctx->event_mgr.error_handler = error_callback;\n\n    ctx->event_mgr.warning_handler = warning_callback;\n\n    opj_set_event_mgr((opj_common_ptr) ctx->compress, &ctx->event_mgr, avctx);\n\n\n\n    return 0;\n\n\n\nfail:\n\n    opj_destroy_compress(ctx->compress);\n\n    ctx->compress = NULL;\n\n    opj_image_destroy(ctx->image);\n\n    ctx->image = NULL;\n\n    av_freep(&avctx->coded_frame);\n\n    return err;\n\n}\n", "idx": 18719, "_split": "test", "_hash": "5427ba20fa67c2ab0c23096b04d5d835"}
{"project": "FFmpeg", "commit_id": "c90b88090c260a0af018b6c1e955266e24ebf6f4", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *src_buffer)\n\n{\n\n    AVFilterContext  *ctx = inlink->dst;\n\n    ATempoContext *atempo = ctx->priv;\n\n    AVFilterLink *outlink = ctx->outputs[0];\n\n\n\n    int ret = 0;\n\n    int n_in = src_buffer->nb_samples;\n\n    int n_out = (int)(0.5 + ((double)n_in) / atempo->tempo);\n\n\n\n    const uint8_t *src = src_buffer->data[0];\n\n    const uint8_t *src_end = src + n_in * atempo->stride;\n\n\n\n    while (src < src_end) {\n\n        if (!atempo->dst_buffer) {\n\n            atempo->dst_buffer = ff_get_audio_buffer(outlink, n_out);\n\n            if (!atempo->dst_buffer)\n\n                return AVERROR(ENOMEM);\n\n            av_frame_copy_props(atempo->dst_buffer, src_buffer);\n\n\n\n            atempo->dst = atempo->dst_buffer->data[0];\n\n            atempo->dst_end = atempo->dst + n_out * atempo->stride;\n\n        }\n\n\n\n        yae_apply(atempo, &src, src_end, &atempo->dst, atempo->dst_end);\n\n\n\n        if (atempo->dst == atempo->dst_end) {\n\n            int n_samples = ((atempo->dst - atempo->dst_buffer->data[0]) /\n\n                             atempo->stride);\n\n            ret = push_samples(atempo, outlink, n_samples);\n\n            if (ret < 0)\n\n                goto end;\n\n        }\n\n    }\n\n\n\n    atempo->nsamples_in += n_in;\n\nend:\n\n    av_frame_free(&src_buffer);\n\n    return ret;\n\n}\n", "idx": 18812, "_split": "test", "_hash": "221337fb4107d1a86309c92d777139b0"}
{"project": "FFmpeg", "commit_id": "aacf6b3a2fd8bc8603e3deaa6e612ea03cf08707", "target": 1, "func": "static inline void rv34_mc(RV34DecContext *r, const int block_type,\n\n                          const int xoff, const int yoff, int mv_off,\n\n                          const int width, const int height, int dir,\n\n                          const int thirdpel, int weighted,\n\n                          qpel_mc_func (*qpel_mc)[16],\n\n                          h264_chroma_mc_func (*chroma_mc))\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    uint8_t *Y, *U, *V, *srcY, *srcU, *srcV;\n\n    int dxy, mx, my, umx, umy, lx, ly, uvmx, uvmy, src_x, src_y, uvsrc_x, uvsrc_y;\n\n    int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride + mv_off;\n\n    int is16x16 = 1;\n\n\n\n    if(thirdpel){\n\n        int chroma_mx, chroma_my;\n\n        mx = (s->current_picture_ptr->f.motion_val[dir][mv_pos][0] + (3 << 24)) / 3 - (1 << 24);\n\n        my = (s->current_picture_ptr->f.motion_val[dir][mv_pos][1] + (3 << 24)) / 3 - (1 << 24);\n\n        lx = (s->current_picture_ptr->f.motion_val[dir][mv_pos][0] + (3 << 24)) % 3;\n\n        ly = (s->current_picture_ptr->f.motion_val[dir][mv_pos][1] + (3 << 24)) % 3;\n\n        chroma_mx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] / 2;\n\n        chroma_my = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] / 2;\n\n        umx = (chroma_mx + (3 << 24)) / 3 - (1 << 24);\n\n        umy = (chroma_my + (3 << 24)) / 3 - (1 << 24);\n\n        uvmx = chroma_coeffs[(chroma_mx + (3 << 24)) % 3];\n\n        uvmy = chroma_coeffs[(chroma_my + (3 << 24)) % 3];\n\n    }else{\n\n        int cx, cy;\n\n        mx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] >> 2;\n\n        my = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] >> 2;\n\n        lx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] & 3;\n\n        ly = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] & 3;\n\n        cx = s->current_picture_ptr->f.motion_val[dir][mv_pos][0] / 2;\n\n        cy = s->current_picture_ptr->f.motion_val[dir][mv_pos][1] / 2;\n\n        umx = cx >> 2;\n\n        umy = cy >> 2;\n\n        uvmx = (cx & 3) << 1;\n\n        uvmy = (cy & 3) << 1;\n\n        //due to some flaw RV40 uses the same MC compensation routine for H2V2 and H3V3\n\n        if(uvmx == 6 && uvmy == 6)\n\n            uvmx = uvmy = 4;\n\n    }\n\n    dxy = ly*4 + lx;\n\n    srcY = dir ? s->next_picture_ptr->f.data[0] : s->last_picture_ptr->f.data[0];\n\n    srcU = dir ? s->next_picture_ptr->f.data[1] : s->last_picture_ptr->f.data[1];\n\n    srcV = dir ? s->next_picture_ptr->f.data[2] : s->last_picture_ptr->f.data[2];\n\n    src_x = s->mb_x * 16 + xoff + mx;\n\n    src_y = s->mb_y * 16 + yoff + my;\n\n    uvsrc_x = s->mb_x * 8 + (xoff >> 1) + umx;\n\n    uvsrc_y = s->mb_y * 8 + (yoff >> 1) + umy;\n\n    srcY += src_y * s->linesize + src_x;\n\n    srcU += uvsrc_y * s->uvlinesize + uvsrc_x;\n\n    srcV += uvsrc_y * s->uvlinesize + uvsrc_x;\n\n    if(   (unsigned)(src_x - !!lx*2) > s->h_edge_pos - !!lx*2 - (width <<3) - 4\n\n       || (unsigned)(src_y - !!ly*2) > s->v_edge_pos - !!ly*2 - (height<<3) - 4){\n\n        uint8_t *uvbuf = s->edge_emu_buffer + 22 * s->linesize;\n\n\n\n        srcY -= 2 + 2*s->linesize;\n\n        s->dsp.emulated_edge_mc(s->edge_emu_buffer, srcY, s->linesize, (width<<3)+6, (height<<3)+6,\n\n                            src_x - 2, src_y - 2, s->h_edge_pos, s->v_edge_pos);\n\n        srcY = s->edge_emu_buffer + 2 + 2*s->linesize;\n\n        s->dsp.emulated_edge_mc(uvbuf     , srcU, s->uvlinesize, (width<<2)+1, (height<<2)+1,\n\n                            uvsrc_x, uvsrc_y, s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n        s->dsp.emulated_edge_mc(uvbuf + 16, srcV, s->uvlinesize, (width<<2)+1, (height<<2)+1,\n\n                            uvsrc_x, uvsrc_y, s->h_edge_pos >> 1, s->v_edge_pos >> 1);\n\n        srcU = uvbuf;\n\n        srcV = uvbuf + 16;\n\n    }\n\n    if(!weighted){\n\n        Y = s->dest[0] + xoff      + yoff     *s->linesize;\n\n        U = s->dest[1] + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n        V = s->dest[2] + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n    }else{\n\n        Y = r->tmp_b_block_y [dir]     +  xoff     +  yoff    *s->linesize;\n\n        U = r->tmp_b_block_uv[dir*2]   + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n        V = r->tmp_b_block_uv[dir*2+1] + (xoff>>1) + (yoff>>1)*s->uvlinesize;\n\n    }\n\n\n\n    if(block_type == RV34_MB_P_16x8){\n\n        qpel_mc[1][dxy](Y, srcY, s->linesize);\n\n        Y    += 8;\n\n        srcY += 8;\n\n    }else if(block_type == RV34_MB_P_8x16){\n\n        qpel_mc[1][dxy](Y, srcY, s->linesize);\n\n        Y    += 8 * s->linesize;\n\n        srcY += 8 * s->linesize;\n\n    }\n\n    is16x16 = (block_type != RV34_MB_P_8x8) && (block_type != RV34_MB_P_16x8) && (block_type != RV34_MB_P_8x16);\n\n    qpel_mc[!is16x16][dxy](Y, srcY, s->linesize);\n\n    chroma_mc[2-width]   (U, srcU, s->uvlinesize, height*4, uvmx, uvmy);\n\n    chroma_mc[2-width]   (V, srcV, s->uvlinesize, height*4, uvmx, uvmy);\n\n}\n", "idx": 18830, "_split": "test", "_hash": "23027173204fd0d56da832374edc6979"}
{"project": "FFmpeg", "commit_id": "2e5195646dc5578e1751004b0ac6e787d18637e4", "target": 1, "func": "static int mpc_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    MPCContext *c = s->priv_data;\n\n    int ret, size, size2, curbits, cur = c->curframe;\n\n    int64_t tmp, pos;\n\n\n\n    if (c->curframe >= c->fcount)\n\n        return -1;\n\n\n\n    if(c->curframe != c->lastframe + 1){\n\n        url_fseek(s->pb, c->frames[c->curframe].pos, SEEK_SET);\n\n        c->curbits = c->frames[c->curframe].skip;\n\n    }\n\n    c->lastframe = c->curframe;\n\n    c->curframe++;\n\n    curbits = c->curbits;\n\n    pos = url_ftell(s->pb);\n\n    tmp = get_le32(s->pb);\n\n    if(curbits <= 12){\n\n        size2 = (tmp >> (12 - curbits)) & 0xFFFFF;\n\n    }else{\n\n        tmp = (tmp << 32) | get_le32(s->pb);\n\n        size2 = (tmp >> (44 - curbits)) & 0xFFFFF;\n\n    }\n\n    curbits += 20;\n\n    url_fseek(s->pb, pos, SEEK_SET);\n\n\n\n    size = ((size2 + curbits + 31) & ~31) >> 3;\n\n    if(cur == c->frames_noted){\n\n        c->frames[cur].pos = pos;\n\n        c->frames[cur].size = size;\n\n        c->frames[cur].skip = curbits - 20;\n\n        av_add_index_entry(s->streams[0], cur, cur, size, 0, AVINDEX_KEYFRAME);\n\n        c->frames_noted++;\n\n    }\n\n    c->curbits = (curbits + size2) & 0x1F;\n\n\n\n    if (av_new_packet(pkt, size) < 0)\n\n        return AVERROR(EIO);\n\n\n\n    pkt->data[0] = curbits;\n\n    pkt->data[1] = (c->curframe > c->fcount);\n\n\n\n\n\n    pkt->stream_index = 0;\n\n    pkt->pts = cur;\n\n    ret = get_buffer(s->pb, pkt->data + 4, size);\n\n    if(c->curbits)\n\n        url_fseek(s->pb, -4, SEEK_CUR);\n\n    if(ret < size){\n\n        av_free_packet(pkt);\n\n        return AVERROR(EIO);\n\n    }\n\n    pkt->size = ret + 4;\n\n\n\n    return 0;\n\n}", "idx": 18963, "_split": "test", "_hash": "72d25c0296b7e56dd37a752a2da1523f"}
{"project": "FFmpeg", "commit_id": "dd561441b1e849df7d8681c6f32af82d4088dafd", "target": 0, "func": "static av_always_inline av_flatten void h264_loop_filter_chroma_intra_c(uint8_t *pix, int xstride, int ystride, int alpha, int beta)\n\n{\n\n    int d;\n\n    for( d = 0; d < 8; d++ ) {\n\n        const int p0 = pix[-1*xstride];\n\n        const int p1 = pix[-2*xstride];\n\n        const int q0 = pix[0];\n\n        const int q1 = pix[1*xstride];\n\n\n\n        if( FFABS( p0 - q0 ) < alpha &&\n\n            FFABS( p1 - p0 ) < beta &&\n\n            FFABS( q1 - q0 ) < beta ) {\n\n\n\n            pix[-xstride] = ( 2*p1 + p0 + q1 + 2 ) >> 2;   /* p0' */\n\n            pix[0]        = ( 2*q1 + q0 + p1 + 2 ) >> 2;   /* q0' */\n\n        }\n\n        pix += ystride;\n\n    }\n\n}\n", "idx": 19011, "_split": "test", "_hash": "d65ebb330f8aacae2c68ebf5b8c46246"}
{"project": "FFmpeg", "commit_id": "74b1bf632f125a795e66e5fd0a060b9c7c55b7a3", "target": 1, "func": "static int mp_decode_frame(MPADecodeContext *s, OUT_INT **samples,\n\n                           const uint8_t *buf, int buf_size)\n\n{\n\n    int i, nb_frames, ch, ret;\n\n    OUT_INT *samples_ptr;\n\n\n\n    init_get_bits(&s->gb, buf + HEADER_SIZE, (buf_size - HEADER_SIZE) * 8);\n\n\n\n    /* skip error protection field */\n\n    if (s->error_protection)\n\n        skip_bits(&s->gb, 16);\n\n\n\n    switch(s->layer) {\n\n    case 1:\n\n        s->avctx->frame_size = 384;\n\n        nb_frames = mp_decode_layer1(s);\n\n        break;\n\n    case 2:\n\n        s->avctx->frame_size = 1152;\n\n        nb_frames = mp_decode_layer2(s);\n\n        break;\n\n    case 3:\n\n        s->avctx->frame_size = s->lsf ? 576 : 1152;\n\n    default:\n\n        nb_frames = mp_decode_layer3(s);\n\n\n\n        if (nb_frames < 0)\n\n            return nb_frames;\n\n\n\n        s->last_buf_size=0;\n\n        if (s->in_gb.buffer) {\n\n            align_get_bits(&s->gb);\n\n            i = get_bits_left(&s->gb)>>3;\n\n            if (i >= 0 && i <= BACKSTEP_SIZE) {\n\n                memmove(s->last_buf, s->gb.buffer + (get_bits_count(&s->gb)>>3), i);\n\n                s->last_buf_size=i;\n\n            } else\n\n                av_log(s->avctx, AV_LOG_ERROR, \"invalid old backstep %d\\n\", i);\n\n            s->gb           = s->in_gb;\n\n            s->in_gb.buffer = NULL;\n\n        }\n\n\n\n        align_get_bits(&s->gb);\n\n        assert((get_bits_count(&s->gb) & 7) == 0);\n\n        i = get_bits_left(&s->gb) >> 3;\n\n\n\n        if (i < 0 || i > BACKSTEP_SIZE || nb_frames < 0) {\n\n            if (i < 0)\n\n                av_log(s->avctx, AV_LOG_ERROR, \"invalid new backstep %d\\n\", i);\n\n            i = FFMIN(BACKSTEP_SIZE, buf_size - HEADER_SIZE);\n\n        }\n\n        assert(i <= buf_size - HEADER_SIZE && i >= 0);\n\n        memcpy(s->last_buf + s->last_buf_size, s->gb.buffer + buf_size - HEADER_SIZE - i, i);\n\n        s->last_buf_size += i;\n\n    }\n\n\n\n    /* get output buffer */\n\n    if (!samples) {\n\n        av_assert0(s->frame != NULL);\n\n        s->frame->nb_samples = s->avctx->frame_size;\n\n        if ((ret = ff_get_buffer(s->avctx, s->frame, 0)) < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n            return ret;\n\n        }\n\n        samples = (OUT_INT **)s->frame->extended_data;\n\n    }\n\n\n\n    /* apply the synthesis filter */\n\n    for (ch = 0; ch < s->nb_channels; ch++) {\n\n        int sample_stride;\n\n        if (s->avctx->sample_fmt == OUT_FMT_P) {\n\n            samples_ptr   = samples[ch];\n\n            sample_stride = 1;\n\n        } else {\n\n            samples_ptr   = samples[0] + ch;\n\n            sample_stride = s->nb_channels;\n\n        }\n\n        for (i = 0; i < nb_frames; i++) {\n\n            RENAME(ff_mpa_synth_filter)(&s->mpadsp, s->synth_buf[ch],\n\n                                        &(s->synth_buf_offset[ch]),\n\n                                        RENAME(ff_mpa_synth_window),\n\n                                        &s->dither_state, samples_ptr,\n\n                                        sample_stride, s->sb_samples[ch][i]);\n\n            samples_ptr += 32 * sample_stride;\n\n        }\n\n    }\n\n\n\n    return nb_frames * 32 * sizeof(OUT_INT) * s->nb_channels;\n\n}\n", "idx": 19041, "_split": "test", "_hash": "11223f92a02e91757874cd581ea1c381"}
{"project": "FFmpeg", "commit_id": "fbd97184f8b68b2074b79a1698e4d9404292f7ca", "target": 1, "func": "static int link_filter_inouts(AVFilterContext *filt_ctx,\n\n                              AVFilterInOut **curr_inputs,\n\n                              AVFilterInOut **open_inputs, AVClass *log_ctx)\n\n{\n\n    int pad = filt_ctx->input_count, ret;\n\n\n\n    while (pad--) {\n\n        AVFilterInOut *p = *curr_inputs;\n\n        if (!p) {\n\n            av_log(log_ctx, AV_LOG_ERROR,\n\n                   \"Not enough inputs specified for the \\\"%s\\\" filter.\\n\",\n\n                   filt_ctx->filter->name);\n\n            return AVERROR(EINVAL);\n\n        }\n\n\n\n        *curr_inputs = (*curr_inputs)->next;\n\n\n\n        if (p->filter) {\n\n            if ((ret = link_filter(p->filter, p->pad_idx, filt_ctx, pad, log_ctx)) < 0)\n\n                return ret;\n\n            av_free(p->name);\n\n            av_free(p);\n\n        } else {\n\n            p->filter = filt_ctx;\n\n            p->pad_idx = pad;\n\n            insert_inout(open_inputs, p);\n\n        }\n\n    }\n\n\n\n    if (*curr_inputs) {\n\n        av_log(log_ctx, AV_LOG_ERROR,\n\n               \"Too many inputs specified for the \\\"%s\\\" filter.\\n\",\n\n               filt_ctx->filter->name);\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    pad = filt_ctx->output_count;\n\n    while (pad--) {\n\n        AVFilterInOut *currlinkn = av_mallocz(sizeof(AVFilterInOut));\n\n\n\n        currlinkn->filter  = filt_ctx;\n\n        currlinkn->pad_idx = pad;\n\n        insert_inout(curr_inputs, currlinkn);\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 19245, "_split": "test", "_hash": "f638b28680d8b31dc0728767e6a43ad8"}
{"project": "FFmpeg", "commit_id": "816577716bc6170bccfea3b9e865618b69a4b426", "target": 1, "func": "static av_cold int dvdsub_close(AVCodecContext *avctx)\n\n{\n\n    DVDSubContext *ctx = avctx->priv_data;\n\n    av_freep(&ctx->buf);\n\n    ctx->buf_size = 0;\n\n    return 0;\n\n}\n", "idx": 19353, "_split": "test", "_hash": "3477edf6d811aa2a1dc9846e5fe5fbce"}
{"project": "FFmpeg", "commit_id": "919d13d2383bd7318b80ed0c5b723323a79a8996", "target": 0, "func": "static int cookie_string(AVDictionary *dict, char **cookies)\n\n{\n\n    AVDictionaryEntry *e = NULL;\n\n    int len = 1;\n\n\n\n    // determine how much memory is needed for the cookies string\n\n    while (e = av_dict_get(dict, \"\", e, AV_DICT_IGNORE_SUFFIX))\n\n        len += strlen(e->key) + strlen(e->value) + 1;\n\n\n\n    // reallocate the cookies\n\n    e = NULL;\n\n    if (*cookies) av_free(*cookies);\n\n    *cookies = av_malloc(len);\n\n    if (!cookies) return AVERROR(ENOMEM);\n\n    *cookies[0] = '\\0';\n\n\n\n    // write out the cookies\n\n    while (e = av_dict_get(dict, \"\", e, AV_DICT_IGNORE_SUFFIX))\n\n        av_strlcatf(*cookies, len, \"%s%s\\n\", e->key, e->value);\n\n\n\n    return 0;\n\n}\n", "idx": 19411, "_split": "test", "_hash": "0108054483df6e15b55cab981a5d889c"}
{"project": "FFmpeg", "commit_id": "3594554a064d76e3514fab9781c0e63ea9e08ea9", "target": 0, "func": "av_cold void ff_dsputil_init_vis(DSPContext *c, AVCodecContext *avctx)\n\n{\n\n  /* VIS-specific optimizations */\n\n  int accel = vis_level ();\n\n  const int high_bit_depth = avctx->bits_per_raw_sample > 8;\n\n\n\n  if (accel & ACCEL_SPARC_VIS) {\n\n      if (avctx->bits_per_raw_sample <= 8 &&\n\n          avctx->idct_algo == FF_IDCT_SIMPLEVIS) {\n\n          c->idct_put = ff_simple_idct_put_vis;\n\n          c->idct_add = ff_simple_idct_add_vis;\n\n          c->idct     = ff_simple_idct_vis;\n\n          c->idct_permutation_type = FF_TRANSPOSE_IDCT_PERM;\n\n      }\n\n\n\n      if (!high_bit_depth) {\n\n      c->put_pixels_tab[0][0] = MC_put_o_16_vis;\n\n      c->put_pixels_tab[0][1] = MC_put_x_16_vis;\n\n      c->put_pixels_tab[0][2] = MC_put_y_16_vis;\n\n      c->put_pixels_tab[0][3] = MC_put_xy_16_vis;\n\n\n\n      c->put_pixels_tab[1][0] = MC_put_o_8_vis;\n\n      c->put_pixels_tab[1][1] = MC_put_x_8_vis;\n\n      c->put_pixels_tab[1][2] = MC_put_y_8_vis;\n\n      c->put_pixels_tab[1][3] = MC_put_xy_8_vis;\n\n\n\n      c->avg_pixels_tab[0][0] = MC_avg_o_16_vis;\n\n      c->avg_pixels_tab[0][1] = MC_avg_x_16_vis;\n\n      c->avg_pixels_tab[0][2] = MC_avg_y_16_vis;\n\n      c->avg_pixels_tab[0][3] = MC_avg_xy_16_vis;\n\n\n\n      c->avg_pixels_tab[1][0] = MC_avg_o_8_vis;\n\n      c->avg_pixels_tab[1][1] = MC_avg_x_8_vis;\n\n      c->avg_pixels_tab[1][2] = MC_avg_y_8_vis;\n\n      c->avg_pixels_tab[1][3] = MC_avg_xy_8_vis;\n\n\n\n      c->put_no_rnd_pixels_tab[0][0] = MC_put_no_round_o_16_vis;\n\n      c->put_no_rnd_pixels_tab[0][1] = MC_put_no_round_x_16_vis;\n\n      c->put_no_rnd_pixels_tab[0][2] = MC_put_no_round_y_16_vis;\n\n      c->put_no_rnd_pixels_tab[0][3] = MC_put_no_round_xy_16_vis;\n\n\n\n      c->put_no_rnd_pixels_tab[1][0] = MC_put_no_round_o_8_vis;\n\n      c->put_no_rnd_pixels_tab[1][1] = MC_put_no_round_x_8_vis;\n\n      c->put_no_rnd_pixels_tab[1][2] = MC_put_no_round_y_8_vis;\n\n      c->put_no_rnd_pixels_tab[1][3] = MC_put_no_round_xy_8_vis;\n\n\n\n      c->avg_no_rnd_pixels_tab[0] = MC_avg_no_round_o_16_vis;\n\n      c->avg_no_rnd_pixels_tab[1] = MC_avg_no_round_x_16_vis;\n\n      c->avg_no_rnd_pixels_tab[2] = MC_avg_no_round_y_16_vis;\n\n      c->avg_no_rnd_pixels_tab[3] = MC_avg_no_round_xy_16_vis;\n\n      }\n\n  }\n\n}\n", "idx": 19494, "_split": "test", "_hash": "96c74e55d34a4d4a63ac8d1578459335"}
{"project": "FFmpeg", "commit_id": "5ad4335c2233d5a6d9487d2d56387b7484aecded", "target": 0, "func": "void vp8_mc(VP8Context *s, int luma,\n\n            uint8_t *dst, uint8_t *src, const VP56mv *mv,\n\n            int x_off, int y_off, int block_w, int block_h,\n\n            int width, int height, int linesize,\n\n            vp8_mc_func mc_func[3][3])\n\n{\n\n    if (AV_RN32A(mv)) {\n\n        static const uint8_t idx[3][8] = {\n\n            { 0, 1, 2, 1, 2, 1, 2, 1 }, // nr. of left extra pixels,\n\n                                        // also function pointer index\n\n            { 0, 3, 5, 3, 5, 3, 5, 3 }, // nr. of extra pixels required\n\n            { 0, 2, 3, 2, 3, 2, 3, 2 }, // nr. of right extra pixels\n\n        };\n\n        int mx = (mv->x << luma)&7, mx_idx = idx[0][mx];\n\n        int my = (mv->y << luma)&7, my_idx = idx[0][my];\n\n\n\n        x_off += mv->x >> (3 - luma);\n\n        y_off += mv->y >> (3 - luma);\n\n\n\n        // edge emulation\n\n        src += y_off * linesize + x_off;\n\n        if (x_off < mx_idx || x_off >= width  - block_w - idx[2][mx] ||\n\n            y_off < my_idx || y_off >= height - block_h - idx[2][my]) {\n\n            s->dsp.emulated_edge_mc(s->edge_emu_buffer, src - my_idx * linesize - mx_idx, linesize,\n\n                                block_w + idx[1][mx], block_h + idx[1][my],\n\n                                x_off - mx_idx, y_off - my_idx, width, height);\n\n            src = s->edge_emu_buffer + mx_idx + linesize * my_idx;\n\n        }\n\n        mc_func[my_idx][mx_idx](dst, linesize, src, linesize, block_h, mx, my);\n\n    } else\n\n        mc_func[0][0](dst, linesize, src + y_off * linesize + x_off, linesize, block_h, 0, 0);\n\n}\n", "idx": 19538, "_split": "test", "_hash": "6189751b1b1bb260860ec750056da744"}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "DECLARE_LOOP_FILTER(mmxext)\n\nDECLARE_LOOP_FILTER(sse2)\n\nDECLARE_LOOP_FILTER(ssse3)\n\nDECLARE_LOOP_FILTER(sse4)\n\n\n\n#endif /* HAVE_YASM */\n\n\n\n#define VP8_LUMA_MC_FUNC(IDX, SIZE, OPT) \\\n\n    c->put_vp8_epel_pixels_tab[IDX][0][2] = ff_put_vp8_epel ## SIZE ## _h6_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][2][0] = ff_put_vp8_epel ## SIZE ## _v6_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][2][2] = ff_put_vp8_epel ## SIZE ## _h6v6_ ## OPT\n\n\n\n#define VP8_MC_FUNC(IDX, SIZE, OPT) \\\n\n    c->put_vp8_epel_pixels_tab[IDX][0][1] = ff_put_vp8_epel ## SIZE ## _h4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][1][0] = ff_put_vp8_epel ## SIZE ## _v4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][1][1] = ff_put_vp8_epel ## SIZE ## _h4v4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][1][2] = ff_put_vp8_epel ## SIZE ## _h6v4_ ## OPT; \\\n\n    c->put_vp8_epel_pixels_tab[IDX][2][1] = ff_put_vp8_epel ## SIZE ## _h4v6_ ## OPT; \\\n\n    VP8_LUMA_MC_FUNC(IDX, SIZE, OPT)\n\n\n\n#define VP8_BILINEAR_MC_FUNC(IDX, SIZE, OPT) \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][0][1] = ff_put_vp8_bilinear ## SIZE ## _h_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][0][2] = ff_put_vp8_bilinear ## SIZE ## _h_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][1][0] = ff_put_vp8_bilinear ## SIZE ## _v_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][1][1] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][1][2] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][2][0] = ff_put_vp8_bilinear ## SIZE ## _v_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][2][1] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT; \\\n\n    c->put_vp8_bilinear_pixels_tab[IDX][2][2] = ff_put_vp8_bilinear ## SIZE ## _hv_ ## OPT\n\n\n\n\n\nav_cold void ff_vp8dsp_init_x86(VP8DSPContext* c)\n\n{\n\n#if HAVE_YASM\n\n    int cpu_flags = av_get_cpu_flags();\n\n\n\n    if (EXTERNAL_MMX(cpu_flags)) {\n\n        c->vp8_idct_dc_add    = ff_vp8_idct_dc_add_mmx;\n\n        c->vp8_idct_dc_add4uv = ff_vp8_idct_dc_add4uv_mmx;\n\n#if ARCH_X86_32\n\n        c->vp8_idct_dc_add4y  = ff_vp8_idct_dc_add4y_mmx;\n\n        c->vp8_idct_add       = ff_vp8_idct_add_mmx;\n\n        c->vp8_luma_dc_wht    = ff_vp8_luma_dc_wht_mmx;\n\n        c->put_vp8_epel_pixels_tab[0][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_mmx;\n\n#endif\n\n        c->put_vp8_epel_pixels_tab[1][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[1][0][0] = ff_put_vp8_pixels8_mmx;\n\n\n\n#if ARCH_X86_32\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_mmx;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_mmx;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmx;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmx;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmx;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmx;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_mmx;\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_mmx;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_mmx;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_mmx;\n\n#endif\n\n    }\n\n\n\n    /* note that 4-tap width=16 functions are missing because w=16\n\n     * is only used for luma, and luma is always a copy or sixtap. */\n\n    if (EXTERNAL_MMXEXT(cpu_flags)) {\n\n        VP8_MC_FUNC(2, 4, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(2, 4, mmxext);\n\n#if ARCH_X86_32\n\n        VP8_LUMA_MC_FUNC(0, 16, mmxext);\n\n        VP8_MC_FUNC(1, 8, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, mmxext);\n\n        VP8_BILINEAR_MC_FUNC(1,  8, mmxext);\n\n\n\n        c->vp8_v_loop_filter_simple   = ff_vp8_v_loop_filter_simple_mmxext;\n\n        c->vp8_h_loop_filter_simple   = ff_vp8_h_loop_filter_simple_mmxext;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_mmxext;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_mmxext;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_mmxext;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_mmxext;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_mmxext;\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_mmxext;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_mmxext;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_mmxext;\n\n#endif\n\n    }\n\n\n\n    if (EXTERNAL_SSE(cpu_flags)) {\n\n        c->vp8_idct_add                         = ff_vp8_idct_add_sse;\n\n        c->vp8_luma_dc_wht                      = ff_vp8_luma_dc_wht_sse;\n\n        c->put_vp8_epel_pixels_tab[0][0][0]     =\n\n        c->put_vp8_bilinear_pixels_tab[0][0][0] = ff_put_vp8_pixels16_sse;\n\n    }\n\n\n\n    if (EXTERNAL_SSE2(cpu_flags) && (cpu_flags & AV_CPU_FLAG_SSE2SLOW)) {\n\n        VP8_LUMA_MC_FUNC(0, 16, sse2);\n\n        VP8_MC_FUNC(1, 8, sse2);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, sse2);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, sse2);\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_sse2;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_sse2;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_sse2;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_sse2;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_sse2;\n\n    }\n\n\n\n    if (EXTERNAL_SSE2(cpu_flags)) {\n\n        c->vp8_idct_dc_add4y          = ff_vp8_idct_dc_add4y_sse2;\n\n\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_sse2;\n\n\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_sse2;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_sse2;\n\n\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_sse2;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_sse2;\n\n    }\n\n\n\n    if (EXTERNAL_SSSE3(cpu_flags)) {\n\n        VP8_LUMA_MC_FUNC(0, 16, ssse3);\n\n        VP8_MC_FUNC(1, 8, ssse3);\n\n        VP8_MC_FUNC(2, 4, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(0, 16, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(1, 8, ssse3);\n\n        VP8_BILINEAR_MC_FUNC(2, 4, ssse3);\n\n\n\n        c->vp8_v_loop_filter_simple = ff_vp8_v_loop_filter_simple_ssse3;\n\n        c->vp8_h_loop_filter_simple = ff_vp8_h_loop_filter_simple_ssse3;\n\n\n\n        c->vp8_v_loop_filter16y_inner = ff_vp8_v_loop_filter16y_inner_ssse3;\n\n        c->vp8_h_loop_filter16y_inner = ff_vp8_h_loop_filter16y_inner_ssse3;\n\n        c->vp8_v_loop_filter8uv_inner = ff_vp8_v_loop_filter8uv_inner_ssse3;\n\n        c->vp8_h_loop_filter8uv_inner = ff_vp8_h_loop_filter8uv_inner_ssse3;\n\n\n\n        c->vp8_v_loop_filter16y       = ff_vp8_v_loop_filter16y_mbedge_ssse3;\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_ssse3;\n\n        c->vp8_v_loop_filter8uv       = ff_vp8_v_loop_filter8uv_mbedge_ssse3;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_ssse3;\n\n    }\n\n\n\n    if (EXTERNAL_SSE4(cpu_flags)) {\n\n        c->vp8_idct_dc_add                  = ff_vp8_idct_dc_add_sse4;\n\n\n\n        c->vp8_h_loop_filter_simple   = ff_vp8_h_loop_filter_simple_sse4;\n\n        c->vp8_h_loop_filter16y       = ff_vp8_h_loop_filter16y_mbedge_sse4;\n\n        c->vp8_h_loop_filter8uv       = ff_vp8_h_loop_filter8uv_mbedge_sse4;\n\n    }\n\n#endif /* HAVE_YASM */\n\n}\n", "idx": 19557, "_split": "test", "_hash": "dbe7904d53ee3c1ec59fdbcce518c846"}
{"project": "FFmpeg", "commit_id": "7b6a51f59c467ab9f4b73122dc269206fb517425", "target": 1, "func": "static inline unsigned int get_uint(ShortenContext *s, int k)\n\n{\n\n    if (s->version != 0)\n\n        k = get_ur_golomb_shorten(&s->gb, ULONGSIZE);\n\n    return get_ur_golomb_shorten(&s->gb, k);\n\n}\n", "idx": 19593, "_split": "test", "_hash": "5ce9e91106a64fdd79ad9edab8cb28fc"}
{"project": "FFmpeg", "commit_id": "136ce8baa4fc16cf38690cb457f7356c00e00a28", "target": 1, "func": "static void scale_coefs (\n\n    int32_t *dst,\n\n    const int32_t *src,\n\n    int dynrng,\n\n    int len)\n\n{\n\n    int i, shift, round;\n\n    int16_t mul;\n\n    int temp, temp1, temp2, temp3, temp4, temp5, temp6, temp7;\n\n\n\n    mul = (dynrng & 0x1f) + 0x20;\n\n    shift = 4 - ((dynrng << 23) >> 28);\n\n    if (shift > 0 ) {\n\n      round = 1 << (shift-1);\n\n      for (i=0; i<len; i+=8) {\n\n\n\n          temp = src[i] * mul;\n\n          temp1 = src[i+1] * mul;\n\n          temp = temp + round;\n\n          temp2 = src[i+2] * mul;\n\n\n\n          temp1 = temp1 + round;\n\n          dst[i] = temp >> shift;\n\n          temp3 = src[i+3] * mul;\n\n          temp2 = temp2 + round;\n\n\n\n          dst[i+1] = temp1 >> shift;\n\n          temp4 = src[i + 4] * mul;\n\n          temp3 = temp3 + round;\n\n          dst[i+2] = temp2 >> shift;\n\n\n\n          temp5 = src[i+5] * mul;\n\n          temp4 = temp4 + round;\n\n          dst[i+3] = temp3 >> shift;\n\n          temp6 = src[i+6] * mul;\n\n\n\n          dst[i+4] = temp4 >> shift;\n\n          temp5 = temp5 + round;\n\n          temp7 = src[i+7] * mul;\n\n          temp6 = temp6 + round;\n\n\n\n          dst[i+5] = temp5 >> shift;\n\n          temp7 = temp7 + round;\n\n          dst[i+6] = temp6 >> shift;\n\n          dst[i+7] = temp7 >> shift;\n\n\n\n      }\n\n    } else {\n\n      shift = -shift;\n\n      for (i=0; i<len; i+=8) {\n\n\n\n          temp = src[i] * mul;\n\n          temp1 = src[i+1] * mul;\n\n          temp2 = src[i+2] * mul;\n\n\n\n          dst[i] = temp << shift;\n\n          temp3 = src[i+3] * mul;\n\n\n\n          dst[i+1] = temp1 << shift;\n\n          temp4 = src[i + 4] * mul;\n\n          dst[i+2] = temp2 << shift;\n\n\n\n          temp5 = src[i+5] * mul;\n\n          dst[i+3] = temp3 << shift;\n\n          temp6 = src[i+6] * mul;\n\n\n\n          dst[i+4] = temp4 << shift;\n\n          temp7 = src[i+7] * mul;\n\n\n\n          dst[i+5] = temp5 << shift;\n\n          dst[i+6] = temp6 << shift;\n\n          dst[i+7] = temp7 << shift;\n\n\n\n      }\n\n    }\n\n}\n", "idx": 19595, "_split": "test", "_hash": "23bdccd82b1a8ac44ef72af644275d68"}
{"project": "FFmpeg", "commit_id": "8f4020d8a4b2e6264f54accbcb881577316c3ca6", "target": 0, "func": "static int svq1_decode_frame_header(GetBitContext *bitbuf, MpegEncContext *s)\n\n{\n\n    int frame_size_code;\n\n\n\n    skip_bits(bitbuf, 8); /* temporal_reference */\n\n\n\n    /* frame type */\n\n    s->pict_type = get_bits(bitbuf, 2) + 1;\n\n    if (s->pict_type == 4)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n\n        /* unknown fields */\n\n        if (s->f_code == 0x50 || s->f_code == 0x60) {\n\n            int csum = get_bits(bitbuf, 16);\n\n\n\n            csum = ff_svq1_packet_checksum(bitbuf->buffer,\n\n                                           bitbuf->size_in_bits >> 3,\n\n                                           csum);\n\n\n\n            av_dlog(s->avctx, \"%s checksum (%02x) for packet data\\n\",\n\n                    (csum == 0) ? \"correct\" : \"incorrect\", csum);\n\n        }\n\n\n\n        if ((s->f_code ^ 0x10) >= 0x50) {\n\n            uint8_t msg[256];\n\n\n\n            svq1_parse_string(bitbuf, msg);\n\n\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"embedded message: \\\"%s\\\"\\n\", (char *)msg);\n\n        }\n\n\n\n        skip_bits(bitbuf, 2);\n\n        skip_bits(bitbuf, 2);\n\n        skip_bits1(bitbuf);\n\n\n\n        /* load frame size */\n\n        frame_size_code = get_bits(bitbuf, 3);\n\n\n\n        if (frame_size_code == 7) {\n\n            /* load width, height (12 bits each) */\n\n            s->width  = get_bits(bitbuf, 12);\n\n            s->height = get_bits(bitbuf, 12);\n\n\n\n            if (!s->width || !s->height)\n\n                return AVERROR_INVALIDDATA;\n\n        } else {\n\n            /* get width, height from table */\n\n            s->width  = ff_svq1_frame_size_table[frame_size_code].width;\n\n            s->height = ff_svq1_frame_size_table[frame_size_code].height;\n\n        }\n\n    }\n\n\n\n    /* unknown fields */\n\n    if (get_bits1(bitbuf) == 1) {\n\n        skip_bits1(bitbuf);    /* use packet checksum if (1) */\n\n        skip_bits1(bitbuf);    /* component checksums after image data if (1) */\n\n\n\n        if (get_bits(bitbuf, 2) != 0)\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (get_bits1(bitbuf) == 1) {\n\n        skip_bits1(bitbuf);\n\n        skip_bits(bitbuf, 4);\n\n        skip_bits1(bitbuf);\n\n        skip_bits(bitbuf, 2);\n\n\n\n        while (get_bits1(bitbuf) == 1)\n\n            skip_bits(bitbuf, 8);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 19654, "_split": "test", "_hash": "40481f82e5671376edf2cd46cb8a6be0"}
{"project": "FFmpeg", "commit_id": "bf5af5687569e34d6e3a4d31fc6bb5dc44efdb29", "target": 1, "func": "void prepare_grab(void)\n\n{\n\n    fprintf(stderr, \"Must supply at least one input file\\n\");\n\n    exit(1);\n\n}\n", "idx": 19665, "_split": "test", "_hash": "ec30d6c69ee88d2de8309d80b3fa3f94"}
{"project": "FFmpeg", "commit_id": "92e483f8ed70d88d4f64337f65bae212502735d4", "target": 1, "func": "static int compare_codec_desc(const void *a, const void *b)\n\n{\n\n    const AVCodecDescriptor * const *da = a;\n\n    const AVCodecDescriptor * const *db = b;\n\n\n\n    return (*da)->type != (*db)->type ? (*da)->type - (*db)->type :\n\n           strcmp((*da)->name, (*db)->name);\n\n}\n", "idx": 19667, "_split": "test", "_hash": "4a7fec3bd0d7f0a2a141914ec2519fe5"}
{"project": "FFmpeg", "commit_id": "0d21a84605bad4e75dacb8196e5859902ed36f01", "target": 0, "func": "int ff_estimate_motion_b(MpegEncContext * s,\n\n                       int mb_x, int mb_y, int16_t (*mv_table)[2], uint8_t *ref_picture, int f_code)\n\n{\n\n    int mx, my, range, dmin;\n\n    int xmin, ymin, xmax, ymax;\n\n    int rel_xmin, rel_ymin, rel_xmax, rel_ymax;\n\n    int pred_x=0, pred_y=0;\n\n    int P[6][2];\n\n    const int shift= 1+s->quarter_sample;\n\n    const int mot_stride = s->mb_width + 2;\n\n    const int mot_xy = (mb_y + 1)*mot_stride + mb_x + 1;\n\n    \n\n    get_limits(s, &range, &xmin, &ymin, &xmax, &ymax, f_code);\n\n\n\n    switch(s->me_method) {\n\n    case ME_ZERO:\n\n    default:\n\n\tno_motion_search(s, &mx, &my);\n\n        dmin = 0;\n\n        break;\n\n    case ME_FULL:\n\n\tdmin = full_motion_search(s, &mx, &my, range, xmin, ymin, xmax, ymax, ref_picture);\n\n        break;\n\n    case ME_LOG:\n\n\tdmin = log_motion_search(s, &mx, &my, range / 2, xmin, ymin, xmax, ymax, ref_picture);\n\n        break;\n\n    case ME_PHODS:\n\n\tdmin = phods_motion_search(s, &mx, &my, range / 2, xmin, ymin, xmax, ymax, ref_picture);\n\n        break;\n\n    case ME_X1:\n\n    case ME_EPZS:\n\n       {\n\n\n\n            rel_xmin= xmin - mb_x*16;\n\n            rel_xmax= xmax - mb_x*16;\n\n            rel_ymin= ymin - mb_y*16;\n\n            rel_ymax= ymax - mb_y*16;\n\n\n\n            P[0][0] = mv_table[mot_xy    ][0];\n\n            P[0][1] = mv_table[mot_xy    ][1];\n\n            P[1][0] = mv_table[mot_xy - 1][0];\n\n            P[1][1] = mv_table[mot_xy - 1][1];\n\n            if(P[1][0] > (rel_xmax<<shift)) P[1][0]= (rel_xmax<<shift);\n\n\n\n            /* special case for first line */\n\n            if ((mb_y == 0 || s->first_slice_line || s->first_gob_line)) {\n\n                P[4][0] = P[1][0];\n\n                P[4][1] = P[1][1];\n\n            } else {\n\n                P[2][0] = mv_table[mot_xy - mot_stride             ][0];\n\n                P[2][1] = mv_table[mot_xy - mot_stride             ][1];\n\n                P[3][0] = mv_table[mot_xy - mot_stride + 1         ][0];\n\n                P[3][1] = mv_table[mot_xy - mot_stride + 1         ][1];\n\n                if(P[2][1] > (rel_ymax<<shift)) P[2][1]= (rel_ymax<<shift);\n\n                if(P[3][0] < (rel_xmin<<shift)) P[3][0]= (rel_xmin<<shift);\n\n                if(P[3][1] > (rel_ymax<<shift)) P[3][1]= (rel_ymax<<shift);\n\n        \n\n                P[4][0]= mid_pred(P[1][0], P[2][0], P[3][0]);\n\n                P[4][1]= mid_pred(P[1][1], P[2][1], P[3][1]);\n\n            }\n\n            pred_x= P[1][0];\n\n            pred_y= P[1][1];\n\n        }\n\n        dmin = epzs_motion_search(s, &mx, &my, P, pred_x, pred_y, rel_xmin, rel_ymin, rel_xmax, rel_ymax, ref_picture);\n\n \n\n        mx+= mb_x*16;\n\n        my+= mb_y*16;\n\n        break;\n\n    }\n\n    \n\n    /* intra / predictive decision */\n\n//    xx = mb_x * 16;\n\n//    yy = mb_y * 16;\n\n\n\n//    pix = s->new_picture[0] + (yy * s->linesize) + xx;\n\n    /* At this point (mx,my) are full-pell and the absolute displacement */\n\n//    ppix = ref_picture + (my * s->linesize) + mx;\n\n    \n\n    dmin= halfpel_motion_search(s, &mx, &my, dmin, xmin, ymin, xmax, ymax, pred_x, pred_y, ref_picture);\n\n\n\n//    s->mb_type[mb_y*s->mb_width + mb_x]= mb_type;\n\n    mv_table[mot_xy][0]= mx;\n\n    mv_table[mot_xy][1]= my;\n\n    return dmin;\n\n}\n", "idx": 19721, "_split": "test", "_hash": "812f1f5415e37db242522ffc776956c6"}
{"project": "FFmpeg", "commit_id": "ecb14b8af73b92e5a1be47c119d2f528ff402ebd", "target": 0, "func": "static int decode_nal_units(H264Context *h, const uint8_t *buf, int buf_size){\n\n    MpegEncContext * const s = &h->s;\n\n    AVCodecContext * const avctx= s->avctx;\n\n    H264Context *hx; ///< thread context\n\n    int buf_index;\n\n    int context_count;\n\n    int next_avc;\n\n    int pass = !(avctx->active_thread_type & FF_THREAD_FRAME);\n\n    int nals_needed=0; ///< number of NALs that need decoding before the next frame thread starts\n\n    int nal_index;\n\n\n\n    h->nal_unit_type= 0;\n\n\n\n    h->max_contexts = (HAVE_THREADS && (s->avctx->active_thread_type&FF_THREAD_SLICE)) ? avctx->thread_count : 1;\n\n    if(!(s->flags2 & CODEC_FLAG2_CHUNKS)){\n\n        h->current_slice = 0;\n\n        if (!s->first_field)\n\n            s->current_picture_ptr= NULL;\n\n        ff_h264_reset_sei(h);\n\n    }\n\n\n\n    for(;pass <= 1;pass++){\n\n        buf_index = 0;\n\n        context_count = 0;\n\n        next_avc = h->is_avc ? 0 : buf_size;\n\n        nal_index = 0;\n\n    for(;;){\n\n        int consumed;\n\n        int dst_length;\n\n        int bit_length;\n\n        uint8_t *ptr;\n\n        int i, nalsize = 0;\n\n        int err;\n\n\n\n        if(buf_index >= next_avc) {\n\n            if (buf_index >= buf_size - h->nal_length_size) break;\n\n            nalsize = 0;\n\n            for(i = 0; i < h->nal_length_size; i++)\n\n                nalsize = (nalsize << 8) | buf[buf_index++];\n\n            if(nalsize <= 0 || nalsize > buf_size - buf_index){\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"AVC: nal size %d\\n\", nalsize);\n\n                break;\n\n            }\n\n            next_avc= buf_index + nalsize;\n\n        } else {\n\n            // start code prefix search\n\n            for(; buf_index + 3 < next_avc; buf_index++){\n\n                // This should always succeed in the first iteration.\n\n                if(buf[buf_index] == 0 && buf[buf_index+1] == 0 && buf[buf_index+2] == 1)\n\n                    break;\n\n            }\n\n\n\n            if(buf_index+3 >= buf_size) break;\n\n\n\n            buf_index+=3;\n\n            if(buf_index >= next_avc) continue;\n\n        }\n\n\n\n        hx = h->thread_context[context_count];\n\n\n\n        ptr= ff_h264_decode_nal(hx, buf + buf_index, &dst_length, &consumed, next_avc - buf_index);\n\n        if (ptr==NULL || dst_length < 0){\n\n            return -1;\n\n        }\n\n        i= buf_index + consumed;\n\n        if((s->workaround_bugs & FF_BUG_AUTODETECT) && i+3<next_avc &&\n\n           buf[i]==0x00 && buf[i+1]==0x00 && buf[i+2]==0x01 && buf[i+3]==0xE0)\n\n            s->workaround_bugs |= FF_BUG_TRUNCATED;\n\n\n\n        if(!(s->workaround_bugs & FF_BUG_TRUNCATED)){\n\n        while(dst_length > 0 && ptr[dst_length - 1] == 0)\n\n            dst_length--;\n\n        }\n\n        bit_length= !dst_length ? 0 : (8*dst_length - ff_h264_decode_rbsp_trailing(h, ptr + dst_length - 1));\n\n\n\n        if(s->avctx->debug&FF_DEBUG_STARTCODE){\n\n            av_log(h->s.avctx, AV_LOG_DEBUG, \"NAL %d/%d at %d/%d length %d pass %d\\n\", hx->nal_unit_type, hx->nal_ref_idc, buf_index, buf_size, dst_length, pass);\n\n        }\n\n\n\n        if (h->is_avc && (nalsize != consumed) && nalsize){\n\n            av_log(h->s.avctx, AV_LOG_DEBUG, \"AVC: Consumed only %d bytes instead of %d\\n\", consumed, nalsize);\n\n        }\n\n\n\n        buf_index += consumed;\n\n        nal_index++;\n\n\n\n        if(pass == 0) {\n\n            // packets can sometimes contain multiple PPS/SPS\n\n            // e.g. two PAFF field pictures in one packet, or a demuxer which splits NALs strangely\n\n            // if so, when frame threading we can't start the next thread until we've read all of them\n\n            switch (hx->nal_unit_type) {\n\n                case NAL_SPS:\n\n                case NAL_PPS:\n\n                    nals_needed = nal_index;\n\n                    break;\n\n                case NAL_IDR_SLICE:\n\n                case NAL_SLICE:\n\n                    init_get_bits(&hx->s.gb, ptr, bit_length);\n\n                    if (!get_ue_golomb(&hx->s.gb))\n\n                        nals_needed = nal_index;\n\n            }\n\n            continue;\n\n        }\n\n\n\n        //FIXME do not discard SEI id\n\n        if(avctx->skip_frame >= AVDISCARD_NONREF && h->nal_ref_idc  == 0)\n\n            continue;\n\n\n\n      again:\n\n        err = 0;\n\n        switch(hx->nal_unit_type){\n\n        case NAL_IDR_SLICE:\n\n            if (h->nal_unit_type != NAL_IDR_SLICE) {\n\n                av_log(h->s.avctx, AV_LOG_ERROR, \"Invalid mix of idr and non-idr slices\");\n\n                return -1;\n\n            }\n\n            idr(h); // FIXME ensure we don't lose some frames if there is reordering\n\n        case NAL_SLICE:\n\n            init_get_bits(&hx->s.gb, ptr, bit_length);\n\n            hx->intra_gb_ptr=\n\n            hx->inter_gb_ptr= &hx->s.gb;\n\n            hx->s.data_partitioning = 0;\n\n\n\n            if((err = decode_slice_header(hx, h)))\n\n               break;\n\n\n\n            if (   h->sei_recovery_frame_cnt >= 0\n\n                && ((h->recovery_frame - h->frame_num) & ((1 << h->sps.log2_max_frame_num)-1)) > h->sei_recovery_frame_cnt) {\n\n                h->recovery_frame = (h->frame_num + h->sei_recovery_frame_cnt) %\n\n                                    (1 << h->sps.log2_max_frame_num);\n\n            }\n\n\n\n            s->current_picture_ptr->f.key_frame |=\n\n                    (hx->nal_unit_type == NAL_IDR_SLICE);\n\n\n\n            if (h->recovery_frame == h->frame_num) {\n\n                h->sync |= 1;\n\n                h->recovery_frame = -1;\n\n            }\n\n\n\n            h->sync |= !!s->current_picture_ptr->f.key_frame;\n\n            h->sync |= 3*!!(s->flags2 & CODEC_FLAG2_SHOW_ALL);\n\n            s->current_picture_ptr->sync = h->sync;\n\n\n\n            if (h->current_slice == 1) {\n\n                if(!(s->flags2 & CODEC_FLAG2_CHUNKS)) {\n\n                    decode_postinit(h, nal_index >= nals_needed);\n\n                }\n\n\n\n                if (s->avctx->hwaccel && s->avctx->hwaccel->start_frame(s->avctx, NULL, 0) < 0)\n\n                    return -1;\n\n                if(CONFIG_H264_VDPAU_DECODER && s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU)\n\n                    ff_vdpau_h264_picture_start(s);\n\n            }\n\n\n\n            if(hx->redundant_pic_count==0\n\n               && (avctx->skip_frame < AVDISCARD_NONREF || hx->nal_ref_idc)\n\n               && (avctx->skip_frame < AVDISCARD_BIDIR  || hx->slice_type_nos!=AV_PICTURE_TYPE_B)\n\n               && (avctx->skip_frame < AVDISCARD_NONKEY || hx->slice_type_nos==AV_PICTURE_TYPE_I)\n\n               && avctx->skip_frame < AVDISCARD_ALL){\n\n                if(avctx->hwaccel) {\n\n                    if (avctx->hwaccel->decode_slice(avctx, &buf[buf_index - consumed], consumed) < 0)\n\n                        return -1;\n\n                }else\n\n                if(CONFIG_H264_VDPAU_DECODER && s->avctx->codec->capabilities&CODEC_CAP_HWACCEL_VDPAU){\n\n                    static const uint8_t start_code[] = {0x00, 0x00, 0x01};\n\n                    ff_vdpau_add_data_chunk(s, start_code, sizeof(start_code));\n\n                    ff_vdpau_add_data_chunk(s, &buf[buf_index - consumed], consumed );\n\n                }else\n\n                    context_count++;\n\n            }\n\n            break;\n\n        case NAL_DPA:\n\n            init_get_bits(&hx->s.gb, ptr, bit_length);\n\n            hx->intra_gb_ptr=\n\n            hx->inter_gb_ptr= NULL;\n\n\n\n            if ((err = decode_slice_header(hx, h)) < 0)\n\n                break;\n\n\n\n            hx->s.data_partitioning = 1;\n\n\n\n            break;\n\n        case NAL_DPB:\n\n            init_get_bits(&hx->intra_gb, ptr, bit_length);\n\n            hx->intra_gb_ptr= &hx->intra_gb;\n\n            break;\n\n        case NAL_DPC:\n\n            init_get_bits(&hx->inter_gb, ptr, bit_length);\n\n            hx->inter_gb_ptr= &hx->inter_gb;\n\n\n\n            if(hx->redundant_pic_count==0 && hx->intra_gb_ptr && hx->s.data_partitioning\n\n               && s->context_initialized\n\n               && (avctx->skip_frame < AVDISCARD_NONREF || hx->nal_ref_idc)\n\n               && (avctx->skip_frame < AVDISCARD_BIDIR  || hx->slice_type_nos!=AV_PICTURE_TYPE_B)\n\n               && (avctx->skip_frame < AVDISCARD_NONKEY || hx->slice_type_nos==AV_PICTURE_TYPE_I)\n\n               && avctx->skip_frame < AVDISCARD_ALL)\n\n                context_count++;\n\n            break;\n\n        case NAL_SEI:\n\n            init_get_bits(&s->gb, ptr, bit_length);\n\n            ff_h264_decode_sei(h);\n\n            break;\n\n        case NAL_SPS:\n\n            init_get_bits(&s->gb, ptr, bit_length);\n\n            if(ff_h264_decode_seq_parameter_set(h) < 0 && (h->is_avc ? (nalsize != consumed) && nalsize : 1)){\n\n                av_log(h->s.avctx, AV_LOG_DEBUG, \"SPS decoding failure, trying alternative mode\\n\");\n\n                if(h->is_avc) av_assert0(next_avc - buf_index + consumed == nalsize);\n\n                init_get_bits(&s->gb, &buf[buf_index + 1 - consumed], 8*(next_avc - buf_index + consumed));\n\n                ff_h264_decode_seq_parameter_set(h);\n\n            }\n\n\n\n            if (s->flags& CODEC_FLAG_LOW_DELAY ||\n\n                (h->sps.bitstream_restriction_flag && !h->sps.num_reorder_frames))\n\n                s->low_delay=1;\n\n\n\n            if(avctx->has_b_frames < 2)\n\n                avctx->has_b_frames= !s->low_delay;\n\n            break;\n\n        case NAL_PPS:\n\n            init_get_bits(&s->gb, ptr, bit_length);\n\n\n\n            ff_h264_decode_picture_parameter_set(h, bit_length);\n\n\n\n            break;\n\n        case NAL_AUD:\n\n        case NAL_END_SEQUENCE:\n\n        case NAL_END_STREAM:\n\n        case NAL_FILLER_DATA:\n\n        case NAL_SPS_EXT:\n\n        case NAL_AUXILIARY_SLICE:\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_DEBUG, \"Unknown NAL code: %d (%d bits)\\n\", hx->nal_unit_type, bit_length);\n\n        }\n\n\n\n        if(context_count == h->max_contexts) {\n\n            execute_decode_slices(h, context_count);\n\n            context_count = 0;\n\n        }\n\n\n\n        if (err < 0)\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"decode_slice_header error\\n\");\n\n        else if(err == 1) {\n\n            /* Slice could not be decoded in parallel mode, copy down\n\n             * NAL unit stuff to context 0 and restart. Note that\n\n             * rbsp_buffer is not transferred, but since we no longer\n\n             * run in parallel mode this should not be an issue. */\n\n            h->nal_unit_type = hx->nal_unit_type;\n\n            h->nal_ref_idc   = hx->nal_ref_idc;\n\n            hx = h;\n\n            goto again;\n\n        }\n\n    }\n\n    }\n\n    if(context_count)\n\n        execute_decode_slices(h, context_count);\n\n    return buf_index;\n\n}\n", "idx": 19724, "_split": "test", "_hash": "269582b1cb8ca156cb26e7e576c40148"}
{"project": "FFmpeg", "commit_id": "611b35627488a8d0763e75c25ee0875c5b7987dd", "target": 1, "func": "static int dnxhd_find_frame_end(DNXHDParserContext *dctx,\n\n                                const uint8_t *buf, int buf_size)\n\n{\n\n    ParseContext *pc = &dctx->pc;\n\n    uint64_t state = pc->state64;\n\n    int pic_found = pc->frame_start_found;\n\n    int i = 0;\n\n\n\n    if (!pic_found) {\n\n        for (i = 0; i < buf_size; i++) {\n\n            state = (state << 8) | buf[i];\n\n            if (ff_dnxhd_check_header_prefix(state & 0xffffffffff00LL) != 0) {\n\n                i++;\n\n                pic_found = 1;\n\n                dctx->cur_byte = 0;\n\n                dctx->remaining = 0;\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (pic_found && !dctx->remaining) {\n\n        if (!buf_size) /* EOF considered as end of frame */\n\n            return 0;\n\n        for (; i < buf_size; i++) {\n\n            dctx->cur_byte++;\n\n            state = (state << 8) | buf[i];\n\n\n\n            if (dctx->cur_byte == 24) {\n\n                dctx->h = (state >> 32) & 0xFFFF;\n\n            } else if (dctx->cur_byte == 26) {\n\n                dctx->w = (state >> 32) & 0xFFFF;\n\n            } else if (dctx->cur_byte == 42) {\n\n                int cid = (state >> 32) & 0xFFFFFFFF;\n\n\n\n                if (cid <= 0)\n\n                    continue;\n\n\n\n                dctx->remaining = avpriv_dnxhd_get_frame_size(cid);\n\n                if (dctx->remaining <= 0) {\n\n                    dctx->remaining = ff_dnxhd_get_hr_frame_size(cid, dctx->w, dctx->h);\n\n                    if (dctx->remaining <= 0)\n\n                        return dctx->remaining;\n\n                }\n\n                if (buf_size - i + 47 >= dctx->remaining) {\n\n                    int remaining = dctx->remaining;\n\n\n\n                    pc->frame_start_found = 0;\n\n                    pc->state64 = -1;\n\n                    dctx->cur_byte = 0;\n\n                    dctx->remaining = 0;\n\n                    return remaining;\n\n                } else {\n\n                    dctx->remaining -= buf_size;\n\n                }\n\n            }\n\n        }\n\n    } else if (pic_found) {\n\n        if (dctx->remaining > buf_size) {\n\n            dctx->remaining -= buf_size;\n\n        } else {\n\n            int remaining = dctx->remaining;\n\n\n\n            pc->frame_start_found = 0;\n\n            pc->state64 = -1;\n\n            dctx->cur_byte = 0;\n\n            dctx->remaining = 0;\n\n            return remaining;\n\n        }\n\n    }\n\n    pc->frame_start_found = pic_found;\n\n    pc->state64 = state;\n\n    return END_NOT_FOUND;\n\n}\n", "idx": 19728, "_split": "test", "_hash": "98ac4dc2a7e2de0a003422f0a78c1e30"}
{"project": "FFmpeg", "commit_id": "c8241e730f116f1c9cfc0b34110aa7f052e05332", "target": 0, "func": "static av_cold int vaapi_encode_h264_init_constant_bitrate(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext      *ctx = avctx->priv_data;\n\n    VAAPIEncodeH264Context *priv = ctx->priv_data;\n\n    int hrd_buffer_size;\n\n    int hrd_initial_buffer_fullness;\n\n\n\n    if (avctx->bit_rate > INT32_MAX) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Target bitrate of 2^31 bps or \"\n\n               \"higher is not supported.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (avctx->rc_buffer_size)\n\n        hrd_buffer_size = avctx->rc_buffer_size;\n\n    else\n\n        hrd_buffer_size = avctx->bit_rate;\n\n    if (avctx->rc_initial_buffer_occupancy)\n\n        hrd_initial_buffer_fullness = avctx->rc_initial_buffer_occupancy;\n\n    else\n\n        hrd_initial_buffer_fullness = hrd_buffer_size * 3 / 4;\n\n\n\n    priv->rc_params.misc.type = VAEncMiscParameterTypeRateControl;\n\n    priv->rc_params.rc = (VAEncMiscParameterRateControl) {\n\n        .bits_per_second   = avctx->bit_rate,\n\n        .target_percentage = 66,\n\n        .window_size       = 1000,\n\n        .initial_qp        = (avctx->qmax >= 0 ? avctx->qmax : 40),\n\n        .min_qp            = (avctx->qmin >= 0 ? avctx->qmin : 18),\n\n        .basic_unit_size   = 0,\n\n    };\n\n    ctx->global_params[ctx->nb_global_params] =\n\n        &priv->rc_params.misc;\n\n    ctx->global_params_size[ctx->nb_global_params++] =\n\n        sizeof(priv->rc_params);\n\n\n\n    priv->hrd_params.misc.type = VAEncMiscParameterTypeHRD;\n\n    priv->hrd_params.hrd = (VAEncMiscParameterHRD) {\n\n        .initial_buffer_fullness = hrd_initial_buffer_fullness,\n\n        .buffer_size             = hrd_buffer_size,\n\n    };\n\n    ctx->global_params[ctx->nb_global_params] =\n\n        &priv->hrd_params.misc;\n\n    ctx->global_params_size[ctx->nb_global_params++] =\n\n        sizeof(priv->hrd_params);\n\n\n\n    // These still need to be  set for pic_init_qp/slice_qp_delta.\n\n    priv->fixed_qp_idr = 26;\n\n    priv->fixed_qp_p   = 26;\n\n    priv->fixed_qp_b   = 26;\n\n\n\n    av_log(avctx, AV_LOG_DEBUG, \"Using constant-bitrate = %\"PRId64\" bps.\\n\",\n\n           avctx->bit_rate);\n\n    return 0;\n\n}\n", "idx": 19759, "_split": "test", "_hash": "657f5ed869b0cfd047b0ff95974c5a85"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void RENAME(planar2x)(const uint8_t *src, uint8_t *dst, long srcWidth, long srcHeight, long srcStride, long dstStride)\n\n{\n\n\tlong x,y;\n\n\n\n\tdst[0]= src[0];\n\n\n\n\t// first line\n\n\tfor(x=0; x<srcWidth-1; x++){\n\n\t\tdst[2*x+1]= (3*src[x] +   src[x+1])>>2;\n\n\t\tdst[2*x+2]= (  src[x] + 3*src[x+1])>>2;\n\n\t}\n\n\tdst[2*srcWidth-1]= src[srcWidth-1];\n\n\n\n        dst+= dstStride;\n\n\n\n\tfor(y=1; y<srcHeight; y++){\n\n#if defined (HAVE_MMX2) || defined (HAVE_3DNOW)\n\n\t\tconst long mmxSize= srcWidth&~15;\n\n\t\tasm volatile(\n\n\t\t\t\"mov %4, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movq (%0, %%\"REG_a\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movq (%1, %%\"REG_a\"), %%mm1\t\\n\\t\"\n\n\t\t\t\"movq 1(%0, %%\"REG_a\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"movq 1(%1, %%\"REG_a\"), %%mm3\t\\n\\t\"\n\n\t\t\t\"movq -1(%0, %%\"REG_a\"), %%mm4\t\\n\\t\"\n\n\t\t\t\"movq -1(%1, %%\"REG_a\"), %%mm5\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm5\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm3\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm5\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm0, %%mm3\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm2\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\tPAVGB\" %%mm1, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm5, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq %%mm4, %%mm6\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm3, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"punpckhbw %%mm3, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm2, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"punpckhbw %%mm2, %%mm6\t\t\\n\\t\"\n\n#if 1\n\n\t\t\tMOVNTQ\" %%mm5, (%2, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm7, 8(%2, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm4, (%3, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\tMOVNTQ\" %%mm6, 8(%3, %%\"REG_a\", 2)\\n\\t\"\n\n#else\n\n\t\t\t\"movq %%mm5, (%2, %%\"REG_a\", 2)\t\\n\\t\"\n\n\t\t\t\"movq %%mm7, 8(%2, %%\"REG_a\", 2)\\n\\t\"\n\n\t\t\t\"movq %%mm4, (%3, %%\"REG_a\", 2)\t\\n\\t\"\n\n\t\t\t\"movq %%mm6, 8(%3, %%\"REG_a\", 2)\\n\\t\"\n\n#endif\n\n\t\t\t\"add $8, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\" js 1b\t\t\t\t\\n\\t\"\n\n\t\t\t:: \"r\" (src + mmxSize  ), \"r\" (src + srcStride + mmxSize  ),\n\n\t\t\t   \"r\" (dst + mmxSize*2), \"r\" (dst + dstStride + mmxSize*2),\n\n\t\t\t   \"g\" (-mmxSize)\n\n\t\t\t: \"%\"REG_a\n\n\n\n\t\t);\n\n#else\n\n\t\tconst long mmxSize=1;\n\n#endif\n\n\t\tdst[0        ]= (3*src[0] +   src[srcStride])>>2;\n\n\t\tdst[dstStride]= (  src[0] + 3*src[srcStride])>>2;\n\n\n\n\t\tfor(x=mmxSize-1; x<srcWidth-1; x++){\n\n\t\t\tdst[2*x          +1]= (3*src[x+0] +   src[x+srcStride+1])>>2;\n\n\t\t\tdst[2*x+dstStride+2]= (  src[x+0] + 3*src[x+srcStride+1])>>2;\n\n\t\t\tdst[2*x+dstStride+1]= (  src[x+1] + 3*src[x+srcStride  ])>>2;\n\n\t\t\tdst[2*x          +2]= (3*src[x+1] +   src[x+srcStride  ])>>2;\n\n\t\t}\n\n\t\tdst[srcWidth*2 -1            ]= (3*src[srcWidth-1] +   src[srcWidth-1 + srcStride])>>2;\n\n\t\tdst[srcWidth*2 -1 + dstStride]= (  src[srcWidth-1] + 3*src[srcWidth-1 + srcStride])>>2;\n\n\n\n\t\tdst+=dstStride*2;\n\n\t\tsrc+=srcStride;\n\n\t}\n\n\n\n\t// last line\n\n#if 1\n\n\tdst[0]= src[0];\n\n\n\n\tfor(x=0; x<srcWidth-1; x++){\n\n\t\tdst[2*x+1]= (3*src[x] +   src[x+1])>>2;\n\n\t\tdst[2*x+2]= (  src[x] + 3*src[x+1])>>2;\n\n\t}\n\n\tdst[2*srcWidth-1]= src[srcWidth-1];\n\n#else\n\n\tfor(x=0; x<srcWidth; x++){\n\n\t\tdst[2*x+0]=\n\n\t\tdst[2*x+1]= src[x];\n\n\t}\n\n#endif\n\n\n\n#ifdef HAVE_MMX\n\nasm volatile(   EMMS\" \\n\\t\"\n\n        \tSFENCE\" \\n\\t\"\n\n        \t:::\"memory\");\n\n#endif\n\n}\n", "idx": 19782, "_split": "test", "_hash": "31e0307e5df02dcb9aefda6df32a59b8"}
{"project": "FFmpeg", "commit_id": "2162b862eba5aadb59c0cf7cc304c67f4a5fb946", "target": 1, "func": "static int huff_build10(VLC *vlc, uint8_t *len)\n\n{\n\n    HuffEntry he[1024];\n\n    uint32_t codes[1024];\n\n    uint8_t bits[1024];\n\n    uint16_t syms[1024];\n\n    uint32_t code;\n\n    int i;\n\n\n\n    for (i = 0; i < 1024; i++) {\n\n        he[i].sym = 1023 - i;\n\n        he[i].len = len[i];\n\n\n\n    }\n\n    AV_QSORT(he, 1024, HuffEntry, huff_cmp_len10);\n\n\n\n    code = 1;\n\n    for (i = 1023; i >= 0; i--) {\n\n        codes[i] = code >> (32 - he[i].len);\n\n        bits[i]  = he[i].len;\n\n        syms[i]  = he[i].sym;\n\n        code += 0x80000000u >> (he[i].len - 1);\n\n    }\n\n\n\n    ff_free_vlc(vlc);\n\n    return ff_init_vlc_sparse(vlc, FFMIN(he[1023].len, 12), 1024,\n\n                              bits,  sizeof(*bits),  sizeof(*bits),\n\n                              codes, sizeof(*codes), sizeof(*codes),\n\n                              syms,  sizeof(*syms),  sizeof(*syms), 0);\n\n}", "idx": 19827, "_split": "test", "_hash": "77f12f06cd5193b854dd763afec23016"}
{"project": "FFmpeg", "commit_id": "465e1dadbef7596a3eb87089a66bb4ecdc26d3c4", "target": 0, "func": "static int nut_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    NUTContext *nut = s->priv_data;\n\n    ByteIOContext *bc = &s->pb;\n\n    int64_t pos;\n\n    int inited_stream_count;\n\n\n\n    nut->avf= s;\n\n    \n\n    av_set_pts_info(s, 60, 1, AV_TIME_BASE);\n\n\n\n    /* main header */\n\n    pos=0;\n\n    for(;;){\n\n        if (find_startcode(bc, MAIN_STARTCODE, pos)<0){\n\n            av_log(s, AV_LOG_ERROR, \"no main startcode found\\n\");\n\n            return -1;\n\n        }\n\n        pos= url_ftell(bc);\n\n        if(decode_main_header(nut) >= 0)\n\n            break;\n\n    }\n\n    \n\n    \n\n    s->bit_rate = 0;\n\n\n\n    nut->stream = av_malloc(sizeof(StreamContext)*nut->stream_count);\n\n\n\n    /* stream headers */\n\n    pos=0;\n\n    for(inited_stream_count=0; inited_stream_count < nut->stream_count;){\n\n        if (find_startcode(bc, STREAM_STARTCODE, pos)<0){\n\n            av_log(s, AV_LOG_ERROR, \"not all stream headers found\\n\");\n\n            return -1;\n\n        }\n\n        pos= url_ftell(bc);\n\n        if(decode_stream_header(nut) >= 0)\n\n            inited_stream_count++;\n\n    }\n\n\n\n    /* info headers */\n\n    pos=0;\n\n    for(;;){\n\n        uint64_t startcode= find_any_startcode(bc, pos);\n\n        pos= url_ftell(bc);\n\n\n\n        if(startcode==0){\n\n            av_log(s, AV_LOG_ERROR, \"EOF before video frames\\n\");\n\n            return -1;\n\n        }else if(startcode == KEYFRAME_STARTCODE){\n\n            url_fseek(bc, -8, SEEK_CUR); //FIXME\n\n            break;\n\n        }else if(startcode != INFO_STARTCODE){\n\n            continue;\n\n        }\n\n\n\n        decode_info_header(nut);\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 19886, "_split": "test", "_hash": "0f2d70d10ffb97e57b4bedf735d4e218"}
{"project": "FFmpeg", "commit_id": "a0c624e299730c8c5800375c2f5f3c6c200053ff", "target": 1, "func": "int ff_v4l2_m2m_codec_reinit(V4L2m2mContext* s)\n\n{\n\n    int ret;\n\n\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"reinit context\\n\");\n\n\n\n    /* 1. streamoff */\n\n    ret = ff_v4l2_context_set_status(&s->capture, VIDIOC_STREAMOFF);\n\n    if (ret)\n\n        av_log(s->avctx, AV_LOG_ERROR, \"capture VIDIOC_STREAMOFF\\n\");\n\n\n\n    /* 2. unmap the capture buffers (v4l2 and ffmpeg):\n\n     *    we must wait for all references to be released before being allowed\n\n     *    to queue new buffers.\n\n     */\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"waiting for user to release AVBufferRefs\\n\");\n\n    if (atomic_load(&s->refcount))\n\n        while(sem_wait(&s->refsync) == -1 && errno == EINTR);\n\n\n\n    ff_v4l2_context_release(&s->capture);\n\n\n\n    /* 3. get the new capture format */\n\n    ret = ff_v4l2_context_get_format(&s->capture);\n\n    if (ret) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"query the new capture format\\n\");\n\n        return ret;\n\n    }\n\n\n\n    /* 4. set the capture format */\n\n    ret = ff_v4l2_context_set_format(&s->capture);\n\n    if (ret) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"setting capture format\\n\");\n\n        return ret;\n\n    }\n\n\n\n    /* 5. complete reinit */\n\n    sem_destroy(&s->refsync);\n\n    sem_init(&s->refsync, 0, 0);\n\n    s->draining = 0;\n\n    s->reinit = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 19889, "_split": "test", "_hash": "20df1093f969d8bb02aea604e17fbf64"}
{"project": "FFmpeg", "commit_id": "e3123856c79c36507772ada1bcda6cfe36a1e297", "target": 1, "func": "static int wsvqa_read_header(AVFormatContext *s,\n\n                             AVFormatParameters *ap)\n\n{\n\n    WsVqaDemuxContext *wsvqa = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    unsigned char *header;\n\n    unsigned char scratch[VQA_PREAMBLE_SIZE];\n\n    unsigned int chunk_tag;\n\n    unsigned int chunk_size;\n\n\n\n    /* initialize the video decoder stream */\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n    av_set_pts_info(st, 33, 1, VQA_FRAMERATE);\n\n    wsvqa->video_stream_index = st->index;\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = CODEC_ID_WS_VQA;\n\n    st->codec->codec_tag = 0;  /* no fourcc */\n\n\n\n    /* skip to the start of the VQA header */\n\n    avio_seek(pb, 20, SEEK_SET);\n\n\n\n    /* the VQA header needs to go to the decoder */\n\n    st->codec->extradata_size = VQA_HEADER_SIZE;\n\n    st->codec->extradata = av_mallocz(VQA_HEADER_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    header = (unsigned char *)st->codec->extradata;\n\n    if (avio_read(pb, st->codec->extradata, VQA_HEADER_SIZE) !=\n\n        VQA_HEADER_SIZE) {\n\n        av_free(st->codec->extradata);\n\n        return AVERROR(EIO);\n\n    }\n\n    st->codec->width = AV_RL16(&header[6]);\n\n    st->codec->height = AV_RL16(&header[8]);\n\n\n\n    /* initialize the audio decoder stream for VQA v1 or nonzero samplerate */\n\n    if (AV_RL16(&header[24]) || (AV_RL16(&header[0]) == 1 && AV_RL16(&header[2]) == 1)) {\n\n        st = av_new_stream(s, 0);\n\n        if (!st)\n\n            return AVERROR(ENOMEM);\n\n        av_set_pts_info(st, 33, 1, VQA_FRAMERATE);\n\n        st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n        if (AV_RL16(&header[0]) == 1)\n\n            st->codec->codec_id = CODEC_ID_WESTWOOD_SND1;\n\n        else\n\n            st->codec->codec_id = CODEC_ID_ADPCM_IMA_WS;\n\n        st->codec->codec_tag = 0;  /* no tag */\n\n        st->codec->sample_rate = AV_RL16(&header[24]);\n\n        if (!st->codec->sample_rate)\n\n            st->codec->sample_rate = 22050;\n\n        st->codec->channels = header[26];\n\n        if (!st->codec->channels)\n\n            st->codec->channels = 1;\n\n        st->codec->bits_per_coded_sample = 16;\n\n        st->codec->bit_rate = st->codec->channels * st->codec->sample_rate *\n\n            st->codec->bits_per_coded_sample / 4;\n\n        st->codec->block_align = st->codec->channels * st->codec->bits_per_coded_sample;\n\n\n\n        wsvqa->audio_stream_index = st->index;\n\n        wsvqa->audio_samplerate = st->codec->sample_rate;\n\n        wsvqa->audio_channels = st->codec->channels;\n\n        wsvqa->audio_frame_counter = 0;\n\n    }\n\n\n\n    /* there are 0 or more chunks before the FINF chunk; iterate until\n\n     * FINF has been skipped and the file will be ready to be demuxed */\n\n    do {\n\n        if (avio_read(pb, scratch, VQA_PREAMBLE_SIZE) != VQA_PREAMBLE_SIZE) {\n\n            av_free(st->codec->extradata);\n\n            return AVERROR(EIO);\n\n        }\n\n        chunk_tag = AV_RB32(&scratch[0]);\n\n        chunk_size = AV_RB32(&scratch[4]);\n\n\n\n        /* catch any unknown header tags, for curiousity */\n\n        switch (chunk_tag) {\n\n        case CINF_TAG:\n\n        case CINH_TAG:\n\n        case CIND_TAG:\n\n        case PINF_TAG:\n\n        case PINH_TAG:\n\n        case PIND_TAG:\n\n        case FINF_TAG:\n\n        case CMDS_TAG:\n\n            break;\n\n\n\n        default:\n\n            av_log (s, AV_LOG_ERROR, \" note: unknown chunk seen (%c%c%c%c)\\n\",\n\n                scratch[0], scratch[1],\n\n                scratch[2], scratch[3]);\n\n            break;\n\n        }\n\n\n\n        avio_skip(pb, chunk_size);\n\n    } while (chunk_tag != FINF_TAG);\n\n\n\n    return 0;\n\n}\n", "idx": 19892, "_split": "test", "_hash": "e5cbb6787e494af27c6b4d1396db036a"}
{"project": "FFmpeg", "commit_id": "984add64a41c3296a8a82051cc90bff2eb449609", "target": 1, "func": "int ff_wma_init(AVCodecContext *avctx, int flags2)\n\n{\n\n    WMACodecContext *s = avctx->priv_data;\n\n    int i;\n\n    float bps1, high_freq;\n\n    volatile float bps;\n\n    int sample_rate1;\n\n    int coef_vlc_table;\n\n\n\n    if (   avctx->sample_rate <= 0 || avctx->sample_rate > 50000\n\n        || avctx->channels    <= 0 || avctx->channels    > 2\n\n        || avctx->bit_rate    <= 0)\n\n        return -1;\n\n\n\n    ff_fmt_convert_init(&s->fmt_conv, avctx);\n\n    avpriv_float_dsp_init(&s->fdsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n\n\n    if (avctx->codec->id == AV_CODEC_ID_WMAV1) {\n\n        s->version = 1;\n\n    } else {\n\n        s->version = 2;\n\n\n\n\n    /* compute MDCT block size */\n\n    s->frame_len_bits = ff_wma_get_frame_len_bits(avctx->sample_rate,\n\n                                                  s->version, 0);\n\n    s->next_block_len_bits = s->frame_len_bits;\n\n    s->prev_block_len_bits = s->frame_len_bits;\n\n    s->block_len_bits      = s->frame_len_bits;\n\n\n\n    s->frame_len = 1 << s->frame_len_bits;\n\n    if (s->use_variable_block_len) {\n\n        int nb_max, nb;\n\n        nb = ((flags2 >> 3) & 3) + 1;\n\n        if ((avctx->bit_rate / avctx->channels) >= 32000)\n\n            nb += 2;\n\n        nb_max = s->frame_len_bits - BLOCK_MIN_BITS;\n\n        if (nb > nb_max)\n\n            nb = nb_max;\n\n        s->nb_block_sizes = nb + 1;\n\n    } else {\n\n        s->nb_block_sizes = 1;\n\n\n\n\n    /* init rate dependent parameters */\n\n    s->use_noise_coding = 1;\n\n    high_freq = avctx->sample_rate * 0.5;\n\n\n\n    /* if version 2, then the rates are normalized */\n\n    sample_rate1 = avctx->sample_rate;\n\n    if (s->version == 2) {\n\n        if (sample_rate1 >= 44100) {\n\n            sample_rate1 = 44100;\n\n        } else if (sample_rate1 >= 22050) {\n\n            sample_rate1 = 22050;\n\n        } else if (sample_rate1 >= 16000) {\n\n            sample_rate1 = 16000;\n\n        } else if (sample_rate1 >= 11025) {\n\n            sample_rate1 = 11025;\n\n        } else if (sample_rate1 >= 8000) {\n\n            sample_rate1 = 8000;\n\n\n\n\n\n    bps = (float)avctx->bit_rate / (float)(avctx->channels * avctx->sample_rate);\n\n    s->byte_offset_bits = av_log2((int)(bps * s->frame_len / 8.0 + 0.5)) + 2;\n\n\n\n\n\n\n\n    /* compute high frequency value and choose if noise coding should\n\n       be activated */\n\n    bps1 = bps;\n\n    if (avctx->channels == 2)\n\n        bps1 = bps * 1.6;\n\n    if (sample_rate1 == 44100) {\n\n        if (bps1 >= 0.61) {\n\n            s->use_noise_coding = 0;\n\n        } else {\n\n            high_freq = high_freq * 0.4;\n\n\n    } else if (sample_rate1 == 22050) {\n\n        if (bps1 >= 1.16) {\n\n            s->use_noise_coding = 0;\n\n        } else if (bps1 >= 0.72) {\n\n            high_freq = high_freq * 0.7;\n\n        } else {\n\n            high_freq = high_freq * 0.6;\n\n\n    } else if (sample_rate1 == 16000) {\n\n        if (bps > 0.5) {\n\n            high_freq = high_freq * 0.5;\n\n        } else {\n\n            high_freq = high_freq * 0.3;\n\n\n    } else if (sample_rate1 == 11025) {\n\n        high_freq = high_freq * 0.7;\n\n    } else if (sample_rate1 == 8000) {\n\n        if (bps <= 0.625) {\n\n            high_freq = high_freq * 0.5;\n\n        } else if (bps > 0.75) {\n\n            s->use_noise_coding = 0;\n\n        } else {\n\n            high_freq = high_freq * 0.65;\n\n\n    } else {\n\n        if (bps >= 0.8) {\n\n            high_freq = high_freq * 0.75;\n\n        } else if (bps >= 0.6) {\n\n            high_freq = high_freq * 0.6;\n\n        } else {\n\n            high_freq = high_freq * 0.5;\n\n\n\n    av_dlog(s->avctx, \"flags2=0x%x\\n\", flags2);\n\n    av_dlog(s->avctx, \"version=%d channels=%d sample_rate=%d bitrate=%d block_align=%d\\n\",\n\n            s->version, avctx->channels, avctx->sample_rate, avctx->bit_rate,\n\n            avctx->block_align);\n\n    av_dlog(s->avctx, \"bps=%f bps1=%f high_freq=%f bitoffset=%d\\n\",\n\n            bps, bps1, high_freq, s->byte_offset_bits);\n\n    av_dlog(s->avctx, \"use_noise_coding=%d use_exp_vlc=%d nb_block_sizes=%d\\n\",\n\n            s->use_noise_coding, s->use_exp_vlc, s->nb_block_sizes);\n\n\n\n    /* compute the scale factor band sizes for each MDCT block size */\n\n    {\n\n        int a, b, pos, lpos, k, block_len, i, j, n;\n\n        const uint8_t *table;\n\n\n\n        if (s->version == 1) {\n\n            s->coefs_start = 3;\n\n        } else {\n\n            s->coefs_start = 0;\n\n\n        for (k = 0; k < s->nb_block_sizes; k++) {\n\n            block_len = s->frame_len >> k;\n\n\n\n            if (s->version == 1) {\n\n                lpos = 0;\n\n                for (i = 0; i < 25; i++) {\n\n                    a = ff_wma_critical_freqs[i];\n\n                    b = avctx->sample_rate;\n\n                    pos = ((block_len * 2 * a) + (b >> 1)) / b;\n\n                    if (pos > block_len)\n\n                        pos = block_len;\n\n                    s->exponent_bands[0][i] = pos - lpos;\n\n                    if (pos >= block_len) {\n\n                        i++;\n\n                        break;\n\n\n                    lpos = pos;\n\n\n                s->exponent_sizes[0] = i;\n\n            } else {\n\n                /* hardcoded tables */\n\n                table = NULL;\n\n                a = s->frame_len_bits - BLOCK_MIN_BITS - k;\n\n                if (a < 3) {\n\n                    if (avctx->sample_rate >= 44100) {\n\n                        table = exponent_band_44100[a];\n\n                    } else if (avctx->sample_rate >= 32000) {\n\n                        table = exponent_band_32000[a];\n\n                    } else if (avctx->sample_rate >= 22050) {\n\n                        table = exponent_band_22050[a];\n\n\n\n                if (table) {\n\n                    n = *table++;\n\n                    for (i = 0; i < n; i++)\n\n                        s->exponent_bands[k][i] = table[i];\n\n                    s->exponent_sizes[k] = n;\n\n                } else {\n\n                    j = 0;\n\n                    lpos = 0;\n\n                    for (i = 0; i < 25; i++) {\n\n                        a = ff_wma_critical_freqs[i];\n\n                        b = avctx->sample_rate;\n\n                        pos = ((block_len * 2 * a) + (b << 1)) / (4 * b);\n\n                        pos <<= 2;\n\n                        if (pos > block_len)\n\n                            pos = block_len;\n\n                        if (pos > lpos)\n\n                            s->exponent_bands[k][j++] = pos - lpos;\n\n                        if (pos >= block_len)\n\n                            break;\n\n                        lpos = pos;\n\n\n                    s->exponent_sizes[k] = j;\n\n\n\n\n\n            /* max number of coefs */\n\n            s->coefs_end[k] = (s->frame_len - ((s->frame_len * 9) / 100)) >> k;\n\n            /* high freq computation */\n\n            s->high_band_start[k] = (int)((block_len * 2 * high_freq) /\n\n                                          avctx->sample_rate + 0.5);\n\n            n = s->exponent_sizes[k];\n\n            j = 0;\n\n            pos = 0;\n\n            for (i = 0; i < n; i++) {\n\n                int start, end;\n\n                start = pos;\n\n                pos += s->exponent_bands[k][i];\n\n                end = pos;\n\n                if (start < s->high_band_start[k])\n\n                    start = s->high_band_start[k];\n\n                if (end > s->coefs_end[k])\n\n                    end = s->coefs_end[k];\n\n                if (end > start)\n\n                    s->exponent_high_bands[k][j++] = end - start;\n\n\n            s->exponent_high_sizes[k] = j;\n\n#if 0\n\n            tprintf(s->avctx, \"%5d: coefs_end=%d high_band_start=%d nb_high_bands=%d: \",\n\n                    s->frame_len >> k,\n\n                    s->coefs_end[k],\n\n                    s->high_band_start[k],\n\n                    s->exponent_high_sizes[k]);\n\n            for (j = 0; j < s->exponent_high_sizes[k]; j++)\n\n                tprintf(s->avctx, \" %d\", s->exponent_high_bands[k][j]);\n\n            tprintf(s->avctx, \"\\n\");\n\n#endif\n\n\n\n\n\n#ifdef TRACE\n\n    {\n\n        int i, j;\n\n        for (i = 0; i < s->nb_block_sizes; i++) {\n\n            tprintf(s->avctx, \"%5d: n=%2d:\",\n\n                    s->frame_len >> i,\n\n                    s->exponent_sizes[i]);\n\n            for (j = 0; j < s->exponent_sizes[i]; j++)\n\n                tprintf(s->avctx, \" %d\", s->exponent_bands[i][j]);\n\n            tprintf(s->avctx, \"\\n\");\n\n\n\n#endif\n\n\n\n    /* init MDCT windows : simple sinus window */\n\n    for (i = 0; i < s->nb_block_sizes; i++) {\n\n        ff_init_ff_sine_windows(s->frame_len_bits - i);\n\n        s->windows[i] = ff_sine_windows[s->frame_len_bits - i];\n\n\n\n\n    s->reset_block_lengths = 1;\n\n\n\n    if (s->use_noise_coding) {\n\n\n\n        /* init the noise generator */\n\n        if (s->use_exp_vlc) {\n\n            s->noise_mult = 0.02;\n\n        } else {\n\n            s->noise_mult = 0.04;\n\n\n\n\n#ifdef TRACE\n\n        for (i = 0; i < NOISE_TAB_SIZE; i++)\n\n            s->noise_table[i] = 1.0 * s->noise_mult;\n\n#else\n\n        {\n\n            unsigned int seed;\n\n            float norm;\n\n            seed = 1;\n\n            norm = (1.0 / (float)(1LL << 31)) * sqrt(3) * s->noise_mult;\n\n            for (i = 0; i < NOISE_TAB_SIZE; i++) {\n\n                seed = seed * 314159 + 1;\n\n                s->noise_table[i] = (float)((int)seed) * norm;\n\n\n\n#endif\n\n\n\n\n    /* choose the VLC tables for the coefficients */\n\n    coef_vlc_table = 2;\n\n    if (avctx->sample_rate >= 32000) {\n\n        if (bps1 < 0.72) {\n\n            coef_vlc_table = 0;\n\n        } else if (bps1 < 1.16) {\n\n            coef_vlc_table = 1;\n\n\n\n    s->coef_vlcs[0]= &coef_vlcs[coef_vlc_table * 2    ];\n\n    s->coef_vlcs[1]= &coef_vlcs[coef_vlc_table * 2 + 1];\n\n    init_coef_vlc(&s->coef_vlc[0], &s->run_table[0], &s->level_table[0], &s->int_table[0],\n\n                  s->coef_vlcs[0]);\n\n    init_coef_vlc(&s->coef_vlc[1], &s->run_table[1], &s->level_table[1], &s->int_table[1],\n\n                  s->coef_vlcs[1]);\n\n\n\n    return 0;\n", "idx": 19908, "_split": "test", "_hash": "a31faf463c8136610c3baaa0e3fbf463"}
{"project": "FFmpeg", "commit_id": "12dea8a5a15343e9c404376c40ca8a1cc9d1479e", "target": 1, "func": "av_cold int ff_ivi_decode_close(AVCodecContext *avctx)\n{\n    IVI45DecContext *ctx = avctx->priv_data;\n    ivi_free_buffers(&ctx->planes[0]);\n    if (ctx->mb_vlc.cust_tab.table)\n        ff_free_vlc(&ctx->mb_vlc.cust_tab);\n    av_frame_free(&ctx->p_frame);\n    return 0;\n}", "idx": 19912, "_split": "test", "_hash": "11c11dcdaa468502573b6635b0b64b26"}
{"project": "FFmpeg", "commit_id": "101ef19ef4dc9f5c3d536aee8fcc10fff2af4d9e", "target": 1, "func": "static void decode_block(BinkAudioContext *s, short *out, int use_dct)\n\n{\n\n    int ch, i, j, k;\n\n    float q, quant[25];\n\n    int width, coeff;\n\n    GetBitContext *gb = &s->gb;\n\n\n\n    if (use_dct)\n\n        skip_bits(gb, 2);\n\n\n\n    for (ch = 0; ch < s->channels; ch++) {\n\n        FFTSample *coeffs = s->coeffs_ptr[ch];\n\n        if (s->version_b) {\n\n            coeffs[0] = av_int2flt(get_bits(gb, 32)) * s->root;\n\n            coeffs[1] = av_int2flt(get_bits(gb, 32)) * s->root;\n\n        } else {\n\n            coeffs[0] = get_float(gb) * s->root;\n\n            coeffs[1] = get_float(gb) * s->root;\n\n        }\n\n\n\n        for (i = 0; i < s->num_bands; i++) {\n\n            /* constant is result of 0.066399999/log10(M_E) */\n\n            int value = get_bits(gb, 8);\n\n            quant[i] = expf(FFMIN(value, 95) * 0.15289164787221953823f) * s->root;\n\n        }\n\n\n\n        k = 0;\n\n        q = quant[0];\n\n\n\n        // parse coefficients\n\n        i = 2;\n\n        while (i < s->frame_len) {\n\n            if (s->version_b) {\n\n                j = i + 16;\n\n            } else if (get_bits1(gb)) {\n\n                j = i + rle_length_tab[get_bits(gb, 4)] * 8;\n\n            } else {\n\n                j = i + 8;\n\n            }\n\n\n\n            j = FFMIN(j, s->frame_len);\n\n\n\n            width = get_bits(gb, 4);\n\n            if (width == 0) {\n\n                memset(coeffs + i, 0, (j - i) * sizeof(*coeffs));\n\n                i = j;\n\n                while (s->bands[k] < i)\n\n                    q = quant[k++];\n\n            } else {\n\n                while (i < j) {\n\n                    if (s->bands[k] == i)\n\n                        q = quant[k++];\n\n                    coeff = get_bits(gb, width);\n\n                    if (coeff) {\n\n                        if (get_bits1(gb))\n\n                            coeffs[i] = -q * coeff;\n\n                        else\n\n                            coeffs[i] =  q * coeff;\n\n                    } else {\n\n                        coeffs[i] = 0.0f;\n\n                    }\n\n                    i++;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (CONFIG_BINKAUDIO_DCT_DECODER && use_dct) {\n\n            coeffs[0] /= 0.5;\n\n            s->trans.dct.dct_calc(&s->trans.dct,  coeffs);\n\n            s->dsp.vector_fmul_scalar(coeffs, coeffs, s->frame_len / 2, s->frame_len);\n\n        }\n\n        else if (CONFIG_BINKAUDIO_RDFT_DECODER)\n\n            s->trans.rdft.rdft_calc(&s->trans.rdft, coeffs);\n\n    }\n\n\n\n    s->fmt_conv.float_to_int16_interleave(out, (const float **)s->coeffs_ptr,\n\n                                          s->frame_len, s->channels);\n\n\n\n    if (!s->first) {\n\n        int count = s->overlap_len * s->channels;\n\n        int shift = av_log2(count);\n\n        for (i = 0; i < count; i++) {\n\n            out[i] = (s->previous[i] * (count - i) + out[i] * i) >> shift;\n\n        }\n\n    }\n\n\n\n    memcpy(s->previous, out + s->block_size,\n\n           s->overlap_len * s->channels * sizeof(*out));\n\n\n\n    s->first = 0;\n\n}\n", "idx": 19965, "_split": "test", "_hash": "3276eb7ad57af9904a85de622514e8aa"}
{"project": "FFmpeg", "commit_id": "0dbb48d91e9e97c7eb11f4ebc03c4ff4b6f5b692", "target": 1, "func": "static int mpeg_mux_write_packet(AVFormatContext *ctx, int stream_index,\n\n                                 const uint8_t *buf, int size, int64_t pts)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    AVStream *st = ctx->streams[stream_index];\n\n    StreamInfo *stream = st->priv_data;\n\n    int64_t dts;\n\n    int len;\n\n\n\n    /* XXX: system clock should be computed precisely, especially for\n\n       CBR case. The current mode gives at least something coherent */\n\n    if (stream_index == s->scr_stream_index)\n\n        s->last_scr = pts;\n\n    \n\n#if 0\n\n    printf(\"%d: pts=%0.3f scr=%0.3f\\n\", \n\n           stream_index, pts / 90000.0, s->last_scr / 90000.0);\n\n#endif\n\n    \n\n    /* XXX: currently no way to pass dts, will change soon */\n\n    dts = AV_NOPTS_VALUE;\n\n\n\n    /* we assume here that pts != AV_NOPTS_VALUE */\n\n    if (stream->start_pts == AV_NOPTS_VALUE) {\n\n        stream->start_pts = pts;\n\n        stream->start_dts = dts;\n\n    }\n\n    while (size > 0) {\n\n        len = s->packet_data_max_size - stream->buffer_ptr;\n\n        if (len > size)\n\n            len = size;\n\n        memcpy(stream->buffer + stream->buffer_ptr, buf, len);\n\n        stream->buffer_ptr += len;\n\n        buf += len;\n\n        size -= len;\n\n        while (stream->buffer_ptr >= s->packet_data_max_size) {\n\n            /* output the packet */\n\n            flush_packet(ctx, stream_index,\n\n                         stream->start_pts, stream->start_dts, s->last_scr);\n\n            /* Make sure only the FIRST pes packet for this frame has\n\n               a timestamp */\n\n            stream->start_pts = AV_NOPTS_VALUE;\n\n            stream->start_dts = AV_NOPTS_VALUE;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 19976, "_split": "test", "_hash": "76b0bdb47fe74d6d7918e016cf1949e5"}
{"project": "FFmpeg", "commit_id": "4b1f5e5090abed6c618c8ba380cd7d28d140f867", "target": 0, "func": "av_cold void avcodec_register(AVCodec *codec)\n\n{\n\n    AVCodec **p;\n\n    avcodec_init();\n\n    p = &first_avcodec;\n\n    while (*p != NULL)\n\n        p = &(*p)->next;\n\n    *p          = codec;\n\n    codec->next = NULL;\n\n\n\n    if (codec->init_static_data)\n\n        codec->init_static_data(codec);\n\n}\n", "idx": 19998, "_split": "test", "_hash": "2182c3f17e0d37b0d8506fae31b42f25"}
{"project": "FFmpeg", "commit_id": "bf2bc926f04dcdde0a22c137d08a0bb546e0179e", "target": 1, "func": "static int decode_i_picture_header(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    int pqindex, status = 0;\n\n\n\n    /* Prolog common to all frametypes should be done in caller */\n\n    //BF = Buffer Fullness\n\n    if (v->profile <= PROFILE_MAIN && get_bits(gb, 7))\n\n    {\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"I BufferFullness not 0\\n\");\n\n    }\n\n\n\n    /* Quantizer stuff */\n\n    pqindex = get_bits(gb, 5);\n\n    if (v->quantizer_mode == QUANT_FRAME_IMPLICIT)\n\n        v->pq = pquant_table[0][pqindex];\n\n    else\n\n    {\n\n        v->pq = pquant_table[v->quantizer_mode-1][pqindex];\n\n    }\n\n    if (pqindex < 9) v->halfpq = get_bits(gb, 1);\n\n    if (v->quantizer_mode == QUANT_FRAME_EXPLICIT)\n\n        v->pquantizer = get_bits(gb, 1);\n\n    av_log(v->s.avctx, AV_LOG_DEBUG, \"I frame: QP=%i (+%i/2)\\n\",\n\n           v->pq, v->halfpq);\n\n#if HAS_ADVANCED_PROFILE\n\n    if (v->profile <= PROFILE_MAIN)\n\n#endif\n\n    {\n\n        if (v->extended_mv) v->mvrange = get_prefix(gb, 0, 3);\n\n        if (v->multires) v->respic = get_bits(gb, 2);\n\n    }\n\n#if HAS_ADVANCED_PROFILE\n\n    else\n\n    {\n\n        v->s.ac_pred = get_bits(gb, 1);\n\n        if (v->postprocflag) v->postproc = get_bits(gb, 1);\n\n        /* 7.1.1.34 + 8.5.2 */\n\n        if (v->overlap && v->pq<9)\n\n        {\n\n            v->condover = get_bits(gb, 1);\n\n            if (v->condover)\n\n            {\n\n                v->condover = 2+get_bits(gb, 1);\n\n                if (v->condover == 3)\n\n                {\n\n                    status = bitplane_decoding(&v->over_flags_plane, v);\n\n                    if (status < 0) return -1;\n\n#if TRACE\n\n                    av_log(v->s.avctx, AV_LOG_DEBUG, \"Overflags plane encoding: \"\n\n                           \"Imode: %i, Invert: %i\\n\", status>>1, status&1);\n\n#endif\n\n                }\n\n            }\n\n        }\n\n    }\n\n#endif\n\n\n\n    /* Epilog (AC/DC syntax) should be done in caller */\n\n    return status;\n\n}\n", "idx": 20000, "_split": "test", "_hash": "6b759bdbeaca3bed04774af1b1f24106"}
{"project": "FFmpeg", "commit_id": "3a8c95f730732b9f1ffacdbfbf79a01b202a67af", "target": 0, "func": "static void show_stream(AVFormatContext *fmt_ctx, int stream_idx)\n\n{\n\n    AVStream *stream = fmt_ctx->streams[stream_idx];\n\n    AVCodecContext *dec_ctx;\n\n    AVCodec *dec;\n\n    char val_str[128];\n\n    AVDictionaryEntry *tag = NULL;\n\n    AVRational display_aspect_ratio;\n\n\n\n    printf(\"[STREAM]\\n\");\n\n\n\n    printf(\"index=%d\\n\", stream->index);\n\n\n\n    if ((dec_ctx = stream->codec)) {\n\n        if ((dec = dec_ctx->codec)) {\n\n            printf(\"codec_name=%s\\n\", dec->name);\n\n            printf(\"codec_long_name=%s\\n\", dec->long_name);\n\n        } else {\n\n            printf(\"codec_name=unknown\\n\");\n\n        }\n\n\n\n        printf(\"codec_type=%s\\n\", media_type_string(dec_ctx->codec_type));\n\n        printf(\"codec_time_base=%d/%d\\n\",\n\n               dec_ctx->time_base.num, dec_ctx->time_base.den);\n\n\n\n        /* print AVI/FourCC tag */\n\n        av_get_codec_tag_string(val_str, sizeof(val_str), dec_ctx->codec_tag);\n\n        printf(\"codec_tag_string=%s\\n\", val_str);\n\n        printf(\"codec_tag=0x%04x\\n\", dec_ctx->codec_tag);\n\n\n\n        switch (dec_ctx->codec_type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            printf(\"width=%d\\n\", dec_ctx->width);\n\n            printf(\"height=%d\\n\", dec_ctx->height);\n\n            printf(\"has_b_frames=%d\\n\", dec_ctx->has_b_frames);\n\n            if (dec_ctx->sample_aspect_ratio.num) {\n\n                printf(\"sample_aspect_ratio=%d:%d\\n\",\n\n                       dec_ctx->sample_aspect_ratio.num,\n\n                       dec_ctx->sample_aspect_ratio.den);\n\n                av_reduce(&display_aspect_ratio.num, &display_aspect_ratio.den,\n\n                          dec_ctx->width  * dec_ctx->sample_aspect_ratio.num,\n\n                          dec_ctx->height * dec_ctx->sample_aspect_ratio.den,\n\n                          1024*1024);\n\n                printf(\"display_aspect_ratio=%d:%d\\n\",\n\n                       display_aspect_ratio.num, display_aspect_ratio.den);\n\n            }\n\n            printf(\"pix_fmt=%s\\n\",\n\n                   dec_ctx->pix_fmt != PIX_FMT_NONE ? av_pix_fmt_descriptors[dec_ctx->pix_fmt].name\n\n                                                    : \"unknown\");\n\n            printf(\"level=%d\\n\", dec_ctx->level);\n\n            break;\n\n\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            printf(\"sample_rate=%s\\n\", value_string(val_str, sizeof(val_str),\n\n                                                    dec_ctx->sample_rate,\n\n                                                    unit_hertz_str));\n\n            printf(\"channels=%d\\n\", dec_ctx->channels);\n\n            printf(\"bits_per_sample=%d\\n\",\n\n                   av_get_bits_per_sample(dec_ctx->codec_id));\n\n            break;\n\n        }\n\n    } else {\n\n        printf(\"codec_type=unknown\\n\");\n\n    }\n\n\n\n    if (fmt_ctx->iformat->flags & AVFMT_SHOW_IDS)\n\n        printf(\"id=0x%x\\n\", stream->id);\n\n    printf(\"r_frame_rate=%d/%d\\n\",\n\n           stream->r_frame_rate.num, stream->r_frame_rate.den);\n\n    printf(\"avg_frame_rate=%d/%d\\n\",\n\n           stream->avg_frame_rate.num, stream->avg_frame_rate.den);\n\n    printf(\"time_base=%d/%d\\n\",\n\n           stream->time_base.num, stream->time_base.den);\n\n    printf(\"start_time=%s\\n\",\n\n           time_value_string(val_str, sizeof(val_str),\n\n                             stream->start_time, &stream->time_base));\n\n    printf(\"duration=%s\\n\",\n\n           time_value_string(val_str, sizeof(val_str),\n\n                             stream->duration, &stream->time_base));\n\n    if (stream->nb_frames)\n\n        printf(\"nb_frames=%\"PRId64\"\\n\", stream->nb_frames);\n\n\n\n    while ((tag = av_dict_get(stream->metadata, \"\", tag,\n\n                              AV_DICT_IGNORE_SUFFIX)))\n\n        printf(\"TAG:%s=%s\\n\", tag->key, tag->value);\n\n\n\n    printf(\"[/STREAM]\\n\");\n\n}\n", "idx": 20005, "_split": "test", "_hash": "a9f263825b343dfbf2e15f2265acda44"}
{"project": "FFmpeg", "commit_id": "3e1507a9547ac09b6ff4372123cde09f19218f3d", "target": 0, "func": "static void encode_block(MpegEncContext *s, int16_t *block, int n)\n\n{\n\n    int i, j, table_id;\n\n    int component, dc, last_index, val, run;\n\n    MJpegContext *m = s->mjpeg_ctx;\n\n\n\n    /* DC coef */\n\n    component = (n <= 3 ? 0 : (n&1) + 1);\n\n    table_id = (n <= 3 ? 0 : 1);\n\n    dc = block[0]; /* overflow is impossible */\n\n    val = dc - s->last_dc[component];\n\n\n\n    ff_mjpeg_encode_coef(m, table_id, val, 0);\n\n\n\n    s->last_dc[component] = dc;\n\n\n\n    /* AC coefs */\n\n\n\n    run = 0;\n\n    last_index = s->block_last_index[n];\n\n    table_id |= 2;\n\n\n\n    for(i=1;i<=last_index;i++) {\n\n        j = s->intra_scantable.permutated[i];\n\n        val = block[j];\n\n\n\n        if (val == 0) {\n\n            run++;\n\n        } else {\n\n            while (run >= 16) {\n\n                ff_mjpeg_encode_code(m, table_id, 0xf0);\n\n                run -= 16;\n\n            }\n\n            ff_mjpeg_encode_coef(m, table_id, val, run);\n\n            run = 0;\n\n        }\n\n    }\n\n\n\n    /* output EOB only if not already 64 values */\n\n    if (last_index < 63 || run != 0)\n\n        ff_mjpeg_encode_code(m, table_id, 0);\n\n}\n", "idx": 20019, "_split": "test", "_hash": "0fc010e0a44a27e4131e7fe723d55704"}
{"project": "FFmpeg", "commit_id": "6ff0ad6bfd0f00a3d54705811ee91a7ce3c22cda", "target": 0, "func": "static void RENAME(swScale)(SwsContext *c, uint8_t* srcParam[], int srcStrideParam[], int srcSliceY,\n\n             int srcSliceH, uint8_t* dstParam[], int dstStride[]){\n\n\n\n\t/* load a few things into local vars to make the code more readable? and faster */\n\n\tconst int srcW= c->srcW;\n\n\tconst int dstW= c->dstW;\n\n\tconst int dstH= c->dstH;\n\n\tconst int chrDstW= c->chrDstW;\n\n\tconst int lumXInc= c->lumXInc;\n\n\tconst int chrXInc= c->chrXInc;\n\n\tconst int dstFormat= c->dstFormat;\n\n\tconst int flags= c->flags;\n\n\tconst int canMMX2BeUsed= c->canMMX2BeUsed;\n\n\tint16_t *vLumFilterPos= c->vLumFilterPos;\n\n\tint16_t *vChrFilterPos= c->vChrFilterPos;\n\n\tint16_t *hLumFilterPos= c->hLumFilterPos;\n\n\tint16_t *hChrFilterPos= c->hChrFilterPos;\n\n\tint16_t *vLumFilter= c->vLumFilter;\n\n\tint16_t *vChrFilter= c->vChrFilter;\n\n\tint16_t *hLumFilter= c->hLumFilter;\n\n\tint16_t *hChrFilter= c->hChrFilter;\n\n\tint16_t *lumMmxFilter= c->lumMmxFilter;\n\n\tint16_t *chrMmxFilter= c->chrMmxFilter;\n\n\tconst int vLumFilterSize= c->vLumFilterSize;\n\n\tconst int vChrFilterSize= c->vChrFilterSize;\n\n\tconst int hLumFilterSize= c->hLumFilterSize;\n\n\tconst int hChrFilterSize= c->hChrFilterSize;\n\n\tint16_t **lumPixBuf= c->lumPixBuf;\n\n\tint16_t **chrPixBuf= c->chrPixBuf;\n\n\tconst int vLumBufSize= c->vLumBufSize;\n\n\tconst int vChrBufSize= c->vChrBufSize;\n\n\tuint8_t *funnyYCode= c->funnyYCode;\n\n\tuint8_t *funnyUVCode= c->funnyUVCode;\n\n\tuint8_t *formatConvBuffer= c->formatConvBuffer;\n\n\n\n\t/* vars whch will change and which we need to storw back in the context */\n\n\tint dstY= c->dstY;\n\n\tint lumBufIndex= c->lumBufIndex;\n\n\tint chrBufIndex= c->chrBufIndex;\n\n\tint lastInLumBuf= c->lastInLumBuf;\n\n\tint lastInChrBuf= c->lastInChrBuf;\n\n\tint srcStride[3];\n\n\tuint8_t *src[3];\n\n\tuint8_t *dst[3];\n\n\t\n\n\tif((c->srcFormat == IMGFMT_IYUV) || (c->srcFormat == IMGFMT_I420)){\n\n\t\tsrc[0]= srcParam[0];\n\n\t\tsrc[1]= srcParam[2];\n\n\t\tsrc[2]= srcParam[1];\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]= srcStrideParam[2];\n\n\t\tsrcStride[2]= srcStrideParam[1];\n\n\t}\n\n\telse if(c->srcFormat==IMGFMT_YV12){\n\n\t\tsrc[0]= srcParam[0];\n\n\t\tsrc[1]= srcParam[1];\n\n\t\tsrc[2]= srcParam[2];\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]= srcStrideParam[1];\n\n\t\tsrcStride[2]= srcStrideParam[2];\n\n\t}\n\n\telse if(isPacked(c->srcFormat)){\n\n\t\tsrc[0]=\n\n\t\tsrc[1]=\n\n\t\tsrc[2]= srcParam[0];\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]=\n\n\t\tsrcStride[2]= srcStrideParam[0]<<1;\n\n\t}\n\n\telse if(c->srcFormat==IMGFMT_Y8){\n\n\t\tsrc[0]= srcParam[0];\n\n\t\tsrc[1]=\n\n\t\tsrc[2]= NULL;\n\n\t\tsrcStride[0]= srcStrideParam[0];\n\n\t\tsrcStride[1]=\n\n\t\tsrcStride[2]= 0;\n\n\t}\n\n\n\n\tif((c->dstFormat == IMGFMT_IYUV) || (c->dstFormat == IMGFMT_I420)){\n\n\t\tdst[0]= dstParam[0];\n\n\t\tdst[1]= dstParam[2];\n\n\t\tdst[2]= dstParam[1];\n\n\t\t\n\n\t}else{\n\n\t\tdst[0]= dstParam[0];\n\n\t\tdst[1]= dstParam[1];\n\n\t\tdst[2]= dstParam[2];\n\n\t}\n\n\t\n\n\n\n\tif(dstStride[0]%8 !=0 || dstStride[1]%8 !=0 || dstStride[2]%8 !=0)\n\n\t{\n\n\t\tstatic int firstTime=1; //FIXME move this into the context perhaps\n\n\t\tif(flags & SWS_PRINT_INFO && firstTime)\n\n\t\t{\n\n\t\t\tfprintf(stderr, \"SwScaler: Warning: dstStride is not aligned!\\n\"\n\n\t\t\t\t\t\"SwScaler:          ->cannot do aligned memory acesses anymore\\n\");\n\n\t\t\tfirstTime=0;\n\n\t\t}\n\n\t}\n\n\n\n\t/* Note the user might start scaling the picture in the middle so this will not get executed\n\n\t   this is not really intended but works currently, so ppl might do it */\n\n\tif(srcSliceY ==0){\n\n\t\tlumBufIndex=0;\n\n\t\tchrBufIndex=0;\n\n\t\tdstY=0;\t\n\n\t\tlastInLumBuf= -1;\n\n\t\tlastInChrBuf= -1;\n\n\t}\n\n\n\n\tfor(;dstY < dstH; dstY++){\n\n\t\tunsigned char *dest =dst[0]+dstStride[0]*dstY;\n\n\t\tunsigned char *uDest=dst[1]+dstStride[1]*(dstY>>1);\n\n\t\tunsigned char *vDest=dst[2]+dstStride[2]*(dstY>>1);\n\n\t\tconst int chrDstY= isHalfChrV(dstFormat) ? (dstY>>1) : dstY;\n\n\n\n\t\tconst int firstLumSrcY= vLumFilterPos[dstY]; //First line needed as input\n\n\t\tconst int firstChrSrcY= vChrFilterPos[chrDstY]; //First line needed as input\n\n\t\tconst int lastLumSrcY= firstLumSrcY + vLumFilterSize -1; // Last line needed as input\n\n\t\tconst int lastChrSrcY= firstChrSrcY + vChrFilterSize -1; // Last line needed as input\n\n\n\n\t\t//handle holes (FAST_BILINEAR & weird filters)\n\n\t\tif(firstLumSrcY > lastInLumBuf) lastInLumBuf= firstLumSrcY-1;\n\n\t\tif(firstChrSrcY > lastInChrBuf) lastInChrBuf= firstChrSrcY-1;\n\n//printf(\"%d %d %d\\n\", firstChrSrcY, lastInChrBuf, vChrBufSize);\n\n\t\tASSERT(firstLumSrcY >= lastInLumBuf - vLumBufSize + 1)\n\n\t\tASSERT(firstChrSrcY >= lastInChrBuf - vChrBufSize + 1)\n\n\n\n\t\t// Do we have enough lines in this slice to output the dstY line\n\n\t\tif(lastLumSrcY < srcSliceY + srcSliceH && lastChrSrcY < ((srcSliceY + srcSliceH)>>1))\n\n\t\t{\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf < lastLumSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *s= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n\t\t\t\tlumBufIndex++;\n\n//\t\t\t\tprintf(\"%d %d %d %d\\n\", lumBufIndex, vLumBufSize, lastInLumBuf,  lastLumSrcY);\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n//\t\t\t\tprintf(\"%d %d\\n\", lumBufIndex, vLumBufSize);\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, s, srcW, lumXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n\t\t\t\t\t\tfunnyYCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf < lastChrSrcY)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= src[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[1];\n\n\t\t\t\tuint8_t *src2= src[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < (srcSliceH>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\t//FIXME replace parameters through context struct (some at least)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, (srcW+1)>>1, chrXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hChrFilter, hChrFilterPos, hChrFilterSize,\n\n\t\t\t\t\t\tfunnyUVCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t}\n\n\t\telse // not enough lines left in this slice -> load the rest in the buffer\n\n\t\t{\n\n/*\t\tprintf(\"%d %d Last:%d %d LastInBuf:%d %d Index:%d %d Y:%d FSize: %d %d BSize: %d %d\\n\",\n\n\t\t\tfirstChrSrcY,firstLumSrcY,lastChrSrcY,lastLumSrcY,\n\n\t\t\tlastInChrBuf,lastInLumBuf,chrBufIndex,lumBufIndex,dstY,vChrFilterSize,vLumFilterSize,\n\n\t\t\tvChrBufSize, vLumBufSize);\n\n*/\n\n\t\t\t//Do horizontal scaling\n\n\t\t\twhile(lastInLumBuf+1 < srcSliceY + srcSliceH)\n\n\t\t\t{\n\n\t\t\t\tuint8_t *s= src[0]+(lastInLumBuf + 1 - srcSliceY)*srcStride[0];\n\n\t\t\t\tlumBufIndex++;\n\n\t\t\t\tASSERT(lumBufIndex < 2*vLumBufSize)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY < srcSliceH)\n\n\t\t\t\tASSERT(lastInLumBuf + 1 - srcSliceY >= 0)\n\n\t\t\t\tRENAME(hyscale)(lumPixBuf[ lumBufIndex ], dstW, s, srcW, lumXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hLumFilter, hLumFilterPos, hLumFilterSize,\n\n\t\t\t\t\t\tfunnyYCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInLumBuf++;\n\n\t\t\t}\n\n\t\t\twhile(lastInChrBuf+1 < ((srcSliceY + srcSliceH)>>1))\n\n\t\t\t{\n\n\t\t\t\tuint8_t *src1= src[1]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[1];\n\n\t\t\t\tuint8_t *src2= src[2]+(lastInChrBuf + 1 - (srcSliceY>>1))*srcStride[2];\n\n\t\t\t\tchrBufIndex++;\n\n\t\t\t\tASSERT(chrBufIndex < 2*vChrBufSize)\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) < (srcSliceH>>1))\n\n\t\t\t\tASSERT(lastInChrBuf + 1 - (srcSliceY>>1) >= 0)\n\n\t\t\t\tRENAME(hcscale)(chrPixBuf[ chrBufIndex ], chrDstW, src1, src2, (srcW+1)>>1, chrXInc,\n\n\t\t\t\t\t\tflags, canMMX2BeUsed, hChrFilter, hChrFilterPos, hChrFilterSize,\n\n\t\t\t\t\t\tfunnyUVCode, c->srcFormat, formatConvBuffer);\n\n\t\t\t\tlastInChrBuf++;\n\n\t\t\t}\n\n\t\t\t//wrap buf index around to stay inside the ring buffer\n\n\t\t\tif(lumBufIndex >= vLumBufSize ) lumBufIndex-= vLumBufSize;\n\n\t\t\tif(chrBufIndex >= vChrBufSize ) chrBufIndex-= vChrBufSize;\n\n\t\t\tbreak; //we cant output a dstY line so lets try with the next slice\n\n\t\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t\tb5Dither= dither8[dstY&1];\n\n\t\tg6Dither= dither4[dstY&1];\n\n\t\tg5Dither= dither8[dstY&1];\n\n\t\tr5Dither= dither8[(dstY+1)&1];\n\n#endif\n\n\t    if(dstY < dstH-2)\n\n\t    {\n\n\t\tif(isPlanarYUV(dstFormat)) //YV12 like\n\n\t\t{\n\n\t\t\tif(dstY&1) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 1) // Unscaled YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t *lumBuf = lumPixBuf[0];\n\n\t\t\t\tint16_t *chrBuf= chrPixBuf[0];\n\n\t\t\t\tRENAME(yuv2yuv1)(lumBuf, chrBuf, dest, uDest, vDest, dstW);\n\n\t\t\t}\n\n\t\t\telse //General YV12\n\n\t\t\t{\n\n\t\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\t\t\t\tRENAME(yuv2yuvX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize     , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+(dstY>>1)*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, uDest, vDest, dstW,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+(dstY>>1)*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tif(vLumFilterSize == 1 && vChrFilterSize == 2) //Unscaled RGB\n\n\t\t\t{\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb1)(*lumSrcPtr, *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, chrAlpha, dstFormat, flags);\n\n\t\t\t}\n\n\t\t\telse if(vLumFilterSize == 2 && vChrFilterSize == 2) //BiLinear Upscale RGB\n\n\t\t\t{\n\n\t\t\t\tint lumAlpha= vLumFilter[2*dstY+1];\n\n\t\t\t\tint chrAlpha= vChrFilter[2*dstY+1];\n\n\n\n\t\t\t\tRENAME(yuv2rgb2)(*lumSrcPtr, *(lumSrcPtr+1), *chrSrcPtr, *(chrSrcPtr+1),\n\n\t\t\t\t\t\t dest, dstW, lumAlpha, chrAlpha, dstFormat, flags);\n\n\t\t\t}\n\n\t\t\telse //General RGB\n\n\t\t\t{\n\n\t\t\t\tRENAME(yuv2rgbX)(\n\n\t\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\t\tdest, dstW, dstFormat,\n\n\t\t\t\t\tlumMmxFilter+dstY*vLumFilterSize*4, chrMmxFilter+dstY*vChrFilterSize*4);\n\n\t\t\t}\n\n\t\t}\n\n            }\n\n\t    else // hmm looks like we cant use MMX here without overwriting this arrays tail\n\n\t    {\n\n\t\tint16_t **lumSrcPtr= lumPixBuf + lumBufIndex + firstLumSrcY - lastInLumBuf + vLumBufSize;\n\n\t\tint16_t **chrSrcPtr= chrPixBuf + chrBufIndex + firstChrSrcY - lastInChrBuf + vChrBufSize;\n\n\t\tif(isPlanarYUV(dstFormat)) //YV12\n\n\t\t{\n\n\t\t\tif(dstY&1) uDest=vDest= NULL; //FIXME split functions in lumi / chromi\n\n\t\t\tyuv2yuvXinC(\n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize     , lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+(dstY>>1)*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, uDest, vDest, dstW);\n\n\t\t}\n\n\t\telse\n\n\t\t{\n\n\t\t\tASSERT(lumSrcPtr + vLumFilterSize - 1 < lumPixBuf + vLumBufSize*2);\n\n\t\t\tASSERT(chrSrcPtr + vChrFilterSize - 1 < chrPixBuf + vChrBufSize*2);\n\n\t\t\tyuv2rgbXinC(\n\n\t\t\t\tvLumFilter+dstY*vLumFilterSize, lumSrcPtr, vLumFilterSize,\n\n\t\t\t\tvChrFilter+dstY*vChrFilterSize, chrSrcPtr, vChrFilterSize,\n\n\t\t\t\tdest, dstW, dstFormat);\n\n\t\t}\n\n\t    }\n\n\t}\n\n\n\n#ifdef HAVE_MMX\n\n\t__asm __volatile(SFENCE:::\"memory\");\n\n\t__asm __volatile(EMMS:::\"memory\");\n\n#endif\n\n\t/* store changed local vars back in the context */\n\n\tc->dstY= dstY;\n\n\tc->lumBufIndex= lumBufIndex;\n\n\tc->chrBufIndex= chrBufIndex;\n\n\tc->lastInLumBuf= lastInLumBuf;\n\n\tc->lastInChrBuf= lastInChrBuf;\n\n}\n", "idx": 20022, "_split": "test", "_hash": "d288b4de1b7a43428752b1636b6f8e78"}
{"project": "FFmpeg", "commit_id": "55d7371fe0c44c025eb0e75215e0685870f31874", "target": 1, "func": "static int vp9_decode_frame(AVCodecContext *ctx, void *frame,\n\n                            int *got_frame, AVPacket *pkt)\n\n{\n\n    const uint8_t *data = pkt->data;\n\n    int size = pkt->size;\n\n    VP9Context *s = ctx->priv_data;\n\n    int res, tile_row, tile_col, i, ref, row, col;\n\n    int retain_segmap_ref = s->s.frames[REF_FRAME_SEGMAP].segmentation_map &&\n\n                            (!s->s.h.segmentation.enabled || !s->s.h.segmentation.update_map);\n\n    ptrdiff_t yoff, uvoff, ls_y, ls_uv;\n\n    AVFrame *f;\n\n    int bytesperpixel;\n\n\n\n    if ((res = decode_frame_header(ctx, data, size, &ref)) < 0) {\n\n        return res;\n\n    } else if (res == 0) {\n\n        if (!s->s.refs[ref].f->buf[0]) {\n\n            av_log(ctx, AV_LOG_ERROR, \"Requested reference %d not available\\n\", ref);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        if ((res = av_frame_ref(frame, s->s.refs[ref].f)) < 0)\n\n            return res;\n\n        ((AVFrame *)frame)->pts = pkt->pts;\n\n#if FF_API_PKT_PTS\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n        ((AVFrame *)frame)->pkt_pts = pkt->pts;\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n#endif\n\n        ((AVFrame *)frame)->pkt_dts = pkt->dts;\n\n        for (i = 0; i < 8; i++) {\n\n            if (s->next_refs[i].f->buf[0])\n\n                ff_thread_release_buffer(ctx, &s->next_refs[i]);\n\n            if (s->s.refs[i].f->buf[0] &&\n\n                (res = ff_thread_ref_frame(&s->next_refs[i], &s->s.refs[i])) < 0)\n\n                return res;\n\n        }\n\n        *got_frame = 1;\n\n        return pkt->size;\n\n    }\n\n    data += res;\n\n    size -= res;\n\n\n\n    if (!retain_segmap_ref || s->s.h.keyframe || s->s.h.intraonly) {\n\n        if (s->s.frames[REF_FRAME_SEGMAP].tf.f->buf[0])\n\n            vp9_unref_frame(ctx, &s->s.frames[REF_FRAME_SEGMAP]);\n\n        if (!s->s.h.keyframe && !s->s.h.intraonly && !s->s.h.errorres && s->s.frames[CUR_FRAME].tf.f->buf[0] &&\n\n            (res = vp9_ref_frame(ctx, &s->s.frames[REF_FRAME_SEGMAP], &s->s.frames[CUR_FRAME])) < 0)\n\n            return res;\n\n    }\n\n    if (s->s.frames[REF_FRAME_MVPAIR].tf.f->buf[0])\n\n        vp9_unref_frame(ctx, &s->s.frames[REF_FRAME_MVPAIR]);\n\n    if (!s->s.h.intraonly && !s->s.h.keyframe && !s->s.h.errorres && s->s.frames[CUR_FRAME].tf.f->buf[0] &&\n\n        (res = vp9_ref_frame(ctx, &s->s.frames[REF_FRAME_MVPAIR], &s->s.frames[CUR_FRAME])) < 0)\n\n        return res;\n\n    if (s->s.frames[CUR_FRAME].tf.f->buf[0])\n\n        vp9_unref_frame(ctx, &s->s.frames[CUR_FRAME]);\n\n    if ((res = vp9_alloc_frame(ctx, &s->s.frames[CUR_FRAME])) < 0)\n\n        return res;\n\n    f = s->s.frames[CUR_FRAME].tf.f;\n\n    f->key_frame = s->s.h.keyframe;\n\n    f->pict_type = (s->s.h.keyframe || s->s.h.intraonly) ? AV_PICTURE_TYPE_I : AV_PICTURE_TYPE_P;\n\n    ls_y = f->linesize[0];\n\n    ls_uv =f->linesize[1];\n\n\n\n    if (s->s.frames[REF_FRAME_SEGMAP].tf.f->buf[0] &&\n\n        (s->s.frames[REF_FRAME_MVPAIR].tf.f->width  != s->s.frames[CUR_FRAME].tf.f->width ||\n\n         s->s.frames[REF_FRAME_MVPAIR].tf.f->height != s->s.frames[CUR_FRAME].tf.f->height)) {\n\n        vp9_unref_frame(ctx, &s->s.frames[REF_FRAME_SEGMAP]);\n\n    }\n\n\n\n    // ref frame setup\n\n    for (i = 0; i < 8; i++) {\n\n        if (s->next_refs[i].f->buf[0])\n\n            ff_thread_release_buffer(ctx, &s->next_refs[i]);\n\n        if (s->s.h.refreshrefmask & (1 << i)) {\n\n            res = ff_thread_ref_frame(&s->next_refs[i], &s->s.frames[CUR_FRAME].tf);\n\n        } else if (s->s.refs[i].f->buf[0]) {\n\n            res = ff_thread_ref_frame(&s->next_refs[i], &s->s.refs[i]);\n\n        }\n\n        if (res < 0)\n\n            return res;\n\n    }\n\n\n\n    if (ctx->hwaccel) {\n\n        res = ctx->hwaccel->start_frame(ctx, NULL, 0);\n\n        if (res < 0)\n\n            return res;\n\n        res = ctx->hwaccel->decode_slice(ctx, pkt->data, pkt->size);\n\n        if (res < 0)\n\n            return res;\n\n        res = ctx->hwaccel->end_frame(ctx);\n\n        if (res < 0)\n\n            return res;\n\n        goto finish;\n\n    }\n\n\n\n    // main tile decode loop\n\n    bytesperpixel = s->bytesperpixel;\n\n    memset(s->above_partition_ctx, 0, s->cols);\n\n    memset(s->above_skip_ctx, 0, s->cols);\n\n    if (s->s.h.keyframe || s->s.h.intraonly) {\n\n        memset(s->above_mode_ctx, DC_PRED, s->cols * 2);\n\n    } else {\n\n        memset(s->above_mode_ctx, NEARESTMV, s->cols);\n\n    }\n\n    memset(s->above_y_nnz_ctx, 0, s->sb_cols * 16);\n\n    memset(s->above_uv_nnz_ctx[0], 0, s->sb_cols * 16 >> s->ss_h);\n\n    memset(s->above_uv_nnz_ctx[1], 0, s->sb_cols * 16 >> s->ss_h);\n\n    memset(s->above_segpred_ctx, 0, s->cols);\n\n    s->pass = s->s.frames[CUR_FRAME].uses_2pass =\n\n        ctx->active_thread_type == FF_THREAD_FRAME && s->s.h.refreshctx && !s->s.h.parallelmode;\n\n    if ((res = update_block_buffers(ctx)) < 0) {\n\n        av_log(ctx, AV_LOG_ERROR,\n\n               \"Failed to allocate block buffers\\n\");\n\n        return res;\n\n    }\n\n    if (s->s.h.refreshctx && s->s.h.parallelmode) {\n\n        int j, k, l, m;\n\n\n\n        for (i = 0; i < 4; i++) {\n\n            for (j = 0; j < 2; j++)\n\n                for (k = 0; k < 2; k++)\n\n                    for (l = 0; l < 6; l++)\n\n                        for (m = 0; m < 6; m++)\n\n                            memcpy(s->prob_ctx[s->s.h.framectxid].coef[i][j][k][l][m],\n\n                                   s->prob.coef[i][j][k][l][m], 3);\n\n            if (s->s.h.txfmmode == i)\n\n                break;\n\n        }\n\n        s->prob_ctx[s->s.h.framectxid].p = s->prob.p;\n\n        ff_thread_finish_setup(ctx);\n\n    } else if (!s->s.h.refreshctx) {\n\n        ff_thread_finish_setup(ctx);\n\n    }\n\n\n\n    do {\n\n        yoff = uvoff = 0;\n\n        s->b = s->b_base;\n\n        s->block = s->block_base;\n\n        s->uvblock[0] = s->uvblock_base[0];\n\n        s->uvblock[1] = s->uvblock_base[1];\n\n        s->eob = s->eob_base;\n\n        s->uveob[0] = s->uveob_base[0];\n\n        s->uveob[1] = s->uveob_base[1];\n\n\n\n        for (tile_row = 0; tile_row < s->s.h.tiling.tile_rows; tile_row++) {\n\n            set_tile_offset(&s->tile_row_start, &s->tile_row_end,\n\n                            tile_row, s->s.h.tiling.log2_tile_rows, s->sb_rows);\n\n            if (s->pass != 2) {\n\n                for (tile_col = 0; tile_col < s->s.h.tiling.tile_cols; tile_col++) {\n\n                    int64_t tile_size;\n\n\n\n                    if (tile_col == s->s.h.tiling.tile_cols - 1 &&\n\n                        tile_row == s->s.h.tiling.tile_rows - 1) {\n\n                        tile_size = size;\n\n                    } else {\n\n                        tile_size = AV_RB32(data);\n\n                        data += 4;\n\n                        size -= 4;\n\n                    }\n\n                    if (tile_size > size) {\n\n                        ff_thread_report_progress(&s->s.frames[CUR_FRAME].tf, INT_MAX, 0);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    ff_vp56_init_range_decoder(&s->c_b[tile_col], data, tile_size);\n\n                    if (vp56_rac_get_prob_branchy(&s->c_b[tile_col], 128)) { // marker bit\n\n                        ff_thread_report_progress(&s->s.frames[CUR_FRAME].tf, INT_MAX, 0);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n                    data += tile_size;\n\n                    size -= tile_size;\n\n                }\n\n            }\n\n\n\n            for (row = s->tile_row_start; row < s->tile_row_end;\n\n                 row += 8, yoff += ls_y * 64, uvoff += ls_uv * 64 >> s->ss_v) {\n\n                struct VP9Filter *lflvl_ptr = s->lflvl;\n\n                ptrdiff_t yoff2 = yoff, uvoff2 = uvoff;\n\n\n\n                for (tile_col = 0; tile_col < s->s.h.tiling.tile_cols; tile_col++) {\n\n                    set_tile_offset(&s->tile_col_start, &s->tile_col_end,\n\n                                    tile_col, s->s.h.tiling.log2_tile_cols, s->sb_cols);\n\n\n\n                    if (s->pass != 2) {\n\n                        memset(s->left_partition_ctx, 0, 8);\n\n                        memset(s->left_skip_ctx, 0, 8);\n\n                        if (s->s.h.keyframe || s->s.h.intraonly) {\n\n                            memset(s->left_mode_ctx, DC_PRED, 16);\n\n                        } else {\n\n                            memset(s->left_mode_ctx, NEARESTMV, 8);\n\n                        }\n\n                        memset(s->left_y_nnz_ctx, 0, 16);\n\n                        memset(s->left_uv_nnz_ctx, 0, 32);\n\n                        memset(s->left_segpred_ctx, 0, 8);\n\n\n\n                        memcpy(&s->c, &s->c_b[tile_col], sizeof(s->c));\n\n                    }\n\n\n\n                    for (col = s->tile_col_start;\n\n                         col < s->tile_col_end;\n\n                         col += 8, yoff2 += 64 * bytesperpixel,\n\n                         uvoff2 += 64 * bytesperpixel >> s->ss_h, lflvl_ptr++) {\n\n                        // FIXME integrate with lf code (i.e. zero after each\n\n                        // use, similar to invtxfm coefficients, or similar)\n\n                        if (s->pass != 1) {\n\n                            memset(lflvl_ptr->mask, 0, sizeof(lflvl_ptr->mask));\n\n                        }\n\n\n\n                        if (s->pass == 2) {\n\n                            decode_sb_mem(ctx, row, col, lflvl_ptr,\n\n                                          yoff2, uvoff2, BL_64X64);\n\n                        } else {\n\n                            decode_sb(ctx, row, col, lflvl_ptr,\n\n                                      yoff2, uvoff2, BL_64X64);\n\n                        }\n\n                    }\n\n                    if (s->pass != 2) {\n\n                        memcpy(&s->c_b[tile_col], &s->c, sizeof(s->c));\n\n                    }\n\n                }\n\n\n\n                if (s->pass == 1) {\n\n                    continue;\n\n                }\n\n\n\n                // backup pre-loopfilter reconstruction data for intra\n\n                // prediction of next row of sb64s\n\n                if (row + 8 < s->rows) {\n\n                    memcpy(s->intra_pred_data[0],\n\n                           f->data[0] + yoff + 63 * ls_y,\n\n                           8 * s->cols * bytesperpixel);\n\n                    memcpy(s->intra_pred_data[1],\n\n                           f->data[1] + uvoff + ((64 >> s->ss_v) - 1) * ls_uv,\n\n                           8 * s->cols * bytesperpixel >> s->ss_h);\n\n                    memcpy(s->intra_pred_data[2],\n\n                           f->data[2] + uvoff + ((64 >> s->ss_v) - 1) * ls_uv,\n\n                           8 * s->cols * bytesperpixel >> s->ss_h);\n\n                }\n\n\n\n                // loopfilter one row\n\n                if (s->s.h.filter.level) {\n\n                    yoff2 = yoff;\n\n                    uvoff2 = uvoff;\n\n                    lflvl_ptr = s->lflvl;\n\n                    for (col = 0; col < s->cols;\n\n                         col += 8, yoff2 += 64 * bytesperpixel,\n\n                         uvoff2 += 64 * bytesperpixel >> s->ss_h, lflvl_ptr++) {\n\n                        loopfilter_sb(ctx, lflvl_ptr, row, col, yoff2, uvoff2);\n\n                    }\n\n                }\n\n\n\n                // FIXME maybe we can make this more finegrained by running the\n\n                // loopfilter per-block instead of after each sbrow\n\n                // In fact that would also make intra pred left preparation easier?\n\n                ff_thread_report_progress(&s->s.frames[CUR_FRAME].tf, row >> 3, 0);\n\n            }\n\n        }\n\n\n\n        if (s->pass < 2 && s->s.h.refreshctx && !s->s.h.parallelmode) {\n\n            adapt_probs(s);\n\n            ff_thread_finish_setup(ctx);\n\n        }\n\n    } while (s->pass++ == 1);\n\n    ff_thread_report_progress(&s->s.frames[CUR_FRAME].tf, INT_MAX, 0);\n\n\n\nfinish:\n\n    // ref frame setup\n\n    for (i = 0; i < 8; i++) {\n\n        if (s->s.refs[i].f->buf[0])\n\n            ff_thread_release_buffer(ctx, &s->s.refs[i]);\n\n        if (s->next_refs[i].f->buf[0] &&\n\n            (res = ff_thread_ref_frame(&s->s.refs[i], &s->next_refs[i])) < 0)\n\n            return res;\n\n    }\n\n\n\n    if (!s->s.h.invisible) {\n\n        if ((res = av_frame_ref(frame, s->s.frames[CUR_FRAME].tf.f)) < 0)\n\n            return res;\n\n        *got_frame = 1;\n\n    }\n\n\n\n    return pkt->size;\n\n}\n", "idx": 20035, "_split": "test", "_hash": "6e46f7191be7cf27270eacd86a696e1a"}
{"project": "FFmpeg", "commit_id": "c9c55a56996836e7783fb27018834f230c553c98", "target": 0, "func": "static const MXFCodecUL *mxf_get_codec_ul(const MXFCodecUL *uls, UID *uid)\n\n{\n\n    while (uls->id != CODEC_ID_NONE) {\n\n        if(mxf_match_uid(uls->uid, *uid, 16))\n\n            break;\n\n        uls++;\n\n    }\n\n    return uls;\n\n}\n", "idx": 20102, "_split": "test", "_hash": "9e8ff846b5f15f889b156468d7b351fd"}
{"project": "FFmpeg", "commit_id": "544286b3d39365b30298ae07e66a755200b0895c", "target": 1, "func": "int h263_decode_picture_header(MpegEncContext *s)\n\n{\n\n    int format, width, height;\n\n\n\n    /* picture header */\n\n    if (get_bits(&s->gb, 22) != 0x20)\n\n        return -1;\n\n    skip_bits(&s->gb, 8); /* picture timestamp */\n\n\n\n    if (get_bits1(&s->gb) != 1)\n\n        return -1;\t/* marker */\n\n    if (get_bits1(&s->gb) != 0)\n\n        return -1;\t/* h263 id */\n\n    skip_bits1(&s->gb);\t/* split screen off */\n\n    skip_bits1(&s->gb);\t/* camera  off */\n\n    skip_bits1(&s->gb);\t/* freeze picture release off */\n\n\n\n    format = get_bits(&s->gb, 3);\n\n\n\n    if (format != 7) {\n\n        s->h263_plus = 0;\n\n        /* H.263v1 */\n\n        width = h263_format[format][0];\n\n        height = h263_format[format][1];\n\n        if (!width)\n\n            return -1;\n\n\n\n        s->pict_type = I_TYPE + get_bits1(&s->gb);\n\n\n\n        s->unrestricted_mv = get_bits1(&s->gb); \n\n        s->h263_long_vectors = s->unrestricted_mv;\n\n\n\n        if (get_bits1(&s->gb) != 0)\n\n            return -1;\t/* SAC: off */\n\n        if (get_bits1(&s->gb) != 0)\n\n            return -1;\t/* advanced prediction mode: off */\n\n        if (get_bits1(&s->gb) != 0)\n\n            return -1;\t/* not PB frame */\n\n\n\n        s->qscale = get_bits(&s->gb, 5);\n\n        skip_bits1(&s->gb);\t/* Continuous Presence Multipoint mode: off */\n\n    } else {\n\n        s->h263_plus = 1;\n\n        /* H.263v2 */\n\n        /* OPPTYPE */\n\n     \n\n        if (get_bits(&s->gb, 3) != 1) /* Update Full Extended PTYPE */\n\n            return -1;\n\n        format = get_bits(&s->gb, 3);\n\n                \n\n        skip_bits(&s->gb,1); /* Custom PCF */\n\n        umvplus_dec = get_bits(&s->gb, 1); /* Unrestricted Motion Vector */\n\n        skip_bits(&s->gb, 10);\n\n        skip_bits(&s->gb, 3); /* Reserved */\n\n        \n\n        /* MPPTYPE */\n\n        s->pict_type = get_bits(&s->gb, 3) + 1;\n\n        if (s->pict_type != I_TYPE &&\n\n            s->pict_type != P_TYPE)\n\n            return -1;\n\n        skip_bits(&s->gb, 7);\n\n        \n\n        /* Get the picture dimensions */\n\n        if (format == 6) {\n\n            /* Custom Picture Format (CPFMT) */\n\n            skip_bits(&s->gb, 4); /* aspect ratio */\n\n            width = (get_bits(&s->gb, 9) + 1) * 4;\n\n            skip_bits1(&s->gb);\n\n            height = get_bits(&s->gb, 9) * 4;\n\n#ifdef DEBUG \n\n            fprintf(stderr,\"\\nH.263+ Custom picture: %dx%d\\n\",width,height);\n\n#endif            \n\n        }\n\n        else {\n\n            width = h263_format[format][0];\n\n            height = h263_format[format][1];\n\n        }\n\n        \n\n        if ((width == 0) || (height == 0))\n\n            return -1;\n\n            \n\n        if (umvplus_dec) {\n\n            skip_bits1(&s->gb); /* Unlimited Unrestricted Motion Vectors Indicator (UUI) */\n\n        }\n\n            \n\n        s->qscale = get_bits(&s->gb, 5);\n\n    }\n\n    /* PEI */\n\n    while (get_bits1(&s->gb) != 0) {\n\n        skip_bits(&s->gb, 8);\n\n    }\n\n    s->f_code = 1;\n\n    s->width = width;\n\n    s->height = height;\n\n    return 0;\n\n}\n", "idx": 20109, "_split": "test", "_hash": "397a1fe24fc9905485f91fe326e29275"}
{"project": "FFmpeg", "commit_id": "47219e1c0c2f8a159e70b58e6293c169c7dd62cc", "target": 1, "func": "static void do_video_out(AVFormatContext *s,\n\n                         OutputStream *ost,\n\n                         InputStream *ist,\n\n                         AVFrame *in_picture,\n\n                         int *frame_size, float quality)\n\n{\n\n    int nb_frames, i, ret, av_unused resample_changed;\n\n    AVFrame *final_picture, *formatted_picture;\n\n    AVCodecContext *enc, *dec;\n\n    double sync_ipts;\n\n\n\n    enc = ost->st->codec;\n\n    dec = ist->st->codec;\n\n\n\n    sync_ipts = get_sync_ipts(ost) / av_q2d(enc->time_base);\n\n\n\n    /* by default, we output a single frame */\n\n    nb_frames = 1;\n\n\n\n    *frame_size = 0;\n\n\n\n    if(video_sync_method){\n\n        double vdelta = sync_ipts - ost->sync_opts;\n\n        //FIXME set to 0.5 after we fix some dts/pts bugs like in avidec.c\n\n        if (vdelta < -1.1)\n\n            nb_frames = 0;\n\n        else if (video_sync_method == 2 || (video_sync_method<0 && (s->oformat->flags & AVFMT_VARIABLE_FPS))){\n\n            if(vdelta<=-0.6){\n\n                nb_frames=0;\n\n            }else if(vdelta>0.6)\n\n                ost->sync_opts= lrintf(sync_ipts);\n\n        }else if (vdelta > 1.1)\n\n            nb_frames = lrintf(vdelta);\n\n//fprintf(stderr, \"vdelta:%f, ost->sync_opts:%\"PRId64\", ost->sync_ipts:%f nb_frames:%d\\n\", vdelta, ost->sync_opts, get_sync_ipts(ost), nb_frames);\n\n        if (nb_frames == 0){\n\n            ++nb_frames_drop;\n\n            if (verbose>2)\n\n                fprintf(stderr, \"*** drop!\\n\");\n\n        }else if (nb_frames > 1) {\n\n            nb_frames_dup += nb_frames - 1;\n\n            if (verbose>2)\n\n                fprintf(stderr, \"*** %d dup!\\n\", nb_frames-1);\n\n        }\n\n    }else\n\n        ost->sync_opts= lrintf(sync_ipts);\n\n\n\n    nb_frames= FFMIN(nb_frames, max_frames[AVMEDIA_TYPE_VIDEO] - ost->frame_number);\n\n    if (nb_frames <= 0)\n\n        return;\n\n\n\n    formatted_picture = in_picture;\n\n    final_picture = formatted_picture;\n\n\n\n#if !CONFIG_AVFILTER\n\n    resample_changed = ost->resample_width   != dec->width  ||\n\n                       ost->resample_height  != dec->height ||\n\n                       ost->resample_pix_fmt != dec->pix_fmt;\n\n\n\n    if (resample_changed) {\n\n        av_log(NULL, AV_LOG_INFO,\n\n               \"Input stream #%d.%d frame changed from size:%dx%d fmt:%s to size:%dx%d fmt:%s\\n\",\n\n               ist->file_index, ist->st->index,\n\n               ost->resample_width, ost->resample_height, av_get_pix_fmt_name(ost->resample_pix_fmt),\n\n               dec->width         , dec->height         , av_get_pix_fmt_name(dec->pix_fmt));\n\n        ost->resample_width   = dec->width;\n\n        ost->resample_height  = dec->height;\n\n        ost->resample_pix_fmt = dec->pix_fmt;\n\n    }\n\n\n\n    ost->video_resample = dec->width   != enc->width  ||\n\n                          dec->height  != enc->height ||\n\n                          dec->pix_fmt != enc->pix_fmt;\n\n\n\n    if (ost->video_resample) {\n\n        final_picture = &ost->resample_frame;\n\n        if (!ost->img_resample_ctx || resample_changed) {\n\n            /* initialize the destination picture */\n\n            if (!ost->resample_frame.data[0]) {\n\n                avcodec_get_frame_defaults(&ost->resample_frame);\n\n                if (avpicture_alloc((AVPicture *)&ost->resample_frame, enc->pix_fmt,\n\n                                    enc->width, enc->height)) {\n\n                    fprintf(stderr, \"Cannot allocate temp picture, check pix fmt\\n\");\n\n                    exit_program(1);\n\n                }\n\n            }\n\n            /* initialize a new scaler context */\n\n            sws_freeContext(ost->img_resample_ctx);\n\n            ost->img_resample_ctx = sws_getContext(dec->width, dec->height, dec->pix_fmt,\n\n                                                   enc->width, enc->height, enc->pix_fmt,\n\n                                                   ost->sws_flags, NULL, NULL, NULL);\n\n            if (ost->img_resample_ctx == NULL) {\n\n                fprintf(stderr, \"Cannot get resampling context\\n\");\n\n                exit_program(1);\n\n            }\n\n        }\n\n        sws_scale(ost->img_resample_ctx, formatted_picture->data, formatted_picture->linesize,\n\n              0, ost->resample_height, final_picture->data, final_picture->linesize);\n\n    }\n\n#else\n\n    if (resample_changed) {\n\n        avfilter_graph_free(&ost->graph);\n\n        if (configure_video_filters(ist, ost)) {\n\n            fprintf(stderr, \"Error reinitialising filters!\\n\");\n\n            exit_program(1);\n\n        }\n\n    }\n\n#endif\n\n    if (resample_changed) {\n\n        ost->resample_width   = dec->width;\n\n        ost->resample_height  = dec->height;\n\n        ost->resample_pix_fmt = dec->pix_fmt;\n\n    }\n\n\n\n    /* duplicates frame if needed */\n\n    for(i=0;i<nb_frames;i++) {\n\n        AVPacket pkt;\n\n        av_init_packet(&pkt);\n\n        pkt.stream_index= ost->index;\n\n\n\n        if (s->oformat->flags & AVFMT_RAWPICTURE) {\n\n            /* raw pictures are written as AVPicture structure to\n\n               avoid any copies. We support temorarily the older\n\n               method. */\n\n            AVFrame* old_frame = enc->coded_frame;\n\n            enc->coded_frame = dec->coded_frame; //FIXME/XXX remove this hack\n\n            pkt.data= (uint8_t *)final_picture;\n\n            pkt.size=  sizeof(AVPicture);\n\n            pkt.pts= av_rescale_q(ost->sync_opts, enc->time_base, ost->st->time_base);\n\n            pkt.flags |= AV_PKT_FLAG_KEY;\n\n\n\n            write_frame(s, &pkt, ost->st->codec, ost->bitstream_filters);\n\n            enc->coded_frame = old_frame;\n\n        } else {\n\n            AVFrame big_picture;\n\n\n\n            big_picture= *final_picture;\n\n            /* better than nothing: use input picture interlaced\n\n               settings */\n\n            big_picture.interlaced_frame = in_picture->interlaced_frame;\n\n            if (ost->st->codec->flags & (CODEC_FLAG_INTERLACED_DCT|CODEC_FLAG_INTERLACED_ME)) {\n\n                if(top_field_first == -1)\n\n                    big_picture.top_field_first = in_picture->top_field_first;\n\n                else\n\n                    big_picture.top_field_first = top_field_first;\n\n            }\n\n\n\n            /* handles sameq here. This is not correct because it may\n\n               not be a global option */\n\n            big_picture.quality = quality;\n\n            if(!me_threshold)\n\n                big_picture.pict_type = 0;\n\n//            big_picture.pts = AV_NOPTS_VALUE;\n\n            big_picture.pts= ost->sync_opts;\n\n//            big_picture.pts= av_rescale(ost->sync_opts, AV_TIME_BASE*(int64_t)enc->time_base.num, enc->time_base.den);\n\n//av_log(NULL, AV_LOG_DEBUG, \"%\"PRId64\" -> encoder\\n\", ost->sync_opts);\n\n            if (ost->forced_kf_index < ost->forced_kf_count &&\n\n                big_picture.pts >= ost->forced_kf_pts[ost->forced_kf_index]) {\n\n                big_picture.pict_type = AV_PICTURE_TYPE_I;\n\n                ost->forced_kf_index++;\n\n            }\n\n            ret = avcodec_encode_video(enc,\n\n                                       bit_buffer, bit_buffer_size,\n\n                                       &big_picture);\n\n            if (ret < 0) {\n\n                fprintf(stderr, \"Video encoding failed\\n\");\n\n                exit_program(1);\n\n            }\n\n\n\n            if(ret>0){\n\n                pkt.data= bit_buffer;\n\n                pkt.size= ret;\n\n                if(enc->coded_frame->pts != AV_NOPTS_VALUE)\n\n                    pkt.pts= av_rescale_q(enc->coded_frame->pts, enc->time_base, ost->st->time_base);\n\n/*av_log(NULL, AV_LOG_DEBUG, \"encoder -> %\"PRId64\"/%\"PRId64\"\\n\",\n\n   pkt.pts != AV_NOPTS_VALUE ? av_rescale(pkt.pts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1,\n\n   pkt.dts != AV_NOPTS_VALUE ? av_rescale(pkt.dts, enc->time_base.den, AV_TIME_BASE*(int64_t)enc->time_base.num) : -1);*/\n\n\n\n                if(enc->coded_frame->key_frame)\n\n                    pkt.flags |= AV_PKT_FLAG_KEY;\n\n                write_frame(s, &pkt, ost->st->codec, ost->bitstream_filters);\n\n                *frame_size = ret;\n\n                video_size += ret;\n\n                //fprintf(stderr,\"\\nFrame: %3d size: %5d type: %d\",\n\n                //        enc->frame_number-1, ret, enc->pict_type);\n\n                /* if two pass, output log */\n\n                if (ost->logfile && enc->stats_out) {\n\n                    fprintf(ost->logfile, \"%s\", enc->stats_out);\n\n                }\n\n            }\n\n        }\n\n        ost->sync_opts++;\n\n        ost->frame_number++;\n\n    }\n\n}\n", "idx": 20129, "_split": "test", "_hash": "5dc12cc7af90831384afb7dc3ae6fe8b"}
{"project": "FFmpeg", "commit_id": "aac0eda40754c010ab5156dcd5d0d1554937e9a7", "target": 0, "func": "static int decode_ics(AACContext * ac, SingleChannelElement * sce, GetBitContext * gb, int common_window, int scale_flag) {\n\n    Pulse pulse;\n\n    TemporalNoiseShaping * tns = &sce->tns;\n\n    IndividualChannelStream * ics = &sce->ics;\n\n    float * out = sce->coeffs;\n\n    int global_gain, pulse_present = 0;\n\n\n\n    /* This assignment is to silence a GCC warning about the variable being used\n\n     * uninitialized when in fact it always is.\n\n     */\n\n    pulse.num_pulse = 0;\n\n\n\n    global_gain = get_bits(gb, 8);\n\n\n\n    if (!common_window && !scale_flag) {\n\n        if (decode_ics_info(ac, ics, gb, 0) < 0)\n\n            return -1;\n\n    }\n\n\n\n    if (decode_band_types(ac, sce->band_type, sce->band_type_run_end, gb, ics) < 0)\n\n        return -1;\n\n    if (decode_scalefactors(ac, sce->sf, gb, global_gain, ics, sce->band_type, sce->band_type_run_end) < 0)\n\n        return -1;\n\n\n\n    pulse_present = 0;\n\n    if (!scale_flag) {\n\n        if ((pulse_present = get_bits1(gb))) {\n\n            if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n                av_log(ac->avccontext, AV_LOG_ERROR, \"Pulse tool not allowed in eight short sequence.\\n\");\n\n                return -1;\n\n            }\n\n            decode_pulses(&pulse, gb, ics->swb_offset);\n\n        }\n\n        if ((tns->present = get_bits1(gb)) && decode_tns(ac, tns, gb, ics))\n\n            return -1;\n\n        if (get_bits1(gb)) {\n\n            av_log_missing_feature(ac->avccontext, \"SSR\", 1);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (decode_spectrum_and_dequant(ac, out, gb, sce->sf, pulse_present, &pulse, ics, sce->band_type) < 0)\n\n        return -1;\n\n    return 0;\n\n}\n", "idx": 20199, "_split": "test", "_hash": "83e976933bcfb4de7a44920bad4fd2ce"}
{"project": "FFmpeg", "commit_id": "b7b8fc340632d15cb3b26a57915ebea84f37d03e", "target": 0, "func": "static int rtsp_read_header(AVFormatContext *s,\n\n                            AVFormatParameters *ap)\n\n{\n\n    RTSPState *rt = s->priv_data;\n\n    char host[1024], path[1024], tcpname[1024], cmd[2048];\n\n    URLContext *rtsp_hd;\n\n    int port, i, ret, err;\n\n    RTSPHeader reply1, *reply = &reply1;\n\n    unsigned char *content = NULL;\n\n    AVStream *st;\n\n    RTSPStream *rtsp_st;\n\n    int protocol_mask;\n\n\n\n    rtsp_abort_req = 0;\n\n    \n\n    /* extract hostname and port */\n\n    url_split(NULL, 0,\n\n              host, sizeof(host), &port, path, sizeof(path), s->filename);\n\n    if (port < 0)\n\n        port = RTSP_DEFAULT_PORT;\n\n\n\n    /* open the tcp connexion */\n\n    snprintf(tcpname, sizeof(tcpname), \"tcp://%s:%d\", host, port);\n\n    if (url_open(&rtsp_hd, tcpname, URL_RDWR) < 0)\n\n        return AVERROR_IO;\n\n    rt->rtsp_hd = rtsp_hd;\n\n    rt->seq = 0;\n\n    \n\n    /* describe the stream */\n\n    snprintf(cmd, sizeof(cmd), \n\n             \"DESCRIBE %s RTSP/1.0\\r\\n\"\n\n             \"Accept: application/sdp\\r\\n\",\n\n             s->filename);\n\n    rtsp_send_cmd(s, cmd, reply, &content);\n\n    if (!content) {\n\n        err = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n    if (reply->status_code != RTSP_STATUS_OK) {\n\n        err = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n        \n\n    /* now we got the SDP description, we parse it */\n\n    ret = sdp_parse(s, (const char *)content);\n\n    av_freep(&content);\n\n    if (ret < 0) {\n\n        err = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n    \n\n    protocol_mask = rtsp_default_protocols;\n\n\n\n    /* for each stream, make the setup request */\n\n    /* XXX: we assume the same server is used for the control of each\n\n       RTSP stream */\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        char transport[2048];\n\n        AVInputFormat *fmt;\n\n\n\n        st = s->streams[i];\n\n        rtsp_st = st->priv_data;\n\n\n\n        /* compute available transports */\n\n        transport[0] = '\\0';\n\n\n\n        /* RTP/UDP */\n\n        if (protocol_mask & (1 << RTSP_PROTOCOL_RTP_UDP)) {\n\n            char buf[256];\n\n            int j;\n\n\n\n            /* first try in specified port range */\n\n            if (rtsp_rtp_port_min != 0) {\n\n                for(j=rtsp_rtp_port_min;j<=rtsp_rtp_port_max;j++) {\n\n                    snprintf(buf, sizeof(buf), \"rtp://?localport=%d\", j);\n\n                    if (!av_open_input_file(&rtsp_st->ic, buf, \n\n                                            &rtp_demux, 0, NULL))\n\n                        goto rtp_opened;\n\n                }\n\n            }\n\n\n\n            /* then try on any port */\n\n            if (av_open_input_file(&rtsp_st->ic, \"rtp://\", \n\n                                       &rtp_demux, 0, NULL) < 0) {\n\n                    err = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n            }\n\n\n\n        rtp_opened:\n\n            port = rtp_get_local_port(url_fileno(&rtsp_st->ic->pb));\n\n            if (transport[0] != '\\0')\n\n                pstrcat(transport, sizeof(transport), \",\");\n\n            snprintf(transport + strlen(transport), sizeof(transport) - strlen(transport) - 1,\n\n                     \"RTP/AVP/UDP;unicast;client_port=%d-%d\",\n\n                     port, port + 1);\n\n        }\n\n\n\n        /* RTP/TCP */\n\n        if (protocol_mask & (1 << RTSP_PROTOCOL_RTP_TCP)) {\n\n            if (transport[0] != '\\0')\n\n                pstrcat(transport, sizeof(transport), \",\");\n\n            snprintf(transport + strlen(transport), sizeof(transport) - strlen(transport) - 1,\n\n                     \"RTP/AVP/TCP\");\n\n        }\n\n\n\n        if (protocol_mask & (1 << RTSP_PROTOCOL_RTP_UDP_MULTICAST)) {\n\n            if (transport[0] != '\\0')\n\n                pstrcat(transport, sizeof(transport), \",\");\n\n            snprintf(transport + strlen(transport), \n\n                     sizeof(transport) - strlen(transport) - 1,\n\n                     \"RTP/AVP/UDP;multicast\");\n\n        }\n\n        snprintf(cmd, sizeof(cmd), \n\n                 \"SETUP %s RTSP/1.0\\r\\n\"\n\n                 \"Transport: %s\\r\\n\",\n\n                 rtsp_st->control_url, transport);\n\n        rtsp_send_cmd(s, cmd, reply, NULL);\n\n        if (reply->status_code != RTSP_STATUS_OK ||\n\n            reply->nb_transports != 1) {\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n\n\n        /* XXX: same protocol for all streams is required */\n\n        if (i > 0) {\n\n            if (reply->transports[0].protocol != rt->protocol) {\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n        } else {\n\n            rt->protocol = reply->transports[0].protocol;\n\n        }\n\n\n\n        /* close RTP connection if not choosen */\n\n        if (reply->transports[0].protocol != RTSP_PROTOCOL_RTP_UDP &&\n\n            (protocol_mask & (1 << RTSP_PROTOCOL_RTP_UDP))) {\n\n            av_close_input_file(rtsp_st->ic);\n\n            rtsp_st->ic = NULL;\n\n        }\n\n\n\n        switch(reply->transports[0].protocol) {\n\n        case RTSP_PROTOCOL_RTP_TCP:\n\n            fmt = &rtp_demux;\n\n            if (av_open_input_file(&rtsp_st->ic, \"null\", fmt, 0, NULL) < 0) {\n\n                err = AVERROR_INVALIDDATA;\n\n                goto fail;\n\n            }\n\n            rtsp_st->interleaved_min = reply->transports[0].interleaved_min;\n\n            rtsp_st->interleaved_max = reply->transports[0].interleaved_max;\n\n            break;\n\n            \n\n        case RTSP_PROTOCOL_RTP_UDP:\n\n            {\n\n                char url[1024];\n\n                \n\n                /* XXX: also use address if specified */\n\n                snprintf(url, sizeof(url), \"rtp://%s:%d\", \n\n                         host, reply->transports[0].server_port_min);\n\n                if (rtp_set_remote_url(url_fileno(&rtsp_st->ic->pb), url) < 0) {\n\n                    err = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n                }\n\n            }\n\n            break;\n\n        case RTSP_PROTOCOL_RTP_UDP_MULTICAST:\n\n            {\n\n                char url[1024];\n\n                int ttl;\n\n\n\n                fmt = &rtp_demux;\n\n                ttl = reply->transports[0].ttl;\n\n                if (!ttl)\n\n                    ttl = 16;\n\n                snprintf(url, sizeof(url), \"rtp://%s:%d?multicast=1&ttl=%d\", \n\n                         host, \n\n                         reply->transports[0].server_port_min,\n\n                         ttl);\n\n                if (av_open_input_file(&rtsp_st->ic, url, fmt, 0, NULL) < 0) {\n\n                    err = AVERROR_INVALIDDATA;\n\n                    goto fail;\n\n                }\n\n            }\n\n            break;\n\n        }\n\n    }\n\n\n\n    /* use callback if available to extend setup */\n\n    if (ff_rtsp_callback) {\n\n        if (ff_rtsp_callback(RTSP_ACTION_CLIENT_SETUP, rt->session_id, \n\n                             NULL, 0, rt->last_reply) < 0) {\n\n            err = AVERROR_INVALIDDATA;\n\n            goto fail;\n\n        }\n\n    }\n\n                         \n\n    /* start playing */\n\n    snprintf(cmd, sizeof(cmd), \n\n             \"PLAY %s RTSP/1.0\\r\\n\"\n\n             \"Range: npt=0-\\r\\n\",\n\n             s->filename);\n\n    rtsp_send_cmd(s, cmd, reply, NULL);\n\n    if (reply->status_code != RTSP_STATUS_OK) {\n\n        err = AVERROR_INVALIDDATA;\n\n        goto fail;\n\n    }\n\n\n\n#if 0\n\n    /* open TCP with bufferized input */\n\n    if (rt->protocol == RTSP_PROTOCOL_RTP_TCP) {\n\n        if (url_fdopen(&rt->rtsp_gb, rt->rtsp_hd) < 0) {\n\n            err = AVERROR_NOMEM;\n\n            goto fail;\n\n        }\n\n    }\n\n#endif\n\n\n\n    return 0;\n\n fail:\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        st = s->streams[i];\n\n        rtsp_st = st->priv_data;\n\n        if (rtsp_st) {\n\n            if (rtsp_st->ic)\n\n                av_close_input_file(rtsp_st->ic);\n\n        }\n\n        av_free(rtsp_st);\n\n    }\n\n    av_freep(&content);\n\n    url_close(rt->rtsp_hd);\n\n    return err;\n\n}\n", "idx": 20237, "_split": "test", "_hash": "4fd2b9baf621841a18df8086e1475940"}
{"project": "FFmpeg", "commit_id": "099d6813c27faf95257a529aa2c65dfde816a487", "target": 1, "func": "int ff_h264_alloc_tables(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    const int big_mb_num= s->mb_stride * (s->mb_height+1);\n\n    const int row_mb_num= 2*s->mb_stride*s->avctx->thread_count;\n\n    int x,y;\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->intra4x4_pred_mode, row_mb_num * 8  * sizeof(uint8_t), fail)\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->non_zero_count    , big_mb_num * 48 * sizeof(uint8_t), fail)\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->slice_table_base  , (big_mb_num+s->mb_stride) * sizeof(*h->slice_table_base), fail)\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->cbp_table, big_mb_num * sizeof(uint16_t), fail)\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->chroma_pred_mode_table, big_mb_num * sizeof(uint8_t), fail)\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mvd_table[0], 16*row_mb_num * sizeof(uint8_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mvd_table[1], 16*row_mb_num * sizeof(uint8_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->direct_table, 4*big_mb_num * sizeof(uint8_t) , fail);\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->list_counts, big_mb_num * sizeof(uint8_t), fail)\n\n\n\n    memset(h->slice_table_base, -1, (big_mb_num+s->mb_stride)  * sizeof(*h->slice_table_base));\n\n    h->slice_table= h->slice_table_base + s->mb_stride*2 + 1;\n\n\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mb2b_xy  , big_mb_num * sizeof(uint32_t), fail);\n\n    FF_ALLOCZ_OR_GOTO(h->s.avctx, h->mb2br_xy , big_mb_num * sizeof(uint32_t), fail);\n\n    for(y=0; y<s->mb_height; y++){\n\n        for(x=0; x<s->mb_width; x++){\n\n            const int mb_xy= x + y*s->mb_stride;\n\n            const int b_xy = 4*x + 4*y*h->b_stride;\n\n\n\n            h->mb2b_xy [mb_xy]= b_xy;\n\n            h->mb2br_xy[mb_xy]= 8*(FMO ? mb_xy : (mb_xy % (2*s->mb_stride)));\n\n        }\n\n    }\n\n\n\n    s->obmc_scratchpad = NULL;\n\n\n\n    if(!h->dequant4_coeff[0])\n\n        init_dequant_tables(h);\n\n\n\n    return 0;\n\nfail:\n\n    free_tables(h, 1);\n\n    return -1;\n\n}\n", "idx": 20305, "_split": "test", "_hash": "feb4cb35b4a1c74537ff5ada7c355398"}
{"project": "FFmpeg", "commit_id": "3583eb93410a73cac8ddf291baa405005ff4c405", "target": 0, "func": "static inline CopyRet copy_frame(AVCodecContext *avctx,\n\n                                 BC_DTS_PROC_OUT *output,\n\n                                 void *data, int *data_size,\n\n                                 uint8_t second_field)\n\n{\n\n    BC_STATUS ret;\n\n    BC_DTS_STATUS decoder_status;\n\n    uint8_t is_paff;\n\n    uint8_t next_frame_same;\n\n    uint8_t interlaced;\n\n\n\n    CHDContext *priv = avctx->priv_data;\n\n\n\n    uint8_t bottom_field = (output->PicInfo.flags & VDEC_FLAG_BOTTOMFIELD) ==\n\n                           VDEC_FLAG_BOTTOMFIELD;\n\n    uint8_t bottom_first = !!(output->PicInfo.flags & VDEC_FLAG_BOTTOM_FIRST);\n\n\n\n    int width    = output->PicInfo.width;\n\n    int height   = output->PicInfo.height;\n\n    int bwidth;\n\n    uint8_t *src = output->Ybuff;\n\n    int sStride;\n\n    uint8_t *dst;\n\n    int dStride;\n\n\n\n    ret = DtsGetDriverStatus(priv->dev, &decoder_status);\n\n    if (ret != BC_STS_SUCCESS) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"CrystalHD: GetDriverStatus failed: %u\\n\", ret);\n\n       return RET_ERROR;\n\n    }\n\n\n\n    is_paff           = ASSUME_PAFF_OVER_MBAFF ||\n\n                        !(output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC);\n\n    next_frame_same   = output->PicInfo.picture_number ==\n\n                        (decoder_status.picNumFlags & ~0x40000000);\n\n    interlaced        = ((output->PicInfo.flags &\n\n                          VDEC_FLAG_INTERLACED_SRC) && is_paff) ||\n\n                         next_frame_same || bottom_field || second_field;\n\n\n\n    av_log(avctx, AV_LOG_VERBOSE, \"CrystalHD: next_frame_same: %u | %u | %u\\n\",\n\n           next_frame_same, output->PicInfo.picture_number,\n\n           decoder_status.picNumFlags & ~0x40000000);\n\n\n\n    if (priv->pic.data[0] && !priv->need_second_field)\n\n        avctx->release_buffer(avctx, &priv->pic);\n\n\n\n    priv->need_second_field = interlaced && !priv->need_second_field;\n\n\n\n    priv->pic.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE |\n\n                             FF_BUFFER_HINTS_REUSABLE;\n\n    if (!priv->pic.data[0]) {\n\n        if (avctx->get_buffer(avctx, &priv->pic) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n            return RET_ERROR;\n\n        }\n\n    }\n\n\n\n    bwidth = av_image_get_linesize(avctx->pix_fmt, width, 0);\n\n    if (priv->is_70012) {\n\n        int pStride;\n\n\n\n        if (width <= 720)\n\n            pStride = 720;\n\n        else if (width <= 1280)\n\n            pStride = 1280;\n\n        else if (width <= 1080)\n\n            pStride = 1080;\n\n        sStride = av_image_get_linesize(avctx->pix_fmt, pStride, 0);\n\n    } else {\n\n        sStride = bwidth;\n\n    }\n\n\n\n    dStride = priv->pic.linesize[0];\n\n    dst     = priv->pic.data[0];\n\n\n\n    av_log(priv->avctx, AV_LOG_VERBOSE, \"CrystalHD: Copying out frame\\n\");\n\n\n\n    if (interlaced) {\n\n        int dY = 0;\n\n        int sY = 0;\n\n\n\n        height /= 2;\n\n        if (bottom_field) {\n\n            av_log(priv->avctx, AV_LOG_VERBOSE, \"Interlaced: bottom field\\n\");\n\n            dY = 1;\n\n        } else {\n\n            av_log(priv->avctx, AV_LOG_VERBOSE, \"Interlaced: top field\\n\");\n\n            dY = 0;\n\n        }\n\n\n\n        for (sY = 0; sY < height; dY++, sY++) {\n\n            memcpy(&(dst[dY * dStride]), &(src[sY * sStride]), bwidth);\n\n            if (interlaced)\n\n                dY++;\n\n        }\n\n    } else {\n\n        av_image_copy_plane(dst, dStride, src, sStride, bwidth, height);\n\n    }\n\n\n\n    priv->pic.interlaced_frame = interlaced;\n\n    if (interlaced)\n\n        priv->pic.top_field_first = !bottom_first;\n\n\n\n    if (output->PicInfo.timeStamp != 0) {\n\n        priv->pic.pkt_pts = opaque_list_pop(priv, output->PicInfo.timeStamp);\n\n        av_log(avctx, AV_LOG_VERBOSE, \"output \\\"pts\\\": %\"PRIu64\"\\n\",\n\n               priv->pic.pkt_pts);\n\n    }\n\n\n\n    if (!priv->need_second_field) {\n\n        *data_size       = sizeof(AVFrame);\n\n        *(AVFrame *)data = priv->pic;\n\n    }\n\n\n\n    if (ASSUME_TWO_INPUTS_ONE_OUTPUT &&\n\n        output->PicInfo.flags & VDEC_FLAG_UNKNOWN_SRC) {\n\n        av_log(priv->avctx, AV_LOG_VERBOSE, \"Fieldpair from two packets.\\n\");\n\n        return RET_SKIP_NEXT_COPY;\n\n    }\n\n\n\n    return RET_OK;\n\n}\n", "idx": 20320, "_split": "test", "_hash": "2dc09862bcd5ea77b9caf55c19905eb6"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuv2yuv1)(SwsContext *c, const int16_t *lumSrc, const int16_t *chrSrc, const int16_t *alpSrc,\n\n                                    uint8_t *dest, uint8_t *uDest, uint8_t *vDest, uint8_t *aDest, long dstW, long chrDstW)\n\n{\n\n    int i;\n\n#if COMPILE_TEMPLATE_MMX\n\n    if(!(c->flags & SWS_BITEXACT)) {\n\n        long p= 4;\n\n        const int16_t *src[4]= {alpSrc + dstW, lumSrc + dstW, chrSrc + chrDstW, chrSrc + VOFW + chrDstW};\n\n        uint8_t *dst[4]= {aDest, dest, uDest, vDest};\n\n        x86_reg counter[4]= {dstW, dstW, chrDstW, chrDstW};\n\n\n\n        if (c->flags & SWS_ACCURATE_RND) {\n\n            while(p--) {\n\n                if (dst[p]) {\n\n                    __asm__ volatile(\n\n                        YSCALEYUV2YV121_ACCURATE\n\n                        :: \"r\" (src[p]), \"r\" (dst[p] + counter[p]),\n\n                        \"g\" (-counter[p])\n\n                        : \"%\"REG_a\n\n                    );\n\n                }\n\n            }\n\n        } else {\n\n            while(p--) {\n\n                if (dst[p]) {\n\n                    __asm__ volatile(\n\n                        YSCALEYUV2YV121\n\n                        :: \"r\" (src[p]), \"r\" (dst[p] + counter[p]),\n\n                        \"g\" (-counter[p])\n\n                        : \"%\"REG_a\n\n                    );\n\n                }\n\n            }\n\n        }\n\n        return;\n\n    }\n\n#endif\n\n    for (i=0; i<dstW; i++) {\n\n        int val= (lumSrc[i]+64)>>7;\n\n\n\n        if (val&256) {\n\n            if (val<0) val=0;\n\n            else       val=255;\n\n        }\n\n\n\n        dest[i]= val;\n\n    }\n\n\n\n    if (uDest)\n\n        for (i=0; i<chrDstW; i++) {\n\n            int u=(chrSrc[i       ]+64)>>7;\n\n            int v=(chrSrc[i + VOFW]+64)>>7;\n\n\n\n            if ((u|v)&256) {\n\n                if (u<0)        u=0;\n\n                else if (u>255) u=255;\n\n                if (v<0)        v=0;\n\n                else if (v>255) v=255;\n\n            }\n\n\n\n            uDest[i]= u;\n\n            vDest[i]= v;\n\n        }\n\n\n\n    if (CONFIG_SWSCALE_ALPHA && aDest)\n\n        for (i=0; i<dstW; i++) {\n\n            int val= (alpSrc[i]+64)>>7;\n\n            aDest[i]= av_clip_uint8(val);\n\n        }\n\n}\n", "idx": 20338, "_split": "test", "_hash": "3b690119f2ae80e1b4e84cc461cc3a7d"}
{"project": "FFmpeg", "commit_id": "70b1dcef2d859ae6b3e21d61de928c3dd0cf1aa4", "target": 0, "func": "int ff_h264_decode_seq_parameter_set(GetBitContext *gb, AVCodecContext *avctx,\n\n                                     H264ParamSets *ps)\n\n{\n\n    AVBufferRef *sps_buf;\n\n    int profile_idc, level_idc, constraint_set_flags = 0;\n\n    unsigned int sps_id;\n\n    int i, log2_max_frame_num_minus4;\n\n    SPS *sps;\n\n\n\n    profile_idc           = get_bits(gb, 8);\n\n    constraint_set_flags |= get_bits1(gb) << 0;   // constraint_set0_flag\n\n    constraint_set_flags |= get_bits1(gb) << 1;   // constraint_set1_flag\n\n    constraint_set_flags |= get_bits1(gb) << 2;   // constraint_set2_flag\n\n    constraint_set_flags |= get_bits1(gb) << 3;   // constraint_set3_flag\n\n    constraint_set_flags |= get_bits1(gb) << 4;   // constraint_set4_flag\n\n    constraint_set_flags |= get_bits1(gb) << 5;   // constraint_set5_flag\n\n    skip_bits(gb, 2);                             // reserved_zero_2bits\n\n    level_idc = get_bits(gb, 8);\n\n    sps_id    = get_ue_golomb_31(gb);\n\n\n\n    if (sps_id >= MAX_SPS_COUNT) {\n\n        av_log(avctx, AV_LOG_ERROR, \"sps_id %u out of range\\n\", sps_id);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    sps_buf = av_buffer_allocz(sizeof(*sps));\n\n    if (!sps_buf)\n\n        return AVERROR(ENOMEM);\n\n    sps = (SPS*)sps_buf->data;\n\n\n\n    sps->sps_id               = sps_id;\n\n    sps->time_offset_length   = 24;\n\n    sps->profile_idc          = profile_idc;\n\n    sps->constraint_set_flags = constraint_set_flags;\n\n    sps->level_idc            = level_idc;\n\n\n\n    memset(sps->scaling_matrix4, 16, sizeof(sps->scaling_matrix4));\n\n    memset(sps->scaling_matrix8, 16, sizeof(sps->scaling_matrix8));\n\n    sps->scaling_matrix_present = 0;\n\n\n\n    if (sps->profile_idc == 100 ||  // High profile\n\n        sps->profile_idc == 110 ||  // High10 profile\n\n        sps->profile_idc == 122 ||  // High422 profile\n\n        sps->profile_idc == 244 ||  // High444 Predictive profile\n\n        sps->profile_idc ==  44 ||  // Cavlc444 profile\n\n        sps->profile_idc ==  83 ||  // Scalable Constrained High profile (SVC)\n\n        sps->profile_idc ==  86 ||  // Scalable High Intra profile (SVC)\n\n        sps->profile_idc == 118 ||  // Stereo High profile (MVC)\n\n        sps->profile_idc == 128 ||  // Multiview High profile (MVC)\n\n        sps->profile_idc == 138 ||  // Multiview Depth High profile (MVCD)\n\n        sps->profile_idc == 144) {  // old High444 profile\n\n        sps->chroma_format_idc = get_ue_golomb_31(gb);\n\n        if (sps->chroma_format_idc > 3) {\n\n            avpriv_request_sample(avctx, \"chroma_format_idc %u\",\n\n                                  sps->chroma_format_idc);\n\n            goto fail;\n\n        } else if (sps->chroma_format_idc == 3) {\n\n            sps->residual_color_transform_flag = get_bits1(gb);\n\n        }\n\n        sps->bit_depth_luma   = get_ue_golomb(gb) + 8;\n\n        sps->bit_depth_chroma = get_ue_golomb(gb) + 8;\n\n        if (sps->bit_depth_chroma != sps->bit_depth_luma) {\n\n            avpriv_request_sample(avctx,\n\n                                  \"Different chroma and luma bit depth\");\n\n            goto fail;\n\n        }\n\n        sps->transform_bypass = get_bits1(gb);\n\n        decode_scaling_matrices(gb, sps, NULL, 1,\n\n                                sps->scaling_matrix4, sps->scaling_matrix8);\n\n    } else {\n\n        sps->chroma_format_idc = 1;\n\n        sps->bit_depth_luma    = 8;\n\n        sps->bit_depth_chroma  = 8;\n\n    }\n\n\n\n    log2_max_frame_num_minus4 = get_ue_golomb(gb);\n\n    if (log2_max_frame_num_minus4 < MIN_LOG2_MAX_FRAME_NUM - 4 ||\n\n        log2_max_frame_num_minus4 > MAX_LOG2_MAX_FRAME_NUM - 4) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"log2_max_frame_num_minus4 out of range (0-12): %d\\n\",\n\n               log2_max_frame_num_minus4);\n\n        goto fail;\n\n    }\n\n    sps->log2_max_frame_num = log2_max_frame_num_minus4 + 4;\n\n\n\n    sps->poc_type = get_ue_golomb_31(gb);\n\n\n\n    if (sps->poc_type == 0) { // FIXME #define\n\n        sps->log2_max_poc_lsb = get_ue_golomb(gb) + 4;\n\n    } else if (sps->poc_type == 1) { // FIXME #define\n\n        sps->delta_pic_order_always_zero_flag = get_bits1(gb);\n\n        sps->offset_for_non_ref_pic           = get_se_golomb(gb);\n\n        sps->offset_for_top_to_bottom_field   = get_se_golomb(gb);\n\n        sps->poc_cycle_length                 = get_ue_golomb(gb);\n\n\n\n        if ((unsigned)sps->poc_cycle_length >=\n\n            FF_ARRAY_ELEMS(sps->offset_for_ref_frame)) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"poc_cycle_length overflow %d\\n\", sps->poc_cycle_length);\n\n            goto fail;\n\n        }\n\n\n\n        for (i = 0; i < sps->poc_cycle_length; i++)\n\n            sps->offset_for_ref_frame[i] = get_se_golomb(gb);\n\n    } else if (sps->poc_type != 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"illegal POC type %d\\n\", sps->poc_type);\n\n        goto fail;\n\n    }\n\n\n\n    sps->ref_frame_count = get_ue_golomb_31(gb);\n\n    if (sps->ref_frame_count > H264_MAX_PICTURE_COUNT - 2 ||\n\n        sps->ref_frame_count >= 32U) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"too many reference frames %d\\n\", sps->ref_frame_count);\n\n        goto fail;\n\n    }\n\n    sps->gaps_in_frame_num_allowed_flag = get_bits1(gb);\n\n    sps->mb_width                       = get_ue_golomb(gb) + 1;\n\n    sps->mb_height                      = get_ue_golomb(gb) + 1;\n\n    if ((unsigned)sps->mb_width  >= INT_MAX / 16 ||\n\n        (unsigned)sps->mb_height >= INT_MAX / 16 ||\n\n        av_image_check_size(16 * sps->mb_width,\n\n                            16 * sps->mb_height, 0, avctx)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"mb_width/height overflow\\n\");\n\n        goto fail;\n\n    }\n\n\n\n    sps->frame_mbs_only_flag = get_bits1(gb);\n\n    if (!sps->frame_mbs_only_flag)\n\n        sps->mb_aff = get_bits1(gb);\n\n    else\n\n        sps->mb_aff = 0;\n\n\n\n    sps->direct_8x8_inference_flag = get_bits1(gb);\n\n    if (!sps->frame_mbs_only_flag && !sps->direct_8x8_inference_flag) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"This stream was generated by a broken encoder, invalid 8x8 inference\\n\");\n\n        goto fail;\n\n    }\n\n\n\n#ifndef ALLOW_INTERLACE\n\n    if (sps->mb_aff)\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"MBAFF support not included; enable it at compile-time.\\n\");\n\n#endif\n\n    sps->crop = get_bits1(gb);\n\n    if (sps->crop) {\n\n        unsigned int crop_left   = get_ue_golomb(gb);\n\n        unsigned int crop_right  = get_ue_golomb(gb);\n\n        unsigned int crop_top    = get_ue_golomb(gb);\n\n        unsigned int crop_bottom = get_ue_golomb(gb);\n\n\n\n        if (avctx->flags2 & AV_CODEC_FLAG2_IGNORE_CROP) {\n\n            av_log(avctx, AV_LOG_DEBUG, \"discarding sps cropping, original \"\n\n                                           \"values are l:%d r:%d t:%d b:%d\\n\",\n\n                   crop_left, crop_right, crop_top, crop_bottom);\n\n\n\n            sps->crop_left   =\n\n            sps->crop_right  =\n\n            sps->crop_top    =\n\n            sps->crop_bottom = 0;\n\n        } else {\n\n            int vsub   = (sps->chroma_format_idc == 1) ? 1 : 0;\n\n            int hsub   = (sps->chroma_format_idc == 1 ||\n\n                          sps->chroma_format_idc == 2) ? 1 : 0;\n\n            int step_x = 1 << hsub;\n\n            int step_y = (2 - sps->frame_mbs_only_flag) << vsub;\n\n\n\n            if (crop_left & (0x1F >> (sps->bit_depth_luma > 8)) &&\n\n                !(avctx->flags & AV_CODEC_FLAG_UNALIGNED)) {\n\n                crop_left &= ~(0x1F >> (sps->bit_depth_luma > 8));\n\n                av_log(avctx, AV_LOG_WARNING,\n\n                       \"Reducing left cropping to %d \"\n\n                       \"chroma samples to preserve alignment.\\n\",\n\n                       crop_left);\n\n            }\n\n\n\n            if (INT_MAX / step_x             <= crop_left               ||\n\n                INT_MAX / step_x - crop_left <= crop_right              ||\n\n                16 * sps->mb_width <= step_x * (crop_left + crop_right) ||\n\n                INT_MAX / step_y             <= crop_top                ||\n\n                INT_MAX / step_y - crop_top  <= crop_bottom             ||\n\n                16 * sps->mb_height <= step_y * (crop_top + crop_bottom)) {\n\n                av_log(avctx, AV_LOG_WARNING, \"Invalid crop parameters\\n\");\n\n                if (avctx->err_recognition & AV_EF_EXPLODE)\n\n                    goto fail;\n\n                crop_left = crop_right = crop_top = crop_bottom = 0;\n\n            }\n\n\n\n            sps->crop_left   = crop_left   * step_x;\n\n            sps->crop_right  = crop_right  * step_x;\n\n            sps->crop_top    = crop_top    * step_y;\n\n            sps->crop_bottom = crop_bottom * step_y;\n\n        }\n\n    } else {\n\n        sps->crop_left   =\n\n        sps->crop_right  =\n\n        sps->crop_top    =\n\n        sps->crop_bottom =\n\n        sps->crop        = 0;\n\n    }\n\n\n\n    sps->vui_parameters_present_flag = get_bits1(gb);\n\n    if (sps->vui_parameters_present_flag) {\n\n        int ret = decode_vui_parameters(gb, avctx, sps);\n\n        if (ret < 0 && avctx->err_recognition & AV_EF_EXPLODE)\n\n            goto fail;\n\n    }\n\n\n\n    /* if the maximum delay is not stored in the SPS, derive it based on the\n\n     * level */\n\n    if (!sps->bitstream_restriction_flag &&\n\n        (sps->ref_frame_count || avctx->strict_std_compliance >= FF_COMPLIANCE_STRICT)) {\n\n        sps->num_reorder_frames = MAX_DELAYED_PIC_COUNT - 1;\n\n        for (i = 0; i < FF_ARRAY_ELEMS(level_max_dpb_mbs); i++) {\n\n            if (level_max_dpb_mbs[i][0] == sps->level_idc) {\n\n                sps->num_reorder_frames = FFMIN(level_max_dpb_mbs[i][1] / (sps->mb_width * sps->mb_height),\n\n                                                sps->num_reorder_frames);\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (!sps->sar.den)\n\n        sps->sar.den = 1;\n\n\n\n    if (avctx->debug & FF_DEBUG_PICT_INFO) {\n\n        static const char csp[4][5] = { \"Gray\", \"420\", \"422\", \"444\" };\n\n        av_log(avctx, AV_LOG_DEBUG,\n\n               \"sps:%u profile:%d/%d poc:%d ref:%d %dx%d %s %s crop:%u/%u/%u/%u %s %s %\"PRId32\"/%\"PRId32\"\\n\",\n\n               sps_id, sps->profile_idc, sps->level_idc,\n\n               sps->poc_type,\n\n               sps->ref_frame_count,\n\n               sps->mb_width, sps->mb_height,\n\n               sps->frame_mbs_only_flag ? \"FRM\" : (sps->mb_aff ? \"MB-AFF\" : \"PIC-AFF\"),\n\n               sps->direct_8x8_inference_flag ? \"8B8\" : \"\",\n\n               sps->crop_left, sps->crop_right,\n\n               sps->crop_top, sps->crop_bottom,\n\n               sps->vui_parameters_present_flag ? \"VUI\" : \"\",\n\n               csp[sps->chroma_format_idc],\n\n               sps->timing_info_present_flag ? sps->num_units_in_tick : 0,\n\n               sps->timing_info_present_flag ? sps->time_scale : 0);\n\n    }\n\n\n\n    /* check if this is a repeat of an already parsed SPS, then keep the\n\n     * original one.\n\n     * otherwise drop all PPSes that depend on it */\n\n    if (ps->sps_list[sps_id] &&\n\n        !memcmp(ps->sps_list[sps_id]->data, sps_buf->data, sps_buf->size)) {\n\n        av_buffer_unref(&sps_buf);\n\n    } else {\n\n        remove_sps(ps, sps_id);\n\n        ps->sps_list[sps_id] = sps_buf;\n\n    }\n\n\n\n    return 0;\n\n\n\nfail:\n\n    av_buffer_unref(&sps_buf);\n\n    return AVERROR_INVALIDDATA;\n\n}\n", "idx": 20352, "_split": "test", "_hash": "bae2a655d0c81b5741503cd01736f832"}
{"project": "FFmpeg", "commit_id": "5d7e3d71673d64a16b58430a0027afadb6b3a54e", "target": 1, "func": "static int seqvideo_decode_frame(AVCodecContext *avctx,\n\n                                 void *data, int *data_size,\n\n                                 AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n\n\n    SeqVideoContext *seq = avctx->priv_data;\n\n\n\n    seq->frame.reference = 1;\n\n    seq->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &seq->frame)) {\n\n        av_log(seq->avctx, AV_LOG_ERROR, \"tiertexseqvideo: reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    seqvideo_decode(seq, buf, buf_size);\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame *)data = seq->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 20422, "_split": "test", "_hash": "a3db3903eb58217cc36483b15bc54816"}
{"project": "FFmpeg", "commit_id": "183216b21870f21c86c904a7530d53682d7db46d", "target": 1, "func": "static void * attribute_align_arg worker(void *v){\n\n    AVCodecContext *avctx = v;\n\n    ThreadContext *c = avctx->internal->frame_thread_encoder;\n\n    AVPacket *pkt = NULL;\n\n\n\n    while(!c->exit){\n\n        int got_packet, ret;\n\n        AVFrame *frame;\n\n        Task task;\n\n\n\n        if(!pkt) pkt= av_mallocz(sizeof(*pkt));\n\n        if(!pkt) continue;\n\n        av_init_packet(pkt);\n\n\n\n        pthread_mutex_lock(&c->task_fifo_mutex);\n\n        while (av_fifo_size(c->task_fifo) <= 0 || c->exit) {\n\n            if(c->exit){\n\n                pthread_mutex_unlock(&c->task_fifo_mutex);\n\n                goto end;\n\n            }\n\n            pthread_cond_wait(&c->task_fifo_cond, &c->task_fifo_mutex);\n\n        }\n\n        av_fifo_generic_read(c->task_fifo, &task, sizeof(task), NULL);\n\n        pthread_mutex_unlock(&c->task_fifo_mutex);\n\n        frame = task.indata;\n\n\n\n        ret = avcodec_encode_video2(avctx, pkt, frame, &got_packet);\n\n        pthread_mutex_lock(&c->buffer_mutex);\n\n        av_frame_unref(frame);\n\n        pthread_mutex_unlock(&c->buffer_mutex);\n\n        av_frame_free(&frame);\n\n        if(got_packet) {\n\n            int ret2 = av_dup_packet(pkt);\n\n            if (ret >= 0 && ret2 < 0)\n\n                ret = ret2;\n\n        } else {\n\n            pkt->data = NULL;\n\n            pkt->size = 0;\n\n        }\n\n        pthread_mutex_lock(&c->finished_task_mutex);\n\n        c->finished_tasks[task.index].outdata = pkt; pkt = NULL;\n\n        c->finished_tasks[task.index].return_code = ret;\n\n        pthread_cond_signal(&c->finished_task_cond);\n\n        pthread_mutex_unlock(&c->finished_task_mutex);\n\n    }\n\nend:\n\n    av_free(pkt);\n\n    pthread_mutex_lock(&c->buffer_mutex);\n\n    avcodec_close(avctx);\n\n    pthread_mutex_unlock(&c->buffer_mutex);\n\n    av_freep(&avctx);\n\n    return NULL;\n\n}\n", "idx": 20457, "_split": "test", "_hash": "8b0188fbbb963fdd5fb491cc7cd4c382"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "void ff_h264_init_dequant_tables(H264Context *h)\n\n{\n\n    int i, x;\n\n    init_dequant4_coeff_table(h);\n\n    if (h->pps.transform_8x8_mode)\n\n        init_dequant8_coeff_table(h);\n\n    if (h->sps.transform_bypass) {\n\n        for (i = 0; i < 6; i++)\n\n            for (x = 0; x < 16; x++)\n\n                h->dequant4_coeff[i][0][x] = 1 << 6;\n\n        if (h->pps.transform_8x8_mode)\n\n            for (i = 0; i < 6; i++)\n\n                for (x = 0; x < 64; x++)\n\n                    h->dequant8_coeff[i][0][x] = 1 << 6;\n\n    }\n\n}\n", "idx": 20534, "_split": "test", "_hash": "ff7bd3cd7e5342189687d9c4e89ad3bb"}
{"project": "FFmpeg", "commit_id": "2df0c32ea12ddfa72ba88309812bfb13b674130f", "target": 0, "func": "static av_cold int g722_encode_init(AVCodecContext * avctx)\n\n{\n\n    G722Context *c = avctx->priv_data;\n\n    int ret;\n\n\n\n    if (avctx->channels != 1) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono tracks are allowed.\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    c->band[0].scale_factor = 8;\n\n    c->band[1].scale_factor = 2;\n\n    c->prev_samples_pos = 22;\n\n\n\n    if (avctx->trellis) {\n\n        int frontier = 1 << avctx->trellis;\n\n        int max_paths = frontier * FREEZE_INTERVAL;\n\n        int i;\n\n        for (i = 0; i < 2; i++) {\n\n            c->paths[i] = av_mallocz(max_paths * sizeof(**c->paths));\n\n            c->node_buf[i] = av_mallocz(2 * frontier * sizeof(**c->node_buf));\n\n            c->nodep_buf[i] = av_mallocz(2 * frontier * sizeof(**c->nodep_buf));\n\n            if (!c->paths[i] || !c->node_buf[i] || !c->nodep_buf[i]) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto error;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (avctx->frame_size) {\n\n        /* validate frame size */\n\n        if (avctx->frame_size & 1 || avctx->frame_size > MAX_FRAME_SIZE) {\n\n            int new_frame_size;\n\n\n\n            if (avctx->frame_size == 1)\n\n                new_frame_size = 2;\n\n            else if (avctx->frame_size > MAX_FRAME_SIZE)\n\n                new_frame_size = MAX_FRAME_SIZE;\n\n            else\n\n                new_frame_size = avctx->frame_size - 1;\n\n\n\n            av_log(avctx, AV_LOG_WARNING, \"Requested frame size is not \"\n\n                   \"allowed. Using %d instead of %d\\n\", new_frame_size,\n\n                   avctx->frame_size);\n\n            avctx->frame_size = new_frame_size;\n\n        }\n\n    } else {\n\n        /* This is arbitrary. We use 320 because it's 20ms @ 16kHz, which is\n\n           a common packet size for VoIP applications */\n\n        avctx->frame_size = 320;\n\n    }\n\n    avctx->delay = 22;\n\n\n\n    if (avctx->trellis) {\n\n        /* validate trellis */\n\n        if (avctx->trellis < MIN_TRELLIS || avctx->trellis > MAX_TRELLIS) {\n\n            int new_trellis = av_clip(avctx->trellis, MIN_TRELLIS, MAX_TRELLIS);\n\n            av_log(avctx, AV_LOG_WARNING, \"Requested trellis value is not \"\n\n                   \"allowed. Using %d instead of %d\\n\", new_trellis,\n\n                   avctx->trellis);\n\n            avctx->trellis = new_trellis;\n\n        }\n\n    }\n\n\n\n    return 0;\n\nerror:\n\n    g722_encode_close(avctx);\n\n    return ret;\n\n}\n", "idx": 20541, "_split": "test", "_hash": "f7b01f9db2705e9b1e82189cd69b5b72"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static void RENAME(chrRangeToJpeg)(int16_t *dst, int width)\n\n{\n\n    int i;\n\n    for (i = 0; i < width; i++) {\n\n        dst[i     ] = (FFMIN(dst[i     ],30775)*4663 - 9289992)>>12; //-264\n\n        dst[i+VOFW] = (FFMIN(dst[i+VOFW],30775)*4663 - 9289992)>>12; //-264\n\n    }\n\n}\n", "idx": 20581, "_split": "test", "_hash": "7ef88839aa19a2effef985004fa6b4e6"}
{"project": "FFmpeg", "commit_id": "6fd00e9dd94ac3aecf4fa14ca6fa23c395215ac9", "target": 1, "func": "static int decode_pce(AVCodecContext *avctx, MPEG4AudioConfig *m4ac,\n\n                      enum ChannelPosition new_che_pos[4][MAX_ELEM_ID],\n\n                      GetBitContext *gb)\n\n{\n\n    int num_front, num_side, num_back, num_lfe, num_assoc_data, num_cc, sampling_index;\n\n    int comment_len;\n\n\n\n    skip_bits(gb, 2);  // object_type\n\n\n\n    sampling_index = get_bits(gb, 4);\n\n    if (m4ac->sampling_index != sampling_index)\n\n        av_log(avctx, AV_LOG_WARNING, \"Sample rate index in program config element does not match the sample rate index configured by the container.\\n\");\n\n\n\n    num_front       = get_bits(gb, 4);\n\n    num_side        = get_bits(gb, 4);\n\n    num_back        = get_bits(gb, 4);\n\n    num_lfe         = get_bits(gb, 2);\n\n    num_assoc_data  = get_bits(gb, 3);\n\n    num_cc          = get_bits(gb, 4);\n\n\n\n    if (get_bits1(gb))\n\n        skip_bits(gb, 4); // mono_mixdown_tag\n\n    if (get_bits1(gb))\n\n        skip_bits(gb, 4); // stereo_mixdown_tag\n\n\n\n    if (get_bits1(gb))\n\n        skip_bits(gb, 3); // mixdown_coeff_index and pseudo_surround\n\n\n\n\n\n\n\n    decode_channel_map(new_che_pos[TYPE_CPE], new_che_pos[TYPE_SCE], AAC_CHANNEL_FRONT, gb, num_front);\n\n    decode_channel_map(new_che_pos[TYPE_CPE], new_che_pos[TYPE_SCE], AAC_CHANNEL_SIDE,  gb, num_side );\n\n    decode_channel_map(new_che_pos[TYPE_CPE], new_che_pos[TYPE_SCE], AAC_CHANNEL_BACK,  gb, num_back );\n\n    decode_channel_map(NULL,                  new_che_pos[TYPE_LFE], AAC_CHANNEL_LFE,   gb, num_lfe  );\n\n\n\n    skip_bits_long(gb, 4 * num_assoc_data);\n\n\n\n    decode_channel_map(new_che_pos[TYPE_CCE], new_che_pos[TYPE_CCE], AAC_CHANNEL_CC,    gb, num_cc   );\n\n\n\n    align_get_bits(gb);\n\n\n\n    /* comment field, first byte is length */\n\n    comment_len = get_bits(gb, 8) * 8;\n\n    if (get_bits_left(gb) < comment_len) {\n\n\n\n\n    skip_bits_long(gb, comment_len);\n\n    return 0;\n", "idx": 20600, "_split": "test", "_hash": "c8a630ef5d932610046bcc15c015a2fe"}
{"project": "FFmpeg", "commit_id": "5257743aee0c3982f0079e6553aabc6aa39401d2", "target": 1, "func": "static int ws_snd_decode_frame(AVCodecContext *avctx, void *data,\n\n                               int *got_frame_ptr, AVPacket *avpkt)\n\n{\n\n    WSSndContext *s = avctx->priv_data;\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n\n\n    int in_size, out_size, ret;\n\n    int sample = 128;\n\n    uint8_t *samples;\n\n    uint8_t *samples_end;\n\n\n\n    if (!buf_size)\n\n        return 0;\n\n\n\n    if (buf_size < 4) {\n\n        av_log(avctx, AV_LOG_ERROR, \"packet is too small\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    out_size = AV_RL16(&buf[0]);\n\n    in_size  = AV_RL16(&buf[2]);\n\n    buf += 4;\n\n\n\n    if (in_size > buf_size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Frame data is larger than input buffer\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* get output buffer */\n\n    s->frame.nb_samples = out_size;\n\n    if ((ret = avctx->get_buffer(avctx, &s->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n    samples     = s->frame.data[0];\n\n    samples_end = samples + out_size;\n\n\n\n    if (in_size == out_size) {\n\n        memcpy(samples, buf, out_size);\n\n        *got_frame_ptr   = 1;\n\n        *(AVFrame *)data = s->frame;\n\n        return buf_size;\n\n    }\n\n\n\n    while (samples < samples_end && buf - avpkt->data < buf_size) {\n\n        int code, smp, size;\n\n        uint8_t count;\n\n        code  = *buf >> 6;\n\n        count = *buf & 0x3F;\n\n        buf++;\n\n\n\n        /* make sure we don't write past the output buffer */\n\n        switch (code) {\n\n        case 0:  smp = 4;                              break;\n\n        case 1:  smp = 2;                              break;\n\n        case 2:  smp = (count & 0x20) ? 1 : count + 1; break;\n\n        default: smp = count + 1;                      break;\n\n        }\n\n        if (samples_end - samples < smp)\n\n            break;\n\n\n\n        /* make sure we don't read past the input buffer */\n\n        size = ((code == 2 && (count & 0x20)) || code == 3) ? 0 : count + 1;\n\n        if ((buf - avpkt->data) + size > buf_size)\n\n            break;\n\n\n\n        switch (code) {\n\n        case 0: /* ADPCM 2-bit */\n\n            for (count++; count > 0; count--) {\n\n                code = *buf++;\n\n                sample += ( code       & 0x3) - 2;\n\n                sample = av_clip_uint8(sample);\n\n                *samples++ = sample;\n\n                sample += ((code >> 2) & 0x3) - 2;\n\n                sample = av_clip_uint8(sample);\n\n                *samples++ = sample;\n\n                sample += ((code >> 4) & 0x3) - 2;\n\n                sample = av_clip_uint8(sample);\n\n                *samples++ = sample;\n\n                sample +=  (code >> 6)        - 2;\n\n                sample = av_clip_uint8(sample);\n\n                *samples++ = sample;\n\n            }\n\n            break;\n\n        case 1: /* ADPCM 4-bit */\n\n            for (count++; count > 0; count--) {\n\n                code = *buf++;\n\n                sample += ws_adpcm_4bit[code & 0xF];\n\n                sample = av_clip_uint8(sample);\n\n                *samples++ = sample;\n\n                sample += ws_adpcm_4bit[code >> 4];\n\n                sample = av_clip_uint8(sample);\n\n                *samples++ = sample;\n\n            }\n\n            break;\n\n        case 2: /* no compression */\n\n            if (count & 0x20) { /* big delta */\n\n                int8_t t;\n\n                t = count;\n\n                t <<= 3;\n\n                sample += t >> 3;\n\n                sample = av_clip_uint8(sample);\n\n                *samples++ = sample;\n\n            } else { /* copy */\n\n                memcpy(samples, buf, smp);\n\n                samples += smp;\n\n                buf     += smp;\n\n                sample = buf[-1];\n\n            }\n\n            break;\n\n        default: /* run */\n\n            memset(samples, sample, smp);\n\n            samples += smp;\n\n        }\n\n    }\n\n\n\n    s->frame.nb_samples = samples - s->frame.data[0];\n\n    *got_frame_ptr   = 1;\n\n    *(AVFrame *)data = s->frame;\n\n\n\n    return buf_size;\n\n}\n", "idx": 20606, "_split": "test", "_hash": "5a71ebdee43da71305a58666e114d4c3"}
{"project": "FFmpeg", "commit_id": "2254b559cbcfc0418135f09add37c0a5866b1981", "target": 1, "func": "static av_always_inline void hyscale(SwsContext *c, int16_t *dst, int dstWidth,\n\n                                     const uint8_t *src_in[4], int srcW, int xInc,\n\n                                     const int16_t *hLumFilter,\n\n                                     const int16_t *hLumFilterPos, int hLumFilterSize,\n\n                                     uint8_t *formatConvBuffer,\n\n                                     uint32_t *pal, int isAlpha)\n\n{\n\n    void (*toYV12)(uint8_t *, const uint8_t *, int, uint32_t *) = isAlpha ? c->alpToYV12 : c->lumToYV12;\n\n    void (*convertRange)(int16_t *, int) = isAlpha ? NULL : c->lumConvertRange;\n\n    const uint8_t *src = src_in[isAlpha ? 3 : 0];\n\n\n\n    if (toYV12) {\n\n        toYV12(formatConvBuffer, src, srcW, pal);\n\n        src= formatConvBuffer;\n\n    } else if (c->readLumPlanar && !isAlpha) {\n\n        c->readLumPlanar(formatConvBuffer, src_in, srcW);\n\n        src = formatConvBuffer;\n\n    }\n\n\n\n    if (!c->hyscale_fast) {\n\n        c->hyScale(c, dst, dstWidth, src, hLumFilter, hLumFilterPos, hLumFilterSize);\n\n    } else { // fast bilinear upscale / crap downscale\n\n        c->hyscale_fast(c, dst, dstWidth, src, srcW, xInc);\n\n    }\n\n\n\n    if (convertRange)\n\n        convertRange(dst, dstWidth);\n\n}\n", "idx": 20613, "_split": "test", "_hash": "8b403768c5231671a6a9ed98e2cc4617"}
{"project": "FFmpeg", "commit_id": "dd561441b1e849df7d8681c6f32af82d4088dafd", "target": 0, "func": "static av_always_inline av_flatten void h264_loop_filter_chroma_c(uint8_t *pix, int xstride, int ystride, int alpha, int beta, int8_t *tc0)\n\n{\n\n    int i, d;\n\n    for( i = 0; i < 4; i++ ) {\n\n        const int tc = tc0[i];\n\n        if( tc <= 0 ) {\n\n            pix += 2*ystride;\n\n            continue;\n\n        }\n\n        for( d = 0; d < 2; d++ ) {\n\n            const int p0 = pix[-1*xstride];\n\n            const int p1 = pix[-2*xstride];\n\n            const int q0 = pix[0];\n\n            const int q1 = pix[1*xstride];\n\n\n\n            if( FFABS( p0 - q0 ) < alpha &&\n\n                FFABS( p1 - p0 ) < beta &&\n\n                FFABS( q1 - q0 ) < beta ) {\n\n\n\n                int delta = av_clip( (((q0 - p0 ) << 2) + (p1 - q1) + 4) >> 3, -tc, tc );\n\n\n\n                pix[-xstride] = av_clip_uint8( p0 + delta );    /* p0' */\n\n                pix[0]        = av_clip_uint8( q0 - delta );    /* q0' */\n\n            }\n\n            pix += ystride;\n\n        }\n\n    }\n\n}\n", "idx": 20617, "_split": "test", "_hash": "4c2d33eef98779734e36263a2764a8de"}
{"project": "FFmpeg", "commit_id": "68f593b48433842f3407586679fe07f3e5199ab9", "target": 0, "func": "int ff_mpeg4_decode_picture_header(MpegEncContext * s, GetBitContext *gb)\n\n{\n\n    int startcode, v;\n\n\n\n    /* search next start code */\n\n    align_get_bits(gb);\n\n    startcode = 0xff;\n\n    for(;;) {\n\n        v = get_bits(gb, 8);\n\n        startcode = ((startcode << 8) | v) & 0xffffffff;\n\n        \n\n        if(get_bits_count(gb) >= gb->size*8){\n\n            if(gb->size==1 && s->divx_version){\n\n                printf(\"frame skip %d\\n\", gb->size);\n\n                return FRAME_SKIPED; //divx bug\n\n            }else\n\n                return -1; //end of stream\n\n        }\n\n\n\n        if((startcode&0xFFFFFF00) != 0x100)\n\n            continue; //no startcode\n\n        \n\n        if(s->avctx->debug&FF_DEBUG_STARTCODE){\n\n            printf(\"startcode: %3X \", startcode);\n\n            if     (startcode<=0x11F) printf(\"Video Object Start\");\n\n            else if(startcode<=0x12F) printf(\"Video Object Layer Start\");\n\n            else if(startcode<=0x13F) printf(\"Reserved\");\n\n            else if(startcode<=0x15F) printf(\"FGS bp start\");\n\n            else if(startcode<=0x1AF) printf(\"Reserved\");\n\n            else if(startcode==0x1B0) printf(\"Visual Object Seq Start\");\n\n            else if(startcode==0x1B1) printf(\"Visual Object Seq End\");\n\n            else if(startcode==0x1B2) printf(\"User Data\");\n\n            else if(startcode==0x1B3) printf(\"Group of VOP start\");\n\n            else if(startcode==0x1B4) printf(\"Video Session Error\");\n\n            else if(startcode==0x1B5) printf(\"Visual Object Start\");\n\n            else if(startcode==0x1B6) printf(\"Video Object Plane start\");\n\n            else if(startcode==0x1B7) printf(\"slice start\");\n\n            else if(startcode==0x1B8) printf(\"extension start\");\n\n            else if(startcode==0x1B9) printf(\"fgs start\");\n\n            else if(startcode==0x1BA) printf(\"FBA Object start\");\n\n            else if(startcode==0x1BB) printf(\"FBA Object Plane start\");\n\n            else if(startcode==0x1BC) printf(\"Mesh Object start\");\n\n            else if(startcode==0x1BD) printf(\"Mesh Object Plane start\");\n\n            else if(startcode==0x1BE) printf(\"Still Textutre Object start\");\n\n            else if(startcode==0x1BF) printf(\"Textutre Spatial Layer start\");\n\n            else if(startcode==0x1C0) printf(\"Textutre SNR Layer start\");\n\n            else if(startcode==0x1C1) printf(\"Textutre Tile start\");\n\n            else if(startcode==0x1C2) printf(\"Textutre Shape Layer start\");\n\n            else if(startcode==0x1C3) printf(\"stuffing start\");\n\n            else if(startcode<=0x1C5) printf(\"reserved\");\n\n            else if(startcode<=0x1FF) printf(\"System start\");\n\n            printf(\" at %d\\n\", get_bits_count(gb));\n\n        }\n\n\n\n        switch(startcode){\n\n        case 0x120:\n\n            decode_vol_header(s, gb);\n\n            break;\n\n        case USER_DATA_STARTCODE:\n\n            decode_user_data(s, gb);\n\n            break;\n\n        case GOP_STARTCODE:\n\n            mpeg4_decode_gop_header(s, gb);\n\n            break;\n\n        case VOP_STARTCODE:\n\n            return decode_vop_header(s, gb);\n\n        default:\n\n            break;\n\n        }\n\n\n\n        align_get_bits(gb);\n\n        startcode = 0xff;\n\n    }\n\n}\n", "idx": 20618, "_split": "test", "_hash": "568e3869d24f12cac887e229ffa4a268"}
{"project": "FFmpeg", "commit_id": "a4c7a5ea27050a28625eabf1ba98cfef9ac6620d", "target": 0, "func": "static void mpegvideo_extract_headers(AVCodecParserContext *s,\n\n                                      AVCodecContext *avctx,\n\n                                      const uint8_t *buf, int buf_size)\n\n{\n\n    ParseContext1 *pc = s->priv_data;\n\n    const uint8_t *buf_end;\n\n    const uint8_t *buf_start= buf;\n\n    uint32_t start_code;\n\n    int frame_rate_index, ext_type, bytes_left;\n\n    int frame_rate_ext_n, frame_rate_ext_d;\n\n    int picture_structure, top_field_first, repeat_first_field, progressive_frame;\n\n    int horiz_size_ext, vert_size_ext, bit_rate_ext;\n\n//FIXME replace the crap with get_bits()\n\n    s->repeat_pict = 0;\n\n    buf_end = buf + buf_size;\n\n    while (buf < buf_end) {\n\n        start_code= -1;\n\n        buf= ff_find_start_code(buf, buf_end, &start_code);\n\n        bytes_left = buf_end - buf;\n\n        switch(start_code) {\n\n        case PICTURE_START_CODE:\n\n            ff_fetch_timestamp(s, buf-buf_start-4, 1);\n\n\n\n            if (bytes_left >= 2) {\n\n                s->pict_type = (buf[1] >> 3) & 7;\n\n            }\n\n            break;\n\n        case SEQ_START_CODE:\n\n            if (bytes_left >= 7) {\n\n                pc->width  = (buf[0] << 4) | (buf[1] >> 4);\n\n                pc->height = ((buf[1] & 0x0f) << 8) | buf[2];\n\n                avcodec_set_dimensions(avctx, pc->width, pc->height);\n\n                frame_rate_index = buf[3] & 0xf;\n\n                pc->frame_rate.den = avctx->time_base.den = ff_frame_rate_tab[frame_rate_index].num;\n\n                pc->frame_rate.num = avctx->time_base.num = ff_frame_rate_tab[frame_rate_index].den;\n\n                avctx->bit_rate = ((buf[4]<<10) | (buf[5]<<2) | (buf[6]>>6))*400;\n\n                avctx->codec_id = CODEC_ID_MPEG1VIDEO;\n\n                avctx->sub_id = 1;\n\n            }\n\n            break;\n\n        case EXT_START_CODE:\n\n            if (bytes_left >= 1) {\n\n                ext_type = (buf[0] >> 4);\n\n                switch(ext_type) {\n\n                case 0x1: /* sequence extension */\n\n                    if (bytes_left >= 6) {\n\n                        horiz_size_ext = ((buf[1] & 1) << 1) | (buf[2] >> 7);\n\n                        vert_size_ext = (buf[2] >> 5) & 3;\n\n                        bit_rate_ext = ((buf[2] & 0x1F)<<7) | (buf[3]>>1);\n\n                        frame_rate_ext_n = (buf[5] >> 5) & 3;\n\n                        frame_rate_ext_d = (buf[5] & 0x1f);\n\n                        pc->progressive_sequence = buf[1] & (1 << 3);\n\n                        avctx->has_b_frames= !(buf[5] >> 7);\n\n\n\n                        pc->width  |=(horiz_size_ext << 12);\n\n                        pc->height |=( vert_size_ext << 12);\n\n                        avctx->bit_rate += (bit_rate_ext << 18) * 400;\n\n                        avcodec_set_dimensions(avctx, pc->width, pc->height);\n\n                        avctx->time_base.den = pc->frame_rate.den * (frame_rate_ext_n + 1) * 2;\n\n                        avctx->time_base.num = pc->frame_rate.num * (frame_rate_ext_d + 1);\n\n                        avctx->codec_id = CODEC_ID_MPEG2VIDEO;\n\n                        avctx->sub_id = 2; /* forces MPEG2 */\n\n                    }\n\n                    break;\n\n                case 0x8: /* picture coding extension */\n\n                    if (bytes_left >= 5) {\n\n                        picture_structure = buf[2]&3;\n\n                        top_field_first = buf[3] & (1 << 7);\n\n                        repeat_first_field = buf[3] & (1 << 1);\n\n                        progressive_frame = buf[4] & (1 << 7);\n\n\n\n                        /* check if we must repeat the frame */\n\n                        s->repeat_pict = 1;\n\n                        if (repeat_first_field) {\n\n                            if (pc->progressive_sequence) {\n\n                                if (top_field_first)\n\n                                    s->repeat_pict = 5;\n\n                                else\n\n                                    s->repeat_pict = 3;\n\n                            } else if (progressive_frame) {\n\n                                s->repeat_pict = 2;\n\n                            }\n\n                        }\n\n                    }\n\n                    break;\n\n                }\n\n            }\n\n            break;\n\n        case -1:\n\n            goto the_end;\n\n        default:\n\n            /* we stop parsing when we encounter a slice. It ensures\n\n               that this function takes a negligible amount of time */\n\n            if (start_code >= SLICE_MIN_START_CODE &&\n\n                start_code <= SLICE_MAX_START_CODE)\n\n                goto the_end;\n\n            break;\n\n        }\n\n    }\n\n the_end: ;\n\n}\n", "idx": 20620, "_split": "test", "_hash": "f7c401e2bb2f2463e8e5132a2d2b0c4e"}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "static int set_chroma_format(AVCodecContext *avctx)\n\n{\n\n    int num_formats = sizeof(schro_pixel_format_map) /\n\n                      sizeof(schro_pixel_format_map[0]);\n\n    int idx;\n\n\n\n    SchroEncoderParams *p_schro_params = avctx->priv_data;\n\n\n\n    for (idx = 0; idx < num_formats; ++idx) {\n\n        if (schro_pixel_format_map[idx].ff_pix_fmt == avctx->pix_fmt) {\n\n            p_schro_params->format->chroma_format =\n\n                            schro_pixel_format_map[idx].schro_pix_fmt;\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_ERROR,\n\n           \"This codec currently only supports planar YUV 4:2:0, 4:2:2\"\n\n           \" and 4:4:4 formats.\\n\");\n\n\n\n    return -1;\n\n}\n", "idx": 20623, "_split": "test", "_hash": "f516c3b1783e99c0887920ee14546f66"}
{"project": "FFmpeg", "commit_id": "8728360b5664ef9db31137d8d3104cac33b9a911", "target": 1, "func": "static av_cold int mp_decode_init(AVCodecContext *avctx)\n\n{\n\n    MotionPixelsContext *mp = avctx->priv_data;\n\n    int w4 = (avctx->width  + 3) & ~3;\n\n    int h4 = (avctx->height + 3) & ~3;\n\n\n\n    if(avctx->extradata_size < 2){\n\n        av_log(avctx, AV_LOG_ERROR, \"extradata too small\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    motionpixels_tableinit();\n\n    mp->avctx = avctx;\n\n    ff_dsputil_init(&mp->dsp, avctx);\n\n    mp->changes_map = av_mallocz(avctx->width * h4);\n\n    mp->offset_bits_len = av_log2(avctx->width * avctx->height) + 1;\n\n    mp->vpt = av_mallocz(avctx->height * sizeof(YuvPixel));\n\n    mp->hpt = av_mallocz(h4 * w4 / 16 * sizeof(YuvPixel));\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_RGB555;\n\n    avcodec_get_frame_defaults(&mp->frame);\n\n    return 0;\n\n}", "idx": 20659, "_split": "test", "_hash": "4feaa4eb44baedf67dce742ef3cda2dc"}
{"project": "FFmpeg", "commit_id": "3c895fc098f7637f6d5ec3a9d6766e724a8b9e41", "target": 0, "func": "static void put_payload_header(\n\n                                AVFormatContext *s,\n\n                                ASFStream       *stream,\n\n                                int             presentation_time,\n\n                                int             m_obj_size,\n\n                                int             m_obj_offset,\n\n                                int             payload_len\n\n            )\n\n{\n\n    ASFContext *asf = s->priv_data;\n\n    ByteIOContext *pb = &asf->pb;\n\n    int val;\n\n    \n\n    val = stream->num;\n\n    if (s->streams[val - 1]->codec.coded_frame->key_frame)\n\n        val |= ASF_PL_FLAG_KEY_FRAME;\n\n    put_byte(pb, val);\n\n        \n\n    put_byte(pb, stream->seq);  //Media object number\n\n    put_le32(pb, m_obj_offset); //Offset Into Media Object\n\n         \n\n    // Replicated Data shall be at least 8 bytes long.\n\n    // The first 4 bytes of data shall contain the \n\n    // Size of the Media Object that the payload belongs to.\n\n    // The next 4 bytes of data shall contain the \n\n    // Presentation Time for the media object that the payload belongs to.\n\n    put_byte(pb, ASF_PAYLOAD_REPLICATED_DATA_LENGTH);\n\n\n\n    put_le32(pb, m_obj_size);       //Replicated Data - Media Object Size\n\n    put_le32(pb, presentation_time);//Replicated Data - Presentation Time\n\n    \n\n    if (asf->multi_payloads_present){\n\n        put_le16(pb, payload_len);   //payload length\n\n    }\n\n}\n", "idx": 20662, "_split": "test", "_hash": "b1745e1d59e2c25f824e446ea51972b9"}
{"project": "FFmpeg", "commit_id": "0eaec10550bd9a0682db9f7920ed0d86f1450f4b", "target": 1, "func": "static int pcm_encode_frame(AVCodecContext *avctx,\n\n\t\t\t    unsigned char *frame, int buf_size, void *data)\n\n{\n\n    int n, sample_size, v;\n\n    short *samples;\n\n    unsigned char *dst;\n\n\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_PCM_S16LE:\n\n    case CODEC_ID_PCM_S16BE:\n\n    case CODEC_ID_PCM_U16LE:\n\n    case CODEC_ID_PCM_U16BE:\n\n        sample_size = 2;\n\n        break;\n\n    default:\n\n        sample_size = 1;\n\n        break;\n\n    }\n\n    n = buf_size / sample_size;\n\n    samples = data;\n\n    dst = frame;\n\n\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_PCM_S16LE:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            dst[0] = v & 0xff;\n\n            dst[1] = v >> 8;\n\n            dst += 2;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_S16BE:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            dst[0] = v >> 8;\n\n            dst[1] = v;\n\n            dst += 2;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_U16LE:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            v += 0x8000;\n\n            dst[0] = v & 0xff;\n\n            dst[1] = v >> 8;\n\n            dst += 2;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_U16BE:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            v += 0x8000;\n\n            dst[0] = v >> 8;\n\n            dst[1] = v;\n\n            dst += 2;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_S8:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            dst[0] = (v + 128) >> 8;\n\n            dst++;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_U8:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            dst[0] = ((v + 128) >> 8) + 128;\n\n            dst++;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_ALAW:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            dst[0] = linear_to_alaw[(v + 32768) >> 2];\n\n            dst++;\n\n        }\n\n        break;\n\n    case CODEC_ID_PCM_MULAW:\n\n        for(;n>0;n--) {\n\n            v = *samples++;\n\n            dst[0] = linear_to_ulaw[(v + 32768) >> 2];\n\n            dst++;\n\n        }\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n    avctx->key_frame = 1;\n\n    //avctx->frame_size = (dst - frame) / (sample_size * avctx->channels);\n\n\n\n    return dst - frame;\n\n}\n", "idx": 20697, "_split": "test", "_hash": "da81cedbf5a5dc01358228e2f78349b7"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "static inline void hScale_altivec_real(int16_t *dst, int dstW, uint8_t *src, int srcW, int xInc, int16_t *filter, int16_t *filterPos, int filterSize) {\n\n  register int i;\n\n  int __attribute__ ((aligned (16))) tempo[4];\n\n\n\n  if (filterSize % 4) {\n\n    for(i=0; i<dstW; i++) {\n\n      register int j;\n\n      register int srcPos = filterPos[i];\n\n      register int val = 0;\n\n      for(j=0; j<filterSize; j++) {\n\n\tval += ((int)src[srcPos + j])*filter[filterSize*i + j];\n\n      }\n\n      dst[i] = av_clip(val>>7, 0, (1<<15)-1);\n\n    }\n\n  }\n\n  else\n\n  switch (filterSize) {\n\n  case 4:\n\n    {\n\n      for(i=0; i<dstW; i++) {\n\n\tregister int srcPos = filterPos[i];\n\n\n\n\tvector unsigned char src_v0 = vec_ld(srcPos, src);\n\n\tvector unsigned char src_v1, src_vF;\n\n\tvector signed short src_v, filter_v;\n\n\tvector signed int val_vEven, val_s;\n\n\tif ((((int)src + srcPos)% 16) > 12) {\n\n\t  src_v1 = vec_ld(srcPos + 16, src);\n\n\t}\n\n\tsrc_vF = vec_perm(src_v0, src_v1, vec_lvsl(srcPos, src));\n\n\n\n\tsrc_v = // vec_unpackh sign-extends...\n\n\t  (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));\n\n\t// now put our elements in the even slots\n\n\tsrc_v = vec_mergeh(src_v, (vector signed short)vzero);\n\n\n\n\tfilter_v = vec_ld(i << 3, filter);\n\n        // the 3 above is 2 (filterSize == 4) + 1 (sizeof(short) == 2)\n\n\n\n        // the neat trick : we only care for half the elements,\n\n        // high or low depending on (i<<3)%16 (it's 0 or 8 here),\n\n        // and we're going to use vec_mule, so we chose\n\n        // carefully how to \"unpack\" the elements into the even slots\n\n\tif ((i << 3) % 16)\n\n\t  filter_v = vec_mergel(filter_v,(vector signed short)vzero);\n\n\telse\n\n\t  filter_v = vec_mergeh(filter_v,(vector signed short)vzero);\n\n\n\n\tval_vEven = vec_mule(src_v, filter_v);\n\n\tval_s = vec_sums(val_vEven, vzero);\n\n\tvec_st(val_s, 0, tempo);\n\n\tdst[i] = av_clip(tempo[3]>>7, 0, (1<<15)-1);\n\n      }\n\n    }\n\n    break;\n\n\n\n  case 8:\n\n    {\n\n      for(i=0; i<dstW; i++) {\n\n\tregister int srcPos = filterPos[i];\n\n\n\n\tvector unsigned char src_v0 = vec_ld(srcPos, src);\n\n\tvector unsigned char src_v1, src_vF;\n\n\tvector signed short src_v, filter_v;\n\n\tvector signed int val_v, val_s;\n\n\tif ((((int)src + srcPos)% 16) > 8) {\n\n\t  src_v1 = vec_ld(srcPos + 16, src);\n\n\t}\n\n\tsrc_vF = vec_perm(src_v0, src_v1, vec_lvsl(srcPos, src));\n\n\n\n\tsrc_v = // vec_unpackh sign-extends...\n\n\t  (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));\n\n\tfilter_v = vec_ld(i << 4, filter);\n\n        // the 4 above is 3 (filterSize == 8) + 1 (sizeof(short) == 2)\n\n\n\n\tval_v = vec_msums(src_v, filter_v, (vector signed int)vzero);\n\n\tval_s = vec_sums(val_v, vzero);\n\n\tvec_st(val_s, 0, tempo);\n\n\tdst[i] = av_clip(tempo[3]>>7, 0, (1<<15)-1);\n\n      }\n\n    }\n\n    break;\n\n\n\n  case 16:\n\n    {\n\n      for(i=0; i<dstW; i++) {\n\n\tregister int srcPos = filterPos[i];\n\n\n\n\tvector unsigned char src_v0 = vec_ld(srcPos, src);\n\n\tvector unsigned char src_v1 = vec_ld(srcPos + 16, src);\n\n\tvector unsigned char src_vF = vec_perm(src_v0, src_v1, vec_lvsl(srcPos, src));\n\n\n\n\tvector signed short src_vA = // vec_unpackh sign-extends...\n\n\t  (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));\n\n\tvector signed short src_vB = // vec_unpackh sign-extends...\n\n\t  (vector signed short)(vec_mergel((vector unsigned char)vzero, src_vF));\n\n\n\n\tvector signed short filter_v0 = vec_ld(i << 5, filter);\n\n       \tvector signed short filter_v1 = vec_ld((i << 5) + 16, filter);\n\n        // the 5 above are 4 (filterSize == 16) + 1 (sizeof(short) == 2)\n\n\n\n\tvector signed int val_acc = vec_msums(src_vA, filter_v0, (vector signed int)vzero);\n\n\tvector signed int val_v = vec_msums(src_vB, filter_v1, val_acc);\n\n\n\n\tvector signed int val_s = vec_sums(val_v, vzero);\n\n\n\n\tvec_st(val_s, 0, tempo);\n\n\tdst[i] = av_clip(tempo[3]>>7, 0, (1<<15)-1);\n\n      }\n\n    }\n\n    break;\n\n\n\n  default:\n\n    {\n\n      for(i=0; i<dstW; i++) {\n\n\tregister int j;\n\n\tregister int srcPos = filterPos[i];\n\n\n\n        vector signed int val_s, val_v = (vector signed int)vzero;\n\n\tvector signed short filter_v0R = vec_ld(i * 2 * filterSize, filter);\n\n        vector unsigned char permF = vec_lvsl((i * 2 * filterSize), filter);\n\n\n\n        vector unsigned char src_v0 = vec_ld(srcPos, src);\n\n        vector unsigned char permS = vec_lvsl(srcPos, src);\n\n\n\n        for (j = 0 ; j < filterSize - 15; j += 16) {\n\n          vector unsigned char src_v1 = vec_ld(srcPos + j + 16, src);\n\n          vector unsigned char src_vF = vec_perm(src_v0, src_v1, permS);\n\n\n\n          vector signed short src_vA = // vec_unpackh sign-extends...\n\n            (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));\n\n          vector signed short src_vB = // vec_unpackh sign-extends...\n\n            (vector signed short)(vec_mergel((vector unsigned char)vzero, src_vF));\n\n\n\n          vector signed short filter_v1R = vec_ld((i * 2 * filterSize) + (j * 2) + 16, filter);\n\n          vector signed short filter_v2R = vec_ld((i * 2 * filterSize) + (j * 2) + 32, filter);\n\n          vector signed short filter_v0 = vec_perm(filter_v0R, filter_v1R, permF);\n\n          vector signed short filter_v1 = vec_perm(filter_v1R, filter_v2R, permF);\n\n\n\n          vector signed int val_acc = vec_msums(src_vA, filter_v0, val_v);\n\n          val_v = vec_msums(src_vB, filter_v1, val_acc);\n\n\n\n          filter_v0R = filter_v2R;\n\n          src_v0 = src_v1;\n\n        }\n\n\n\n        if (j < (filterSize-7)) {\n\n          // loading src_v0 is useless, it's already done above\n\n          //vector unsigned char src_v0 = vec_ld(srcPos + j, src);\n\n          vector unsigned char src_v1, src_vF;\n\n          vector signed short src_v, filter_v1R, filter_v;\n\n          if ((((int)src + srcPos)% 16) > 8) {\n\n            src_v1 = vec_ld(srcPos + j + 16, src);\n\n          }\n\n          src_vF = vec_perm(src_v0, src_v1, permS);\n\n\n\n          src_v = // vec_unpackh sign-extends...\n\n            (vector signed short)(vec_mergeh((vector unsigned char)vzero, src_vF));\n\n          // loading filter_v0R is useless, it's already done above\n\n          //vector signed short filter_v0R = vec_ld((i * 2 * filterSize) + j, filter);\n\n          filter_v1R = vec_ld((i * 2 * filterSize) + (j * 2) + 16, filter);\n\n          filter_v = vec_perm(filter_v0R, filter_v1R, permF);\n\n\n\n          val_v = vec_msums(src_v, filter_v, val_v);\n\n        }\n\n\n\n        val_s = vec_sums(val_v, vzero);\n\n\n\n        vec_st(val_s, 0, tempo);\n\n        dst[i] = av_clip(tempo[3]>>7, 0, (1<<15)-1);\n\n      }\n\n\n\n    }\n\n  }\n\n}\n", "idx": 20698, "_split": "test", "_hash": "dcb998c9c1ef517d2d472196b7d7f991"}
{"project": "FFmpeg", "commit_id": "ccff9da62a833238db7a22eb39be0814f522c2c5", "target": 0, "func": "static int h261_find_frame_end(ParseContext *pc, AVCodecContext* avctx, const uint8_t *buf, int buf_size){\n\n    int vop_found, i, j, bits_left, last_bits;\n\n    uint32_t state;\n\n\n\n    H261Context *h = avctx->priv_data;\n\n\n\n    if(h){\n\n        bits_left = h->bits_left;\n\n        last_bits = h->last_bits;\n\n    }\n\n    else{\n\n        bits_left = 0;\n\n        last_bits = 0;\n\n    }\n\n\n\n    vop_found= pc->frame_start_found;\n\n    state= pc->state;\n\n    if(bits_left!=0 && !vop_found)\n\n        state = state << (8-bits_left) | last_bits;\n\n    i=0;\n\n    if(!vop_found){\n\n        for(i=0; i<buf_size; i++){\n\n            state= (state<<8) | buf[i];\n\n            for(j=0; j<8; j++){\n\n                if(( (  (state<<j)  |  (buf[i]>>(8-j))  )>>(32-20) == 0x10 )&&(((state >> (17-j)) & 0x4000) == 0x0)){\n\n                    i++;\n\n                    vop_found=1;\n\n                    break;\n\n                }\n\n            }\n\n            if(vop_found)\n\n                    break;    \n\n        }\n\n    }\n\n    if(vop_found){\n\n        for(; i<buf_size; i++){\n\n            if(avctx->flags & CODEC_FLAG_TRUNCATED)//XXX ffplay workaround, someone a better solution?\n\n                state= (state<<8) | buf[i];\n\n            for(j=0; j<8; j++){\n\n                if(( (  (state<<j)  |  (buf[i]>>(8-j))  )>>(32-20) == 0x10 )&&(((state >> (17-j)) & 0x4000) == 0x0)){\n\n                    pc->frame_start_found=0;\n\n                    pc->state=-1;\n\n                    return i-3;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    pc->frame_start_found= vop_found;\n\n    pc->state= state;\n\n    return END_NOT_FOUND;\n\n}\n", "idx": 20741, "_split": "test", "_hash": "52742217995b82c128d14f09a385ed6f"}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "static void RENAME(yuv2yuvX)(SwsContext *c, const int16_t *lumFilter,\n\n                             const int16_t **lumSrc, int lumFilterSize,\n\n                             const int16_t *chrFilter, const int16_t **chrUSrc,\n\n                             const int16_t **chrVSrc,\n\n                             int chrFilterSize, const int16_t **alpSrc,\n\n                             uint8_t *dest, uint8_t *uDest, uint8_t *vDest,\n\n                             uint8_t *aDest, int dstW, int chrDstW)\n\n{\n\n    if (uDest) {\n\n        x86_reg uv_off = c->uv_off;\n\n        YSCALEYUV2YV12X(CHR_MMX_FILTER_OFFSET, uDest, chrDstW, 0)\n\n        YSCALEYUV2YV12X(CHR_MMX_FILTER_OFFSET, vDest - uv_off, chrDstW + uv_off, uv_off)\n\n    }\n\n    if (CONFIG_SWSCALE_ALPHA && aDest) {\n\n        YSCALEYUV2YV12X(ALP_MMX_FILTER_OFFSET, aDest, dstW, 0)\n\n    }\n\n\n\n    YSCALEYUV2YV12X(LUM_MMX_FILTER_OFFSET, dest, dstW, 0)\n\n}\n", "idx": 20856, "_split": "test", "_hash": "734a6d2ca512e925630594284ebfef91"}
{"project": "FFmpeg", "commit_id": "ca16618b01abfde44b4eaf92dc89b01aa1b4a91e", "target": 0, "func": "static int xan_huffman_decode(unsigned char *dest, unsigned char *src)\n\n{\n\n    unsigned char byte = *src++;\n\n    unsigned char ival = byte + 0x16;\n\n    unsigned char * ptr = src + byte*2;\n\n    unsigned char val = ival;\n\n    int counter = 0;\n\n\n\n    unsigned char bits = *ptr++;\n\n\n\n    while ( val != 0x16 ) {\n\n        if ( (1 << counter) & bits )\n\n            val = src[byte + val - 0x17];\n\n        else\n\n            val = src[val - 0x17];\n\n\n\n        if ( val < 0x16 ) {\n\n            *dest++ = val;\n\n            val = ival;\n\n        }\n\n\n\n        if (counter++ == 7) {\n\n            counter = 0;\n\n            bits = *ptr++;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 20903, "_split": "test", "_hash": "3af62baedb3ad0feca313b1f0b91b54d"}
{"project": "FFmpeg", "commit_id": "3dbc0ff9c3e6f6e0d08ea3d42cb33761bae084ba", "target": 1, "func": "static int iff_read_header(AVFormatContext *s)\n\n{\n\n    IffDemuxContext *iff = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    uint8_t *buf;\n\n    uint32_t chunk_id, data_size;\n\n    uint32_t screenmode = 0, num, den;\n\n    unsigned transparency = 0;\n\n    unsigned masking = 0; // no mask\n\n    uint8_t fmt[16];\n\n    int fmt_size;\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    st->codec->channels = 1;\n\n    st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n    avio_skip(pb, 8);\n\n    // codec_tag used by ByteRun1 decoder to distinguish progressive (PBM) and interlaced (ILBM) content\n\n    st->codec->codec_tag = avio_rl32(pb);\n\n    iff->bitmap_compression = -1;\n\n    iff->svx8_compression = -1;\n\n    iff->maud_bits = -1;\n\n    iff->maud_compression = -1;\n\n\n\n    while(!url_feof(pb)) {\n\n        uint64_t orig_pos;\n\n        int res;\n\n        const char *metadata_tag = NULL;\n\n        chunk_id = avio_rl32(pb);\n\n        data_size = avio_rb32(pb);\n\n        orig_pos = avio_tell(pb);\n\n\n\n        switch(chunk_id) {\n\n        case ID_VHDR:\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n            if (data_size < 14)\n\n                return AVERROR_INVALIDDATA;\n\n            avio_skip(pb, 12);\n\n            st->codec->sample_rate = avio_rb16(pb);\n\n            if (data_size >= 16) {\n\n                avio_skip(pb, 1);\n\n                iff->svx8_compression = avio_r8(pb);\n\n            }\n\n            break;\n\n\n\n        case ID_MHDR:\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n\n\n            if (data_size < 32)\n\n                return AVERROR_INVALIDDATA;\n\n            avio_skip(pb, 4);\n\n            iff->maud_bits = avio_rb16(pb);\n\n            avio_skip(pb, 2);\n\n            num = avio_rb32(pb);\n\n            den = avio_rb16(pb);\n\n            if (!den)\n\n                return AVERROR_INVALIDDATA;\n\n            avio_skip(pb, 2);\n\n            st->codec->sample_rate = num / den;\n\n            st->codec->channels = avio_rb16(pb);\n\n            iff->maud_compression = avio_rb16(pb);\n\n            if (st->codec->channels == 1)\n\n                st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n            else if (st->codec->channels == 2)\n\n                st->codec->channel_layout = AV_CH_LAYOUT_STEREO;\n\n            break;\n\n\n\n        case ID_ABIT:\n\n        case ID_BODY:\n\n        case ID_DBOD:\n\n        case ID_MDAT:\n\n            iff->body_pos = avio_tell(pb);\n\n            iff->body_end = iff->body_pos + data_size;\n\n            iff->body_size = data_size;\n\n            break;\n\n\n\n        case ID_CHAN:\n\n            if (data_size < 4)\n\n                return AVERROR_INVALIDDATA;\n\n            if (avio_rb32(pb) < 6) {\n\n                st->codec->channels       = 1;\n\n                st->codec->channel_layout = AV_CH_LAYOUT_MONO;\n\n            } else {\n\n                st->codec->channels       = 2;\n\n                st->codec->channel_layout = AV_CH_LAYOUT_STEREO;\n\n            }\n\n            break;\n\n\n\n        case ID_CAMG:\n\n            if (data_size < 4)\n\n                return AVERROR_INVALIDDATA;\n\n            screenmode                = avio_rb32(pb);\n\n            break;\n\n\n\n        case ID_CMAP:\n\n            if (data_size > INT_MAX - IFF_EXTRA_VIDEO_SIZE - FF_INPUT_BUFFER_PADDING_SIZE)\n\n                return AVERROR_INVALIDDATA;\n\n            st->codec->extradata_size = data_size + IFF_EXTRA_VIDEO_SIZE;\n\n            st->codec->extradata      = av_malloc(data_size + IFF_EXTRA_VIDEO_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!st->codec->extradata)\n\n                return AVERROR(ENOMEM);\n\n            if (avio_read(pb, st->codec->extradata + IFF_EXTRA_VIDEO_SIZE, data_size) < 0)\n\n                return AVERROR(EIO);\n\n            break;\n\n\n\n        case ID_BMHD:\n\n            st->codec->codec_type            = AVMEDIA_TYPE_VIDEO;\n\n            if (data_size <= 8)\n\n                return AVERROR_INVALIDDATA;\n\n            st->codec->width                 = avio_rb16(pb);\n\n            st->codec->height                = avio_rb16(pb);\n\n            avio_skip(pb, 4); // x, y offset\n\n            st->codec->bits_per_coded_sample = avio_r8(pb);\n\n            if (data_size >= 10)\n\n                masking                      = avio_r8(pb);\n\n            if (data_size >= 11)\n\n                iff->bitmap_compression      = avio_r8(pb);\n\n            if (data_size >= 14) {\n\n                avio_skip(pb, 1); // padding\n\n                transparency                 = avio_rb16(pb);\n\n            }\n\n            if (data_size >= 16) {\n\n                st->sample_aspect_ratio.num  = avio_r8(pb);\n\n                st->sample_aspect_ratio.den  = avio_r8(pb);\n\n            }\n\n            break;\n\n\n\n        case ID_DPEL:\n\n            if (data_size < 4 || (data_size & 3))\n\n                return AVERROR_INVALIDDATA;\n\n            if ((fmt_size = avio_read(pb, fmt, sizeof(fmt))) < 0)\n\n                return fmt_size;\n\n            if (fmt_size == sizeof(deep_rgb24) && !memcmp(fmt, deep_rgb24, sizeof(deep_rgb24)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_RGB24;\n\n            else if (fmt_size == sizeof(deep_rgba) && !memcmp(fmt, deep_rgba, sizeof(deep_rgba)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_RGBA;\n\n            else if (fmt_size == sizeof(deep_bgra) && !memcmp(fmt, deep_bgra, sizeof(deep_bgra)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_BGRA;\n\n            else if (fmt_size == sizeof(deep_argb) && !memcmp(fmt, deep_argb, sizeof(deep_argb)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_ARGB;\n\n            else if (fmt_size == sizeof(deep_abgr) && !memcmp(fmt, deep_abgr, sizeof(deep_abgr)))\n\n                st->codec->pix_fmt = AV_PIX_FMT_ABGR;\n\n            else {\n\n                av_log_ask_for_sample(s, \"unsupported color format\\n\");\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n            break;\n\n\n\n        case ID_DGBL:\n\n            st->codec->codec_type            = AVMEDIA_TYPE_VIDEO;\n\n            if (data_size < 8)\n\n                return AVERROR_INVALIDDATA;\n\n            st->codec->width                 = avio_rb16(pb);\n\n            st->codec->height                = avio_rb16(pb);\n\n            iff->bitmap_compression          = avio_rb16(pb);\n\n            st->sample_aspect_ratio.num      = avio_r8(pb);\n\n            st->sample_aspect_ratio.den      = avio_r8(pb);\n\n            st->codec->bits_per_coded_sample = 24;\n\n            break;\n\n\n\n        case ID_DLOC:\n\n            if (data_size < 4)\n\n                return AVERROR_INVALIDDATA;\n\n            st->codec->width  = avio_rb16(pb);\n\n            st->codec->height = avio_rb16(pb);\n\n            break;\n\n\n\n        case ID_TVDC:\n\n            if (data_size < sizeof(iff->tvdc))\n\n                return AVERROR_INVALIDDATA;\n\n            res = avio_read(pb, iff->tvdc, sizeof(iff->tvdc));\n\n            if (res < 0)\n\n                return res;\n\n            break;\n\n\n\n        case ID_ANNO:\n\n        case ID_TEXT:      metadata_tag = \"comment\";   break;\n\n        case ID_AUTH:      metadata_tag = \"artist\";    break;\n\n        case ID_COPYRIGHT: metadata_tag = \"copyright\"; break;\n\n        case ID_NAME:      metadata_tag = \"title\";     break;\n\n        }\n\n\n\n        if (metadata_tag) {\n\n            if ((res = get_metadata(s, metadata_tag, data_size)) < 0) {\n\n                av_log(s, AV_LOG_ERROR, \"cannot allocate metadata tag %s!\\n\", metadata_tag);\n\n                return res;\n\n            }\n\n        }\n\n        avio_skip(pb, data_size - (avio_tell(pb) - orig_pos) + (data_size & 1));\n\n    }\n\n\n\n    avio_seek(pb, iff->body_pos, SEEK_SET);\n\n\n\n    switch(st->codec->codec_type) {\n\n    case AVMEDIA_TYPE_AUDIO:\n\n        avpriv_set_pts_info(st, 32, 1, st->codec->sample_rate);\n\n\n\n        if (st->codec->codec_tag == ID_16SV)\n\n            st->codec->codec_id = AV_CODEC_ID_PCM_S16BE_PLANAR;\n\n        else if (st->codec->codec_tag == ID_MAUD) {\n\n            if (iff->maud_bits == 8 && !iff->maud_compression) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_U8;\n\n            } else if (iff->maud_bits == 16 && !iff->maud_compression) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_S16BE;\n\n            } else if (iff->maud_bits ==  8 && iff->maud_compression == 2) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_ALAW;\n\n            } else if (iff->maud_bits ==  8 && iff->maud_compression == 3) {\n\n                st->codec->codec_id = AV_CODEC_ID_PCM_MULAW;\n\n            } else {\n\n                av_log_ask_for_sample(s, \"unsupported compression %d and bit depth %d\\n\", iff->maud_compression, iff->maud_bits);\n\n                return AVERROR_PATCHWELCOME;\n\n            }\n\n\n\n            st->codec->bits_per_coded_sample =\n\n                av_get_bits_per_sample(st->codec->codec_id);\n\n\n\n            st->codec->block_align =\n\n                st->codec->bits_per_coded_sample * st->codec->channels / 8;\n\n        } else {\n\n        switch (iff->svx8_compression) {\n\n        case COMP_NONE:\n\n            st->codec->codec_id = AV_CODEC_ID_PCM_S8_PLANAR;\n\n            break;\n\n        case COMP_FIB:\n\n            st->codec->codec_id = AV_CODEC_ID_8SVX_FIB;\n\n            break;\n\n        case COMP_EXP:\n\n            st->codec->codec_id = AV_CODEC_ID_8SVX_EXP;\n\n            break;\n\n        default:\n\n            av_log(s, AV_LOG_ERROR,\n\n                   \"Unknown SVX8 compression method '%d'\\n\", iff->svx8_compression);\n\n            return -1;\n\n        }\n\n        }\n\n\n\n        st->codec->bits_per_coded_sample = av_get_bits_per_sample(st->codec->codec_id);\n\n        st->codec->bit_rate = st->codec->channels * st->codec->sample_rate * st->codec->bits_per_coded_sample;\n\n        st->codec->block_align = st->codec->channels * st->codec->bits_per_coded_sample;\n\n        break;\n\n\n\n    case AVMEDIA_TYPE_VIDEO:\n\n        iff->bpp          = st->codec->bits_per_coded_sample;\n\n        if ((screenmode & 0x800 /* Hold And Modify */) && iff->bpp <= 8) {\n\n            iff->ham      = iff->bpp > 6 ? 6 : 4;\n\n            st->codec->bits_per_coded_sample = 24;\n\n        }\n\n        iff->flags        = (screenmode & 0x80 /* Extra HalfBrite */) && iff->bpp <= 8;\n\n        iff->masking      = masking;\n\n        iff->transparency = transparency;\n\n\n\n        if (!st->codec->extradata) {\n\n            st->codec->extradata_size = IFF_EXTRA_VIDEO_SIZE;\n\n            st->codec->extradata      = av_malloc(IFF_EXTRA_VIDEO_SIZE + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!st->codec->extradata)\n\n                return AVERROR(ENOMEM);\n\n        }\n\n\n        buf = st->codec->extradata;\n\n        bytestream_put_be16(&buf, IFF_EXTRA_VIDEO_SIZE);\n\n        bytestream_put_byte(&buf, iff->bitmap_compression);\n\n        bytestream_put_byte(&buf, iff->bpp);\n\n        bytestream_put_byte(&buf, iff->ham);\n\n        bytestream_put_byte(&buf, iff->flags);\n\n        bytestream_put_be16(&buf, iff->transparency);\n\n        bytestream_put_byte(&buf, iff->masking);\n\n        bytestream_put_buffer(&buf, iff->tvdc, sizeof(iff->tvdc));\n\n        st->codec->codec_id = AV_CODEC_ID_IFF_ILBM;\n\n        break;\n\n    default:\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}", "idx": 20917, "_split": "test", "_hash": "1a9486f505ebd2002e5a995f932af818"}
{"project": "FFmpeg", "commit_id": "f3ace37a3b8c93218630a37b7df4dc195f1215a9", "target": 1, "func": "static int ftp_status(FTPContext *s, char **line, const int response_codes[])\n\n{\n\n    int err, i, dash = 0, result = 0, code_found = 0;\n\n    char buf[CONTROL_BUFFER_SIZE];\n\n    AVBPrint line_buffer;\n\n\n\n    if (line)\n\n        av_bprint_init(&line_buffer, 0, AV_BPRINT_SIZE_AUTOMATIC);\n\n\n\n    while (!code_found || dash) {\n\n        if ((err = ftp_get_line(s, buf, sizeof(buf))) < 0) {\n\n            av_bprint_finalize(&line_buffer, NULL);\n\n            return err;\n\n        }\n\n\n\n        av_log(s, AV_LOG_DEBUG, \"%s\\n\", buf);\n\n\n\n        if (strlen(buf) < 4)\n\n            continue;\n\n\n\n        err = 0;\n\n        for (i = 0; i < 3; ++i) {\n\n            if (buf[i] < '0' || buf[i] > '9')\n\n                continue;\n\n            err *= 10;\n\n            err += buf[i] - '0';\n\n        }\n\n        dash = !!(buf[3] == '-');\n\n\n\n        for (i = 0; response_codes[i]; ++i) {\n\n            if (err == response_codes[i]) {\n\n                if (line)\n\n                    av_bprintf(&line_buffer, \"%s\", buf);\n\n                code_found = 1;\n\n                result = err;\n\n                break;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (line)\n\n        av_bprint_finalize(&line_buffer, line);\n\n    return result;\n\n}\n", "idx": 20918, "_split": "test", "_hash": "1f1a8d8d8876b0bc91d32f6045c49950"}
{"project": "FFmpeg", "commit_id": "2bb62455c899cdccbdc2a6ad33f9582008ed9f05", "target": 0, "func": "double avpriv_strtod(char *restrict nptr, char **restrict endptr)\n\n{\n\n    char *end;\n\n    double res;\n\n\n\n    /* Skip leading spaces */\n\n    while (isspace(*nptr))\n\n        nptr++;\n\n\n\n    if (!av_strncasecmp(nptr, \"infinity\", 8)) {\n\n        end = nptr + 8;\n\n        res = INFINITY;\n\n    } else if (!av_strncasecmp(nptr, \"inf\", 3)) {\n\n        end = nptr + 3;\n\n        res = INFINITY;\n\n    } else if (!av_strncasecmp(nptr, \"+infinity\", 9)) {\n\n        end = nptr + 9;\n\n        res = INFINITY;\n\n    } else if (!av_strncasecmp(nptr, \"+inf\", 4)) {\n\n        end = nptr + 4;\n\n        res = INFINITY;\n\n    } else if (!av_strncasecmp(nptr, \"-infinity\", 9)) {\n\n        end = nptr + 9;\n\n        res = -INFINITY;\n\n    } else if (!av_strncasecmp(nptr, \"-inf\", 4)) {\n\n        end = nptr + 4;\n\n        res = -INFINITY;\n\n    } else if (!av_strncasecmp(nptr, \"nan\", 3)) {\n\n        end = check_nan_suffix(nptr + 3);\n\n        res = NAN;\n\n    } else if (!av_strncasecmp(nptr, \"+nan\", 4) ||\n\n               !av_strncasecmp(nptr, \"-nan\", 4)) {\n\n        end = check_nan_suffix(nptr + 4);\n\n        res = NAN;\n\n    } else if (!av_strncasecmp(nptr, \"0x\", 2) ||\n\n               !av_strncasecmp(nptr, \"-0x\", 3) ||\n\n               !av_strncasecmp(nptr, \"+0x\", 3)) {\n\n        /* FIXME this doesn't handle exponents, non-integers (float/double)\n\n         * and numbers too large for long long */\n\n        res = strtoll(nptr, &end, 16);\n\n    } else {\n\n        res = strtod(nptr, &end);\n\n    }\n\n\n\n    if (endptr)\n\n        *endptr = end;\n\n\n\n    return res;\n\n}\n", "idx": 20958, "_split": "test", "_hash": "710058074bf2a346047c24aa4442e1a9"}
{"project": "FFmpeg", "commit_id": "b2a8850969b89151677253be4d99e0ba29212749", "target": 0, "func": "static void update_video_pts(VideoState *is, double pts, int64_t pos, int serial) {\n\n    double time = av_gettime() / 1000000.0;\n\n    /* update current video pts */\n\n    is->video_current_pts = pts;\n\n    is->video_current_pts_drift = is->video_current_pts - time;\n\n    is->video_current_pos = pos;\n\n    is->frame_last_pts = pts;\n\n    check_external_clock_sync(is, is->video_current_pts);\n\n}\n", "idx": 20961, "_split": "test", "_hash": "f9ee38e121aca3172f38d144b239ca2d"}
{"project": "FFmpeg", "commit_id": "e30b068ef79f604ff439418da07f7e2efd01d4ea", "target": 1, "func": "static void save_bits(WMAProDecodeCtx *s, GetBitContext* gb, int len,\n                      int append)\n{\n    int buflen;\n    /** when the frame data does not need to be concatenated, the input buffer\n        is resetted and additional bits from the previous frame are copyed\n        and skipped later so that a fast byte copy is possible */\n    if (!append) {\n        s->frame_offset = get_bits_count(gb) & 7;\n        s->num_saved_bits = s->frame_offset;\n        init_put_bits(&s->pb, s->frame_data, MAX_FRAMESIZE);\n    buflen = (s->num_saved_bits + len + 8) >> 3;\n    if (len <= 0 || buflen > MAX_FRAMESIZE) {\n        avpriv_request_sample(s->avctx, \"Too small input buffer\");\n    s->num_saved_bits += len;\n    if (!append) {\n        avpriv_copy_bits(&s->pb, gb->buffer + (get_bits_count(gb) >> 3),\n                     s->num_saved_bits);\n    } else {\n        int align = 8 - (get_bits_count(gb) & 7);\n        align = FFMIN(align, len);\n        put_bits(&s->pb, align, get_bits(gb, align));\n        len -= align;\n        avpriv_copy_bits(&s->pb, gb->buffer + (get_bits_count(gb) >> 3), len);\n    skip_bits_long(gb, len);\n    {\n        PutBitContext tmp = s->pb;\n        flush_put_bits(&tmp);\n    init_get_bits(&s->gb, s->frame_data, s->num_saved_bits);\n    skip_bits(&s->gb, s->frame_offset);", "idx": 21007, "_split": "test", "_hash": "bd95c7f12473cf49543f3a5bad5f1f56"}
{"project": "FFmpeg", "commit_id": "a55692a96099c40aabb25e1443890be99f9c845c", "target": 1, "func": "static int read_interval_packets(WriterContext *w, AVFormatContext *fmt_ctx,\n\n                                 const ReadInterval *interval, int64_t *cur_ts)\n\n{\n\n    AVPacket pkt, pkt1;\n\n    AVFrame *frame = NULL;\n\n    int ret = 0, i = 0, frame_count = 0;\n\n    int64_t start = -INT64_MAX, end = interval->end;\n\n    int has_start = 0, has_end = interval->has_end && !interval->end_is_offset;\n\n\n\n    av_init_packet(&pkt);\n\n\n\n    av_log(NULL, AV_LOG_VERBOSE, \"Processing read interval \");\n\n    log_read_interval(interval, NULL, AV_LOG_VERBOSE);\n\n\n\n    if (interval->has_start) {\n\n        int64_t target;\n\n        if (interval->start_is_offset) {\n\n            if (*cur_ts == AV_NOPTS_VALUE) {\n\n                av_log(NULL, AV_LOG_ERROR,\n\n                       \"Could not seek to relative position since current \"\n\n                       \"timestamp is not defined\\n\");\n\n                ret = AVERROR(EINVAL);\n\n\n\n            target = *cur_ts + interval->start;\n\n        } else {\n\n            target = interval->start;\n\n\n\n\n        av_log(NULL, AV_LOG_VERBOSE, \"Seeking to read interval start point %s\\n\",\n\n               av_ts2timestr(target, &AV_TIME_BASE_Q));\n\n        if ((ret = avformat_seek_file(fmt_ctx, -1, -INT64_MAX, target, INT64_MAX, 0)) < 0) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Could not seek to position %\"PRId64\": %s\\n\",\n\n                   interval->start, av_err2str(ret));\n\n\n\n\n\n\n    frame = av_frame_alloc();\n\n\n\n\n\n    while (!av_read_frame(fmt_ctx, &pkt)) {\n\n        if (selected_streams[pkt.stream_index]) {\n\n            AVRational tb = fmt_ctx->streams[pkt.stream_index]->time_base;\n\n\n\n            if (pkt.pts != AV_NOPTS_VALUE)\n\n                *cur_ts = av_rescale_q(pkt.pts, tb, AV_TIME_BASE_Q);\n\n\n\n            if (!has_start && *cur_ts != AV_NOPTS_VALUE) {\n\n                start = *cur_ts;\n\n                has_start = 1;\n\n\n\n\n            if (has_start && !has_end && interval->end_is_offset) {\n\n                end = start + interval->end;\n\n                has_end = 1;\n\n\n\n\n            if (interval->end_is_offset && interval->duration_frames) {\n\n                if (frame_count >= interval->end)\n\n                    break;\n\n            } else if (has_end && *cur_ts != AV_NOPTS_VALUE && *cur_ts >= end) {\n\n                break;\n\n\n\n\n            frame_count++;\n\n            if (do_read_packets) {\n\n                if (do_show_packets)\n\n                    show_packet(w, fmt_ctx, &pkt, i++);\n\n                nb_streams_packets[pkt.stream_index]++;\n\n\n            if (do_read_frames) {\n\n                pkt1 = pkt;\n\n                while (pkt1.size && process_frame(w, fmt_ctx, frame, &pkt1) > 0);\n\n\n\n        av_free_packet(&pkt);\n\n\n    av_init_packet(&pkt);\n\n    pkt.data = NULL;\n\n    pkt.size = 0;\n\n    //Flush remaining frames that are cached in the decoder\n\n    for (i = 0; i < fmt_ctx->nb_streams; i++) {\n\n        pkt.stream_index = i;\n\n        if (do_read_frames)\n\n            while (process_frame(w, fmt_ctx, frame, &pkt) > 0);\n\n\n\n\nend:\n\n    av_frame_free(&frame);\n\n    if (ret < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Could not read packets in interval \");\n\n        log_read_interval(interval, NULL, AV_LOG_ERROR);\n\n\n    return ret;\n", "idx": 21012, "_split": "test", "_hash": "83855e046086bd1ef62036238944922a"}
{"project": "FFmpeg", "commit_id": "d32547a24a3fcc8286b318353f43805838b84775", "target": 1, "func": "int attribute_align_arg avcodec_encode_audio(AVCodecContext *avctx,\n                                             uint8_t *buf, int buf_size,\n                                             const short *samples)\n{\n    AVPacket pkt;\n    AVFrame *frame;\n    int ret, samples_size, got_packet;\n    av_init_packet(&pkt);\n    pkt.data = buf;\n    pkt.size = buf_size;\n    if (samples) {\n        frame = av_frame_alloc();\n        if (!frame)\n            return AVERROR(ENOMEM);\n        if (avctx->frame_size) {\n            frame->nb_samples = avctx->frame_size;\n        } else {\n            /* if frame_size is not set, the number of samples must be\n             * calculated from the buffer size */\n            int64_t nb_samples;\n            if (!av_get_bits_per_sample(avctx->codec_id)) {\n                av_log(avctx, AV_LOG_ERROR, \"avcodec_encode_audio() does not \"\n                                            \"support this codec\\n\");\n                av_frame_free(&frame);\n                return AVERROR(EINVAL);\n            }\n            nb_samples = (int64_t)buf_size * 8 /\n                         (av_get_bits_per_sample(avctx->codec_id) *\n                          avctx->channels);\n            if (nb_samples >= INT_MAX) {\n                av_frame_free(&frame);\n                return AVERROR(EINVAL);\n            }\n            frame->nb_samples = nb_samples;\n        }\n        /* it is assumed that the samples buffer is large enough based on the\n         * relevant parameters */\n        samples_size = av_samples_get_buffer_size(NULL, avctx->channels,\n                                                  frame->nb_samples,\n                                                  avctx->sample_fmt, 1);\n        if ((ret = avcodec_fill_audio_frame(frame, avctx->channels,\n                                            avctx->sample_fmt,\n                                            (const uint8_t *)samples,\n                                            samples_size, 1)) < 0) {\n            av_frame_free(&frame);\n            return ret;\n        }\n        /* fabricate frame pts from sample count.\n         * this is needed because the avcodec_encode_audio() API does not have\n         * a way for the user to provide pts */\n        if (avctx->sample_rate && avctx->time_base.num)\n            frame->pts = ff_samples_to_time_base(avctx,\n                                                 avctx->internal->sample_count);\n        else\n            frame->pts = AV_NOPTS_VALUE;\n        avctx->internal->sample_count += frame->nb_samples;\n    } else {\n        frame = NULL;\n    }\n    got_packet = 0;\n    ret = avcodec_encode_audio2(avctx, &pkt, frame, &got_packet);\n    if (!ret && got_packet && avctx->coded_frame) {\n        avctx->coded_frame->pts       = pkt.pts;\n        avctx->coded_frame->key_frame = !!(pkt.flags & AV_PKT_FLAG_KEY);\n    }\n    /* free any side data since we cannot return it */\n    av_packet_free_side_data(&pkt);\n    if (frame && frame->extended_data != frame->data)\n        av_freep(&frame->extended_data);\n    av_frame_free(&frame);\n    return ret ? ret : pkt.size;\n}", "idx": 21030, "_split": "test", "_hash": "fb41e4ab95627364d9bc7dcd7c133fa5"}
{"project": "FFmpeg", "commit_id": "18516d3e695980525bd9758dc7b8a8e36cd3f09e", "target": 1, "func": "static int dxva2_map_frame(AVHWFramesContext *ctx, AVFrame *dst, const AVFrame *src,\n\n                           int flags)\n\n{\n\n    IDirect3DSurface9 *surface = (IDirect3DSurface9*)src->data[3];\n\n    DXVA2Mapping      *map;\n\n    D3DSURFACE_DESC    surfaceDesc;\n\n    D3DLOCKED_RECT     LockedRect;\n\n    HRESULT            hr;\n\n    int i, err, nb_planes;\n\n    int lock_flags = 0;\n\n\n\n    nb_planes = av_pix_fmt_count_planes(dst->format);\n\n\n\n    hr = IDirect3DSurface9_GetDesc(surface, &surfaceDesc);\n\n    if (FAILED(hr)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Error getting a surface description\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if (!(flags & AV_HWFRAME_MAP_WRITE))\n\n        lock_flags |= D3DLOCK_READONLY;\n\n    if (flags & AV_HWFRAME_MAP_OVERWRITE)\n\n        lock_flags |= D3DLOCK_DISCARD;\n\n\n\n    hr = IDirect3DSurface9_LockRect(surface, &LockedRect, NULL, lock_flags);\n\n    if (FAILED(hr)) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Unable to lock DXVA2 surface\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    map = av_mallocz(sizeof(*map));\n\n    if (!map)\n\n        goto fail;\n\n\n\n    err = ff_hwframe_map_create(src->hw_frames_ctx, dst, src,\n\n                                dxva2_unmap_frame, map);\n\n    if (err < 0) {\n\n        av_freep(&map);\n\n        goto fail;\n\n    }\n\n\n\n    for (i = 0; i < nb_planes; i++)\n\n        dst->linesize[i] = LockedRect.Pitch;\n\n\n\n    av_image_fill_pointers(dst->data, dst->format, surfaceDesc.Height,\n\n                           (uint8_t*)LockedRect.pBits, dst->linesize);\n\n\n\n    if (dst->format == AV_PIX_FMT_PAL8)\n\n        dst->data[1] = (uint8_t*)map->palette_dummy;\n\n\n\n    return 0;\n\nfail:\n\n    IDirect3DSurface9_UnlockRect(surface);\n\n    return err;\n\n}\n", "idx": 21037, "_split": "test", "_hash": "b8a3181b3109e53fbdac98444eb05d13"}
{"project": "FFmpeg", "commit_id": "bf5af5687569e34d6e3a4d31fc6bb5dc44efdb29", "target": 1, "func": "void show_help(void)\n\n{\n\n    const char *prog;\n\n    const OptionDef *po;\n\n    int i, expert;\n\n    \n\n    prog = do_play ? \"ffplay\" : \"ffmpeg\";\n\n\n\n    printf(\"%s version \" FFMPEG_VERSION \", Copyright (c) 2000, 2001, 2002 Gerard Lantau\\n\", \n\n           prog);\n\n    \n\n    if (!do_play) {\n\n        printf(\"usage: ffmpeg [[options] -i input_file]... {[options] outfile}...\\n\"\n\n               \"Hyper fast MPEG1/MPEG4/H263/RV and AC3/MPEG audio encoder\\n\");\n\n    } else {\n\n        printf(\"usage: ffplay [options] input_file...\\n\"\n\n               \"Simple audio player\\n\");\n\n    }\n\n           \n\n    printf(\"\\n\"\n\n           \"Main options are:\\n\");\n\n    for(i=0;i<2;i++) {\n\n        if (i == 1)\n\n            printf(\"\\nAdvanced options are:\\n\");\n\n        for(po = options; po->name != NULL; po++) {\n\n            char buf[64];\n\n            expert = (po->flags & OPT_EXPERT) != 0;\n\n            if (expert == i) {\n\n                strcpy(buf, po->name);\n\n                if (po->flags & HAS_ARG) {\n\n                    strcat(buf, \" \");\n\n                    strcat(buf, po->argname);\n\n                }\n\n                printf(\"-%-17s  %s\\n\", buf, po->help);\n\n            }\n\n        }\n\n    }\n\n\n\n    exit(1);\n\n}\n", "idx": 21050, "_split": "test", "_hash": "5f549975306e846098ec25a00194609a"}
{"project": "FFmpeg", "commit_id": "b8a2331a70b720e83e1be243f7d17941c8952ef2", "target": 1, "func": "av_cold int ffv1_common_init(AVCodecContext *avctx)\n\n{\n\n    FFV1Context *s = avctx->priv_data;\n\n\n\n    if (!avctx->width || !avctx->height)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    s->avctx = avctx;\n\n    s->flags = avctx->flags;\n\n\n\n    s->picture.f = avcodec_alloc_frame();\n\n    s->last_picture.f = av_frame_alloc();\n\n\n\n    ff_dsputil_init(&s->dsp, avctx);\n\n\n\n    s->width  = avctx->width;\n\n    s->height = avctx->height;\n\n\n\n    // defaults\n\n    s->num_h_slices = 1;\n\n    s->num_v_slices = 1;\n\n\n\n    return 0;\n\n}", "idx": 21061, "_split": "test", "_hash": "070a52b9c344e10180aaf9358373d7c0"}
{"project": "FFmpeg", "commit_id": "c776531aef9b546ca576d4c8e3ec14a513394618", "target": 0, "func": "static int vqa_decode_chunk(VqaContext *s)\n\n{\n\n    unsigned int chunk_type;\n\n    unsigned int chunk_size;\n\n    int byte_skip;\n\n    unsigned int index = 0;\n\n    int i;\n\n    unsigned char r, g, b;\n\n    int index_shift;\n\n    int res;\n\n\n\n    int cbf0_chunk = -1;\n\n    int cbfz_chunk = -1;\n\n    int cbp0_chunk = -1;\n\n    int cbpz_chunk = -1;\n\n    int cpl0_chunk = -1;\n\n    int cplz_chunk = -1;\n\n    int vptz_chunk = -1;\n\n\n\n    int x, y;\n\n    int lines = 0;\n\n    int pixel_ptr;\n\n    int vector_index = 0;\n\n    int lobyte = 0;\n\n    int hibyte = 0;\n\n    int lobytes = 0;\n\n    int hibytes = s->decode_buffer_size / 2;\n\n\n\n    /* first, traverse through the frame and find the subchunks */\n\n    while (bytestream2_get_bytes_left(&s->gb) >= 8) {\n\n\n\n        chunk_type = bytestream2_get_be32u(&s->gb);\n\n        index      = bytestream2_tell(&s->gb);\n\n        chunk_size = bytestream2_get_be32u(&s->gb);\n\n\n\n        switch (chunk_type) {\n\n\n\n        case CBF0_TAG:\n\n            cbf0_chunk = index;\n\n            break;\n\n\n\n        case CBFZ_TAG:\n\n            cbfz_chunk = index;\n\n            break;\n\n\n\n        case CBP0_TAG:\n\n            cbp0_chunk = index;\n\n            break;\n\n\n\n        case CBPZ_TAG:\n\n            cbpz_chunk = index;\n\n            break;\n\n\n\n        case CPL0_TAG:\n\n            cpl0_chunk = index;\n\n            break;\n\n\n\n        case CPLZ_TAG:\n\n            cplz_chunk = index;\n\n            break;\n\n\n\n        case VPTZ_TAG:\n\n            vptz_chunk = index;\n\n            break;\n\n\n\n        default:\n\n            av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: Found unknown chunk type: %c%c%c%c (%08X)\\n\",\n\n            (chunk_type >> 24) & 0xFF,\n\n            (chunk_type >> 16) & 0xFF,\n\n            (chunk_type >>  8) & 0xFF,\n\n            (chunk_type >>  0) & 0xFF,\n\n            chunk_type);\n\n            break;\n\n        }\n\n\n\n        byte_skip = chunk_size & 0x01;\n\n        bytestream2_skip(&s->gb, chunk_size + byte_skip);\n\n    }\n\n\n\n    /* next, deal with the palette */\n\n    if ((cpl0_chunk != -1) && (cplz_chunk != -1)) {\n\n\n\n        /* a chunk should not have both chunk types */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: problem: found both CPL0 and CPLZ chunks\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* decompress the palette chunk */\n\n    if (cplz_chunk != -1) {\n\n\n\n/* yet to be handled */\n\n\n\n    }\n\n\n\n    /* convert the RGB palette into the machine's endian format */\n\n    if (cpl0_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cpl0_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n        /* sanity check the palette size */\n\n        if (chunk_size / 3 > 256 || chunk_size > bytestream2_get_bytes_left(&s->gb)) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: problem: found a palette chunk with %d colors\\n\",\n\n                chunk_size / 3);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        for (i = 0; i < chunk_size / 3; i++) {\n\n            /* scale by 4 to transform 6-bit palette -> 8-bit */\n\n            r = bytestream2_get_byteu(&s->gb) * 4;\n\n            g = bytestream2_get_byteu(&s->gb) * 4;\n\n            b = bytestream2_get_byteu(&s->gb) * 4;\n\n            s->palette[i] = (r << 16) | (g << 8) | (b);\n\n        }\n\n    }\n\n\n\n    /* next, look for a full codebook */\n\n    if ((cbf0_chunk != -1) && (cbfz_chunk != -1)) {\n\n\n\n        /* a chunk should not have both chunk types */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: problem: found both CBF0 and CBFZ chunks\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    /* decompress the full codebook chunk */\n\n    if (cbfz_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbfz_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n        if ((res = decode_format80(&s->gb, chunk_size, s->codebook,\n\n                                   s->codebook_size, 0)) < 0)\n\n            return res;\n\n    }\n\n\n\n    /* copy a full codebook */\n\n    if (cbf0_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbf0_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n        /* sanity check the full codebook size */\n\n        if (chunk_size > MAX_CODEBOOK_SIZE) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: problem: CBF0 chunk too large (0x%X bytes)\\n\",\n\n                chunk_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        bytestream2_get_buffer(&s->gb, s->codebook, chunk_size);\n\n    }\n\n\n\n    /* decode the frame */\n\n    if (vptz_chunk == -1) {\n\n\n\n        /* something is wrong if there is no VPTZ chunk */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: problem: no VPTZ chunk found\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bytestream2_seek(&s->gb, vptz_chunk, SEEK_SET);\n\n    chunk_size = bytestream2_get_be32(&s->gb);\n\n    if ((res = decode_format80(&s->gb, chunk_size,\n\n                               s->decode_buffer, s->decode_buffer_size, 1)) < 0)\n\n        return res;\n\n\n\n    /* render the final PAL8 frame */\n\n    if (s->vector_height == 4)\n\n        index_shift = 4;\n\n    else\n\n        index_shift = 3;\n\n    for (y = 0; y < s->frame.linesize[0] * s->height;\n\n        y += s->frame.linesize[0] * s->vector_height) {\n\n\n\n        for (x = y; x < y + s->width; x += 4, lobytes++, hibytes++) {\n\n            pixel_ptr = x;\n\n\n\n            /* get the vector index, the method for which varies according to\n\n             * VQA file version */\n\n            switch (s->vqa_version) {\n\n\n\n            case 1:\n\n                lobyte = s->decode_buffer[lobytes * 2];\n\n                hibyte = s->decode_buffer[(lobytes * 2) + 1];\n\n                vector_index = ((hibyte << 8) | lobyte) >> 3;\n\n                vector_index <<= index_shift;\n\n                lines = s->vector_height;\n\n                /* uniform color fill - a quick hack */\n\n                if (hibyte == 0xFF) {\n\n                    while (lines--) {\n\n                        s->frame.data[0][pixel_ptr + 0] = 255 - lobyte;\n\n                        s->frame.data[0][pixel_ptr + 1] = 255 - lobyte;\n\n                        s->frame.data[0][pixel_ptr + 2] = 255 - lobyte;\n\n                        s->frame.data[0][pixel_ptr + 3] = 255 - lobyte;\n\n                        pixel_ptr += s->frame.linesize[0];\n\n                    }\n\n                    lines=0;\n\n                }\n\n                break;\n\n\n\n            case 2:\n\n                lobyte = s->decode_buffer[lobytes];\n\n                hibyte = s->decode_buffer[hibytes];\n\n                vector_index = (hibyte << 8) | lobyte;\n\n                vector_index <<= index_shift;\n\n                lines = s->vector_height;\n\n                break;\n\n\n\n            case 3:\n\n/* not implemented yet */\n\n                lines = 0;\n\n                break;\n\n            }\n\n\n\n            while (lines--) {\n\n                s->frame.data[0][pixel_ptr + 0] = s->codebook[vector_index++];\n\n                s->frame.data[0][pixel_ptr + 1] = s->codebook[vector_index++];\n\n                s->frame.data[0][pixel_ptr + 2] = s->codebook[vector_index++];\n\n                s->frame.data[0][pixel_ptr + 3] = s->codebook[vector_index++];\n\n                pixel_ptr += s->frame.linesize[0];\n\n            }\n\n        }\n\n    }\n\n\n\n    /* handle partial codebook */\n\n    if ((cbp0_chunk != -1) && (cbpz_chunk != -1)) {\n\n        /* a chunk should not have both chunk types */\n\n        av_log(s->avctx, AV_LOG_ERROR, \"  VQA video: problem: found both CBP0 and CBPZ chunks\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (cbp0_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbp0_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n\n\n        /* accumulate partial codebook */\n\n        bytestream2_get_buffer(&s->gb, &s->next_codebook_buffer[s->next_codebook_buffer_index],\n\n                               chunk_size);\n\n        s->next_codebook_buffer_index += chunk_size;\n\n\n\n        s->partial_countdown--;\n\n        if (s->partial_countdown == 0) {\n\n\n\n            /* time to replace codebook */\n\n            memcpy(s->codebook, s->next_codebook_buffer,\n\n                s->next_codebook_buffer_index);\n\n\n\n            /* reset accounting */\n\n            s->next_codebook_buffer_index = 0;\n\n            s->partial_countdown = s->partial_count;\n\n        }\n\n    }\n\n\n\n    if (cbpz_chunk != -1) {\n\n\n\n        bytestream2_seek(&s->gb, cbpz_chunk, SEEK_SET);\n\n        chunk_size = bytestream2_get_be32(&s->gb);\n\n\n\n        /* accumulate partial codebook */\n\n        bytestream2_get_buffer(&s->gb, &s->next_codebook_buffer[s->next_codebook_buffer_index],\n\n                               chunk_size);\n\n        s->next_codebook_buffer_index += chunk_size;\n\n\n\n        s->partial_countdown--;\n\n        if (s->partial_countdown == 0) {\n\n            GetByteContext gb;\n\n\n\n            bytestream2_init(&gb, s->next_codebook_buffer, s->next_codebook_buffer_index);\n\n            /* decompress codebook */\n\n            if ((res = decode_format80(&gb, s->next_codebook_buffer_index,\n\n                                       s->codebook, s->codebook_size, 0)) < 0)\n\n                return res;\n\n\n\n            /* reset accounting */\n\n            s->next_codebook_buffer_index = 0;\n\n            s->partial_countdown = s->partial_count;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 21070, "_split": "test", "_hash": "7fce1349385ac1d059e33626f4d1096b"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void palette8tobgr16(const uint8_t *src, uint8_t *dst, long num_pixels, const uint8_t *palette)\n\n{\n\n\tlong i;\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t\t((uint16_t *)dst)[i] = bswap_16(((uint16_t *)palette)[ src[i] ]);\n\n}\n", "idx": 21118, "_split": "test", "_hash": "9967d97a27105f1593710bf3196217fe"}
{"project": "FFmpeg", "commit_id": "028cc42a1638e6f93a857f11c2568d1c3a51e612", "target": 1, "func": "static int read_gab2_sub(AVStream *st, AVPacket *pkt) {\n\n    if (!strcmp(pkt->data, \"GAB2\") && AV_RL16(pkt->data+5) == 2) {\n\n        uint8_t desc[256];\n\n        int score = AVPROBE_SCORE_MAX / 2, ret;\n\n        AVIStream *ast = st->priv_data;\n\n        AVInputFormat *sub_demuxer;\n\n        AVRational time_base;\n\n        AVIOContext *pb = avio_alloc_context( pkt->data + 7,\n\n                                              pkt->size - 7,\n\n                                              0, NULL, NULL, NULL, NULL);\n\n        AVProbeData pd;\n\n        unsigned int desc_len = avio_rl32(pb);\n\n\n\n        if (desc_len > pb->buf_end - pb->buf_ptr)\n\n            goto error;\n\n\n\n        ret = avio_get_str16le(pb, desc_len, desc, sizeof(desc));\n\n        avio_skip(pb, desc_len - ret);\n\n        if (*desc)\n\n            av_dict_set(&st->metadata, \"title\", desc, 0);\n\n\n\n        avio_rl16(pb);   /* flags? */\n\n        avio_rl32(pb);   /* data size */\n\n\n\n        pd = (AVProbeData) { .buf = pb->buf_ptr, .buf_size = pb->buf_end - pb->buf_ptr };\n\n        if (!(sub_demuxer = av_probe_input_format2(&pd, 1, &score)))\n\n            goto error;\n\n\n\n        if (!(ast->sub_ctx = avformat_alloc_context()))\n\n            goto error;\n\n\n\n        ast->sub_ctx->pb      = pb;\n\n        if (!avformat_open_input(&ast->sub_ctx, \"\", sub_demuxer, NULL)) {\n\n            ff_read_packet(ast->sub_ctx, &ast->sub_pkt);\n\n            *st->codec = *ast->sub_ctx->streams[0]->codec;\n\n            ast->sub_ctx->streams[0]->codec->extradata = NULL;\n\n            time_base = ast->sub_ctx->streams[0]->time_base;\n\n            avpriv_set_pts_info(st, 64, time_base.num, time_base.den);\n\n        }\n\n        ast->sub_buffer = pkt->data;\n\n        memset(pkt, 0, sizeof(*pkt));\n\n        return 1;\n\nerror:\n\n        av_freep(&pb);\n\n    }\n\n    return 0;\n\n}\n", "idx": 21155, "_split": "test", "_hash": "c4f84f6161912bb765b31c5bf51445f4"}
{"project": "FFmpeg", "commit_id": "add41decd94b2d3581a3715ba10f27168b8cdb1b", "target": 0, "func": "int av_set_string3(void *obj, const char *name, const char *val, int alloc, const AVOption **o_out)\n\n{\n\n    int ret;\n\n    const AVOption *o = av_opt_find(obj, name, NULL, 0, 0);\n\n    if (o_out)\n\n        *o_out = o;\n\n    if (!o)\n\n        return AVERROR_OPTION_NOT_FOUND;\n\n    if (!val || o->offset<=0)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (o->type == FF_OPT_TYPE_BINARY) {\n\n        uint8_t **dst = (uint8_t **)(((uint8_t*)obj) + o->offset);\n\n        int *lendst = (int *)(dst + 1);\n\n        uint8_t *bin, *ptr;\n\n        int len = strlen(val);\n\n        av_freep(dst);\n\n        *lendst = 0;\n\n        if (len & 1) return AVERROR(EINVAL);\n\n        len /= 2;\n\n        ptr = bin = av_malloc(len);\n\n        while (*val) {\n\n            int a = hexchar2int(*val++);\n\n            int b = hexchar2int(*val++);\n\n            if (a < 0 || b < 0) {\n\n                av_free(bin);\n\n                return AVERROR(EINVAL);\n\n            }\n\n            *ptr++ = (a << 4) | b;\n\n        }\n\n        *dst = bin;\n\n        *lendst = len;\n\n        return 0;\n\n    }\n\n    if (o->type != FF_OPT_TYPE_STRING) {\n\n        int notfirst=0;\n\n        for (;;) {\n\n            int i;\n\n            char buf[256];\n\n            int cmd=0;\n\n            double d;\n\n\n\n            if (*val == '+' || *val == '-')\n\n                cmd= *(val++);\n\n\n\n            for (i=0; i<sizeof(buf)-1 && val[i] && val[i]!='+' && val[i]!='-'; i++)\n\n                buf[i]= val[i];\n\n            buf[i]=0;\n\n\n\n            {\n\n                const AVOption *o_named = av_opt_find(obj, buf, o->unit, 0, 0);\n\n                if (o_named && o_named->type == FF_OPT_TYPE_CONST)\n\n                    d= o_named->default_val.dbl;\n\n                else if (!strcmp(buf, \"default\")) d= o->default_val.dbl;\n\n                else if (!strcmp(buf, \"max\"    )) d= o->max;\n\n                else if (!strcmp(buf, \"min\"    )) d= o->min;\n\n                else if (!strcmp(buf, \"none\"   )) d= 0;\n\n                else if (!strcmp(buf, \"all\"    )) d= ~0;\n\n                else {\n\n                    int res = av_expr_parse_and_eval(&d, buf, const_names, const_values, NULL, NULL, NULL, NULL, NULL, 0, obj);\n\n                    if (res < 0) {\n\n                        av_log(obj, AV_LOG_ERROR, \"Unable to parse option value \\\"%s\\\"\\n\", val);\n\n                        return res;\n\n                    }\n\n                }\n\n            }\n\n            if (o->type == FF_OPT_TYPE_FLAGS) {\n\n                if      (cmd=='+') d= av_get_int(obj, name, NULL) | (int64_t)d;\n\n                else if (cmd=='-') d= av_get_int(obj, name, NULL) &~(int64_t)d;\n\n            } else {\n\n                if      (cmd=='+') d= notfirst*av_get_double(obj, name, NULL) + d;\n\n                else if (cmd=='-') d= notfirst*av_get_double(obj, name, NULL) - d;\n\n            }\n\n\n\n            if ((ret = av_set_number2(obj, name, d, 1, 1, o_out)) < 0)\n\n                return ret;\n\n            val+= i;\n\n            if (!*val)\n\n                return 0;\n\n            notfirst=1;\n\n        }\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    if (alloc) {\n\n        av_free(*(void**)(((uint8_t*)obj) + o->offset));\n\n        val= av_strdup(val);\n\n    }\n\n\n\n    memcpy(((uint8_t*)obj) + o->offset, &val, sizeof(val));\n\n    return 0;\n\n}\n", "idx": 21166, "_split": "test", "_hash": "db67130a2269d48808141df66da78043"}
{"project": "FFmpeg", "commit_id": "bcd7bf7eeb09a395cc01698842d1b8be9af483fc", "target": 0, "func": "void ff_h264_h_lpf_chroma_inter_msa(uint8_t *data, int img_width,\n\n                                    int alpha, int beta, int8_t *tc)\n\n{\n\n    uint8_t bs0 = 1;\n\n    uint8_t bs1 = 1;\n\n    uint8_t bs2 = 1;\n\n    uint8_t bs3 = 1;\n\n\n\n    if (tc[0] < 0)\n\n        bs0 = 0;\n\n    if (tc[1] < 0)\n\n        bs1 = 0;\n\n    if (tc[2] < 0)\n\n        bs2 = 0;\n\n    if (tc[3] < 0)\n\n        bs3 = 0;\n\n\n\n    avc_loopfilter_cb_or_cr_inter_edge_ver_msa(data,\n\n                                               bs0, bs1, bs2, bs3,\n\n                                               tc[0], tc[1], tc[2], tc[3],\n\n                                               alpha, beta,\n\n                                               img_width);\n\n}\n", "idx": 21168, "_split": "test", "_hash": "bb789165b58e71d9e803193070b5fc86"}
{"project": "FFmpeg", "commit_id": "2ac00d2d1d51047c6ce69d5fbe1a08392d142658", "target": 0, "func": "static int mov_read_stsc(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    unsigned int i, entries;\n\n\n\n    if (c->fc->nb_streams < 1)\n\n        return 0;\n\n    st = c->fc->streams[c->fc->nb_streams-1];\n\n    sc = st->priv_data;\n\n\n\n    avio_r8(pb); /* version */\n\n    avio_rb24(pb); /* flags */\n\n\n\n    entries = avio_rb32(pb);\n\n\n\n    av_log(c->fc, AV_LOG_TRACE, \"track[%i].stsc.entries = %i\\n\", c->fc->nb_streams-1, entries);\n\n\n\n    if (!entries)\n\n        return 0;\n\n    if (entries >= UINT_MAX / sizeof(*sc->stsc_data))\n\n        return AVERROR_INVALIDDATA;\n\n    sc->stsc_data = av_malloc(entries * sizeof(*sc->stsc_data));\n\n    if (!sc->stsc_data)\n\n        return AVERROR(ENOMEM);\n\n\n\n    for (i = 0; i < entries && !pb->eof_reached; i++) {\n\n        sc->stsc_data[i].first = avio_rb32(pb);\n\n        sc->stsc_data[i].count = avio_rb32(pb);\n\n        sc->stsc_data[i].id = avio_rb32(pb);\n\n        if (sc->stsc_data[i].id < 0 || sc->stsc_data[i].id > sc->stsd_count) {\n\n            sc->stsc_data[i].id = 0;\n\n            if (c->fc->error_recognition & AV_EF_EXPLODE) {\n\n                av_log(c->fc, AV_LOG_ERROR, \"Invalid stsc index.\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n\n\n    sc->stsc_count = i;\n\n\n\n    if (pb->eof_reached)\n\n        return AVERROR_EOF;\n\n\n\n    return 0;\n\n}\n", "idx": 21281, "_split": "test", "_hash": "73219f5e1a6eae5b6a6bf3a8dff4da2d"}
{"project": "FFmpeg", "commit_id": "29b0d94b43ac960cb442049a5d737a3386ff0337", "target": 1, "func": "static int decode_copy(uint8_t *frame, int width, int height,\n\n                       const uint8_t *src, const uint8_t *src_end)\n\n{\n\n    const int size = width * height;\n\n\n\n    if (src_end - src < size)\n\n        return -1;\n\n    bytestream_get_buffer(&src, frame, size);\n\n    return 0;\n\n}\n", "idx": 21284, "_split": "test", "_hash": "994a49870f21e89349438ca8f1a0fb39"}
{"project": "FFmpeg", "commit_id": "90c6963daea9210d7d2104e2ece94dd4e2fffc17", "target": 1, "func": "void avfilter_link_free(AVFilterLink **link)\n\n{\n\n    if (!*link)\n\n        return;\n\n\n\n    if ((*link)->pool) {\n\n        int i;\n\n        for (i = 0; i < POOL_SIZE; i++) {\n\n            if ((*link)->pool->pic[i]) {\n\n                AVFilterBufferRef *picref = (*link)->pool->pic[i];\n\n                /* free buffer: picrefs stored in the pool are not\n\n                 * supposed to contain a free callback */\n\n                av_freep(&picref->buf->data[0]);\n\n                av_freep(&picref->buf);\n\n\n\n                av_freep(&picref->audio);\n\n                av_freep(&picref->video);\n\n                av_freep(&picref);\n\n            }\n\n        }\n\n        av_freep(&(*link)->pool);\n\n    }\n\n    av_freep(link);\n\n}\n", "idx": 21302, "_split": "test", "_hash": "8a94a2cd3a5d5bd6c5b48afdcfab7a47"}
{"project": "FFmpeg", "commit_id": "eb38d8fe926bdce8110fa4be4fddf6598a079a20", "target": 0, "func": "static void fill_coding_method_array (sb_int8_array tone_level_idx, sb_int8_array tone_level_idx_temp,\n\n                sb_int8_array coding_method, int nb_channels,\n\n                int c, int superblocktype_2_3, int cm_table_select)\n\n{\n\n    int ch, sb, j;\n\n    int tmp, acc, esp_40, comp;\n\n    int add1, add2, add3, add4;\n\n    int64_t multres;\n\n\n\n    // This should never happen\n\n    if (nb_channels <= 0)\n\n        return;\n\n\n\n    if (!superblocktype_2_3) {\n\n        /* This case is untested, no samples available */\n\n        SAMPLES_NEEDED\n\n        for (ch = 0; ch < nb_channels; ch++)\n\n            for (sb = 0; sb < 30; sb++) {\n\n                for (j = 1; j < 63; j++) {  // The loop only iterates to 63 so the code doesn't overflow the buffer\n\n                    add1 = tone_level_idx[ch][sb][j] - 10;\n\n                    if (add1 < 0)\n\n                        add1 = 0;\n\n                    add2 = add3 = add4 = 0;\n\n                    if (sb > 1) {\n\n                        add2 = tone_level_idx[ch][sb - 2][j] + tone_level_idx_offset_table[sb][0] - 6;\n\n                        if (add2 < 0)\n\n                            add2 = 0;\n\n                    }\n\n                    if (sb > 0) {\n\n                        add3 = tone_level_idx[ch][sb - 1][j] + tone_level_idx_offset_table[sb][1] - 6;\n\n                        if (add3 < 0)\n\n                            add3 = 0;\n\n                    }\n\n                    if (sb < 29) {\n\n                        add4 = tone_level_idx[ch][sb + 1][j] + tone_level_idx_offset_table[sb][3] - 6;\n\n                        if (add4 < 0)\n\n                            add4 = 0;\n\n                    }\n\n                    tmp = tone_level_idx[ch][sb][j + 1] * 2 - add4 - add3 - add2 - add1;\n\n                    if (tmp < 0)\n\n                        tmp = 0;\n\n                    tone_level_idx_temp[ch][sb][j + 1] = tmp & 0xff;\n\n                }\n\n                tone_level_idx_temp[ch][sb][0] = tone_level_idx_temp[ch][sb][1];\n\n            }\n\n            acc = 0;\n\n            for (ch = 0; ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++)\n\n                        acc += tone_level_idx_temp[ch][sb][j];\n\n\n\n            multres = 0x66666667 * (acc * 10);\n\n            esp_40 = (multres >> 32) / 8 + ((multres & 0xffffffff) >> 31);\n\n            for (ch = 0;  ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++) {\n\n                        comp = tone_level_idx_temp[ch][sb][j]* esp_40 * 10;\n\n                        if (comp < 0)\n\n                            comp += 0xff;\n\n                        comp /= 256; // signed shift\n\n                        switch(sb) {\n\n                            case 0:\n\n                                if (comp < 30)\n\n                                    comp = 30;\n\n                                comp += 15;\n\n                                break;\n\n                            case 1:\n\n                                if (comp < 24)\n\n                                    comp = 24;\n\n                                comp += 10;\n\n                                break;\n\n                            case 2:\n\n                            case 3:\n\n                            case 4:\n\n                                if (comp < 16)\n\n                                    comp = 16;\n\n                        }\n\n                        if (comp <= 5)\n\n                            tmp = 0;\n\n                        else if (comp <= 10)\n\n                            tmp = 10;\n\n                        else if (comp <= 16)\n\n                            tmp = 16;\n\n                        else if (comp <= 24)\n\n                            tmp = -1;\n\n                        else\n\n                            tmp = 0;\n\n                        coding_method[ch][sb][j] = ((tmp & 0xfffa) + 30 )& 0xff;\n\n                    }\n\n            for (sb = 0; sb < 30; sb++)\n\n                fix_coding_method_array(sb, nb_channels, coding_method);\n\n            for (ch = 0; ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++)\n\n                        if (sb >= 10) {\n\n                            if (coding_method[ch][sb][j] < 10)\n\n                                coding_method[ch][sb][j] = 10;\n\n                        } else {\n\n                            if (sb >= 2) {\n\n                                if (coding_method[ch][sb][j] < 16)\n\n                                    coding_method[ch][sb][j] = 16;\n\n                            } else {\n\n                                if (coding_method[ch][sb][j] < 30)\n\n                                    coding_method[ch][sb][j] = 30;\n\n                            }\n\n                        }\n\n    } else { // superblocktype_2_3 != 0\n\n        for (ch = 0; ch < nb_channels; ch++)\n\n            for (sb = 0; sb < 30; sb++)\n\n                for (j = 0; j < 64; j++)\n\n                    coding_method[ch][sb][j] = coding_method_table[cm_table_select][sb];\n\n    }\n\n\n\n    return;\n\n}\n", "idx": 21311, "_split": "test", "_hash": "f30b882aee648f2fa7727887e1995168"}
{"project": "FFmpeg", "commit_id": "d59591fb02c29b41e5b8d611160971a4493394c2", "target": 1, "func": "static void mpegvideo_extract_headers(AVCodecParserContext *s,\n\n                                      AVCodecContext *avctx,\n\n                                      const uint8_t *buf, int buf_size)\n\n{\n\n    ParseContext1 *pc = s->priv_data;\n\n    const uint8_t *buf_end;\n\n\n    uint32_t start_code;\n\n    int frame_rate_index, ext_type, bytes_left;\n\n    int frame_rate_ext_n, frame_rate_ext_d;\n\n    int picture_structure, top_field_first, repeat_first_field, progressive_frame;\n\n    int horiz_size_ext, vert_size_ext, bit_rate_ext;\n\n//FIXME replace the crap with get_bits()\n\n    s->repeat_pict = 0;\n\n    buf_end = buf + buf_size;\n\n    while (buf < buf_end) {\n\n        start_code= -1;\n\n        buf= ff_find_start_code(buf, buf_end, &start_code);\n\n        bytes_left = buf_end - buf;\n\n        switch(start_code) {\n\n        case PICTURE_START_CODE:\n\n            ff_fetch_timestamp(s, buf-buf_start-4, 1);\n\n\n\n            if (bytes_left >= 2) {\n\n                s->pict_type = (buf[1] >> 3) & 7;\n\n            }\n\n            break;\n\n        case SEQ_START_CODE:\n\n            if (bytes_left >= 7) {\n\n                pc->width  = (buf[0] << 4) | (buf[1] >> 4);\n\n                pc->height = ((buf[1] & 0x0f) << 8) | buf[2];\n\n                avcodec_set_dimensions(avctx, pc->width, pc->height);\n\n                frame_rate_index = buf[3] & 0xf;\n\n                pc->frame_rate.den = avctx->time_base.den = ff_frame_rate_tab[frame_rate_index].num;\n\n                pc->frame_rate.num = avctx->time_base.num = ff_frame_rate_tab[frame_rate_index].den;\n\n                avctx->bit_rate = ((buf[4]<<10) | (buf[5]<<2) | (buf[6]>>6))*400;\n\n                avctx->codec_id = CODEC_ID_MPEG1VIDEO;\n\n                avctx->sub_id = 1;\n\n            }\n\n            break;\n\n        case EXT_START_CODE:\n\n            if (bytes_left >= 1) {\n\n                ext_type = (buf[0] >> 4);\n\n                switch(ext_type) {\n\n                case 0x1: /* sequence extension */\n\n                    if (bytes_left >= 6) {\n\n                        horiz_size_ext = ((buf[1] & 1) << 1) | (buf[2] >> 7);\n\n                        vert_size_ext = (buf[2] >> 5) & 3;\n\n                        bit_rate_ext = ((buf[2] & 0x1F)<<7) | (buf[3]>>1);\n\n                        frame_rate_ext_n = (buf[5] >> 5) & 3;\n\n                        frame_rate_ext_d = (buf[5] & 0x1f);\n\n                        pc->progressive_sequence = buf[1] & (1 << 3);\n\n                        avctx->has_b_frames= !(buf[5] >> 7);\n\n\n\n                        pc->width  |=(horiz_size_ext << 12);\n\n                        pc->height |=( vert_size_ext << 12);\n\n                        avctx->bit_rate += (bit_rate_ext << 18) * 400;\n\n                        avcodec_set_dimensions(avctx, pc->width, pc->height);\n\n                        avctx->time_base.den = pc->frame_rate.den * (frame_rate_ext_n + 1);\n\n                        avctx->time_base.num = pc->frame_rate.num * (frame_rate_ext_d + 1);\n\n                        avctx->codec_id = CODEC_ID_MPEG2VIDEO;\n\n                        avctx->sub_id = 2; /* forces MPEG2 */\n\n                    }\n\n                    break;\n\n                case 0x8: /* picture coding extension */\n\n                    if (bytes_left >= 5) {\n\n                        picture_structure = buf[2]&3;\n\n                        top_field_first = buf[3] & (1 << 7);\n\n                        repeat_first_field = buf[3] & (1 << 1);\n\n                        progressive_frame = buf[4] & (1 << 7);\n\n\n\n                        /* check if we must repeat the frame */\n\n                        if (repeat_first_field) {\n\n                            if (pc->progressive_sequence) {\n\n                                if (top_field_first)\n\n                                    s->repeat_pict = 4;\n\n                                else\n\n                                    s->repeat_pict = 2;\n\n                            } else if (progressive_frame) {\n\n                                s->repeat_pict = 1;\n\n                            }\n\n                        }\n\n                    }\n\n                    break;\n\n                }\n\n            }\n\n            break;\n\n        case -1:\n\n            goto the_end;\n\n        default:\n\n            /* we stop parsing when we encounter a slice. It ensures\n\n               that this function takes a negligible amount of time */\n\n            if (start_code >= SLICE_MIN_START_CODE &&\n\n                start_code <= SLICE_MAX_START_CODE)\n\n                goto the_end;\n\n            break;\n\n        }\n\n    }\n\n the_end: ;\n\n}", "idx": 21374, "_split": "test", "_hash": "96e188a54170bf33eb92267cf168bae1"}
{"project": "FFmpeg", "commit_id": "d59bfcd11229300182c672ca734568919a85f773", "target": 1, "func": "static void mov_update_dts_shift(MOVStreamContext *sc, int duration)\n\n{\n\n    if (duration < 0) {\n\n\n\n\n\n        sc->dts_shift = FFMAX(sc->dts_shift, -duration);\n\n", "idx": 21385, "_split": "test", "_hash": "163fab86f790111092bc040acacd0d2c"}
{"project": "FFmpeg", "commit_id": "1197c04896423c6c7db65f69da8bc3865b26bb50", "target": 1, "func": "static void fft_calc_c(FFTContext *s, FFTComplex *z) {\n\n\n\n    int nbits, i, n, num_transforms, offset, step;\n\n    int n4, n2, n34;\n\n    FFTSample tmp1, tmp2, tmp3, tmp4, tmp5, tmp6, tmp7, tmp8;\n\n    FFTComplex *tmpz;\n\n    const int fft_size = (1 << s->nbits);\n\n    int64_t accu;\n\n\n\n    num_transforms = (0x2aab >> (16 - s->nbits)) | 1;\n\n\n\n    for (n=0; n<num_transforms; n++){\n\n        offset = ff_fft_offsets_lut[n] << 2;\n\n        tmpz = z + offset;\n\n\n\n        tmp1 = tmpz[0].re + tmpz[1].re;\n\n        tmp5 = tmpz[2].re + tmpz[3].re;\n\n        tmp2 = tmpz[0].im + tmpz[1].im;\n\n        tmp6 = tmpz[2].im + tmpz[3].im;\n\n        tmp3 = tmpz[0].re - tmpz[1].re;\n\n        tmp8 = tmpz[2].im - tmpz[3].im;\n\n        tmp4 = tmpz[0].im - tmpz[1].im;\n\n        tmp7 = tmpz[2].re - tmpz[3].re;\n\n\n\n        tmpz[0].re = tmp1 + tmp5;\n\n        tmpz[2].re = tmp1 - tmp5;\n\n        tmpz[0].im = tmp2 + tmp6;\n\n        tmpz[2].im = tmp2 - tmp6;\n\n        tmpz[1].re = tmp3 + tmp8;\n\n        tmpz[3].re = tmp3 - tmp8;\n\n        tmpz[1].im = tmp4 - tmp7;\n\n        tmpz[3].im = tmp4 + tmp7;\n\n    }\n\n\n\n    if (fft_size < 8)\n\n        return;\n\n\n\n    num_transforms = (num_transforms >> 1) | 1;\n\n\n\n    for (n=0; n<num_transforms; n++){\n\n        offset = ff_fft_offsets_lut[n] << 3;\n\n        tmpz = z + offset;\n\n\n\n        tmp1 = tmpz[4].re + tmpz[5].re;\n\n        tmp3 = tmpz[6].re + tmpz[7].re;\n\n        tmp2 = tmpz[4].im + tmpz[5].im;\n\n        tmp4 = tmpz[6].im + tmpz[7].im;\n\n        tmp5 = tmp1 + tmp3;\n\n        tmp7 = tmp1 - tmp3;\n\n        tmp6 = tmp2 + tmp4;\n\n        tmp8 = tmp2 - tmp4;\n\n\n\n        tmp1 = tmpz[4].re - tmpz[5].re;\n\n        tmp2 = tmpz[4].im - tmpz[5].im;\n\n        tmp3 = tmpz[6].re - tmpz[7].re;\n\n        tmp4 = tmpz[6].im - tmpz[7].im;\n\n\n\n        tmpz[4].re = tmpz[0].re - tmp5;\n\n        tmpz[0].re = tmpz[0].re + tmp5;\n\n        tmpz[4].im = tmpz[0].im - tmp6;\n\n        tmpz[0].im = tmpz[0].im + tmp6;\n\n        tmpz[6].re = tmpz[2].re - tmp8;\n\n        tmpz[2].re = tmpz[2].re + tmp8;\n\n        tmpz[6].im = tmpz[2].im + tmp7;\n\n        tmpz[2].im = tmpz[2].im - tmp7;\n\n\n\n        accu = (int64_t)Q31(M_SQRT1_2)*(tmp1 + tmp2);\n\n        tmp5 = (int32_t)((accu + 0x40000000) >> 31);\n\n        accu = (int64_t)Q31(M_SQRT1_2)*(tmp3 - tmp4);\n\n        tmp7 = (int32_t)((accu + 0x40000000) >> 31);\n\n        accu = (int64_t)Q31(M_SQRT1_2)*(tmp2 - tmp1);\n\n        tmp6 = (int32_t)((accu + 0x40000000) >> 31);\n\n        accu = (int64_t)Q31(M_SQRT1_2)*(tmp3 + tmp4);\n\n        tmp8 = (int32_t)((accu + 0x40000000) >> 31);\n\n        tmp1 = tmp5 + tmp7;\n\n        tmp3 = tmp5 - tmp7;\n\n        tmp2 = tmp6 + tmp8;\n\n        tmp4 = tmp6 - tmp8;\n\n\n\n        tmpz[5].re = tmpz[1].re - tmp1;\n\n        tmpz[1].re = tmpz[1].re + tmp1;\n\n        tmpz[5].im = tmpz[1].im - tmp2;\n\n        tmpz[1].im = tmpz[1].im + tmp2;\n\n        tmpz[7].re = tmpz[3].re - tmp4;\n\n        tmpz[3].re = tmpz[3].re + tmp4;\n\n        tmpz[7].im = tmpz[3].im + tmp3;\n\n        tmpz[3].im = tmpz[3].im - tmp3;\n\n    }\n\n\n\n    step = 1 << ((MAX_LOG2_NFFT-4) - 4);\n\n    n4 = 4;\n\n\n\n    for (nbits=4; nbits<=s->nbits; nbits++){\n\n        n2  = 2*n4;\n\n        n34 = 3*n4;\n\n        num_transforms = (num_transforms >> 1) | 1;\n\n\n\n        for (n=0; n<num_transforms; n++){\n\n            const FFTSample *w_re_ptr = ff_w_tab_sr + step;\n\n            const FFTSample *w_im_ptr = ff_w_tab_sr + MAX_FFT_SIZE/(4*16) - step;\n\n            offset = ff_fft_offsets_lut[n] << nbits;\n\n            tmpz = z + offset;\n\n\n\n            tmp5 = tmpz[ n2].re + tmpz[n34].re;\n\n            tmp1 = tmpz[ n2].re - tmpz[n34].re;\n\n            tmp6 = tmpz[ n2].im + tmpz[n34].im;\n\n            tmp2 = tmpz[ n2].im - tmpz[n34].im;\n\n\n\n            tmpz[ n2].re = tmpz[ 0].re - tmp5;\n\n            tmpz[  0].re = tmpz[ 0].re + tmp5;\n\n            tmpz[ n2].im = tmpz[ 0].im - tmp6;\n\n            tmpz[  0].im = tmpz[ 0].im + tmp6;\n\n            tmpz[n34].re = tmpz[n4].re - tmp2;\n\n            tmpz[ n4].re = tmpz[n4].re + tmp2;\n\n            tmpz[n34].im = tmpz[n4].im + tmp1;\n\n            tmpz[ n4].im = tmpz[n4].im - tmp1;\n\n\n\n            for (i=1; i<n4; i++){\n\n                FFTSample w_re = w_re_ptr[0];\n\n                FFTSample w_im = w_im_ptr[0];\n\n                accu  = (int64_t)w_re*tmpz[ n2+i].re;\n\n                accu += (int64_t)w_im*tmpz[ n2+i].im;\n\n                tmp1 = (int32_t)((accu + 0x40000000) >> 31);\n\n                accu  = (int64_t)w_re*tmpz[ n2+i].im;\n\n                accu -= (int64_t)w_im*tmpz[ n2+i].re;\n\n                tmp2 = (int32_t)((accu + 0x40000000) >> 31);\n\n                accu  = (int64_t)w_re*tmpz[n34+i].re;\n\n                accu -= (int64_t)w_im*tmpz[n34+i].im;\n\n                tmp3 = (int32_t)((accu + 0x40000000) >> 31);\n\n                accu  = (int64_t)w_re*tmpz[n34+i].im;\n\n                accu += (int64_t)w_im*tmpz[n34+i].re;\n\n                tmp4 = (int32_t)((accu + 0x40000000) >> 31);\n\n\n\n                tmp5 = tmp1 + tmp3;\n\n                tmp1 = tmp1 - tmp3;\n\n                tmp6 = tmp2 + tmp4;\n\n                tmp2 = tmp2 - tmp4;\n\n\n\n                tmpz[ n2+i].re = tmpz[   i].re - tmp5;\n\n                tmpz[    i].re = tmpz[   i].re + tmp5;\n\n                tmpz[ n2+i].im = tmpz[   i].im - tmp6;\n\n                tmpz[    i].im = tmpz[   i].im + tmp6;\n\n                tmpz[n34+i].re = tmpz[n4+i].re - tmp2;\n\n                tmpz[ n4+i].re = tmpz[n4+i].re + tmp2;\n\n                tmpz[n34+i].im = tmpz[n4+i].im + tmp1;\n\n                tmpz[ n4+i].im = tmpz[n4+i].im - tmp1;\n\n\n\n                w_re_ptr += step;\n\n                w_im_ptr -= step;\n\n            }\n\n        }\n\n        step >>= 1;\n\n        n4   <<= 1;\n\n    }\n\n}\n", "idx": 21386, "_split": "test", "_hash": "819ce3dec6a3fc020b6c79eb8f802df0"}
{"project": "FFmpeg", "commit_id": "577393321c389ad2973bec6168a8045c94a9e099", "target": 0, "func": "int ff_wmv2_decode_secondary_picture_header(MpegEncContext *s)\n\n{\n\n    Wmv2Context *const w = (Wmv2Context *) s;\n\n\n\n    if (s->pict_type == AV_PICTURE_TYPE_I) {\n\n        if (w->j_type_bit)\n\n            w->j_type = get_bits1(&s->gb);\n\n        else\n\n            w->j_type = 0; // FIXME check\n\n\n\n        if (!w->j_type) {\n\n            if (w->per_mb_rl_bit)\n\n                s->per_mb_rl_table = get_bits1(&s->gb);\n\n            else\n\n                s->per_mb_rl_table = 0;\n\n\n\n            if (!s->per_mb_rl_table) {\n\n                s->rl_chroma_table_index = decode012(&s->gb);\n\n                s->rl_table_index        = decode012(&s->gb);\n\n            }\n\n\n\n            s->dc_table_index = get_bits1(&s->gb);\n\n        }\n\n        s->inter_intra_pred = 0;\n\n        s->no_rounding      = 1;\n\n        if (s->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"qscale:%d rlc:%d rl:%d dc:%d mbrl:%d j_type:%d \\n\",\n\n                   s->qscale, s->rl_chroma_table_index, s->rl_table_index,\n\n                   s->dc_table_index, s->per_mb_rl_table, w->j_type);\n\n        }\n\n    } else {\n\n        int cbp_index;\n\n        w->j_type = 0;\n\n\n\n        parse_mb_skip(w);\n\n        cbp_index = decode012(&s->gb);\n\n        if (s->qscale <= 10) {\n\n            int map[3]         = { 0, 2, 1 };\n\n            w->cbp_table_index = map[cbp_index];\n\n        } else if (s->qscale <= 20) {\n\n            int map[3]         = { 1, 0, 2 };\n\n            w->cbp_table_index = map[cbp_index];\n\n        } else {\n\n            int map[3]         = {2,1,0};\n\n            w->cbp_table_index = map[cbp_index];\n\n        }\n\n\n\n        if (w->mspel_bit)\n\n            s->mspel = get_bits1(&s->gb);\n\n        else\n\n            s->mspel = 0; // FIXME check\n\n\n\n        if (w->abt_flag) {\n\n            w->per_mb_abt = get_bits1(&s->gb) ^ 1;\n\n            if (!w->per_mb_abt)\n\n                w->abt_type = decode012(&s->gb);\n\n        }\n\n\n\n        if (w->per_mb_rl_bit)\n\n            s->per_mb_rl_table = get_bits1(&s->gb);\n\n        else\n\n            s->per_mb_rl_table = 0;\n\n\n\n        if (!s->per_mb_rl_table) {\n\n            s->rl_table_index        = decode012(&s->gb);\n\n            s->rl_chroma_table_index = s->rl_table_index;\n\n        }\n\n\n\n        s->dc_table_index   = get_bits1(&s->gb);\n\n        s->mv_table_index   = get_bits1(&s->gb);\n\n\n\n        s->inter_intra_pred = 0; // (s->width * s->height < 320 * 240 && s->bit_rate <= II_BITRATE);\n\n        s->no_rounding     ^= 1;\n\n\n\n        if (s->avctx->debug & FF_DEBUG_PICT_INFO) {\n\n            av_log(s->avctx, AV_LOG_DEBUG,\n\n                   \"rl:%d rlc:%d dc:%d mv:%d mbrl:%d qp:%d mspel:%d \"\n\n                   \"per_mb_abt:%d abt_type:%d cbp:%d ii:%d\\n\",\n\n                   s->rl_table_index, s->rl_chroma_table_index,\n\n                   s->dc_table_index, s->mv_table_index,\n\n                   s->per_mb_rl_table, s->qscale, s->mspel,\n\n                   w->per_mb_abt, w->abt_type, w->cbp_table_index,\n\n                   s->inter_intra_pred);\n\n        }\n\n    }\n\n    s->esc3_level_length = 0;\n\n    s->esc3_run_length   = 0;\n\n    s->picture_number++; // FIXME ?\n\n\n\n    if (w->j_type) {\n\n        ff_intrax8_decode_picture(&w->x8, 2 * s->qscale, (s->qscale - 1) | 1);\n\n\n\n        ff_er_add_slice(&w->s.er, 0, 0,\n\n                        (w->s.mb_x >> 1) - 1, (w->s.mb_y >> 1) - 1,\n\n                        ER_MB_END);\n\n        return 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 21576, "_split": "test", "_hash": "6b0fe96df68eee844426202da0c4483f"}
{"project": "FFmpeg", "commit_id": "a494792961a08f9f0e47e7eeed65e609178ff436", "target": 1, "func": "static void fill_table(uint8_t* table[256 + 2*YUVRGB_TABLE_HEADROOM], const int elemsize,\n\n                       const int inc, void *y_tab)\n\n{\n\n    int i;\n\n    uint8_t *y_table = y_tab;\n\n\n\n    y_table -= elemsize * (inc >> 9);\n\n\n\n    for (i = 0; i < 256 + 2*YUVRGB_TABLE_HEADROOM; i++) {\n\n        int64_t cb = av_clip(i-YUVRGB_TABLE_HEADROOM, 0, 255)*inc;\n\n        table[i] = y_table + elemsize * (cb >> 16);\n\n    }\n\n}\n", "idx": 21583, "_split": "test", "_hash": "81bb642fc3c5986d65c1494197ea6543"}
{"project": "FFmpeg", "commit_id": "f3e5a7844bbf13620ca4b6a5e19aa087c9141b15", "target": 0, "func": "static int allocate_buffers(ALACContext *alac)\n\n{\n\n    int ch;\n\n    for (ch = 0; ch < FFMIN(alac->channels, 2); ch++) {\n\n        int buf_size = alac->max_samples_per_frame * sizeof(int32_t);\n\n\n\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->predict_error_buffer[ch],\n\n                         buf_size, buf_alloc_fail);\n\n\n\n        if (alac->sample_size == 16) {\n\n            FF_ALLOC_OR_GOTO(alac->avctx, alac->output_samples_buffer[ch],\n\n                             buf_size, buf_alloc_fail);\n\n        }\n\n\n\n        FF_ALLOC_OR_GOTO(alac->avctx, alac->extra_bits_buffer[ch],\n\n                         buf_size, buf_alloc_fail);\n\n    }\n\n    return 0;\n\nbuf_alloc_fail:\n\n    alac_decode_close(alac->avctx);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 21584, "_split": "test", "_hash": "d7397a7ab344759c58fc36f46576cd3b"}
{"project": "FFmpeg", "commit_id": "83fd377c94d8fbffdb3e69fb3efe1976ff897a88", "target": 0, "func": "static int put_cod(Jpeg2000EncoderContext *s)\n\n{\n\n    Jpeg2000CodingStyle *codsty = &s->codsty;\n\n\n\n    if (s->buf_end - s->buf < 14)\n\n        return -1;\n\n\n\n    bytestream_put_be16(&s->buf, JPEG2000_COD);\n\n    bytestream_put_be16(&s->buf, 12); // Lcod\n\n    bytestream_put_byte(&s->buf, 0);  // Scod\n\n    // SGcod\n\n    bytestream_put_byte(&s->buf, 0); // progression level\n\n    bytestream_put_be16(&s->buf, 1); // num of layers\n\n    if(s->avctx->pix_fmt == AV_PIX_FMT_YUV444P){\n\n        bytestream_put_byte(&s->buf, 2); // ICT\n\n    }else{\n\n        bytestream_put_byte(&s->buf, 0); // unspecified\n\n    }\n\n    // SPcod\n\n    bytestream_put_byte(&s->buf, codsty->nreslevels - 1); // num of decomp. levels\n\n    bytestream_put_byte(&s->buf, codsty->log2_cblk_width-2); // cblk width\n\n    bytestream_put_byte(&s->buf, codsty->log2_cblk_height-2); // cblk height\n\n    bytestream_put_byte(&s->buf, 0); // cblk style\n\n    bytestream_put_byte(&s->buf, codsty->transform); // transformation\n\n    return 0;\n\n}\n", "idx": 21585, "_split": "test", "_hash": "b55b5484ea882acb17a070f73a0a00fd"}
{"project": "FFmpeg", "commit_id": "40cf1bbacc6220a0aa6bed5c331871d43f9ce370", "target": 0, "func": "static int libschroedinger_encode_frame(AVCodecContext *avctx, AVPacket *pkt,\n\n                                        const AVFrame *frame, int *got_packet)\n\n{\n\n    int enc_size = 0;\n\n    SchroEncoderParams *p_schro_params = avctx->priv_data;\n\n    SchroEncoder *encoder = p_schro_params->encoder;\n\n    struct FFSchroEncodedFrame *p_frame_output = NULL;\n\n    int go = 1;\n\n    SchroBuffer *enc_buf;\n\n    int presentation_frame;\n\n    int parse_code;\n\n    int last_frame_in_sequence = 0;\n\n    int pkt_size, ret;\n\n\n\n    if (!frame) {\n\n        /* Push end of sequence if not already signalled. */\n\n        if (!p_schro_params->eos_signalled) {\n\n            schro_encoder_end_of_stream(encoder);\n\n            p_schro_params->eos_signalled = 1;\n\n        }\n\n    } else {\n\n        /* Allocate frame data to schro input buffer. */\n\n        SchroFrame *in_frame = libschroedinger_frame_from_data(avctx, frame);\n\n        if (!in_frame)\n\n            return AVERROR(ENOMEM);\n\n        /* Load next frame. */\n\n        schro_encoder_push_frame(encoder, in_frame);\n\n    }\n\n\n\n    if (p_schro_params->eos_pulled)\n\n        go = 0;\n\n\n\n    /* Now check to see if we have any output from the encoder. */\n\n    while (go) {\n\n        int err;\n\n        SchroStateEnum state;\n\n        state = schro_encoder_wait(encoder);\n\n        switch (state) {\n\n        case SCHRO_STATE_HAVE_BUFFER:\n\n        case SCHRO_STATE_END_OF_STREAM:\n\n            enc_buf = schro_encoder_pull(encoder, &presentation_frame);\n\n            if (enc_buf->length <= 0)\n\n                return AVERROR_BUG;\n\n            parse_code = enc_buf->data[4];\n\n\n\n            /* All non-frame data is prepended to actual frame data to\n\n             * be able to set the pts correctly. So we don't write data\n\n             * to the frame output queue until we actually have a frame\n\n             */\n\n            if ((err = av_reallocp(&p_schro_params->enc_buf,\n\n                                   p_schro_params->enc_buf_size +\n\n                                   enc_buf->length)) < 0) {\n\n                p_schro_params->enc_buf_size = 0;\n\n                return err;\n\n            }\n\n\n\n            memcpy(p_schro_params->enc_buf + p_schro_params->enc_buf_size,\n\n                   enc_buf->data, enc_buf->length);\n\n            p_schro_params->enc_buf_size += enc_buf->length;\n\n\n\n\n\n            if (state == SCHRO_STATE_END_OF_STREAM) {\n\n                p_schro_params->eos_pulled = 1;\n\n                go = 0;\n\n            }\n\n\n\n            if (!SCHRO_PARSE_CODE_IS_PICTURE(parse_code)) {\n\n                schro_buffer_unref(enc_buf);\n\n                break;\n\n            }\n\n\n\n            /* Create output frame. */\n\n            p_frame_output = av_mallocz(sizeof(FFSchroEncodedFrame));\n\n            if (!p_frame_output)\n\n                return AVERROR(ENOMEM);\n\n            /* Set output data. */\n\n            p_frame_output->size     = p_schro_params->enc_buf_size;\n\n            p_frame_output->p_encbuf = p_schro_params->enc_buf;\n\n            if (SCHRO_PARSE_CODE_IS_INTRA(parse_code) &&\n\n                SCHRO_PARSE_CODE_IS_REFERENCE(parse_code))\n\n                p_frame_output->key_frame = 1;\n\n\n\n            /* Parse the coded frame number from the bitstream. Bytes 14\n\n             * through 17 represesent the frame number. */\n\n            p_frame_output->frame_num = AV_RB32(enc_buf->data + 13);\n\n\n\n            ff_schro_queue_push_back(&p_schro_params->enc_frame_queue,\n\n                                     p_frame_output);\n\n            p_schro_params->enc_buf_size = 0;\n\n            p_schro_params->enc_buf      = NULL;\n\n\n\n            schro_buffer_unref(enc_buf);\n\n\n\n            break;\n\n\n\n        case SCHRO_STATE_NEED_FRAME:\n\n            go = 0;\n\n            break;\n\n\n\n        case SCHRO_STATE_AGAIN:\n\n            break;\n\n\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unknown Schro Encoder state\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    /* Copy 'next' frame in queue. */\n\n\n\n    if (p_schro_params->enc_frame_queue.size == 1 &&\n\n        p_schro_params->eos_pulled)\n\n        last_frame_in_sequence = 1;\n\n\n\n    p_frame_output = ff_schro_queue_pop(&p_schro_params->enc_frame_queue);\n\n\n\n    if (!p_frame_output)\n\n        return 0;\n\n\n\n    pkt_size = p_frame_output->size;\n\n    if (last_frame_in_sequence && p_schro_params->enc_buf_size > 0)\n\n        pkt_size += p_schro_params->enc_buf_size;\n\n    if ((ret = ff_alloc_packet(pkt, pkt_size)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet of size %d.\\n\", pkt_size);\n\n        goto error;\n\n    }\n\n\n\n    memcpy(pkt->data, p_frame_output->p_encbuf, p_frame_output->size);\n\n    avctx->coded_frame->key_frame = p_frame_output->key_frame;\n\n    /* Use the frame number of the encoded frame as the pts. It is OK to\n\n     * do so since Dirac is a constant frame rate codec. It expects input\n\n     * to be of constant frame rate. */\n\n    pkt->pts =\n\n    avctx->coded_frame->pts = p_frame_output->frame_num;\n\n    pkt->dts = p_schro_params->dts++;\n\n    enc_size = p_frame_output->size;\n\n\n\n    /* Append the end of sequence information to the last frame in the\n\n     * sequence. */\n\n    if (last_frame_in_sequence && p_schro_params->enc_buf_size > 0) {\n\n        memcpy(pkt->data + enc_size, p_schro_params->enc_buf,\n\n               p_schro_params->enc_buf_size);\n\n        enc_size += p_schro_params->enc_buf_size;\n\n        av_freep(&p_schro_params->enc_buf);\n\n        p_schro_params->enc_buf_size = 0;\n\n    }\n\n\n\n    if (p_frame_output->key_frame)\n\n        pkt->flags |= AV_PKT_FLAG_KEY;\n\n    *got_packet = 1;\n\n\n\nerror:\n\n    /* free frame */\n\n    libschroedinger_free_frame(p_frame_output);\n\n    return ret;\n\n}\n", "idx": 21641, "_split": "test", "_hash": "01347fb199df998db72196cbae10bd7f"}
{"project": "FFmpeg", "commit_id": "d4f7d8386693beb987382ece8bb7499955620388", "target": 0, "func": "static int fill_default_ref_list(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    int i;\n\n    int smallest_poc_greater_than_current = -1;\n\n    int structure_sel;\n\n    Picture sorted_short_ref[32];\n\n    Picture field_entry_list[2][32];\n\n    Picture *frame_list[2];\n\n\n\n    if (FIELD_PICTURE) {\n\n        structure_sel = PICT_FRAME;\n\n        frame_list[0] = field_entry_list[0];\n\n        frame_list[1] = field_entry_list[1];\n\n    } else {\n\n        structure_sel = 0;\n\n        frame_list[0] = h->default_ref_list[0];\n\n        frame_list[1] = h->default_ref_list[1];\n\n    }\n\n\n\n    if(h->slice_type_nos==FF_B_TYPE){\n\n        int list;\n\n        int len[2];\n\n        int short_len[2];\n\n        int out_i;\n\n        int limit= INT_MIN;\n\n\n\n        /* sort frame according to POC in B slice */\n\n        for(out_i=0; out_i<h->short_ref_count; out_i++){\n\n            int best_i=INT_MIN;\n\n            int best_poc=INT_MAX;\n\n\n\n            for(i=0; i<h->short_ref_count; i++){\n\n                const int poc= h->short_ref[i]->poc;\n\n                if(poc > limit && poc < best_poc){\n\n                    best_poc= poc;\n\n                    best_i= i;\n\n                }\n\n            }\n\n\n\n            assert(best_i != INT_MIN);\n\n\n\n            limit= best_poc;\n\n            sorted_short_ref[out_i]= *h->short_ref[best_i];\n\n            tprintf(h->s.avctx, \"sorted poc: %d->%d poc:%d fn:%d\\n\", best_i, out_i, sorted_short_ref[out_i].poc, sorted_short_ref[out_i].frame_num);\n\n            if (-1 == smallest_poc_greater_than_current) {\n\n                if (h->short_ref[best_i]->poc >= s->current_picture_ptr->poc) {\n\n                    smallest_poc_greater_than_current = out_i;\n\n                }\n\n            }\n\n        }\n\n\n\n        tprintf(h->s.avctx, \"current poc: %d, smallest_poc_greater_than_current: %d\\n\", s->current_picture_ptr->poc, smallest_poc_greater_than_current);\n\n\n\n        // find the largest POC\n\n        for(list=0; list<2; list++){\n\n            int index = 0;\n\n            int j= -99;\n\n            int step= list ? -1 : 1;\n\n\n\n            for(i=0; i<h->short_ref_count && index < h->ref_count[list]; i++, j+=step) {\n\n                int sel;\n\n                while(j<0 || j>= h->short_ref_count){\n\n                    if(j != -99 && step == (list ? -1 : 1))\n\n                        return -1;\n\n                    step = -step;\n\n                    j= smallest_poc_greater_than_current + (step>>1);\n\n                }\n\n                sel = sorted_short_ref[j].reference | structure_sel;\n\n                if(sel != PICT_FRAME) continue;\n\n                frame_list[list][index  ]= sorted_short_ref[j];\n\n                frame_list[list][index++].pic_id= sorted_short_ref[j].frame_num;\n\n            }\n\n            short_len[list] = index;\n\n\n\n            for(i = 0; i < 16 && index < h->ref_count[ list ]; i++){\n\n                int sel;\n\n                if(h->long_ref[i] == NULL) continue;\n\n                sel = h->long_ref[i]->reference | structure_sel;\n\n                if(sel != PICT_FRAME) continue;\n\n\n\n                frame_list[ list ][index  ]= *h->long_ref[i];\n\n                frame_list[ list ][index++].pic_id= i;\n\n            }\n\n            len[list] = index;\n\n        }\n\n\n\n        for(list=0; list<2; list++){\n\n            if (FIELD_PICTURE)\n\n                len[list] = split_field_ref_list(h->default_ref_list[list],\n\n                                                 h->ref_count[list],\n\n                                                 frame_list[list],\n\n                                                 len[list],\n\n                                                 s->picture_structure,\n\n                                                 short_len[list]);\n\n\n\n            // swap the two first elements of L1 when L0 and L1 are identical\n\n            if(list && len[0] > 1 && len[0] == len[1])\n\n                for(i=0; h->default_ref_list[0][i].data[0] == h->default_ref_list[1][i].data[0]; i++)\n\n                    if(i == len[0]){\n\n                        FFSWAP(Picture, h->default_ref_list[1][0], h->default_ref_list[1][1]);\n\n                        break;\n\n                    }\n\n\n\n            if(len[list] < h->ref_count[ list ])\n\n                memset(&h->default_ref_list[list][len[list]], 0, sizeof(Picture)*(h->ref_count[ list ] - len[list]));\n\n        }\n\n\n\n\n\n    }else{\n\n        int index=0;\n\n        int short_len;\n\n        for(i=0; i<h->short_ref_count; i++){\n\n            int sel;\n\n            sel = h->short_ref[i]->reference | structure_sel;\n\n            if(sel != PICT_FRAME) continue;\n\n            frame_list[0][index  ]= *h->short_ref[i];\n\n            frame_list[0][index++].pic_id= h->short_ref[i]->frame_num;\n\n        }\n\n        short_len = index;\n\n        for(i = 0; i < 16; i++){\n\n            int sel;\n\n            if(h->long_ref[i] == NULL) continue;\n\n            sel = h->long_ref[i]->reference | structure_sel;\n\n            if(sel != PICT_FRAME) continue;\n\n            frame_list[0][index  ]= *h->long_ref[i];\n\n            frame_list[0][index++].pic_id= i;\n\n        }\n\n\n\n        if (FIELD_PICTURE)\n\n            index = split_field_ref_list(h->default_ref_list[0],\n\n                                         h->ref_count[0], frame_list[0],\n\n                                         index, s->picture_structure,\n\n                                         short_len);\n\n\n\n        if(index < h->ref_count[0])\n\n            memset(&h->default_ref_list[0][index], 0, sizeof(Picture)*(h->ref_count[0] - index));\n\n    }\n\n#ifdef TRACE\n\n    for (i=0; i<h->ref_count[0]; i++) {\n\n        tprintf(h->s.avctx, \"List0: %s fn:%d 0x%p\\n\", (h->default_ref_list[0][i].long_ref ? \"LT\" : \"ST\"), h->default_ref_list[0][i].pic_id, h->default_ref_list[0][i].data[0]);\n\n    }\n\n    if(h->slice_type_nos==FF_B_TYPE){\n\n        for (i=0; i<h->ref_count[1]; i++) {\n\n            tprintf(h->s.avctx, \"List1: %s fn:%d 0x%p\\n\", (h->default_ref_list[1][i].long_ref ? \"LT\" : \"ST\"), h->default_ref_list[1][i].pic_id, h->default_ref_list[1][i].data[0]);\n\n        }\n\n    }\n\n#endif\n\n    return 0;\n\n}\n", "idx": 21665, "_split": "test", "_hash": "37af78c629eec1b5970a0b03ca2c9241"}
{"project": "FFmpeg", "commit_id": "ae3da0ae5550053583a6f281ea7fd940497ea0d1", "target": 1, "func": "static int decode_band(IVI45DecContext *ctx, int plane_num,\n\n                       IVIBandDesc *band, AVCodecContext *avctx)\n\n{\n\n    int         result, i, t, idx1, idx2, pos;\n\n    IVITile     *tile;\n\n\n\n    band->buf     = band->bufs[ctx->dst_buf];\n\n    if (!band->buf) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Band buffer points to no data!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    band->ref_buf = band->bufs[ctx->ref_buf];\n\n    band->data_ptr = ctx->frame_data + (get_bits_count(&ctx->gb) >> 3);\n\n\n\n    result = ctx->decode_band_hdr(ctx, band, avctx);\n\n    if (result) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error while decoding band header: %d\\n\",\n\n               result);\n\n        return result;\n\n    }\n\n\n\n    if (band->is_empty) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Empty band encountered!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    band->rv_map = &ctx->rvmap_tabs[band->rvmap_sel];\n\n\n\n    /* apply corrections to the selected rvmap table if present */\n\n    for (i = 0; i < band->num_corr; i++) {\n\n        idx1 = band->corr[i * 2];\n\n        idx2 = band->corr[i * 2 + 1];\n\n        FFSWAP(uint8_t, band->rv_map->runtab[idx1], band->rv_map->runtab[idx2]);\n\n        FFSWAP(int16_t, band->rv_map->valtab[idx1], band->rv_map->valtab[idx2]);\n\n    }\n\n\n\n    pos = get_bits_count(&ctx->gb);\n\n\n\n    for (t = 0; t < band->num_tiles; t++) {\n\n        tile = &band->tiles[t];\n\n\n\n        if (tile->mb_size != band->mb_size) {\n\n            av_log(avctx, AV_LOG_ERROR, \"MB sizes mismatch: %d vs. %d\\n\",\n\n                   band->mb_size, tile->mb_size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        tile->is_empty = get_bits1(&ctx->gb);\n\n        if (tile->is_empty) {\n\n            ivi_process_empty_tile(avctx, band, tile,\n\n                                      (ctx->planes[0].bands[0].mb_size >> 3) - (band->mb_size >> 3));\n\n            av_dlog(avctx, \"Empty tile encountered!\\n\");\n\n        } else {\n\n            tile->data_size = ff_ivi_dec_tile_data_size(&ctx->gb);\n\n            if (!tile->data_size) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Tile data size is zero!\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            result = ctx->decode_mb_info(ctx, band, tile, avctx);\n\n            if (result < 0)\n\n                break;\n\n\n\n            result = ff_ivi_decode_blocks(&ctx->gb, band, tile);\n\n            if (result < 0 || ((get_bits_count(&ctx->gb) - pos) >> 3) != tile->data_size) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Corrupted tile data encountered!\\n\");\n\n                break;\n\n            }\n\n\n\n            pos += tile->data_size << 3; // skip to next tile\n\n        }\n\n    }\n\n\n\n    /* restore the selected rvmap table by applying its corrections in reverse order */\n\n    for (i = band->num_corr-1; i >= 0; i--) {\n\n        idx1 = band->corr[i*2];\n\n        idx2 = band->corr[i*2+1];\n\n        FFSWAP(uint8_t, band->rv_map->runtab[idx1], band->rv_map->runtab[idx2]);\n\n        FFSWAP(int16_t, band->rv_map->valtab[idx1], band->rv_map->valtab[idx2]);\n\n    }\n\n\n\n#ifdef DEBUG\n\n    if (band->checksum_present) {\n\n        uint16_t chksum = ivi_calc_band_checksum(band);\n\n        if (chksum != band->checksum) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"Band checksum mismatch! Plane %d, band %d, received: %x, calculated: %x\\n\",\n\n                   band->plane, band->band_num, band->checksum, chksum);\n\n        }\n\n    }\n\n#endif\n\n\n\n    align_get_bits(&ctx->gb);\n\n\n\n    return result;\n\n}\n", "idx": 21708, "_split": "test", "_hash": "11e63048e917a3ba891e5d1820f73c49"}
{"project": "FFmpeg", "commit_id": "17269bdfcdb79679f6b92024d1228e876b799a63", "target": 1, "func": "static int swf_write_trailer(AVFormatContext *s)\n\n{\n\n    SWFContext *swf = s->priv_data;\n\n    ByteIOContext *pb = &s->pb;\n\n    AVCodecContext *enc, *video_enc;\n\n    int file_size, i;\n\n\n\n    video_enc = NULL;\n\n    for(i=0;i<s->nb_streams;i++) {\n\n        enc = &s->streams[i]->codec;\n\n        if (enc->codec_type == CODEC_TYPE_VIDEO)\n\n            video_enc = enc;\n\n    }\n\n\n\n    put_swf_tag(s, TAG_END);\n\n    put_swf_end_tag(s);\n\n    \n\n    put_flush_packet(&s->pb);\n\n\n\n    /* patch file size and number of frames if not streamed */\n\n    if (!url_is_streamed(&s->pb) && video_enc) {\n\n        file_size = url_ftell(pb);\n\n        url_fseek(pb, 4, SEEK_SET);\n\n        put_le32(pb, file_size);\n\n        url_fseek(pb, swf->duration_pos, SEEK_SET);\n\n        put_le16(pb, video_enc->frame_number);\n\n    }\n\n    av_free(swf);\n\n    return 0;\n\n}\n", "idx": 21750, "_split": "test", "_hash": "5d421fac3495df3f2e2b03ab834eb4ca"}
{"project": "FFmpeg", "commit_id": "fbfbd97be25c4da0562ef61e2f27192d1ec4d276", "target": 1, "func": "static int xpm_decode_frame(AVCodecContext *avctx, void *data,\n\n                            int *got_frame, AVPacket *avpkt)\n\n{\n\n    XPMDecContext *x = avctx->priv_data;\n\n    AVFrame *p=data;\n\n    const uint8_t *end, *ptr = avpkt->data;\n\n    int ncolors, cpp, ret, i, j;\n\n    int64_t size;\n\n    uint32_t *dst;\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_BGRA;\n\n\n\n    end = avpkt->data + avpkt->size;\n\n    while (memcmp(ptr, \"/* XPM */\\n\", 10) && ptr < end - 10)\n\n        ptr++;\n\n\n\n    if (ptr >= end) {\n\n        av_log(avctx, AV_LOG_ERROR, \"missing signature\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    ptr += mod_strcspn(ptr, \"\\\"\");\n\n    if (sscanf(ptr, \"\\\"%u %u %u %u\\\",\",\n\n               &avctx->width, &avctx->height, &ncolors, &cpp) != 4) {\n\n        av_log(avctx, AV_LOG_ERROR, \"missing image parameters\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if ((ret = ff_set_dimensions(avctx, avctx->width, avctx->height)) < 0)\n\n        return ret;\n\n\n\n    if ((ret = ff_get_buffer(avctx, p, 0)) < 0)\n\n        return ret;\n\n\n\n    if (cpp <= 0 || cpp >= 5) {\n\n        av_log(avctx, AV_LOG_ERROR, \"unsupported/invalid number of chars per pixel: %d\\n\", cpp);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    size = 1;\n\n    for (i = 0; i < cpp; i++)\n\n        size *= 94;\n\n\n\n    if (ncolors <= 0 || ncolors > size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid number of colors: %d\\n\", ncolors);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    size *= 4;\n\n\n\n    av_fast_padded_malloc(&x->pixels, &x->pixels_size, size);\n\n    if (!x->pixels)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ptr += mod_strcspn(ptr, \",\") + 1;\n\n    for (i = 0; i < ncolors; i++) {\n\n        const uint8_t *index;\n\n        int len;\n\n\n\n        ptr += mod_strcspn(ptr, \"\\\"\") + 1;\n\n        if (ptr + cpp > end)\n\n            return AVERROR_INVALIDDATA;\n\n        index = ptr;\n\n        ptr += cpp;\n\n\n\n        ptr = strstr(ptr, \"c \");\n\n        if (ptr) {\n\n            ptr += 2;\n\n        } else {\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n\n\n        len = strcspn(ptr, \"\\\" \");\n\n\n\n        if ((ret = ascii2index(index, cpp)) < 0)\n\n            return ret;\n\n\n\n        x->pixels[ret] = color_string_to_rgba(ptr, len);\n\n        ptr += mod_strcspn(ptr, \",\") + 1;\n\n    }\n\n\n\n    for (i = 0; i < avctx->height; i++) {\n\n        dst = (uint32_t *)(p->data[0] + i * p->linesize[0]);\n\n        ptr += mod_strcspn(ptr, \"\\\"\") + 1;\n\n\n\n        for (j = 0; j < avctx->width; j++) {\n\n            if (ptr + cpp > end)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            if ((ret = ascii2index(ptr, cpp)) < 0)\n\n                return ret;\n\n\n\n            *dst++ = x->pixels[ret];\n\n            ptr += cpp;\n\n        }\n\n        ptr += mod_strcspn(ptr, \",\") + 1;\n\n    }\n\n\n\n    p->key_frame = 1;\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    *got_frame = 1;\n\n\n\n    return avpkt->size;\n\n}\n", "idx": 21762, "_split": "test", "_hash": "fab23c173e88f05820f122245b17c9ba"}
{"project": "FFmpeg", "commit_id": "452ac2aaecf7210a2912d9156869c6314142a794", "target": 0, "func": "static void ripemd160_transform(uint32_t *state, const uint8_t buffer[64], int ext)\n\n{\n\n    uint32_t a, b, c, d, e, f, g, h, i, j;\n\n    uint32_t block[16];\n\n    int n;\n\n\n\n    if (ext) {\n\n        a = state[0]; b = state[1]; c = state[2]; d = state[3]; e = state[4];\n\n        f = state[5]; g = state[6]; h = state[7]; i = state[8]; j = state[9];\n\n    } else {\n\n        a = f = state[0];\n\n        b = g = state[1];\n\n        c = h = state[2];\n\n        d = i = state[3];\n\n        e = j = state[4];\n\n    }\n\n\n\n    for (n = 0; n < 16; n++)\n\n        block[n] = AV_RL32(buffer + 4 * n);\n\n\n\n    for (n = 0; n < 16 - 1;) {\n\n        ROUND160_0_TO_15(a,b,c,d,e,f,g,h,i,j);\n\n        ROUND160_0_TO_15(e,a,b,c,d,j,f,g,h,i);\n\n        ROUND160_0_TO_15(d,e,a,b,c,i,j,f,g,h);\n\n        ROUND160_0_TO_15(c,d,e,a,b,h,i,j,f,g);\n\n        ROUND160_0_TO_15(b,c,d,e,a,g,h,i,j,f);\n\n    }\n\n    ROUND160_0_TO_15(a,b,c,d,e,f,g,h,i,j);\n\n    SWAP(a,f)\n\n\n\n    for (; n < 32 - 1;) {\n\n        ROUND160_16_TO_31(e,a,b,c,d,j,f,g,h,i);\n\n        ROUND160_16_TO_31(d,e,a,b,c,i,j,f,g,h);\n\n        ROUND160_16_TO_31(c,d,e,a,b,h,i,j,f,g);\n\n        ROUND160_16_TO_31(b,c,d,e,a,g,h,i,j,f);\n\n        ROUND160_16_TO_31(a,b,c,d,e,f,g,h,i,j);\n\n    }\n\n    ROUND160_16_TO_31(e,a,b,c,d,j,f,g,h,i);\n\n    SWAP(b,g)\n\n\n\n    for (; n < 48 - 1;) {\n\n        ROUND160_32_TO_47(d,e,a,b,c,i,j,f,g,h);\n\n        ROUND160_32_TO_47(c,d,e,a,b,h,i,j,f,g);\n\n        ROUND160_32_TO_47(b,c,d,e,a,g,h,i,j,f);\n\n        ROUND160_32_TO_47(a,b,c,d,e,f,g,h,i,j);\n\n        ROUND160_32_TO_47(e,a,b,c,d,j,f,g,h,i);\n\n    }\n\n    ROUND160_32_TO_47(d,e,a,b,c,i,j,f,g,h);\n\n    SWAP(c,h)\n\n\n\n    for (; n < 64 - 1;) {\n\n        ROUND160_48_TO_63(c,d,e,a,b,h,i,j,f,g);\n\n        ROUND160_48_TO_63(b,c,d,e,a,g,h,i,j,f);\n\n        ROUND160_48_TO_63(a,b,c,d,e,f,g,h,i,j);\n\n        ROUND160_48_TO_63(e,a,b,c,d,j,f,g,h,i);\n\n        ROUND160_48_TO_63(d,e,a,b,c,i,j,f,g,h);\n\n    }\n\n    ROUND160_48_TO_63(c,d,e,a,b,h,i,j,f,g);\n\n    SWAP(d,i)\n\n\n\n    for (; n < 75;) {\n\n        ROUND160_64_TO_79(b,c,d,e,a,g,h,i,j,f);\n\n        ROUND160_64_TO_79(a,b,c,d,e,f,g,h,i,j);\n\n        ROUND160_64_TO_79(e,a,b,c,d,j,f,g,h,i);\n\n        ROUND160_64_TO_79(d,e,a,b,c,i,j,f,g,h);\n\n        ROUND160_64_TO_79(c,d,e,a,b,h,i,j,f,g);\n\n    }\n\n    ROUND160_64_TO_79(b,c,d,e,a,g,h,i,j,f);\n\n    SWAP(e,j)\n\n\n\n    if (ext) {\n\n        state[0] += a; state[1] += b; state[2] += c; state[3] += d; state[4] += e;\n\n        state[5] += f; state[6] += g; state[7] += h; state[8] += i; state[9] += j;\n\n    } else {\n\n        i += c + state[1];\n\n        state[1] = state[2] + d + j;\n\n        state[2] = state[3] + e + f;\n\n        state[3] = state[4] + a + g;\n\n        state[4] = state[0] + b + h;\n\n        state[0] = i;\n\n    }\n\n}\n", "idx": 21766, "_split": "test", "_hash": "e9a7af7a13665f8a708b317e4a33b7ab"}
{"project": "FFmpeg", "commit_id": "bc7eb330e3d42f6cff3f95432da999bd4538e2e1", "target": 0, "func": "static void opt_frame_size(const char *arg)\n\n{\n\n    if (av_parse_video_frame_size(&frame_width, &frame_height, arg) < 0) {\n\n        fprintf(stderr, \"Incorrect frame size\\n\");\n\n        av_exit(1);\n\n    }\n\n    if ((frame_width % 2) != 0 || (frame_height % 2) != 0) {\n\n        fprintf(stderr, \"Frame size must be a multiple of 2\\n\");\n\n        av_exit(1);\n\n    }\n\n}\n", "idx": 21767, "_split": "test", "_hash": "9f2ddca138feb03fcd8a946c9802e0d8"}
{"project": "FFmpeg", "commit_id": "20fe316e47fedb28787e77e77a7011133f3d4e73", "target": 1, "func": "static int sdl_write_trailer(AVFormatContext *s)\n\n{\n\n    SDLContext *sdl = s->priv_data;\n\n\n\n    sdl->quit = 1;\n\n\n\n    if (sdl->overlay)\n\n        SDL_FreeYUVOverlay(sdl->overlay);\n\n\n    if (sdl->event_thread)\n\n        SDL_WaitThread(sdl->event_thread, NULL);\n\n\n    if (sdl->mutex)\n\n        SDL_DestroyMutex(sdl->mutex);\n\n\n    if (sdl->init_cond)\n\n        SDL_DestroyCond(sdl->init_cond);\n\n\n\n\n    if (!sdl->sdl_was_already_inited)\n\n        SDL_Quit();\n\n\n\n    return 0;\n\n}", "idx": 21776, "_split": "test", "_hash": "12302cfa1015d598081f7fb3a8444c8b"}
{"project": "FFmpeg", "commit_id": "7f2fe444a39bca733d390b6608801c5f002bfd31", "target": 0, "func": "void MPV_decode_mb(MpegEncContext *s, DCTELEM block[6][64])\n\n{\n\n    int mb_x, mb_y;\n\n    int dct_linesize, dct_offset;\n\n    op_pixels_func *op_pix;\n\n    qpel_mc_func *op_qpix;\n\n\n\n    mb_x = s->mb_x;\n\n    mb_y = s->mb_y;\n\n\n\n#ifdef FF_POSTPROCESS\n\n    quant_store[mb_y][mb_x]=s->qscale;\n\n    //printf(\"[%02d][%02d] %d\\n\",mb_x,mb_y,s->qscale);\n\n#endif\n\n\n\n    /* update DC predictors for P macroblocks */\n\n    if (!s->mb_intra) {\n\n        if (s->h263_pred || s->h263_aic) {\n\n          if(s->mbintra_table[mb_x + mb_y*s->mb_width])\n\n          {\n\n            int wrap, xy, v;\n\n            s->mbintra_table[mb_x + mb_y*s->mb_width]=0;\n\n            wrap = 2 * s->mb_width + 2;\n\n            xy = 2 * mb_x + 1 +  (2 * mb_y + 1) * wrap;\n\n            v = 1024;\n\n            \n\n            s->dc_val[0][xy] = v;\n\n            s->dc_val[0][xy + 1] = v;\n\n            s->dc_val[0][xy + wrap] = v;\n\n            s->dc_val[0][xy + 1 + wrap] = v;\n\n            /* ac pred */\n\n            memset(s->ac_val[0][xy], 0, 16 * sizeof(INT16));\n\n            memset(s->ac_val[0][xy + 1], 0, 16 * sizeof(INT16));\n\n            memset(s->ac_val[0][xy + wrap], 0, 16 * sizeof(INT16));\n\n            memset(s->ac_val[0][xy + 1 + wrap], 0, 16 * sizeof(INT16));\n\n            if (s->h263_msmpeg4) {\n\n                s->coded_block[xy] = 0;\n\n                s->coded_block[xy + 1] = 0;\n\n                s->coded_block[xy + wrap] = 0;\n\n                s->coded_block[xy + 1 + wrap] = 0;\n\n            }\n\n            /* chroma */\n\n            wrap = s->mb_width + 2;\n\n            xy = mb_x + 1 + (mb_y + 1) * wrap;\n\n            s->dc_val[1][xy] = v;\n\n            s->dc_val[2][xy] = v;\n\n            /* ac pred */\n\n            memset(s->ac_val[1][xy], 0, 16 * sizeof(INT16));\n\n            memset(s->ac_val[2][xy], 0, 16 * sizeof(INT16));\n\n          }\n\n        } else {\n\n            s->last_dc[0] = 128 << s->intra_dc_precision;\n\n            s->last_dc[1] = 128 << s->intra_dc_precision;\n\n            s->last_dc[2] = 128 << s->intra_dc_precision;\n\n        }\n\n    }\n\n    else if (s->h263_pred || s->h263_aic)\n\n        s->mbintra_table[mb_x + mb_y*s->mb_width]=1;\n\n\n\n    /* update motion predictor, not for B-frames as they need the motion_val from the last P/S-Frame */\n\n    if (s->out_format == FMT_H263) { //FIXME move into h263.c if possible, format specific stuff shouldnt be here\n\n      if(s->pict_type!=B_TYPE){\n\n        int xy, wrap, motion_x, motion_y;\n\n        \n\n        wrap = 2 * s->mb_width + 2;\n\n        xy = 2 * mb_x + 1 + (2 * mb_y + 1) * wrap;\n\n        if (s->mb_intra) {\n\n            motion_x = 0;\n\n            motion_y = 0;\n\n            goto motion_init;\n\n        } else if (s->mv_type == MV_TYPE_16X16) {\n\n            motion_x = s->mv[0][0][0];\n\n            motion_y = s->mv[0][0][1];\n\n        motion_init:\n\n            /* no update if 8X8 because it has been done during parsing */\n\n            s->motion_val[xy][0] = motion_x;\n\n            s->motion_val[xy][1] = motion_y;\n\n            s->motion_val[xy + 1][0] = motion_x;\n\n            s->motion_val[xy + 1][1] = motion_y;\n\n            s->motion_val[xy + wrap][0] = motion_x;\n\n            s->motion_val[xy + wrap][1] = motion_y;\n\n            s->motion_val[xy + 1 + wrap][0] = motion_x;\n\n            s->motion_val[xy + 1 + wrap][1] = motion_y;\n\n        }\n\n      }\n\n    }\n\n    \n\n    if (!(s->encoding && (s->intra_only || s->pict_type==B_TYPE))) {\n\n        UINT8 *dest_y, *dest_cb, *dest_cr;\n\n        UINT8 *mbskip_ptr;\n\n\n\n        /* avoid copy if macroblock skipped in last frame too \n\n           dont touch it for B-frames as they need the skip info from the next p-frame */\n\n        if (s->pict_type != B_TYPE) {\n\n            mbskip_ptr = &s->mbskip_table[s->mb_y * s->mb_width + s->mb_x];\n\n            if (s->mb_skiped) {\n\n                s->mb_skiped = 0;\n\n                /* if previous was skipped too, then nothing to do ! \n\n                   skip only during decoding as we might trash the buffers during encoding a bit */\n\n                if (*mbskip_ptr != 0 && !s->encoding) \n\n                    goto the_end;\n\n                *mbskip_ptr = 1; /* indicate that this time we skiped it */\n\n            } else {\n\n                *mbskip_ptr = 0; /* not skipped */\n\n            }\n\n        }\n\n\n\n        dest_y = s->current_picture[0] + (mb_y * 16 * s->linesize) + mb_x * 16;\n\n        dest_cb = s->current_picture[1] + (mb_y * 8 * (s->linesize >> 1)) + mb_x * 8;\n\n        dest_cr = s->current_picture[2] + (mb_y * 8 * (s->linesize >> 1)) + mb_x * 8;\n\n\n\n        if (s->interlaced_dct) {\n\n            dct_linesize = s->linesize * 2;\n\n            dct_offset = s->linesize;\n\n        } else {\n\n            dct_linesize = s->linesize;\n\n            dct_offset = s->linesize * 8;\n\n        }\n\n\n\n        if (!s->mb_intra) {\n\n            /* motion handling */\n\n            if((s->flags&CODEC_FLAG_HQ) || (!s->encoding)){\n\n                if ((!s->no_rounding) || s->pict_type==B_TYPE){                \n\n                    op_pix = put_pixels_tab;\n\n                    op_qpix= qpel_mc_rnd_tab;\n\n                }else{\n\n                    op_pix = put_no_rnd_pixels_tab;\n\n                    op_qpix= qpel_mc_no_rnd_tab;\n\n                }\n\n\n\n                if (s->mv_dir & MV_DIR_FORWARD) {\n\n                    MPV_motion(s, dest_y, dest_cb, dest_cr, 0, s->last_picture, op_pix, op_qpix);\n\n                    if ((!s->no_rounding) || s->pict_type==B_TYPE)\n\n                        op_pix = avg_pixels_tab;\n\n                    else\n\n                        op_pix = avg_no_rnd_pixels_tab;\n\n                }\n\n                if (s->mv_dir & MV_DIR_BACKWARD) {\n\n                    MPV_motion(s, dest_y, dest_cb, dest_cr, 1, s->next_picture, op_pix, op_qpix);\n\n                }\n\n            }\n\n\n\n            /* add dct residue */\n\n            add_dct(s, block[0], 0, dest_y, dct_linesize);\n\n            add_dct(s, block[1], 1, dest_y + 8, dct_linesize);\n\n            add_dct(s, block[2], 2, dest_y + dct_offset, dct_linesize);\n\n            add_dct(s, block[3], 3, dest_y + dct_offset + 8, dct_linesize);\n\n\n\n            add_dct(s, block[4], 4, dest_cb, s->linesize >> 1);\n\n            add_dct(s, block[5], 5, dest_cr, s->linesize >> 1);\n\n        } else {\n\n            /* dct only in intra block */\n\n            put_dct(s, block[0], 0, dest_y, dct_linesize);\n\n            put_dct(s, block[1], 1, dest_y + 8, dct_linesize);\n\n            put_dct(s, block[2], 2, dest_y + dct_offset, dct_linesize);\n\n            put_dct(s, block[3], 3, dest_y + dct_offset + 8, dct_linesize);\n\n\n\n            put_dct(s, block[4], 4, dest_cb, s->linesize >> 1);\n\n            put_dct(s, block[5], 5, dest_cr, s->linesize >> 1);\n\n        }\n\n    }\n\n the_end:\n\n    emms_c(); //FIXME remove\n\n}\n", "idx": 21779, "_split": "test", "_hash": "f8b11e07d5f0a5126b03c064d6d0e8b6"}
{"project": "FFmpeg", "commit_id": "7cc84d241ba6ef8e27e4d057176a4ad385ad3d59", "target": 1, "func": "static int decode_i_picture_primary_header(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    int pqindex;\n\n\n\n    /* Prolog common to all frametypes should be done in caller */\n\n    //BF = Buffer Fullness\n\n    if (v->profile <= PROFILE_MAIN && get_bits(gb, 7))\n\n    {\n\n        av_log(v->s.avctx, AV_LOG_DEBUG, \"I BufferFullness not 0\\n\");\n\n    }\n\n\n\n    /* Quantizer stuff */\n\n    pqindex = get_bits(gb, 5);\n\n    if (v->quantizer_mode == QUANT_FRAME_IMPLICIT)\n\n        v->pq = pquant_table[0][pqindex];\n\n    else\n\n    {\n\n        v->pq = pquant_table[v->quantizer_mode-1][pqindex];\n\n    }\n\n    if (pqindex < 9) v->halfpq = get_bits(gb, 1);\n\n    if (v->quantizer_mode == QUANT_FRAME_EXPLICIT)\n\n        v->pquantizer = get_bits(gb, 1);\n\n    av_log(v->s.avctx, AV_LOG_DEBUG, \"I frame: QP=%i (+%i/2)\\n\",\n\n           v->pq, v->halfpq);\n\n    return 0;\n\n}\n", "idx": 21796, "_split": "test", "_hash": "bad497efe2bb2fcd63714a0d6c8bb2ba"}
{"project": "FFmpeg", "commit_id": "1a3598aae768465a8efc8475b6df5a8261bc62fc", "target": 1, "func": "static int get_bits(Jpeg2000DecoderContext *s, int n)\n\n{\n\n    int res = 0;\n\n    if (s->buf_end - s->buf < ((n - s->bit_index) >> 8))\n\n        return AVERROR_INVALIDDATA;\n\n    while (--n >= 0) {\n\n        res <<= 1;\n\n        if (s->bit_index == 0) {\n\n            s->bit_index = 7 + (*s->buf != 0xff);\n\n            s->buf++;\n\n        }\n\n        s->bit_index--;\n\n        res |= (*s->buf >> s->bit_index) & 1;\n\n    }\n\n    return res;\n\n}\n", "idx": 21822, "_split": "test", "_hash": "8ff4f5b114d8bc25c0563d5d2ea0971e"}
{"project": "FFmpeg", "commit_id": "bf252f7f6fa9c79743242f3efdd30827c97407b4", "target": 0, "func": "static int mov_read_udta_string(MOVContext *c, ByteIOContext *pb, MOVAtom atom)\n\n{\n\n    char *str = NULL;\n\n    int size;\n\n    uint16_t str_size;\n\n\n\n    if (c->itunes_metadata) {\n\n        int data_size = get_be32(pb);\n\n        int tag = get_le32(pb);\n\n        if (tag == MKTAG('d','a','t','a')) {\n\n            get_be32(pb); // type\n\n            get_be32(pb); // unknown\n\n            str_size = data_size - 16;\n\n        } else return 0;\n\n    } else {\n\n        str_size = get_be16(pb); // string length\n\n        get_be16(pb); // language\n\n    }\n\n    switch (atom.type) {\n\n    case MKTAG(0xa9,'n','a','m'):\n\n        str = c->fc->title; size = sizeof(c->fc->title); break;\n\n    case MKTAG(0xa9,'A','R','T'):\n\n    case MKTAG(0xa9,'w','r','t'):\n\n        str = c->fc->author; size = sizeof(c->fc->author); break;\n\n    case MKTAG(0xa9,'c','p','y'):\n\n        str = c->fc->copyright; size = sizeof(c->fc->copyright); break;\n\n    case MKTAG(0xa9,'c','m','t'):\n\n    case MKTAG(0xa9,'i','n','f'):\n\n        str = c->fc->comment; size = sizeof(c->fc->comment); break;\n\n    case MKTAG(0xa9,'a','l','b'):\n\n        str = c->fc->album; size = sizeof(c->fc->album); break;\n\n    }\n\n    if (!str)\n\n        return 0;\n\n    get_buffer(pb, str, FFMIN(size, str_size));\n\n    dprintf(c->fc, \"%.4s %s\\n\", (char*)&atom.type, str);\n\n    return 0;\n\n}\n", "idx": 21828, "_split": "test", "_hash": "7a2beaa4455958fb0bf851cdb5c2fa4d"}
{"project": "FFmpeg", "commit_id": "607ad990d31e6be52980970e5ce8cd25ab3de812", "target": 0, "func": "static int dvbsub_display_end_segment(AVCodecContext *avctx, const uint8_t *buf,\n\n                                        int buf_size, AVSubtitle *sub)\n\n{\n\n    DVBSubContext *ctx = avctx->priv_data;\n\n    DVBSubDisplayDefinition *display_def = ctx->display_definition;\n\n\n\n    DVBSubRegion *region;\n\n    DVBSubRegionDisplay *display;\n\n    AVSubtitleRect *rect;\n\n    DVBSubCLUT *clut;\n\n    uint32_t *clut_table;\n\n    int i;\n\n    int offset_x=0, offset_y=0;\n\n\n\n    sub->rects = NULL;\n\n    sub->start_display_time = 0;\n\n    sub->end_display_time = ctx->time_out * 1000;\n\n    sub->format = 0;\n\n\n\n    if (display_def) {\n\n        offset_x = display_def->x;\n\n        offset_y = display_def->y;\n\n    }\n\n\n\n    sub->num_rects = ctx->display_list_size;\n\n    if (sub->num_rects <= 0)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    sub->rects = av_mallocz_array(sub->num_rects * sub->num_rects,\n\n                                  sizeof(*sub->rects));\n\n    if (!sub->rects)\n\n        return AVERROR(ENOMEM);\n\n\n\n    i = 0;\n\n\n\n    for (display = ctx->display_list; display; display = display->next) {\n\n        region = get_region(ctx, display->region_id);\n\n        rect = sub->rects[i];\n\n\n\n        if (!region)\n\n            continue;\n\n\n\n        rect->x = display->x_pos + offset_x;\n\n        rect->y = display->y_pos + offset_y;\n\n        rect->w = region->width;\n\n        rect->h = region->height;\n\n        rect->nb_colors = 16;\n\n        rect->type      = SUBTITLE_BITMAP;\n\n        rect->pict.linesize[0] = region->width;\n\n\n\n        clut = get_clut(ctx, region->clut);\n\n\n\n        if (!clut)\n\n            clut = &default_clut;\n\n\n\n        switch (region->depth) {\n\n        case 2:\n\n            clut_table = clut->clut4;\n\n            break;\n\n        case 8:\n\n            clut_table = clut->clut256;\n\n            break;\n\n        case 4:\n\n        default:\n\n            clut_table = clut->clut16;\n\n            break;\n\n        }\n\n\n\n        rect->pict.data[1] = av_mallocz(AVPALETTE_SIZE);\n\n        if (!rect->pict.data[1]) {\n\n            av_free(sub->rects);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        memcpy(rect->pict.data[1], clut_table, (1 << region->depth) * sizeof(uint32_t));\n\n\n\n        rect->pict.data[0] = av_malloc(region->buf_size);\n\n        if (!rect->pict.data[0]) {\n\n            av_free(rect->pict.data[1]);\n\n            av_free(sub->rects);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        memcpy(rect->pict.data[0], region->pbuf, region->buf_size);\n\n\n\n        i++;\n\n    }\n\n\n\n    sub->num_rects = i;\n\n\n\n#ifdef DEBUG\n\n    save_display_set(ctx);\n\n#endif\n\n\n\n    return 1;\n\n}\n", "idx": 21841, "_split": "test", "_hash": "2c430b5d4a544067fb2b482b539b867f"}
{"project": "FFmpeg", "commit_id": "7b46add7257628bffac96d3002308d1f9e1ed172", "target": 0, "func": "static QUANT_FN(pvq_encode_band)\n\n{\n\n    return quant_band_template(pvq, f, rc, band, X, Y, N, b, blocks, lowband, duration,\n\n                               lowband_out, level, gain, lowband_scratch, fill, 1);\n\n}\n", "idx": 21851, "_split": "test", "_hash": "9d6cff3c0da67093f9fd9b7ce913104f"}
{"project": "FFmpeg", "commit_id": "c81185a18333b28439476fdc00979225158c8755", "target": 1, "func": "void avcodec_align_dimensions(AVCodecContext *s, int *width, int *height){\n\n    int w_align= 1;\n\n    int h_align= 1;\n\n\n\n    switch(s->pix_fmt){\n\n    case PIX_FMT_YUV420P:\n\n    case PIX_FMT_YUYV422:\n\n    case PIX_FMT_UYVY422:\n\n    case PIX_FMT_YUV422P:\n\n    case PIX_FMT_YUV444P:\n\n    case PIX_FMT_GRAY8:\n\n    case PIX_FMT_GRAY16BE:\n\n    case PIX_FMT_GRAY16LE:\n\n    case PIX_FMT_YUVJ420P:\n\n    case PIX_FMT_YUVJ422P:\n\n    case PIX_FMT_YUVJ444P:\n\n    case PIX_FMT_YUVA420P:\n\n        w_align= 16; //FIXME check for non mpeg style codecs and use less alignment\n\n        h_align= 16;\n\n\n\n        break;\n\n    case PIX_FMT_YUV411P:\n\n    case PIX_FMT_UYYVYY411:\n\n        w_align=32;\n\n        h_align=8;\n\n        break;\n\n    case PIX_FMT_YUV410P:\n\n        if(s->codec_id == CODEC_ID_SVQ1){\n\n            w_align=64;\n\n            h_align=64;\n\n        }\n\n    case PIX_FMT_RGB555:\n\n        if(s->codec_id == CODEC_ID_RPZA){\n\n            w_align=4;\n\n            h_align=4;\n\n        }\n\n    case PIX_FMT_PAL8:\n\n    case PIX_FMT_BGR8:\n\n    case PIX_FMT_RGB8:\n\n        if(s->codec_id == CODEC_ID_SMC){\n\n            w_align=4;\n\n            h_align=4;\n\n        }\n\n        break;\n\n    case PIX_FMT_BGR24:\n\n        if((s->codec_id == CODEC_ID_MSZH) || (s->codec_id == CODEC_ID_ZLIB)){\n\n            w_align=4;\n\n            h_align=4;\n\n        }\n\n        break;\n\n    default:\n\n        w_align= 1;\n\n        h_align= 1;\n\n        break;\n\n    }\n\n\n\n    *width = ALIGN(*width , w_align);\n\n    *height= ALIGN(*height, h_align);\n\n    if(s->codec_id == CODEC_ID_H264)\n\n        *height+=2; // some of the optimized chroma MC reads one line too much\n\n}", "idx": 21899, "_split": "test", "_hash": "97ab9d509dd5dd77bb4b75959e769cfd"}
{"project": "FFmpeg", "commit_id": "8000d484b83aafa752d84fbdbfb352ffe0dc64f8", "target": 1, "func": "void ff_init_cabac_decoder(CABACContext *c, const uint8_t *buf, int buf_size){\n\n    c->bytestream_start=\n\n    c->bytestream= buf;\n\n    c->bytestream_end= buf + buf_size;\n\n\n\n#if CABAC_BITS == 16\n\n    c->low =  (*c->bytestream++)<<18;\n\n    c->low+=  (*c->bytestream++)<<10;\n\n#else\n\n    c->low =  (*c->bytestream++)<<10;\n\n#endif\n\n    c->low+= ((*c->bytestream++)<<2) + 2;\n\n    c->range= 0x1FE;\n\n}\n", "idx": 21919, "_split": "test", "_hash": "006b8beeba5de7ee4a3718229f4e166c"}
{"project": "FFmpeg", "commit_id": "2c90316b46fce5785bc6af72c8fd369c31666604", "target": 1, "func": "static int hls_read_header(AVFormatContext *s)\n\n{\n\n    void *u = (s->flags & AVFMT_FLAG_CUSTOM_IO) ? NULL : s->pb;\n\n    HLSContext *c = s->priv_data;\n\n    int ret = 0, i;\n\n    int highest_cur_seq_no = 0;\n\n\n\n    c->ctx                = s;\n\n    c->interrupt_callback = &s->interrupt_callback;\n\n    c->strict_std_compliance = s->strict_std_compliance;\n\n\n\n    c->first_packet = 1;\n\n    c->first_timestamp = AV_NOPTS_VALUE;\n\n    c->cur_timestamp = AV_NOPTS_VALUE;\n\n\n\n    if (u) {\n\n        // get the previous user agent & set back to null if string size is zero\n\n        update_options(&c->user_agent, \"user-agent\", u);\n\n\n\n        // get the previous cookies & set back to null if string size is zero\n\n        update_options(&c->cookies, \"cookies\", u);\n\n\n\n        // get the previous headers & set back to null if string size is zero\n\n        update_options(&c->headers, \"headers\", u);\n\n\n\n        // get the previous http proxt & set back to null if string size is zero\n\n        update_options(&c->http_proxy, \"http_proxy\", u);\n\n    }\n\n\n\n    if ((ret = parse_playlist(c, s->filename, NULL, s->pb)) < 0)\n\n        goto fail;\n\n\n\n    if ((ret = save_avio_options(s)) < 0)\n\n        goto fail;\n\n\n\n    /* Some HLS servers don't like being sent the range header */\n\n    av_dict_set(&c->avio_opts, \"seekable\", \"0\", 0);\n\n\n\n    if (c->n_variants == 0) {\n\n        av_log(NULL, AV_LOG_WARNING, \"Empty playlist\\n\");\n\n        ret = AVERROR_EOF;\n\n        goto fail;\n\n    }\n\n    /* If the playlist only contained playlists (Master Playlist),\n\n     * parse each individual playlist. */\n\n    if (c->n_playlists > 1 || c->playlists[0]->n_segments == 0) {\n\n        for (i = 0; i < c->n_playlists; i++) {\n\n            struct playlist *pls = c->playlists[i];\n\n            if ((ret = parse_playlist(c, pls->url, pls, NULL)) < 0)\n\n                goto fail;\n\n        }\n\n    }\n\n\n\n    if (c->variants[0]->playlists[0]->n_segments == 0) {\n\n        av_log(NULL, AV_LOG_WARNING, \"Empty playlist\\n\");\n\n        ret = AVERROR_EOF;\n\n        goto fail;\n\n    }\n\n\n\n    /* If this isn't a live stream, calculate the total duration of the\n\n     * stream. */\n\n    if (c->variants[0]->playlists[0]->finished) {\n\n        int64_t duration = 0;\n\n        for (i = 0; i < c->variants[0]->playlists[0]->n_segments; i++)\n\n            duration += c->variants[0]->playlists[0]->segments[i]->duration;\n\n        s->duration = duration;\n\n    }\n\n\n\n    /* Associate renditions with variants */\n\n    for (i = 0; i < c->n_variants; i++) {\n\n        struct variant *var = c->variants[i];\n\n\n\n        if (var->audio_group[0])\n\n            add_renditions_to_variant(c, var, AVMEDIA_TYPE_AUDIO, var->audio_group);\n\n        if (var->video_group[0])\n\n            add_renditions_to_variant(c, var, AVMEDIA_TYPE_VIDEO, var->video_group);\n\n        if (var->subtitles_group[0])\n\n            add_renditions_to_variant(c, var, AVMEDIA_TYPE_SUBTITLE, var->subtitles_group);\n\n    }\n\n\n\n    /* Create a program for each variant */\n\n    for (i = 0; i < c->n_variants; i++) {\n\n        struct variant *v = c->variants[i];\n\n        AVProgram *program;\n\n\n\n        program = av_new_program(s, i);\n\n        if (!program)\n\n            goto fail;\n\n        av_dict_set_int(&program->metadata, \"variant_bitrate\", v->bandwidth, 0);\n\n    }\n\n\n\n    /* Select the starting segments */\n\n    for (i = 0; i < c->n_playlists; i++) {\n\n        struct playlist *pls = c->playlists[i];\n\n\n\n        if (pls->n_segments == 0)\n\n            continue;\n\n\n\n        pls->cur_seq_no = select_cur_seq_no(c, pls);\n\n        highest_cur_seq_no = FFMAX(highest_cur_seq_no, pls->cur_seq_no);\n\n    }\n\n\n\n    /* Open the demuxer for each playlist */\n\n    for (i = 0; i < c->n_playlists; i++) {\n\n        struct playlist *pls = c->playlists[i];\n\n        AVInputFormat *in_fmt = NULL;\n\n\n\n        if (!(pls->ctx = avformat_alloc_context())) {\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n\n\n        if (pls->n_segments == 0)\n\n            continue;\n\n\n\n        pls->index  = i;\n\n        pls->needed = 1;\n\n        pls->parent = s;\n\n\n\n        /*\n\n         * If this is a live stream and this playlist looks like it is one segment\n\n         * behind, try to sync it up so that every substream starts at the same\n\n         * time position (so e.g. avformat_find_stream_info() will see packets from\n\n         * all active streams within the first few seconds). This is not very generic,\n\n         * though, as the sequence numbers are technically independent.\n\n         */\n\n        if (!pls->finished && pls->cur_seq_no == highest_cur_seq_no - 1 &&\n\n            highest_cur_seq_no < pls->start_seq_no + pls->n_segments) {\n\n            pls->cur_seq_no = highest_cur_seq_no;\n\n        }\n\n\n\n        pls->read_buffer = av_malloc(INITIAL_BUFFER_SIZE);\n\n        if (!pls->read_buffer){\n\n            ret = AVERROR(ENOMEM);\n\n            avformat_free_context(pls->ctx);\n\n            pls->ctx = NULL;\n\n            goto fail;\n\n        }\n\n        ffio_init_context(&pls->pb, pls->read_buffer, INITIAL_BUFFER_SIZE, 0, pls,\n\n                          read_data, NULL, NULL);\n\n        pls->pb.seekable = 0;\n\n        ret = av_probe_input_buffer(&pls->pb, &in_fmt, pls->segments[0]->url,\n\n                                    NULL, 0, 0);\n\n        if (ret < 0) {\n\n            /* Free the ctx - it isn't initialized properly at this point,\n\n             * so avformat_close_input shouldn't be called. If\n\n             * avformat_open_input fails below, it frees and zeros the\n\n             * context, so it doesn't need any special treatment like this. */\n\n            av_log(s, AV_LOG_ERROR, \"Error when loading first segment '%s'\\n\", pls->segments[0]->url);\n\n            avformat_free_context(pls->ctx);\n\n            pls->ctx = NULL;\n\n            goto fail;\n\n        }\n\n        pls->ctx->pb       = &pls->pb;\n\n        pls->ctx->io_open  = nested_io_open;\n\n\n\n        if ((ret = ff_copy_whiteblacklists(pls->ctx, s)) < 0)\n\n            goto fail;\n\n\n\n        ret = avformat_open_input(&pls->ctx, pls->segments[0]->url, in_fmt, NULL);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        if (pls->id3_deferred_extra && pls->ctx->nb_streams == 1) {\n\n            ff_id3v2_parse_apic(pls->ctx, &pls->id3_deferred_extra);\n\n            avformat_queue_attached_pictures(pls->ctx);\n\n            ff_id3v2_free_extra_meta(&pls->id3_deferred_extra);\n\n            pls->id3_deferred_extra = NULL;\n\n        }\n\n\n\n        if (pls->is_id3_timestamped == -1)\n\n            av_log(s, AV_LOG_WARNING, \"No expected HTTP requests have been made\\n\");\n\n\n\n        /*\n\n         * For ID3 timestamped raw audio streams we need to detect the packet\n\n         * durations to calculate timestamps in fill_timing_for_id3_timestamped_stream(),\n\n         * but for other streams we can rely on our user calling avformat_find_stream_info()\n\n         * on us if they want to.\n\n         */\n\n        if (pls->is_id3_timestamped) {\n\n            ret = avformat_find_stream_info(pls->ctx, NULL);\n\n            if (ret < 0)\n\n                goto fail;\n\n        }\n\n\n\n        pls->has_noheader_flag = !!(pls->ctx->ctx_flags & AVFMTCTX_NOHEADER);\n\n\n\n        /* Create new AVStreams for each stream in this playlist */\n\n        ret = update_streams_from_subdemuxer(s, pls);\n\n        if (ret < 0)\n\n            goto fail;\n\n\n\n        add_metadata_from_renditions(s, pls, AVMEDIA_TYPE_AUDIO);\n\n        add_metadata_from_renditions(s, pls, AVMEDIA_TYPE_VIDEO);\n\n        add_metadata_from_renditions(s, pls, AVMEDIA_TYPE_SUBTITLE);\n\n    }\n\n\n\n    update_noheader_flag(s);\n\n\n\n    return 0;\n\nfail:\n\n    free_playlist_list(c);\n\n    free_variant_list(c);\n\n    free_rendition_list(c);\n\n    return ret;\n\n}\n", "idx": 21925, "_split": "test", "_hash": "653b57bf8dc48d7b57238598675fcd42"}
{"project": "FFmpeg", "commit_id": "8a9641a652ed1546fedfda22584f79d3d423096e", "target": 0, "func": "AVBitStreamFilterContext *av_bitstream_filter_init(const char *name)\n\n{\n\n    AVBitStreamFilter *bsf = first_bitstream_filter;\n\n\n\n    while (bsf) {\n\n        if (!strcmp(name, bsf->name)) {\n\n            AVBitStreamFilterContext *bsfc =\n\n                av_mallocz(sizeof(AVBitStreamFilterContext));\n\n            bsfc->filter    = bsf;\n\n            bsfc->priv_data =\n\n                bsf->priv_data_size ? av_mallocz(bsf->priv_data_size) : NULL;\n\n            return bsfc;\n\n        }\n\n        bsf = bsf->next;\n\n    }\n\n    return NULL;\n\n}\n", "idx": 21938, "_split": "test", "_hash": "bac5bdaf8605201aea78288b3c2ec984"}
{"project": "FFmpeg", "commit_id": "7441d1ec330da810a0ffd44a02b2fc60add5b719", "target": 1, "func": "int avio_close_dyn_buf(AVIOContext *s, uint8_t **pbuffer)\n\n{\n\n    DynBuffer *d = s->opaque;\n\n    int size;\n\n    static const char padbuf[FF_INPUT_BUFFER_PADDING_SIZE] = {0};\n\n    int padding = 0;\n\n\n\n    if (!s) {\n\n        *pbuffer = NULL;\n\n        return 0;\n\n    }\n\n\n\n    /* don't attempt to pad fixed-size packet buffers */\n\n    if (!s->max_packet_size) {\n\n        avio_write(s, padbuf, sizeof(padbuf));\n\n        padding = FF_INPUT_BUFFER_PADDING_SIZE;\n\n    }\n\n\n\n    avio_flush(s);\n\n\n\n    *pbuffer = d->buffer;\n\n    size = d->size;\n\n    av_free(d);\n\n    av_free(s);\n\n    return size - padding;\n\n}\n", "idx": 21971, "_split": "test", "_hash": "8fc371d4da56f1592117b7b09cc3fb92"}
{"project": "FFmpeg", "commit_id": "02591641f88097aec2a573f0ae384c8b87bcfe3b", "target": 1, "func": "static void decode_subframe_lpc(ShortenContext *s, int channel, int residual_size, int pred_order)\n\n{\n\n    int sum, i, j;\n\n    int coeffs[pred_order];\n\n\n\n    for (i=0; i<pred_order; i++)\n\n        coeffs[i] = get_sr_golomb_shorten(&s->gb, LPCQUANT);\n\n\n\n    for (i=0; i < s->blocksize; i++) {\n\n        sum = s->lpcqoffset;\n\n        for (j=0; j<pred_order; j++)\n\n            sum += coeffs[j] * s->decoded[channel][i-j-1];\n\n        s->decoded[channel][i] = get_sr_golomb_shorten(&s->gb, residual_size) + (sum >> LPCQUANT);\n\n    }\n\n}\n", "idx": 22003, "_split": "test", "_hash": "d2bc9460cd663ee881ac7271272acf93"}
{"project": "FFmpeg", "commit_id": "66f0c958bfd5475658b432d1af4d2e174b2dfcda", "target": 1, "func": "static int pxr24_uncompress(EXRContext *s, const uint8_t *src,\n\n                            int compressed_size, int uncompressed_size,\n\n                            EXRThreadData *td)\n\n{\n\n    unsigned long dest_len, expected_len = 0;\n\n    const uint8_t *in = td->tmp;\n\n    uint8_t *out;\n\n    int c, i, j;\n\n\n\n    for (i = 0; i < s->nb_channels; i++) {\n\n        if (s->channels[i].pixel_type == EXR_FLOAT) {\n\n            expected_len += (td->xsize * td->ysize * 3);/* PRX 24 store float in 24 bit instead of 32 */\n\n        } else if (s->channels[i].pixel_type == EXR_HALF) {\n\n            expected_len += (td->xsize * td->ysize * 2);\n\n        } else {//UINT 32\n\n            expected_len += (td->xsize * td->ysize * 4);\n\n        }\n\n    }\n\n\n\n    dest_len = expected_len;\n\n\n\n    if (uncompress(td->tmp, &dest_len, src, compressed_size) != Z_OK) {\n\n        return AVERROR_INVALIDDATA;\n\n    } else if (dest_len != expected_len) {\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    out = td->uncompressed_data;\n\n    for (i = 0; i < td->ysize; i++)\n\n        for (c = 0; c < s->nb_channels; c++) {\n\n            EXRChannel *channel = &s->channels[c];\n\n            const uint8_t *ptr[4];\n\n            uint32_t pixel = 0;\n\n\n\n            switch (channel->pixel_type) {\n\n            case EXR_FLOAT:\n\n                ptr[0] = in;\n\n                ptr[1] = ptr[0] + td->xsize;\n\n                ptr[2] = ptr[1] + td->xsize;\n\n                in     = ptr[2] + td->xsize;\n\n\n\n                for (j = 0; j < td->xsize; ++j) {\n\n                    uint32_t diff = (*(ptr[0]++) << 24) |\n\n                                    (*(ptr[1]++) << 16) |\n\n                                    (*(ptr[2]++) << 8);\n\n                    pixel += diff;\n\n                    bytestream_put_le32(&out, pixel);\n\n                }\n\n                break;\n\n            case EXR_HALF:\n\n                ptr[0] = in;\n\n                ptr[1] = ptr[0] + td->xsize;\n\n                in     = ptr[1] + td->xsize;\n\n                for (j = 0; j < td->xsize; j++) {\n\n                    uint32_t diff = (*(ptr[0]++) << 8) | *(ptr[1]++);\n\n\n\n                    pixel += diff;\n\n                    bytestream_put_le16(&out, pixel);\n\n                }\n\n                break;\n\n            case EXR_UINT:\n\n                ptr[0] = in;\n\n                ptr[1] = ptr[0] + s->xdelta;\n\n                ptr[2] = ptr[1] + s->xdelta;\n\n                ptr[3] = ptr[2] + s->xdelta;\n\n                in     = ptr[3] + s->xdelta;\n\n\n\n                for (j = 0; j < s->xdelta; ++j) {\n\n                    uint32_t diff = (*(ptr[0]++) << 24) |\n\n                    (*(ptr[1]++) << 16) |\n\n                    (*(ptr[2]++) << 8 ) |\n\n                    (*(ptr[3]++));\n\n                    pixel += diff;\n\n                    bytestream_put_le32(&out, pixel);\n\n                }\n\n                break;\n\n            default:\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n\n\n    return 0;\n\n}\n", "idx": 22009, "_split": "test", "_hash": "9348e765d3f0d4141538b32223d14070"}
{"project": "FFmpeg", "commit_id": "caa7a3914f499f74b3ee346f26d598ebdc0ec210", "target": 1, "func": "static int mov_read_default(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    int64_t total_size = 0;\n\n    MOVAtom a;\n\n    int i;\n\n\n\n    if (atom.size < 0)\n\n        atom.size = INT64_MAX;\n\n    while (total_size + 8 <= atom.size && !avio_feof(pb)) {\n\n        int (*parse)(MOVContext*, AVIOContext*, MOVAtom) = NULL;\n\n        a.size = atom.size;\n\n        a.type=0;\n\n        if (atom.size >= 8) {\n\n            a.size = avio_rb32(pb);\n\n            a.type = avio_rl32(pb);\n\n            if (a.type == MKTAG('f','r','e','e') &&\n\n                a.size >= 8 &&\n\n                c->moov_retry) {\n\n                uint8_t buf[8];\n\n                uint32_t *type = (uint32_t *)buf + 1;\n\n                avio_read(pb, buf, 8);\n\n                avio_seek(pb, -8, SEEK_CUR);\n\n                if (*type == MKTAG('m','v','h','d') ||\n\n                    *type == MKTAG('c','m','o','v')) {\n\n                    av_log(c->fc, AV_LOG_ERROR, \"Detected moov in a free atom.\\n\");\n\n                    a.type = MKTAG('m','o','o','v');\n\n                }\n\n            }\n\n            if (atom.type != MKTAG('r','o','o','t') &&\n\n                atom.type != MKTAG('m','o','o','v'))\n\n            {\n\n                if (a.type == MKTAG('t','r','a','k') || a.type == MKTAG('m','d','a','t'))\n\n                {\n\n                    av_log(c->fc, AV_LOG_ERROR, \"Broken file, trak/mdat not at top-level\\n\");\n\n                    avio_skip(pb, -8);\n\n                    return 0;\n\n                }\n\n            }\n\n            total_size += 8;\n\n            if (a.size == 1) { /* 64 bit extended size */\n\n                a.size = avio_rb64(pb) - 8;\n\n                total_size += 8;\n\n            }\n\n        }\n\n        av_dlog(c->fc, \"type: %08x '%.4s' parent:'%.4s' sz: %\"PRId64\" %\"PRId64\" %\"PRId64\"\\n\",\n\n                a.type, (char*)&a.type, (char*)&atom.type, a.size, total_size, atom.size);\n\n        if (a.size == 0) {\n\n            a.size = atom.size - total_size + 8;\n\n        }\n\n        a.size -= 8;\n\n        if (a.size < 0)\n\n            break;\n\n        a.size = FFMIN(a.size, atom.size - total_size);\n\n\n\n        for (i = 0; mov_default_parse_table[i].type; i++)\n\n            if (mov_default_parse_table[i].type == a.type) {\n\n                parse = mov_default_parse_table[i].parse;\n\n                break;\n\n            }\n\n\n\n        // container is user data\n\n        if (!parse && (atom.type == MKTAG('u','d','t','a') ||\n\n                       atom.type == MKTAG('i','l','s','t')))\n\n            parse = mov_read_udta_string;\n\n\n\n        if (!parse) { /* skip leaf atoms data */\n\n            avio_skip(pb, a.size);\n\n        } else {\n\n            int64_t start_pos = avio_tell(pb);\n\n            int64_t left;\n\n            int err = parse(c, pb, a);\n\n            if (err < 0)\n\n                return err;\n\n            if (c->found_moov && c->found_mdat &&\n\n                ((!pb->seekable || c->fc->flags & AVFMT_FLAG_IGNIDX) ||\n\n                 start_pos + a.size == avio_size(pb))) {\n\n                if (!pb->seekable || c->fc->flags & AVFMT_FLAG_IGNIDX)\n\n                    c->next_root_atom = start_pos + a.size;\n\n                return 0;\n\n            }\n\n            left = a.size - avio_tell(pb) + start_pos;\n\n            if (left > 0) /* skip garbage at atom end */\n\n                avio_skip(pb, left);\n\n            else if (left < 0) {\n\n                av_log(c->fc, AV_LOG_WARNING,\n\n                       \"overread end of atom '%.4s' by %\"PRId64\" bytes\\n\",\n\n                       (char*)&a.type, -left);\n\n                avio_seek(pb, left, SEEK_CUR);\n\n            }\n\n        }\n\n\n\n        total_size += a.size;\n\n    }\n\n\n\n    if (total_size < atom.size && atom.size < 0x7ffff)\n\n        avio_skip(pb, atom.size - total_size);\n\n\n\n    return 0;\n\n}\n", "idx": 22013, "_split": "test", "_hash": "ca087e326b7bc3dc632bec56caae06ec"}
{"project": "FFmpeg", "commit_id": "1c495b0bf690995c45f79f4f19500921e14ec78a", "target": 1, "func": "static void dwt_encode97_int(DWTContext *s, int *t)\n\n{\n\n    int lev,\n\n        w = s->linelen[s->ndeclevels-1][0];\n\n    int *line = s->i_linebuf;\n\n    line += 5;\n\n\n\n    for (lev = s->ndeclevels-1; lev >= 0; lev--){\n\n        int lh = s->linelen[lev][0],\n\n            lv = s->linelen[lev][1],\n\n            mh = s->mod[lev][0],\n\n            mv = s->mod[lev][1],\n\n            lp;\n\n        int *l;\n\n\n\n        // VER_SD\n\n        l = line + mv;\n\n        for (lp = 0; lp < lh; lp++) {\n\n            int i, j = 0;\n\n\n\n            for (i = 0; i < lv; i++)\n\n                l[i] = t[w*i + lp];\n\n\n\n            sd_1d97_int(line, mv, mv + lv);\n\n\n\n            // copy back and deinterleave\n\n            for (i =   mv; i < lv; i+=2, j++)\n\n                t[w*j + lp] = ((l[i] * I_LFTG_X) + (1 << 16)) >> 17;\n\n            for (i = 1-mv; i < lv; i+=2, j++)\n\n                t[w*j + lp] = ((l[i] * I_LFTG_K) + (1 << 16)) >> 17;\n\n        }\n\n\n\n        // HOR_SD\n\n        l = line + mh;\n\n        for (lp = 0; lp < lv; lp++){\n\n            int i, j = 0;\n\n\n\n            for (i = 0; i < lh; i++)\n\n                l[i] = t[w*lp + i];\n\n\n\n            sd_1d97_int(line, mh, mh + lh);\n\n\n\n            // copy back and deinterleave\n\n            for (i =   mh; i < lh; i+=2, j++)\n\n                t[w*lp + j] = ((l[i] * I_LFTG_X) + (1 << 16)) >> 17;\n\n            for (i = 1-mh; i < lh; i+=2, j++)\n\n                t[w*lp + j] = ((l[i] * I_LFTG_K) + (1 << 16)) >> 17;\n\n        }\n\n\n\n    }\n\n}\n", "idx": 22034, "_split": "test", "_hash": "8efb69f0a73a6d12802944fa9f915209"}
{"project": "FFmpeg", "commit_id": "0424e052f83adc422d8a746e3cdc5ab6bc28679e", "target": 1, "func": "static void decode_postinit(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    Picture *out = s->current_picture_ptr;\n\n    Picture *cur = s->current_picture_ptr;\n\n    int i, pics, out_of_order, out_idx;\n\n\n\n    s->current_picture_ptr->qscale_type= FF_QSCALE_TYPE_H264;\n\n    s->current_picture_ptr->pict_type= s->pict_type;\n\n\n\n    if (h->next_output_pic) return;\n\n\n\n    if (cur->field_poc[0]==INT_MAX || cur->field_poc[1]==INT_MAX) {\n\n        //FIXME this allows the next thread to start once we encounter the first field of a PAFF packet\n\n        //This works if the next packet contains the second field. It does not work if both fields are\n\n        //in the same packet.\n\n        //ff_thread_finish_setup(s->avctx);\n\n        return;\n\n    }\n\n\n\n    cur->interlaced_frame = 0;\n\n    cur->repeat_pict = 0;\n\n\n\n    /* Signal interlacing information externally. */\n\n    /* Prioritize picture timing SEI information over used decoding process if it exists. */\n\n\n\n    if(h->sps.pic_struct_present_flag){\n\n        switch (h->sei_pic_struct)\n\n        {\n\n        case SEI_PIC_STRUCT_FRAME:\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_FIELD:\n\n        case SEI_PIC_STRUCT_BOTTOM_FIELD:\n\n            cur->interlaced_frame = 1;\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_BOTTOM:\n\n        case SEI_PIC_STRUCT_BOTTOM_TOP:\n\n            if (FIELD_OR_MBAFF_PICTURE)\n\n                cur->interlaced_frame = 1;\n\n            else\n\n                // try to flag soft telecine progressive\n\n                cur->interlaced_frame = h->prev_interlaced_frame;\n\n            break;\n\n        case SEI_PIC_STRUCT_TOP_BOTTOM_TOP:\n\n        case SEI_PIC_STRUCT_BOTTOM_TOP_BOTTOM:\n\n            // Signal the possibility of telecined film externally (pic_struct 5,6)\n\n            // From these hints, let the applications decide if they apply deinterlacing.\n\n            cur->repeat_pict = 1;\n\n            break;\n\n        case SEI_PIC_STRUCT_FRAME_DOUBLING:\n\n            // Force progressive here, as doubling interlaced frame is a bad idea.\n\n            cur->repeat_pict = 2;\n\n            break;\n\n        case SEI_PIC_STRUCT_FRAME_TRIPLING:\n\n            cur->repeat_pict = 4;\n\n            break;\n\n        }\n\n\n\n        if ((h->sei_ct_type & 3) && h->sei_pic_struct <= SEI_PIC_STRUCT_BOTTOM_TOP)\n\n            cur->interlaced_frame = (h->sei_ct_type & (1<<1)) != 0;\n\n    }else{\n\n        /* Derive interlacing flag from used decoding process. */\n\n        cur->interlaced_frame = FIELD_OR_MBAFF_PICTURE;\n\n    }\n\n    h->prev_interlaced_frame = cur->interlaced_frame;\n\n\n\n    if (cur->field_poc[0] != cur->field_poc[1]){\n\n        /* Derive top_field_first from field pocs. */\n\n        cur->top_field_first = cur->field_poc[0] < cur->field_poc[1];\n\n    }else{\n\n        if(cur->interlaced_frame || h->sps.pic_struct_present_flag){\n\n            /* Use picture timing SEI information. Even if it is a information of a past frame, better than nothing. */\n\n            if(h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM\n\n              || h->sei_pic_struct == SEI_PIC_STRUCT_TOP_BOTTOM_TOP)\n\n                cur->top_field_first = 1;\n\n            else\n\n                cur->top_field_first = 0;\n\n        }else{\n\n            /* Most likely progressive */\n\n            cur->top_field_first = 0;\n\n        }\n\n    }\n\n\n\n    //FIXME do something with unavailable reference frames\n\n\n\n    /* Sort B-frames into display order */\n\n\n\n    if(h->sps.bitstream_restriction_flag\n\n       && s->avctx->has_b_frames < h->sps.num_reorder_frames){\n\n        s->avctx->has_b_frames = h->sps.num_reorder_frames;\n\n        s->low_delay = 0;\n\n    }\n\n\n\n    if(   s->avctx->strict_std_compliance >= FF_COMPLIANCE_STRICT\n\n       && !h->sps.bitstream_restriction_flag){\n\n        s->avctx->has_b_frames= MAX_DELAYED_PIC_COUNT;\n\n        s->low_delay= 0;\n\n    }\n\n\n\n    pics = 0;\n\n    while(h->delayed_pic[pics]) pics++;\n\n\n\n    assert(pics <= MAX_DELAYED_PIC_COUNT);\n\n\n\n    h->delayed_pic[pics++] = cur;\n\n    if(cur->reference == 0)\n\n        cur->reference = DELAYED_PIC_REF;\n\n\n\n    out = h->delayed_pic[0];\n\n    out_idx = 0;\n\n    for(i=1; h->delayed_pic[i] && !h->delayed_pic[i]->key_frame && !h->delayed_pic[i]->mmco_reset; i++)\n\n        if(h->delayed_pic[i]->poc < out->poc){\n\n            out = h->delayed_pic[i];\n\n            out_idx = i;\n\n        }\n\n    if(s->avctx->has_b_frames == 0 && (h->delayed_pic[0]->key_frame || h->delayed_pic[0]->mmco_reset))\n\n        h->next_outputed_poc= INT_MIN;\n\n    out_of_order = out->poc < h->next_outputed_poc;\n\n\n\n    if(h->sps.bitstream_restriction_flag && s->avctx->has_b_frames >= h->sps.num_reorder_frames)\n\n        { }\n\n    else if((out_of_order && pics-1 == s->avctx->has_b_frames && s->avctx->has_b_frames < MAX_DELAYED_PIC_COUNT)\n\n       || (s->low_delay &&\n\n        ((h->next_outputed_poc != INT_MIN && out->poc > h->next_outputed_poc + 2)\n\n         || cur->pict_type == AV_PICTURE_TYPE_B)))\n\n    {\n\n        s->low_delay = 0;\n\n        s->avctx->has_b_frames++;\n\n    }\n\n\n\n    if(out_of_order || pics > s->avctx->has_b_frames){\n\n        out->reference &= ~DELAYED_PIC_REF;\n\n        out->owner2 = s; // for frame threading, the owner must be the second field's thread\n\n                         // or else the first thread can release the picture and reuse it unsafely\n\n        for(i=out_idx; h->delayed_pic[i]; i++)\n\n            h->delayed_pic[i] = h->delayed_pic[i+1];\n\n    }\n\n    if(!out_of_order && pics > s->avctx->has_b_frames){\n\n        h->next_output_pic = out;\n\n        if(out_idx==0 && h->delayed_pic[0] && (h->delayed_pic[0]->key_frame || h->delayed_pic[0]->mmco_reset)) {\n\n            h->next_outputed_poc = INT_MIN;\n\n        } else\n\n            h->next_outputed_poc = out->poc;\n\n    }else{\n\n        av_log(s->avctx, AV_LOG_DEBUG, \"no picture\\n\");\n\n    }\n\n\n\n    ff_thread_finish_setup(s->avctx);\n\n}\n", "idx": 22037, "_split": "test", "_hash": "ec19c30435f7683883cd29fbf325199b"}
{"project": "FFmpeg", "commit_id": "808c10e728db2d92ccbb0f8b3bcd4a2f4305a2cf", "target": 0, "func": "static void format_line(void *ptr, int level, const char *fmt, va_list vl,\n\n                        AVBPrint part[3], int *print_prefix, int type[2])\n\n{\n\n    AVClass* avc = ptr ? *(AVClass **) ptr : NULL;\n\n    av_bprint_init(part+0, 0, 1);\n\n    av_bprint_init(part+1, 0, 1);\n\n    av_bprint_init(part+2, 0, 65536);\n\n\n\n    if(type) type[0] = type[1] = AV_CLASS_CATEGORY_NA + 16;\n\n    if (*print_prefix && avc) {\n\n        if (avc->parent_log_context_offset) {\n\n            AVClass** parent = *(AVClass ***) (((uint8_t *) ptr) +\n\n                                   avc->parent_log_context_offset);\n\n            if (parent && *parent) {\n\n                av_bprintf(part+0, \"[%s @ %p] \",\n\n                         (*parent)->item_name(parent), parent);\n\n                if(type) type[0] = get_category(parent);\n\n            }\n\n        }\n\n        av_bprintf(part+1, \"[%s @ %p] \",\n\n                 avc->item_name(ptr), ptr);\n\n        if(type) type[1] = get_category(ptr);\n\n    }\n\n\n\n    av_vbprintf(part+2, fmt, vl);\n\n\n\n    if(*part[0].str || *part[1].str || *part[2].str) {\n\n        char lastc = part[2].len ? part[2].str[part[2].len - 1] : 0;\n\n        *print_prefix = lastc == '\\n' || lastc == '\\r';\n\n    }\n\n}\n", "idx": 22086, "_split": "test", "_hash": "1819c7f09a26c9c001637fdfef2edb75"}
{"project": "FFmpeg", "commit_id": "1f4ff53aea7c5090f31cd1323d95f7c407c9b2bb", "target": 0, "func": "static int dnxhd_init_vlc(DNXHDContext *ctx, uint32_t cid)\n\n{\n\n    if (cid != ctx->cid) {\n\n        int index;\n\n\n\n        if ((index = ff_dnxhd_get_cid_table(cid)) < 0) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"unsupported cid %d\\n\", cid);\n\n            return AVERROR(ENOSYS);\n\n        }\n\n        if (ff_dnxhd_cid_table[index].bit_depth != ctx->bit_depth) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"bit depth mismatches %d %d\\n\", ff_dnxhd_cid_table[index].bit_depth, ctx->bit_depth);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        ctx->cid_table = &ff_dnxhd_cid_table[index];\n\n        av_log(ctx->avctx, AV_LOG_VERBOSE, \"Profile cid %d.\\n\", cid);\n\n\n\n        ff_free_vlc(&ctx->ac_vlc);\n\n        ff_free_vlc(&ctx->dc_vlc);\n\n        ff_free_vlc(&ctx->run_vlc);\n\n\n\n        init_vlc(&ctx->ac_vlc, DNXHD_VLC_BITS, 257,\n\n                 ctx->cid_table->ac_bits, 1, 1,\n\n                 ctx->cid_table->ac_codes, 2, 2, 0);\n\n        init_vlc(&ctx->dc_vlc, DNXHD_DC_VLC_BITS, ctx->bit_depth + 4,\n\n                 ctx->cid_table->dc_bits, 1, 1,\n\n                 ctx->cid_table->dc_codes, 1, 1, 0);\n\n        init_vlc(&ctx->run_vlc, DNXHD_VLC_BITS, 62,\n\n                 ctx->cid_table->run_bits, 1, 1,\n\n                 ctx->cid_table->run_codes, 2, 2, 0);\n\n\n\n        ctx->cid = cid;\n\n    }\n\n    return 0;\n\n}\n", "idx": 22089, "_split": "test", "_hash": "5a6fbcd0b311f3d7a2b9321c869373a2"}
{"project": "FFmpeg", "commit_id": "e89f58810d0d508552089495781e2a70e95edb99", "target": 0, "func": "static void check_default_settings(AVCodecContext *avctx)\n\n{\n\n    X264Context *x4 = avctx->priv_data;\n\n\n\n    int score = 0;\n\n    score += x4->params.analyse.i_me_range == 0;\n\n    score += x4->params.rc.i_qp_step == 3;\n\n    score += x4->params.i_keyint_max == 12;\n\n    score += x4->params.rc.i_qp_min == 2;\n\n    score += x4->params.rc.i_qp_max == 31;\n\n    score += x4->params.rc.f_qcompress == 0.5;\n\n    score += fabs(x4->params.rc.f_ip_factor - 1.25) < 0.01;\n\n    score += fabs(x4->params.rc.f_pb_factor - 1.25) < 0.01;\n\n    score += x4->params.analyse.inter == 0 && x4->params.analyse.i_subpel_refine == 8;\n\n    if (score >= 5) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Default settings detected, using medium profile\\n\");\n\n        x4->preset = av_strdup(\"medium\");\n\n        if (avctx->bit_rate == 200*1000)\n\n            avctx->crf = 23;\n\n    }\n\n}\n", "idx": 22093, "_split": "test", "_hash": "2dd8cda2022e7ef4192faf1d294e923b"}
{"project": "FFmpeg", "commit_id": "de1824e970d448a84bedce4936c301c322baa714", "target": 0, "func": "static int mpeg_decode_frame(AVCodecContext *avctx,\n\n                             void *data, int *data_size,\n\n                             AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    Mpeg1Context *s = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    MpegEncContext *s2 = &s->mpeg_enc_ctx;\n\n    av_dlog(avctx, \"fill_buffer\\n\");\n\n\n\n    if (buf_size == 0 || (buf_size == 4 && AV_RB32(buf) == SEQ_END_CODE)) {\n\n        /* special case for last picture */\n\n        if (s2->low_delay == 0 && s2->next_picture_ptr) {\n\n            *picture = s2->next_picture_ptr->f;\n\n            s2->next_picture_ptr = NULL;\n\n\n\n            *data_size = sizeof(AVFrame);\n\n        }\n\n        return buf_size;\n\n    }\n\n\n\n    if (s2->flags & CODEC_FLAG_TRUNCATED) {\n\n        int next = ff_mpeg1_find_frame_end(&s2->parse_context, buf, buf_size, NULL);\n\n\n\n        if (ff_combine_frame(&s2->parse_context, next, (const uint8_t **)&buf, &buf_size) < 0)\n\n            return buf_size;\n\n    }\n\n\n\n    s2->codec_tag = avpriv_toupper4(avctx->codec_tag);\n\n    if (s->mpeg_enc_ctx_allocated == 0 && (   s2->codec_tag == AV_RL32(\"VCR2\")\n\n                                           || s2->codec_tag == AV_RL32(\"BW10\")\n\n                                          ))\n\n        vcr2_init_sequence(avctx);\n\n\n\n    s->slice_count = 0;\n\n\n\n    if (avctx->extradata && !avctx->frame_number) {\n\n        int ret = decode_chunks(avctx, picture, data_size, avctx->extradata, avctx->extradata_size);\n\n        if(*data_size) {\n\n            av_log(avctx, AV_LOG_ERROR, \"picture in extradata\\n\");\n\n            *data_size = 0;\n\n        }\n\n        if (ret < 0 && (avctx->err_recognition & AV_EF_EXPLODE))\n\n            return ret;\n\n    }\n\n\n\n    return decode_chunks(avctx, picture, data_size, buf, buf_size);\n\n}\n", "idx": 22137, "_split": "test", "_hash": "e67059d2256a23117a6a1db9e97d95d8"}
{"project": "FFmpeg", "commit_id": "5952b8da0b7f65dfa23991e71737e0abdaeb339c", "target": 1, "func": "static int seek_test(const char *input_filename, const char *start, const char *end)\n\n{\n\n    AVCodec *codec = NULL;\n\n    AVCodecContext *ctx= NULL;\n\n    AVCodecParameters *origin_par = NULL;\n\n    AVFrame *fr = NULL;\n\n    AVFormatContext *fmt_ctx = NULL;\n\n    int video_stream;\n\n    int result;\n\n    int i, j;\n\n    long int start_ts, end_ts;\n\n\n\n    size_of_array = 0;\n\n    number_of_elements = 0;\n\n    crc_array = pts_array = NULL;\n\n\n\n    result = avformat_open_input(&fmt_ctx, input_filename, NULL, NULL);\n\n    if (result < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't open file\\n\");\n\n        return result;\n\n    }\n\n\n\n    result = avformat_find_stream_info(fmt_ctx, NULL);\n\n    if (result < 0) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't get stream info\\n\");\n\n        return result;\n\n    }\n\n\n\n    start_ts = read_seek_range(start);\n\n    end_ts = read_seek_range(end);\n\n    if ((start_ts < 0) || (end_ts < 0))\n\n        return -1;\n\n\n\n    //TODO: add ability to work with audio format\n\n    video_stream = av_find_best_stream(fmt_ctx, AVMEDIA_TYPE_VIDEO, -1, -1, NULL, 0);\n\n    if (video_stream < 0) {\n\n      av_log(NULL, AV_LOG_ERROR, \"Can't find video stream in input file\\n\");\n\n      return -1;\n\n    }\n\n\n\n    origin_par = fmt_ctx->streams[video_stream]->codecpar;\n\n\n\n    codec = avcodec_find_decoder(origin_par->codec_id);\n\n    if (!codec) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't find decoder\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx = avcodec_alloc_context3(codec);\n\n    if (!ctx) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't allocate decoder context\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    result = avcodec_parameters_to_context(ctx, origin_par);\n\n    if (result) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't copy decoder context\\n\");\n\n        return result;\n\n    }\n\n\n\n    result = avcodec_open2(ctx, codec, NULL);\n\n    if (result < 0) {\n\n        av_log(ctx, AV_LOG_ERROR, \"Can't open decoder\\n\");\n\n        return result;\n\n    }\n\n\n\n    fr = av_frame_alloc();\n\n    if (!fr) {\n\n        av_log(NULL, AV_LOG_ERROR, \"Can't allocate frame\\n\");\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    result = compute_crc_of_packets(fmt_ctx, video_stream, ctx, fr, i, j, 1);\n\n    if (result != 0)\n\n        return -1;\n\n\n\n    for (i = start_ts; i < end_ts; i += 100) {\n\n        for (j = i + 100; j < end_ts; j += 100)\n\n        result = compute_crc_of_packets(fmt_ctx, video_stream, ctx, fr, i, j, 0);\n\n        if (result != 0)\n\n            return -1;\n\n    }\n\n\n\n    av_freep(&crc_array);\n\n    av_freep(&pts_array);\n\n    av_frame_free(&fr);\n\n    avcodec_close(ctx);\n\n    avformat_close_input(&fmt_ctx);\n\n    avcodec_free_context(&ctx);\n\n    return 0;\n\n}\n", "idx": 22316, "_split": "test", "_hash": "c2becbf5d2afa26847eab6ebc776454f"}
{"project": "FFmpeg", "commit_id": "39d607e5bbc25ad9629683702b510e865434ef21", "target": 1, "func": "static inline void RENAME(yuv2yuvX_ar)(SwsContext *c, const int16_t *lumFilter,\n\n                                       const int16_t **lumSrc, int lumFilterSize,\n\n                                       const int16_t *chrFilter, const int16_t **chrUSrc,\n\n                                       const int16_t **chrVSrc,\n\n                                       int chrFilterSize, const int16_t **alpSrc,\n\n                                       uint8_t *dest, uint8_t *uDest, uint8_t *vDest,\n\n                                       uint8_t *aDest, long dstW, long chrDstW)\n\n{\n\n    if (uDest) {\n\n        YSCALEYUV2YV12X_ACCURATE(CHR_MMX_FILTER_OFFSET, uDest, chrDstW, 0)\n\n        YSCALEYUV2YV12X_ACCURATE(CHR_MMX_FILTER_OFFSET, vDest, chrDstW + c->uv_off, c->uv_off)\n\n    }\n\n    if (CONFIG_SWSCALE_ALPHA && aDest) {\n\n        YSCALEYUV2YV12X_ACCURATE(ALP_MMX_FILTER_OFFSET, aDest, dstW, 0)\n\n    }\n\n\n\n    YSCALEYUV2YV12X_ACCURATE(LUM_MMX_FILTER_OFFSET, dest, dstW, 0)\n\n}\n", "idx": 22361, "_split": "test", "_hash": "4c77ea24d2644cfb054fe22de6e979e3"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int voc_probe(AVProbeData *p)\n\n{\n\n    int version, check;\n\n\n\n    if (p->buf_size < 26)\n\n        return 0;\n\n    if (memcmp(p->buf, voc_magic, sizeof(voc_magic) - 1))\n\n        return 0;\n\n    version = p->buf[22] | (p->buf[23] << 8);\n\n    check = p->buf[24] | (p->buf[25] << 8);\n\n    if (~version + 0x1234 != check)\n\n        return 10;\n\n\n\n    return AVPROBE_SCORE_MAX;\n\n}\n", "idx": 22379, "_split": "test", "_hash": "46f81ae2b953a1a26c96278716bf02d6"}
{"project": "FFmpeg", "commit_id": "e16e49ac90f6da9e019fdf23084cbb256d14bd9c", "target": 0, "func": "static void term_exit(void)\n\n{\n\n#ifndef __MINGW32__\n\n    tcsetattr (0, TCSANOW, &oldtty);\n\n#endif\n\n}\n", "idx": 22392, "_split": "test", "_hash": "f5e32bbd9f495e3d99b526cb69f0eae3"}
{"project": "FFmpeg", "commit_id": "043800a96888f1a04732f12316ba477d8f098d3f", "target": 0, "func": "static int end_frame(AVFilterLink *inlink)\n\n{\n\n    AVFilterContext    *ctx = inlink->dst;\n\n    FPSContext           *s = ctx->priv;\n\n    AVFilterLink   *outlink = ctx->outputs[0];\n\n    AVFilterBufferRef  *buf = inlink->cur_buf;\n\n    int64_t delta;\n\n    int i, ret;\n\n\n\n    inlink->cur_buf = NULL;\n\n    s->frames_in++;\n\n    /* discard frames until we get the first timestamp */\n\n    if (s->pts == AV_NOPTS_VALUE) {\n\n        if (buf->pts != AV_NOPTS_VALUE) {\n\n            write_to_fifo(s->fifo, buf);\n\n            s->first_pts = s->pts = buf->pts;\n\n        } else {\n\n            av_log(ctx, AV_LOG_WARNING, \"Discarding initial frame(s) with no \"\n\n                   \"timestamp.\\n\");\n\n            avfilter_unref_buffer(buf);\n\n            s->drop++;\n\n        }\n\n        return 0;\n\n    }\n\n\n\n    /* now wait for the next timestamp */\n\n    if (buf->pts == AV_NOPTS_VALUE) {\n\n        return write_to_fifo(s->fifo, buf);\n\n    }\n\n\n\n    /* number of output frames */\n\n    delta = av_rescale_q(buf->pts - s->pts, inlink->time_base,\n\n                         outlink->time_base);\n\n\n\n    if (delta < 1) {\n\n        /* drop the frame and everything buffered except the first */\n\n        AVFilterBufferRef *tmp;\n\n        int drop = av_fifo_size(s->fifo)/sizeof(AVFilterBufferRef*);\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"Dropping %d frame(s).\\n\", drop);\n\n        s->drop += drop;\n\n\n\n        av_fifo_generic_read(s->fifo, &tmp, sizeof(tmp), NULL);\n\n        flush_fifo(s->fifo);\n\n        ret = write_to_fifo(s->fifo, tmp);\n\n\n\n        avfilter_unref_buffer(buf);\n\n        return ret;\n\n    }\n\n\n\n    /* can output >= 1 frames */\n\n    for (i = 0; i < delta; i++) {\n\n        AVFilterBufferRef *buf_out;\n\n        av_fifo_generic_read(s->fifo, &buf_out, sizeof(buf_out), NULL);\n\n\n\n        /* duplicate the frame if needed */\n\n        if (!av_fifo_size(s->fifo) && i < delta - 1) {\n\n            av_log(ctx, AV_LOG_DEBUG, \"Duplicating frame.\\n\");\n\n            write_to_fifo(s->fifo, avfilter_ref_buffer(buf_out, AV_PERM_READ));\n\n            s->dup++;\n\n        }\n\n\n\n        buf_out->pts = av_rescale_q(s->first_pts, inlink->time_base,\n\n                                    outlink->time_base) + s->frames_out;\n\n\n\n        if ((ret = ff_start_frame(outlink, buf_out)) < 0 ||\n\n            (ret = ff_draw_slice(outlink, 0, outlink->h, 1)) < 0 ||\n\n            (ret = ff_end_frame(outlink)) < 0) {\n\n            avfilter_unref_bufferp(&buf);\n\n            return ret;\n\n        }\n\n\n\n        s->frames_out++;\n\n    }\n\n    flush_fifo(s->fifo);\n\n\n\n    ret = write_to_fifo(s->fifo, buf);\n\n    s->pts = s->first_pts + av_rescale_q(s->frames_out, outlink->time_base, inlink->time_base);\n\n\n\n    return ret;\n\n}\n", "idx": 22425, "_split": "test", "_hash": "2dfb0829c8d99811f8f3313a0d45b0e8"}
{"project": "FFmpeg", "commit_id": "c0175fa92b7edd45a06e4ab16c8e83da0c94a9f6", "target": 1, "func": "static int roq_read_packet(AVFormatContext *s,\n\n                           AVPacket *pkt)\n\n{\n\n    RoqDemuxContext *roq = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int ret = 0;\n\n    unsigned int chunk_size;\n\n    unsigned int chunk_type;\n\n    unsigned int codebook_size;\n\n    unsigned char preamble[RoQ_CHUNK_PREAMBLE_SIZE];\n\n    int packet_read = 0;\n\n    int64_t codebook_offset;\n\n\n\n    while (!packet_read) {\n\n\n\n        if (avio_feof(s->pb))\n\n            return AVERROR(EIO);\n\n\n\n        /* get the next chunk preamble */\n\n        if ((ret = avio_read(pb, preamble, RoQ_CHUNK_PREAMBLE_SIZE)) !=\n\n            RoQ_CHUNK_PREAMBLE_SIZE)\n\n            return AVERROR(EIO);\n\n\n\n        chunk_type = AV_RL16(&preamble[0]);\n\n        chunk_size = AV_RL32(&preamble[2]);\n\n        if(chunk_size > INT_MAX)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        chunk_size = ffio_limit(pb, chunk_size);\n\n\n\n        switch (chunk_type) {\n\n\n\n        case RoQ_INFO:\n\n            if (roq->video_stream_index == -1) {\n\n                AVStream *st = avformat_new_stream(s, NULL);\n\n                if (!st)\n\n                    return AVERROR(ENOMEM);\n\n                avpriv_set_pts_info(st, 63, 1, roq->frame_rate);\n\n                roq->video_stream_index = st->index;\n\n                st->codecpar->codec_type   = AVMEDIA_TYPE_VIDEO;\n\n                st->codecpar->codec_id     = AV_CODEC_ID_ROQ;\n\n                st->codecpar->codec_tag    = 0;  /* no fourcc */\n\n\n\n                if (avio_read(pb, preamble, RoQ_CHUNK_PREAMBLE_SIZE) != RoQ_CHUNK_PREAMBLE_SIZE)\n\n                    return AVERROR(EIO);\n\n                st->codecpar->width  = roq->width  = AV_RL16(preamble);\n\n                st->codecpar->height = roq->height = AV_RL16(preamble + 2);\n\n                break;\n\n            }\n\n            /* don't care about this chunk anymore */\n\n            avio_skip(pb, RoQ_CHUNK_PREAMBLE_SIZE);\n\n            break;\n\n\n\n        case RoQ_QUAD_CODEBOOK:\n\n            if (roq->video_stream_index < 0)\n\n                return AVERROR_INVALIDDATA;\n\n            /* packet needs to contain both this codebook and next VQ chunk */\n\n            codebook_offset = avio_tell(pb) - RoQ_CHUNK_PREAMBLE_SIZE;\n\n            codebook_size = chunk_size;\n\n            avio_skip(pb, codebook_size);\n\n            if (avio_read(pb, preamble, RoQ_CHUNK_PREAMBLE_SIZE) !=\n\n                RoQ_CHUNK_PREAMBLE_SIZE)\n\n                return AVERROR(EIO);\n\n            chunk_size = AV_RL32(&preamble[2]) + RoQ_CHUNK_PREAMBLE_SIZE * 2 +\n\n                codebook_size;\n\n\n\n            if (chunk_size > INT_MAX)\n\n                return AVERROR_INVALIDDATA;\n\n\n\n            /* rewind */\n\n            avio_seek(pb, codebook_offset, SEEK_SET);\n\n\n\n            /* load up the packet */\n\n            ret= av_get_packet(pb, pkt, chunk_size);\n\n            if (ret != chunk_size)\n\n                return AVERROR(EIO);\n\n            pkt->stream_index = roq->video_stream_index;\n\n            pkt->pts = roq->video_pts++;\n\n\n\n            packet_read = 1;\n\n            break;\n\n\n\n        case RoQ_SOUND_MONO:\n\n        case RoQ_SOUND_STEREO:\n\n            if (roq->audio_stream_index == -1) {\n\n                AVStream *st = avformat_new_stream(s, NULL);\n\n                if (!st)\n\n                    return AVERROR(ENOMEM);\n\n                avpriv_set_pts_info(st, 32, 1, RoQ_AUDIO_SAMPLE_RATE);\n\n                roq->audio_stream_index = st->index;\n\n                st->codecpar->codec_type = AVMEDIA_TYPE_AUDIO;\n\n                st->codecpar->codec_id = AV_CODEC_ID_ROQ_DPCM;\n\n                st->codecpar->codec_tag = 0;  /* no tag */\n\n                if (chunk_type == RoQ_SOUND_STEREO) {\n\n                    st->codecpar->channels       = 2;\n\n                    st->codecpar->channel_layout = AV_CH_LAYOUT_STEREO;\n\n                } else {\n\n                    st->codecpar->channels       = 1;\n\n                    st->codecpar->channel_layout = AV_CH_LAYOUT_MONO;\n\n                }\n\n                roq->audio_channels    = st->codecpar->channels;\n\n                st->codecpar->sample_rate = RoQ_AUDIO_SAMPLE_RATE;\n\n                st->codecpar->bits_per_coded_sample = 16;\n\n                st->codecpar->bit_rate = st->codecpar->channels * st->codecpar->sample_rate *\n\n                    st->codecpar->bits_per_coded_sample;\n\n                st->codecpar->block_align = st->codecpar->channels * st->codecpar->bits_per_coded_sample;\n\n            }\n\n        case RoQ_QUAD_VQ:\n\n            if (chunk_type == RoQ_QUAD_VQ) {\n\n                if (roq->video_stream_index < 0)\n\n                    return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            /* load up the packet */\n\n            if (av_new_packet(pkt, chunk_size + RoQ_CHUNK_PREAMBLE_SIZE))\n\n                return AVERROR(EIO);\n\n            /* copy over preamble */\n\n            memcpy(pkt->data, preamble, RoQ_CHUNK_PREAMBLE_SIZE);\n\n\n\n            if (chunk_type == RoQ_QUAD_VQ) {\n\n                pkt->stream_index = roq->video_stream_index;\n\n                pkt->pts = roq->video_pts++;\n\n            } else {\n\n                pkt->stream_index = roq->audio_stream_index;\n\n                pkt->pts = roq->audio_frame_count;\n\n                roq->audio_frame_count += (chunk_size / roq->audio_channels);\n\n            }\n\n\n\n            pkt->pos= avio_tell(pb);\n\n            ret = avio_read(pb, pkt->data + RoQ_CHUNK_PREAMBLE_SIZE,\n\n                chunk_size);\n\n            if (ret != chunk_size)\n\n                ret = AVERROR(EIO);\n\n\n\n            packet_read = 1;\n\n            break;\n\n\n\n        default:\n\n            av_log(s, AV_LOG_ERROR, \"  unknown RoQ chunk (%04X)\\n\", chunk_type);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    return ret;\n\n}\n", "idx": 22426, "_split": "test", "_hash": "3b90eea88bf278b2c5e8c0deff0933bc"}
{"project": "FFmpeg", "commit_id": "7f526efd17973ec6d2204f7a47b6923e2be31363", "target": 1, "func": "static inline void RENAME(hScale)(int16_t *dst, int dstW, uint8_t *src, int srcW, int xInc,\n\n\t\t\t\t  int16_t *filter, int16_t *filterPos, int filterSize)\n\n{\n\n#ifdef HAVE_MMX\n\n\tassert(filterSize % 4 == 0 && filterSize>0);\n\n\tif(filterSize==4) // allways true for upscaling, sometimes for down too\n\n\t{\n\n\t\tlong counter= -2*dstW;\n\n\t\tfilter-= counter*2;\n\n\t\tfilterPos-= counter/2;\n\n\t\tdst-= counter/2;\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w02)\", %%mm6\t\\n\\t\"\n\n\t\t\t\"push %%\"REG_BP\"\t\t\\n\\t\" // we use 7 regs here ...\n\n\t\t\t\"mov %%\"REG_a\", %%\"REG_BP\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movzwl (%2, %%\"REG_BP\"), %%eax\t\\n\\t\"\n\n\t\t\t\"movzwl 2(%2, %%\"REG_BP\"), %%ebx\\n\\t\"\n\n\t\t\t\"movq (%1, %%\"REG_BP\", 4), %%mm1\\n\\t\"\n\n\t\t\t\"movq 8(%1, %%\"REG_BP\", 4), %%mm3\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_a\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm3, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"movd %%mm0, (%4, %%\"REG_BP\")\t\\n\\t\"\n\n\t\t\t\"add $4, %%\"REG_BP\"\t\t\\n\\t\"\n\n\t\t\t\" jnc 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t\"pop %%\"REG_BP\"\t\t\t\\n\\t\"\n\n\t\t\t: \"+a\" (counter)\n\n\t\t\t: \"c\" (filter), \"d\" (filterPos), \"S\" (src), \"D\" (dst)\n\n\t\t\t: \"%\"REG_b\n\n\t\t);\n\n\t}\n\n\telse if(filterSize==8)\n\n\t{\n\n\t\tlong counter= -2*dstW;\n\n\t\tfilter-= counter*4;\n\n\t\tfilterPos-= counter/2;\n\n\t\tdst-= counter/2;\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w02)\", %%mm6\t\\n\\t\"\n\n\t\t\t\"push %%\"REG_BP\"\t\t\\n\\t\" // we use 7 regs here ...\n\n\t\t\t\"mov %%\"REG_a\", %%\"REG_BP\"\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movzwl (%2, %%\"REG_BP\"), %%eax\t\\n\\t\"\n\n\t\t\t\"movzwl 2(%2, %%\"REG_BP\"), %%ebx\\n\\t\"\n\n\t\t\t\"movq (%1, %%\"REG_BP\", 8), %%mm1\\n\\t\"\n\n\t\t\t\"movq 16(%1, %%\"REG_BP\", 8), %%mm3\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_a\"), %%mm0\t\\n\\t\"\n\n\t\t\t\"movd (%3, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\n\n\t\t\t\"movq 8(%1, %%\"REG_BP\", 8), %%mm1\\n\\t\"\n\n\t\t\t\"movq 24(%1, %%\"REG_BP\", 8), %%mm5\\n\\t\"\n\n\t\t\t\"movd 4(%3, %%\"REG_a\"), %%mm4\t\\n\\t\"\n\n\t\t\t\"movd 4(%3, %%\"REG_b\"), %%mm2\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm4, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm5, %%mm3\t\t\\n\\t\"\n\n\t\t\t\t\t\t\n\n\t\t\t\"psrad $8, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm3, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm0, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"movd %%mm0, (%4, %%\"REG_BP\")\t\\n\\t\"\n\n\t\t\t\"add $4, %%\"REG_BP\"\t\t\\n\\t\"\n\n\t\t\t\" jnc 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t\"pop %%\"REG_BP\"\t\t\t\\n\\t\"\n\n\t\t\t: \"+a\" (counter)\n\n\t\t\t: \"c\" (filter), \"d\" (filterPos), \"S\" (src), \"D\" (dst)\n\n\t\t\t: \"%\"REG_b\n\n\t\t);\n\n\t}\n\n\telse\n\n\t{\n\n\t\tuint8_t *offset = src+filterSize;\n\n\t\tlong counter= -2*dstW;\n\n//\t\tfilter-= counter*filterSize/2;\n\n\t\tfilterPos-= counter/2;\n\n\t\tdst-= counter/2;\n\n\t\tasm volatile(\n\n\t\t\t\"pxor %%mm7, %%mm7\t\t\\n\\t\"\n\n\t\t\t\"movq \"MANGLE(w02)\", %%mm6\t\\n\\t\"\n\n\t\t\t\".balign 16\t\t\t\\n\\t\"\n\n\t\t\t\"1:\t\t\t\t\\n\\t\"\n\n\t\t\t\"mov %2, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"movzwl (%%\"REG_c\", %0), %%eax\t\\n\\t\"\n\n\t\t\t\"movzwl 2(%%\"REG_c\", %0), %%ebx\t\\n\\t\"\n\n\t\t\t\"mov %5, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"pxor %%mm4, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pxor %%mm5, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"2:\t\t\t\t\\n\\t\"\n\n\t\t\t\"movq (%1), %%mm1\t\t\\n\\t\"\n\n\t\t\t\"movq (%1, %6), %%mm3\t\t\\n\\t\"\n\n\t\t\t\"movd (%%\"REG_c\", %%\"REG_a\"), %%mm0\\n\\t\"\n\n\t\t\t\"movd (%%\"REG_c\", %%\"REG_b\"), %%mm2\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"punpcklbw %%mm7, %%mm2\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm1, %%mm0\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm2, %%mm3\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm3, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"paddd %%mm0, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"add $8, %1\t\t\t\\n\\t\"\n\n\t\t\t\"add $4, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\"cmp %4, %%\"REG_c\"\t\t\\n\\t\"\n\n\t\t\t\" jb 2b\t\t\t\t\\n\\t\"\n\n\t\t\t\"add %6, %1\t\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"psrad $8, %%mm5\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm5, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"pmaddwd %%mm6, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"packssdw %%mm4, %%mm4\t\t\\n\\t\"\n\n\t\t\t\"mov %3, %%\"REG_a\"\t\t\\n\\t\"\n\n\t\t\t\"movd %%mm4, (%%\"REG_a\", %0)\t\\n\\t\"\n\n\t\t\t\"add $4, %0\t\t\t\\n\\t\"\n\n\t\t\t\" jnc 1b\t\t\t\\n\\t\"\n\n\n\n\t\t\t: \"+r\" (counter), \"+r\" (filter)\n\n\t\t\t: \"m\" (filterPos), \"m\" (dst), \"m\"(offset),\n\n\t\t\t  \"m\" (src), \"r\" ((long)filterSize*2)\n\n\t\t\t: \"%\"REG_b, \"%\"REG_a, \"%\"REG_c\n\n\t\t);\n\n\t}\n\n#else\n\n#ifdef HAVE_ALTIVEC\n\n\thScale_altivec_real(dst, dstW, src, srcW, xInc, filter, filterPos, filterSize);\n\n#else\n\n\tint i;\n\n\tfor(i=0; i<dstW; i++)\n\n\t{\n\n\t\tint j;\n\n\t\tint srcPos= filterPos[i];\n\n\t\tint val=0;\n\n//\t\tprintf(\"filterPos: %d\\n\", filterPos[i]);\n\n\t\tfor(j=0; j<filterSize; j++)\n\n\t\t{\n\n//\t\t\tprintf(\"filter: %d, src: %d\\n\", filter[i], src[srcPos + j]);\n\n\t\t\tval += ((int)src[srcPos + j])*filter[filterSize*i + j];\n\n\t\t}\n\n//\t\tfilter += hFilterSize;\n\n\t\tdst[i] = MIN(MAX(0, val>>7), (1<<15)-1); // the cubic equation does overflow ...\n\n//\t\tdst[i] = val>>7;\n\n\t}\n\n#endif\n\n#endif\n\n}\n", "idx": 22429, "_split": "test", "_hash": "bef888005aed4502249c5d8ca7192170"}
{"project": "FFmpeg", "commit_id": "d3b4b74c32cf302d36a4c4d2cce08027f0a22560", "target": 0, "func": "static int encode_picture_lossless(AVCodecContext *avctx, unsigned char *buf, int buf_size, void *data){\n\n    MpegEncContext * const s = avctx->priv_data;\n\n    MJpegContext * const m = s->mjpeg_ctx;\n\n    AVFrame *pict = data;\n\n    const int width= s->width;\n\n    const int height= s->height;\n\n    AVFrame * const p= (AVFrame*)&s->current_picture;\n\n    const int predictor= avctx->prediction_method+1;\n\n\n\n    init_put_bits(&s->pb, buf, buf_size);\n\n\n\n    *p = *pict;\n\n    p->pict_type= FF_I_TYPE;\n\n    p->key_frame= 1;\n\n\n\n    ff_mjpeg_encode_picture_header(s);\n\n\n\n    s->header_bits= put_bits_count(&s->pb);\n\n\n\n    if(avctx->pix_fmt == PIX_FMT_RGB32){\n\n        int x, y, i;\n\n        const int linesize= p->linesize[0];\n\n        uint16_t (*buffer)[4]= (void *) s->rd_scratchpad;\n\n        int left[3], top[3], topleft[3];\n\n\n\n        for(i=0; i<3; i++){\n\n            buffer[0][i]= 1 << (9 - 1);\n\n        }\n\n\n\n        for(y = 0; y < height; y++) {\n\n            const int modified_predictor= y ? predictor : 1;\n\n            uint8_t *ptr = p->data[0] + (linesize * y);\n\n\n\n            if(s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb)>>3) < width*3*4){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n                return -1;\n\n            }\n\n\n\n            for(i=0; i<3; i++){\n\n                top[i]= left[i]= topleft[i]= buffer[0][i];\n\n            }\n\n            for(x = 0; x < width; x++) {\n\n                buffer[x][1] = ptr[4*x+0] - ptr[4*x+1] + 0x100;\n\n                buffer[x][2] = ptr[4*x+2] - ptr[4*x+1] + 0x100;\n\n                buffer[x][0] = (ptr[4*x+0] + 2*ptr[4*x+1] + ptr[4*x+2])>>2;\n\n\n\n                for(i=0;i<3;i++) {\n\n                    int pred, diff;\n\n\n\n                    PREDICT(pred, topleft[i], top[i], left[i], modified_predictor);\n\n\n\n                    topleft[i]= top[i];\n\n                    top[i]= buffer[x+1][i];\n\n\n\n                    left[i]= buffer[x][i];\n\n\n\n                    diff= ((left[i] - pred + 0x100)&0x1FF) - 0x100;\n\n\n\n                    if(i==0)\n\n                        ff_mjpeg_encode_dc(s, diff, m->huff_size_dc_luminance, m->huff_code_dc_luminance); //FIXME ugly\n\n                    else\n\n                        ff_mjpeg_encode_dc(s, diff, m->huff_size_dc_chrominance, m->huff_code_dc_chrominance);\n\n                }\n\n            }\n\n        }\n\n    }else{\n\n        int mb_x, mb_y, i;\n\n        const int mb_width  = (width  + s->mjpeg_hsample[0] - 1) / s->mjpeg_hsample[0];\n\n        const int mb_height = (height + s->mjpeg_vsample[0] - 1) / s->mjpeg_vsample[0];\n\n\n\n        for(mb_y = 0; mb_y < mb_height; mb_y++) {\n\n            if(s->pb.buf_end - s->pb.buf - (put_bits_count(&s->pb)>>3) < mb_width * 4 * 3 * s->mjpeg_hsample[0] * s->mjpeg_vsample[0]){\n\n                av_log(s->avctx, AV_LOG_ERROR, \"encoded frame too large\\n\");\n\n                return -1;\n\n            }\n\n            for(mb_x = 0; mb_x < mb_width; mb_x++) {\n\n                if(mb_x==0 || mb_y==0){\n\n                    for(i=0;i<3;i++) {\n\n                        uint8_t *ptr;\n\n                        int x, y, h, v, linesize;\n\n                        h = s->mjpeg_hsample[i];\n\n                        v = s->mjpeg_vsample[i];\n\n                        linesize= p->linesize[i];\n\n\n\n                        for(y=0; y<v; y++){\n\n                            for(x=0; x<h; x++){\n\n                                int pred;\n\n\n\n                                ptr = p->data[i] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n\n                                if(y==0 && mb_y==0){\n\n                                    if(x==0 && mb_x==0){\n\n                                        pred= 128;\n\n                                    }else{\n\n                                        pred= ptr[-1];\n\n                                    }\n\n                                }else{\n\n                                    if(x==0 && mb_x==0){\n\n                                        pred= ptr[-linesize];\n\n                                    }else{\n\n                                        PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n                                    }\n\n                                }\n\n\n\n                                if(i==0)\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_luminance, m->huff_code_dc_luminance); //FIXME ugly\n\n                                else\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_chrominance, m->huff_code_dc_chrominance);\n\n                            }\n\n                        }\n\n                    }\n\n                }else{\n\n                    for(i=0;i<3;i++) {\n\n                        uint8_t *ptr;\n\n                        int x, y, h, v, linesize;\n\n                        h = s->mjpeg_hsample[i];\n\n                        v = s->mjpeg_vsample[i];\n\n                        linesize= p->linesize[i];\n\n\n\n                        for(y=0; y<v; y++){\n\n                            for(x=0; x<h; x++){\n\n                                int pred;\n\n\n\n                                ptr = p->data[i] + (linesize * (v * mb_y + y)) + (h * mb_x + x); //FIXME optimize this crap\n\n//printf(\"%d %d %d %d %8X\\n\", mb_x, mb_y, x, y, ptr);\n\n                                PREDICT(pred, ptr[-linesize-1], ptr[-linesize], ptr[-1], predictor);\n\n\n\n                                if(i==0)\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_luminance, m->huff_code_dc_luminance); //FIXME ugly\n\n                                else\n\n                                    ff_mjpeg_encode_dc(s, (int8_t)(*ptr - pred), m->huff_size_dc_chrominance, m->huff_code_dc_chrominance);\n\n                            }\n\n                        }\n\n                    }\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    emms_c();\n\n\n\n    ff_mjpeg_encode_picture_trailer(s);\n\n    s->picture_number++;\n\n\n\n    flush_put_bits(&s->pb);\n\n    return pbBufPtr(&s->pb) - s->pb.buf;\n\n//    return (put_bits_count(&f->pb)+7)/8;\n\n}\n", "idx": 22436, "_split": "test", "_hash": "2a6b0be8383eec96e272fbe7d708145a"}
{"project": "FFmpeg", "commit_id": "934fe00680a1139cbc0950641655af5923dd7763", "target": 0, "func": "static int opt_input_file(OptionsContext *o, const char *opt, const char *filename)\n\n{\n\n    AVFormatContext *ic;\n\n    AVInputFormat *file_iformat = NULL;\n\n    int err, i, ret;\n\n    int64_t timestamp;\n\n    uint8_t buf[128];\n\n    AVDictionary **opts;\n\n    int orig_nb_streams;                     // number of streams before avformat_find_stream_info\n\n\n\n    if (o->format) {\n\n        if (!(file_iformat = av_find_input_format(o->format))) {\n\n            av_log(NULL, AV_LOG_FATAL, \"Unknown input format: '%s'\\n\", o->format);\n\n            exit_program(1);\n\n        }\n\n    }\n\n\n\n    if (!strcmp(filename, \"-\"))\n\n        filename = \"pipe:\";\n\n\n\n    using_stdin |= !strncmp(filename, \"pipe:\", 5) ||\n\n                    !strcmp(filename, \"/dev/stdin\");\n\n\n\n    /* get default parameters from command line */\n\n    ic = avformat_alloc_context();\n\n    if (!ic) {\n\n        print_error(filename, AVERROR(ENOMEM));\n\n        exit_program(1);\n\n    }\n\n    if (o->nb_audio_sample_rate) {\n\n        snprintf(buf, sizeof(buf), \"%d\", o->audio_sample_rate[o->nb_audio_sample_rate - 1].u.i);\n\n        av_dict_set(&format_opts, \"sample_rate\", buf, 0);\n\n    }\n\n    if (o->nb_audio_channels) {\n\n        snprintf(buf, sizeof(buf), \"%d\", o->audio_channels[o->nb_audio_channels - 1].u.i);\n\n        av_dict_set(&format_opts, \"channels\", buf, 0);\n\n    }\n\n    if (o->nb_frame_rates) {\n\n        av_dict_set(&format_opts, \"framerate\", o->frame_rates[o->nb_frame_rates - 1].u.str, 0);\n\n    }\n\n    if (o->nb_frame_sizes) {\n\n        av_dict_set(&format_opts, \"video_size\", o->frame_sizes[o->nb_frame_sizes - 1].u.str, 0);\n\n    }\n\n    if (o->nb_frame_pix_fmts)\n\n        av_dict_set(&format_opts, \"pixel_format\", o->frame_pix_fmts[o->nb_frame_pix_fmts - 1].u.str, 0);\n\n\n\n    ic->video_codec_id   = video_codec_name ?\n\n        find_codec_or_die(video_codec_name   , AVMEDIA_TYPE_VIDEO   , 0)->id : CODEC_ID_NONE;\n\n    ic->audio_codec_id   = audio_codec_name ?\n\n        find_codec_or_die(audio_codec_name   , AVMEDIA_TYPE_AUDIO   , 0)->id : CODEC_ID_NONE;\n\n    ic->subtitle_codec_id= subtitle_codec_name ?\n\n        find_codec_or_die(subtitle_codec_name, AVMEDIA_TYPE_SUBTITLE, 0)->id : CODEC_ID_NONE;\n\n    ic->flags |= AVFMT_FLAG_NONBLOCK;\n\n    ic->interrupt_callback = int_cb;\n\n\n\n    if (loop_input) {\n\n        av_log(NULL, AV_LOG_WARNING, \"-loop_input is deprecated, use -loop 1\\n\");\n\n        ic->loop_input = loop_input;\n\n    }\n\n\n\n    /* open the input file with generic avformat function */\n\n    err = avformat_open_input(&ic, filename, file_iformat, &format_opts);\n\n    if (err < 0) {\n\n        print_error(filename, err);\n\n        exit_program(1);\n\n    }\n\n    assert_avoptions(format_opts);\n\n\n\n    /* apply forced codec ids */\n\n    for (i = 0; i < ic->nb_streams; i++)\n\n        choose_decoder(o, ic, ic->streams[i]);\n\n\n\n    /* Set AVCodecContext options for avformat_find_stream_info */\n\n    opts = setup_find_stream_info_opts(ic, codec_opts);\n\n    orig_nb_streams = ic->nb_streams;\n\n\n\n    /* If not enough info to get the stream parameters, we decode the\n\n       first frames to get it. (used in mpeg case for example) */\n\n    ret = avformat_find_stream_info(ic, opts);\n\n    if (ret < 0) {\n\n        av_log(NULL, AV_LOG_FATAL, \"%s: could not find codec parameters\\n\", filename);\n\n        av_close_input_file(ic);\n\n        exit_program(1);\n\n    }\n\n\n\n    timestamp = o->start_time;\n\n    /* add the stream start time */\n\n    if (ic->start_time != AV_NOPTS_VALUE)\n\n        timestamp += ic->start_time;\n\n\n\n    /* if seeking requested, we execute it */\n\n    if (o->start_time != 0) {\n\n        ret = av_seek_frame(ic, -1, timestamp, AVSEEK_FLAG_BACKWARD);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_WARNING, \"%s: could not seek to position %0.3f\\n\",\n\n                   filename, (double)timestamp / AV_TIME_BASE);\n\n        }\n\n    }\n\n\n\n    /* update the current parameters so that they match the one of the input stream */\n\n    add_input_streams(o, ic);\n\n\n\n    /* dump the file content */\n\n    av_dump_format(ic, nb_input_files, filename, 0);\n\n\n\n    input_files = grow_array(input_files, sizeof(*input_files), &nb_input_files, nb_input_files + 1);\n\n    input_files[nb_input_files - 1].ctx        = ic;\n\n    input_files[nb_input_files - 1].ist_index  = nb_input_streams - ic->nb_streams;\n\n    input_files[nb_input_files - 1].ts_offset  = o->input_ts_offset - (copy_ts ? 0 : timestamp);\n\n    input_files[nb_input_files - 1].nb_streams = ic->nb_streams;\n\n    input_files[nb_input_files - 1].rate_emu   = o->rate_emu;\n\n\n\n    for (i = 0; i < o->nb_dump_attachment; i++) {\n\n        int j;\n\n\n\n        for (j = 0; j < ic->nb_streams; j++) {\n\n            AVStream *st = ic->streams[j];\n\n\n\n            if (check_stream_specifier(ic, st, o->dump_attachment[i].specifier) == 1)\n\n                dump_attachment(st, o->dump_attachment[i].u.str);\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < orig_nb_streams; i++)\n\n        av_dict_free(&opts[i]);\n\n    av_freep(&opts);\n\n\n\n    reset_options(o, 1);\n\n    return 0;\n\n}\n", "idx": 22459, "_split": "test", "_hash": "fd4116f0d83076e7d276977e405952db"}
{"project": "FFmpeg", "commit_id": "f6774f905fb3cfdc319523ac640be30b14c1bc55", "target": 1, "func": "void ff_thread_release_buffer(AVCodecContext *avctx, ThreadFrame *f)\n\n{\n\n    PerThreadContext *p = avctx->internal->thread_ctx;\n\n    FrameThreadContext *fctx;\n\n    AVFrame *dst, *tmp;\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    int can_direct_free = !(avctx->active_thread_type & FF_THREAD_FRAME) ||\n\n                          avctx->thread_safe_callbacks                   ||\n\n                          (\n\n#if FF_API_GET_BUFFER\n\n                           !avctx->get_buffer &&\n\n#endif\n\n                           avctx->get_buffer2 == avcodec_default_get_buffer2);\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n\n\n    if (!f->f->buf[0])\n\n        return;\n\n\n\n    if (avctx->debug & FF_DEBUG_BUFFERS)\n\n        av_log(avctx, AV_LOG_DEBUG, \"thread_release_buffer called on pic %p\\n\", f);\n\n\n\n    av_buffer_unref(&f->progress);\n\n    f->owner    = NULL;\n\n\n\n    if (can_direct_free) {\n\n        av_frame_unref(f->f);\n\n        return;\n\n    }\n\n\n\n    fctx = p->parent;\n\n    pthread_mutex_lock(&fctx->buffer_mutex);\n\n\n\n    if (p->num_released_buffers + 1 >= INT_MAX / sizeof(*p->released_buffers))\n\n        goto fail;\n\n    tmp = av_fast_realloc(p->released_buffers, &p->released_buffers_allocated,\n\n                          (p->num_released_buffers + 1) *\n\n                          sizeof(*p->released_buffers));\n\n    if (!tmp)\n\n        goto fail;\n\n    p->released_buffers = tmp;\n\n\n\n    dst = &p->released_buffers[p->num_released_buffers];\n\n    av_frame_move_ref(dst, f->f);\n\n\n\n    p->num_released_buffers++;\n\n\n\nfail:\n\n    pthread_mutex_unlock(&fctx->buffer_mutex);\n\n}\n", "idx": 22503, "_split": "test", "_hash": "1822ac8c5f7e830df955d0dcd049f6e9"}
{"project": "FFmpeg", "commit_id": "220b24c7c97dc033ceab1510549f66d0e7b52ef1", "target": 1, "func": "void ff_schro_queue_free(FFSchroQueue *queue, void (*free_func)(void *))\n\n{\n\n    while (queue->p_head)\n\n        free_func(ff_schro_queue_pop(queue));\n\n}\n", "idx": 22531, "_split": "test", "_hash": "3bdc54db11df0c27a3d8f72d424d7563"}
{"project": "FFmpeg", "commit_id": "69e7336b8e16ee65226fc20381baf537f4b125e6", "target": 0, "func": "AVInputFormat *av_find_input_format(const char *short_name)\n\n{\n\n    AVInputFormat *fmt = NULL;\n\n    while ((fmt = av_iformat_next(fmt)))\n\n        if (match_format(short_name, fmt->name))\n\n            return fmt;\n\n    return NULL;\n\n}\n", "idx": 22559, "_split": "test", "_hash": "7bf37ef0afe345630511f8c2e43f5d4a"}
{"project": "FFmpeg", "commit_id": "b791a0831b0a027e7ba4eb6961cc0180472ac603", "target": 1, "func": "static av_cold void dsputil_init_sse2(DSPContext *c, AVCodecContext *avctx,\n\n                                      int mm_flags)\n\n{\n\n#if HAVE_SSE2_INLINE\n\n    const int high_bit_depth = avctx->bits_per_raw_sample > 8;\n\n\n\n    if (!high_bit_depth && avctx->idct_algo == FF_IDCT_XVIDMMX) {\n\n        c->idct_put              = ff_idct_xvid_sse2_put;\n\n        c->idct_add              = ff_idct_xvid_sse2_add;\n\n        c->idct                  = ff_idct_xvid_sse2;\n\n        c->idct_permutation_type = FF_SSE2_IDCT_PERM;\n\n    }\n\n#endif /* HAVE_SSE2_INLINE */\n\n\n\n#if HAVE_SSE2_EXTERNAL\n\n    c->scalarproduct_int16          = ff_scalarproduct_int16_sse2;\n\n    c->scalarproduct_and_madd_int16 = ff_scalarproduct_and_madd_int16_sse2;\n\n    if (mm_flags & AV_CPU_FLAG_ATOM) {\n\n        c->vector_clip_int32 = ff_vector_clip_int32_int_sse2;\n\n    } else {\n\n        c->vector_clip_int32 = ff_vector_clip_int32_sse2;\n\n    }\n\n    if (avctx->flags & CODEC_FLAG_BITEXACT) {\n\n        c->apply_window_int16 = ff_apply_window_int16_sse2;\n\n    } else if (!(mm_flags & AV_CPU_FLAG_SSE2SLOW)) {\n\n        c->apply_window_int16 = ff_apply_window_int16_round_sse2;\n\n    }\n\n    c->bswap_buf = ff_bswap32_buf_sse2;\n\n#endif /* HAVE_SSE2_EXTERNAL */\n\n}\n", "idx": 22597, "_split": "test", "_hash": "0f99e8f9d6164d8a7df24a5c4570cfc6"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int au_probe(AVProbeData *p)\n\n{\n\n    /* check file header */\n\n    if (p->buf_size <= 24)\n\n        return 0;\n\n    if (p->buf[0] == '.' && p->buf[1] == 's' &&\n\n        p->buf[2] == 'n' && p->buf[3] == 'd')\n\n        return AVPROBE_SCORE_MAX;\n\n    else\n\n        return 0;\n\n}\n", "idx": 22601, "_split": "test", "_hash": "f5de4e5a2901c01f861cfe821586437f"}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "void ff_af_queue_remove(AudioFrameQueue *afq, int nb_samples, int64_t *pts,\n\n                        int *duration)\n\n{\n\n    int64_t out_pts = AV_NOPTS_VALUE;\n\n    int removed_samples = 0;\n\n\n\n#ifdef DEBUG\n\n    ff_af_queue_log_state(afq);\n\n#endif\n\n\n\n    /* get output pts from the next frame or generated pts */\n\n    if (afq->frame_queue) {\n\n        if (afq->frame_queue->pts != AV_NOPTS_VALUE)\n\n            out_pts = afq->frame_queue->pts - afq->remaining_delay;\n\n    } else {\n\n        if (afq->next_pts != AV_NOPTS_VALUE)\n\n            out_pts = afq->next_pts - afq->remaining_delay;\n\n    }\n\n    if (pts) {\n\n        if (out_pts != AV_NOPTS_VALUE)\n\n            *pts = ff_samples_to_time_base(afq->avctx, out_pts);\n\n        else\n\n            *pts = AV_NOPTS_VALUE;\n\n    }\n\n\n\n    /* if the delay is larger than the packet duration, we use up delay samples\n\n       for the output packet and leave all frames in the queue */\n\n    if (afq->remaining_delay >= nb_samples) {\n\n        removed_samples      += nb_samples;\n\n        afq->remaining_delay -= nb_samples;\n\n    }\n\n    /* remove frames from the queue until we have enough to cover the\n\n       requested number of samples or until the queue is empty */\n\n    while (removed_samples < nb_samples && afq->frame_queue) {\n\n        removed_samples += afq->frame_queue->duration;\n\n        delete_next_frame(afq);\n\n    }\n\n    afq->remaining_samples -= removed_samples;\n\n\n\n    /* if there are no frames left and we have room for more samples, use\n\n       any remaining delay samples */\n\n    if (removed_samples < nb_samples && afq->remaining_samples > 0) {\n\n        int add_samples = FFMIN(afq->remaining_samples,\n\n                                nb_samples - removed_samples);\n\n        removed_samples        += add_samples;\n\n        afq->remaining_samples -= add_samples;\n\n    }\n\n    if (removed_samples > nb_samples)\n\n        av_log(afq->avctx, AV_LOG_WARNING, \"frame_size is too large\\n\");\n\n    if (duration)\n\n        *duration = ff_samples_to_time_base(afq->avctx, removed_samples);\n\n}\n", "idx": 22637, "_split": "test", "_hash": "04f402127490c0de7534924c906fa0e7"}
{"project": "FFmpeg", "commit_id": "2711cb28f46463760f0326d806fe5ef9551ade2c", "target": 1, "func": "static double get_diff_limited_q(MpegEncContext *s, RateControlEntry *rce, double q){\n\n    RateControlContext *rcc= &s->rc_context;\n\n    AVCodecContext *a= s->avctx;\n\n    const int pict_type= rce->new_pict_type;\n\n    const double last_p_q    = rcc->last_qscale_for[P_TYPE];\n\n    const double last_non_b_q= rcc->last_qscale_for[rcc->last_non_b_pict_type];\n\n\n\n    if     (pict_type==I_TYPE && (a->i_quant_factor>0.0 || rcc->last_non_b_pict_type==P_TYPE))\n\n        q= last_p_q    *FFABS(a->i_quant_factor) + a->i_quant_offset;\n\n    else if(pict_type==B_TYPE && a->b_quant_factor>0.0)\n\n        q= last_non_b_q*    a->b_quant_factor  + a->b_quant_offset;\n\n\n\n\n    /* last qscale / qdiff stuff */\n\n    if(rcc->last_non_b_pict_type==pict_type || pict_type!=I_TYPE){\n\n        double last_q= rcc->last_qscale_for[pict_type];\n\n        const int maxdiff= FF_QP2LAMBDA * a->max_qdiff;\n\n\n\n        if     (q > last_q + maxdiff) q= last_q + maxdiff;\n\n        else if(q < last_q - maxdiff) q= last_q - maxdiff;\n\n    }\n\n\n\n    rcc->last_qscale_for[pict_type]= q; //Note we cannot do that after blurring\n\n\n\n    if(pict_type!=B_TYPE)\n\n        rcc->last_non_b_pict_type= pict_type;\n\n\n\n    return q;\n\n}", "idx": 22655, "_split": "test", "_hash": "5e9c29a40667056c0d4028e66fa6cc0e"}
{"project": "FFmpeg", "commit_id": "67400f6b6219892ab7a555fb61ef979c857692d7", "target": 0, "func": "static int mov_write_hdlr_tag(AVIOContext *pb, MOVTrack *track)\n\n{\n\n    const char *hdlr, *descr = NULL, *hdlr_type = NULL;\n\n    int64_t pos = avio_tell(pb);\n\n\n\n    if (!track) { /* no media --> data handler */\n\n        hdlr      = \"dhlr\";\n\n        hdlr_type = \"url \";\n\n        descr     = \"DataHandler\";\n\n    } else {\n\n        hdlr = (track->mode == MODE_MOV) ? \"mhlr\" : \"\\0\\0\\0\\0\";\n\n        if (track->enc->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            hdlr_type = \"vide\";\n\n            descr     = \"VideoHandler\";\n\n        } else if (track->enc->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            hdlr_type = \"soun\";\n\n            descr     = \"SoundHandler\";\n\n        } else if (track->enc->codec_type == AVMEDIA_TYPE_SUBTITLE) {\n\n            if (track->tag == MKTAG('t','x','3','g')) hdlr_type = \"sbtl\";\n\n            else                                      hdlr_type = \"text\";\n\n            descr = \"SubtitleHandler\";\n\n        } else if (track->enc->codec_tag == MKTAG('r','t','p',' ')) {\n\n            hdlr_type = \"hint\";\n\n            descr     = \"HintHandler\";\n\n        }\n\n    }\n\n\n\n    avio_wb32(pb, 0); /* size */\n\n    ffio_wfourcc(pb, \"hdlr\");\n\n    avio_wb32(pb, 0); /* Version & flags */\n\n    avio_write(pb, hdlr, 4); /* handler */\n\n    ffio_wfourcc(pb, hdlr_type); /* handler type */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    avio_wb32(pb, 0); /* reserved */\n\n    if (!track || track->mode == MODE_MOV)\n\n        avio_w8(pb, strlen(descr)); /* pascal string */\n\n    avio_write(pb, descr, strlen(descr)); /* handler description */\n\n    if (track && track->mode != MODE_MOV)\n\n        avio_w8(pb, 0); /* c string */\n\n    return update_size(pb, pos);\n\n}\n", "idx": 22662, "_split": "test", "_hash": "9150f5c576cbce0b962fa72b49538c77"}
{"project": "FFmpeg", "commit_id": "90fc00a623de44e137fe1601b91356e8cd8bdd54", "target": 1, "func": "static int srt_probe(AVProbeData *p)\n\n{\n\n    const unsigned char *ptr = p->buf;\n\n    int i, v, num = 0;\n\n\n\n    if (AV_RB24(ptr) == 0xEFBBBF)\n\n        ptr += 3;  /* skip UTF-8 BOM */\n\n\n\n    while (*ptr == '\\r' || *ptr == '\\n')\n\n        ptr++;\n\n    for (i=0; i<2; i++) {\n\n        if ((num == i || num + 1 == i)\n\n            && sscanf(ptr, \"%*d:%*2d:%*2d%*1[,.]%*3d --> %*d:%*2d:%*2d%*1[,.]%3d\", &v) == 1)\n\n            return AVPROBE_SCORE_MAX;\n\n        num = atoi(ptr);\n\n        ptr += strcspn(ptr, \"\\n\") + 1;\n\n    }\n\n    return 0;\n\n}\n", "idx": 22702, "_split": "test", "_hash": "4e8a63b61f51dacf9ffb7ec666e43119"}
{"project": "FFmpeg", "commit_id": "cea9eb9520fab9e5ec79d3a2d4dbd03eb71b7fa3", "target": 1, "func": "static av_cold int dnxhd_decode_close(AVCodecContext *avctx)\n\n{\n\n    DNXHDContext *ctx = avctx->priv_data;\n\n\n\n    ff_free_vlc(&ctx->ac_vlc);\n\n    ff_free_vlc(&ctx->dc_vlc);\n\n    ff_free_vlc(&ctx->run_vlc);\n\n\n\n    av_freep(&ctx->mb_scan_index);\n\n    av_freep(&ctx->rows);\n\n\n\n    return 0;\n\n}\n", "idx": 22718, "_split": "test", "_hash": "3184ca998db1fbede063723a07d1ecef"}
{"project": "FFmpeg", "commit_id": "79997def65fd2313b48a5f3c3a884c6149ae9b5d", "target": 0, "func": "static void mdct_test(AC3MDCTContext *mdct, AVLFG *lfg)\n\n{\n\n    int16_t input[MDCT_SAMPLES];\n\n    int32_t output[AC3_MAX_COEFS];\n\n    float input1[MDCT_SAMPLES];\n\n    float output1[AC3_MAX_COEFS];\n\n    float s, a, err, e, emax;\n\n    int i, k, n;\n\n\n\n    for (i = 0; i < MDCT_SAMPLES; i++) {\n\n        input[i]  = (av_lfg_get(lfg) % 65535 - 32767) * 9 / 10;\n\n        input1[i] = input[i];\n\n    }\n\n\n\n    mdct512(mdct, output, input);\n\n\n\n    /* do it by hand */\n\n    for (k = 0; k < AC3_MAX_COEFS; k++) {\n\n        s = 0;\n\n        for (n = 0; n < MDCT_SAMPLES; n++) {\n\n            a = (2*M_PI*(2*n+1+MDCT_SAMPLES/2)*(2*k+1) / (4 * MDCT_SAMPLES));\n\n            s += input1[n] * cos(a);\n\n        }\n\n        output1[k] = -2 * s / MDCT_SAMPLES;\n\n    }\n\n\n\n    err  = 0;\n\n    emax = 0;\n\n    for (i = 0; i < AC3_MAX_COEFS; i++) {\n\n        av_log(NULL, AV_LOG_DEBUG, \"%3d: %7d %7.0f\\n\", i, output[i], output1[i]);\n\n        e = output[i] - output1[i];\n\n        if (e > emax)\n\n            emax = e;\n\n        err += e * e;\n\n    }\n\n    av_log(NULL, AV_LOG_DEBUG, \"err2=%f emax=%f\\n\", err / AC3_MAX_COEFS, emax);\n\n}\n", "idx": 22826, "_split": "test", "_hash": "5a81406abbafd44242b1ce5e9fd9069f"}
{"project": "FFmpeg", "commit_id": "a66c6e28b543804f50df1c6083a204219b6b1daa", "target": 1, "func": "static AVRational update_sar(int old_w, int old_h, AVRational sar, int new_w, int new_h)\n\n{\n\n    // attempt to keep aspect during typical resolution switches\n\n    if (!sar.num)\n\n        sar = (AVRational){1, 1};\n\n\n\n    sar = av_mul_q(sar, (AVRational){new_h * old_w, new_w * old_h});\n\n    return sar;\n\n}\n", "idx": 22833, "_split": "test", "_hash": "e5ae1ef8a5e7202c43bf887a8fd1db3e"}
{"project": "FFmpeg", "commit_id": "ee90119e9ee0e2c54f1017bbe1460bfcd50555d0", "target": 1, "func": "static int decode_block(BinkAudioContext *s, float **out, int use_dct)\n\n{\n\n    int ch, i, j, k;\n\n    float q, quant[25];\n\n    int width, coeff;\n\n    GetBitContext *gb = &s->gb;\n\n\n\n    if (use_dct)\n\n        skip_bits(gb, 2);\n\n\n\n    for (ch = 0; ch < s->channels; ch++) {\n\n        FFTSample *coeffs = out[ch];\n\n\n\n        if (s->version_b) {\n\n            if (get_bits_left(gb) < 64)\n\n                return AVERROR_INVALIDDATA;\n\n            coeffs[0] = av_int2float(get_bits_long(gb, 32)) * s->root;\n\n            coeffs[1] = av_int2float(get_bits_long(gb, 32)) * s->root;\n\n        } else {\n\n            if (get_bits_left(gb) < 58)\n\n                return AVERROR_INVALIDDATA;\n\n            coeffs[0] = get_float(gb) * s->root;\n\n            coeffs[1] = get_float(gb) * s->root;\n\n        }\n\n\n\n        if (get_bits_left(gb) < s->num_bands * 8)\n\n            return AVERROR_INVALIDDATA;\n\n        for (i = 0; i < s->num_bands; i++) {\n\n            int value = get_bits(gb, 8);\n\n            quant[i]  = quant_table[FFMIN(value, 95)];\n\n        }\n\n\n\n        k = 0;\n\n        q = quant[0];\n\n\n\n        // parse coefficients\n\n        i = 2;\n\n        while (i < s->frame_len) {\n\n            if (s->version_b) {\n\n                j = i + 16;\n\n            } else {\n\n                int v;\n\n                GET_BITS_SAFE(v, 1);\n\n                if (v) {\n\n                    GET_BITS_SAFE(v, 4);\n\n                    j = i + rle_length_tab[v] * 8;\n\n                } else {\n\n                    j = i + 8;\n\n                }\n\n            }\n\n\n\n            j = FFMIN(j, s->frame_len);\n\n\n\n            GET_BITS_SAFE(width, 4);\n\n            if (width == 0) {\n\n                memset(coeffs + i, 0, (j - i) * sizeof(*coeffs));\n\n                i = j;\n\n                while (s->bands[k] < i)\n\n                    q = quant[k++];\n\n            } else {\n\n                while (i < j) {\n\n                    if (s->bands[k] == i)\n\n                        q = quant[k++];\n\n                    GET_BITS_SAFE(coeff, width);\n\n                    if (coeff) {\n\n                        int v;\n\n                        GET_BITS_SAFE(v, 1);\n\n                        if (v)\n\n                            coeffs[i] = -q * coeff;\n\n                        else\n\n                            coeffs[i] =  q * coeff;\n\n                    } else {\n\n                        coeffs[i] = 0.0f;\n\n                    }\n\n                    i++;\n\n                }\n\n            }\n\n        }\n\n\n\n        if (CONFIG_BINKAUDIO_DCT_DECODER && use_dct) {\n\n            coeffs[0] /= 0.5;\n\n            s->trans.dct.dct_calc(&s->trans.dct,  coeffs);\n\n        }\n\n        else if (CONFIG_BINKAUDIO_RDFT_DECODER)\n\n            s->trans.rdft.rdft_calc(&s->trans.rdft, coeffs);\n\n    }\n\n\n\n    for (ch = 0; ch < s->channels; ch++) {\n\n        int j;\n\n        int count = s->overlap_len * s->channels;\n\n        if (!s->first) {\n\n            j = ch;\n\n            for (i = 0; i < s->overlap_len; i++, j += s->channels)\n\n                out[ch][i] = (s->previous[ch][i] * (count - j) +\n\n                                      out[ch][i] *          j) / count;\n\n        }\n\n        memcpy(s->previous[ch], &out[ch][s->frame_len - s->overlap_len],\n\n               s->overlap_len * sizeof(*s->previous[ch]));\n\n    }\n\n\n\n    s->first = 0;\n\n\n\n    return 0;\n\n}\n", "idx": 22844, "_split": "test", "_hash": "6680673382509b51bfe3a254cc2eab5d"}
{"project": "FFmpeg", "commit_id": "e3e6a2cff4af9542455d416faec4584d5e823d5d", "target": 1, "func": "static void create_default_qtables(uint8_t *qtables, uint8_t q)\n\n{\n\n    int factor = q;\n\n    int i;\n\n\n\n    factor = av_clip(q, 1, 99);\n\n\n\n    if (q < 50)\n\n        q = 5000 / factor;\n\n    else\n\n        q = 200 - factor * 2;\n\n\n\n    for (i = 0; i < 128; i++) {\n\n        int val = (default_quantizers[i] * q + 50) / 100;\n\n\n\n        /* Limit the quantizers to 1 <= q <= 255. */\n\n        val = av_clip(val, 1, 255);\n\n        qtables[i] = val;\n\n    }\n\n}\n", "idx": 22944, "_split": "test", "_hash": "dbbe608eeadb392dffad65367df09e3f"}
{"project": "FFmpeg", "commit_id": "36583d23bdbe31e8845d3ca9162bce33fef6e48c", "target": 0, "func": "void ff_af_queue_close(AudioFrameQueue *afq)\n\n{\n\n    /* remove/free any remaining frames */\n\n    while (afq->frame_queue)\n\n        delete_next_frame(afq);\n\n    memset(afq, 0, sizeof(*afq));\n\n}\n", "idx": 22949, "_split": "test", "_hash": "9ac3cd8ee7924475305529e29f4148cd"}
{"project": "FFmpeg", "commit_id": "81cc7d0bd1eab0aa782ff8dd49e087025a42cdee", "target": 1, "func": "static void lumRangeToJpeg16_c(int16_t *_dst, int width)\n\n{\n\n    int i;\n\n    int32_t *dst = (int32_t *) _dst;\n\n    for (i = 0; i < width; i++)\n\n        dst[i] = (FFMIN(dst[i],30189<<4)*19077 - (39057361<<4))>>14;\n\n}\n", "idx": 22955, "_split": "test", "_hash": "1f5ebb799258b5f8bedf634a50797859"}
{"project": "FFmpeg", "commit_id": "1f80742f49a9a4e846c9f099387881abc87150b2", "target": 1, "func": "static void fill_coding_method_array(sb_int8_array tone_level_idx,\n\n                                     sb_int8_array tone_level_idx_temp,\n\n                                     sb_int8_array coding_method,\n\n                                     int nb_channels,\n\n                                     int c, int superblocktype_2_3,\n\n                                     int cm_table_select)\n\n{\n\n    int ch, sb, j;\n\n    int tmp, acc, esp_40, comp;\n\n    int add1, add2, add3, add4;\n\n    int64_t multres;\n\n\n\n    if (!superblocktype_2_3) {\n\n        /* This case is untested, no samples available */\n\n        SAMPLES_NEEDED\n\n        for (ch = 0; ch < nb_channels; ch++)\n\n            for (sb = 0; sb < 30; sb++) {\n\n                for (j = 1; j < 63; j++) {  // The loop only iterates to 63 so the code doesn't overflow the buffer\n\n                    add1 = tone_level_idx[ch][sb][j] - 10;\n\n                    if (add1 < 0)\n\n                        add1 = 0;\n\n                    add2 = add3 = add4 = 0;\n\n                    if (sb > 1) {\n\n                        add2 = tone_level_idx[ch][sb - 2][j] + tone_level_idx_offset_table[sb][0] - 6;\n\n                        if (add2 < 0)\n\n                            add2 = 0;\n\n                    }\n\n                    if (sb > 0) {\n\n                        add3 = tone_level_idx[ch][sb - 1][j] + tone_level_idx_offset_table[sb][1] - 6;\n\n                        if (add3 < 0)\n\n                            add3 = 0;\n\n                    }\n\n                    if (sb < 29) {\n\n                        add4 = tone_level_idx[ch][sb + 1][j] + tone_level_idx_offset_table[sb][3] - 6;\n\n                        if (add4 < 0)\n\n                            add4 = 0;\n\n                    }\n\n                    tmp = tone_level_idx[ch][sb][j + 1] * 2 - add4 - add3 - add2 - add1;\n\n                    if (tmp < 0)\n\n                        tmp = 0;\n\n                    tone_level_idx_temp[ch][sb][j + 1] = tmp & 0xff;\n\n                }\n\n                tone_level_idx_temp[ch][sb][0] = tone_level_idx_temp[ch][sb][1];\n\n            }\n\n            acc = 0;\n\n            for (ch = 0; ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++)\n\n                        acc += tone_level_idx_temp[ch][sb][j];\n\n\n\n            multres = 0x66666667 * (acc * 10);\n\n            esp_40 = (multres >> 32) / 8 + ((multres & 0xffffffff) >> 31);\n\n            for (ch = 0;  ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++) {\n\n                        comp = tone_level_idx_temp[ch][sb][j]* esp_40 * 10;\n\n                        if (comp < 0)\n\n                            comp += 0xff;\n\n                        comp /= 256; // signed shift\n\n                        switch(sb) {\n\n                            case 0:\n\n                                if (comp < 30)\n\n                                    comp = 30;\n\n                                comp += 15;\n\n                                break;\n\n                            case 1:\n\n                                if (comp < 24)\n\n                                    comp = 24;\n\n                                comp += 10;\n\n                                break;\n\n                            case 2:\n\n                            case 3:\n\n                            case 4:\n\n                                if (comp < 16)\n\n                                    comp = 16;\n\n                        }\n\n                        if (comp <= 5)\n\n                            tmp = 0;\n\n                        else if (comp <= 10)\n\n                            tmp = 10;\n\n                        else if (comp <= 16)\n\n                            tmp = 16;\n\n                        else if (comp <= 24)\n\n                            tmp = -1;\n\n                        else\n\n                            tmp = 0;\n\n                        coding_method[ch][sb][j] = ((tmp & 0xfffa) + 30 )& 0xff;\n\n                    }\n\n            for (sb = 0; sb < 30; sb++)\n\n                fix_coding_method_array(sb, nb_channels, coding_method);\n\n            for (ch = 0; ch < nb_channels; ch++)\n\n                for (sb = 0; sb < 30; sb++)\n\n                    for (j = 0; j < 64; j++)\n\n                        if (sb >= 10) {\n\n                            if (coding_method[ch][sb][j] < 10)\n\n                                coding_method[ch][sb][j] = 10;\n\n                        } else {\n\n                            if (sb >= 2) {\n\n                                if (coding_method[ch][sb][j] < 16)\n\n                                    coding_method[ch][sb][j] = 16;\n\n                            } else {\n\n                                if (coding_method[ch][sb][j] < 30)\n\n                                    coding_method[ch][sb][j] = 30;\n\n                            }\n\n                        }\n\n    } else { // superblocktype_2_3 != 0\n\n        for (ch = 0; ch < nb_channels; ch++)\n\n            for (sb = 0; sb < 30; sb++)\n\n                for (j = 0; j < 64; j++)\n\n                    coding_method[ch][sb][j] = coding_method_table[cm_table_select][sb];\n\n    }\n\n}\n", "idx": 22956, "_split": "test", "_hash": "fc250280edfe92bcab3eff37bdfbf0e6"}
{"project": "FFmpeg", "commit_id": "9ec39937f9c7f28a2279a19f71f290d8161eb52f", "target": 1, "func": "static void find_motion(DeshakeContext *deshake, uint8_t *src1, uint8_t *src2,\n\n                        int width, int height, int stride, Transform *t)\n\n{\n\n    int x, y;\n\n    IntMotionVector mv = {0, 0};\n\n    int counts[128][128];\n\n    int count_max_value = 0;\n\n    int contrast;\n\n\n\n    int pos;\n\n    double *angles = av_malloc(sizeof(*angles) * width * height / (16 * deshake->blocksize));\n\n    int center_x = 0, center_y = 0;\n\n    double p_x, p_y;\n\n\n\n    // Reset counts to zero\n\n    for (x = 0; x < deshake->rx * 2 + 1; x++) {\n\n        for (y = 0; y < deshake->ry * 2 + 1; y++) {\n\n            counts[x][y] = 0;\n\n        }\n\n    }\n\n\n\n    pos = 0;\n\n    // Find motion for every block and store the motion vector in the counts\n\n    for (y = deshake->ry; y < height - deshake->ry - (deshake->blocksize * 2); y += deshake->blocksize * 2) {\n\n        // We use a width of 16 here to match the libavcodec sad functions\n\n        for (x = deshake->rx; x < width - deshake->rx - 16; x += 16) {\n\n            // If the contrast is too low, just skip this block as it probably\n\n            // won't be very useful to us.\n\n            contrast = block_contrast(src2, x, y, stride, deshake->blocksize);\n\n            if (contrast > deshake->contrast) {\n\n                //av_log(NULL, AV_LOG_ERROR, \"%d\\n\", contrast);\n\n                find_block_motion(deshake, src1, src2, x, y, stride, &mv);\n\n                if (mv.x != -1 && mv.y != -1) {\n\n                    counts[mv.x + deshake->rx][mv.y + deshake->ry] += 1;\n\n                    if (x > deshake->rx && y > deshake->ry)\n\n                        angles[pos++] = block_angle(x, y, 0, 0, &mv);\n\n\n\n                    center_x += mv.x;\n\n                    center_y += mv.y;\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    pos = FFMAX(1, pos);\n\n\n\n    center_x /= pos;\n\n    center_y /= pos;\n\n\n\n    t->angle = clean_mean(angles, pos);\n\n    if (t->angle < 0.001)\n\n        t->angle = 0;\n\n\n\n    // Find the most common motion vector in the frame and use it as the gmv\n\n    for (y = deshake->ry * 2; y >= 0; y--) {\n\n        for (x = 0; x < deshake->rx * 2 + 1; x++) {\n\n            //av_log(NULL, AV_LOG_ERROR, \"%5d \", counts[x][y]);\n\n            if (counts[x][y] > count_max_value) {\n\n                t->vector.x = x - deshake->rx;\n\n                t->vector.y = y - deshake->ry;\n\n                count_max_value = counts[x][y];\n\n            }\n\n        }\n\n        //av_log(NULL, AV_LOG_ERROR, \"\\n\");\n\n    }\n\n\n\n    p_x = (center_x - width / 2);\n\n    p_y = (center_y - height / 2);\n\n    t->vector.x += (cos(t->angle)-1)*p_x  - sin(t->angle)*p_y;\n\n    t->vector.y += sin(t->angle)*p_x  + (cos(t->angle)-1)*p_y;\n\n\n\n    // Clamp max shift & rotation?\n\n    t->vector.x = av_clipf(t->vector.x, -deshake->rx * 2, deshake->rx * 2);\n\n    t->vector.y = av_clipf(t->vector.y, -deshake->ry * 2, deshake->ry * 2);\n\n    t->angle = av_clipf(t->angle, -0.1, 0.1);\n\n\n\n    //av_log(NULL, AV_LOG_ERROR, \"%d x %d\\n\", avg->x, avg->y);\n\n    av_free(angles);\n\n}\n", "idx": 22959, "_split": "test", "_hash": "a98814e2c2a64078eaf8f034ccab0773"}
{"project": "FFmpeg", "commit_id": "984f50deb2d48f6844d65e10991b996a6d29e87c", "target": 1, "func": "static int dirac_decode_frame(AVCodecContext *avctx, void *data, int *got_frame, AVPacket *pkt)\n\n{\n\n    DiracContext *s     = avctx->priv_data;\n\n    AVFrame *picture    = data;\n\n    uint8_t *buf        = pkt->data;\n\n    int buf_size        = pkt->size;\n\n    int i, data_unit_size, buf_idx = 0;\n\n    int ret;\n\n\n\n    /* release unused frames */\n\n    for (i = 0; i < MAX_FRAMES; i++)\n\n        if (s->all_frames[i].avframe->data[0] && !s->all_frames[i].avframe->reference) {\n\n            av_frame_unref(s->all_frames[i].avframe);\n\n            memset(s->all_frames[i].interpolated, 0, sizeof(s->all_frames[i].interpolated));\n\n        }\n\n\n\n    s->current_picture = NULL;\n\n    *got_frame = 0;\n\n\n\n    /* end of stream, so flush delayed pics */\n\n    if (buf_size == 0)\n\n        return get_delayed_pic(s, (AVFrame *)data, got_frame);\n\n\n\n    for (;;) {\n\n        /*[DIRAC_STD] Here starts the code from parse_info() defined in 9.6\n\n          [DIRAC_STD] PARSE_INFO_PREFIX = \"BBCD\" as defined in ISO/IEC 646\n\n          BBCD start code search */\n\n        for (; buf_idx + DATA_UNIT_HEADER_SIZE < buf_size; buf_idx++) {\n\n            if (buf[buf_idx  ] == 'B' && buf[buf_idx+1] == 'B' &&\n\n                buf[buf_idx+2] == 'C' && buf[buf_idx+3] == 'D')\n\n                break;\n\n        }\n\n        /* BBCD found or end of data */\n\n        if (buf_idx + DATA_UNIT_HEADER_SIZE >= buf_size)\n\n            break;\n\n\n\n        data_unit_size = AV_RB32(buf+buf_idx+5);\n\n        if (buf_idx + data_unit_size > buf_size || !data_unit_size) {\n\n            if(buf_idx + data_unit_size > buf_size)\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Data unit with size %d is larger than input buffer, discarding\\n\",\n\n                   data_unit_size);\n\n            buf_idx += 4;\n\n            continue;\n\n        }\n\n        /* [DIRAC_STD] dirac_decode_data_unit makes reference to the while defined in 9.3 inside the function parse_sequence() */\n\n        if (dirac_decode_data_unit(avctx, buf+buf_idx, data_unit_size))\n\n        {\n\n            av_log(s->avctx, AV_LOG_ERROR,\"Error in dirac_decode_data_unit\\n\");\n\n            return -1;\n\n        }\n\n        buf_idx += data_unit_size;\n\n    }\n\n\n\n    if (!s->current_picture)\n\n        return buf_size;\n\n\n\n    if (s->current_picture->avframe->display_picture_number > s->frame_number) {\n\n        DiracFrame *delayed_frame = remove_frame(s->delay_frames, s->frame_number);\n\n\n\n        s->current_picture->avframe->reference |= DELAYED_PIC_REF;\n\n\n\n        if (add_frame(s->delay_frames, MAX_DELAY, s->current_picture)) {\n\n            int min_num = s->delay_frames[0]->avframe->display_picture_number;\n\n            /* Too many delayed frames, so we display the frame with the lowest pts */\n\n            av_log(avctx, AV_LOG_ERROR, \"Delay frame overflow\\n\");\n\n\n\n            for (i = 1; s->delay_frames[i]; i++)\n\n                if (s->delay_frames[i]->avframe->display_picture_number < min_num)\n\n                    min_num = s->delay_frames[i]->avframe->display_picture_number;\n\n\n\n            delayed_frame = remove_frame(s->delay_frames, min_num);\n\n            add_frame(s->delay_frames, MAX_DELAY, s->current_picture);\n\n        }\n\n\n\n        if (delayed_frame) {\n\n            delayed_frame->avframe->reference ^= DELAYED_PIC_REF;\n\n            if((ret=av_frame_ref(data, delayed_frame->avframe)) < 0)\n\n                return ret;\n\n            *got_frame = 1;\n\n        }\n\n    } else if (s->current_picture->avframe->display_picture_number == s->frame_number) {\n\n        /* The right frame at the right time :-) */\n\n        if((ret=av_frame_ref(data, s->current_picture->avframe)) < 0)\n\n            return ret;\n\n        *got_frame = 1;\n\n    }\n\n\n\n    if (*got_frame)\n\n        s->frame_number = picture->display_picture_number + 1;\n\n\n\n    return buf_idx;\n\n}\n", "idx": 22966, "_split": "test", "_hash": "9c5d3796ec04c88eef068ee75998d1ef"}
{"project": "FFmpeg", "commit_id": "1330a0f31f373f3b9f1ea53d48b94edc47759b76", "target": 1, "func": "static av_cold void nvenc_setup_rate_control(AVCodecContext *avctx)\n\n{\n\n    NvencContext *ctx = avctx->priv_data;\n\n\n\n    if (avctx->bit_rate > 0) {\n\n        ctx->encode_config.rcParams.averageBitRate = avctx->bit_rate;\n\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n\n        ctx->encode_config.rcParams.maxBitRate = ctx->encode_config.rcParams.averageBitRate;\n\n    }\n\n\n\n    if (avctx->rc_max_rate > 0)\n\n        ctx->encode_config.rcParams.maxBitRate = avctx->rc_max_rate;\n\n\n\n    if (ctx->rc < 0) {\n\n        if (ctx->flags & NVENC_ONE_PASS)\n\n            ctx->twopass = 0;\n\n        if (ctx->flags & NVENC_TWO_PASSES)\n\n            ctx->twopass = 1;\n\n\n\n        if (ctx->twopass < 0)\n\n            ctx->twopass = (ctx->flags & NVENC_LOWLATENCY) != 0;\n\n\n\n        if (ctx->cbr) {\n\n            if (ctx->twopass) {\n\n                ctx->rc = NV_ENC_PARAMS_RC_2_PASS_QUALITY;\n\n            } else {\n\n                ctx->rc = NV_ENC_PARAMS_RC_CBR;\n\n            }\n\n        } else if (avctx->global_quality > 0) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_CONSTQP;\n\n        } else if (ctx->twopass) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_2_PASS_VBR;\n\n        } else if (avctx->qmin >= 0 && avctx->qmax >= 0) {\n\n            ctx->rc = NV_ENC_PARAMS_RC_VBR_MINQP;\n\n        }\n\n    }\n\n\n\n    if (ctx->flags & NVENC_LOSSLESS) {\n\n        set_lossless(avctx);\n\n    } else if (ctx->rc > 0) {\n\n        nvenc_override_rate_control(avctx);\n\n    } else {\n\n        ctx->encode_config.rcParams.rateControlMode = NV_ENC_PARAMS_RC_VBR;\n\n        set_vbr(avctx);\n\n    }\n\n\n\n    if (avctx->rc_buffer_size > 0) {\n\n        ctx->encode_config.rcParams.vbvBufferSize = avctx->rc_buffer_size;\n\n    } else if (ctx->encode_config.rcParams.averageBitRate > 0) {\n\n        ctx->encode_config.rcParams.vbvBufferSize = 2 * ctx->encode_config.rcParams.averageBitRate;\n\n    }\n\n}\n", "idx": 22970, "_split": "test", "_hash": "747a86c8cd2328125909d8d9c78c5243"}
{"project": "FFmpeg", "commit_id": "8370e426e42f2e4b9d14a1fb8107ecfe5163ce7f", "target": 1, "func": "static av_cold int vp3_decode_end(AVCodecContext *avctx)\n\n{\n\n    Vp3DecodeContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    if (avctx->is_copy && !s->current_frame.data[0])\n\n        return 0;\n\n\n\n    av_free(s->superblock_coding);\n\n    av_free(s->all_fragments);\n\n    av_free(s->coded_fragment_list[0]);\n\n    av_free(s->dct_tokens_base);\n\n    av_free(s->superblock_fragments);\n\n    av_free(s->macroblock_coding);\n\n    av_free(s->motion_val[0]);\n\n    av_free(s->motion_val[1]);\n\n    av_free(s->edge_emu_buffer);\n\n\n\n    if (avctx->is_copy) return 0;\n\n\n\n    for (i = 0; i < 16; i++) {\n\n        free_vlc(&s->dc_vlc[i]);\n\n        free_vlc(&s->ac_vlc_1[i]);\n\n        free_vlc(&s->ac_vlc_2[i]);\n\n        free_vlc(&s->ac_vlc_3[i]);\n\n        free_vlc(&s->ac_vlc_4[i]);\n\n    }\n\n\n\n    free_vlc(&s->superblock_run_length_vlc);\n\n    free_vlc(&s->fragment_run_length_vlc);\n\n    free_vlc(&s->mode_code_vlc);\n\n    free_vlc(&s->motion_vector_vlc);\n\n\n\n    /* release all frames */\n\n    if (s->golden_frame.data[0])\n\n        ff_thread_release_buffer(avctx, &s->golden_frame);\n\n    if (s->last_frame.data[0] && s->last_frame.type != FF_BUFFER_TYPE_COPY)\n\n        ff_thread_release_buffer(avctx, &s->last_frame);\n\n    /* no need to release the current_frame since it will always be pointing\n\n     * to the same frame as either the golden or last frame */\n\n\n\n    return 0;\n\n}\n", "idx": 22976, "_split": "test", "_hash": "b6d2c396b2baec37e73423fa1c7e8826"}
{"project": "FFmpeg", "commit_id": "83548fe894cdb455cc127f754d09905b6d23c173", "target": 0, "func": "static int gxf_write_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    GXFContext *gxf = s->priv_data;\n\n    GXFStreamContext *vsc = NULL;\n\n    uint8_t tracks[255] = {0};\n\n    int i, media_info = 0;\n\n\n\n    if (!pb->seekable) {\n\n        av_log(s, AV_LOG_ERROR, \"gxf muxer does not support streamed output, patch welcome\");\n\n        return -1;\n\n    }\n\n\n\n    gxf->flags |= 0x00080000; /* material is simple clip */\n\n    for (i = 0; i < s->nb_streams; ++i) {\n\n        AVStream *st = s->streams[i];\n\n        GXFStreamContext *sc = av_mallocz(sizeof(*sc));\n\n        if (!sc)\n\n            return AVERROR(ENOMEM);\n\n        st->priv_data = sc;\n\n\n\n        sc->media_type = ff_codec_get_tag(gxf_media_types, st->codecpar->codec_id);\n\n        if (st->codecpar->codec_type == AVMEDIA_TYPE_AUDIO) {\n\n            if (st->codecpar->codec_id != AV_CODEC_ID_PCM_S16LE) {\n\n                av_log(s, AV_LOG_ERROR, \"only 16 BIT PCM LE allowed for now\\n\");\n\n                return -1;\n\n            }\n\n            if (st->codecpar->sample_rate != 48000) {\n\n                av_log(s, AV_LOG_ERROR, \"only 48000hz sampling rate is allowed\\n\");\n\n                return -1;\n\n            }\n\n            if (st->codecpar->channels != 1) {\n\n                av_log(s, AV_LOG_ERROR, \"only mono tracks are allowed\\n\");\n\n                return -1;\n\n            }\n\n            sc->track_type = 2;\n\n            sc->sample_rate = st->codecpar->sample_rate;\n\n            avpriv_set_pts_info(st, 64, 1, sc->sample_rate);\n\n            sc->sample_size = 16;\n\n            sc->frame_rate_index = -2;\n\n            sc->lines_index = -2;\n\n            sc->fields = -2;\n\n            gxf->audio_tracks++;\n\n            gxf->flags |= 0x04000000; /* audio is 16 bit pcm */\n\n            media_info = 'A';\n\n        } else if (st->codecpar->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n            if (i != 0) {\n\n                av_log(s, AV_LOG_ERROR, \"video stream must be the first track\\n\");\n\n                return -1;\n\n            }\n\n            /* FIXME check from time_base ? */\n\n            if (st->codecpar->height == 480 || st->codecpar->height == 512) { /* NTSC or NTSC+VBI */\n\n                sc->frame_rate_index = 5;\n\n                sc->sample_rate = 60;\n\n                gxf->flags |= 0x00000080;\n\n                gxf->time_base = (AVRational){ 1001, 60000 };\n\n            } else if (st->codecpar->height == 576 || st->codecpar->height == 608) { /* PAL or PAL+VBI */\n\n                sc->frame_rate_index = 6;\n\n                sc->media_type++;\n\n                sc->sample_rate = 50;\n\n                gxf->flags |= 0x00000040;\n\n                gxf->time_base = (AVRational){ 1, 50 };\n\n            } else {\n\n                av_log(s, AV_LOG_ERROR, \"unsupported video resolution, \"\n\n                       \"gxf muxer only accepts PAL or NTSC resolutions currently\\n\");\n\n                return -1;\n\n            }\n\n            avpriv_set_pts_info(st, 64, gxf->time_base.num, gxf->time_base.den);\n\n            if (gxf_find_lines_index(st) < 0)\n\n                sc->lines_index = -1;\n\n            sc->sample_size = st->codecpar->bit_rate;\n\n            sc->fields = 2; /* interlaced */\n\n\n\n            vsc = sc;\n\n\n\n            switch (st->codecpar->codec_id) {\n\n            case AV_CODEC_ID_MJPEG:\n\n                sc->track_type = 1;\n\n                gxf->flags |= 0x00004000;\n\n                media_info = 'J';\n\n                break;\n\n            case AV_CODEC_ID_MPEG1VIDEO:\n\n                sc->track_type = 9;\n\n                gxf->mpeg_tracks++;\n\n                media_info = 'L';\n\n                break;\n\n            case AV_CODEC_ID_MPEG2VIDEO:\n\n                sc->first_gop_closed = -1;\n\n                sc->track_type = 4;\n\n                gxf->mpeg_tracks++;\n\n                gxf->flags |= 0x00008000;\n\n                media_info = 'M';\n\n                break;\n\n            case AV_CODEC_ID_DVVIDEO:\n\n                if (st->codecpar->format == AV_PIX_FMT_YUV422P) {\n\n                    sc->media_type += 2;\n\n                    sc->track_type = 6;\n\n                    gxf->flags |= 0x00002000;\n\n                    media_info = 'E';\n\n                } else {\n\n                    sc->track_type = 5;\n\n                    gxf->flags |= 0x00001000;\n\n                    media_info = 'D';\n\n                }\n\n                break;\n\n            default:\n\n                av_log(s, AV_LOG_ERROR, \"video codec not supported\\n\");\n\n                return -1;\n\n            }\n\n        }\n\n        /* FIXME first 10 audio tracks are 0 to 9 next 22 are A to V */\n\n        sc->media_info = media_info<<8 | ('0'+tracks[media_info]++);\n\n        sc->order = s->nb_streams - st->index;\n\n    }\n\n\n\n    if (ff_audio_interleave_init(s, GXF_samples_per_frame, (AVRational){ 1, 48000 }) < 0)\n\n        return -1;\n\n\n\n    gxf_init_timecode_track(&gxf->timecode_track, vsc);\n\n    gxf->flags |= 0x200000; // time code track is non-drop frame\n\n\n\n    gxf_write_map_packet(s, 0);\n\n    gxf_write_flt_packet(s);\n\n    gxf_write_umf_packet(s);\n\n\n\n    gxf->packet_count = 3;\n\n\n\n    avio_flush(pb);\n\n    return 0;\n\n}\n", "idx": 23049, "_split": "test", "_hash": "edb5bbd267f49c8a7b9ef535cd8578c6"}
{"project": "FFmpeg", "commit_id": "9a0f60a0f89a7a71839dfa9def5a26f2037aed62", "target": 0, "func": "static int mpeg4_decode_gop_header(MpegEncContext *s, GetBitContext *gb)\n\n{\n\n    int hours, minutes, seconds;\n\n\n\n    if (!show_bits(gb, 23)) {\n\n        av_log(s->avctx, AV_LOG_WARNING, \"GOP header invalid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    hours   = get_bits(gb, 5);\n\n    minutes = get_bits(gb, 6);\n\n    skip_bits1(gb);\n\n    seconds = get_bits(gb, 6);\n\n\n\n    s->time_base = seconds + 60*(minutes + 60*hours);\n\n\n\n    skip_bits1(gb);\n\n    skip_bits1(gb);\n\n\n\n    return 0;\n\n}\n", "idx": 23123, "_split": "test", "_hash": "704c9a183ab0d6366c4fe1dbac8589aa"}
{"project": "FFmpeg", "commit_id": "ddbcc48b646737c8bff7f8e28e0a69dca65509cf", "target": 0, "func": "static int ftp_restart(FTPContext *s, int64_t pos)\n\n{\n\n    char command[CONTROL_BUFFER_SIZE];\n\n    const int rest_codes[] = {350, 0};\n\n\n\n    snprintf(command, sizeof(command), \"REST %\"PRId64\"\\r\\n\", pos);\n\n    if (!ftp_send_command(s, command, rest_codes, NULL))\n\n        return AVERROR(EIO);\n\n\n\n    return 0;\n\n}\n", "idx": 23136, "_split": "test", "_hash": "b4a06962ee476ae2ce216051ce05a7b5"}
{"project": "FFmpeg", "commit_id": "bb146bb57bea6647f9c080aa4f9323a3a789ad22", "target": 0, "func": "theora_gptopts(AVFormatContext *ctx, int idx, uint64_t gp, int64_t *dts)\n\n{\n\n    struct ogg *ogg = ctx->priv_data;\n\n    struct ogg_stream *os = ogg->streams + idx;\n\n    struct theora_params *thp = os->private;\n\n    uint64_t iframe = gp >> thp->gpshift;\n\n    uint64_t pframe = gp & thp->gpmask;\n\n\n\n    if (thp->version < 0x030201)\n\n        iframe++;\n\n\n\n    if(!pframe)\n\n        os->pflags |= AV_PKT_FLAG_KEY;\n\n\n\n    if (dts)\n\n        *dts = iframe + pframe;\n\n\n\n    return iframe + pframe;\n\n}\n", "idx": 23159, "_split": "test", "_hash": "656e5790930b7da13ef511ea902b653d"}
{"project": "FFmpeg", "commit_id": "b754978a3b0aa17e7794f64c69bf4491762797fd", "target": 0, "func": "static void av_build_index_raw(AVFormatContext *s)\n\n{\n\n    AVPacket pkt1, *pkt = &pkt1;\n\n    int ret;\n\n    AVStream *st;\n\n\n\n    st = s->streams[0];\n\n    av_read_frame_flush(s);\n\n    url_fseek(&s->pb, s->data_offset, SEEK_SET);\n\n\n\n    for(;;) {\n\n        ret = av_read_frame(s, pkt);\n\n        if (ret < 0)\n\n            break;\n\n        if (pkt->stream_index == 0 && st->parser &&\n\n            (pkt->flags & PKT_FLAG_KEY)) {\n\n            add_index_entry(st, st->parser->frame_offset, pkt->dts, \n\n                            AVINDEX_KEYFRAME);\n\n        }\n\n        av_free_packet(pkt);\n\n    }\n\n}\n", "idx": 23161, "_split": "test", "_hash": "1e2e8853c8f4bc04d4828dc326ad11d7"}
{"project": "FFmpeg", "commit_id": "dbc1163b203b175d246b7454c32ac176f84006d1", "target": 0, "func": "static inline int decode_ac_coeffs(GetBitContext *gb, int16_t *out,\n\n                                   int blocks_per_slice,\n\n                                   int plane_size_factor,\n\n                                   const uint8_t *scan)\n\n{\n\n    int pos, block_mask, run, level, sign, run_cb_index, lev_cb_index;\n\n    int max_coeffs, bits_left;\n\n\n\n    /* set initial prediction values */\n\n    run   = 4;\n\n    level = 2;\n\n\n\n    max_coeffs = blocks_per_slice << 6;\n\n    block_mask = blocks_per_slice - 1;\n\n\n\n    for (pos = blocks_per_slice - 1; pos < max_coeffs;) {\n\n        run_cb_index = ff_prores_run_to_cb_index[FFMIN(run, 15)];\n\n        lev_cb_index = ff_prores_lev_to_cb_index[FFMIN(level, 9)];\n\n\n\n        bits_left = get_bits_left(gb);\n\n        if (bits_left <= 0 || (bits_left <= 8 && !show_bits(gb, bits_left)))\n\n            return 0;\n\n\n\n        run = decode_vlc_codeword(gb, ff_prores_ac_codebook[run_cb_index]);\n\n        if (run < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        bits_left = get_bits_left(gb);\n\n        if (bits_left <= 0 || (bits_left <= 8 && !show_bits(gb, bits_left)))\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        level = decode_vlc_codeword(gb, ff_prores_ac_codebook[lev_cb_index]) + 1;\n\n        if (level < 0)\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        pos += run + 1;\n\n        if (pos >= max_coeffs)\n\n            break;\n\n\n\n        sign = get_sbits(gb, 1);\n\n        out[((pos & block_mask) << 6) + scan[pos >> plane_size_factor]] =\n\n            (level ^ sign) - sign;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23184, "_split": "test", "_hash": "0ad988f1ba7a0c0e03dc0a0dea10af91"}
{"project": "FFmpeg", "commit_id": "0dbb48d91e9e97c7eb11f4ebc03c4ff4b6f5b692", "target": 1, "func": "static int mpeg_mux_init(AVFormatContext *ctx)\n\n{\n\n    MpegMuxContext *s = ctx->priv_data;\n\n    int bitrate, i, mpa_id, mpv_id, ac3_id;\n\n    AVStream *st;\n\n    StreamInfo *stream;\n\n\n\n    s->packet_number = 0;\n\n    s->is_vcd = (ctx->oformat == &mpeg1vcd_mux);\n\n    s->is_mpeg2 = (ctx->oformat == &mpeg2vob_mux);\n\n    \n\n    if (s->is_vcd)\n\n        s->packet_size = 2324; /* VCD packet size */\n\n    else\n\n        s->packet_size = 2048;\n\n        \n\n    /* startcode(4) + length(2) + flags(1) */\n\n    s->packet_data_max_size = s->packet_size - 7;\n\n    if (s->is_mpeg2)\n\n        s->packet_data_max_size -= 2;\n\n    s->audio_bound = 0;\n\n    s->video_bound = 0;\n\n    mpa_id = AUDIO_ID;\n\n    ac3_id = 0x80;\n\n    mpv_id = VIDEO_ID;\n\n    s->scr_stream_index = -1;\n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        st = ctx->streams[i];\n\n        stream = av_mallocz(sizeof(StreamInfo));\n\n        if (!stream)\n\n            goto fail;\n\n        st->priv_data = stream;\n\n\n\n        switch(st->codec.codec_type) {\n\n        case CODEC_TYPE_AUDIO:\n\n            if (st->codec.codec_id == CODEC_ID_AC3)\n\n                stream->id = ac3_id++;\n\n            else\n\n                stream->id = mpa_id++;\n\n            stream->max_buffer_size = 4 * 1024; \n\n            s->audio_bound++;\n\n            break;\n\n        case CODEC_TYPE_VIDEO:\n\n            /* by default, video is used for the SCR computation */\n\n            if (s->scr_stream_index == -1)\n\n                s->scr_stream_index = i;\n\n            stream->id = mpv_id++;\n\n            stream->max_buffer_size = 46 * 1024; \n\n            s->video_bound++;\n\n            break;\n\n        default:\n\n            av_abort();\n\n        }\n\n    }\n\n    /* if no SCR, use first stream (audio) */\n\n    if (s->scr_stream_index == -1)\n\n        s->scr_stream_index = 0;\n\n\n\n    /* we increase slightly the bitrate to take into account the\n\n       headers. XXX: compute it exactly */\n\n    bitrate = 2000;\n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        st = ctx->streams[i];\n\n        bitrate += st->codec.bit_rate;\n\n    }\n\n    s->mux_rate = (bitrate + (8 * 50) - 1) / (8 * 50);\n\n    \n\n    if (s->is_vcd || s->is_mpeg2)\n\n        /* every packet */\n\n        s->pack_header_freq = 1;\n\n    else\n\n        /* every 2 seconds */\n\n        s->pack_header_freq = 2 * bitrate / s->packet_size / 8;\n\n\n\n    /* the above seems to make pack_header_freq zero sometimes */\n\n    if (s->pack_header_freq == 0)\n\n       s->pack_header_freq = 1;\n\n    \n\n    if (s->is_mpeg2)\n\n        /* every 200 packets. Need to look at the spec.  */\n\n        s->system_header_freq = s->pack_header_freq * 40;\n\n    else if (s->is_vcd)\n\n        /* every 40 packets, this is my invention */\n\n        s->system_header_freq = s->pack_header_freq * 40;\n\n    else\n\n        s->system_header_freq = s->pack_header_freq * 5;\n\n    \n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        stream = ctx->streams[i]->priv_data;\n\n        stream->buffer_ptr = 0;\n\n        stream->packet_number = 0;\n\n        stream->start_pts = AV_NOPTS_VALUE;\n\n        stream->start_dts = AV_NOPTS_VALUE;\n\n    }\n\n    s->last_scr = 0;\n\n    return 0;\n\n fail:\n\n    for(i=0;i<ctx->nb_streams;i++) {\n\n        av_free(ctx->streams[i]->priv_data);\n\n    }\n\n    return -ENOMEM;\n\n}\n", "idx": 23193, "_split": "test", "_hash": "9078dac6ec8025f39ab84ae231d18fb9"}
{"project": "FFmpeg", "commit_id": "d7da4d47a6841444f12bf56dfe4230d3e4af8646", "target": 1, "func": "static int mxf_read_header(AVFormatContext *s)\n\n{\n\n    MXFContext *mxf = s->priv_data;\n\n    KLVPacket klv;\n\n    int64_t essence_offset = 0;\n\n    int ret;\n\n\n\n    mxf->last_forward_tell = INT64_MAX;\n\n    mxf->edit_units_per_packet = 1;\n\n\n\n    if (!mxf_read_sync(s->pb, mxf_header_partition_pack_key, 14)) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find header partition pack key\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, -14, SEEK_CUR);\n\n    mxf->fc = s;\n\n    mxf->run_in = avio_tell(s->pb);\n\n\n\n    while (!url_feof(s->pb)) {\n\n        const MXFMetadataReadTableEntry *metadata;\n\n\n\n        if (klv_read_packet(&klv, s->pb) < 0) {\n\n            /* EOF - seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else\n\n                continue;\n\n        }\n\n\n\n        PRINT_KEY(s, \"read header\", klv.key);\n\n        av_dlog(s, \"size %\"PRIu64\" offset %#\"PRIx64\"\\n\", klv.length, klv.offset);\n\n        if (IS_KLV_KEY(klv.key, mxf_encrypted_triplet_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_avid_essence_element_key) ||\n\n            IS_KLV_KEY(klv.key, mxf_system_item_key)) {\n\n\n\n            if (!mxf->current_partition) {\n\n                av_log(mxf->fc, AV_LOG_ERROR, \"found essence prior to first PartitionPack\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n\n\n            if (!mxf->current_partition->essence_offset) {\n\n                /* for OP1a we compute essence_offset\n\n                 * for OPAtom we point essence_offset after the KL (usually op1a_essence_offset + 20 or 25)\n\n                 * TODO: for OP1a we could eliminate this entire if statement, always stopping parsing at op1a_essence_offset\n\n                 *       for OPAtom we still need the actual essence_offset though (the KL's length can vary)\n\n                 */\n\n                int64_t op1a_essence_offset =\n\n                    round_to_kag(mxf->current_partition->this_partition +\n\n                                 mxf->current_partition->pack_length,       mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->header_byte_count, mxf->current_partition->kag_size) +\n\n                    round_to_kag(mxf->current_partition->index_byte_count,  mxf->current_partition->kag_size);\n\n\n\n                if (mxf->op == OPAtom) {\n\n                    /* point essence_offset to the actual data\n\n                    * OPAtom has all the essence in one big KLV\n\n                    */\n\n                    mxf->current_partition->essence_offset = avio_tell(s->pb);\n\n                    mxf->current_partition->essence_length = klv.length;\n\n                } else {\n\n                    /* NOTE: op1a_essence_offset may be less than to klv.offset (C0023S01.mxf)  */\n\n                    mxf->current_partition->essence_offset = op1a_essence_offset;\n\n                }\n\n            }\n\n\n\n            if (!essence_offset)\n\n                essence_offset = klv.offset;\n\n\n\n            /* seek to footer, previous partition or stop */\n\n            if (mxf_parse_handle_essence(mxf) <= 0)\n\n                break;\n\n            continue;\n\n        } else if (!memcmp(klv.key, mxf_header_partition_pack_key, 13) &&\n\n                   klv.key[13] >= 2 && klv.key[13] <= 4 && mxf->current_partition) {\n\n            /* next partition pack - keep going, seek to previous partition or stop */\n\n            if(mxf_parse_handle_partition_or_eof(mxf) <= 0)\n\n                break;\n\n            else if (mxf->parsing_backward)\n\n                continue;\n\n            /* we're still parsing forward. proceed to parsing this partition pack */\n\n        }\n\n\n\n        for (metadata = mxf_metadata_read_table; metadata->read; metadata++) {\n\n            if (IS_KLV_KEY(klv.key, metadata->key)) {\n\n                int res;\n\n                if (klv.key[5] == 0x53) {\n\n                    res = mxf_read_local_tags(mxf, &klv, metadata->read, metadata->ctx_size, metadata->type);\n\n                } else {\n\n                    uint64_t next = avio_tell(s->pb) + klv.length;\n\n                    res = metadata->read(mxf, s->pb, 0, klv.length, klv.key, klv.offset);\n\n\n\n                    /* only seek forward, else this can loop for a long time */\n\n                    if (avio_tell(s->pb) > next) {\n\n                        av_log(s, AV_LOG_ERROR, \"read past end of KLV @ %#\"PRIx64\"\\n\",\n\n                               klv.offset);\n\n                        return AVERROR_INVALIDDATA;\n\n                    }\n\n\n\n                    avio_seek(s->pb, next, SEEK_SET);\n\n                }\n\n                if (res < 0) {\n\n                    av_log(s, AV_LOG_ERROR, \"error reading header metadata\\n\");\n\n                    return res;\n\n                }\n\n                break;\n\n            }\n\n        }\n\n        if (!metadata->read)\n\n            avio_skip(s->pb, klv.length);\n\n    }\n\n    /* FIXME avoid seek */\n\n    if (!essence_offset)  {\n\n        av_log(s, AV_LOG_ERROR, \"no essence\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    avio_seek(s->pb, essence_offset, SEEK_SET);\n\n\n\n    mxf_compute_essence_containers(mxf);\n\n\n\n    /* we need to do this before computing the index tables\n\n     * to be able to fill in zero IndexDurations with st->duration */\n\n    if ((ret = mxf_parse_structural_metadata(mxf)) < 0)\n\n        return ret;\n\n\n\n    if ((ret = mxf_compute_index_tables(mxf)) < 0)\n\n        return ret;\n\n\n\n    if (mxf->nb_index_tables > 1) {\n\n        /* TODO: look up which IndexSID to use via EssenceContainerData */\n\n        av_log(mxf->fc, AV_LOG_INFO, \"got %i index tables - only the first one (IndexSID %i) will be used\\n\",\n\n               mxf->nb_index_tables, mxf->index_tables[0].index_sid);\n\n    } else if (mxf->nb_index_tables == 0 && mxf->op == OPAtom) {\n\n        av_log(mxf->fc, AV_LOG_ERROR, \"cannot demux OPAtom without an index\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    mxf_handle_small_eubc(s);\n\n\n\n    return 0;\n\n}\n", "idx": 23206, "_split": "test", "_hash": "6c0c0caaa288e7768433020e1504ed3a"}
{"project": "FFmpeg", "commit_id": "d1adad3cca407f493c3637e20ecd4f7124e69212", "target": 0, "func": "static inline void RENAME(yuv422ptoyuy2)(const uint8_t *ysrc, const uint8_t *usrc, const uint8_t *vsrc, uint8_t *dst,\n\n                                         long width, long height,\n\n                                         long lumStride, long chromStride, long dstStride)\n\n{\n\n    RENAME(yuvPlanartoyuy2)(ysrc, usrc, vsrc, dst, width, height, lumStride, chromStride, dstStride, 1);\n\n}\n", "idx": 23250, "_split": "test", "_hash": "32101130a31fe2f831c98e9406a716f9"}
{"project": "FFmpeg", "commit_id": "b7d9b4a1f1fcd01084ccbec6f7ef32c853681833", "target": 1, "func": "int ff_h263_decode_mb(MpegEncContext *s,\n                      int16_t block[6][64])\n{\n    int cbpc, cbpy, i, cbp, pred_x, pred_y, mx, my, dquant;\n    int16_t *mot_val;\n    const int xy= s->mb_x + s->mb_y * s->mb_stride;\n    int cbpb = 0, pb_mv_count = 0;\n    av_assert2(!s->h263_pred);\n    if (s->pict_type == AV_PICTURE_TYPE_P) {\n        do{\n            if (get_bits1(&s->gb)) {\n                /* skip mb */\n                s->mb_intra = 0;\n                for(i=0;i<6;i++)\n                    s->block_last_index[i] = -1;\n                s->mv_dir = MV_DIR_FORWARD;\n                s->mv_type = MV_TYPE_16X16;\n                s->current_picture.mb_type[xy] = MB_TYPE_SKIP | MB_TYPE_16x16 | MB_TYPE_L0;\n                s->mv[0][0][0] = 0;\n                s->mv[0][0][1] = 0;\n                s->mb_skipped = !(s->obmc | s->loop_filter);\n                goto end;\n            cbpc = get_vlc2(&s->gb, ff_h263_inter_MCBPC_vlc.table, INTER_MCBPC_VLC_BITS, 2);\n            if (cbpc < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"cbpc damaged at %d %d\\n\", s->mb_x, s->mb_y);\n        }while(cbpc == 20);\n        s->bdsp.clear_blocks(s->block[0]);\n        dquant = cbpc & 8;\n        s->mb_intra = ((cbpc & 4) != 0);\n        if (s->mb_intra) goto intra;\n        if(s->pb_frame && get_bits1(&s->gb))\n            pb_mv_count = h263_get_modb(&s->gb, s->pb_frame, &cbpb);\n        cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1);\n        if(s->alt_inter_vlc==0 || (cbpc & 3)!=3)\n            cbpy ^= 0xF;\n        cbp = (cbpc & 3) | (cbpy << 2);\n        if (dquant) {\n            h263_decode_dquant(s);\n        s->mv_dir = MV_DIR_FORWARD;\n        if ((cbpc & 16) == 0) {\n            s->current_picture.mb_type[xy] = MB_TYPE_16x16 | MB_TYPE_L0;\n            /* 16x16 motion prediction */\n            s->mv_type = MV_TYPE_16X16;\n            ff_h263_pred_motion(s, 0, 0, &pred_x, &pred_y);\n            if (s->umvplus)\n               mx = h263p_decode_umotion(s, pred_x);\n            else\n               mx = ff_h263_decode_motion(s, pred_x, 1);\n            if (mx >= 0xffff)\n            if (s->umvplus)\n               my = h263p_decode_umotion(s, pred_y);\n            else\n               my = ff_h263_decode_motion(s, pred_y, 1);\n            if (my >= 0xffff)\n            s->mv[0][0][0] = mx;\n            s->mv[0][0][1] = my;\n            if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n               skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n        } else {\n            s->current_picture.mb_type[xy] = MB_TYPE_8x8 | MB_TYPE_L0;\n            s->mv_type = MV_TYPE_8X8;\n            for(i=0;i<4;i++) {\n                mot_val = ff_h263_pred_motion(s, i, 0, &pred_x, &pred_y);\n                if (s->umvplus)\n                    mx = h263p_decode_umotion(s, pred_x);\n                else\n                    mx = ff_h263_decode_motion(s, pred_x, 1);\n                if (mx >= 0xffff)\n                if (s->umvplus)\n                    my = h263p_decode_umotion(s, pred_y);\n                else\n                    my = ff_h263_decode_motion(s, pred_y, 1);\n                if (my >= 0xffff)\n                s->mv[0][i][0] = mx;\n                s->mv[0][i][1] = my;\n                if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n                  skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n                mot_val[0] = mx;\n                mot_val[1] = my;\n    } else if(s->pict_type==AV_PICTURE_TYPE_B) {\n        int mb_type;\n        const int stride= s->b8_stride;\n        int16_t *mot_val0 = s->current_picture.motion_val[0][2 * (s->mb_x + s->mb_y * stride)];\n        int16_t *mot_val1 = s->current_picture.motion_val[1][2 * (s->mb_x + s->mb_y * stride)];\n//        const int mv_xy= s->mb_x + 1 + s->mb_y * s->mb_stride;\n        //FIXME ugly\n        mot_val0[0       ]= mot_val0[2       ]= mot_val0[0+2*stride]= mot_val0[2+2*stride]=\n        mot_val0[1       ]= mot_val0[3       ]= mot_val0[1+2*stride]= mot_val0[3+2*stride]=\n        mot_val1[0       ]= mot_val1[2       ]= mot_val1[0+2*stride]= mot_val1[2+2*stride]=\n        mot_val1[1       ]= mot_val1[3       ]= mot_val1[1+2*stride]= mot_val1[3+2*stride]= 0;\n        do{\n            mb_type= get_vlc2(&s->gb, h263_mbtype_b_vlc.table, H263_MBTYPE_B_VLC_BITS, 2);\n            if (mb_type < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"b mb_type damaged at %d %d\\n\", s->mb_x, s->mb_y);\n            mb_type= h263_mb_type_b_map[ mb_type ];\n        }while(!mb_type);\n        s->mb_intra = IS_INTRA(mb_type);\n        if(HAS_CBP(mb_type)){\n            s->bdsp.clear_blocks(s->block[0]);\n            cbpc = get_vlc2(&s->gb, cbpc_b_vlc.table, CBPC_B_VLC_BITS, 1);\n            if(s->mb_intra){\n                dquant = IS_QUANT(mb_type);\n                goto intra;\n            cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1);\n            if (cbpy < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"b cbpy damaged at %d %d\\n\", s->mb_x, s->mb_y);\n            if(s->alt_inter_vlc==0 || (cbpc & 3)!=3)\n                cbpy ^= 0xF;\n            cbp = (cbpc & 3) | (cbpy << 2);\n        }else\n            cbp=0;\n        av_assert2(!s->mb_intra);\n        if(IS_QUANT(mb_type)){\n            h263_decode_dquant(s);\n        if(IS_DIRECT(mb_type)){\n            s->mv_dir = MV_DIR_FORWARD | MV_DIR_BACKWARD | MV_DIRECT;\n            mb_type |= set_direct_mv(s);\n        }else{\n            s->mv_dir = 0;\n            s->mv_type= MV_TYPE_16X16;\n//FIXME UMV\n            if(USES_LIST(mb_type, 0)){\n                int16_t *mot_val= ff_h263_pred_motion(s, 0, 0, &pred_x, &pred_y);\n                s->mv_dir = MV_DIR_FORWARD;\n                if (s->umvplus)\n                    mx = h263p_decode_umotion(s, pred_x);\n                else\n                    mx = ff_h263_decode_motion(s, pred_x, 1);\n                if (mx >= 0xffff)\n                if (s->umvplus)\n                    my = h263p_decode_umotion(s, pred_y);\n                else\n                    my = ff_h263_decode_motion(s, pred_y, 1);\n                if (my >= 0xffff)\n                if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n                    skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n                s->mv[0][0][0] = mx;\n                s->mv[0][0][1] = my;\n                mot_val[0       ]= mot_val[2       ]= mot_val[0+2*stride]= mot_val[2+2*stride]= mx;\n                mot_val[1       ]= mot_val[3       ]= mot_val[1+2*stride]= mot_val[3+2*stride]= my;\n            if(USES_LIST(mb_type, 1)){\n                int16_t *mot_val= ff_h263_pred_motion(s, 0, 1, &pred_x, &pred_y);\n                s->mv_dir |= MV_DIR_BACKWARD;\n                if (s->umvplus)\n                    mx = h263p_decode_umotion(s, pred_x);\n                else\n                    mx = ff_h263_decode_motion(s, pred_x, 1);\n                if (mx >= 0xffff)\n                if (s->umvplus)\n                    my = h263p_decode_umotion(s, pred_y);\n                else\n                    my = ff_h263_decode_motion(s, pred_y, 1);\n                if (my >= 0xffff)\n                if (s->umvplus && (mx - pred_x) == 1 && (my - pred_y) == 1)\n                    skip_bits1(&s->gb); /* Bit stuffing to prevent PSC */\n                s->mv[1][0][0] = mx;\n                s->mv[1][0][1] = my;\n                mot_val[0       ]= mot_val[2       ]= mot_val[0+2*stride]= mot_val[2+2*stride]= mx;\n                mot_val[1       ]= mot_val[3       ]= mot_val[1+2*stride]= mot_val[3+2*stride]= my;\n        s->current_picture.mb_type[xy] = mb_type;\n    } else { /* I-Frame */\n        do{\n            cbpc = get_vlc2(&s->gb, ff_h263_intra_MCBPC_vlc.table, INTRA_MCBPC_VLC_BITS, 2);\n            if (cbpc < 0){\n                av_log(s->avctx, AV_LOG_ERROR, \"I cbpc damaged at %d %d\\n\", s->mb_x, s->mb_y);\n        }while(cbpc == 8);\n        s->bdsp.clear_blocks(s->block[0]);\n        dquant = cbpc & 4;\n        s->mb_intra = 1;\nintra:\n        s->current_picture.mb_type[xy] = MB_TYPE_INTRA;\n        if (s->h263_aic) {\n            s->ac_pred = get_bits1(&s->gb);\n            if(s->ac_pred){\n                s->current_picture.mb_type[xy] = MB_TYPE_INTRA | MB_TYPE_ACPRED;\n                s->h263_aic_dir = get_bits1(&s->gb);\n        }else\n            s->ac_pred = 0;\n        if(s->pb_frame && get_bits1(&s->gb))\n            pb_mv_count = h263_get_modb(&s->gb, s->pb_frame, &cbpb);\n        cbpy = get_vlc2(&s->gb, ff_h263_cbpy_vlc.table, CBPY_VLC_BITS, 1);\n        if(cbpy<0){\n            av_log(s->avctx, AV_LOG_ERROR, \"I cbpy damaged at %d %d\\n\", s->mb_x, s->mb_y);\n        cbp = (cbpc & 3) | (cbpy << 2);\n        if (dquant) {\n            h263_decode_dquant(s);\n        pb_mv_count += !!s->pb_frame;\n    while(pb_mv_count--){\n        ff_h263_decode_motion(s, 0, 1);\n        ff_h263_decode_motion(s, 0, 1);\n    /* decode each block */\n    for (i = 0; i < 6; i++) {\n        if (h263_decode_block(s, block[i], i, cbp&32) < 0)\n            return -1;\n        cbp+=cbp;\n    if(s->pb_frame && h263_skip_b_part(s, cbpb) < 0)\n        return -1;\n    if(s->obmc && !s->mb_intra){\n        if(s->pict_type == AV_PICTURE_TYPE_P && s->mb_x+1<s->mb_width && s->mb_num_left != 1)\n            preview_obmc(s);\nend:\n        /* per-MB end of slice check */\n    {\n        int v= show_bits(&s->gb, 16);\n        if (get_bits_left(&s->gb) < 16) {\n            v >>= 16 - get_bits_left(&s->gb);\n        if(v==0)\n            return SLICE_END;\n    return SLICE_OK;", "idx": 23256, "_split": "test", "_hash": "79d163e2254ba939eaefa175bc9e02d9"}
{"project": "FFmpeg", "commit_id": "92fabca427ff2d8fffa4bd4f09839d8d3822ef31", "target": 0, "func": "static void DEF(put, pixels16_x2)(uint8_t *block, const uint8_t *pixels, ptrdiff_t line_size, int h)\n\n{\n\n    MOVQ_BFE(mm6);\n\n    __asm__ volatile(\n\n        \"lea        (%3, %3), %%\"REG_a\" \\n\\t\"\n\n        \".p2align 3                     \\n\\t\"\n\n        \"1:                             \\n\\t\"\n\n        \"movq   (%1), %%mm0             \\n\\t\"\n\n        \"movq   1(%1), %%mm1            \\n\\t\"\n\n        \"movq   (%1, %3), %%mm2         \\n\\t\"\n\n        \"movq   1(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, (%2)             \\n\\t\"\n\n        \"movq   %%mm5, (%2, %3)         \\n\\t\"\n\n        \"movq   8(%1), %%mm0            \\n\\t\"\n\n        \"movq   9(%1), %%mm1            \\n\\t\"\n\n        \"movq   8(%1, %3), %%mm2        \\n\\t\"\n\n        \"movq   9(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, 8(%2)            \\n\\t\"\n\n        \"movq   %%mm5, 8(%2, %3)        \\n\\t\"\n\n        \"add    %%\"REG_a\", %1           \\n\\t\"\n\n        \"add    %%\"REG_a\", %2           \\n\\t\"\n\n        \"movq   (%1), %%mm0             \\n\\t\"\n\n        \"movq   1(%1), %%mm1            \\n\\t\"\n\n        \"movq   (%1, %3), %%mm2         \\n\\t\"\n\n        \"movq   1(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, (%2)             \\n\\t\"\n\n        \"movq   %%mm5, (%2, %3)         \\n\\t\"\n\n        \"movq   8(%1), %%mm0            \\n\\t\"\n\n        \"movq   9(%1), %%mm1            \\n\\t\"\n\n        \"movq   8(%1, %3), %%mm2        \\n\\t\"\n\n        \"movq   9(%1, %3), %%mm3        \\n\\t\"\n\n        PAVGBP(%%mm0, %%mm1, %%mm4,   %%mm2, %%mm3, %%mm5)\n\n        \"movq   %%mm4, 8(%2)            \\n\\t\"\n\n        \"movq   %%mm5, 8(%2, %3)        \\n\\t\"\n\n        \"add    %%\"REG_a\", %1           \\n\\t\"\n\n        \"add    %%\"REG_a\", %2           \\n\\t\"\n\n        \"subl   $4, %0                  \\n\\t\"\n\n        \"jnz    1b                      \\n\\t\"\n\n        :\"+g\"(h), \"+S\"(pixels), \"+D\"(block)\n\n        :\"r\"((x86_reg)line_size)\n\n        :REG_a, \"memory\");\n\n}\n", "idx": 23259, "_split": "test", "_hash": "effae03c5b6e6035493d3f78b030b05f"}
{"project": "FFmpeg", "commit_id": "042ef4b720f5d3321d9b7eeeb2067c671d5aeefd", "target": 1, "func": "static int decode_mb_cavlc(H264Context *h){\n\n    MpegEncContext * const s = &h->s;\n\n    const int mb_xy= s->mb_x + s->mb_y*s->mb_stride;\n\n    int partition_count;\n\n    unsigned int mb_type, cbp;\n\n    int dct8x8_allowed= h->pps.transform_8x8_mode;\n\n\n\n    s->dsp.clear_blocks(h->mb); //FIXME avoid if already clear (move after skip handlong?\n\n\n\n    tprintf(s->avctx, \"pic:%d mb:%d/%d\\n\", h->frame_num, s->mb_x, s->mb_y);\n\n    cbp = 0; /* avoid warning. FIXME: find a solution without slowing\n\n                down the code */\n\n    if(h->slice_type != I_TYPE && h->slice_type != SI_TYPE){\n\n        if(s->mb_skip_run==-1)\n\n            s->mb_skip_run= get_ue_golomb(&s->gb);\n\n\n\n        if (s->mb_skip_run--) {\n\n            if(FRAME_MBAFF && (s->mb_y&1) == 0){\n\n                if(s->mb_skip_run==0)\n\n                    h->mb_mbaff = h->mb_field_decoding_flag = get_bits1(&s->gb);\n\n                else\n\n                    predict_field_decoding_flag(h);\n\n            }\n\n            decode_mb_skip(h);\n\n            return 0;\n\n        }\n\n    }\n\n    if(FRAME_MBAFF){\n\n        if( (s->mb_y&1) == 0 )\n\n            h->mb_mbaff = h->mb_field_decoding_flag = get_bits1(&s->gb);\n\n    }else\n\n        h->mb_field_decoding_flag= (s->picture_structure!=PICT_FRAME);\n\n\n\n    h->prev_mb_skipped= 0;\n\n\n\n    mb_type= get_ue_golomb(&s->gb);\n\n    if(h->slice_type == B_TYPE){\n\n        if(mb_type < 23){\n\n            partition_count= b_mb_type_info[mb_type].partition_count;\n\n            mb_type=         b_mb_type_info[mb_type].type;\n\n        }else{\n\n            mb_type -= 23;\n\n            goto decode_intra_mb;\n\n        }\n\n    }else if(h->slice_type == P_TYPE /*|| h->slice_type == SP_TYPE */){\n\n        if(mb_type < 5){\n\n            partition_count= p_mb_type_info[mb_type].partition_count;\n\n            mb_type=         p_mb_type_info[mb_type].type;\n\n        }else{\n\n            mb_type -= 5;\n\n            goto decode_intra_mb;\n\n        }\n\n    }else{\n\n       assert(h->slice_type == I_TYPE);\n\ndecode_intra_mb:\n\n        if(mb_type > 25){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"mb_type %d in %c slice too large at %d %d\\n\", mb_type, av_get_pict_type_char(h->slice_type), s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n        partition_count=0;\n\n        cbp= i_mb_type_info[mb_type].cbp;\n\n        h->intra16x16_pred_mode= i_mb_type_info[mb_type].pred_mode;\n\n        mb_type= i_mb_type_info[mb_type].type;\n\n    }\n\n\n\n    if(MB_FIELD)\n\n        mb_type |= MB_TYPE_INTERLACED;\n\n\n\n    h->slice_table[ mb_xy ]= h->slice_num;\n\n\n\n    if(IS_INTRA_PCM(mb_type)){\n\n        unsigned int x, y;\n\n\n\n        // We assume these blocks are very rare so we do not optimize it.\n\n        align_get_bits(&s->gb);\n\n\n\n        // The pixels are stored in the same order as levels in h->mb array.\n\n        for(y=0; y<16; y++){\n\n            const int index= 4*(y&3) + 32*((y>>2)&1) + 128*(y>>3);\n\n            for(x=0; x<16; x++){\n\n                tprintf(s->avctx, \"LUMA ICPM LEVEL (%3d)\\n\", show_bits(&s->gb, 8));\n\n                h->mb[index + (x&3) + 16*((x>>2)&1) + 64*(x>>3)]= get_bits(&s->gb, 8);\n\n            }\n\n        }\n\n        for(y=0; y<8; y++){\n\n            const int index= 256 + 4*(y&3) + 32*(y>>2);\n\n            for(x=0; x<8; x++){\n\n                tprintf(s->avctx, \"CHROMA U ICPM LEVEL (%3d)\\n\", show_bits(&s->gb, 8));\n\n                h->mb[index + (x&3) + 16*(x>>2)]= get_bits(&s->gb, 8);\n\n            }\n\n        }\n\n        for(y=0; y<8; y++){\n\n            const int index= 256 + 64 + 4*(y&3) + 32*(y>>2);\n\n            for(x=0; x<8; x++){\n\n                tprintf(s->avctx, \"CHROMA V ICPM LEVEL (%3d)\\n\", show_bits(&s->gb, 8));\n\n                h->mb[index + (x&3) + 16*(x>>2)]= get_bits(&s->gb, 8);\n\n            }\n\n        }\n\n\n\n        // In deblocking, the quantizer is 0\n\n        s->current_picture.qscale_table[mb_xy]= 0;\n\n        h->chroma_qp = get_chroma_qp(h->pps.chroma_qp_index_offset, 0);\n\n        // All coeffs are present\n\n        memset(h->non_zero_count[mb_xy], 16, 16);\n\n\n\n        s->current_picture.mb_type[mb_xy]= mb_type;\n\n        return 0;\n\n    }\n\n\n\n    if(MB_MBAFF){\n\n        h->ref_count[0] <<= 1;\n\n        h->ref_count[1] <<= 1;\n\n    }\n\n\n\n    fill_caches(h, mb_type, 0);\n\n\n\n    //mb_pred\n\n    if(IS_INTRA(mb_type)){\n\n            int pred_mode;\n\n//            init_top_left_availability(h);\n\n            if(IS_INTRA4x4(mb_type)){\n\n                int i;\n\n                int di = 1;\n\n                if(dct8x8_allowed && get_bits1(&s->gb)){\n\n                    mb_type |= MB_TYPE_8x8DCT;\n\n                    di = 4;\n\n                }\n\n\n\n//                fill_intra4x4_pred_table(h);\n\n                for(i=0; i<16; i+=di){\n\n                    int mode= pred_intra_mode(h, i);\n\n\n\n                    if(!get_bits1(&s->gb)){\n\n                        const int rem_mode= get_bits(&s->gb, 3);\n\n                        mode = rem_mode + (rem_mode >= mode);\n\n                    }\n\n\n\n                    if(di==4)\n\n                        fill_rectangle( &h->intra4x4_pred_mode_cache[ scan8[i] ], 2, 2, 8, mode, 1 );\n\n                    else\n\n                        h->intra4x4_pred_mode_cache[ scan8[i] ] = mode;\n\n                }\n\n                write_back_intra_pred_mode(h);\n\n                if( check_intra4x4_pred_mode(h) < 0)\n\n                    return -1;\n\n            }else{\n\n                h->intra16x16_pred_mode= check_intra_pred_mode(h, h->intra16x16_pred_mode);\n\n                if(h->intra16x16_pred_mode < 0)\n\n                    return -1;\n\n            }\n\n\n\n            pred_mode= check_intra_pred_mode(h, get_ue_golomb(&s->gb));\n\n            if(pred_mode < 0)\n\n                return -1;\n\n            h->chroma_pred_mode= pred_mode;\n\n    }else if(partition_count==4){\n\n        int i, j, sub_partition_count[4], list, ref[2][4];\n\n\n\n        if(h->slice_type == B_TYPE){\n\n            for(i=0; i<4; i++){\n\n                h->sub_mb_type[i]= get_ue_golomb(&s->gb);\n\n                if(h->sub_mb_type[i] >=13){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"B sub_mb_type %u out of range at %d %d\\n\", h->sub_mb_type[i], s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                sub_partition_count[i]= b_sub_mb_type_info[ h->sub_mb_type[i] ].partition_count;\n\n                h->sub_mb_type[i]=      b_sub_mb_type_info[ h->sub_mb_type[i] ].type;\n\n            }\n\n            if(   IS_DIRECT(h->sub_mb_type[0]) || IS_DIRECT(h->sub_mb_type[1])\n\n               || IS_DIRECT(h->sub_mb_type[2]) || IS_DIRECT(h->sub_mb_type[3])) {\n\n                pred_direct_motion(h, &mb_type);\n\n                h->ref_cache[0][scan8[4]] =\n\n                h->ref_cache[1][scan8[4]] =\n\n                h->ref_cache[0][scan8[12]] =\n\n                h->ref_cache[1][scan8[12]] = PART_NOT_AVAILABLE;\n\n            }\n\n        }else{\n\n            assert(h->slice_type == P_TYPE || h->slice_type == SP_TYPE); //FIXME SP correct ?\n\n            for(i=0; i<4; i++){\n\n                h->sub_mb_type[i]= get_ue_golomb(&s->gb);\n\n                if(h->sub_mb_type[i] >=4){\n\n                    av_log(h->s.avctx, AV_LOG_ERROR, \"P sub_mb_type %u out of range at %d %d\\n\", h->sub_mb_type[i], s->mb_x, s->mb_y);\n\n                    return -1;\n\n                }\n\n                sub_partition_count[i]= p_sub_mb_type_info[ h->sub_mb_type[i] ].partition_count;\n\n                h->sub_mb_type[i]=      p_sub_mb_type_info[ h->sub_mb_type[i] ].type;\n\n            }\n\n        }\n\n\n\n        for(list=0; list<h->list_count; list++){\n\n            int ref_count= IS_REF0(mb_type) ? 1 : h->ref_count[list];\n\n            for(i=0; i<4; i++){\n\n                if(IS_DIRECT(h->sub_mb_type[i])) continue;\n\n                if(IS_DIR(h->sub_mb_type[i], 0, list)){\n\n                    unsigned int tmp = get_te0_golomb(&s->gb, ref_count); //FIXME init to 0 before and skip?\n\n                    if(tmp>=ref_count){\n\n                        av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", tmp);\n\n                        return -1;\n\n                    }\n\n                    ref[list][i]= tmp;\n\n                }else{\n\n                 //FIXME\n\n                    ref[list][i] = -1;\n\n                }\n\n            }\n\n        }\n\n\n\n        if(dct8x8_allowed)\n\n            dct8x8_allowed = get_dct8x8_allowed(h);\n\n\n\n        for(list=0; list<h->list_count; list++){\n\n            for(i=0; i<4; i++){\n\n                if(IS_DIRECT(h->sub_mb_type[i])) {\n\n                    h->ref_cache[list][ scan8[4*i] ] = h->ref_cache[list][ scan8[4*i]+1 ];\n\n                    continue;\n\n                }\n\n                h->ref_cache[list][ scan8[4*i]   ]=h->ref_cache[list][ scan8[4*i]+1 ]=\n\n                h->ref_cache[list][ scan8[4*i]+8 ]=h->ref_cache[list][ scan8[4*i]+9 ]= ref[list][i];\n\n\n\n                if(IS_DIR(h->sub_mb_type[i], 0, list)){\n\n                    const int sub_mb_type= h->sub_mb_type[i];\n\n                    const int block_width= (sub_mb_type & (MB_TYPE_16x16|MB_TYPE_16x8)) ? 2 : 1;\n\n                    for(j=0; j<sub_partition_count[i]; j++){\n\n                        int mx, my;\n\n                        const int index= 4*i + block_width*j;\n\n                        int16_t (* mv_cache)[2]= &h->mv_cache[list][ scan8[index] ];\n\n                        pred_motion(h, index, block_width, list, h->ref_cache[list][ scan8[index] ], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        if(IS_SUB_8X8(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]=\n\n                            mv_cache[ 8 ][0]= mv_cache[ 9 ][0]= mx;\n\n                            mv_cache[ 1 ][1]=\n\n                            mv_cache[ 8 ][1]= mv_cache[ 9 ][1]= my;\n\n                        }else if(IS_SUB_8X4(sub_mb_type)){\n\n                            mv_cache[ 1 ][0]= mx;\n\n                            mv_cache[ 1 ][1]= my;\n\n                        }else if(IS_SUB_4X8(sub_mb_type)){\n\n                            mv_cache[ 8 ][0]= mx;\n\n                            mv_cache[ 8 ][1]= my;\n\n                        }\n\n                        mv_cache[ 0 ][0]= mx;\n\n                        mv_cache[ 0 ][1]= my;\n\n                    }\n\n                }else{\n\n                    uint32_t *p= (uint32_t *)&h->mv_cache[list][ scan8[4*i] ][0];\n\n                    p[0] = p[1]=\n\n                    p[8] = p[9]= 0;\n\n                }\n\n            }\n\n        }\n\n    }else if(IS_DIRECT(mb_type)){\n\n        pred_direct_motion(h, &mb_type);\n\n        dct8x8_allowed &= h->sps.direct_8x8_inference_flag;\n\n    }else{\n\n        int list, mx, my, i;\n\n         //FIXME we should set ref_idx_l? to 0 if we use that later ...\n\n        if(IS_16X16(mb_type)){\n\n            for(list=0; list<h->list_count; list++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, 0, list)){\n\n                        val= get_te0_golomb(&s->gb, h->ref_count[list]);\n\n                        if(val >= h->ref_count[list]){\n\n                            av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                            return -1;\n\n                        }\n\n                    }else\n\n                        val= LIST_NOT_USED&0xFF;\n\n                    fill_rectangle(&h->ref_cache[list][ scan8[0] ], 4, 4, 8, val, 1);\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                unsigned int val;\n\n                if(IS_DIR(mb_type, 0, list)){\n\n                    pred_motion(h, 0, 4, list, h->ref_cache[list][ scan8[0] ], &mx, &my);\n\n                    mx += get_se_golomb(&s->gb);\n\n                    my += get_se_golomb(&s->gb);\n\n                    tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                    val= pack16to32(mx,my);\n\n                }else\n\n                    val=0;\n\n                fill_rectangle(h->mv_cache[list][ scan8[0] ], 4, 4, 8, val, 4);\n\n            }\n\n        }\n\n        else if(IS_16X8(mb_type)){\n\n            for(list=0; list<h->list_count; list++){\n\n                    for(i=0; i<2; i++){\n\n                        unsigned int val;\n\n                        if(IS_DIR(mb_type, i, list)){\n\n                            val= get_te0_golomb(&s->gb, h->ref_count[list]);\n\n                            if(val >= h->ref_count[list]){\n\n                                av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            val= LIST_NOT_USED&0xFF;\n\n                        fill_rectangle(&h->ref_cache[list][ scan8[0] + 16*i ], 4, 2, 8, val, 1);\n\n                    }\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                for(i=0; i<2; i++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        pred_16x8_motion(h, 8*i, list, h->ref_cache[list][scan8[0] + 16*i], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        val= pack16to32(mx,my);\n\n                    }else\n\n                        val=0;\n\n                    fill_rectangle(h->mv_cache[list][ scan8[0] + 16*i ], 4, 2, 8, val, 4);\n\n                }\n\n            }\n\n        }else{\n\n            assert(IS_8X16(mb_type));\n\n            for(list=0; list<h->list_count; list++){\n\n                    for(i=0; i<2; i++){\n\n                        unsigned int val;\n\n                        if(IS_DIR(mb_type, i, list)){ //FIXME optimize\n\n                            val= get_te0_golomb(&s->gb, h->ref_count[list]);\n\n                            if(val >= h->ref_count[list]){\n\n                                av_log(h->s.avctx, AV_LOG_ERROR, \"ref %u overflow\\n\", val);\n\n                                return -1;\n\n                            }\n\n                        }else\n\n                            val= LIST_NOT_USED&0xFF;\n\n                        fill_rectangle(&h->ref_cache[list][ scan8[0] + 2*i ], 2, 4, 8, val, 1);\n\n                    }\n\n            }\n\n            for(list=0; list<h->list_count; list++){\n\n                for(i=0; i<2; i++){\n\n                    unsigned int val;\n\n                    if(IS_DIR(mb_type, i, list)){\n\n                        pred_8x16_motion(h, i*4, list, h->ref_cache[list][ scan8[0] + 2*i ], &mx, &my);\n\n                        mx += get_se_golomb(&s->gb);\n\n                        my += get_se_golomb(&s->gb);\n\n                        tprintf(s->avctx, \"final mv:%d %d\\n\", mx, my);\n\n\n\n                        val= pack16to32(mx,my);\n\n                    }else\n\n                        val=0;\n\n                    fill_rectangle(h->mv_cache[list][ scan8[0] + 2*i ], 2, 4, 8, val, 4);\n\n                }\n\n            }\n\n        }\n\n    }\n\n\n\n    if(IS_INTER(mb_type))\n\n        write_back_motion(h, mb_type);\n\n\n\n    if(!IS_INTRA16x16(mb_type)){\n\n        cbp= get_ue_golomb(&s->gb);\n\n        if(cbp > 47){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"cbp too large (%u) at %d %d\\n\", cbp, s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n\n\n        if(IS_INTRA4x4(mb_type))\n\n            cbp= golomb_to_intra4x4_cbp[cbp];\n\n        else\n\n            cbp= golomb_to_inter_cbp[cbp];\n\n    }\n\n    h->cbp = cbp;\n\n\n\n    if(dct8x8_allowed && (cbp&15) && !IS_INTRA(mb_type)){\n\n        if(get_bits1(&s->gb))\n\n            mb_type |= MB_TYPE_8x8DCT;\n\n    }\n\n    s->current_picture.mb_type[mb_xy]= mb_type;\n\n\n\n    if(cbp || IS_INTRA16x16(mb_type)){\n\n        int i8x8, i4x4, chroma_idx;\n\n        int chroma_qp, dquant;\n\n        GetBitContext *gb= IS_INTRA(mb_type) ? h->intra_gb_ptr : h->inter_gb_ptr;\n\n        const uint8_t *scan, *scan8x8, *dc_scan;\n\n\n\n//        fill_non_zero_count_cache(h);\n\n\n\n        if(IS_INTERLACED(mb_type)){\n\n            scan8x8= s->qscale ? h->field_scan8x8_cavlc : h->field_scan8x8_cavlc_q0;\n\n            scan= s->qscale ? h->field_scan : h->field_scan_q0;\n\n            dc_scan= luma_dc_field_scan;\n\n        }else{\n\n            scan8x8= s->qscale ? h->zigzag_scan8x8_cavlc : h->zigzag_scan8x8_cavlc_q0;\n\n            scan= s->qscale ? h->zigzag_scan : h->zigzag_scan_q0;\n\n            dc_scan= luma_dc_zigzag_scan;\n\n        }\n\n\n\n        dquant= get_se_golomb(&s->gb);\n\n\n\n        if( dquant > 25 || dquant < -26 ){\n\n            av_log(h->s.avctx, AV_LOG_ERROR, \"dquant out of range (%d) at %d %d\\n\", dquant, s->mb_x, s->mb_y);\n\n            return -1;\n\n        }\n\n\n\n        s->qscale += dquant;\n\n        if(((unsigned)s->qscale) > 51){\n\n            if(s->qscale<0) s->qscale+= 52;\n\n            else            s->qscale-= 52;\n\n        }\n\n\n\n        h->chroma_qp= chroma_qp= get_chroma_qp(h->pps.chroma_qp_index_offset, s->qscale);\n\n        if(IS_INTRA16x16(mb_type)){\n\n            if( decode_residual(h, h->intra_gb_ptr, h->mb, LUMA_DC_BLOCK_INDEX, dc_scan, h->dequant4_coeff[0][s->qscale], 16) < 0){\n\n                return -1; //FIXME continue if partitioned and other return -1 too\n\n            }\n\n\n\n            assert((cbp&15) == 0 || (cbp&15) == 15);\n\n\n\n            if(cbp&15){\n\n                for(i8x8=0; i8x8<4; i8x8++){\n\n                    for(i4x4=0; i4x4<4; i4x4++){\n\n                        const int index= i4x4 + 4*i8x8;\n\n                        if( decode_residual(h, h->intra_gb_ptr, h->mb + 16*index, index, scan + 1, h->dequant4_coeff[0][s->qscale], 15) < 0 ){\n\n                            return -1;\n\n                        }\n\n                    }\n\n                }\n\n            }else{\n\n                fill_rectangle(&h->non_zero_count_cache[scan8[0]], 4, 4, 8, 0, 1);\n\n            }\n\n        }else{\n\n            for(i8x8=0; i8x8<4; i8x8++){\n\n                if(cbp & (1<<i8x8)){\n\n                    if(IS_8x8DCT(mb_type)){\n\n                        DCTELEM *buf = &h->mb[64*i8x8];\n\n                        uint8_t *nnz;\n\n                        for(i4x4=0; i4x4<4; i4x4++){\n\n                            if( decode_residual(h, gb, buf, i4x4+4*i8x8, scan8x8+16*i4x4,\n\n                                                h->dequant8_coeff[IS_INTRA( mb_type ) ? 0:1][s->qscale], 16) <0 )\n\n                                return -1;\n\n                        }\n\n                        nnz= &h->non_zero_count_cache[ scan8[4*i8x8] ];\n\n                        nnz[0] += nnz[1] + nnz[8] + nnz[9];\n\n                    }else{\n\n                        for(i4x4=0; i4x4<4; i4x4++){\n\n                            const int index= i4x4 + 4*i8x8;\n\n\n\n                            if( decode_residual(h, gb, h->mb + 16*index, index, scan, h->dequant4_coeff[IS_INTRA( mb_type ) ? 0:3][s->qscale], 16) <0 ){\n\n                                return -1;\n\n                            }\n\n                        }\n\n                    }\n\n                }else{\n\n                    uint8_t * const nnz= &h->non_zero_count_cache[ scan8[4*i8x8] ];\n\n                    nnz[0] = nnz[1] = nnz[8] = nnz[9] = 0;\n\n                }\n\n            }\n\n        }\n\n\n\n        if(cbp&0x30){\n\n            for(chroma_idx=0; chroma_idx<2; chroma_idx++)\n\n                if( decode_residual(h, gb, h->mb + 256 + 16*4*chroma_idx, CHROMA_DC_BLOCK_INDEX, chroma_dc_scan, NULL, 4) < 0){\n\n                    return -1;\n\n                }\n\n        }\n\n\n\n        if(cbp&0x20){\n\n            for(chroma_idx=0; chroma_idx<2; chroma_idx++){\n\n                const uint32_t *qmul = h->dequant4_coeff[chroma_idx+1+(IS_INTRA( mb_type ) ? 0:3)][chroma_qp];\n\n                for(i4x4=0; i4x4<4; i4x4++){\n\n                    const int index= 16 + 4*chroma_idx + i4x4;\n\n                    if( decode_residual(h, gb, h->mb + 16*index, index, scan + 1, qmul, 15) < 0){\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n        }else{\n\n            uint8_t * const nnz= &h->non_zero_count_cache[0];\n\n            nnz[ scan8[16]+0 ] = nnz[ scan8[16]+1 ] =nnz[ scan8[16]+8 ] =nnz[ scan8[16]+9 ] =\n\n            nnz[ scan8[20]+0 ] = nnz[ scan8[20]+1 ] =nnz[ scan8[20]+8 ] =nnz[ scan8[20]+9 ] = 0;\n\n        }\n\n    }else{\n\n        uint8_t * const nnz= &h->non_zero_count_cache[0];\n\n        fill_rectangle(&nnz[scan8[0]], 4, 4, 8, 0, 1);\n\n        nnz[ scan8[16]+0 ] = nnz[ scan8[16]+1 ] =nnz[ scan8[16]+8 ] =nnz[ scan8[16]+9 ] =\n\n        nnz[ scan8[20]+0 ] = nnz[ scan8[20]+1 ] =nnz[ scan8[20]+8 ] =nnz[ scan8[20]+9 ] = 0;\n\n    }\n\n    s->current_picture.qscale_table[mb_xy]= s->qscale;\n\n    write_back_non_zero_count(h);\n\n\n\n    if(MB_MBAFF){\n\n        h->ref_count[0] >>= 1;\n\n        h->ref_count[1] >>= 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23299, "_split": "test", "_hash": "0ce89a053871794f1ff423959862e83c"}
{"project": "FFmpeg", "commit_id": "e477f09d0b3619f3d29173b2cd593e17e2d1978e", "target": 1, "func": "static int decode_trns_chunk(AVCodecContext *avctx, PNGDecContext *s,\n\n                             uint32_t length)\n\n{\n\n    int v, i;\n\n\n\n    if (s->color_type == PNG_COLOR_TYPE_PALETTE) {\n\n        if (length > 256 || !(s->state & PNG_PLTE))\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        for (i = 0; i < length; i++) {\n\n            v = bytestream2_get_byte(&s->gb);\n\n            s->palette[i] = (s->palette[i] & 0x00ffffff) | (v << 24);\n\n        }\n\n    } else if (s->color_type == PNG_COLOR_TYPE_GRAY || s->color_type == PNG_COLOR_TYPE_RGB) {\n\n        if ((s->color_type == PNG_COLOR_TYPE_GRAY && length != 2) ||\n\n            (s->color_type == PNG_COLOR_TYPE_RGB && length != 6))\n\n            return AVERROR_INVALIDDATA;\n\n\n\n        for (i = 0; i < length / 2; i++) {\n\n            /* only use the least significant bits */\n\n            v = av_mod_uintp2(bytestream2_get_be16(&s->gb), s->bit_depth);\n\n\n\n            if (s->bit_depth > 8)\n\n                AV_WB16(&s->transparent_color_be[2 * i], v);\n\n            else\n\n                s->transparent_color_be[i] = v;\n\n        }\n\n    } else {\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bytestream2_skip(&s->gb, 4); /* crc */\n\n    s->has_trns = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 23309, "_split": "test", "_hash": "33719b040383a32cf6540fb766f73093"}
{"project": "FFmpeg", "commit_id": "3016e919d4e1d90da98af19ce2a9d4979506eaf3", "target": 1, "func": "static inline int wv_get_value_integer(WavpackFrameContext *s, uint32_t *crc,\n\n                                       int S)\n\n{\n\n    unsigned bit;\n\n\n\n    if (s->extra_bits) {\n\n        S <<= s->extra_bits;\n\n\n\n        if (s->got_extra_bits &&\n\n            get_bits_left(&s->gb_extra_bits) >= s->extra_bits) {\n\n            S   |= get_bits_long(&s->gb_extra_bits, s->extra_bits);\n\n            *crc = *crc * 9 + (S & 0xffff) * 3 + ((unsigned)S >> 16);\n\n        }\n\n    }\n\n\n\n    bit = (S & s->and) | s->or;\n\n    bit = ((S + bit) << s->shift) - bit;\n\n\n\n    if (s->hybrid)\n\n        bit = av_clip(bit, s->hybrid_minclip, s->hybrid_maxclip);\n\n\n\n    return bit << s->post_shift;\n\n}\n", "idx": 23323, "_split": "test", "_hash": "5d7fbd48b81bb1b2a46df8a589fb47fc"}
{"project": "FFmpeg", "commit_id": "289520fd97395ffd5bf933ac80487e858bc4039d", "target": 0, "func": "static int load_matrix(MpegEncContext *s, uint16_t matrix0[64], uint16_t matrix1[64], int intra)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 64; i++) {\n\n        int j = s->dsp.idct_permutation[ff_zigzag_direct[i]];\n\n        int v = get_bits(&s->gb, 8);\n\n        if (v == 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"matrix damaged\\n\");\n\n            return -1;\n\n        }\n\n        if (intra && i == 0 && v != 8) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"intra matrix specifies invalid DC quantizer %d, ignoring\\n\", v);\n\n            v = 8; // needed by pink.mpg / issue1046\n\n        }\n\n        matrix0[j] = v;\n\n        if (matrix1)\n\n            matrix1[j] = v;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23344, "_split": "test", "_hash": "68873a3c2b35c4fe90b57ac5813c15ea"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "static int copy_from(IpvideoContext *s, AVFrame *src, AVFrame *dst, int delta_x, int delta_y)\n\n{\n\n    int current_offset = s->pixel_ptr - dst->data[0];\n\n    int motion_offset = current_offset + delta_y * dst->linesize[0]\n\n                       + delta_x * (1 + s->is_16bpp);\n\n    if (motion_offset < 0) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: motion offset < 0 (%d)\\n\", motion_offset);\n\n        return AVERROR_INVALIDDATA;\n\n    } else if (motion_offset > s->upper_motion_limit_offset) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \" Interplay video: motion offset above limit (%d >= %d)\\n\",\n\n            motion_offset, s->upper_motion_limit_offset);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (src->data[0] == NULL) {\n\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid decode type, corrupted header?\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n    s->hdsp.put_pixels_tab[!s->is_16bpp][0](s->pixel_ptr, src->data[0] + motion_offset,\n\n                                            dst->linesize[0], 8);\n\n    return 0;\n\n}\n", "idx": 23361, "_split": "test", "_hash": "ac1de882e57f6f65de67025feb53a1e7"}
{"project": "FFmpeg", "commit_id": "b3f9f7a33337e9b64e6044b0010e2722fa0b2f9c", "target": 0, "func": "static PESContext *add_pes_stream(MpegTSContext *ts, int pid, int pcr_pid, int stream_type)\n\n{\n\n    MpegTSFilter *tss;\n\n    PESContext *pes;\n\n\n\n    /* if no pid found, then add a pid context */\n\n    pes = av_mallocz(sizeof(PESContext));\n\n    if (!pes)\n\n        return 0;\n\n    pes->ts = ts;\n\n    pes->stream = ts->stream;\n\n    pes->pid = pid;\n\n    pes->pcr_pid = pcr_pid;\n\n    pes->stream_type = stream_type;\n\n    pes->state = MPEGTS_SKIP;\n\n    pes->pts = AV_NOPTS_VALUE;\n\n    pes->dts = AV_NOPTS_VALUE;\n\n    tss = mpegts_open_pes_filter(ts, pid, mpegts_push_data, pes);\n\n    if (!tss) {\n\n        av_free(pes);\n\n        return 0;\n\n    }\n\n    return pes;\n\n}\n", "idx": 23425, "_split": "test", "_hash": "afda9dcc682c0f9efe0bb47351a70c64"}
{"project": "FFmpeg", "commit_id": "c341f734e5f9d6af4a8fdcceb6f5d12de6395c76", "target": 1, "func": "void mpeg_motion_internal(MpegEncContext *s,\n\n                 uint8_t *dest_y, uint8_t *dest_cb, uint8_t *dest_cr,\n\n                 int field_based, int bottom_field, int field_select,\n\n                 uint8_t **ref_picture, op_pixels_func (*pix_op)[4],\n\n                 int motion_x, int motion_y, int h, int is_mpeg12, int mb_y)\n\n{\n\n    uint8_t *ptr_y, *ptr_cb, *ptr_cr;\n\n    int dxy, uvdxy, mx, my, src_x, src_y,\n\n        uvsrc_x, uvsrc_y, v_edge_pos;\n\n    emuedge_linesize_type uvlinesize, linesize;\n\n\n\n#if 0\n\nif(s->quarter_sample)\n\n{\n\n    motion_x>>=1;\n\n    motion_y>>=1;\n\n}\n\n#endif\n\n\n\n    v_edge_pos = s->v_edge_pos >> field_based;\n\n    linesize   = s->current_picture.f.linesize[0] << field_based;\n\n    uvlinesize = s->current_picture.f.linesize[1] << field_based;\n\n\n\n    dxy = ((motion_y & 1) << 1) | (motion_x & 1);\n\n    src_x = s->mb_x* 16               + (motion_x >> 1);\n\n    src_y =(   mb_y<<(4-field_based)) + (motion_y >> 1);\n\n\n\n    if (!is_mpeg12 && s->out_format == FMT_H263) {\n\n        if((s->workaround_bugs & FF_BUG_HPEL_CHROMA) && field_based){\n\n            mx = (motion_x>>1)|(motion_x&1);\n\n            my = motion_y >>1;\n\n            uvdxy = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x* 8               + (mx >> 1);\n\n            uvsrc_y =(   mb_y<<(3-field_based))+ (my >> 1);\n\n        }else{\n\n            uvdxy = dxy | (motion_y & 2) | ((motion_x & 2) >> 1);\n\n            uvsrc_x = src_x>>1;\n\n            uvsrc_y = src_y>>1;\n\n        }\n\n    }else if(!is_mpeg12 && s->out_format == FMT_H261){//even chroma mv's are full pel in H261\n\n        mx = motion_x / 4;\n\n        my = motion_y / 4;\n\n        uvdxy = 0;\n\n        uvsrc_x = s->mb_x*8 + mx;\n\n        uvsrc_y =    mb_y*8 + my;\n\n    } else {\n\n        if(s->chroma_y_shift){\n\n            mx = motion_x / 2;\n\n            my = motion_y / 2;\n\n            uvdxy = ((my & 1) << 1) | (mx & 1);\n\n            uvsrc_x = s->mb_x* 8               + (mx >> 1);\n\n            uvsrc_y =(   mb_y<<(3-field_based))+ (my >> 1);\n\n        } else {\n\n            if(s->chroma_x_shift){\n\n            //Chroma422\n\n                mx = motion_x / 2;\n\n                uvdxy = ((motion_y & 1) << 1) | (mx & 1);\n\n                uvsrc_x = s->mb_x* 8           + (mx >> 1);\n\n                uvsrc_y = src_y;\n\n            } else {\n\n            //Chroma444\n\n                uvdxy = dxy;\n\n                uvsrc_x = src_x;\n\n                uvsrc_y = src_y;\n\n            }\n\n        }\n\n    }\n\n\n\n    ptr_y  = ref_picture[0] + src_y * linesize + src_x;\n\n    ptr_cb = ref_picture[1] + uvsrc_y * uvlinesize + uvsrc_x;\n\n    ptr_cr = ref_picture[2] + uvsrc_y * uvlinesize + uvsrc_x;\n\n\n\n    if(   (unsigned)src_x > FFMAX(s->h_edge_pos - (motion_x&1) - 16, 0)\n\n       || (unsigned)src_y > FFMAX(   v_edge_pos - (motion_y&1) - h , 0)){\n\n            if(is_mpeg12 || s->codec_id == AV_CODEC_ID_MPEG2VIDEO ||\n\n               s->codec_id == AV_CODEC_ID_MPEG1VIDEO){\n\n                av_log(s->avctx,AV_LOG_DEBUG,\n\n                        \"MPEG motion vector out of boundary (%d %d)\\n\", src_x, src_y);\n\n                return;\n\n            }\n\n            s->vdsp.emulated_edge_mc(s->edge_emu_buffer, ptr_y, s->linesize,\n\n                                17, 17+field_based,\n\n                                src_x, src_y<<field_based,\n\n                                s->h_edge_pos, s->v_edge_pos);\n\n            ptr_y = s->edge_emu_buffer;\n\n            if(!CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n                uint8_t *uvbuf= s->edge_emu_buffer+18*s->linesize;\n\n                s->vdsp.emulated_edge_mc(uvbuf ,\n\n                                    ptr_cb, s->uvlinesize,\n\n                                    9, 9+field_based,\n\n                                    uvsrc_x, uvsrc_y<<field_based,\n\n                                    s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n                s->vdsp.emulated_edge_mc(uvbuf+16,\n\n                                    ptr_cr, s->uvlinesize,\n\n                                    9, 9+field_based,\n\n                                    uvsrc_x, uvsrc_y<<field_based,\n\n                                    s->h_edge_pos>>1, s->v_edge_pos>>1);\n\n                ptr_cb= uvbuf;\n\n                ptr_cr= uvbuf+16;\n\n            }\n\n    }\n\n\n\n    if(bottom_field){ //FIXME use this for field pix too instead of the obnoxious hack which changes picture.data\n\n        dest_y += s->linesize;\n\n        dest_cb+= s->uvlinesize;\n\n        dest_cr+= s->uvlinesize;\n\n    }\n\n\n\n    if(field_select){\n\n        ptr_y += s->linesize;\n\n        ptr_cb+= s->uvlinesize;\n\n        ptr_cr+= s->uvlinesize;\n\n    }\n\n\n\n    pix_op[0][dxy](dest_y, ptr_y, linesize, h);\n\n\n\n    if(!CONFIG_GRAY || !(s->flags&CODEC_FLAG_GRAY)){\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n                (dest_cb, ptr_cb, uvlinesize, h >> s->chroma_y_shift);\n\n        pix_op[s->chroma_x_shift][uvdxy]\n\n                (dest_cr, ptr_cr, uvlinesize, h >> s->chroma_y_shift);\n\n    }\n\n    if(!is_mpeg12 && (CONFIG_H261_ENCODER || CONFIG_H261_DECODER) &&\n\n         s->out_format == FMT_H261){\n\n        ff_h261_loop_filter(s);\n\n    }\n\n}\n", "idx": 23429, "_split": "test", "_hash": "3560c76210060b1dc00d7c6988c89268"}
{"project": "FFmpeg", "commit_id": "dde0af2df1caffb9e33855c08fc691dbbbbc72b3", "target": 0, "func": "static int vble_unpack(VBLEContext *ctx, GetBitContext *gb)\n\n{\n\n    int i;\n\n    static const uint8_t LUT[256] = {\n\n        8,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        6,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        7,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        6,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n        5,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,4,0,1,0,2,0,1,0,3,0,1,0,2,0,1,0,\n\n    };\n\n\n\n    /* Read all the lengths in first */\n\n    for (i = 0; i < ctx->size; i++) {\n\n        /* At most we need to read 9 bits total to get indices up to 8 */\n\n        int val = show_bits(gb, 8);\n\n\n\n        // read reverse unary\n\n        if (val) {\n\n            val = LUT[val];\n\n            skip_bits(gb, val + 1);\n\n            ctx->len[i] = val;\n\n        } else {\n\n            skip_bits(gb, 8);\n\n            if (!get_bits1(gb))\n\n                return -1;\n\n            ctx->len[i] = 8;\n\n        }\n\n    }\n\n\n\n    /* For any values that have length 0 */\n\n    memset(ctx->val, 0, ctx->size);\n\n\n\n    for (i = 0; i < ctx->size; i++) {\n\n        /* Check we have enough bits left */\n\n        if (get_bits_left(gb) < ctx->len[i])\n\n            return -1;\n\n\n\n        /* get_bits can't take a length of 0 */\n\n        if (ctx->len[i])\n\n            ctx->val[i] = (1 << ctx->len[i]) + get_bits(gb, ctx->len[i]) - 1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23465, "_split": "test", "_hash": "31684de311406b8f356c39cebb61153c"}
{"project": "FFmpeg", "commit_id": "2758cdedfb7ac61f8b5e4861f99218b6fd43491d", "target": 0, "func": "int ffurl_alloc(URLContext **puc, const char *filename, int flags,\n\n                const AVIOInterruptCB *int_cb)\n\n{\n\n    URLProtocol *up = NULL;\n\n    char proto_str[128], proto_nested[128], *ptr;\n\n    size_t proto_len = strspn(filename, URL_SCHEME_CHARS);\n\n\n\n    if (filename[proto_len] != ':' || is_dos_path(filename))\n\n        strcpy(proto_str, \"file\");\n\n    else\n\n        av_strlcpy(proto_str, filename,\n\n                   FFMIN(proto_len + 1, sizeof(proto_str)));\n\n\n\n    av_strlcpy(proto_nested, proto_str, sizeof(proto_nested));\n\n    if ((ptr = strchr(proto_nested, '+')))\n\n        *ptr = '\\0';\n\n\n\n    while (up = ffurl_protocol_next(up)) {\n\n        if (!strcmp(proto_str, up->name))\n\n            return url_alloc_for_protocol(puc, up, filename, flags, int_cb);\n\n        if (up->flags & URL_PROTOCOL_FLAG_NESTED_SCHEME &&\n\n            !strcmp(proto_nested, up->name))\n\n            return url_alloc_for_protocol(puc, up, filename, flags, int_cb);\n\n    }\n\n    *puc = NULL;\n\n    return AVERROR_PROTOCOL_NOT_FOUND;\n\n}\n", "idx": 23470, "_split": "test", "_hash": "8eef484359e61973f57d857b10491b1a"}
{"project": "FFmpeg", "commit_id": "83548fe894cdb455cc127f754d09905b6d23c173", "target": 0, "func": "static int avi_write_trailer(AVFormatContext *s)\n\n{\n\n    AVIContext *avi = s->priv_data;\n\n    AVIOContext *pb = s->pb;\n\n    int res = 0;\n\n    int i, j, n, nb_frames;\n\n    int64_t file_size;\n\n\n\n    if (pb->seekable) {\n\n        if (avi->riff_id == 1) {\n\n            ff_end_tag(pb, avi->movi_list);\n\n            res = avi_write_idx1(s);\n\n            ff_end_tag(pb, avi->riff_start);\n\n        } else {\n\n            avi_write_ix(s);\n\n            ff_end_tag(pb, avi->movi_list);\n\n            ff_end_tag(pb, avi->riff_start);\n\n\n\n            file_size = avio_tell(pb);\n\n            avio_seek(pb, avi->odml_list - 8, SEEK_SET);\n\n            ffio_wfourcc(pb, \"LIST\"); /* Making this AVI OpenDML one */\n\n            avio_skip(pb, 16);\n\n\n\n            for (n = nb_frames = 0; n < s->nb_streams; n++) {\n\n                AVCodecParameters *par = s->streams[n]->codecpar;\n\n                AVIStream *avist       = s->streams[n]->priv_data;\n\n\n\n                if (par->codec_type == AVMEDIA_TYPE_VIDEO) {\n\n                    if (nb_frames < avist->packet_count)\n\n                        nb_frames = avist->packet_count;\n\n                } else {\n\n                    if (par->codec_id == AV_CODEC_ID_MP2 ||\n\n                        par->codec_id == AV_CODEC_ID_MP3)\n\n                        nb_frames += avist->packet_count;\n\n                }\n\n            }\n\n            avio_wl32(pb, nb_frames);\n\n            avio_seek(pb, file_size, SEEK_SET);\n\n\n\n            avi_write_counters(s, avi->riff_id);\n\n        }\n\n    }\n\n\n\n    for (i = 0; i < s->nb_streams; i++) {\n\n        AVIStream *avist = s->streams[i]->priv_data;\n\n        for (j = 0; j < avist->indexes.ents_allocated / AVI_INDEX_CLUSTER_SIZE; j++)\n\n            av_free(avist->indexes.cluster[j]);\n\n        av_freep(&avist->indexes.cluster);\n\n        avist->indexes.ents_allocated = avist->indexes.entry = 0;\n\n    }\n\n\n\n    return res;\n\n}\n", "idx": 23508, "_split": "test", "_hash": "28d1b76ed6fed41e256f06fa096b876d"}
{"project": "FFmpeg", "commit_id": "70143a3954e1c4412efb2bf1a3a818adea2d3abf", "target": 0, "func": "static int dxva2_get_buffer(AVCodecContext *s, AVFrame *frame, int flags)\n\n{\n\n    InputStream  *ist = s->opaque;\n\n    DXVA2Context *ctx = ist->hwaccel_ctx;\n\n\n\n    return av_hwframe_get_buffer(ctx->hw_frames_ctx, frame, 0);\n\n}\n", "idx": 23560, "_split": "test", "_hash": "0c8288e0cc8ea098d6248f44e7acedb6"}
{"project": "FFmpeg", "commit_id": "ca32f7f2083f9ededd1d9964ed065e0ad07a01e0", "target": 0, "func": "void ff_h264_idct8_add_c(uint8_t *dst, DCTELEM *block, int stride){\n\n    int i;\n\n    uint8_t *cm = ff_cropTbl + MAX_NEG_CROP;\n\n\n\n    block[0] += 32;\n\n\n\n    for( i = 0; i < 8; i++ )\n\n    {\n\n        const int a0 =  block[0+i*8] + block[4+i*8];\n\n        const int a2 =  block[0+i*8] - block[4+i*8];\n\n        const int a4 = (block[2+i*8]>>1) - block[6+i*8];\n\n        const int a6 = (block[6+i*8]>>1) + block[2+i*8];\n\n\n\n        const int b0 = a0 + a6;\n\n        const int b2 = a2 + a4;\n\n        const int b4 = a2 - a4;\n\n        const int b6 = a0 - a6;\n\n\n\n        const int a1 = -block[3+i*8] + block[5+i*8] - block[7+i*8] - (block[7+i*8]>>1);\n\n        const int a3 =  block[1+i*8] + block[7+i*8] - block[3+i*8] - (block[3+i*8]>>1);\n\n        const int a5 = -block[1+i*8] + block[7+i*8] + block[5+i*8] + (block[5+i*8]>>1);\n\n        const int a7 =  block[3+i*8] + block[5+i*8] + block[1+i*8] + (block[1+i*8]>>1);\n\n\n\n        const int b1 = (a7>>2) + a1;\n\n        const int b3 =  a3 + (a5>>2);\n\n        const int b5 = (a3>>2) - a5;\n\n        const int b7 =  a7 - (a1>>2);\n\n\n\n        block[0+i*8] = b0 + b7;\n\n        block[7+i*8] = b0 - b7;\n\n        block[1+i*8] = b2 + b5;\n\n        block[6+i*8] = b2 - b5;\n\n        block[2+i*8] = b4 + b3;\n\n        block[5+i*8] = b4 - b3;\n\n        block[3+i*8] = b6 + b1;\n\n        block[4+i*8] = b6 - b1;\n\n    }\n\n    for( i = 0; i < 8; i++ )\n\n    {\n\n        const int a0 =  block[i+0*8] + block[i+4*8];\n\n        const int a2 =  block[i+0*8] - block[i+4*8];\n\n        const int a4 = (block[i+2*8]>>1) - block[i+6*8];\n\n        const int a6 = (block[i+6*8]>>1) + block[i+2*8];\n\n\n\n        const int b0 = a0 + a6;\n\n        const int b2 = a2 + a4;\n\n        const int b4 = a2 - a4;\n\n        const int b6 = a0 - a6;\n\n\n\n        const int a1 = -block[i+3*8] + block[i+5*8] - block[i+7*8] - (block[i+7*8]>>1);\n\n        const int a3 =  block[i+1*8] + block[i+7*8] - block[i+3*8] - (block[i+3*8]>>1);\n\n        const int a5 = -block[i+1*8] + block[i+7*8] + block[i+5*8] + (block[i+5*8]>>1);\n\n        const int a7 =  block[i+3*8] + block[i+5*8] + block[i+1*8] + (block[i+1*8]>>1);\n\n\n\n        const int b1 = (a7>>2) + a1;\n\n        const int b3 =  a3 + (a5>>2);\n\n        const int b5 = (a3>>2) - a5;\n\n        const int b7 =  a7 - (a1>>2);\n\n\n\n        dst[i + 0*stride] = cm[ dst[i + 0*stride] + ((b0 + b7) >> 6) ];\n\n        dst[i + 1*stride] = cm[ dst[i + 1*stride] + ((b2 + b5) >> 6) ];\n\n        dst[i + 2*stride] = cm[ dst[i + 2*stride] + ((b4 + b3) >> 6) ];\n\n        dst[i + 3*stride] = cm[ dst[i + 3*stride] + ((b6 + b1) >> 6) ];\n\n        dst[i + 4*stride] = cm[ dst[i + 4*stride] + ((b6 - b1) >> 6) ];\n\n        dst[i + 5*stride] = cm[ dst[i + 5*stride] + ((b4 - b3) >> 6) ];\n\n        dst[i + 6*stride] = cm[ dst[i + 6*stride] + ((b2 - b5) >> 6) ];\n\n        dst[i + 7*stride] = cm[ dst[i + 7*stride] + ((b0 - b7) >> 6) ];\n\n    }\n\n}\n", "idx": 23576, "_split": "test", "_hash": "7ea6af2b867f9c23b1fb4010fc1cb4f6"}
{"project": "FFmpeg", "commit_id": "3ab9a2a5577d445252724af4067d2a7c8a378efa", "target": 1, "func": "static void rv40_h_weak_loop_filter(uint8_t *src, const int stride,\n\n                                    const int filter_p1, const int filter_q1,\n\n                                    const int alpha, const int beta,\n\n                                    const int lim_p0q0, const int lim_q1,\n\n                                    const int lim_p1)\n\n{\n\n    rv40_weak_loop_filter(src, stride, 1, filter_p1, filter_q1,\n\n                          alpha, beta, lim_p0q0, lim_q1, lim_p1);\n\n}\n", "idx": 23627, "_split": "test", "_hash": "3a7c3c6eb3e89570aafd2909022a3226"}
{"project": "FFmpeg", "commit_id": "3ca5df36a50e3ffd3b24734725bf545617a627a8", "target": 1, "func": "static int decode_subframe(WmallDecodeCtx *s)\n\n{\n\n    int offset        = s->samples_per_frame;\n\n    int subframe_len  = s->samples_per_frame;\n\n    int total_samples = s->samples_per_frame * s->num_channels;\n\n    int i, j, rawpcm_tile, padding_zeroes, res;\n\n\n\n    s->subframe_offset = get_bits_count(&s->gb);\n\n\n\n    /* reset channel context and find the next block offset and size\n\n        == the next block of the channel with the smallest number of\n\n        decoded samples */\n\n    for (i = 0; i < s->num_channels; i++) {\n\n        if (offset > s->channel[i].decoded_samples) {\n\n            offset = s->channel[i].decoded_samples;\n\n            subframe_len =\n\n                s->channel[i].subframe_len[s->channel[i].cur_subframe];\n\n        }\n\n    }\n\n\n\n    /* get a list of all channels that contain the estimated block */\n\n    s->channels_for_cur_subframe = 0;\n\n    for (i = 0; i < s->num_channels; i++) {\n\n        const int cur_subframe = s->channel[i].cur_subframe;\n\n        /* subtract already processed samples */\n\n        total_samples -= s->channel[i].decoded_samples;\n\n\n\n        /* and count if there are multiple subframes that match our profile */\n\n        if (offset == s->channel[i].decoded_samples &&\n\n            subframe_len == s->channel[i].subframe_len[cur_subframe]) {\n\n            total_samples -= s->channel[i].subframe_len[cur_subframe];\n\n            s->channel[i].decoded_samples +=\n\n                s->channel[i].subframe_len[cur_subframe];\n\n            s->channel_indexes_for_cur_subframe[s->channels_for_cur_subframe] = i;\n\n            ++s->channels_for_cur_subframe;\n\n        }\n\n    }\n\n\n\n    /* check if the frame will be complete after processing the\n\n        estimated block */\n\n    if (!total_samples)\n\n        s->parsed_all_subframes = 1;\n\n\n\n\n\n    s->seekable_tile = get_bits1(&s->gb);\n\n    if (s->seekable_tile) {\n\n        clear_codec_buffers(s);\n\n\n\n        s->do_arith_coding    = get_bits1(&s->gb);\n\n        if (s->do_arith_coding) {\n\n            avpriv_request_sample(s->avctx, \"Arithmetic coding\");\n\n            return AVERROR_PATCHWELCOME;\n\n        }\n\n        s->do_ac_filter       = get_bits1(&s->gb);\n\n        s->do_inter_ch_decorr = get_bits1(&s->gb);\n\n        s->do_mclms           = get_bits1(&s->gb);\n\n\n\n        if (s->do_ac_filter)\n\n            decode_ac_filter(s);\n\n\n\n        if (s->do_mclms)\n\n            decode_mclms(s);\n\n\n\n        if ((res = decode_cdlms(s)) < 0)\n\n            return res;\n\n        s->movave_scaling = get_bits(&s->gb, 3);\n\n        s->quant_stepsize = get_bits(&s->gb, 8) + 1;\n\n\n\n        reset_codec(s);\n\n    } else if (!s->cdlms[0][0].order) {\n\n        av_log(s->avctx, AV_LOG_DEBUG,\n\n               \"Waiting for seekable tile\\n\");\n\n        s->frame.nb_samples = 0;\n\n        return -1;\n\n    }\n\n\n\n    rawpcm_tile = get_bits1(&s->gb);\n\n\n\n    for (i = 0; i < s->num_channels; i++)\n\n        s->is_channel_coded[i] = 1;\n\n\n\n    if (!rawpcm_tile) {\n\n        for (i = 0; i < s->num_channels; i++)\n\n            s->is_channel_coded[i] = get_bits1(&s->gb);\n\n\n\n        if (s->bV3RTM) {\n\n            // LPC\n\n            s->do_lpc = get_bits1(&s->gb);\n\n            if (s->do_lpc) {\n\n                decode_lpc(s);\n\n                avpriv_request_sample(s->avctx, \"Expect wrong output since \"\n\n                                      \"inverse LPC filter\");\n\n            }\n\n        } else\n\n            s->do_lpc = 0;\n\n    }\n\n\n\n\n\n    if (get_bits1(&s->gb))\n\n        padding_zeroes = get_bits(&s->gb, 5);\n\n    else\n\n        padding_zeroes = 0;\n\n\n\n    if (rawpcm_tile) {\n\n        int bits = s->bits_per_sample - padding_zeroes;\n\n        if (bits <= 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR,\n\n                   \"Invalid number of padding bits in raw PCM tile\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        av_dlog(s->avctx, \"RAWPCM %d bits per sample. \"\n\n                \"total %d bits, remain=%d\\n\", bits,\n\n                bits * s->num_channels * subframe_len, get_bits_count(&s->gb));\n\n        for (i = 0; i < s->num_channels; i++)\n\n            for (j = 0; j < subframe_len; j++)\n\n                s->channel_coeffs[i][j] = get_sbits(&s->gb, bits);\n\n    } else {\n\n        for (i = 0; i < s->num_channels; i++)\n\n            if (s->is_channel_coded[i]) {\n\n                decode_channel_residues(s, i, subframe_len);\n\n                if (s->seekable_tile)\n\n                    use_high_update_speed(s, i);\n\n                else\n\n                    use_normal_update_speed(s, i);\n\n                revert_cdlms(s, i, 0, subframe_len);\n\n            } else {\n\n                memset(s->channel_residues[i], 0, sizeof(**s->channel_residues) * subframe_len);\n\n            }\n\n    }\n\n    if (s->do_mclms)\n\n        revert_mclms(s, subframe_len);\n\n    if (s->do_inter_ch_decorr)\n\n        revert_inter_ch_decorr(s, subframe_len);\n\n    if (s->do_ac_filter)\n\n        revert_acfilter(s, subframe_len);\n\n\n\n    /* Dequantize */\n\n    if (s->quant_stepsize != 1)\n\n        for (i = 0; i < s->num_channels; i++)\n\n            for (j = 0; j < subframe_len; j++)\n\n                s->channel_residues[i][j] *= s->quant_stepsize;\n\n\n\n    /* Write to proper output buffer depending on bit-depth */\n\n    for (i = 0; i < s->channels_for_cur_subframe; i++) {\n\n        int c = s->channel_indexes_for_cur_subframe[i];\n\n        int subframe_len = s->channel[c].subframe_len[s->channel[c].cur_subframe];\n\n\n\n        for (j = 0; j < subframe_len; j++) {\n\n            if (s->bits_per_sample == 16) {\n\n                *s->samples_16[c]++ = (int16_t) s->channel_residues[c][j] << padding_zeroes;\n\n            } else {\n\n                *s->samples_32[c]++ = s->channel_residues[c][j] << padding_zeroes;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* handled one subframe */\n\n    for (i = 0; i < s->channels_for_cur_subframe; i++) {\n\n        int c = s->channel_indexes_for_cur_subframe[i];\n\n        if (s->channel[c].cur_subframe >= s->channel[c].num_subframes) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"broken subframe\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        ++s->channel[c].cur_subframe;\n\n    }\n\n    return 0;\n\n}\n", "idx": 23636, "_split": "test", "_hash": "354f5ade75cec9c3a11d1bf966ca3f78"}
{"project": "FFmpeg", "commit_id": "1bab6f852c7ca433285d19f65c701885fa69cc57", "target": 1, "func": "static void RENAME(yuv2rgb565_1)(SwsContext *c, const int16_t *buf0,\n\n                                 const int16_t *ubuf[2], const int16_t *bguf[2],\n\n                                 const int16_t *abuf0, uint8_t *dest,\n\n                                 int dstW, int uvalpha, int y)\n\n{\n\n    const int16_t *ubuf0 = ubuf[0], *ubuf1 = ubuf[1];\n\n    const int16_t *buf1= buf0; //FIXME needed for RGB1/BGR1\n\n\n\n    if (uvalpha < 2048) { // note this is not correct (shifts chrominance by 0.5 pixels) but it is a bit faster\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB1(%%REGBP, %5)\n\n            \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n            /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n            \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n            \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n            \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n            WRITERGB16(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n    } else {\n\n        __asm__ volatile(\n\n            \"mov %%\"REG_b\", \"ESP_OFFSET\"(%5)        \\n\\t\"\n\n            \"mov        %4, %%\"REG_b\"               \\n\\t\"\n\n            \"push %%\"REG_BP\"                        \\n\\t\"\n\n            YSCALEYUV2RGB1b(%%REGBP, %5)\n\n            \"pxor    %%mm7, %%mm7                   \\n\\t\"\n\n            /* mm2=B, %%mm4=G, %%mm5=R, %%mm7=0 */\n\n#ifdef DITHER1XBPP\n\n            \"paddusb \"BLUE_DITHER\"(%5), %%mm2      \\n\\t\"\n\n            \"paddusb \"GREEN_DITHER\"(%5), %%mm4      \\n\\t\"\n\n            \"paddusb \"RED_DITHER\"(%5), %%mm5      \\n\\t\"\n\n#endif\n\n            WRITERGB16(%%REGb, 8280(%5), %%REGBP)\n\n            \"pop %%\"REG_BP\"                         \\n\\t\"\n\n            \"mov \"ESP_OFFSET\"(%5), %%\"REG_b\"        \\n\\t\"\n\n            :: \"c\" (buf0), \"d\" (buf1), \"S\" (ubuf0), \"D\" (ubuf1), \"m\" (dest),\n\n               \"a\" (&c->redDither)\n\n        );\n\n    }\n\n}\n", "idx": 23643, "_split": "test", "_hash": "92bf9e04ca88e761b5088f6e3a077285"}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static int do_bit_allocation(AC3DecodeContext *ctx, int flags)\n\n{\n\n    ac3_audio_block *ab = &ctx->audio_block;\n\n    int i, snroffst = 0;\n\n\n\n    if (!flags) /* bit allocation is not required */\n\n        return 0;\n\n\n\n    if (ab->flags & AC3_AB_SNROFFSTE) { /* check whether snroffsts are zero */\n\n        snroffst += ab->csnroffst;\n\n        if (ab->flags & AC3_AB_CPLINU)\n\n            snroffst += ab->cplfsnroffst;\n\n        for (i = 0; i < ctx->bsi.nfchans; i++)\n\n            snroffst += ab->fsnroffst[i];\n\n        if (ctx->bsi.flags & AC3_BSI_LFEON)\n\n            snroffst += ab->lfefsnroffst;\n\n        if (!snroffst) {\n\n            memset(ab->cplbap, 0, sizeof (ab->cplbap));\n\n            for (i = 0; i < ctx->bsi.nfchans; i++)\n\n                memset(ab->bap[i], 0, sizeof (ab->bap[i]));\n\n            memset(ab->lfebap, 0, sizeof (ab->lfebap));\n\n\n\n            return 0;\n\n        }\n\n    }\n\n\n\n    /* perform bit allocation */\n\n    if ((ab->flags & AC3_AB_CPLINU) && (flags & 64))\n\n        if (_do_bit_allocation(ctx, 5))\n\n            return -1;\n\n    for (i = 0; i < ctx->bsi.nfchans; i++)\n\n        if (flags & (1 << i))\n\n            if (_do_bit_allocation(ctx, i))\n\n                return -1;\n\n    if ((ctx->bsi.flags & AC3_BSI_LFEON) && (flags & 32))\n\n        if (_do_bit_allocation(ctx, 6))\n\n            return -1;\n\n\n\n    return 0;\n\n}\n", "idx": 23668, "_split": "test", "_hash": "ff9d93a23a4723d6226ba02da07ede5a"}
{"project": "FFmpeg", "commit_id": "94bb1ce882a12b6d7a1fa32715a68121b39ee838", "target": 0, "func": "static int revert_channel_correlation(ALSDecContext *ctx, ALSBlockData *bd,\n\n                                       ALSChannelData **cd, int *reverted,\n\n                                       unsigned int offset, int c)\n\n{\n\n    ALSChannelData *ch = cd[c];\n\n    unsigned int   dep = 0;\n\n    unsigned int channels = ctx->avctx->channels;\n\n\n\n    if (reverted[c])\n\n        return 0;\n\n\n\n    reverted[c] = 1;\n\n\n\n    while (dep < channels && !ch[dep].stop_flag) {\n\n        revert_channel_correlation(ctx, bd, cd, reverted, offset,\n\n                                   ch[dep].master_channel);\n\n\n\n        dep++;\n\n    }\n\n\n\n    if (dep == channels) {\n\n        av_log(ctx->avctx, AV_LOG_WARNING, \"Invalid channel correlation!\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    bd->const_block = ctx->const_block + c;\n\n    bd->shift_lsbs  = ctx->shift_lsbs + c;\n\n    bd->opt_order   = ctx->opt_order + c;\n\n    bd->store_prev_samples = ctx->store_prev_samples + c;\n\n    bd->use_ltp     = ctx->use_ltp + c;\n\n    bd->ltp_lag     = ctx->ltp_lag + c;\n\n    bd->ltp_gain    = ctx->ltp_gain[c];\n\n    bd->lpc_cof     = ctx->lpc_cof[c];\n\n    bd->quant_cof   = ctx->quant_cof[c];\n\n    bd->raw_samples = ctx->raw_samples[c] + offset;\n\n\n\n    dep = 0;\n\n    while (!ch[dep].stop_flag) {\n\n        unsigned int smp;\n\n        unsigned int begin = 1;\n\n        unsigned int end   = bd->block_length - 1;\n\n        int64_t y;\n\n        int32_t *master = ctx->raw_samples[ch[dep].master_channel] + offset;\n\n\n\n        if (ch[dep].time_diff_flag) {\n\n            int t = ch[dep].time_diff_index;\n\n\n\n            if (ch[dep].time_diff_sign) {\n\n                t      = -t;\n\n                begin -= t;\n\n            } else {\n\n                end   -= t;\n\n            }\n\n\n\n            for (smp = begin; smp < end; smp++) {\n\n                y  = (1 << 6) +\n\n                     MUL64(ch[dep].weighting[0], master[smp - 1    ]) +\n\n                     MUL64(ch[dep].weighting[1], master[smp        ]) +\n\n                     MUL64(ch[dep].weighting[2], master[smp + 1    ]) +\n\n                     MUL64(ch[dep].weighting[3], master[smp - 1 + t]) +\n\n                     MUL64(ch[dep].weighting[4], master[smp     + t]) +\n\n                     MUL64(ch[dep].weighting[5], master[smp + 1 + t]);\n\n\n\n                bd->raw_samples[smp] += y >> 7;\n\n            }\n\n        } else {\n\n            for (smp = begin; smp < end; smp++) {\n\n                y  = (1 << 6) +\n\n                     MUL64(ch[dep].weighting[0], master[smp - 1]) +\n\n                     MUL64(ch[dep].weighting[1], master[smp    ]) +\n\n                     MUL64(ch[dep].weighting[2], master[smp + 1]);\n\n\n\n                bd->raw_samples[smp] += y >> 7;\n\n            }\n\n        }\n\n\n\n        dep++;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23692, "_split": "test", "_hash": "5f33767b4b6612d0f669cb44243f2bed"}
{"project": "FFmpeg", "commit_id": "0058584580b87feb47898e60e4b80c7f425882ad", "target": 0, "func": "static inline void downmix_3f_1r_to_mono(float *samples)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 256; i++) {\n\n        samples[i] += (samples[i + 256] + samples[i + 512] + samples[i + 768]);\n\n        samples[i + 256] = samples[i + 512] = samples[i + 768] = 0;\n\n    }\n\n}\n", "idx": 23704, "_split": "test", "_hash": "d014d7acfac5c2b2e57419ecfe2dbc5d"}
{"project": "FFmpeg", "commit_id": "cd1047f3911fa0d34c86f470537f343d23c8b956", "target": 0, "func": "static int qsv_decode_init(AVCodecContext *avctx, QSVContext *q)\n\n{\n\n    const AVPixFmtDescriptor *desc;\n\n    mfxSession session = NULL;\n\n    int iopattern = 0;\n\n    mfxVideoParam param = { { 0 } };\n\n    int frame_width  = avctx->coded_width;\n\n    int frame_height = avctx->coded_height;\n\n    int ret;\n\n\n\n    desc = av_pix_fmt_desc_get(avctx->sw_pix_fmt);\n\n    if (!desc)\n\n        return AVERROR_BUG;\n\n\n\n    if (!q->async_fifo) {\n\n        q->async_fifo = av_fifo_alloc((1 + q->async_depth) *\n\n                                      (sizeof(mfxSyncPoint*) + sizeof(QSVFrame*)));\n\n        if (!q->async_fifo)\n\n            return AVERROR(ENOMEM);\n\n    }\n\n\n\n    if (avctx->pix_fmt == AV_PIX_FMT_QSV && avctx->hwaccel_context) {\n\n        AVQSVContext *user_ctx = avctx->hwaccel_context;\n\n        session           = user_ctx->session;\n\n        iopattern         = user_ctx->iopattern;\n\n        q->ext_buffers    = user_ctx->ext_buffers;\n\n        q->nb_ext_buffers = user_ctx->nb_ext_buffers;\n\n    }\n\n\n\n    if (avctx->hw_frames_ctx) {\n\n        AVHWFramesContext    *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n\n        AVQSVFramesContext *frames_hwctx = frames_ctx->hwctx;\n\n\n\n        if (!iopattern) {\n\n            if (frames_hwctx->frame_type & MFX_MEMTYPE_OPAQUE_FRAME)\n\n                iopattern = MFX_IOPATTERN_OUT_OPAQUE_MEMORY;\n\n            else if (frames_hwctx->frame_type & MFX_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET)\n\n                iopattern = MFX_IOPATTERN_OUT_VIDEO_MEMORY;\n\n        }\n\n\n\n        frame_width  = frames_hwctx->surfaces[0].Info.Width;\n\n        frame_height = frames_hwctx->surfaces[0].Info.Height;\n\n    }\n\n\n\n    if (!iopattern)\n\n        iopattern = MFX_IOPATTERN_OUT_SYSTEM_MEMORY;\n\n    q->iopattern = iopattern;\n\n\n\n    ret = qsv_init_session(avctx, q, session, avctx->hw_frames_ctx);\n\n    if (ret < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing an MFX session\\n\");\n\n        return ret;\n\n    }\n\n\n\n    ret = ff_qsv_codec_id_to_mfx(avctx->codec_id);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    param.mfx.CodecId      = ret;\n\n    param.mfx.CodecProfile = avctx->profile;\n\n    param.mfx.CodecLevel   = avctx->level;\n\n\n\n    param.mfx.FrameInfo.BitDepthLuma   = desc->comp[0].depth;\n\n    param.mfx.FrameInfo.BitDepthChroma = desc->comp[0].depth;\n\n    param.mfx.FrameInfo.Shift          = desc->comp[0].depth > 8;\n\n    param.mfx.FrameInfo.FourCC         = q->fourcc;\n\n    param.mfx.FrameInfo.Width          = frame_width;\n\n    param.mfx.FrameInfo.Height         = frame_height;\n\n    param.mfx.FrameInfo.ChromaFormat   = MFX_CHROMAFORMAT_YUV420;\n\n\n\n    param.IOPattern   = q->iopattern;\n\n    param.AsyncDepth  = q->async_depth;\n\n    param.ExtParam    = q->ext_buffers;\n\n    param.NumExtParam = q->nb_ext_buffers;\n\n\n\n    ret = MFXVideoDECODE_Init(q->session, &param);\n\n    if (ret < 0)\n\n        return ff_qsv_print_error(avctx, ret,\n\n                                  \"Error initializing the MFX video decoder\");\n\n\n\n    q->frame_info = param.mfx.FrameInfo;\n\n\n\n    return 0;\n\n}\n", "idx": 23714, "_split": "test", "_hash": "77ac087713bde2dc15c86dcb6841f28f"}
{"project": "FFmpeg", "commit_id": "5705dc527687fd84d94c934169b6bd753459744f", "target": 1, "func": "int av_image_check_sar(unsigned int w, unsigned int h, AVRational sar)\n\n{\n\n    int64_t scaled_dim;\n\n\n\n    if (!sar.den)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (!sar.num || sar.num == sar.den)\n\n        return 0;\n\n\n\n    if (sar.num < sar.den)\n\n        scaled_dim = av_rescale_rnd(w, sar.num, sar.den, AV_ROUND_ZERO);\n\n    else\n\n        scaled_dim = av_rescale_rnd(h, sar.den, sar.num, AV_ROUND_ZERO);\n\n\n\n    if (scaled_dim > 0)\n\n        return 0;\n\n\n\n    return AVERROR(EINVAL);\n\n}\n", "idx": 23762, "_split": "test", "_hash": "075b5083ea85a168731ef281ae9e939a"}
{"project": "FFmpeg", "commit_id": "ba47d519e537299179d20b9a599c5824589a3f7a", "target": 1, "func": "static void decode_gray_bitstream(HYuvContext *s, int count)\n\n{\n\n    int i;\n\n    OPEN_READER(re, &s->gb);\n\n    count /= 2;\n\n\n\n    if (count >= (get_bits_left(&s->gb)) / (32 * 2)) {\n\n        for (i = 0; i < count && get_bits_left(&s->gb) > 0; i++) {\n\n            READ_2PIX(s->temp[0][2 * i], s->temp[0][2 * i + 1], 0);\n\n        }\n\n    } else {\n\n        for (i = 0; i < count; i++) {\n\n            READ_2PIX(s->temp[0][2 * i], s->temp[0][2 * i + 1], 0);\n\n        }\n\n    }\n\n    CLOSE_READER(re, &s->gb);\n\n}\n", "idx": 23769, "_split": "test", "_hash": "e90db4630a2e4c260d8638c0e48ab98d"}
{"project": "FFmpeg", "commit_id": "8cd1c0febe88b757e915e9af15559575c21ca728", "target": 1, "func": "static int pcx_decode_frame(AVCodecContext *avctx, void *data, int *data_size,\n\n                            AVPacket *avpkt) {\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    PCXContext * const s = avctx->priv_data;\n\n    AVFrame *picture = data;\n\n    AVFrame * const p = &s->picture;\n\n    int compressed, xmin, ymin, xmax, ymax;\n\n    unsigned int w, h, bits_per_pixel, bytes_per_line, nplanes, stride, y, x,\n\n                 bytes_per_scanline;\n\n    uint8_t *ptr;\n\n    uint8_t const *bufstart = buf;\n\n    uint8_t *scanline;\n\n    int ret = -1;\n\n\n\n    if (buf[0] != 0x0a || buf[1] > 5) {\n\n        av_log(avctx, AV_LOG_ERROR, \"this is not PCX encoded data\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    compressed = buf[2];\n\n    xmin = AV_RL16(buf+ 4);\n\n    ymin = AV_RL16(buf+ 6);\n\n    xmax = AV_RL16(buf+ 8);\n\n    ymax = AV_RL16(buf+10);\n\n\n\n    if (xmax < xmin || ymax < ymin) {\n\n        av_log(avctx, AV_LOG_ERROR, \"invalid image dimensions\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    w = xmax - xmin + 1;\n\n    h = ymax - ymin + 1;\n\n\n\n    bits_per_pixel     = buf[3];\n\n    bytes_per_line     = AV_RL16(buf+66);\n\n    nplanes            = buf[65];\n\n    bytes_per_scanline = nplanes * bytes_per_line;\n\n\n\n    if (bytes_per_scanline < w * bits_per_pixel * nplanes / 8) {\n\n        av_log(avctx, AV_LOG_ERROR, \"PCX data is corrupted\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch ((nplanes<<8) + bits_per_pixel) {\n\n        case 0x0308:\n\n            avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n            break;\n\n        case 0x0108:\n\n        case 0x0104:\n\n        case 0x0102:\n\n        case 0x0101:\n\n        case 0x0401:\n\n        case 0x0301:\n\n        case 0x0201:\n\n            avctx->pix_fmt = AV_PIX_FMT_PAL8;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid PCX file\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    buf += 128;\n\n\n\n    if (p->data[0])\n\n        avctx->release_buffer(avctx, p);\n\n\n\n    if (av_image_check_size(w, h, 0, avctx))\n\n        return AVERROR_INVALIDDATA;\n\n    if (w != avctx->width || h != avctx->height)\n\n        avcodec_set_dimensions(avctx, w, h);\n\n    if ((ret = avctx->get_buffer(avctx, p)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    p->pict_type = AV_PICTURE_TYPE_I;\n\n\n\n    ptr    = p->data[0];\n\n    stride = p->linesize[0];\n\n\n\n    scanline = av_malloc(bytes_per_scanline);\n\n    if (!scanline)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (nplanes == 3 && bits_per_pixel == 8) {\n\n        for (y=0; y<h; y++) {\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n\n\n            for (x=0; x<w; x++) {\n\n                ptr[3*x  ] = scanline[x                    ];\n\n                ptr[3*x+1] = scanline[x+ bytes_per_line    ];\n\n                ptr[3*x+2] = scanline[x+(bytes_per_line<<1)];\n\n            }\n\n\n\n            ptr += stride;\n\n        }\n\n\n\n    } else if (nplanes == 1 && bits_per_pixel == 8) {\n\n        const uint8_t *palstart = bufstart + buf_size - 769;\n\n\n\n        for (y=0; y<h; y++, ptr+=stride) {\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n            memcpy(ptr, scanline, w);\n\n        }\n\n\n\n        if (buf != palstart) {\n\n            av_log(avctx, AV_LOG_WARNING, \"image data possibly corrupted\\n\");\n\n            buf = palstart;\n\n        }\n\n        if (*buf++ != 12) {\n\n            av_log(avctx, AV_LOG_ERROR, \"expected palette after image data\\n\");\n\n            ret = AVERROR_INVALIDDATA;\n\n            goto end;\n\n        }\n\n\n\n    } else if (nplanes == 1) {   /* all packed formats, max. 16 colors */\n\n        GetBitContext s;\n\n\n\n        for (y=0; y<h; y++) {\n\n            init_get_bits(&s, scanline, bytes_per_scanline<<3);\n\n\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n\n\n            for (x=0; x<w; x++)\n\n                ptr[x] = get_bits(&s, bits_per_pixel);\n\n            ptr += stride;\n\n        }\n\n\n\n    } else {    /* planar, 4, 8 or 16 colors */\n\n        int i;\n\n\n\n        for (y=0; y<h; y++) {\n\n            buf = pcx_rle_decode(buf, scanline, bytes_per_scanline, compressed);\n\n\n\n            for (x=0; x<w; x++) {\n\n                int m = 0x80 >> (x&7), v = 0;\n\n                for (i=nplanes - 1; i>=0; i--) {\n\n                    v <<= 1;\n\n                    v  += !!(scanline[i*bytes_per_line + (x>>3)] & m);\n\n                }\n\n                ptr[x] = v;\n\n            }\n\n            ptr += stride;\n\n        }\n\n    }\n\n\n\n    if (nplanes == 1 && bits_per_pixel == 8) {\n\n        pcx_palette(&buf, (uint32_t *) p->data[1], 256);\n\n    } else if (bits_per_pixel * nplanes == 1) {\n\n        AV_WN32A(p->data[1]  , 0xFF000000);\n\n        AV_WN32A(p->data[1]+4, 0xFFFFFFFF);\n\n    } else if (bits_per_pixel < 8) {\n\n        const uint8_t *palette = bufstart+16;\n\n        pcx_palette(&palette, (uint32_t *) p->data[1], 16);\n\n    }\n\n\n\n    *picture = s->picture;\n\n    *data_size = sizeof(AVFrame);\n\n\n\n    ret = buf - bufstart;\n\nend:\n\n    av_free(scanline);\n\n    return ret;\n\n}\n", "idx": 23786, "_split": "test", "_hash": "946d133dc46ca47ba117415b3b10b230"}
{"project": "FFmpeg", "commit_id": "f1e173049ecc9de03817385ba8962d14cba779db", "target": 0, "func": "static void dequantization_int(int x, int y, Jpeg2000Cblk *cblk,\n\n                               Jpeg2000Component *comp,\n\n                               Jpeg2000T1Context *t1, Jpeg2000Band *band)\n\n{\n\n    int i, j;\n\n    int w = cblk->coord[0][1] - cblk->coord[0][0];\n\n    for (j = 0; j < (cblk->coord[1][1] - cblk->coord[1][0]); ++j) {\n\n        int32_t *datap = &comp->i_data[(comp->coord[0][1] - comp->coord[0][0]) * (y + j) + x];\n\n        int *src = t1->data[j];\n\n        if (band->i_stepsize == 16384) {\n\n            for (i = 0; i < w; ++i)\n\n                datap[i] = src[i] / 2;\n\n        } else {\n\n            // This should be VERY uncommon\n\n            for (i = 0; i < w; ++i)\n\n                datap[i] = (src[i] * (int64_t)band->i_stepsize) / 32768;\n\n        }\n\n    }\n\n}\n", "idx": 23854, "_split": "test", "_hash": "74e0f35a51791aaf9e42938254ea68b8"}
{"project": "FFmpeg", "commit_id": "80a5d05108cb218e8cd2e25c6621a3bfef0a832e", "target": 0, "func": "static int vaapi_encode_h265_init_sequence_params(AVCodecContext *avctx)\n\n{\n\n    VAAPIEncodeContext                 *ctx = avctx->priv_data;\n\n    VAEncSequenceParameterBufferHEVC  *vseq = ctx->codec_sequence_params;\n\n    VAEncPictureParameterBufferHEVC   *vpic = ctx->codec_picture_params;\n\n    VAAPIEncodeH265Context            *priv = ctx->priv_data;\n\n    VAAPIEncodeH265MiscSequenceParams *mseq = &priv->misc_sequence_params;\n\n    int i;\n\n\n\n    {\n\n        // general_profile_space == 0.\n\n        vseq->general_profile_idc = 1; // Main profile (ctx->codec_profile?)\n\n        vseq->general_tier_flag = 0;\n\n\n\n        vseq->general_level_idc = avctx->level * 3;\n\n\n\n        vseq->intra_period = 0;\n\n        vseq->intra_idr_period = 0;\n\n        vseq->ip_period = 0;\n\n\n\n        vseq->pic_width_in_luma_samples  = ctx->aligned_width;\n\n        vseq->pic_height_in_luma_samples = ctx->aligned_height;\n\n\n\n        vseq->seq_fields.bits.chroma_format_idc = 1; // 4:2:0.\n\n        vseq->seq_fields.bits.separate_colour_plane_flag = 0;\n\n        vseq->seq_fields.bits.bit_depth_luma_minus8 = 0; // 8-bit luma.\n\n        vseq->seq_fields.bits.bit_depth_chroma_minus8 = 0; // 8-bit chroma.\n\n        // Other misc flags all zero.\n\n\n\n        // These have to come from the capabilities of the encoder.  We have\n\n        // no way to query it, so just hardcode ones which worked for me...\n\n        // CTB size from 8x8 to 32x32.\n\n        vseq->log2_min_luma_coding_block_size_minus3 = 0;\n\n        vseq->log2_diff_max_min_luma_coding_block_size = 2;\n\n        // Transform size from 4x4 to 32x32.\n\n        vseq->log2_min_transform_block_size_minus2 = 0;\n\n        vseq->log2_diff_max_min_transform_block_size = 3;\n\n        // Full transform hierarchy allowed (2-5).\n\n        vseq->max_transform_hierarchy_depth_inter = 3;\n\n        vseq->max_transform_hierarchy_depth_intra = 3;\n\n\n\n        vseq->vui_parameters_present_flag = 0;\n\n\n\n        vseq->bits_per_second = avctx->bit_rate;\n\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0) {\n\n            vseq->vui_num_units_in_tick = avctx->framerate.num;\n\n            vseq->vui_time_scale        = avctx->framerate.den;\n\n        } else {\n\n            vseq->vui_num_units_in_tick = avctx->time_base.num;\n\n            vseq->vui_time_scale        = avctx->time_base.den;\n\n        }\n\n\n\n        vseq->intra_period     = ctx->p_per_i * (ctx->b_per_p + 1);\n\n        vseq->intra_idr_period = vseq->intra_period;\n\n        vseq->ip_period        = ctx->b_per_p + 1;\n\n    }\n\n\n\n    {\n\n        vpic->decoded_curr_pic.picture_id = VA_INVALID_ID;\n\n        vpic->decoded_curr_pic.flags      = VA_PICTURE_HEVC_INVALID;\n\n\n\n        for (i = 0; i < FF_ARRAY_ELEMS(vpic->reference_frames); i++) {\n\n            vpic->reference_frames[i].picture_id = VA_INVALID_ID;\n\n            vpic->reference_frames[i].flags      = VA_PICTURE_HEVC_INVALID;\n\n        }\n\n\n\n        vpic->collocated_ref_pic_index = 0xff;\n\n\n\n        vpic->last_picture = 0;\n\n\n\n        vpic->pic_init_qp = priv->fixed_qp_idr;\n\n\n\n        vpic->diff_cu_qp_delta_depth = 0;\n\n        vpic->pps_cb_qp_offset = 0;\n\n        vpic->pps_cr_qp_offset = 0;\n\n\n\n        // tiles_enabled_flag == 0, so ignore num_tile_(rows|columns)_minus1.\n\n\n\n        vpic->log2_parallel_merge_level_minus2 = 0;\n\n\n\n        // No limit on size.\n\n        vpic->ctu_max_bitsize_allowed = 0;\n\n\n\n        vpic->num_ref_idx_l0_default_active_minus1 = 0;\n\n        vpic->num_ref_idx_l1_default_active_minus1 = 0;\n\n\n\n        vpic->slice_pic_parameter_set_id = 0;\n\n\n\n        vpic->pic_fields.bits.screen_content_flag = 0;\n\n        vpic->pic_fields.bits.enable_gpu_weighted_prediction = 0;\n\n\n\n        // Per-CU QP changes are required for non-constant-QP modes.\n\n        vpic->pic_fields.bits.cu_qp_delta_enabled_flag =\n\n            ctx->va_rc_mode != VA_RC_CQP;\n\n    }\n\n\n\n    {\n\n        mseq->video_parameter_set_id = 5;\n\n        mseq->seq_parameter_set_id = 5;\n\n\n\n        mseq->vps_max_layers_minus1 = 0;\n\n        mseq->vps_max_sub_layers_minus1 = 0;\n\n        mseq->vps_temporal_id_nesting_flag = 1;\n\n        mseq->sps_max_sub_layers_minus1 = 0;\n\n        mseq->sps_temporal_id_nesting_flag = 1;\n\n\n\n        for (i = 0; i < 32; i++) {\n\n            mseq->general_profile_compatibility_flag[i] =\n\n                (i == vseq->general_profile_idc);\n\n        }\n\n\n\n        mseq->general_progressive_source_flag    = 1;\n\n        mseq->general_interlaced_source_flag     = 0;\n\n        mseq->general_non_packed_constraint_flag = 0;\n\n        mseq->general_frame_only_constraint_flag = 1;\n\n        mseq->general_inbld_flag = 0;\n\n\n\n        mseq->log2_max_pic_order_cnt_lsb_minus4 = 8;\n\n        mseq->vps_sub_layer_ordering_info_present_flag = 0;\n\n        mseq->vps_max_dec_pic_buffering_minus1[0] = 1;\n\n        mseq->vps_max_num_reorder_pics[0]         = ctx->b_per_p;\n\n        mseq->vps_max_latency_increase_plus1[0]   = 0;\n\n        mseq->sps_sub_layer_ordering_info_present_flag = 0;\n\n        mseq->sps_max_dec_pic_buffering_minus1[0] = 1;\n\n        mseq->sps_max_num_reorder_pics[0]         = ctx->b_per_p;\n\n        mseq->sps_max_latency_increase_plus1[0]   = 0;\n\n\n\n        mseq->vps_timing_info_present_flag = 1;\n\n        mseq->vps_num_units_in_tick = avctx->time_base.num;\n\n        mseq->vps_time_scale        = avctx->time_base.den;\n\n        mseq->vps_poc_proportional_to_timing_flag = 1;\n\n        mseq->vps_num_ticks_poc_diff_minus1 = 0;\n\n\n\n        if (ctx->input_width  != ctx->aligned_width ||\n\n            ctx->input_height != ctx->aligned_height) {\n\n            mseq->conformance_window_flag = 1;\n\n            mseq->conf_win_left_offset   = 0;\n\n            mseq->conf_win_right_offset  =\n\n                (ctx->aligned_width - ctx->input_width) / 2;\n\n            mseq->conf_win_top_offset    = 0;\n\n            mseq->conf_win_bottom_offset =\n\n                (ctx->aligned_height - ctx->input_height) / 2;\n\n        } else {\n\n            mseq->conformance_window_flag = 0;\n\n        }\n\n\n\n        mseq->num_short_term_ref_pic_sets = 0;\n\n        // STRPSs should ideally be here rather than repeated in each slice.\n\n\n\n        mseq->vui_parameters_present_flag = 1;\n\n        if (avctx->sample_aspect_ratio.num != 0) {\n\n            mseq->aspect_ratio_info_present_flag = 1;\n\n            if (avctx->sample_aspect_ratio.num ==\n\n                avctx->sample_aspect_ratio.den) {\n\n                mseq->aspect_ratio_idc = 1;\n\n            } else {\n\n                mseq->aspect_ratio_idc = 255; // Extended SAR.\n\n                mseq->sar_width  = avctx->sample_aspect_ratio.num;\n\n                mseq->sar_height = avctx->sample_aspect_ratio.den;\n\n            }\n\n        }\n\n        if (1) {\n\n            // Should this be conditional on some of these being set?\n\n            mseq->video_signal_type_present_flag = 1;\n\n            mseq->video_format = 5; // Unspecified.\n\n            mseq->video_full_range_flag = 0;\n\n            mseq->colour_description_present_flag = 1;\n\n            mseq->colour_primaries = avctx->color_primaries;\n\n            mseq->transfer_characteristics = avctx->color_trc;\n\n            mseq->matrix_coeffs = avctx->colorspace;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 23870, "_split": "test", "_hash": "6808b3b5990dd406f9d809f15ebc538f"}
{"project": "FFmpeg", "commit_id": "0780ad9c688cc8272daa7780d3f112a9f55208ca", "target": 0, "func": "static void rdft_calc_c(RDFTContext *s, FFTSample *data)\n\n{\n\n    int i, i1, i2;\n\n    FFTComplex ev, od;\n\n    const int n = 1 << s->nbits;\n\n    const float k1 = 0.5;\n\n    const float k2 = 0.5 - s->inverse;\n\n    const FFTSample *tcos = s->tcos;\n\n    const FFTSample *tsin = s->tsin;\n\n\n\n    if (!s->inverse) {\n\n        s->fft.fft_permute(&s->fft, (FFTComplex*)data);\n\n        s->fft.fft_calc(&s->fft, (FFTComplex*)data);\n\n    }\n\n    /* i=0 is a special case because of packing, the DC term is real, so we\n\n       are going to throw the N/2 term (also real) in with it. */\n\n    ev.re = data[0];\n\n    data[0] = ev.re+data[1];\n\n    data[1] = ev.re-data[1];\n\n    for (i = 1; i < (n>>2); i++) {\n\n        i1 = 2*i;\n\n        i2 = n-i1;\n\n        /* Separate even and odd FFTs */\n\n        ev.re =  k1*(data[i1  ]+data[i2  ]);\n\n        od.im = -k2*(data[i1  ]-data[i2  ]);\n\n        ev.im =  k1*(data[i1+1]-data[i2+1]);\n\n        od.re =  k2*(data[i1+1]+data[i2+1]);\n\n        /* Apply twiddle factors to the odd FFT and add to the even FFT */\n\n        data[i1  ] =  ev.re + od.re*tcos[i] - od.im*tsin[i];\n\n        data[i1+1] =  ev.im + od.im*tcos[i] + od.re*tsin[i];\n\n        data[i2  ] =  ev.re - od.re*tcos[i] + od.im*tsin[i];\n\n        data[i2+1] = -ev.im + od.im*tcos[i] + od.re*tsin[i];\n\n    }\n\n    data[2*i+1]=s->sign_convention*data[2*i+1];\n\n    if (s->inverse) {\n\n        data[0] *= k1;\n\n        data[1] *= k1;\n\n        s->fft.fft_permute(&s->fft, (FFTComplex*)data);\n\n        s->fft.fft_calc(&s->fft, (FFTComplex*)data);\n\n    }\n\n}\n", "idx": 23872, "_split": "test", "_hash": "1f0bdc502dc1d78bb22e424527fb3f4a"}
{"project": "FFmpeg", "commit_id": "aca490777f9da2a71b537874ed4e16105bb3df02", "target": 0, "func": "static av_cold int g726_init(AVCodecContext * avctx)\n\n{\n\n    AVG726Context* c = (AVG726Context*)avctx->priv_data;\n\n    unsigned int index= (avctx->bit_rate + avctx->sample_rate/2) / avctx->sample_rate - 2;\n\n\n\n    if (\n\n        (avctx->bit_rate != 16000 && avctx->bit_rate != 24000 &&\n\n         avctx->bit_rate != 32000 && avctx->bit_rate != 40000)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"G726: unsupported audio format\\n\");\n\n        return -1;\n\n    }\n\n    if (avctx->sample_rate != 8000 && avctx->strict_std_compliance>FF_COMPLIANCE_INOFFICIAL) {\n\n        av_log(avctx, AV_LOG_ERROR, \"G726: unsupported audio format\\n\");\n\n        return -1;\n\n    }\n\n    if(avctx->channels != 1){\n\n        av_log(avctx, AV_LOG_ERROR, \"Only mono is supported\\n\");\n\n        return -1;\n\n    }\n\n    if(index>3){\n\n        av_log(avctx, AV_LOG_ERROR, \"Unsupported number of bits %d\\n\", index+2);\n\n        return -1;\n\n    }\n\n    g726_reset(&c->c, index);\n\n    c->code_size = c->c.tbls->bits;\n\n    c->bit_buffer = 0;\n\n    c->bits_left = 0;\n\n\n\n    avctx->coded_frame = avcodec_alloc_frame();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n    avctx->coded_frame->key_frame = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 23877, "_split": "test", "_hash": "faf556adb769eda3d78ea1f9cfaee913"}
{"project": "FFmpeg", "commit_id": "cd19c677cb5dcaecc472c021bd38370817740a5e", "target": 1, "func": "static int decode_frame(AVCodecContext *avctx, \n\n                             void *data, int *data_size,\n\n                             uint8_t *buf, int buf_size)\n\n{\n\n    H264Context *h = avctx->priv_data;\n\n    MpegEncContext *s = &h->s;\n\n    AVFrame *pict = data; \n\n    int buf_index;\n\n    \n\n    s->flags= avctx->flags;\n\n    s->flags2= avctx->flags2;\n\n\n\n   /* no supplementary picture */\n\n    if (buf_size == 0) {\n\n        return 0;\n\n    }\n\n    \n\n    if(s->flags&CODEC_FLAG_TRUNCATED){\n\n        int next= find_frame_end(h, buf, buf_size);\n\n        \n\n        if( ff_combine_frame(&s->parse_context, next, &buf, &buf_size) < 0 )\n\n            return buf_size;\n\n//printf(\"next:%d buf_size:%d last_index:%d\\n\", next, buf_size, s->parse_context.last_index);\n\n    }\n\n\n\n    if(h->is_avc && !h->got_avcC) {\n\n        int i, cnt, nalsize;\n\n        unsigned char *p = avctx->extradata;\n\n        if(avctx->extradata_size < 7) {\n\n            av_log(avctx, AV_LOG_ERROR, \"avcC too short\\n\");\n\n            return -1;\n\n        }\n\n        if(*p != 1) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unknown avcC version %d\\n\", *p);\n\n            return -1;\n\n        }\n\n        /* sps and pps in the avcC always have length coded with 2 bytes,\n\n           so put a fake nal_length_size = 2 while parsing them */\n\n        h->nal_length_size = 2;\n\n        // Decode sps from avcC\n\n        cnt = *(p+5) & 0x1f; // Number of sps\n\n        p += 6;\n\n        for (i = 0; i < cnt; i++) {\n\n            nalsize = BE_16(p) + 2;\n\n            if(decode_nal_units(h, p, nalsize) < 0) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Decoding sps %d from avcC failed\\n\", i);\n\n                return -1;\n\n            }\n\n            p += nalsize;\n\n        }        \n\n        // Decode pps from avcC\n\n        cnt = *(p++); // Number of pps\n\n        for (i = 0; i < cnt; i++) {\n\n            nalsize = BE_16(p) + 2;\n\n            if(decode_nal_units(h, p, nalsize)  != nalsize) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Decoding pps %d from avcC failed\\n\", i);\n\n                return -1;\n\n            }\n\n            p += nalsize;\n\n        }        \n\n        // Now store right nal length size, that will be use to parse all other nals\n\n        h->nal_length_size = ((*(((char*)(avctx->extradata))+4))&0x03)+1;\n\n        // Do not reparse avcC\n\n        h->got_avcC = 1;\n\n    }\n\n\n\n    if(!h->is_avc && s->avctx->extradata_size && s->picture_number==0){\n\n        if(decode_nal_units(h, s->avctx->extradata, s->avctx->extradata_size) < 0) \n\n            return -1;\n\n    }\n\n\n\n    buf_index=decode_nal_units(h, buf, buf_size);\n\n    if(buf_index < 0) \n\n        return -1;\n\n\n\n    //FIXME do something with unavailable reference frames    \n\n \n\n//    if(ret==FRAME_SKIPPED) return get_consumed_bytes(s, buf_index, buf_size);\n\n    if(!s->current_picture_ptr){\n\n        av_log(h->s.avctx, AV_LOG_DEBUG, \"error, NO frame\\n\");\n\n        return -1;\n\n    }\n\n\n\n    {\n\n        Picture *out = s->current_picture_ptr;\n\n#if 0 //decode order\n\n        *data_size = sizeof(AVFrame);\n\n#else\n\n        /* Sort B-frames into display order */\n\n        Picture *cur = s->current_picture_ptr;\n\n        Picture *prev = h->delayed_output_pic;\n\n        int out_idx = 0;\n\n        int pics = 0;\n\n        int out_of_order;\n\n        int cross_idr = 0;\n\n        int dropped_frame = 0;\n\n        int i;\n\n\n\n        if(h->sps.bitstream_restriction_flag\n\n           && s->avctx->has_b_frames < h->sps.num_reorder_frames){\n\n            s->avctx->has_b_frames = h->sps.num_reorder_frames;\n\n            s->low_delay = 0;\n\n        }\n\n\n\n        while(h->delayed_pic[pics]) pics++;\n\n        h->delayed_pic[pics++] = cur;\n\n        if(cur->reference == 0)\n\n            cur->reference = 1;\n\n\n\n        for(i=0; h->delayed_pic[i]; i++)\n\n            if(h->delayed_pic[i]->key_frame || h->delayed_pic[i]->poc==0)\n\n                cross_idr = 1;\n\n\n\n        out = h->delayed_pic[0];\n\n        for(i=1; h->delayed_pic[i] && !h->delayed_pic[i]->key_frame; i++)\n\n            if(h->delayed_pic[i]->poc < out->poc){\n\n                out = h->delayed_pic[i];\n\n                out_idx = i;\n\n            }\n\n\n\n        out_of_order = !cross_idr && prev && out->poc < prev->poc;\n\n        if(prev && pics <= s->avctx->has_b_frames)\n\n            out = prev;\n\n        else if((out_of_order && pics-1 == s->avctx->has_b_frames)\n\n           || (s->low_delay && \n\n            ((!cross_idr && prev && out->poc > prev->poc + 2)\n\n             || cur->pict_type == B_TYPE)))\n\n        {\n\n            s->low_delay = 0;\n\n            s->avctx->has_b_frames++;\n\n            out = prev;\n\n        }\n\n        else if(out_of_order)\n\n            out = prev;\n\n\n\n        if(out_of_order || pics > s->avctx->has_b_frames){\n\n            dropped_frame = (out != h->delayed_pic[out_idx]);\n\n            for(i=out_idx; h->delayed_pic[i]; i++)\n\n                h->delayed_pic[i] = h->delayed_pic[i+1];\n\n        }\n\n\n\n        if(prev == out && !dropped_frame)\n\n            *data_size = 0;\n\n        else\n\n            *data_size = sizeof(AVFrame);\n\n        if(prev && prev != out && prev->reference == 1)\n\n            prev->reference = 0;\n\n        h->delayed_output_pic = out;\n\n#endif\n\n\n\n        *pict= *(AVFrame*)out;\n\n    }\n\n\n\n    assert(pict->data[0]);\n\n    ff_print_debug_info(s, pict);\n\n//printf(\"out %d\\n\", (int)pict->data[0]);\n\n#if 0 //?\n\n\n\n    /* Return the Picture timestamp as the frame number */\n\n    /* we substract 1 because it is added on utils.c    */\n\n    avctx->frame_number = s->picture_number - 1;\n\n#endif\n\n    return get_consumed_bytes(s, buf_index, buf_size);\n\n}\n", "idx": 24018, "_split": "test", "_hash": "88b1df79545dc4db7a3650c597ddc842"}
{"project": "FFmpeg", "commit_id": "48e52e4edd12adbc36eee0eebe1b97ffe0255be3", "target": 0, "func": "static int nvenc_find_free_reg_resource(AVCodecContext *avctx)\n\n{\n\n    NvencContext *ctx = avctx->priv_data;\n\n    NvencDynLoadFunctions *dl_fn = &ctx->nvenc_dload_funcs;\n\n    NV_ENCODE_API_FUNCTION_LIST *p_nvenc = &dl_fn->nvenc_funcs;\n\n\n\n    int i;\n\n\n\n    if (ctx->nb_registered_frames == FF_ARRAY_ELEMS(ctx->registered_frames)) {\n\n        for (i = 0; i < ctx->nb_registered_frames; i++) {\n\n            if (!ctx->registered_frames[i].mapped) {\n\n                if (ctx->registered_frames[i].regptr) {\n\n                    p_nvenc->nvEncUnregisterResource(ctx->nvencoder,\n\n                                                ctx->registered_frames[i].regptr);\n\n                    ctx->registered_frames[i].regptr = NULL;\n\n                }\n\n                return i;\n\n            }\n\n        }\n\n    } else {\n\n        return ctx->nb_registered_frames++;\n\n    }\n\n\n\n    av_log(avctx, AV_LOG_ERROR, \"Too many registered CUDA frames\\n\");\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 24072, "_split": "test", "_hash": "9a15490e428450a423151bf9b6cbc5d7"}
{"project": "FFmpeg", "commit_id": "70f9661542a581dfe93b636b1c55b5558e4a4e3c", "target": 0, "func": "static int jpeg2000_decode_frame(AVCodecContext *avctx, void *data,\n\n                                 int *got_frame, AVPacket *avpkt)\n\n{\n\n    Jpeg2000DecoderContext *s = avctx->priv_data;\n\n    ThreadFrame frame = { .f = data };\n\n    AVFrame *picture = data;\n\n    int tileno, ret;\n\n\n\n    s->avctx     = avctx;\n\n    s->buf       = s->buf_start = avpkt->data;\n\n    s->buf_end   = s->buf_start + avpkt->size;\n\n    s->curtileno = 0; // TODO: only one tile in DCI JP2K. to implement for more tiles\n\n\n\n    // reduction factor, i.e number of resolution levels to skip\n\n    s->reduction_factor = s->lowres;\n\n\n\n    ff_jpeg2000_init_tier1_luts();\n\n\n\n    if (s->buf_end - s->buf < 2)\n\n        return AVERROR(EINVAL);\n\n\n\n    // check if the image is in jp2 format\n\n    if ((AV_RB32(s->buf) == 12) &&\n\n        (AV_RB32(s->buf + 4) == JP2_SIG_TYPE) &&\n\n        (AV_RB32(s->buf + 8) == JP2_SIG_VALUE)) {\n\n        if (!jp2_find_codestream(s)) {\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"couldn't find jpeg2k codestream atom\\n\");\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    if (bytestream_get_be16(&s->buf) != JPEG2000_SOC) {\n\n        av_log(avctx, AV_LOG_ERROR, \"SOC marker not present\\n\");\n\n        return -1;\n\n    }\n\n    if (ret = jpeg2000_read_main_headers(s))\n\n        goto end;\n\n\n\n    /* get picture buffer */\n\n    if ((ret = ff_thread_get_buffer(avctx, &frame, 0)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"ff_thread_get_buffer() failed.\\n\");\n\n        goto end;\n\n    }\n\n    picture->pict_type = AV_PICTURE_TYPE_I;\n\n    picture->key_frame = 1;\n\n\n\n    if (ret = jpeg2000_read_bitstream_packets(s))\n\n        goto end;\n\n    for (tileno = 0; tileno < s->numXtiles * s->numYtiles; tileno++)\n\n        if (ret = jpeg2000_decode_tile(s, s->tile + tileno, picture))\n\n            goto end;\n\n\n\n    *got_frame = 1;\n\n\n\nend:\n\n    jpeg2000_dec_cleanup(s);\n\n    return ret ? ret : s->buf - s->buf_start;\n\n}\n", "idx": 24148, "_split": "test", "_hash": "43cc6b40013d44d6ba6515bc295bcac6"}
{"project": "FFmpeg", "commit_id": "1dba8371d93cf1c83bcd5c432d921905206a60f3", "target": 0, "func": "int ffurl_connect(URLContext *uc, AVDictionary **options)\n\n{\n\n    int err =\n\n        uc->prot->url_open2 ? uc->prot->url_open2(uc,\n\n                                                  uc->filename,\n\n                                                  uc->flags,\n\n                                                  options) :\n\n        uc->prot->url_open(uc, uc->filename, uc->flags);\n\n    if (err)\n\n        return err;\n\n    uc->is_connected = 1;\n\n    /* We must be careful here as ffurl_seek() could be slow,\n\n     * for example for http */\n\n    if ((uc->flags & AVIO_FLAG_WRITE) || !strcmp(uc->prot->name, \"file\"))\n\n        if (!uc->is_streamed && ffurl_seek(uc, 0, SEEK_SET) < 0)\n\n            uc->is_streamed = 1;\n\n    return 0;\n\n}\n", "idx": 24205, "_split": "test", "_hash": "244670ddd5eaf8408447c459c8aa2e43"}
{"project": "FFmpeg", "commit_id": "86dfcfd0e30d6645eea2c63c1c60a0550e7c97ea", "target": 1, "func": "static int read_kuki_chunk(AVFormatContext *s, int64_t size)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st      = s->streams[0];\n\n\n\n    if (size < 0 || size > INT_MAX - FF_INPUT_BUFFER_PADDING_SIZE)\n\n        return -1;\n\n\n\n    if (st->codec->codec_id == AV_CODEC_ID_AAC) {\n\n        /* The magic cookie format for AAC is an mp4 esds atom.\n\n           The lavc AAC decoder requires the data from the codec specific\n\n           description as extradata input. */\n\n        int strt, skip;\n\n        MOVAtom atom;\n\n\n\n        strt = avio_tell(pb);\n\n        ff_mov_read_esds(s, pb, atom);\n\n        skip = size - (avio_tell(pb) - strt);\n\n        if (skip < 0 || !st->codec->extradata ||\n\n            st->codec->codec_id != AV_CODEC_ID_AAC) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid AAC magic cookie\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        avio_skip(pb, skip);\n\n    } else if (st->codec->codec_id == AV_CODEC_ID_ALAC) {\n\n#define ALAC_PREAMBLE 12\n\n#define ALAC_HEADER   36\n\n#define ALAC_NEW_KUKI 24\n\n        uint8_t preamble[12];\n\n        if (size < ALAC_NEW_KUKI) {\n\n            av_log(s, AV_LOG_ERROR, \"invalid ALAC magic cookie\\n\");\n\n            avio_skip(pb, size);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n        avio_read(pb, preamble, ALAC_PREAMBLE);\n\n\n\n        st->codec->extradata = av_mallocz(ALAC_HEADER + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!st->codec->extradata)\n\n            return AVERROR(ENOMEM);\n\n\n\n        /* For the old style cookie, we skip 12 bytes, then read 36 bytes.\n\n         * The new style cookie only contains the last 24 bytes of what was\n\n         * 36 bytes in the old style cookie, so we fabricate the first 12 bytes\n\n         * in that case to maintain compatibility. */\n\n        if (!memcmp(&preamble[4], \"frmaalac\", 8)) {\n\n            if (size < ALAC_PREAMBLE + ALAC_HEADER) {\n\n                av_log(s, AV_LOG_ERROR, \"invalid ALAC magic cookie\\n\");\n\n                av_freep(&st->codec->extradata);\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n            avio_read(pb, st->codec->extradata, ALAC_HEADER);\n\n            avio_skip(pb, size - ALAC_PREAMBLE - ALAC_HEADER);\n\n        } else {\n\n            AV_WB32(st->codec->extradata, 36);\n\n            memcpy(&st->codec->extradata[4], \"alac\", 4);\n\n            AV_WB32(&st->codec->extradata[8], 0);\n\n            memcpy(&st->codec->extradata[12], preamble, 12);\n\n            avio_read(pb, &st->codec->extradata[24], ALAC_NEW_KUKI - 12);\n\n            avio_skip(pb, size - ALAC_NEW_KUKI);\n\n        }\n\n        st->codec->extradata_size = ALAC_HEADER;\n\n    } else {\n\n        st->codec->extradata = av_mallocz(size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!st->codec->extradata)\n\n            return AVERROR(ENOMEM);\n\n        avio_read(pb, st->codec->extradata, size);\n\n        st->codec->extradata_size = size;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24230, "_split": "test", "_hash": "1bf7c57f209fa7bb8c94a8fd4d8925b0"}
{"project": "FFmpeg", "commit_id": "ddfa3751c092feaf1e080f66587024689dfe603c", "target": 1, "func": "static int decode_codestream(J2kDecoderContext *s)\n\n{\n\n    J2kCodingStyle *codsty = s->codsty;\n\n    J2kQuantStyle  *qntsty = s->qntsty;\n\n    uint8_t *properties = s->properties;\n\n\n\n    for (;;){\n\n        int marker, len, ret = 0;\n\n        const uint8_t *oldbuf;\n\n        if (s->buf_end - s->buf < 2){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"Missing EOC\\n\");\n\n            break;\n\n        }\n\n\n\n        marker = bytestream_get_be16(&s->buf);\n\n        if(s->avctx->debug & FF_DEBUG_STARTCODE)\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"marker 0x%.4X at pos 0x%tx\\n\", marker, s->buf - s->buf_start - 4);\n\n        oldbuf = s->buf;\n\n\n\n        if (marker == J2K_SOD){\n\n            J2kTile *tile = s->tile + s->curtileno;\n\n            if (ret = init_tile(s, s->curtileno))\n\n                return ret;\n\n            if (ret = decode_packets(s, tile))\n\n                return ret;\n\n            continue;\n\n        }\n\n        if (marker == J2K_EOC)\n\n            break;\n\n\n\n        if (s->buf_end - s->buf < 2)\n\n            return AVERROR(EINVAL);\n\n        len = bytestream_get_be16(&s->buf);\n\n        switch(marker){\n\n            case J2K_SIZ:\n\n                ret = get_siz(s); break;\n\n            case J2K_COC:\n\n                ret = get_coc(s, codsty, properties); break;\n\n            case J2K_COD:\n\n                ret = get_cod(s, codsty, properties); break;\n\n            case J2K_QCC:\n\n                ret = get_qcc(s, len, qntsty, properties); break;\n\n            case J2K_QCD:\n\n                ret = get_qcd(s, len, qntsty, properties); break;\n\n            case J2K_SOT:\n\n                if (!(ret = get_sot(s))){\n\n                    codsty = s->tile[s->curtileno].codsty;\n\n                    qntsty = s->tile[s->curtileno].qntsty;\n\n                    properties = s->tile[s->curtileno].properties;\n\n                }\n\n                break;\n\n            case J2K_COM:\n\n                // the comment is ignored\n\n                s->buf += len - 2; break;\n\n            default:\n\n                av_log(s->avctx, AV_LOG_ERROR, \"unsupported marker 0x%.4X at pos 0x%tx\\n\", marker, s->buf - s->buf_start - 4);\n\n                s->buf += len - 2; break;\n\n        }\n\n        if (s->buf - oldbuf != len || ret){\n\n            av_log(s->avctx, AV_LOG_ERROR, \"error during processing marker segment %.4x\\n\", marker);\n\n            return ret ? ret : -1;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 24244, "_split": "test", "_hash": "87c5bb8aac20f17ea21f99cf96958901"}
{"project": "FFmpeg", "commit_id": "9745f19ffc9031ce480e43d7cf1053b58100d70f", "target": 0, "func": "static av_cold int ass_decode_init(AVCodecContext *avctx)\n\n{\n\n    avctx->subtitle_header = av_malloc(avctx->extradata_size);\n\n    if (!avctx->extradata)\n\n        return AVERROR(ENOMEM);\n\n    memcpy(avctx->subtitle_header, avctx->extradata, avctx->extradata_size);\n\n    avctx->subtitle_header_size = avctx->extradata_size;\n\n    return 0;\n\n}\n", "idx": 24269, "_split": "test", "_hash": "74f80af2c44c294206893aac560ba61d"}
{"project": "FFmpeg", "commit_id": "ad5807f8aa883bee5431186dc1f24c5435d722d3", "target": 1, "func": "static int wsd_read_header(AVFormatContext *s)\n\n{\n\n    AVIOContext *pb = s->pb;\n\n    AVStream *st;\n\n    int version;\n\n    uint32_t text_offset, data_offset, channel_assign;\n\n    char playback_time[AV_TIMECODE_STR_SIZE];\n\n\n\n    st = avformat_new_stream(s, NULL);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avio_skip(pb, 8);\n\n    version = avio_r8(pb);\n\n    av_log(s, AV_LOG_DEBUG, \"version: %i.%i\\n\", version >> 4, version & 0xF);\n\n    avio_skip(pb, 11);\n\n\n\n    if (version < 0x10) {\n\n        text_offset = 0x80;\n\n        data_offset = 0x800;\n\n        avio_skip(pb, 8);\n\n    } else {\n\n        text_offset = avio_rb32(pb);\n\n        data_offset = avio_rb32(pb);\n\n    }\n\n\n\n    avio_skip(pb, 4);\n\n    av_timecode_make_smpte_tc_string(playback_time, avio_rb32(pb), 0);\n\n    av_dict_set(&s->metadata, \"playback_time\", playback_time, 0);\n\n\n\n    st->codecpar->codec_type  = AVMEDIA_TYPE_AUDIO;\n\n    st->codecpar->codec_id    = s->iformat->raw_codec_id;\n\n    st->codecpar->sample_rate = avio_rb32(pb) / 8;\n\n    avio_skip(pb, 4);\n\n    st->codecpar->channels    = avio_r8(pb) & 0xF;\n\n    st->codecpar->bit_rate    = st->codecpar->channels * st->codecpar->sample_rate * 8LL;\n\n    if (!st->codecpar->channels)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    avio_skip(pb, 3);\n\n    channel_assign         = avio_rb32(pb);\n\n    if (!(channel_assign & 1)) {\n\n        int i;\n\n        for (i = 1; i < 32; i++)\n\n            if (channel_assign & (1 << i))\n\n                st->codecpar->channel_layout |= wsd_to_av_channel_layoyt(s, i);\n\n    }\n\n\n\n    avio_skip(pb, 16);\n\n    if (avio_rb32(pb))\n\n       avpriv_request_sample(s, \"emphasis\");\n\n\n\n    if (avio_seek(pb, text_offset, SEEK_SET) >= 0) {\n\n        get_metadata(s, \"title\",       128);\n\n        get_metadata(s, \"composer\",    128);\n\n        get_metadata(s, \"song_writer\", 128);\n\n        get_metadata(s, \"artist\",      128);\n\n        get_metadata(s, \"album\",       128);\n\n        get_metadata(s, \"genre\",        32);\n\n        get_metadata(s, \"date\",         32);\n\n        get_metadata(s, \"location\",     32);\n\n        get_metadata(s, \"comment\",     512);\n\n        get_metadata(s, \"user\",        512);\n\n    }\n\n\n\n    return avio_seek(pb, data_offset, SEEK_SET);\n\n}\n", "idx": 24283, "_split": "test", "_hash": "ba7f911f0c805f784dc0088ce165f2fd"}
{"project": "FFmpeg", "commit_id": "16c6795465fd7663792fe535256c760560714863", "target": 0, "func": "x11grab_read_header(AVFormatContext *s1)\n\n{\n\n    struct x11grab *x11grab = s1->priv_data;\n\n    Display *dpy;\n\n    AVStream *st = NULL;\n\n    enum AVPixelFormat input_pixfmt;\n\n    XImage *image;\n\n    int x_off = 0;\n\n    int y_off = 0;\n\n    int screen;\n\n    int use_shm;\n\n    char *dpyname, *offset;\n\n    int ret = 0;\n\n    Colormap color_map;\n\n    XColor color[256];\n\n    int i;\n\n\n\n    dpyname = av_strdup(s1->filename);\n\n    if (!dpyname)\n\n        goto out;\n\n\n\n    offset = strchr(dpyname, '+');\n\n    if (offset) {\n\n        sscanf(offset, \"%d,%d\", &x_off, &y_off);\n\n        if (strstr(offset, \"nomouse\")) {\n\n            av_log(s1, AV_LOG_WARNING,\n\n                   \"'nomouse' specification in argument is deprecated: \"\n\n                   \"use 'draw_mouse' option with value 0 instead\\n\");\n\n            x11grab->draw_mouse = 0;\n\n        }\n\n        *offset= 0;\n\n    }\n\n\n\n    av_log(s1, AV_LOG_INFO, \"device: %s -> display: %s x: %d y: %d width: %d height: %d\\n\",\n\n           s1->filename, dpyname, x_off, y_off, x11grab->width, x11grab->height);\n\n\n\n    dpy = XOpenDisplay(dpyname);\n\n    av_freep(&dpyname);\n\n    if(!dpy) {\n\n        av_log(s1, AV_LOG_ERROR, \"Could not open X display.\\n\");\n\n        ret = AVERROR(EIO);\n\n        goto out;\n\n    }\n\n\n\n    st = avformat_new_stream(s1, NULL);\n\n    if (!st) {\n\n        ret = AVERROR(ENOMEM);\n\n        goto out;\n\n    }\n\n    avpriv_set_pts_info(st, 64, 1, 1000000); /* 64 bits pts in us */\n\n\n\n    screen = DefaultScreen(dpy);\n\n\n\n    if (x11grab->follow_mouse) {\n\n        int screen_w, screen_h;\n\n        Window w;\n\n\n\n        screen_w = DisplayWidth(dpy, screen);\n\n        screen_h = DisplayHeight(dpy, screen);\n\n        XQueryPointer(dpy, RootWindow(dpy, screen), &w, &w, &x_off, &y_off, &ret, &ret, &ret);\n\n        x_off -= x11grab->width / 2;\n\n        y_off -= x11grab->height / 2;\n\n        x_off = FFMIN(FFMAX(x_off, 0), screen_w - x11grab->width);\n\n        y_off = FFMIN(FFMAX(y_off, 0), screen_h - x11grab->height);\n\n        av_log(s1, AV_LOG_INFO, \"followmouse is enabled, resetting grabbing region to x: %d y: %d\\n\", x_off, y_off);\n\n    }\n\n\n\n    use_shm = XShmQueryExtension(dpy);\n\n    av_log(s1, AV_LOG_INFO, \"shared memory extension%s found\\n\", use_shm ? \"\" : \" not\");\n\n\n\n    if(use_shm) {\n\n        int scr = XDefaultScreen(dpy);\n\n        image = XShmCreateImage(dpy,\n\n                                DefaultVisual(dpy, scr),\n\n                                DefaultDepth(dpy, scr),\n\n                                ZPixmap,\n\n                                NULL,\n\n                                &x11grab->shminfo,\n\n                                x11grab->width, x11grab->height);\n\n        x11grab->shminfo.shmid = shmget(IPC_PRIVATE,\n\n                                        image->bytes_per_line * image->height,\n\n                                        IPC_CREAT|0777);\n\n        if (x11grab->shminfo.shmid == -1) {\n\n            av_log(s1, AV_LOG_ERROR, \"Fatal: Can't get shared memory!\\n\");\n\n            ret = AVERROR(ENOMEM);\n\n            goto out;\n\n        }\n\n        x11grab->shminfo.shmaddr = image->data = shmat(x11grab->shminfo.shmid, 0, 0);\n\n        x11grab->shminfo.readOnly = False;\n\n\n\n        if (!XShmAttach(dpy, &x11grab->shminfo)) {\n\n            av_log(s1, AV_LOG_ERROR, \"Fatal: Failed to attach shared memory!\\n\");\n\n            /* needs some better error subroutine :) */\n\n            ret = AVERROR(EIO);\n\n            goto out;\n\n        }\n\n    } else {\n\n        image = XGetImage(dpy, RootWindow(dpy, screen),\n\n                          x_off,y_off,\n\n                          x11grab->width, x11grab->height,\n\n                          AllPlanes, ZPixmap);\n\n    }\n\n\n\n    switch (image->bits_per_pixel) {\n\n    case 8:\n\n        av_log (s1, AV_LOG_DEBUG, \"8 bit palette\\n\");\n\n        input_pixfmt = AV_PIX_FMT_PAL8;\n\n        color_map = DefaultColormap(dpy, screen);\n\n        for (i = 0; i < 256; ++i)\n\n            color[i].pixel = i;\n\n        XQueryColors(dpy, color_map, color, 256);\n\n        for (i = 0; i < 256; ++i)\n\n            x11grab->palette[i] = (color[i].red   & 0xFF00) << 8 |\n\n                                  (color[i].green & 0xFF00)      |\n\n                                  (color[i].blue  & 0xFF00) >> 8;\n\n        x11grab->palette_changed = 1;\n\n        break;\n\n    case 16:\n\n        if (       image->red_mask   == 0xf800 &&\n\n                   image->green_mask == 0x07e0 &&\n\n                   image->blue_mask  == 0x001f ) {\n\n            av_log (s1, AV_LOG_DEBUG, \"16 bit RGB565\\n\");\n\n            input_pixfmt = AV_PIX_FMT_RGB565;\n\n        } else if (image->red_mask   == 0x7c00 &&\n\n                   image->green_mask == 0x03e0 &&\n\n                   image->blue_mask  == 0x001f ) {\n\n            av_log(s1, AV_LOG_DEBUG, \"16 bit RGB555\\n\");\n\n            input_pixfmt = AV_PIX_FMT_RGB555;\n\n        } else {\n\n            av_log(s1, AV_LOG_ERROR, \"RGB ordering at image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n            av_log(s1, AV_LOG_ERROR, \"color masks: r 0x%.6lx g 0x%.6lx b 0x%.6lx\\n\", image->red_mask, image->green_mask, image->blue_mask);\n\n            ret = AVERROR_PATCHWELCOME;\n\n            goto out;\n\n        }\n\n        break;\n\n    case 24:\n\n        if (        image->red_mask   == 0xff0000 &&\n\n                    image->green_mask == 0x00ff00 &&\n\n                    image->blue_mask  == 0x0000ff ) {\n\n            input_pixfmt = AV_PIX_FMT_BGR24;\n\n        } else if ( image->red_mask   == 0x0000ff &&\n\n                    image->green_mask == 0x00ff00 &&\n\n                    image->blue_mask  == 0xff0000 ) {\n\n            input_pixfmt = AV_PIX_FMT_RGB24;\n\n        } else {\n\n            av_log(s1, AV_LOG_ERROR,\"rgb ordering at image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n            av_log(s1, AV_LOG_ERROR, \"color masks: r 0x%.6lx g 0x%.6lx b 0x%.6lx\\n\", image->red_mask, image->green_mask, image->blue_mask);\n\n            ret = AVERROR_PATCHWELCOME;\n\n            goto out;\n\n        }\n\n        break;\n\n    case 32:\n\n        input_pixfmt = AV_PIX_FMT_0RGB32;\n\n        break;\n\n    default:\n\n        av_log(s1, AV_LOG_ERROR, \"image depth %i not supported ... aborting\\n\", image->bits_per_pixel);\n\n        ret = AVERROR_PATCHWELCOME;\n\n        goto out;\n\n    }\n\n\n\n    x11grab->frame_size = x11grab->width * x11grab->height * image->bits_per_pixel/8;\n\n    x11grab->dpy = dpy;\n\n    x11grab->time_base  = av_inv_q(x11grab->framerate);\n\n    x11grab->time_frame = av_gettime() / av_q2d(x11grab->time_base);\n\n    x11grab->x_off = x_off;\n\n    x11grab->y_off = y_off;\n\n    x11grab->image = image;\n\n    x11grab->use_shm = use_shm;\n\n\n\n    st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n    st->codec->codec_id = AV_CODEC_ID_RAWVIDEO;\n\n    st->codec->width  = x11grab->width;\n\n    st->codec->height = x11grab->height;\n\n    st->codec->pix_fmt = input_pixfmt;\n\n    st->codec->time_base = x11grab->time_base;\n\n    st->codec->bit_rate = x11grab->frame_size * 1/av_q2d(x11grab->time_base) * 8;\n\n\n\nout:\n\n    av_free(dpyname);\n\n    return ret;\n\n}\n", "idx": 24289, "_split": "test", "_hash": "1bccfda9324ae1b724c621bd55ead59d"}
{"project": "FFmpeg", "commit_id": "b8664c929437d6d079e16979c496a2db40cf2324", "target": 0, "func": "static void vp8_h_loop_filter_simple_c(uint8_t *dst, ptrdiff_t stride, int flim)\n\n{\n\n    int i;\n\n\n\n    for (i = 0; i < 16; i++)\n\n        if (simple_limit(dst+i*stride, 1, flim))\n\n            filter_common(dst+i*stride, 1, 1);\n\n}\n", "idx": 24291, "_split": "test", "_hash": "1effdc0ff1913373253f4f34ec9be597"}
{"project": "FFmpeg", "commit_id": "7cf22c79706d23d40d16cee37eb32d5797adcc2c", "target": 0, "func": "yuv2rgba64_1_c_template(SwsContext *c, const int32_t *buf0,\n\n                       const int32_t *ubuf[2], const int32_t *vbuf[2],\n\n                       const int32_t *abuf0, uint16_t *dest, int dstW,\n\n                       int uvalpha, int y, enum AVPixelFormat target, int hasAlpha, int eightbytes)\n\n{\n\n    const int32_t *ubuf0 = ubuf[0], *vbuf0 = vbuf[0];\n\n    int i;\n\n    int A1 = 0xffff<<14, A2= 0xffff<<14;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < ((dstW + 1) >> 1); i++) {\n\n            int Y1 = (buf0[i * 2]    ) >> 2;\n\n            int Y2 = (buf0[i * 2 + 1]) >> 2;\n\n            int U  = (ubuf0[i] + (-128 << 11)) >> 2;\n\n            int V  = (vbuf0[i] + (-128 << 11)) >> 2;\n\n            int R, G, B;\n\n\n\n            Y1 -= c->yuv2rgb_y_offset;\n\n            Y2 -= c->yuv2rgb_y_offset;\n\n            Y1 *= c->yuv2rgb_y_coeff;\n\n            Y2 *= c->yuv2rgb_y_coeff;\n\n            Y1 += 1 << 13;\n\n            Y2 += 1 << 13;\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] << 11;\n\n                A2 = abuf0[i * 2 + 1] << 11;\n\n\n\n                A1 += 1 << 13;\n\n                A2 += 1 << 13;\n\n            }\n\n\n\n            R = V * c->yuv2rgb_v2r_coeff;\n\n            G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n            B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n            output_pixel(&dest[0], av_clip_uintp2(R_B + Y1, 30) >> 14);\n\n            output_pixel(&dest[1], av_clip_uintp2(  G + Y1, 30) >> 14);\n\n            output_pixel(&dest[2], av_clip_uintp2(B_R + Y1, 30) >> 14);\n\n            if (eightbytes) {\n\n                output_pixel(&dest[3], av_clip_uintp2(A1      , 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[6], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                output_pixel(&dest[7], av_clip_uintp2(A2      , 30) >> 14);\n\n                dest += 8;\n\n            } else {\n\n                output_pixel(&dest[3], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                dest += 6;\n\n            }\n\n        }\n\n    } else {\n\n        const int32_t *ubuf1 = ubuf[1], *vbuf1 = vbuf[1];\n\n        int A1 = 0xffff<<14, A2 = 0xffff<<14;\n\n        for (i = 0; i < ((dstW + 1) >> 1); i++) {\n\n            int Y1 = (buf0[i * 2]    ) >> 2;\n\n            int Y2 = (buf0[i * 2 + 1]) >> 2;\n\n            int U  = (ubuf0[i] + ubuf1[i] + (-128 << 12)) >> 3;\n\n            int V  = (vbuf0[i] + vbuf1[i] + (-128 << 12)) >> 3;\n\n            int R, G, B;\n\n\n\n            Y1 -= c->yuv2rgb_y_offset;\n\n            Y2 -= c->yuv2rgb_y_offset;\n\n            Y1 *= c->yuv2rgb_y_coeff;\n\n            Y2 *= c->yuv2rgb_y_coeff;\n\n            Y1 += 1 << 13;\n\n            Y2 += 1 << 13;\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] << 11;\n\n                A2 = abuf0[i * 2 + 1] << 11;\n\n\n\n                A1 += 1 << 13;\n\n                A2 += 1 << 13;\n\n            }\n\n\n\n            R = V * c->yuv2rgb_v2r_coeff;\n\n            G = V * c->yuv2rgb_v2g_coeff + U * c->yuv2rgb_u2g_coeff;\n\n            B =                            U * c->yuv2rgb_u2b_coeff;\n\n\n\n            output_pixel(&dest[0], av_clip_uintp2(R_B + Y1, 30) >> 14);\n\n            output_pixel(&dest[1], av_clip_uintp2(  G + Y1, 30) >> 14);\n\n            output_pixel(&dest[2], av_clip_uintp2(B_R + Y1, 30) >> 14);\n\n            if (eightbytes) {\n\n                output_pixel(&dest[3], av_clip_uintp2(A1      , 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[6], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                output_pixel(&dest[7], av_clip_uintp2(A2      , 30) >> 14);\n\n                dest += 8;\n\n            } else {\n\n                output_pixel(&dest[3], av_clip_uintp2(R_B + Y2, 30) >> 14);\n\n                output_pixel(&dest[4], av_clip_uintp2(  G + Y2, 30) >> 14);\n\n                output_pixel(&dest[5], av_clip_uintp2(B_R + Y2, 30) >> 14);\n\n                dest += 6;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24356, "_split": "test", "_hash": "5c4edb511755eea5a8af287d0e20f1d1"}
{"project": "FFmpeg", "commit_id": "e549933a270dd2cfc36f2cf9bb6b29acf3dc6d08", "target": 0, "func": "static void avc_luma_mid_8w_msa(const uint8_t *src, int32_t src_stride,\n\n                                uint8_t *dst, int32_t dst_stride,\n\n                                int32_t height)\n\n{\n\n    uint32_t loop_cnt;\n\n    v16i8 src0, src1, src2, src3, src4;\n\n    v16i8 mask0, mask1, mask2;\n\n    v8i16 hz_out0, hz_out1, hz_out2, hz_out3;\n\n    v8i16 hz_out4, hz_out5, hz_out6, hz_out7, hz_out8;\n\n    v8i16 dst0, dst1, dst2, dst3;\n\n    v16u8 out0, out1;\n\n\n\n    LD_SB3(&luma_mask_arr[0], 16, mask0, mask1, mask2);\n\n\n\n    LD_SB5(src, src_stride, src0, src1, src2, src3, src4);\n\n    XORI_B5_128_SB(src0, src1, src2, src3, src4);\n\n    src += (5 * src_stride);\n\n\n\n    hz_out0 = AVC_HORZ_FILTER_SH(src0, src0, mask0, mask1, mask2);\n\n    hz_out1 = AVC_HORZ_FILTER_SH(src1, src1, mask0, mask1, mask2);\n\n    hz_out2 = AVC_HORZ_FILTER_SH(src2, src2, mask0, mask1, mask2);\n\n    hz_out3 = AVC_HORZ_FILTER_SH(src3, src3, mask0, mask1, mask2);\n\n    hz_out4 = AVC_HORZ_FILTER_SH(src4, src4, mask0, mask1, mask2);\n\n\n\n    for (loop_cnt = (height >> 2); loop_cnt--;) {\n\n        LD_SB4(src, src_stride, src0, src1, src2, src3);\n\n        XORI_B4_128_SB(src0, src1, src2, src3);\n\n        src += (4 * src_stride);\n\n\n\n        hz_out5 = AVC_HORZ_FILTER_SH(src0, src0, mask0, mask1, mask2);\n\n        hz_out6 = AVC_HORZ_FILTER_SH(src1, src1, mask0, mask1, mask2);\n\n        hz_out7 = AVC_HORZ_FILTER_SH(src2, src2, mask0, mask1, mask2);\n\n        hz_out8 = AVC_HORZ_FILTER_SH(src3, src3, mask0, mask1, mask2);\n\n        dst0 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out0, hz_out1, hz_out2,\n\n                                               hz_out3, hz_out4, hz_out5);\n\n        dst1 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out1, hz_out2, hz_out3,\n\n                                               hz_out4, hz_out5, hz_out6);\n\n        dst2 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out2, hz_out3, hz_out4,\n\n                                               hz_out5, hz_out6, hz_out7);\n\n        dst3 = AVC_CALC_DPADD_H_6PIX_2COEFF_SH(hz_out3, hz_out4, hz_out5,\n\n                                               hz_out6, hz_out7, hz_out8);\n\n        out0 = PCKEV_XORI128_UB(dst0, dst1);\n\n        out1 = PCKEV_XORI128_UB(dst2, dst3);\n\n        ST8x4_UB(out0, out1, dst, dst_stride);\n\n\n\n        dst += (4 * dst_stride);\n\n        hz_out3 = hz_out7;\n\n        hz_out1 = hz_out5;\n\n        hz_out5 = hz_out4;\n\n        hz_out4 = hz_out8;\n\n        hz_out2 = hz_out6;\n\n        hz_out0 = hz_out5;\n\n    }\n\n}\n", "idx": 24368, "_split": "test", "_hash": "e6c19614714b6634affe34eeb1d25b56"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int pam_encode_close(AVCodecContext *avctx)\n\n{\n\n    av_frame_free(&avctx->coded_frame);\n\n    return 0;\n\n}\n", "idx": 24371, "_split": "test", "_hash": "fd7ee2b2a678305b57d9a05f487bd6f0"}
{"project": "FFmpeg", "commit_id": "6f600ab35424823fb682b5669241edcc66590a8d", "target": 0, "func": "static av_cold int oggvorbis_init_encoder(vorbis_info *vi, AVCodecContext *avccontext)\n\n{\n\n    OggVorbisContext *context = avccontext->priv_data;\n\n    double cfreq;\n\n\n\n    if (avccontext->flags & CODEC_FLAG_QSCALE) {\n\n        /* variable bitrate */\n\n        if (vorbis_encode_setup_vbr(vi, avccontext->channels,\n\n                                    avccontext->sample_rate,\n\n                                    avccontext->global_quality / (float)FF_QP2LAMBDA / 10.0))\n\n            return -1;\n\n    } else {\n\n        int minrate = avccontext->rc_min_rate > 0 ? avccontext->rc_min_rate : -1;\n\n        int maxrate = avccontext->rc_min_rate > 0 ? avccontext->rc_max_rate : -1;\n\n\n\n        /* constant bitrate */\n\n        if (vorbis_encode_setup_managed(vi, avccontext->channels,\n\n                                        avccontext->sample_rate, minrate,\n\n                                        avccontext->bit_rate, maxrate))\n\n            return -1;\n\n\n\n        /* variable bitrate by estimate, disable slow rate management */\n\n        if (minrate == -1 && maxrate == -1)\n\n            if (vorbis_encode_ctl(vi, OV_ECTL_RATEMANAGE2_SET, NULL))\n\n                return -1;\n\n    }\n\n\n\n    /* cutoff frequency */\n\n    if (avccontext->cutoff > 0) {\n\n        cfreq = avccontext->cutoff / 1000.0;\n\n        if (vorbis_encode_ctl(vi, OV_ECTL_LOWPASS_SET, &cfreq))\n\n            return -1;\n\n    }\n\n\n\n    if (context->iblock) {\n\n        vorbis_encode_ctl(vi, OV_ECTL_IBLOCK_SET, &context->iblock);\n\n    }\n\n\n\n    return vorbis_encode_setup_init(vi);\n\n}\n", "idx": 24375, "_split": "test", "_hash": "758eab8148dd284cac52c73743659bfc"}
{"project": "FFmpeg", "commit_id": "439c3d5bcc4a4560eaf5fd43c6e156e3d9bc42f2", "target": 1, "func": "static int encode_frame(AVCodecContext *avctx, AVPacket *avpkt,\n\n                        const AVFrame *frame, int *got_packet_ptr)\n\n{\n\n    NellyMoserEncodeContext *s = avctx->priv_data;\n\n    int ret;\n\n\n\n    if (s->last_frame)\n\n        return 0;\n\n\n\n    memcpy(s->buf, s->buf + NELLY_SAMPLES, NELLY_BUF_LEN * sizeof(*s->buf));\n\n    if (frame) {\n\n        memcpy(s->buf + NELLY_BUF_LEN, frame->data[0],\n\n               frame->nb_samples * sizeof(*s->buf));\n\n        if (frame->nb_samples < NELLY_SAMPLES) {\n\n            memset(s->buf + NELLY_BUF_LEN + avctx->frame_size, 0,\n\n                   (NELLY_SAMPLES - frame->nb_samples) * sizeof(*s->buf));\n\n            if (frame->nb_samples >= NELLY_BUF_LEN)\n\n                s->last_frame = 1;\n\n        }\n\n        if ((ret = ff_af_queue_add(&s->afq, frame) < 0))\n\n            return ret;\n\n    } else {\n\n        memset(s->buf + NELLY_BUF_LEN, 0, NELLY_SAMPLES * sizeof(*s->buf));\n\n        s->last_frame = 1;\n\n    }\n\n\n\n    if ((ret = ff_alloc_packet(avpkt, NELLY_BLOCK_LEN))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error getting output packet\\n\");\n\n        return ret;\n\n    }\n\n    encode_block(s, avpkt->data, avpkt->size);\n\n\n\n    /* Get the next frame pts/duration */\n\n    ff_af_queue_remove(&s->afq, avctx->frame_size, &avpkt->pts,\n\n                       &avpkt->duration);\n\n\n\n    *got_packet_ptr = 1;\n\n    return 0;\n\n}\n", "idx": 24400, "_split": "test", "_hash": "9f507f567848c48e8a972ccfa0335427"}
{"project": "FFmpeg", "commit_id": "7167bc94cb695a3027aea6aac34a1b040848c7dc", "target": 1, "func": "static void imdct_and_windowing(AACContext *ac, SingleChannelElement *sce, float bias)\n\n{\n\n    IndividualChannelStream *ics = &sce->ics;\n\n    float *in    = sce->coeffs;\n\n    float *out   = sce->ret;\n\n    float *saved = sce->saved;\n\n    const float *swindow      = ics->use_kb_window[0] ? ff_aac_kbd_short_128 : ff_sine_128;\n\n    const float *lwindow_prev = ics->use_kb_window[1] ? ff_aac_kbd_long_1024 : ff_sine_1024;\n\n    const float *swindow_prev = ics->use_kb_window[1] ? ff_aac_kbd_short_128 : ff_sine_128;\n\n    float *buf  = ac->buf_mdct;\n\n    float *temp = ac->temp;\n\n    int i;\n\n\n\n    // imdct\n\n    if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n        if (ics->window_sequence[1] == ONLY_LONG_SEQUENCE || ics->window_sequence[1] == LONG_STOP_SEQUENCE)\n\n            av_log(ac->avctx, AV_LOG_WARNING,\n\n                   \"Transition from an ONLY_LONG or LONG_STOP to an EIGHT_SHORT sequence detected. \"\n\n                   \"If you heard an audible artifact, please submit the sample to the FFmpeg developers.\\n\");\n\n        for (i = 0; i < 1024; i += 128)\n\n            ff_imdct_half(&ac->mdct_small, buf + i, in + i);\n\n    } else\n\n        ff_imdct_half(&ac->mdct, buf, in);\n\n\n\n    /* window overlapping\n\n     * NOTE: To simplify the overlapping code, all 'meaningless' short to long\n\n     * and long to short transitions are considered to be short to short\n\n     * transitions. This leaves just two cases (long to long and short to short)\n\n     * with a little special sauce for EIGHT_SHORT_SEQUENCE.\n\n     */\n\n    if ((ics->window_sequence[1] == ONLY_LONG_SEQUENCE || ics->window_sequence[1] == LONG_STOP_SEQUENCE) &&\n\n            (ics->window_sequence[0] == ONLY_LONG_SEQUENCE || ics->window_sequence[0] == LONG_START_SEQUENCE)) {\n\n        ac->dsp.vector_fmul_window(    out,               saved,            buf,         lwindow_prev, bias, 512);\n\n    } else {\n\n        for (i = 0; i < 448; i++)\n\n            out[i] = saved[i] + bias;\n\n\n\n        if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n            ac->dsp.vector_fmul_window(out + 448 + 0*128, saved + 448,      buf + 0*128, swindow_prev, bias, 64);\n\n            ac->dsp.vector_fmul_window(out + 448 + 1*128, buf + 0*128 + 64, buf + 1*128, swindow,      bias, 64);\n\n            ac->dsp.vector_fmul_window(out + 448 + 2*128, buf + 1*128 + 64, buf + 2*128, swindow,      bias, 64);\n\n            ac->dsp.vector_fmul_window(out + 448 + 3*128, buf + 2*128 + 64, buf + 3*128, swindow,      bias, 64);\n\n            ac->dsp.vector_fmul_window(temp,              buf + 3*128 + 64, buf + 4*128, swindow,      bias, 64);\n\n            memcpy(                    out + 448 + 4*128, temp, 64 * sizeof(float));\n\n        } else {\n\n            ac->dsp.vector_fmul_window(out + 448,         saved + 448,      buf,         swindow_prev, bias, 64);\n\n            for (i = 576; i < 1024; i++)\n\n                out[i] = buf[i-512] + bias;\n\n        }\n\n    }\n\n\n\n    // buffer update\n\n    if (ics->window_sequence[0] == EIGHT_SHORT_SEQUENCE) {\n\n        for (i = 0; i < 64; i++)\n\n            saved[i] = temp[64 + i] - bias;\n\n        ac->dsp.vector_fmul_window(saved + 64,  buf + 4*128 + 64, buf + 5*128, swindow, 0, 64);\n\n        ac->dsp.vector_fmul_window(saved + 192, buf + 5*128 + 64, buf + 6*128, swindow, 0, 64);\n\n        ac->dsp.vector_fmul_window(saved + 320, buf + 6*128 + 64, buf + 7*128, swindow, 0, 64);\n\n        memcpy(                    saved + 448, buf + 7*128 + 64,  64 * sizeof(float));\n\n    } else if (ics->window_sequence[0] == LONG_START_SEQUENCE) {\n\n        memcpy(                    saved,       buf + 512,        448 * sizeof(float));\n\n        memcpy(                    saved + 448, buf + 7*128 + 64,  64 * sizeof(float));\n\n    } else { // LONG_STOP or ONLY_LONG\n\n        memcpy(                    saved,       buf + 512,        512 * sizeof(float));\n\n    }\n\n}\n", "idx": 24424, "_split": "test", "_hash": "9147243ee0f208110f9d091ff1af7274"}
{"project": "FFmpeg", "commit_id": "70d54392f5015b9c6594fcae558f59f952501e3b", "target": 0, "func": "void ff_dsputil_init_alpha(DSPContext* c, AVCodecContext *avctx)\n\n{\n\n    const int high_bit_depth = avctx->bits_per_raw_sample > 8;\n\n\n\n    if (!high_bit_depth) {\n\n    c->put_pixels_tab[0][0] = put_pixels16_axp_asm;\n\n    c->put_pixels_tab[0][1] = put_pixels16_x2_axp;\n\n    c->put_pixels_tab[0][2] = put_pixels16_y2_axp;\n\n    c->put_pixels_tab[0][3] = put_pixels16_xy2_axp;\n\n\n\n    c->put_no_rnd_pixels_tab[0][0] = put_pixels16_axp_asm;\n\n    c->put_no_rnd_pixels_tab[0][1] = put_no_rnd_pixels16_x2_axp;\n\n    c->put_no_rnd_pixels_tab[0][2] = put_no_rnd_pixels16_y2_axp;\n\n    c->put_no_rnd_pixels_tab[0][3] = put_no_rnd_pixels16_xy2_axp;\n\n\n\n    c->avg_pixels_tab[0][0] = avg_pixels16_axp;\n\n    c->avg_pixels_tab[0][1] = avg_pixels16_x2_axp;\n\n    c->avg_pixels_tab[0][2] = avg_pixels16_y2_axp;\n\n    c->avg_pixels_tab[0][3] = avg_pixels16_xy2_axp;\n\n\n\n    c->avg_no_rnd_pixels_tab[0][0] = avg_no_rnd_pixels16_axp;\n\n    c->avg_no_rnd_pixels_tab[0][1] = avg_no_rnd_pixels16_x2_axp;\n\n    c->avg_no_rnd_pixels_tab[0][2] = avg_no_rnd_pixels16_y2_axp;\n\n    c->avg_no_rnd_pixels_tab[0][3] = avg_no_rnd_pixels16_xy2_axp;\n\n\n\n    c->put_pixels_tab[1][0] = put_pixels_axp_asm;\n\n    c->put_pixels_tab[1][1] = put_pixels_x2_axp;\n\n    c->put_pixels_tab[1][2] = put_pixels_y2_axp;\n\n    c->put_pixels_tab[1][3] = put_pixels_xy2_axp;\n\n\n\n    c->put_no_rnd_pixels_tab[1][0] = put_pixels_axp_asm;\n\n    c->put_no_rnd_pixels_tab[1][1] = put_no_rnd_pixels_x2_axp;\n\n    c->put_no_rnd_pixels_tab[1][2] = put_no_rnd_pixels_y2_axp;\n\n    c->put_no_rnd_pixels_tab[1][3] = put_no_rnd_pixels_xy2_axp;\n\n\n\n    c->avg_pixels_tab[1][0] = avg_pixels_axp;\n\n    c->avg_pixels_tab[1][1] = avg_pixels_x2_axp;\n\n    c->avg_pixels_tab[1][2] = avg_pixels_y2_axp;\n\n    c->avg_pixels_tab[1][3] = avg_pixels_xy2_axp;\n\n\n\n    c->avg_no_rnd_pixels_tab[1][0] = avg_no_rnd_pixels_axp;\n\n    c->avg_no_rnd_pixels_tab[1][1] = avg_no_rnd_pixels_x2_axp;\n\n    c->avg_no_rnd_pixels_tab[1][2] = avg_no_rnd_pixels_y2_axp;\n\n    c->avg_no_rnd_pixels_tab[1][3] = avg_no_rnd_pixels_xy2_axp;\n\n\n\n    c->clear_blocks = clear_blocks_axp;\n\n    }\n\n\n\n    /* amask clears all bits that correspond to present features.  */\n\n    if (amask(AMASK_MVI) == 0) {\n\n        c->put_pixels_clamped = put_pixels_clamped_mvi_asm;\n\n        c->add_pixels_clamped = add_pixels_clamped_mvi_asm;\n\n\n\n        if (!high_bit_depth)\n\n            c->get_pixels   = get_pixels_mvi;\n\n        c->diff_pixels      = diff_pixels_mvi;\n\n        c->sad[0]           = pix_abs16x16_mvi_asm;\n\n        c->sad[1]           = pix_abs8x8_mvi;\n\n        c->pix_abs[0][0]    = pix_abs16x16_mvi_asm;\n\n        c->pix_abs[1][0]    = pix_abs8x8_mvi;\n\n        c->pix_abs[0][1]    = pix_abs16x16_x2_mvi;\n\n        c->pix_abs[0][2]    = pix_abs16x16_y2_mvi;\n\n        c->pix_abs[0][3]    = pix_abs16x16_xy2_mvi;\n\n    }\n\n\n\n    put_pixels_clamped_axp_p = c->put_pixels_clamped;\n\n    add_pixels_clamped_axp_p = c->add_pixels_clamped;\n\n\n\n    if (avctx->bits_per_raw_sample <= 8 &&\n\n        (avctx->idct_algo == FF_IDCT_AUTO ||\n\n         avctx->idct_algo == FF_IDCT_SIMPLEALPHA)) {\n\n        c->idct_put = ff_simple_idct_put_axp;\n\n        c->idct_add = ff_simple_idct_add_axp;\n\n        c->idct =     ff_simple_idct_axp;\n\n    }\n\n}\n", "idx": 24426, "_split": "test", "_hash": "2cc12b360ac7bf32a60f36705fa1804a"}
{"project": "FFmpeg", "commit_id": "2bb62455c899cdccbdc2a6ad33f9582008ed9f05", "target": 0, "func": "static char *check_nan_suffix(char *s)\n\n{\n\n    char *start = s;\n\n\n\n    if (*s++ != '(')\n\n        return start;\n\n\n\n    while ((*s >= 'a' && *s <= 'z') || (*s >= 'A' && *s <= 'Z') ||\n\n           (*s >= '0' && *s <= '9') ||  *s == '_')\n\n        s++;\n\n\n\n    return *s == ')' ? s + 1 : start;\n\n}\n", "idx": 24433, "_split": "test", "_hash": "ca2d4dc273393e88108afd080e6598fa"}
{"project": "FFmpeg", "commit_id": "d1916d13e28b87f4b1b214231149e12e1d536b4b", "target": 1, "func": "static void diff_bytes_c(uint8_t *dst, uint8_t *src1, uint8_t *src2, int w){\n\n    long i;\n\n#if !HAVE_FAST_UNALIGNED\n\n    if((long)src2 & (sizeof(long)-1)){\n\n        for(i=0; i+7<w; i+=8){\n\n            dst[i+0] = src1[i+0]-src2[i+0];\n\n            dst[i+1] = src1[i+1]-src2[i+1];\n\n            dst[i+2] = src1[i+2]-src2[i+2];\n\n            dst[i+3] = src1[i+3]-src2[i+3];\n\n            dst[i+4] = src1[i+4]-src2[i+4];\n\n            dst[i+5] = src1[i+5]-src2[i+5];\n\n            dst[i+6] = src1[i+6]-src2[i+6];\n\n            dst[i+7] = src1[i+7]-src2[i+7];\n\n        }\n\n    }else\n\n#endif\n\n    for(i=0; i<=w-sizeof(long); i+=sizeof(long)){\n\n        long a = *(long*)(src1+i);\n\n        long b = *(long*)(src2+i);\n\n        *(long*)(dst+i) = ((a|pb_80) - (b&pb_7f)) ^ ((a^b^pb_80)&pb_80);\n\n    }\n\n    for(; i<w; i++)\n\n        dst[i+0] = src1[i+0]-src2[i+0];\n\n}\n", "idx": 24472, "_split": "test", "_hash": "354143a3af74cbb218ce9e40dc3bd548"}
{"project": "FFmpeg", "commit_id": "cb85779d459c6486acbbf060b3f169779424583e", "target": 0, "func": "static int decode_frame(AVCodecContext *avctx,\n\n                        void *data,\n\n                        int *got_frame,\n\n                        AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size       = avpkt->size;\n\n    DPXContext *const s = avctx->priv_data;\n\n    AVFrame *picture  = data;\n\n    AVFrame *const p = &s->picture;\n\n    uint8_t *ptr[AV_NUM_DATA_POINTERS];\n\n\n\n    unsigned int offset;\n\n    int magic_num, endian;\n\n    int x, y, i, ret;\n\n    int w, h, bits_per_color, descriptor, elements, packing, total_size;\n\n\n\n    unsigned int rgbBuffer = 0;\n\n    int n_datum = 0;\n\n\n\n    if (avpkt->size <= 1634) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Packet too small for DPX header\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    magic_num = AV_RB32(buf);\n\n    buf += 4;\n\n\n\n    /* Check if the files \"magic number\" is \"SDPX\" which means it uses\n\n     * big-endian or XPDS which is for little-endian files */\n\n    if (magic_num == AV_RL32(\"SDPX\")) {\n\n        endian = 0;\n\n    } else if (magic_num == AV_RB32(\"SDPX\")) {\n\n        endian = 1;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"DPX marker not found\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    offset = read32(&buf, endian);\n\n    if (avpkt->size <= offset) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Invalid data start offset\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    // Need to end in 0x304 offset from start of file\n\n    buf = avpkt->data + 0x304;\n\n    w = read32(&buf, endian);\n\n    h = read32(&buf, endian);\n\n    if ((ret = av_image_check_size(w, h, 0, avctx)) < 0)\n\n        return ret;\n\n\n\n    if (w != avctx->width || h != avctx->height)\n\n        avcodec_set_dimensions(avctx, w, h);\n\n\n\n    // Need to end in 0x320 to read the descriptor\n\n    buf += 20;\n\n    descriptor = buf[0];\n\n\n\n    // Need to end in 0x323 to read the bits per color\n\n    buf += 3;\n\n    avctx->bits_per_raw_sample =\n\n    bits_per_color = buf[0];\n\n    buf++;\n\n    packing = *((uint16_t*)buf);\n\n\n\n    buf += 824;\n\n    avctx->sample_aspect_ratio.num = read32(&buf, endian);\n\n    avctx->sample_aspect_ratio.den = read32(&buf, endian);\n\n    if (avctx->sample_aspect_ratio.num > 0 && avctx->sample_aspect_ratio.den > 0)\n\n        av_reduce(&avctx->sample_aspect_ratio.num, &avctx->sample_aspect_ratio.den,\n\n                   avctx->sample_aspect_ratio.num,  avctx->sample_aspect_ratio.den,\n\n                  0x10000);\n\n    else\n\n        avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n\n\n\n    switch (descriptor) {\n\n        case 51: // RGBA\n\n            elements = 4;\n\n            break;\n\n        case 50: // RGB\n\n            elements = 3;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported descriptor %d\\n\", descriptor);\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    switch (bits_per_color) {\n\n        case 8:\n\n            if (elements == 4) {\n\n                avctx->pix_fmt = AV_PIX_FMT_RGBA;\n\n            } else {\n\n                avctx->pix_fmt = AV_PIX_FMT_RGB24;\n\n            }\n\n            total_size = avctx->width * avctx->height * elements;\n\n            break;\n\n        case 10:\n\n            if (!packing) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Packing to 32bit required\\n\");\n\n                return -1;\n\n            }\n\n            avctx->pix_fmt = AV_PIX_FMT_GBRP10;\n\n            total_size = (avctx->width * avctx->height * elements + 2) / 3 * 4;\n\n            break;\n\n        case 12:\n\n            if (!packing) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Packing to 16bit required\\n\");\n\n                return -1;\n\n            }\n\n            if (endian) {\n\n                avctx->pix_fmt = AV_PIX_FMT_GBRP12BE;\n\n            } else {\n\n                avctx->pix_fmt = AV_PIX_FMT_GBRP12LE;\n\n            }\n\n            total_size = 2 * avctx->width * avctx->height * elements;\n\n            break;\n\n        case 16:\n\n            if (endian) {\n\n                avctx->pix_fmt = elements == 4 ? AV_PIX_FMT_RGBA64BE : AV_PIX_FMT_RGB48BE;\n\n            } else {\n\n                avctx->pix_fmt = elements == 4 ? AV_PIX_FMT_RGBA64LE : AV_PIX_FMT_RGB48LE;\n\n            }\n\n            total_size = 2 * avctx->width * avctx->height * elements;\n\n            break;\n\n        default:\n\n            av_log(avctx, AV_LOG_ERROR, \"Unsupported color depth : %d\\n\", bits_per_color);\n\n            return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (s->picture.data[0])\n\n        avctx->release_buffer(avctx, &s->picture);\n\n    if ((ret = ff_get_buffer(avctx, p)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return ret;\n\n    }\n\n\n\n    // Move pointer to offset from start of file\n\n    buf =  avpkt->data + offset;\n\n\n\n    for (i=0; i<AV_NUM_DATA_POINTERS; i++)\n\n        ptr[i] = p->data[i];\n\n\n\n    if (total_size > avpkt->size) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Overread buffer. Invalid header?\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    switch (bits_per_color) {\n\n    case 10:\n\n        for (x = 0; x < avctx->height; x++) {\n\n            uint16_t *dst[3] = {(uint16_t*)ptr[0],\n\n                                (uint16_t*)ptr[1],\n\n                                (uint16_t*)ptr[2]};\n\n            for (y = 0; y < avctx->width; y++) {\n\n                *dst[2]++ = read10in32(&buf, &rgbBuffer,\n\n                                       &n_datum, endian);\n\n                *dst[0]++ = read10in32(&buf, &rgbBuffer,\n\n                                       &n_datum, endian);\n\n                *dst[1]++ = read10in32(&buf, &rgbBuffer,\n\n                                       &n_datum, endian);\n\n                // For 10 bit, ignore alpha\n\n                if (elements == 4)\n\n                    read10in32(&buf, &rgbBuffer,\n\n                               &n_datum, endian);\n\n            }\n\n            for (i = 0; i < 3; i++)\n\n                ptr[i] += p->linesize[i];\n\n        }\n\n        break;\n\n    case 12:\n\n        for (x = 0; x < avctx->height; x++) {\n\n            uint16_t *dst[3] = {(uint16_t*)ptr[0],\n\n                                (uint16_t*)ptr[1],\n\n                                (uint16_t*)ptr[2]};\n\n            for (y = 0; y < avctx->width; y++) {\n\n                *dst[2] = *((uint16_t*)buf);\n\n                *dst[2] = (*dst[2] >> 4) | (*dst[2] << 12);\n\n                dst[2]++;\n\n                buf += 2;\n\n                *dst[0] = *((uint16_t*)buf);\n\n                *dst[0] = (*dst[0] >> 4) | (*dst[0] << 12);\n\n                dst[0]++;\n\n                buf += 2;\n\n                *dst[1] = *((uint16_t*)buf);\n\n                *dst[1] = (*dst[1] >> 4) | (*dst[1] << 12);\n\n                dst[1]++;\n\n                buf += 2;\n\n                // For 12 bit, ignore alpha\n\n                if (elements == 4)\n\n                    buf += 2;\n\n            }\n\n            for (i = 0; i < 3; i++)\n\n                ptr[i] += p->linesize[i];\n\n        }\n\n        break;\n\n    case 16:\n\n        elements *= 2;\n\n    case 8:\n\n        for (x = 0; x < avctx->height; x++) {\n\n            memcpy(ptr[0], buf, elements*avctx->width);\n\n            ptr[0] += p->linesize[0];\n\n            buf += elements*avctx->width;\n\n        }\n\n        break;\n\n    }\n\n\n\n    *picture   = s->picture;\n\n    *got_frame = 1;\n\n\n\n    return buf_size;\n\n}\n", "idx": 24478, "_split": "test", "_hash": "5b56eaa4d28518bfae0b8e4163194be1"}
{"project": "FFmpeg", "commit_id": "abb5e37f64c48bba8bd0fde2bada0f7544defa24", "target": 1, "func": "int ff_filter_frame(AVFilterLink *link, AVFrame *frame)\n\n{\n\n    int (*filter_frame)(AVFilterLink *, AVFrame *);\n\n    AVFilterPad *dst = link->dstpad;\n\n    AVFrame *out;\n\n\n\n    FF_DPRINTF_START(NULL, filter_frame);\n\n    ff_dlog_link(NULL, link, 1);\n\n\n\n    if (!(filter_frame = dst->filter_frame))\n\n        filter_frame = default_filter_frame;\n\n\n\n    /* copy the frame if needed */\n\n    if (dst->needs_writable && !av_frame_is_writable(frame)) {\n\n        av_log(link->dst, AV_LOG_DEBUG, \"Copying data in avfilter.\\n\");\n\n\n\n        switch (link->type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            out = ff_get_video_buffer(link, link->w, link->h);\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            out = ff_get_audio_buffer(link, frame->nb_samples);\n\n            break;\n\n        default: return AVERROR(EINVAL);\n\n        }\n\n        if (!out) {\n\n            av_frame_free(&frame);\n\n            return AVERROR(ENOMEM);\n\n        }\n\n        av_frame_copy_props(out, frame);\n\n\n\n        switch (link->type) {\n\n        case AVMEDIA_TYPE_VIDEO:\n\n            av_image_copy(out->data, out->linesize, frame->data, frame->linesize,\n\n                          frame->format, frame->width, frame->height);\n\n            break;\n\n        case AVMEDIA_TYPE_AUDIO:\n\n            av_samples_copy(out->extended_data, frame->extended_data,\n\n                            0, 0, frame->nb_samples,\n\n                            av_get_channel_layout_nb_channels(frame->channel_layout),\n\n                            frame->format);\n\n            break;\n\n        default: return AVERROR(EINVAL);\n\n        }\n\n\n\n        av_frame_free(&frame);\n\n    } else\n\n        out = frame;\n\n\n\n    return filter_frame(link, out);\n\n}\n", "idx": 24484, "_split": "test", "_hash": "19629a407b054542496641c1406f5cb8"}
{"project": "FFmpeg", "commit_id": "3176217c60ca7828712985092d9102d331ea4f3d", "target": 0, "func": "void ff_h264_filter_mb_fast(const H264Context *h, H264SliceContext *sl,\n\n                            int mb_x, int mb_y, uint8_t *img_y,\n\n                            uint8_t *img_cb, uint8_t *img_cr,\n\n                            unsigned int linesize, unsigned int uvlinesize)\n\n{\n\n    assert(!FRAME_MBAFF(h));\n\n    if(!h->h264dsp.h264_loop_filter_strength || h->pps.chroma_qp_diff) {\n\n        ff_h264_filter_mb(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize);\n\n        return;\n\n    }\n\n\n\n#if CONFIG_SMALL\n\n    h264_filter_mb_fast_internal(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize, h->pixel_shift);\n\n#else\n\n    if(h->pixel_shift){\n\n        h264_filter_mb_fast_internal(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize, 1);\n\n    }else{\n\n        h264_filter_mb_fast_internal(h, sl, mb_x, mb_y, img_y, img_cb, img_cr, linesize, uvlinesize, 0);\n\n    }\n\n#endif\n\n}\n", "idx": 24488, "_split": "test", "_hash": "d3d56fbf6b5bab2a8ff4b187bd5f531f"}
{"project": "FFmpeg", "commit_id": "8bc80f8b24cb6f03ad209ce546ae594904c8b353", "target": 1, "func": "static int http_server(void)\n\n{\n\n    int server_fd, ret, rtsp_server_fd, delay, delay1;\n\n    struct pollfd poll_table[HTTP_MAX_CONNECTIONS + 2], *poll_entry;\n\n    HTTPContext *c, *c_next;\n\n\n\n    server_fd = socket_open_listen(&my_http_addr);\n\n    if (server_fd < 0)\n\n        return -1;\n\n\n\n    rtsp_server_fd = socket_open_listen(&my_rtsp_addr);\n\n    if (rtsp_server_fd < 0)\n\n        return -1;\n\n    \n\n    http_log(\"ffserver started.\\n\");\n\n\n\n    start_children(first_feed);\n\n\n\n    first_http_ctx = NULL;\n\n    nb_connections = 0;\n\n    first_http_ctx = NULL;\n\n\n\n    start_multicast();\n\n\n\n    for(;;) {\n\n        poll_entry = poll_table;\n\n        poll_entry->fd = server_fd;\n\n        poll_entry->events = POLLIN;\n\n        poll_entry++;\n\n\n\n        poll_entry->fd = rtsp_server_fd;\n\n        poll_entry->events = POLLIN;\n\n        poll_entry++;\n\n\n\n        /* wait for events on each HTTP handle */\n\n        c = first_http_ctx;\n\n        delay = 1000;\n\n        while (c != NULL) {\n\n            int fd;\n\n            fd = c->fd;\n\n            switch(c->state) {\n\n            case HTTPSTATE_SEND_HEADER:\n\n            case RTSPSTATE_SEND_REPLY:\n\n            case RTSPSTATE_SEND_PACKET:\n\n                c->poll_entry = poll_entry;\n\n                poll_entry->fd = fd;\n\n                poll_entry->events = POLLOUT;\n\n                poll_entry++;\n\n                break;\n\n            case HTTPSTATE_SEND_DATA_HEADER:\n\n            case HTTPSTATE_SEND_DATA:\n\n            case HTTPSTATE_SEND_DATA_TRAILER:\n\n                if (!c->is_packetized) {\n\n                    /* for TCP, we output as much as we can (may need to put a limit) */\n\n                    c->poll_entry = poll_entry;\n\n                    poll_entry->fd = fd;\n\n                    poll_entry->events = POLLOUT;\n\n                    poll_entry++;\n\n                } else {\n\n                    /* not strictly correct, but currently cannot add\n\n                       more than one fd in poll entry */\n\n                    delay = 0;\n\n                }\n\n                break;\n\n            case HTTPSTATE_WAIT_REQUEST:\n\n            case HTTPSTATE_RECEIVE_DATA:\n\n            case HTTPSTATE_WAIT_FEED:\n\n            case RTSPSTATE_WAIT_REQUEST:\n\n                /* need to catch errors */\n\n                c->poll_entry = poll_entry;\n\n                poll_entry->fd = fd;\n\n                poll_entry->events = POLLIN;/* Maybe this will work */\n\n                poll_entry++;\n\n                break;\n\n            case HTTPSTATE_WAIT:\n\n                c->poll_entry = NULL;\n\n                delay1 = compute_send_delay(c);\n\n                if (delay1 < delay)\n\n                    delay = delay1;\n\n                break;\n\n            case HTTPSTATE_WAIT_SHORT:\n\n                c->poll_entry = NULL;\n\n                delay1 = 10; /* one tick wait XXX: 10 ms assumed */\n\n                if (delay1 < delay)\n\n                    delay = delay1;\n\n                break;\n\n            default:\n\n                c->poll_entry = NULL;\n\n                break;\n\n            }\n\n            c = c->next;\n\n        }\n\n\n\n        /* wait for an event on one connection. We poll at least every\n\n           second to handle timeouts */\n\n        do {\n\n            ret = poll(poll_table, poll_entry - poll_table, delay);\n\n        } while (ret == -1);\n\n        \n\n        cur_time = gettime_ms();\n\n\n\n        if (need_to_start_children) {\n\n            need_to_start_children = 0;\n\n            start_children(first_feed);\n\n        }\n\n\n\n        /* now handle the events */\n\n        for(c = first_http_ctx; c != NULL; c = c_next) {\n\n            c_next = c->next;\n\n            if (handle_connection(c) < 0) {\n\n                /* close and free the connection */\n\n                log_connection(c);\n\n                close_connection(c);\n\n            }\n\n        }\n\n\n\n        poll_entry = poll_table;\n\n        /* new HTTP connection request ? */\n\n        if (poll_entry->revents & POLLIN) {\n\n            new_connection(server_fd, 0);\n\n        }\n\n        poll_entry++;\n\n        /* new RTSP connection request ? */\n\n        if (poll_entry->revents & POLLIN) {\n\n            new_connection(rtsp_server_fd, 1);\n\n        }\n\n    }\n\n}\n", "idx": 24542, "_split": "test", "_hash": "546e6164daf77850728305b41b53bba1"}
{"project": "FFmpeg", "commit_id": "f3c0e0bf6f53df0977f3878d4f5cec99dff8de9e", "target": 0, "func": "static int dnxhd_decode_header(DNXHDContext *ctx, AVFrame *frame,\n\n                               const uint8_t *buf, int buf_size,\n\n                               int first_field)\n\n{\n\n    static const uint8_t header_prefix[]    = { 0x00, 0x00, 0x02, 0x80, 0x01 };\n\n    static const uint8_t header_prefix444[] = { 0x00, 0x00, 0x02, 0x80, 0x02 };\n\n    int i, cid, ret;\n\n\n\n    if (buf_size < 0x280)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (memcmp(buf, header_prefix, 5) && memcmp(buf, header_prefix444, 5)) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"error in header\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n    if (buf[5] & 2) { /* interlaced */\n\n        ctx->cur_field = buf[5] & 1;\n\n        frame->interlaced_frame = 1;\n\n        frame->top_field_first  = first_field ^ ctx->cur_field;\n\n        av_log(ctx->avctx, AV_LOG_DEBUG,\n\n               \"interlaced %d, cur field %d\\n\", buf[5] & 3, ctx->cur_field);\n\n    }\n\n\n\n    ctx->height = AV_RB16(buf + 0x18);\n\n    ctx->width  = AV_RB16(buf + 0x1a);\n\n\n\n    av_dlog(ctx->avctx, \"width %d, height %d\\n\", ctx->width, ctx->height);\n\n\n\n    ctx->is_444 = 0;\n\n    if (buf[0x4] == 0x2) {\n\n        ctx->avctx->pix_fmt = AV_PIX_FMT_YUV444P10;\n\n        ctx->avctx->bits_per_raw_sample = 10;\n\n        if (ctx->bit_depth != 10) {\n\n            ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n\n            ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n\n            ctx->bit_depth = 10;\n\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10_444;\n\n        }\n\n        ctx->is_444 = 1;\n\n    } else if (buf[0x21] & 0x40) {\n\n        ctx->avctx->pix_fmt = AV_PIX_FMT_YUV422P10;\n\n        ctx->avctx->bits_per_raw_sample = 10;\n\n        if (ctx->bit_depth != 10) {\n\n            ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n\n            ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n\n            ctx->bit_depth = 10;\n\n            ctx->decode_dct_block = dnxhd_decode_dct_block_10;\n\n        }\n\n    } else {\n\n        ctx->avctx->pix_fmt = AV_PIX_FMT_YUV422P;\n\n        ctx->avctx->bits_per_raw_sample = 8;\n\n        if (ctx->bit_depth != 8) {\n\n            ff_blockdsp_init(&ctx->bdsp, ctx->avctx);\n\n            ff_idctdsp_init(&ctx->idsp, ctx->avctx);\n\n            ctx->bit_depth = 8;\n\n            ctx->decode_dct_block = dnxhd_decode_dct_block_8;\n\n        }\n\n    }\n\n\n\n    cid = AV_RB32(buf + 0x28);\n\n    av_dlog(ctx->avctx, \"compression id %d\\n\", cid);\n\n\n\n    if ((ret = dnxhd_init_vlc(ctx, cid)) < 0)\n\n        return ret;\n\n\n\n    if (buf_size < ctx->cid_table->coding_unit_size) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR, \"incorrect frame size\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    ctx->mb_width  = ctx->width >> 4;\n\n    ctx->mb_height = buf[0x16d];\n\n\n\n    av_dlog(ctx->avctx,\n\n            \"mb width %d, mb height %d\\n\", ctx->mb_width, ctx->mb_height);\n\n\n\n    if ((ctx->height + 15) >> 4 == ctx->mb_height && frame->interlaced_frame)\n\n        ctx->height <<= 1;\n\n\n\n    if (ctx->mb_height > 68 ||\n\n        (ctx->mb_height << frame->interlaced_frame) > (ctx->height + 15) >> 4) {\n\n        av_log(ctx->avctx, AV_LOG_ERROR,\n\n               \"mb height too big: %d\\n\", ctx->mb_height);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    for (i = 0; i < ctx->mb_height; i++) {\n\n        ctx->mb_scan_index[i] = AV_RB32(buf + 0x170 + (i << 2));\n\n        av_dlog(ctx->avctx, \"mb scan index %d\\n\", ctx->mb_scan_index[i]);\n\n        if (buf_size < ctx->mb_scan_index[i] + 0x280LL) {\n\n            av_log(ctx->avctx, AV_LOG_ERROR, \"invalid mb scan index\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24555, "_split": "test", "_hash": "e68019d2822c4dc3a5b3e0127e1ccb8b"}
{"project": "FFmpeg", "commit_id": "2caf19e90f270abe1e80a3e85acaf0eb5c9d0aac", "target": 1, "func": "static void FUNCC(pred8x8_left_dc)(uint8_t *_src, int stride){\n\n    int i;\n\n    int dc0, dc2;\n\n    pixel4 dc0splat, dc2splat;\n\n    pixel *src = (pixel*)_src;\n\n    stride /= sizeof(pixel);\n\n\n\n    dc0=dc2=0;\n\n    for(i=0;i<4; i++){\n\n        dc0+= src[-1+i*stride];\n\n        dc2+= src[-1+(i+4)*stride];\n\n    }\n\n    dc0splat = PIXEL_SPLAT_X4((dc0 + 2)>>2);\n\n    dc2splat = PIXEL_SPLAT_X4((dc2 + 2)>>2);\n\n\n\n    for(i=0; i<4; i++){\n\n        ((pixel4*)(src+i*stride))[0]=\n\n        ((pixel4*)(src+i*stride))[1]= dc0splat;\n\n    }\n\n    for(i=4; i<8; i++){\n\n        ((pixel4*)(src+i*stride))[0]=\n\n        ((pixel4*)(src+i*stride))[1]= dc2splat;\n\n    }\n\n}\n", "idx": 24621, "_split": "test", "_hash": "48b989d1fc20da67b75f95145c91a343"}
{"project": "FFmpeg", "commit_id": "48aecf5a7dd8e914d44cb4210a09172dbd8d5d86", "target": 1, "func": "static void alloc_and_copy(uint8_t **poutbuf,          int *poutbuf_size,\n\n                           const uint8_t *sps_pps, uint32_t sps_pps_size,\n\n                           const uint8_t *in,      uint32_t in_size) {\n\n    uint32_t offset = *poutbuf_size;\n\n    uint8_t nal_header_size = offset ? 3 : 4;\n\n\n\n    *poutbuf_size += sps_pps_size+in_size+nal_header_size;\n\n    *poutbuf = av_realloc(*poutbuf, *poutbuf_size);\n\n    if (sps_pps)\n\n        memcpy(*poutbuf+offset, sps_pps, sps_pps_size);\n\n    memcpy(*poutbuf+sps_pps_size+nal_header_size+offset, in, in_size);\n\n    if (!offset)\n\n        AV_WB32(*poutbuf+sps_pps_size, 1);\n\n    else {\n\n        (*poutbuf+offset)[0] = (*poutbuf+offset)[1] = 0;\n\n        (*poutbuf+offset)[2] = 1;\n\n    }\n\n}\n", "idx": 24625, "_split": "test", "_hash": "2ea3760562d3f64429426ec165d2124d"}
{"project": "FFmpeg", "commit_id": "40ad05bab206c932a32171d45581080c914b06ec", "target": 0, "func": "int float_near_ulp(float a, float b, unsigned max_ulp)\n\n{\n\n    union av_intfloat32 x, y;\n\n\n\n    x.f = a;\n\n    y.f = b;\n\n\n\n    if (is_negative(x) != is_negative(y)) {\n\n        // handle -0.0 == +0.0\n\n        return a == b;\n\n    }\n\n\n\n    if (abs(x.i - y.i) <= max_ulp)\n\n        return 1;\n\n\n\n    return 0;\n\n}\n", "idx": 24629, "_split": "test", "_hash": "852e6fb60a57b7a68083c1110a5572a9"}
{"project": "FFmpeg", "commit_id": "a8bdf2405c6027f45a899eaaa6ba74e97c1c2701", "target": 1, "func": "static av_cold int roq_dpcm_encode_init(AVCodecContext *avctx)\n\n{\n\n    ROQDPCMContext *context = avctx->priv_data;\n\n\n\n    if (avctx->channels > 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Audio must be mono or stereo\\n\");\n\n        return -1;\n\n    }\n\n    if (avctx->sample_rate != 22050) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Audio must be 22050 Hz\\n\");\n\n        return -1;\n\n    }\n\n    if (avctx->sample_fmt != AV_SAMPLE_FMT_S16) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Audio must be signed 16-bit\\n\");\n\n        return -1;\n\n    }\n\n\n\n    avctx->frame_size = ROQ_FIRST_FRAME_SIZE;\n\n\n\n    context->lastSample[0] = context->lastSample[1] = 0;\n\n\n\n    avctx->coded_frame= avcodec_alloc_frame();\n\n\n\n\n\n    return 0;\n\n}", "idx": 24631, "_split": "test", "_hash": "94c969275c0f540bdf45a7c27a8f36b2"}
{"project": "FFmpeg", "commit_id": "1bfb4587a2e5b25ed15f742149e555efc8f305ae", "target": 1, "func": "static void test_function(const TestStruct test_sample)\n\n{\n\n    int ret, i;\n\n    void **output_data  = NULL;\n\n    AVAudioFifo *afifo  = av_audio_fifo_alloc(test_sample.format, test_sample.nb_ch,\n\n                                            test_sample.nb_samples_pch);\n\n    if (!afifo) {\n\n        ERROR(\"ERROR: av_audio_fifo_alloc returned NULL!\");\n\n    }\n\n    ret = write_samples_to_audio_fifo(afifo, test_sample, test_sample.nb_samples_pch, 0);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_write failed!\");\n\n    }\n\n    printf(\"written: %d\\n\", ret);\n\n\n\n    ret = write_samples_to_audio_fifo(afifo, test_sample, test_sample.nb_samples_pch, 0);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_write failed!\");\n\n    }\n\n    printf(\"written: %d\\n\", ret);\n\n    printf(\"remaining samples in audio_fifo: %d\\n\\n\", av_audio_fifo_size(afifo));\n\n\n\n    ret = read_samples_from_audio_fifo(afifo, &output_data, test_sample.nb_samples_pch);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_read failed!\");\n\n    }\n\n    printf(\"read: %d\\n\", ret);\n\n    print_audio_bytes(&test_sample, output_data, ret);\n\n    printf(\"remaining samples in audio_fifo: %d\\n\\n\", av_audio_fifo_size(afifo));\n\n\n\n    /* test av_audio_fifo_peek */\n\n    ret = av_audio_fifo_peek(afifo, output_data, afifo->nb_samples);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_peek failed!\");\n\n    }\n\n    printf(\"peek:\\n\");\n\n    print_audio_bytes(&test_sample, output_data, ret);\n\n    printf(\"\\n\");\n\n\n\n    /* test av_audio_fifo_peek_at */\n\n    printf(\"peek_at:\\n\");\n\n    for (i = 0; i < afifo->nb_samples; ++i){\n\n        ret = av_audio_fifo_peek_at(afifo, output_data, 1, i);\n\n        if (ret < 0){\n\n            ERROR(\"ERROR: av_audio_fifo_peek_at failed!\");\n\n        }\n\n        printf(\"%d:\\n\", i);\n\n        print_audio_bytes(&test_sample, output_data, ret);\n\n    }\n\n    printf(\"\\n\");\n\n\n\n    /* test av_audio_fifo_drain */\n\n    ret = av_audio_fifo_drain(afifo, afifo->nb_samples);\n\n    if (ret < 0){\n\n        ERROR(\"ERROR: av_audio_fifo_drain failed!\");\n\n    }\n\n    if (afifo->nb_samples){\n\n        ERROR(\"drain failed to flush all samples in audio_fifo!\");\n\n    }\n\n\n\n    /* deallocate */\n\n    for (i = 0; i < afifo->nb_buffers; ++i){\n\n        av_freep(&output_data[i]);\n\n    }\n\n    av_freep(&output_data);\n\n    av_audio_fifo_free(afifo);\n\n}\n", "idx": 24655, "_split": "test", "_hash": "b7ea1022c177c2e45d5f85f6211a6da9"}
{"project": "FFmpeg", "commit_id": "e6bc38fd49c94726b45d5d5cc2b756ad8ec49ee0", "target": 1, "func": "static void ff_wmv2_idct_put_c(uint8_t *dest, int line_size, DCTELEM *block)\n\n{\n\n    ff_wmv2_idct_c(block);\n\n    put_pixels_clamped_c(block, dest, line_size);\n\n}\n", "idx": 24668, "_split": "test", "_hash": "3a59224eee16c2413e83dae996894551"}
{"project": "FFmpeg", "commit_id": "5a08ba5381cf8d46034440163e71cd95748beceb", "target": 0, "func": "static void decode_interframe_v4(AVCodecContext *avctx, uint8_t *src, uint32_t size)\n\n{\n\n    Hnm4VideoContext *hnm = avctx->priv_data;\n\n    GetByteContext gb;\n\n    uint32_t writeoffset = 0, count, left, offset;\n\n    uint8_t tag, previous, backline, backward, swap;\n\n\n\n    bytestream2_init(&gb, src, size);\n\n\n\n    while (bytestream2_tell(&gb) < size) {\n\n        count = bytestream2_peek_byte(&gb) & 0x1F;\n\n        if (count == 0) {\n\n            tag = bytestream2_get_byte(&gb) & 0xE0;\n\n            tag = tag >> 5;\n\n            if (tag == 0) {\n\n                hnm->current[writeoffset++] = bytestream2_get_byte(&gb);\n\n                hnm->current[writeoffset++] = bytestream2_get_byte(&gb);\n\n            } else if (tag == 1) {\n\n                writeoffset += bytestream2_get_byte(&gb) * 2;\n\n            } else if (tag == 2) {\n\n                count = bytestream2_get_le16(&gb);\n\n                count *= 2;\n\n                writeoffset += count;\n\n            } else if (tag == 3) {\n\n                count = bytestream2_get_byte(&gb) * 2;\n\n                while (count > 0) {\n\n                    hnm->current[writeoffset++] = bytestream2_peek_byte(&gb);\n\n                    count--;\n\n                }\n\n                bytestream2_skip(&gb, 1);\n\n            } else {\n\n                break;\n\n            }\n\n        } else {\n\n            previous = bytestream2_peek_byte(&gb) & 0x20;\n\n            backline = bytestream2_peek_byte(&gb) & 0x40;\n\n            backward = bytestream2_peek_byte(&gb) & 0x80;\n\n            bytestream2_skip(&gb, 1);\n\n            swap   = bytestream2_peek_byte(&gb) & 0x01;\n\n            offset = bytestream2_get_le16(&gb);\n\n            offset = (offset >> 1) & 0x7FFF;\n\n            offset = writeoffset + (offset * 2) - 0x8000;\n\n\n\n            left = count;\n\n\n\n            if (!backward && offset + count >= hnm->width * hnm->height) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Attempting to read out of bounds\");\n\n                break;\n\n            } else if (backward && offset >= hnm->width * hnm->height) {\n\n                av_log(avctx, AV_LOG_ERROR, \"Attempting to read out of bounds\");\n\n                break;\n\n            } else if (writeoffset + count >= hnm->width * hnm->height) {\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"Attempting to write out of bounds\");\n\n                break;\n\n            }\n\n\n\n            if (previous) {\n\n                while (left > 0) {\n\n                    if (backline) {\n\n                        hnm->current[writeoffset++] = hnm->previous[offset - (2 * hnm->width) + 1];\n\n                        hnm->current[writeoffset++] = hnm->previous[offset++];\n\n                        offset++;\n\n                    } else {\n\n                        hnm->current[writeoffset++] = hnm->previous[offset++];\n\n                        hnm->current[writeoffset++] = hnm->previous[offset++];\n\n                    }\n\n                    if (backward)\n\n                        offset -= 4;\n\n                    left--;\n\n                }\n\n            } else {\n\n                while (left > 0) {\n\n                    if (backline) {\n\n                        hnm->current[writeoffset++] = hnm->current[offset - (2 * hnm->width) + 1];\n\n                        hnm->current[writeoffset++] = hnm->current[offset++];\n\n                        offset++;\n\n                    } else {\n\n                        hnm->current[writeoffset++] = hnm->current[offset++];\n\n                        hnm->current[writeoffset++] = hnm->current[offset++];\n\n                    }\n\n                    if (backward)\n\n                        offset -= 4;\n\n                    left--;\n\n                }\n\n            }\n\n\n\n            if (swap) {\n\n                left         = count;\n\n                writeoffset -= count * 2;\n\n                while (left > 0) {\n\n                    swap = hnm->current[writeoffset];\n\n                    hnm->current[writeoffset] = hnm->current[writeoffset + 1];\n\n                    hnm->current[writeoffset + 1] = swap;\n\n                    left--;\n\n                    writeoffset += 2;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24677, "_split": "test", "_hash": "970527bb53dfc98ebfeb44903abe2305"}
{"project": "FFmpeg", "commit_id": "93c39db5f1544d1220488cfeb93bfe812a52f374", "target": 1, "func": "static int aiff_read_packet(AVFormatContext *s,\n                            AVPacket *pkt)\n{\n    AVStream *st = s->streams[0];\n    AIFFInputContext *aiff = s->priv_data;\n    int64_t max_size;\n    int res, size;\n    /* calculate size of remaining data */\n    max_size = aiff->data_end - avio_tell(s->pb);\n    if (max_size <= 0)\n        return AVERROR_EOF;\n    /* Now for that packet */\n    switch (st->codecpar->codec_id) {\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    case AV_CODEC_ID_GSM:\n    case AV_CODEC_ID_QDM2:\n    case AV_CODEC_ID_QCELP:\n        size = st->codecpar->block_align;\n        break;\n    default:\n        size = st->codecpar->block_align ? (MAX_SIZE / st->codecpar->block_align) * st->codecpar->block_align : MAX_SIZE;\n    size = FFMIN(max_size, size);\n    res = av_get_packet(s->pb, pkt, size);\n    if (res < 0)\n        return res;\n    if (size >= st->codecpar->block_align)\n        pkt->flags &= ~AV_PKT_FLAG_CORRUPT;\n    /* Only one stream in an AIFF file */\n    pkt->stream_index = 0;\n    pkt->duration     = (res / st->codecpar->block_align) * aiff->block_duration;\n    return 0;", "idx": 24732, "_split": "test", "_hash": "84b438325efe79d800b6df2607d39807"}
{"project": "FFmpeg", "commit_id": "f20b67173ca6a05b8c3dee02dad3b7243b96292b", "target": 0, "func": "static void apply_tns_filter(float *out, float *in, int order, int direction,\n\n                             float *tns_coefs, int ltp_used, int w, int filt,\n\n                             int start_i, int len)\n\n{\n\n    int i, j, inc, start = start_i;\n\n    float tmp[TNS_MAX_ORDER+1];\n\n    if (direction) {\n\n        inc = -1;\n\n        start = (start + len) - 1;\n\n    } else {\n\n        inc = 1;\n\n    }\n\n    if (!ltp_used) {    /* AR filter */\n\n        for (i = 0; i < len; i++, start += inc)\n\n            out[i] = in[start];\n\n            for (j = 1; j <= FFMIN(i, order); j++)\n\n                out[i] += tns_coefs[j]*in[start - j*inc];\n\n    } else {            /* MA filter */\n\n        for (i = 0; i < len; i++, start += inc) {\n\n            tmp[0] = out[i] = in[start];\n\n            for (j = 1; j <= FFMIN(i, order); j++)\n\n                out[i] += tmp[j]*tns_coefs[j];\n\n            for (j = order; j > 0; j--)\n\n                tmp[j] = tmp[j - 1];\n\n        }\n\n    }\n\n}\n", "idx": 24761, "_split": "test", "_hash": "57ef8bfd6f95dac4d83d7f795c94f391"}
{"project": "FFmpeg", "commit_id": "69c1fe7c9c9bc85eebfc02c6a19caf7e88cd74ff", "target": 0, "func": "static int mkv_write_ass_blocks(AVFormatContext *s, AVIOContext *pb,\n\n                                AVPacket *pkt)\n\n{\n\n    MatroskaMuxContext *mkv = s->priv_data;\n\n    int i, layer = 0, max_duration = 0, size, line_size, data_size = pkt->size;\n\n    uint8_t *start, *end, *data = pkt->data;\n\n    ebml_master blockgroup;\n\n    char buffer[2048];\n\n\n\n    while (data_size) {\n\n        int duration = ass_get_duration(data);\n\n        max_duration = FFMAX(duration, max_duration);\n\n        end          = memchr(data, '\\n', data_size);\n\n        size         = line_size = end ? end - data + 1 : data_size;\n\n        size        -= end ? (end[-1] == '\\r') + 1 : 0;\n\n        start        = data;\n\n        for (i = 0; i < 3; i++, start++)\n\n            if (!(start = memchr(start, ',', size - (start - data))))\n\n                return max_duration;\n\n        size -= start - data;\n\n        sscanf(data, \"Dialogue: %d,\", &layer);\n\n        i = snprintf(buffer, sizeof(buffer), \"%\" PRId64 \",%d,\",\n\n                     s->streams[pkt->stream_index]->nb_frames, layer);\n\n        size = FFMIN(i + size, sizeof(buffer));\n\n        memcpy(buffer + i, start, size - i);\n\n\n\n        av_log(s, AV_LOG_DEBUG,\n\n               \"Writing block at offset %\" PRIu64 \", size %d, \"\n\n               \"pts %\" PRId64 \", duration %d\\n\",\n\n               avio_tell(pb), size, pkt->pts, duration);\n\n        blockgroup = start_ebml_master(pb, MATROSKA_ID_BLOCKGROUP,\n\n                                       mkv_blockgroup_size(size));\n\n        put_ebml_id(pb, MATROSKA_ID_BLOCK);\n\n        put_ebml_num(pb, size + 4, 0);\n\n        // this assumes stream_index is less than 126\n\n        avio_w8(pb, 0x80 | (pkt->stream_index + 1));\n\n        avio_wb16(pb, pkt->pts - mkv->cluster_pts);\n\n        avio_w8(pb, 0);\n\n        avio_write(pb, buffer, size);\n\n        put_ebml_uint(pb, MATROSKA_ID_BLOCKDURATION, duration);\n\n        end_ebml_master(pb, blockgroup);\n\n\n\n        data      += line_size;\n\n        data_size -= line_size;\n\n    }\n\n\n\n    return max_duration;\n\n}\n", "idx": 24768, "_split": "test", "_hash": "4bce4b7a1006ebea180ce745e620dda1"}
{"project": "FFmpeg", "commit_id": "6df2c94130b026930d1f7148699925dcaa08759c", "target": 0, "func": "static void draw_bar_yuv(AVFrame *out, const float *h, const float *rcp_h,\n\n                         const ColorFloat *c, int bar_h)\n\n{\n\n    int x, y, yh, w = out->width;\n\n    float mul, ht, rcp_bar_h = 1.0f / bar_h;\n\n    uint8_t *vy = out->data[0], *vu = out->data[1], *vv = out->data[2];\n\n    uint8_t *lpy, *lpu, *lpv;\n\n    int lsy = out->linesize[0], lsu = out->linesize[1], lsv = out->linesize[2];\n\n    int fmt = out->format;\n\n\n\n    for (y = 0; y < bar_h; y += 2) {\n\n        yh = (fmt == AV_PIX_FMT_YUV420P) ? y / 2 : y;\n\n        ht = (bar_h - y) * rcp_bar_h;\n\n        lpy = vy + y * lsy;\n\n        lpu = vu + yh * lsu;\n\n        lpv = vv + yh * lsv;\n\n        for (x = 0; x < w; x += 2) {\n\n            if (h[x] <= ht) {\n\n                *lpy++ = 16;\n\n                *lpu++ = 128;\n\n                *lpv++ = 128;\n\n            } else {\n\n                mul = (h[x] - ht) * rcp_h[x];\n\n                *lpy++ = mul * c[x].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                *lpu++ = mul * c[x].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                *lpv++ = mul * c[x].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n            }\n\n            /* u and v are skipped on yuv422p and yuv420p */\n\n            if (fmt == AV_PIX_FMT_YUV444P) {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                    *lpu++ = 128;\n\n                    *lpv++ = 128;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                    *lpu++ = mul * c[x+1].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                    *lpv++ = mul * c[x+1].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n                }\n\n            } else {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                }\n\n            }\n\n        }\n\n\n\n        ht = (bar_h - (y+1)) * rcp_bar_h;\n\n        lpy = vy + (y+1) * lsy;\n\n        lpu = vu + (y+1) * lsu;\n\n        lpv = vv + (y+1) * lsv;\n\n        for (x = 0; x < w; x += 2) {\n\n            /* u and v are skipped on yuv420p */\n\n            if (fmt != AV_PIX_FMT_YUV420P) {\n\n                if (h[x] <= ht) {\n\n                    *lpy++ = 16;\n\n                    *lpu++ = 128;\n\n                    *lpv++ = 128;\n\n                } else {\n\n                    mul = (h[x] - ht) * rcp_h[x];\n\n                    *lpy++ = mul * c[x].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                    *lpu++ = mul * c[x].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                    *lpv++ = mul * c[x].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n                }\n\n            } else {\n\n                if (h[x] <= ht) {\n\n                    *lpy++ = 16;\n\n                } else {\n\n                    mul = (h[x] - ht) * rcp_h[x];\n\n                    *lpy++ = mul * c[x].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                }\n\n            }\n\n            /* u and v are skipped on yuv422p and yuv420p */\n\n            if (out->format == AV_PIX_FMT_YUV444P) {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                    *lpu++ = 128;\n\n                    *lpv++ = 128;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                    *lpu++ = mul * c[x+1].yuv.u + (1.0f - mul) * 128.0f + 0.5f;\n\n                    *lpv++ = mul * c[x+1].yuv.v + (1.0f - mul) * 128.0f + 0.5f;\n\n                }\n\n            } else {\n\n                if (h[x+1] <= ht) {\n\n                    *lpy++ = 16;\n\n                } else {\n\n                    mul = (h[x+1] - ht) * rcp_h[x+1];\n\n                    *lpy++ = mul * c[x+1].yuv.y + (1.0f - mul) * 16.0f + 0.5f;\n\n                }\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 24787, "_split": "test", "_hash": "57898e74f79ef9e36118981612e217a8"}
{"project": "FFmpeg", "commit_id": "a38758a97efe9c2de48b5429fd2fdebd55ba6a64", "target": 1, "func": "int ff_h264_fill_default_ref_list(H264Context *h, H264SliceContext *sl)\n\n{\n\n    int i, len;\n\n\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        H264Picture *sorted[32];\n\n        int cur_poc, list;\n\n        int lens[2];\n\n\n\n        if (FIELD_PICTURE(h))\n\n            cur_poc = h->cur_pic_ptr->field_poc[h->picture_structure == PICT_BOTTOM_FIELD];\n\n        else\n\n            cur_poc = h->cur_pic_ptr->poc;\n\n\n\n        for (list = 0; list < 2; list++) {\n\n            len  = add_sorted(sorted,       h->short_ref, h->short_ref_count, cur_poc, 1 ^ list);\n\n            len += add_sorted(sorted + len, h->short_ref, h->short_ref_count, cur_poc, 0 ^ list);\n\n            av_assert0(len <= 32);\n\n\n\n            len  = build_def_list(h->default_ref_list[list], FF_ARRAY_ELEMS(h->default_ref_list[0]),\n\n                                  sorted, len, 0, h->picture_structure);\n\n            len += build_def_list(h->default_ref_list[list] + len,\n\n                                  FF_ARRAY_ELEMS(h->default_ref_list[0]) - len,\n\n                                  h->long_ref, 16, 1, h->picture_structure);\n\n            av_assert0(len <= 32);\n\n\n\n            if (len < sl->ref_count[list])\n\n                memset(&h->default_ref_list[list][len], 0, sizeof(H264Ref) * (sl->ref_count[list] - len));\n\n            lens[list] = len;\n\n        }\n\n\n\n        if (lens[0] == lens[1] && lens[1] > 1) {\n\n            for (i = 0; i < lens[0] &&\n\n                        h->default_ref_list[0][i].parent->f.buf[0]->buffer ==\n\n                        h->default_ref_list[1][i].parent->f.buf[0]->buffer; i++);\n\n            if (i == lens[0]) {\n\n                FFSWAP(H264Ref, h->default_ref_list[1][0], h->default_ref_list[1][1]);\n\n            }\n\n        }\n\n    } else {\n\n        len  = build_def_list(h->default_ref_list[0], FF_ARRAY_ELEMS(h->default_ref_list[0]),\n\n                              h->short_ref, h->short_ref_count, 0, h->picture_structure);\n\n        len += build_def_list(h->default_ref_list[0] + len,\n\n                              FF_ARRAY_ELEMS(h->default_ref_list[0]) - len,\n\n                              h-> long_ref, 16, 1, h->picture_structure);\n\n        av_assert0(len <= 32);\n\n\n\n        if (len < sl->ref_count[0])\n\n            memset(&h->default_ref_list[0][len], 0, sizeof(H264Ref) * (sl->ref_count[0] - len));\n\n    }\n\n#ifdef TRACE\n\n    for (i = 0; i < sl->ref_count[0]; i++) {\n\n        tprintf(h->avctx, \"List0: %s fn:%d 0x%p\\n\",\n\n                (h->default_ref_list[0][i].parent->long_ref ? \"LT\" : \"ST\"),\n\n                h->default_ref_list[0][i].pic_id,\n\n                h->default_ref_list[0][i].parent->f.data[0]);\n\n    }\n\n    if (sl->slice_type_nos == AV_PICTURE_TYPE_B) {\n\n        for (i = 0; i < sl->ref_count[1]; i++) {\n\n            tprintf(h->avctx, \"List1: %s fn:%d 0x%p\\n\",\n\n                    (h->default_ref_list[1][i].parent->long_ref ? \"LT\" : \"ST\"),\n\n                    h->default_ref_list[1][i].pic_id,\n\n                    h->default_ref_list[1][i].parent->f.data[0]);\n\n        }\n\n    }\n\n#endif\n\n    return 0;\n\n}\n", "idx": 24818, "_split": "test", "_hash": "5669d18bc530bfd76de2a05824c5c21f"}
{"project": "FFmpeg", "commit_id": "ce19aec15b4291dc48e791d89a1f940babc22cdc", "target": 0, "func": "const uint8_t *ff_h263_find_resync_marker(const uint8_t *av_restrict p, const uint8_t *av_restrict end)\n\n{\n\n    av_assert2(p < end);\n\n\n\n    end-=2;\n\n    p++;\n\n    for(;p<end; p+=2){\n\n        if(!*p){\n\n            if     (!p[-1] && p[1]) return p - 1;\n\n            else if(!p[ 1] && p[2]) return p;\n\n        }\n\n    }\n\n    return end+2;\n\n}\n", "idx": 24829, "_split": "test", "_hash": "56aaedd62266271ab9e8df7f917c9e46"}
{"project": "FFmpeg", "commit_id": "42361bdf51c4495ca71a532efbb7769475c1822c", "target": 0, "func": "int ff_MPV_frame_start(MpegEncContext *s, AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    Picture *pic;\n\n    s->mb_skipped = 0;\n\n\n\n    if (!ff_thread_can_start_frame(avctx)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Attempt to start a frame outside SETUP state\\n\");\n\n        return -1;\n\n    }\n\n\n\n    /* mark & release old frames */\n\n    if (s->pict_type != AV_PICTURE_TYPE_B && s->last_picture_ptr &&\n\n        s->last_picture_ptr != s->next_picture_ptr &&\n\n        s->last_picture_ptr->f.buf[0]) {\n\n        ff_mpeg_unref_picture(s, s->last_picture_ptr);\n\n    }\n\n\n\n    /* release forgotten pictures */\n\n    /* if (mpeg124/h263) */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (&s->picture[i] != s->last_picture_ptr &&\n\n            &s->picture[i] != s->next_picture_ptr &&\n\n            s->picture[i].reference && !s->picture[i].needs_realloc) {\n\n            if (!(avctx->active_thread_type & FF_THREAD_FRAME))\n\n                av_log(avctx, AV_LOG_ERROR,\n\n                       \"releasing zombie picture\\n\");\n\n            ff_mpeg_unref_picture(s, &s->picture[i]);\n\n        }\n\n    }\n\n\n\n    ff_mpeg_unref_picture(s, &s->current_picture);\n\n\n\n    release_unused_pictures(s);\n\n\n\n    if (s->current_picture_ptr &&\n\n        s->current_picture_ptr->f.buf[0] == NULL) {\n\n        // we already have a unused image\n\n        // (maybe it was set before reading the header)\n\n        pic = s->current_picture_ptr;\n\n    } else {\n\n        i   = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        pic = &s->picture[i];\n\n    }\n\n\n\n    pic->reference = 0;\n\n    if (!s->droppable) {\n\n        if (s->pict_type != AV_PICTURE_TYPE_B)\n\n            pic->reference = 3;\n\n    }\n\n\n\n    pic->f.coded_picture_number = s->coded_picture_number++;\n\n\n\n    if (ff_alloc_picture(s, pic, 0) < 0)\n\n        return -1;\n\n\n\n    s->current_picture_ptr = pic;\n\n    // FIXME use only the vars from current_pic\n\n    s->current_picture_ptr->f.top_field_first = s->top_field_first;\n\n    if (s->codec_id == AV_CODEC_ID_MPEG1VIDEO ||\n\n        s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        if (s->picture_structure != PICT_FRAME)\n\n            s->current_picture_ptr->f.top_field_first =\n\n                (s->picture_structure == PICT_TOP_FIELD) == s->first_field;\n\n    }\n\n    s->current_picture_ptr->f.interlaced_frame = !s->progressive_frame &&\n\n                                                 !s->progressive_sequence;\n\n    s->current_picture_ptr->field_picture      =  s->picture_structure != PICT_FRAME;\n\n\n\n    s->current_picture_ptr->f.pict_type = s->pict_type;\n\n    // if (s->flags && CODEC_FLAG_QSCALE)\n\n    //     s->current_picture_ptr->quality = s->new_picture_ptr->quality;\n\n    s->current_picture_ptr->f.key_frame = s->pict_type == AV_PICTURE_TYPE_I;\n\n\n\n    if ((ret = ff_mpeg_ref_picture(s, &s->current_picture,\n\n                                   s->current_picture_ptr)) < 0)\n\n        return ret;\n\n\n\n    if (s->pict_type != AV_PICTURE_TYPE_B) {\n\n        s->last_picture_ptr = s->next_picture_ptr;\n\n        if (!s->droppable)\n\n            s->next_picture_ptr = s->current_picture_ptr;\n\n    }\n\n    av_dlog(s->avctx, \"L%p N%p C%p L%p N%p C%p type:%d drop:%d\\n\",\n\n            s->last_picture_ptr, s->next_picture_ptr,s->current_picture_ptr,\n\n            s->last_picture_ptr    ? s->last_picture_ptr->f.data[0]    : NULL,\n\n            s->next_picture_ptr    ? s->next_picture_ptr->f.data[0]    : NULL,\n\n            s->current_picture_ptr ? s->current_picture_ptr->f.data[0] : NULL,\n\n            s->pict_type, s->droppable);\n\n\n\n    if ((s->last_picture_ptr == NULL ||\n\n         s->last_picture_ptr->f.buf[0] == NULL) &&\n\n        (s->pict_type != AV_PICTURE_TYPE_I ||\n\n         s->picture_structure != PICT_FRAME)) {\n\n        int h_chroma_shift, v_chroma_shift;\n\n        av_pix_fmt_get_chroma_sub_sample(s->avctx->pix_fmt,\n\n                                         &h_chroma_shift, &v_chroma_shift);\n\n        if (s->pict_type == AV_PICTURE_TYPE_B && s->next_picture_ptr && s->next_picture_ptr->f.buf[0])\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocating dummy last picture for B frame\\n\");\n\n        else if (s->pict_type != AV_PICTURE_TYPE_I)\n\n            av_log(avctx, AV_LOG_ERROR,\n\n                   \"warning: first frame is no keyframe\\n\");\n\n        else if (s->picture_structure != PICT_FRAME)\n\n            av_log(avctx, AV_LOG_DEBUG,\n\n                   \"allocate dummy last picture for field based first keyframe\\n\");\n\n\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->last_picture_ptr = &s->picture[i];\n\n\n\n        s->last_picture_ptr->reference   = 3;\n\n        s->last_picture_ptr->f.key_frame = 0;\n\n        s->last_picture_ptr->f.pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->last_picture_ptr, 0) < 0) {\n\n            s->last_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n\n\n        memset(s->last_picture_ptr->f.data[0], 0x80,\n\n               avctx->height * s->last_picture_ptr->f.linesize[0]);\n\n        memset(s->last_picture_ptr->f.data[1], 0x80,\n\n               (avctx->height >> v_chroma_shift) *\n\n               s->last_picture_ptr->f.linesize[1]);\n\n        memset(s->last_picture_ptr->f.data[2], 0x80,\n\n               (avctx->height >> v_chroma_shift) *\n\n               s->last_picture_ptr->f.linesize[2]);\n\n\n\n        if(s->codec_id == AV_CODEC_ID_FLV1 || s->codec_id == AV_CODEC_ID_H263){\n\n            for(i=0; i<avctx->height; i++)\n\n            memset(s->last_picture_ptr->f.data[0] + s->last_picture_ptr->f.linesize[0]*i, 16, avctx->width);\n\n        }\n\n\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->last_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n    if ((s->next_picture_ptr == NULL ||\n\n         s->next_picture_ptr->f.buf[0] == NULL) &&\n\n        s->pict_type == AV_PICTURE_TYPE_B) {\n\n        /* Allocate a dummy frame */\n\n        i = ff_find_unused_picture(s, 0);\n\n        if (i < 0) {\n\n            av_log(s->avctx, AV_LOG_ERROR, \"no frame buffer available\\n\");\n\n            return i;\n\n        }\n\n        s->next_picture_ptr = &s->picture[i];\n\n\n\n        s->next_picture_ptr->reference   = 3;\n\n        s->next_picture_ptr->f.key_frame = 0;\n\n        s->next_picture_ptr->f.pict_type = AV_PICTURE_TYPE_P;\n\n\n\n        if (ff_alloc_picture(s, s->next_picture_ptr, 0) < 0) {\n\n            s->next_picture_ptr = NULL;\n\n            return -1;\n\n        }\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 0);\n\n        ff_thread_report_progress(&s->next_picture_ptr->tf, INT_MAX, 1);\n\n    }\n\n\n\n#if 0 // BUFREF-FIXME\n\n    memset(s->last_picture.f.data, 0, sizeof(s->last_picture.f.data));\n\n    memset(s->next_picture.f.data, 0, sizeof(s->next_picture.f.data));\n\n#endif\n\n    if (s->last_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->last_picture);\n\n        if (s->last_picture_ptr->f.buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->last_picture,\n\n                                       s->last_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n    if (s->next_picture_ptr) {\n\n        ff_mpeg_unref_picture(s, &s->next_picture);\n\n        if (s->next_picture_ptr->f.buf[0] &&\n\n            (ret = ff_mpeg_ref_picture(s, &s->next_picture,\n\n                                       s->next_picture_ptr)) < 0)\n\n            return ret;\n\n    }\n\n\n\n    av_assert0(s->pict_type == AV_PICTURE_TYPE_I || (s->last_picture_ptr &&\n\n                                                 s->last_picture_ptr->f.buf[0]));\n\n\n\n    if (s->picture_structure!= PICT_FRAME) {\n\n        int i;\n\n        for (i = 0; i < 4; i++) {\n\n            if (s->picture_structure == PICT_BOTTOM_FIELD) {\n\n                s->current_picture.f.data[i] +=\n\n                    s->current_picture.f.linesize[i];\n\n            }\n\n            s->current_picture.f.linesize[i] *= 2;\n\n            s->last_picture.f.linesize[i]    *= 2;\n\n            s->next_picture.f.linesize[i]    *= 2;\n\n        }\n\n    }\n\n\n\n    s->err_recognition = avctx->err_recognition;\n\n\n\n    /* set dequantizer, we can't do it during init as\n\n     * it might change for mpeg4 and we can't do it in the header\n\n     * decode as init is not called for mpeg4 there yet */\n\n    if (s->mpeg_quant || s->codec_id == AV_CODEC_ID_MPEG2VIDEO) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg2_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg2_inter;\n\n    } else if (s->out_format == FMT_H263 || s->out_format == FMT_H261) {\n\n        s->dct_unquantize_intra = s->dct_unquantize_h263_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_h263_inter;\n\n    } else {\n\n        s->dct_unquantize_intra = s->dct_unquantize_mpeg1_intra;\n\n        s->dct_unquantize_inter = s->dct_unquantize_mpeg1_inter;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 24881, "_split": "test", "_hash": "219ef0ef17273ebabc031880ef247a06"}
{"project": "FFmpeg", "commit_id": "41abc9da50ba7a7b68bbbf6622475ce7a3c72e3f", "target": 1, "func": "static int decode_frame_ilbm(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    IffContext *s = avctx->priv_data;\n\n    const uint8_t *buf = avpkt->size >= 2 ? avpkt->data + AV_RB16(avpkt->data) : NULL;\n\n    const int buf_size = avpkt->size >= 2 ? avpkt->size - AV_RB16(avpkt->data) : 0;\n\n    const uint8_t *buf_end = buf+buf_size;\n\n    int y, plane, res;\n\n\n\n    if ((res = extract_header(avctx, avpkt)) < 0)\n\n        return res;\n\n\n\n    if (s->init) {\n\n        if ((res = avctx->reget_buffer(avctx, &s->frame)) < 0) {\n\n            av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n            return res;\n\n        }\n\n    } else if ((res = avctx->get_buffer(avctx, &s->frame)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return res;\n\n    } else if (avctx->bits_per_coded_sample <= 8 && avctx->pix_fmt != PIX_FMT_GRAY8) {\n\n        if ((res = ff_cmap_read_palette(avctx, (uint32_t*)s->frame.data[1])) < 0)\n\n            return res;\n\n    }\n\n    s->init = 1;\n\n\n\n    if (avctx->codec_tag == MKTAG('A','C','B','M')) {\n\n        if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n            memset(s->frame.data[0], 0, avctx->height * s->frame.linesize[0]);\n\n            for (plane = 0; plane < s->bpp; plane++) {\n\n                for(y = 0; y < avctx->height && buf < buf_end; y++ ) {\n\n                    uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                    decodeplane8(row, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n            }\n\n        } else if (s->ham) { // HAM to PIX_FMT_BGR32\n\n            memset(s->frame.data[0], 0, avctx->height * s->frame.linesize[0]);\n\n            for(y = 0; y < avctx->height; y++) {\n\n                uint8_t *row = &s->frame.data[0][y * s->frame.linesize[0]];\n\n                memset(s->ham_buf, 0, s->planesize * 8);\n\n                for (plane = 0; plane < s->bpp; plane++) {\n\n                    const uint8_t * start = buf + (plane * avctx->height + y) * s->planesize;\n\n                    if (start >= buf_end)\n\n                        break;\n\n                    decodeplane8(s->ham_buf, start, FFMIN(s->planesize, buf_end - start), plane);\n\n                }\n\n                decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, s->planesize);\n\n            }\n\n        }\n\n    } else if (avctx->codec_tag == MKTAG('D','E','E','P')) {\n\n        int raw_width = avctx->width * (av_get_bits_per_pixel(&av_pix_fmt_descriptors[avctx->pix_fmt]) >> 3);\n\n        int x;\n\n        for(y = 0; y < avctx->height && buf < buf_end; y++ ) {\n\n            uint8_t *row = &s->frame.data[0][y * s->frame.linesize[0]];\n\n            memcpy(row, buf, FFMIN(raw_width, buf_end - buf));\n\n            buf += raw_width;\n\n            if (avctx->pix_fmt == PIX_FMT_BGR32) {\n\n                for(x = 0; x < avctx->width; x++)\n\n                    row[4 * x + 3] = row[4 * x + 3] & 0xF0 | (row[4 * x + 3] >> 4);\n\n            }\n\n        }\n\n    } else if (avctx->codec_tag == MKTAG('I','L','B','M')) { // interleaved\n\n        if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n            for(y = 0; y < avctx->height; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                memset(row, 0, avctx->width);\n\n                for (plane = 0; plane < s->bpp && buf < buf_end; plane++) {\n\n                    decodeplane8(row, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n            }\n\n        } else if (s->ham) { // HAM to PIX_FMT_BGR32\n\n            for (y = 0; y < avctx->height; y++) {\n\n                uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                memset(s->ham_buf, 0, s->planesize * 8);\n\n                for (plane = 0; plane < s->bpp && buf < buf_end; plane++) {\n\n                    decodeplane8(s->ham_buf, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n                decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, s->planesize);\n\n            }\n\n        } else { // PIX_FMT_BGR32\n\n            for(y = 0; y < avctx->height; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][y*s->frame.linesize[0]];\n\n                memset(row, 0, avctx->width << 2);\n\n                for (plane = 0; plane < s->bpp && buf < buf_end; plane++) {\n\n                    decodeplane32((uint32_t *) row, buf, FFMIN(s->planesize, buf_end - buf), plane);\n\n                    buf += s->planesize;\n\n                }\n\n            }\n\n        }\n\n    } else if (avctx->codec_tag == MKTAG('P','B','M',' ')) { // IFF-PBM\n\n        if (avctx->pix_fmt == PIX_FMT_PAL8 || avctx->pix_fmt == PIX_FMT_GRAY8) {\n\n            for(y = 0; y < avctx->height; y++ ) {\n\n                uint8_t *row = &s->frame.data[0][y * s->frame.linesize[0]];\n\n                memcpy(row, buf, FFMIN(avctx->width, buf_end - buf));\n\n                buf += avctx->width + (avctx->width % 2); // padding if odd\n\n            }\n\n        } else if (s->ham) { // IFF-PBM: HAM to PIX_FMT_BGR32\n\n            for (y = 0; y < avctx->height; y++) {\n\n                uint8_t *row = &s->frame.data[0][ y*s->frame.linesize[0] ];\n\n                memcpy(s->ham_buf, buf, FFMIN(avctx->width, buf_end - buf));\n\n                buf += avctx->width + (avctx->width & 1); // padding if odd\n\n                decode_ham_plane32((uint32_t *) row, s->ham_buf, s->ham_palbuf, s->planesize);\n\n            }\n\n        } else {\n\n            av_log_ask_for_sample(avctx, \"unsupported bpp\\n\");\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n    return buf_size;\n\n}\n", "idx": 24896, "_split": "test", "_hash": "d81054a683df4143c4d3f1724d3f2a39"}
{"project": "FFmpeg", "commit_id": "39e0accb7a934bfe3d42324b016dd8790790746d", "target": 1, "func": "static unsigned int find_best(struct vf_instance *vf){\n\n  int is_format_okay = vf->next->query_format(vf->next, IMGFMT_YV12);\n\n  if ((is_format_okay & VFCAP_CSP_SUPPORTED_BY_HW) || (is_format_okay & VFCAP_CSP_SUPPORTED))\n\n    return IMGFMT_YV12;\n\n  else\n\n    return 0;\n\n}\n", "idx": 25066, "_split": "test", "_hash": "bc48c08d99195dfdb7165d5b5633d802"}
{"project": "FFmpeg", "commit_id": "5d5118f81bd51b9c33500616b3c637123e8e4691", "target": 1, "func": "static inline void idct_col(int16_t *blk, const uint8_t *quant)\n\n{\n\n    int t0, t1, t2, t3, t4, t5, t6, t7, t8, t9, tA, tB, tC, tD, tE, tF;\n\n    int t10, t11, t12, t13;\n\n    int s0, s1, s2, s3, s4, s5, s6, s7;\n\n\n\n    s0 = (int) blk[0 * 8] * quant[0 * 8];\n\n    s1 = (int) blk[1 * 8] * quant[1 * 8];\n\n    s2 = (int) blk[2 * 8] * quant[2 * 8];\n\n    s3 = (int) blk[3 * 8] * quant[3 * 8];\n\n    s4 = (int) blk[4 * 8] * quant[4 * 8];\n\n    s5 = (int) blk[5 * 8] * quant[5 * 8];\n\n    s6 = (int) blk[6 * 8] * quant[6 * 8];\n\n    s7 = (int) blk[7 * 8] * quant[7 * 8];\n\n\n\n    t0  =  (s3 * 19266 + s5 * 12873) >> 15;\n\n    t1  =  (s5 * 19266 - s3 * 12873) >> 15;\n\n    t2  = ((s7 * 4520  + s1 * 22725) >> 15) - t0;\n\n    t3  = ((s1 * 4520  - s7 * 22725) >> 15) - t1;\n\n    t4  = t0 * 2 + t2;\n\n    t5  = t1 * 2 + t3;\n\n    t6  = t2 - t3;\n\n    t7  = t3 * 2 + t6;\n\n    t8  = (t6 * 11585) >> 14;\n\n    t9  = (t7 * 11585) >> 14;\n\n    tA  = (s2 * 8867 - s6 * 21407) >> 14;\n\n    tB  = (s6 * 8867 + s2 * 21407) >> 14;\n\n    tC  = (s0 >> 1) - (s4 >> 1);\n\n    tD  = (s4 >> 1) * 2 + tC;\n\n    tE  = tC - (tA >> 1);\n\n    tF  = tD - (tB >> 1);\n\n    t10 = tF - t5;\n\n    t11 = tE - t8;\n\n    t12 = tE + (tA >> 1) * 2 - t9;\n\n    t13 = tF + (tB >> 1) * 2 - t4;\n\n\n\n    blk[0 * 8] = t13 + t4 * 2;\n\n    blk[1 * 8] = t12 + t9 * 2;\n\n    blk[2 * 8] = t11 + t8 * 2;\n\n    blk[3 * 8] = t10 + t5 * 2;\n\n    blk[4 * 8] = t10;\n\n    blk[5 * 8] = t11;\n\n    blk[6 * 8] = t12;\n\n    blk[7 * 8] = t13;\n\n}\n", "idx": 25081, "_split": "test", "_hash": "4719cf3af57e62823cf61902f7ee9b2e"}
{"project": "FFmpeg", "commit_id": "87e8788680e16c51f6048af26f3f7830c35207a5", "target": 0, "func": "static int fourxm_probe(AVProbeData *p)\n\n{\n\n    if (p->buf_size < 12)\n\n        return 0;\n\n\n\n    if ((AV_RL32(&p->buf[0]) != RIFF_TAG) ||\n\n        (AV_RL32(&p->buf[8]) != _4XMV_TAG))\n\n        return 0;\n\n\n\n    return AVPROBE_SCORE_MAX;\n\n}\n", "idx": 25091, "_split": "test", "_hash": "8281c52ad2a68fa469ca4e1899a8563d"}
{"project": "FFmpeg", "commit_id": "2c9be3882a03823413945bd9e2d9af33e6e322d5", "target": 0, "func": "static void jpeg_table_header(AVCodecContext *avctx, PutBitContext *p,\n\n                              ScanTable *intra_scantable,\n\n                              uint16_t luma_intra_matrix[64],\n\n                              uint16_t chroma_intra_matrix[64],\n\n                              int hsample[3])\n\n{\n\n    int i, j, size;\n\n    uint8_t *ptr;\n\n    MpegEncContext *s = avctx->priv_data;\n\n\n\n    if (avctx->codec_id != AV_CODEC_ID_LJPEG) {\n\n        int matrix_count = 1 + !!memcmp(luma_intra_matrix,\n\n                                        chroma_intra_matrix,\n\n                                        sizeof(luma_intra_matrix[0]) * 64);\n\n    if (s->force_duplicated_matrix)\n\n        matrix_count = 2;\n\n    /* quant matrixes */\n\n    put_marker(p, DQT);\n\n    put_bits(p, 16, 2 + matrix_count * (1 + 64));\n\n    put_bits(p, 4, 0); /* 8 bit precision */\n\n    put_bits(p, 4, 0); /* table 0 */\n\n    for(i=0;i<64;i++) {\n\n        j = intra_scantable->permutated[i];\n\n        put_bits(p, 8, luma_intra_matrix[j]);\n\n    }\n\n\n\n        if (matrix_count > 1) {\n\n            put_bits(p, 4, 0); /* 8 bit precision */\n\n            put_bits(p, 4, 1); /* table 1 */\n\n            for(i=0;i<64;i++) {\n\n                j = intra_scantable->permutated[i];\n\n                put_bits(p, 8, chroma_intra_matrix[j]);\n\n            }\n\n        }\n\n    }\n\n\n\n    if(avctx->active_thread_type & FF_THREAD_SLICE){\n\n        put_marker(p, DRI);\n\n        put_bits(p, 16, 4);\n\n        put_bits(p, 16, (avctx->width-1)/(8*hsample[0]) + 1);\n\n    }\n\n\n\n    /* huffman table */\n\n    put_marker(p, DHT);\n\n    flush_put_bits(p);\n\n    ptr = put_bits_ptr(p);\n\n    put_bits(p, 16, 0); /* patched later */\n\n    size = 2;\n\n\n\n    // Only MJPEG can have a variable Huffman variable. All other\n\n    // formats use the default Huffman table.\n\n    if (s->out_format == FMT_MJPEG && s->huffman == HUFFMAN_TABLE_OPTIMAL) {\n\n        size += put_huffman_table(p, 0, 0, s->mjpeg_ctx->bits_dc_luminance,\n\n                                  s->mjpeg_ctx->val_dc_luminance);\n\n        size += put_huffman_table(p, 0, 1, s->mjpeg_ctx->bits_dc_chrominance,\n\n                                  s->mjpeg_ctx->val_dc_chrominance);\n\n\n\n        size += put_huffman_table(p, 1, 0, s->mjpeg_ctx->bits_ac_luminance,\n\n                                  s->mjpeg_ctx->val_ac_luminance);\n\n        size += put_huffman_table(p, 1, 1, s->mjpeg_ctx->bits_ac_chrominance,\n\n                                  s->mjpeg_ctx->val_ac_chrominance);\n\n    } else {\n\n        size += put_huffman_table(p, 0, 0, avpriv_mjpeg_bits_dc_luminance,\n\n                                  avpriv_mjpeg_val_dc);\n\n        size += put_huffman_table(p, 0, 1, avpriv_mjpeg_bits_dc_chrominance,\n\n                                  avpriv_mjpeg_val_dc);\n\n\n\n        size += put_huffman_table(p, 1, 0, avpriv_mjpeg_bits_ac_luminance,\n\n                                  avpriv_mjpeg_val_ac_luminance);\n\n        size += put_huffman_table(p, 1, 1, avpriv_mjpeg_bits_ac_chrominance,\n\n                                  avpriv_mjpeg_val_ac_chrominance);\n\n    }\n\n    AV_WB16(ptr, size);\n\n}\n", "idx": 25095, "_split": "test", "_hash": "bcffbbd04f06c870b1b0bc168b95275d"}
{"project": "FFmpeg", "commit_id": "fb1473080223a634b8ac2cca48a632d037a0a69d", "target": 1, "func": "static int aac_sync(uint64_t state, AACAC3ParseContext *hdr_info,\n\n        int *need_next_header, int *new_frame_start)\n\n{\n\n    GetBitContext bits;\n\n    AACADTSHeaderInfo hdr;\n\n    int size;\n\n    union {\n\n        uint64_t u64;\n\n        uint8_t  u8[8];\n\n    } tmp;\n\n\n\n    tmp.u64 = av_be2ne64(state);\n\n    init_get_bits(&bits, tmp.u8+8-AAC_ADTS_HEADER_SIZE, AAC_ADTS_HEADER_SIZE * 8);\n\n\n\n    if ((size = avpriv_aac_parse_header(&bits, &hdr)) < 0)\n\n        return 0;\n\n    *need_next_header = 0;\n\n    *new_frame_start  = 1;\n\n    hdr_info->sample_rate = hdr.sample_rate;\n\n    hdr_info->channels    = ff_mpeg4audio_channels[hdr.chan_config];\n\n    hdr_info->samples     = hdr.samples;\n\n    hdr_info->bit_rate    = hdr.bit_rate;\n\n    return size;\n\n}\n", "idx": 25130, "_split": "test", "_hash": "253cf542ced6409ca60984025647d5f8"}
{"project": "FFmpeg", "commit_id": "3228ac730c11eca49d5680d5550128e397061c85", "target": 1, "func": "static av_cold int vc2_encode_init(AVCodecContext *avctx)\n\n{\n\n    Plane *p;\n\n    SubBand *b;\n\n    int i, j, level, o, shift, ret;\n\n    const AVPixFmtDescriptor *fmt = av_pix_fmt_desc_get(avctx->pix_fmt);\n\n    const int depth = fmt->comp[0].depth;\n\n    VC2EncContext *s = avctx->priv_data;\n\n\n\n    s->picture_number = 0;\n\n\n\n    /* Total allowed quantization range */\n\n    s->q_ceil    = DIRAC_MAX_QUANT_INDEX;\n\n\n\n    s->ver.major = 2;\n\n    s->ver.minor = 0;\n\n    s->profile   = 3;\n\n    s->level     = 3;\n\n\n\n    s->base_vf   = -1;\n\n    s->strict_compliance = 1;\n\n\n\n    s->q_avg = 0;\n\n    s->slice_max_bytes = 0;\n\n    s->slice_min_bytes = 0;\n\n\n\n    /* Mark unknown as progressive */\n\n    s->interlaced = !((avctx->field_order == AV_FIELD_UNKNOWN) ||\n\n                      (avctx->field_order == AV_FIELD_PROGRESSIVE));\n\n\n\n    for (i = 0; i < base_video_fmts_len; i++) {\n\n        const VC2BaseVideoFormat *fmt = &base_video_fmts[i];\n\n        if (avctx->pix_fmt != fmt->pix_fmt)\n\n            continue;\n\n        if (avctx->time_base.num != fmt->time_base.num)\n\n            continue;\n\n        if (avctx->time_base.den != fmt->time_base.den)\n\n            continue;\n\n        if (avctx->width != fmt->width)\n\n            continue;\n\n        if (avctx->height != fmt->height)\n\n            continue;\n\n        if (s->interlaced != fmt->interlaced)\n\n            continue;\n\n        s->base_vf = i;\n\n        s->level   = base_video_fmts[i].level;\n\n        break;\n\n    }\n\n\n\n    if (s->interlaced)\n\n        av_log(avctx, AV_LOG_WARNING, \"Interlacing enabled!\\n\");\n\n\n\n    if ((s->slice_width  & (s->slice_width  - 1)) ||\n\n        (s->slice_height & (s->slice_height - 1))) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Slice size is not a power of two!\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if ((s->slice_width > avctx->width) ||\n\n        (s->slice_height > avctx->height)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Slice size is bigger than the image!\\n\");\n\n        return AVERROR_UNKNOWN;\n\n    }\n\n\n\n    if (s->base_vf <= 0) {\n\n        if (avctx->strict_std_compliance < FF_COMPLIANCE_STRICT) {\n\n            s->strict_compliance = s->base_vf = 0;\n\n            av_log(avctx, AV_LOG_WARNING, \"Format does not strictly comply with VC2 specs\\n\");\n\n        } else {\n\n            av_log(avctx, AV_LOG_WARNING, \"Given format does not strictly comply with \"\n\n                   \"the specifications, decrease strictness to use it.\\n\");\n\n            return AVERROR_UNKNOWN;\n\n        }\n\n    } else {\n\n        av_log(avctx, AV_LOG_INFO, \"Selected base video format = %i (%s)\\n\",\n\n               s->base_vf, base_video_fmts[s->base_vf].name);\n\n    }\n\n\n\n    /* Chroma subsampling */\n\n    ret = av_pix_fmt_get_chroma_sub_sample(avctx->pix_fmt, &s->chroma_x_shift, &s->chroma_y_shift);\n\n    if (ret)\n\n        return ret;\n\n\n\n    /* Bit depth and color range index */\n\n    if (depth == 8 && avctx->color_range == AVCOL_RANGE_JPEG) {\n\n        s->bpp = 1;\n\n        s->bpp_idx = 1;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 8 && (avctx->color_range == AVCOL_RANGE_MPEG ||\n\n               avctx->color_range == AVCOL_RANGE_UNSPECIFIED)) {\n\n        s->bpp = 1;\n\n        s->bpp_idx = 2;\n\n        s->diff_offset = 128;\n\n    } else if (depth == 10) {\n\n        s->bpp = 2;\n\n        s->bpp_idx = 3;\n\n        s->diff_offset = 512;\n\n    } else {\n\n        s->bpp = 2;\n\n        s->bpp_idx = 4;\n\n        s->diff_offset = 2048;\n\n    }\n\n\n\n    /* Planes initialization */\n\n    for (i = 0; i < 3; i++) {\n\n        int w, h;\n\n        p = &s->plane[i];\n\n        p->width      = avctx->width  >> (i ? s->chroma_x_shift : 0);\n\n        p->height     = avctx->height >> (i ? s->chroma_y_shift : 0);\n\n        if (s->interlaced)\n\n            p->height >>= 1;\n\n        p->dwt_width  = w = FFALIGN(p->width,  (1 << s->wavelet_depth));\n\n        p->dwt_height = h = FFALIGN(p->height, (1 << s->wavelet_depth));\n\n        p->coef_stride = FFALIGN(p->dwt_width, 32);\n\n        p->coef_buf = av_malloc(p->coef_stride*p->dwt_height*sizeof(dwtcoef));\n\n        if (!p->coef_buf)\n\n            goto alloc_fail;\n\n        for (level = s->wavelet_depth-1; level >= 0; level--) {\n\n            w = w >> 1;\n\n            h = h >> 1;\n\n            for (o = 0; o < 4; o++) {\n\n                b = &p->band[level][o];\n\n                b->width  = w;\n\n                b->height = h;\n\n                b->stride = p->coef_stride;\n\n                shift = (o > 1)*b->height*b->stride + (o & 1)*b->width;\n\n                b->buf = p->coef_buf + shift;\n\n            }\n\n        }\n\n\n\n        /* DWT init */\n\n        if (ff_vc2enc_init_transforms(&s->transform_args[i].t,\n\n                                      s->plane[i].coef_stride,\n\n                                      s->plane[i].dwt_height))\n\n            goto alloc_fail;\n\n    }\n\n\n\n    /* Slices */\n\n    s->num_x = s->plane[0].dwt_width/s->slice_width;\n\n    s->num_y = s->plane[0].dwt_height/s->slice_height;\n\n\n\n    s->slice_args = av_calloc(s->num_x*s->num_y, sizeof(SliceArgs));\n\n    if (!s->slice_args)\n\n        goto alloc_fail;\n\n\n\n    /* Lookup tables */\n\n    s->coef_lut_len = av_malloc(COEF_LUT_TAB*(s->q_ceil+1)*sizeof(*s->coef_lut_len));\n\n    if (!s->coef_lut_len)\n\n        goto alloc_fail;\n\n\n\n    s->coef_lut_val = av_malloc(COEF_LUT_TAB*(s->q_ceil+1)*sizeof(*s->coef_lut_val));\n\n    if (!s->coef_lut_val)\n\n        goto alloc_fail;\n\n\n\n    for (i = 0; i < s->q_ceil; i++) {\n\n        uint8_t  *len_lut = &s->coef_lut_len[i*COEF_LUT_TAB];\n\n        uint32_t *val_lut = &s->coef_lut_val[i*COEF_LUT_TAB];\n\n        for (j = 0; j < COEF_LUT_TAB; j++) {\n\n            get_vc2_ue_uint(QUANT(j, ff_dirac_qscale_tab[i]),\n\n                            &len_lut[j], &val_lut[j]);\n\n            if (len_lut[j] != 1) {\n\n                len_lut[j] += 1;\n\n                val_lut[j] <<= 1;\n\n            } else {\n\n                val_lut[j] = 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    return 0;\n\n\n\nalloc_fail:\n\n    vc2_encode_end(avctx);\n\n    av_log(avctx, AV_LOG_ERROR, \"Unable to allocate memory!\\n\");\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 25135, "_split": "test", "_hash": "40e2e6c7a5e48a1a40d1ae0bd9c71560"}
{"project": "FFmpeg", "commit_id": "b86651a208ee67666a7305b002bc9f14b21dae7f", "target": 1, "func": "static av_cold int rv40_decode_init(AVCodecContext *avctx)\n\n{\n\n    RV34DecContext *r = avctx->priv_data;\n\n\n\n    r->rv30 = 0;\n\n    ff_rv34_decode_init(avctx);\n\n    if(!aic_top_vlc.bits)\n\n        rv40_init_tables();\n\n    r->parse_slice_header = rv40_parse_slice_header;\n\n    r->decode_intra_types = rv40_decode_intra_types;\n\n    r->decode_mb_info     = rv40_decode_mb_info;\n\n    r->loop_filter        = rv40_loop_filter;\n\n    r->luma_dc_quant_i = rv40_luma_dc_quant[0];\n\n    r->luma_dc_quant_p = rv40_luma_dc_quant[1];\n\n    return 0;\n\n}\n", "idx": 25149, "_split": "test", "_hash": "bf5ec75e18565d76c8ff9b2c3be1e57d"}
{"project": "FFmpeg", "commit_id": "5a412a5c3cc216ae1d15e6b884bda7214b73a5b0", "target": 1, "func": "static int extract_extradata_h2645(AVBSFContext *ctx, AVPacket *pkt,\n\n                                   uint8_t **data, int *size)\n\n{\n\n    static const int extradata_nal_types_hevc[] = {\n\n        HEVC_NAL_VPS, HEVC_NAL_SPS, HEVC_NAL_PPS,\n\n    };\n\n    static const int extradata_nal_types_h264[] = {\n\n        H264_NAL_SPS, H264_NAL_PPS,\n\n    };\n\n\n\n    ExtractExtradataContext *s = ctx->priv_data;\n\n\n\n    H2645Packet h2645_pkt = { 0 };\n\n    int extradata_size = 0;\n\n    const int *extradata_nal_types;\n\n    int nb_extradata_nal_types;\n\n    int i, has_sps = 0, has_vps = 0, ret = 0;\n\n\n\n    if (ctx->par_in->codec_id == AV_CODEC_ID_HEVC) {\n\n        extradata_nal_types    = extradata_nal_types_hevc;\n\n        nb_extradata_nal_types = FF_ARRAY_ELEMS(extradata_nal_types_hevc);\n\n    } else {\n\n        extradata_nal_types    = extradata_nal_types_h264;\n\n        nb_extradata_nal_types = FF_ARRAY_ELEMS(extradata_nal_types_h264);\n\n    }\n\n\n\n    ret = ff_h2645_packet_split(&h2645_pkt, pkt->data, pkt->size,\n\n                                ctx, 0, 0, ctx->par_in->codec_id, 1);\n\n    if (ret < 0)\n\n        return ret;\n\n\n\n    for (i = 0; i < h2645_pkt.nb_nals; i++) {\n\n        H2645NAL *nal = &h2645_pkt.nals[i];\n\n        if (val_in_array(extradata_nal_types, nb_extradata_nal_types, nal->type)) {\n\n            extradata_size += nal->raw_size + 3;\n\n            if (ctx->par_in->codec_id == AV_CODEC_ID_HEVC) {\n\n                if (nal->type == HEVC_NAL_SPS) has_sps = 1;\n\n                if (nal->type == HEVC_NAL_VPS) has_vps = 1;\n\n            } else {\n\n                if (nal->type == H264_NAL_SPS) has_sps = 1;\n\n            }\n\n        }\n\n    }\n\n\n\n    if (extradata_size &&\n\n        ((ctx->par_in->codec_id == AV_CODEC_ID_HEVC && has_sps && has_vps) ||\n\n         (ctx->par_in->codec_id == AV_CODEC_ID_H264 && has_sps))) {\n\n        AVBufferRef *filtered_buf;\n\n        uint8_t *extradata, *filtered_data;\n\n\n\n        if (s->remove) {\n\n            filtered_buf = av_buffer_alloc(pkt->size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n            if (!filtered_buf) {\n\n                ret = AVERROR(ENOMEM);\n\n                goto fail;\n\n            }\n\n            filtered_data = filtered_buf->data;\n\n        }\n\n\n\n        extradata = av_malloc(extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n\n        if (!extradata) {\n\n            av_buffer_unref(&filtered_buf);\n\n            ret = AVERROR(ENOMEM);\n\n            goto fail;\n\n        }\n\n\n\n        *data = extradata;\n\n        *size = extradata_size;\n\n\n\n        for (i = 0; i < h2645_pkt.nb_nals; i++) {\n\n            H2645NAL *nal = &h2645_pkt.nals[i];\n\n            if (val_in_array(extradata_nal_types, nb_extradata_nal_types,\n\n                             nal->type)) {\n\n                AV_WB24(extradata, 1); // startcode\n\n                memcpy(extradata + 3, nal->raw_data, nal->raw_size);\n\n                extradata += 3 + nal->raw_size;\n\n            } else if (s->remove) {\n\n                AV_WB24(filtered_data, 1); // startcode\n\n                memcpy(filtered_data + 3, nal->raw_data, nal->raw_size);\n\n                filtered_data += 3 + nal->raw_size;\n\n            }\n\n        }\n\n\n\n        if (s->remove) {\n\n            av_buffer_unref(&pkt->buf);\n\n            pkt->buf  = filtered_buf;\n\n            pkt->data = filtered_buf->data;\n\n            pkt->size = filtered_data - filtered_buf->data;\n\n        }\n\n    }\n\n\n\nfail:\n\n    ff_h2645_packet_uninit(&h2645_pkt);\n\n    return ret;\n\n}\n", "idx": 25179, "_split": "test", "_hash": "01627ae114201d8e1f65d1e349dd0ef4"}
{"project": "FFmpeg", "commit_id": "0409d333115e623b5ccdbb364d64ca2a52fd8467", "target": 1, "func": "static void FUNC(put_hevc_epel_bi_w_h)(uint8_t *_dst, ptrdiff_t _dststride, uint8_t *_src, ptrdiff_t _srcstride,\n\n                                       int16_t *src2,\n\n                                       int height, int denom, int wx0, int wx1,\n\n                                       int ox0, int ox1, intptr_t mx, intptr_t my, int width)\n\n{\n\n    int x, y;\n\n    pixel *src = (pixel *)_src;\n\n    ptrdiff_t srcstride  = _srcstride / sizeof(pixel);\n\n    pixel *dst          = (pixel *)_dst;\n\n    ptrdiff_t dststride = _dststride / sizeof(pixel);\n\n    const int8_t *filter = ff_hevc_epel_filters[mx - 1];\n\n    int shift = 14 + 1 - BIT_DEPTH;\n\n    int log2Wd = denom + shift - 1;\n\n\n\n    ox0     = ox0 * (1 << (BIT_DEPTH - 8));\n\n    ox1     = ox1 * (1 << (BIT_DEPTH - 8));\n\n    for (y = 0; y < height; y++) {\n\n        for (x = 0; x < width; x++)\n\n            dst[x] = av_clip_pixel(((EPEL_FILTER(src, 1) >> (BIT_DEPTH - 8)) * wx1 + src2[x] * wx0 +\n\n                                    ((ox0 + ox1 + 1) << log2Wd)) >> (log2Wd + 1));\n\n        src  += srcstride;\n\n        dst  += dststride;\n\n        src2 += MAX_PB_SIZE;\n\n    }\n\n}\n", "idx": 25181, "_split": "test", "_hash": "17b71e8d49e71ad1643c5017682554c6"}
{"project": "FFmpeg", "commit_id": "04763c6f87690b31cfcd0d324cf36a451531dcd0", "target": 1, "func": "static void pred_spatial_direct_motion(const H264Context *const h, H264SliceContext *sl,\n\n                                       int *mb_type)\n\n{\n\n    int b8_stride = 2;\n\n    int b4_stride = h->b_stride;\n\n    int mb_xy = sl->mb_xy, mb_y = sl->mb_y;\n\n    int mb_type_col[2];\n\n    const int16_t (*l1mv0)[2], (*l1mv1)[2];\n\n    const int8_t *l1ref0, *l1ref1;\n\n    const int is_b8x8 = IS_8X8(*mb_type);\n\n    unsigned int sub_mb_type = MB_TYPE_L0L1;\n\n    int i8, i4;\n\n    int ref[2];\n\n    int mv[2];\n\n    int list;\n\n\n\n    assert(sl->ref_list[1][0].reference & 3);\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent,\n\n                           sl->mb_y + !!IS_INTERLACED(*mb_type));\n\n\n\n#define MB_TYPE_16x16_OR_INTRA (MB_TYPE_16x16 | MB_TYPE_INTRA4x4 | \\\n\n                                MB_TYPE_INTRA16x16 | MB_TYPE_INTRA_PCM)\n\n\n\n    /* ref = min(neighbors) */\n\n    for (list = 0; list < 2; list++) {\n\n        int left_ref     = sl->ref_cache[list][scan8[0] - 1];\n\n        int top_ref      = sl->ref_cache[list][scan8[0] - 8];\n\n        int refc         = sl->ref_cache[list][scan8[0] - 8 + 4];\n\n        const int16_t *C = sl->mv_cache[list][scan8[0]  - 8 + 4];\n\n        if (refc == PART_NOT_AVAILABLE) {\n\n            refc = sl->ref_cache[list][scan8[0] - 8 - 1];\n\n            C    = sl->mv_cache[list][scan8[0]  - 8 - 1];\n\n        }\n\n        ref[list] = FFMIN3((unsigned)left_ref,\n\n                           (unsigned)top_ref,\n\n                           (unsigned)refc);\n\n        if (ref[list] >= 0) {\n\n            /* This is just pred_motion() but with the cases removed that\n\n             * cannot happen for direct blocks. */\n\n            const int16_t *const A = sl->mv_cache[list][scan8[0] - 1];\n\n            const int16_t *const B = sl->mv_cache[list][scan8[0] - 8];\n\n\n\n            int match_count = (left_ref == ref[list]) +\n\n                              (top_ref  == ref[list]) +\n\n                              (refc     == ref[list]);\n\n\n\n            if (match_count > 1) { // most common\n\n                mv[list] = pack16to32(mid_pred(A[0], B[0], C[0]),\n\n                                      mid_pred(A[1], B[1], C[1]));\n\n            } else {\n\n                assert(match_count == 1);\n\n                if (left_ref == ref[list])\n\n                    mv[list] = AV_RN32A(A);\n\n                else if (top_ref == ref[list])\n\n                    mv[list] = AV_RN32A(B);\n\n                else\n\n                    mv[list] = AV_RN32A(C);\n\n            }\n\n        } else {\n\n            int mask = ~(MB_TYPE_L0 << (2 * list));\n\n            mv[list]  = 0;\n\n            ref[list] = -1;\n\n            if (!is_b8x8)\n\n                *mb_type &= mask;\n\n            sub_mb_type &= mask;\n\n        }\n\n    }\n\n    if (ref[0] < 0 && ref[1] < 0) {\n\n        ref[0] = ref[1] = 0;\n\n        if (!is_b8x8)\n\n            *mb_type |= MB_TYPE_L0L1;\n\n        sub_mb_type |= MB_TYPE_L0L1;\n\n    }\n\n\n\n    if (!(is_b8x8 | mv[0] | mv[1])) {\n\n        fill_rectangle(&sl->ref_cache[0][scan8[0]], 4, 4, 8, (uint8_t)ref[0], 1);\n\n        fill_rectangle(&sl->ref_cache[1][scan8[0]], 4, 4, 8, (uint8_t)ref[1], 1);\n\n        fill_rectangle(&sl->mv_cache[0][scan8[0]], 4, 4, 8, 0, 4);\n\n        fill_rectangle(&sl->mv_cache[1][scan8[0]], 4, 4, 8, 0, 4);\n\n        *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                 MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                   MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n        return;\n\n    }\n\n\n\n    if (IS_INTERLACED(sl->ref_list[1][0].parent->mb_type[mb_xy])) { // AFL/AFR/FR/FL -> AFL/FL\n\n        if (!IS_INTERLACED(*mb_type)) {                    //     AFR/FR    -> AFL/FL\n\n            mb_y  = (sl->mb_y & ~1) + sl->col_parity;\n\n            mb_xy = sl->mb_x +\n\n                    ((sl->mb_y & ~1) + sl->col_parity) * h->mb_stride;\n\n            b8_stride = 0;\n\n        } else {\n\n            mb_y  += sl->col_fieldoff;\n\n            mb_xy += h->mb_stride * sl->col_fieldoff; // non-zero for FL -> FL & differ parity\n\n        }\n\n        goto single_col;\n\n    } else {                                             // AFL/AFR/FR/FL -> AFR/FR\n\n        if (IS_INTERLACED(*mb_type)) {                   // AFL       /FL -> AFR/FR\n\n            mb_y           =  sl->mb_y & ~1;\n\n            mb_xy          = (sl->mb_y & ~1) * h->mb_stride + sl->mb_x;\n\n            mb_type_col[0] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n            mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy + h->mb_stride];\n\n            b8_stride      = 2 + 4 * h->mb_stride;\n\n            b4_stride     *= 6;\n\n            if (IS_INTERLACED(mb_type_col[0]) !=\n\n                IS_INTERLACED(mb_type_col[1])) {\n\n                mb_type_col[0] &= ~MB_TYPE_INTERLACED;\n\n                mb_type_col[1] &= ~MB_TYPE_INTERLACED;\n\n            }\n\n\n\n            sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n            if ((mb_type_col[0] & MB_TYPE_16x16_OR_INTRA) &&\n\n                (mb_type_col[1] & MB_TYPE_16x16_OR_INTRA) &&\n\n                !is_b8x8) {\n\n                *mb_type |= MB_TYPE_16x8 | MB_TYPE_DIRECT2;  /* B_16x8 */\n\n            } else {\n\n                *mb_type |= MB_TYPE_8x8;\n\n            }\n\n        } else {                                         //     AFR/FR    -> AFR/FR\n\nsingle_col:\n\n            mb_type_col[0] =\n\n            mb_type_col[1] = sl->ref_list[1][0].parent->mb_type[mb_xy];\n\n\n\n            sub_mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_SUB_8x8 */\n\n            if (!is_b8x8 && (mb_type_col[0] & MB_TYPE_16x16_OR_INTRA)) {\n\n                *mb_type |= MB_TYPE_16x16 | MB_TYPE_DIRECT2; /* B_16x16 */\n\n            } else if (!is_b8x8 &&\n\n                       (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16))) {\n\n                *mb_type |= MB_TYPE_DIRECT2 |\n\n                            (mb_type_col[0] & (MB_TYPE_16x8 | MB_TYPE_8x16));\n\n            } else {\n\n                if (!h->ps.sps->direct_8x8_inference_flag) {\n\n                    /* FIXME: Save sub mb types from previous frames (or derive\n\n                     * from MVs) so we know exactly what block size to use. */\n\n                    sub_mb_type += (MB_TYPE_8x8 - MB_TYPE_16x16); /* B_SUB_4x4 */\n\n                }\n\n                *mb_type |= MB_TYPE_8x8;\n\n            }\n\n        }\n\n    }\n\n\n\n    await_reference_mb_row(h, sl->ref_list[1][0].parent, mb_y);\n\n\n\n    l1mv0  = &sl->ref_list[1][0].parent->motion_val[0][h->mb2b_xy[mb_xy]];\n\n    l1mv1  = &sl->ref_list[1][0].parent->motion_val[1][h->mb2b_xy[mb_xy]];\n\n    l1ref0 = &sl->ref_list[1][0].parent->ref_index[0][4 * mb_xy];\n\n    l1ref1 = &sl->ref_list[1][0].parent->ref_index[1][4 * mb_xy];\n\n    if (!b8_stride) {\n\n        if (sl->mb_y & 1) {\n\n            l1ref0 += 2;\n\n            l1ref1 += 2;\n\n            l1mv0  += 2 * b4_stride;\n\n            l1mv1  += 2 * b4_stride;\n\n        }\n\n    }\n\n\n\n    if (IS_INTERLACED(*mb_type) != IS_INTERLACED(mb_type_col[0])) {\n\n        int n = 0;\n\n        for (i8 = 0; i8 < 4; i8++) {\n\n            int x8  = i8 & 1;\n\n            int y8  = i8 >> 1;\n\n            int xy8 = x8     + y8 * b8_stride;\n\n            int xy4 = x8 * 3 + y8 * b4_stride;\n\n            int a, b;\n\n\n\n            if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                continue;\n\n            sl->sub_mb_type[i8] = sub_mb_type;\n\n\n\n            fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[0], 1);\n\n            fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[1], 1);\n\n            if (!IS_INTRA(mb_type_col[y8]) && !sl->ref_list[1][0].parent->long_ref &&\n\n                ((l1ref0[xy8] == 0 &&\n\n                  FFABS(l1mv0[xy4][0]) <= 1 &&\n\n                  FFABS(l1mv0[xy4][1]) <= 1) ||\n\n                 (l1ref0[xy8] < 0 &&\n\n                  l1ref1[xy8] == 0 &&\n\n                  FFABS(l1mv1[xy4][0]) <= 1 &&\n\n                  FFABS(l1mv1[xy4][1]) <= 1))) {\n\n                a =\n\n                b = 0;\n\n                if (ref[0] > 0)\n\n                    a = mv[0];\n\n                if (ref[1] > 0)\n\n                    b = mv[1];\n\n                n++;\n\n            } else {\n\n                a = mv[0];\n\n                b = mv[1];\n\n            }\n\n            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, a, 4);\n\n            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, b, 4);\n\n        }\n\n        if (!is_b8x8 && !(n & 3))\n\n            *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                     MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                       MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n    } else if (IS_16X16(*mb_type)) {\n\n        int a, b;\n\n\n\n        fill_rectangle(&sl->ref_cache[0][scan8[0]], 4, 4, 8, (uint8_t)ref[0], 1);\n\n        fill_rectangle(&sl->ref_cache[1][scan8[0]], 4, 4, 8, (uint8_t)ref[1], 1);\n\n        if (!IS_INTRA(mb_type_col[0]) && !sl->ref_list[1][0].parent->long_ref &&\n\n            ((l1ref0[0] == 0 &&\n\n              FFABS(l1mv0[0][0]) <= 1 &&\n\n              FFABS(l1mv0[0][1]) <= 1) ||\n\n             (l1ref0[0] < 0 && !l1ref1[0] &&\n\n              FFABS(l1mv1[0][0]) <= 1 &&\n\n              FFABS(l1mv1[0][1]) <= 1 &&\n\n              h->sei.unregistered.x264_build > 33U))) {\n\n            a = b = 0;\n\n            if (ref[0] > 0)\n\n                a = mv[0];\n\n            if (ref[1] > 0)\n\n                b = mv[1];\n\n        } else {\n\n            a = mv[0];\n\n            b = mv[1];\n\n        }\n\n        fill_rectangle(&sl->mv_cache[0][scan8[0]], 4, 4, 8, a, 4);\n\n        fill_rectangle(&sl->mv_cache[1][scan8[0]], 4, 4, 8, b, 4);\n\n    } else {\n\n        int n = 0;\n\n        for (i8 = 0; i8 < 4; i8++) {\n\n            const int x8 = i8 & 1;\n\n            const int y8 = i8 >> 1;\n\n\n\n            if (is_b8x8 && !IS_DIRECT(sl->sub_mb_type[i8]))\n\n                continue;\n\n            sl->sub_mb_type[i8] = sub_mb_type;\n\n\n\n            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2, 8, mv[0], 4);\n\n            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2, 8, mv[1], 4);\n\n            fill_rectangle(&sl->ref_cache[0][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[0], 1);\n\n            fill_rectangle(&sl->ref_cache[1][scan8[i8 * 4]], 2, 2, 8,\n\n                           (uint8_t)ref[1], 1);\n\n\n\n            assert(b8_stride == 2);\n\n            /* col_zero_flag */\n\n            if (!IS_INTRA(mb_type_col[0]) && !sl->ref_list[1][0].parent->long_ref &&\n\n                (l1ref0[i8] == 0 ||\n\n                 (l1ref0[i8] < 0 &&\n\n                  l1ref1[i8] == 0 &&\n\n                  h->sei.unregistered.x264_build > 33U))) {\n\n                const int16_t (*l1mv)[2] = l1ref0[i8] == 0 ? l1mv0 : l1mv1;\n\n                if (IS_SUB_8X8(sub_mb_type)) {\n\n                    const int16_t *mv_col = l1mv[x8 * 3 + y8 * 3 * b4_stride];\n\n                    if (FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1) {\n\n                        if (ref[0] == 0)\n\n                            fill_rectangle(&sl->mv_cache[0][scan8[i8 * 4]], 2, 2,\n\n                                           8, 0, 4);\n\n                        if (ref[1] == 0)\n\n                            fill_rectangle(&sl->mv_cache[1][scan8[i8 * 4]], 2, 2,\n\n                                           8, 0, 4);\n\n                        n += 4;\n\n                    }\n\n                } else {\n\n                    int m = 0;\n\n                    for (i4 = 0; i4 < 4; i4++) {\n\n                        const int16_t *mv_col = l1mv[x8 * 2 + (i4 & 1) +\n\n                                                     (y8 * 2 + (i4 >> 1)) * b4_stride];\n\n                        if (FFABS(mv_col[0]) <= 1 && FFABS(mv_col[1]) <= 1) {\n\n                            if (ref[0] == 0)\n\n                                AV_ZERO32(sl->mv_cache[0][scan8[i8 * 4 + i4]]);\n\n                            if (ref[1] == 0)\n\n                                AV_ZERO32(sl->mv_cache[1][scan8[i8 * 4 + i4]]);\n\n                            m++;\n\n                        }\n\n                    }\n\n                    if (!(m & 3))\n\n                        sl->sub_mb_type[i8] += MB_TYPE_16x16 - MB_TYPE_8x8;\n\n                    n += m;\n\n                }\n\n            }\n\n        }\n\n        if (!is_b8x8 && !(n & 15))\n\n            *mb_type = (*mb_type & ~(MB_TYPE_8x8 | MB_TYPE_16x8 | MB_TYPE_8x16 |\n\n                                     MB_TYPE_P1L0 | MB_TYPE_P1L1)) |\n\n                       MB_TYPE_16x16 | MB_TYPE_DIRECT2;\n\n    }\n\n}\n", "idx": 25245, "_split": "test", "_hash": "05b62c3628394d558a7e36689bca2cfc"}
{"project": "FFmpeg", "commit_id": "c2c1726847fe3a043762062db40774bf0cc434c3", "target": 0, "func": "static void compute_status(HTTPContext *c)\n\n{\n\n    HTTPContext *c1;\n\n    FFStream *stream;\n\n    char *p;\n\n    time_t ti;\n\n    int i, len;\n\n    AVIOContext *pb;\n\n\n\n    if (avio_open_dyn_buf(&pb) < 0) {\n\n        /* XXX: return an error ? */\n\n        c->buffer_ptr = c->buffer;\n\n        c->buffer_end = c->buffer;\n\n        return;\n\n    }\n\n\n\n    avio_printf(pb, \"HTTP/1.0 200 OK\\r\\n\");\n\n    avio_printf(pb, \"Content-type: %s\\r\\n\", \"text/html\");\n\n    avio_printf(pb, \"Pragma: no-cache\\r\\n\");\n\n    avio_printf(pb, \"\\r\\n\");\n\n\n\n    avio_printf(pb, \"<html><head><title>%s Status</title>\\n\", program_name);\n\n    if (c->stream->feed_filename[0])\n\n        avio_printf(pb, \"<link rel=\\\"shortcut icon\\\" href=\\\"%s\\\">\\n\", c->stream->feed_filename);\n\n    avio_printf(pb, \"</head>\\n<body>\");\n\n    avio_printf(pb, \"<h1>%s Status</h1>\\n\", program_name);\n\n    /* format status */\n\n    avio_printf(pb, \"<h2>Available Streams</h2>\\n\");\n\n    avio_printf(pb, \"<table cellspacing=0 cellpadding=4>\\n\");\n\n    avio_printf(pb, \"<tr><th valign=top>Path<th align=left>Served<br>Conns<th><br>bytes<th valign=top>Format<th>Bit rate<br>kbits/s<th align=left>Video<br>kbits/s<th><br>Codec<th align=left>Audio<br>kbits/s<th><br>Codec<th align=left valign=top>Feed\\n\");\n\n    stream = first_stream;\n\n    while (stream != NULL) {\n\n        char sfilename[1024];\n\n        char *eosf;\n\n\n\n        if (stream->feed != stream) {\n\n            av_strlcpy(sfilename, stream->filename, sizeof(sfilename) - 10);\n\n            eosf = sfilename + strlen(sfilename);\n\n            if (eosf - sfilename >= 4) {\n\n                if (strcmp(eosf - 4, \".asf\") == 0)\n\n                    strcpy(eosf - 4, \".asx\");\n\n                else if (strcmp(eosf - 3, \".rm\") == 0)\n\n                    strcpy(eosf - 3, \".ram\");\n\n                else if (stream->fmt && !strcmp(stream->fmt->name, \"rtp\")) {\n\n                    /* generate a sample RTSP director if\n\n                       unicast. Generate an SDP redirector if\n\n                       multicast */\n\n                    eosf = strrchr(sfilename, '.');\n\n                    if (!eosf)\n\n                        eosf = sfilename + strlen(sfilename);\n\n                    if (stream->is_multicast)\n\n                        strcpy(eosf, \".sdp\");\n\n                    else\n\n                        strcpy(eosf, \".rtsp\");\n\n                }\n\n            }\n\n\n\n            avio_printf(pb, \"<tr><td><a href=\\\"/%s\\\">%s</a> \",\n\n                         sfilename, stream->filename);\n\n            avio_printf(pb, \"<td align=right> %d <td align=right> \",\n\n                        stream->conns_served);\n\n            fmt_bytecount(pb, stream->bytes_served);\n\n            switch(stream->stream_type) {\n\n            case STREAM_TYPE_LIVE: {\n\n                    int audio_bit_rate = 0;\n\n                    int video_bit_rate = 0;\n\n                    const char *audio_codec_name = \"\";\n\n                    const char *video_codec_name = \"\";\n\n                    const char *audio_codec_name_extra = \"\";\n\n                    const char *video_codec_name_extra = \"\";\n\n\n\n                    for(i=0;i<stream->nb_streams;i++) {\n\n                        AVStream *st = stream->streams[i];\n\n                        AVCodec *codec = avcodec_find_encoder(st->codec->codec_id);\n\n                        switch(st->codec->codec_type) {\n\n                        case AVMEDIA_TYPE_AUDIO:\n\n                            audio_bit_rate += st->codec->bit_rate;\n\n                            if (codec) {\n\n                                if (*audio_codec_name)\n\n                                    audio_codec_name_extra = \"...\";\n\n                                audio_codec_name = codec->name;\n\n                            }\n\n                            break;\n\n                        case AVMEDIA_TYPE_VIDEO:\n\n                            video_bit_rate += st->codec->bit_rate;\n\n                            if (codec) {\n\n                                if (*video_codec_name)\n\n                                    video_codec_name_extra = \"...\";\n\n                                video_codec_name = codec->name;\n\n                            }\n\n                            break;\n\n                        case AVMEDIA_TYPE_DATA:\n\n                            video_bit_rate += st->codec->bit_rate;\n\n                            break;\n\n                        default:\n\n                            abort();\n\n                        }\n\n                    }\n\n                    avio_printf(pb, \"<td align=center> %s <td align=right> %d <td align=right> %d <td> %s %s <td align=right> %d <td> %s %s\",\n\n                                 stream->fmt->name,\n\n                                 stream->bandwidth,\n\n                                 video_bit_rate / 1000, video_codec_name, video_codec_name_extra,\n\n                                 audio_bit_rate / 1000, audio_codec_name, audio_codec_name_extra);\n\n                    if (stream->feed)\n\n                        avio_printf(pb, \"<td>%s\", stream->feed->filename);\n\n                    else\n\n                        avio_printf(pb, \"<td>%s\", stream->feed_filename);\n\n                    avio_printf(pb, \"\\n\");\n\n                }\n\n                break;\n\n            default:\n\n                avio_printf(pb, \"<td align=center> - <td align=right> - <td align=right> - <td><td align=right> - <td>\\n\");\n\n                break;\n\n            }\n\n        }\n\n        stream = stream->next;\n\n    }\n\n    avio_printf(pb, \"</table>\\n\");\n\n\n\n    stream = first_stream;\n\n    while (stream != NULL) {\n\n        if (stream->feed == stream) {\n\n            avio_printf(pb, \"<h2>Feed %s</h2>\", stream->filename);\n\n            if (stream->pid) {\n\n                avio_printf(pb, \"Running as pid %d.\\n\", stream->pid);\n\n\n\n#if defined(linux) && !defined(CONFIG_NOCUTILS)\n\n                {\n\n                    FILE *pid_stat;\n\n                    char ps_cmd[64];\n\n\n\n                    /* This is somewhat linux specific I guess */\n\n                    snprintf(ps_cmd, sizeof(ps_cmd),\n\n                             \"ps -o \\\"%%cpu,cputime\\\" --no-headers %d\",\n\n                             stream->pid);\n\n\n\n                    pid_stat = popen(ps_cmd, \"r\");\n\n                    if (pid_stat) {\n\n                        char cpuperc[10];\n\n                        char cpuused[64];\n\n\n\n                        if (fscanf(pid_stat, \"%9s %63s\", cpuperc,\n\n                                   cpuused) == 2) {\n\n                            avio_printf(pb, \"Currently using %s%% of the cpu. Total time used %s.\\n\",\n\n                                         cpuperc, cpuused);\n\n                        }\n\n                        fclose(pid_stat);\n\n                    }\n\n                }\n\n#endif\n\n\n\n                avio_printf(pb, \"<p>\");\n\n            }\n\n            avio_printf(pb, \"<table cellspacing=0 cellpadding=4><tr><th>Stream<th>type<th>kbits/s<th align=left>codec<th align=left>Parameters\\n\");\n\n\n\n            for (i = 0; i < stream->nb_streams; i++) {\n\n                AVStream *st = stream->streams[i];\n\n                AVCodec *codec = avcodec_find_encoder(st->codec->codec_id);\n\n                const char *type = \"unknown\";\n\n                char parameters[64];\n\n\n\n                parameters[0] = 0;\n\n\n\n                switch(st->codec->codec_type) {\n\n                case AVMEDIA_TYPE_AUDIO:\n\n                    type = \"audio\";\n\n                    snprintf(parameters, sizeof(parameters), \"%d channel(s), %d Hz\", st->codec->channels, st->codec->sample_rate);\n\n                    break;\n\n                case AVMEDIA_TYPE_VIDEO:\n\n                    type = \"video\";\n\n                    snprintf(parameters, sizeof(parameters), \"%dx%d, q=%d-%d, fps=%d\", st->codec->width, st->codec->height,\n\n                                st->codec->qmin, st->codec->qmax, st->codec->time_base.den / st->codec->time_base.num);\n\n                    break;\n\n                default:\n\n                    abort();\n\n                }\n\n                avio_printf(pb, \"<tr><td align=right>%d<td>%s<td align=right>%d<td>%s<td>%s\\n\",\n\n                        i, type, st->codec->bit_rate/1000, codec ? codec->name : \"\", parameters);\n\n            }\n\n            avio_printf(pb, \"</table>\\n\");\n\n\n\n        }\n\n        stream = stream->next;\n\n    }\n\n\n\n    /* connection status */\n\n    avio_printf(pb, \"<h2>Connection Status</h2>\\n\");\n\n\n\n    avio_printf(pb, \"Number of connections: %d / %d<br>\\n\",\n\n                 nb_connections, nb_max_connections);\n\n\n\n    avio_printf(pb, \"Bandwidth in use: %\"PRIu64\"k / %\"PRIu64\"k<br>\\n\",\n\n                 current_bandwidth, max_bandwidth);\n\n\n\n    avio_printf(pb, \"<table>\\n\");\n\n    avio_printf(pb, \"<tr><th>#<th>File<th>IP<th>Proto<th>State<th>Target bits/sec<th>Actual bits/sec<th>Bytes transferred\\n\");\n\n    c1 = first_http_ctx;\n\n    i = 0;\n\n    while (c1 != NULL) {\n\n        int bitrate;\n\n        int j;\n\n\n\n        bitrate = 0;\n\n        if (c1->stream) {\n\n            for (j = 0; j < c1->stream->nb_streams; j++) {\n\n                if (!c1->stream->feed)\n\n                    bitrate += c1->stream->streams[j]->codec->bit_rate;\n\n                else if (c1->feed_streams[j] >= 0)\n\n                    bitrate += c1->stream->feed->streams[c1->feed_streams[j]]->codec->bit_rate;\n\n            }\n\n        }\n\n\n\n        i++;\n\n        p = inet_ntoa(c1->from_addr.sin_addr);\n\n        avio_printf(pb, \"<tr><td><b>%d</b><td>%s%s<td>%s<td>%s<td>%s<td align=right>\",\n\n                    i,\n\n                    c1->stream ? c1->stream->filename : \"\",\n\n                    c1->state == HTTPSTATE_RECEIVE_DATA ? \"(input)\" : \"\",\n\n                    p,\n\n                    c1->protocol,\n\n                    http_state[c1->state]);\n\n        fmt_bytecount(pb, bitrate);\n\n        avio_printf(pb, \"<td align=right>\");\n\n        fmt_bytecount(pb, compute_datarate(&c1->datarate, c1->data_count) * 8);\n\n        avio_printf(pb, \"<td align=right>\");\n\n        fmt_bytecount(pb, c1->data_count);\n\n        avio_printf(pb, \"\\n\");\n\n        c1 = c1->next;\n\n    }\n\n    avio_printf(pb, \"</table>\\n\");\n\n\n\n    /* date */\n\n    ti = time(NULL);\n\n    p = ctime(&ti);\n\n    avio_printf(pb, \"<hr size=1 noshade>Generated at %s\", p);\n\n    avio_printf(pb, \"</body>\\n</html>\\n\");\n\n\n\n    len = avio_close_dyn_buf(pb, &c->pb_buffer);\n\n    c->buffer_ptr = c->pb_buffer;\n\n    c->buffer_end = c->pb_buffer + len;\n\n}\n", "idx": 25265, "_split": "test", "_hash": "fcb03cea34d02cb0bab3202a9c2d4026"}
{"project": "FFmpeg", "commit_id": "4dec101acc393fbfe9a8ce0237b9efbae3f20139", "target": 0, "func": "int ff_dxva2_commit_buffer(AVCodecContext *avctx,\n\n                           AVDXVAContext *ctx,\n\n                           DECODER_BUFFER_DESC *dsc,\n\n                           unsigned type, const void *data, unsigned size,\n\n                           unsigned mb_count)\n\n{\n\n    void     *dxva_data;\n\n    unsigned dxva_size;\n\n    int      result;\n\n    HRESULT hr;\n\n\n\n#if CONFIG_D3D11VA\n\n    if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD)\n\n        hr = ID3D11VideoContext_GetDecoderBuffer(D3D11VA_CONTEXT(ctx)->video_context,\n\n                                                 D3D11VA_CONTEXT(ctx)->decoder,\n\n                                                 type,\n\n                                                 &dxva_size, &dxva_data);\n\n#endif\n\n#if CONFIG_DXVA2\n\n    if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD)\n\n        hr = IDirectXVideoDecoder_GetBuffer(DXVA2_CONTEXT(ctx)->decoder, type,\n\n                                            &dxva_data, &dxva_size);\n\n#endif\n\n    if (FAILED(hr)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Failed to get a buffer for %u: 0x%x\\n\",\n\n               type, hr);\n\n        return -1;\n\n    }\n\n    if (size <= dxva_size) {\n\n        memcpy(dxva_data, data, size);\n\n\n\n#if CONFIG_D3D11VA\n\n        if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD) {\n\n            D3D11_VIDEO_DECODER_BUFFER_DESC *dsc11 = dsc;\n\n            memset(dsc11, 0, sizeof(*dsc11));\n\n            dsc11->BufferType           = type;\n\n            dsc11->DataSize             = size;\n\n            dsc11->NumMBsInBuffer       = mb_count;\n\n        }\n\n#endif\n\n#if CONFIG_DXVA2\n\n        if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD) {\n\n            DXVA2_DecodeBufferDesc *dsc2 = dsc;\n\n            memset(dsc2, 0, sizeof(*dsc2));\n\n            dsc2->CompressedBufferType = type;\n\n            dsc2->DataSize             = size;\n\n            dsc2->NumMBsInBuffer       = mb_count;\n\n        }\n\n#endif\n\n\n\n        result = 0;\n\n    } else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Buffer for type %u was too small\\n\", type);\n\n        result = -1;\n\n    }\n\n\n\n#if CONFIG_D3D11VA\n\n    if (avctx->pix_fmt == AV_PIX_FMT_D3D11VA_VLD)\n\n        hr = ID3D11VideoContext_ReleaseDecoderBuffer(D3D11VA_CONTEXT(ctx)->video_context, D3D11VA_CONTEXT(ctx)->decoder, type);\n\n#endif\n\n#if CONFIG_DXVA2\n\n    if (avctx->pix_fmt == AV_PIX_FMT_DXVA2_VLD)\n\n        hr = IDirectXVideoDecoder_ReleaseBuffer(DXVA2_CONTEXT(ctx)->decoder, type);\n\n#endif\n\n    if (FAILED(hr)) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Failed to release buffer type %u: 0x%x\\n\",\n\n               type, hr);\n\n        result = -1;\n\n    }\n\n    return result;\n\n}\n", "idx": 25344, "_split": "test", "_hash": "1553a0bef8597f02d80ab3ebd553ffcd"}
{"project": "FFmpeg", "commit_id": "a7f27453f64d9020b92b01687baeb5909c6cdad0", "target": 0, "func": "static int mov_read_ares(MOVContext *c, AVIOContext *pb, MOVAtom atom)\n\n{\n\n    AVCodecContext *codec = c->fc->streams[c->fc->nb_streams-1]->codec;\n\n    if (codec->codec_tag == MKTAG('A', 'V', 'i', 'n') &&\n\n        codec->codec_id == AV_CODEC_ID_H264 &&\n\n        atom.size > 11) {\n\n        avio_skip(pb, 10);\n\n        /* For AVID AVCI50, force width of 1440 to be able to select the correct SPS and PPS */\n\n        if (avio_rb16(pb) == 0xd4d)\n\n            codec->width = 1440;\n\n        return 0;\n\n    }\n\n\n\n    return mov_read_avid(c, pb, atom);\n\n}\n", "idx": 25357, "_split": "test", "_hash": "d30572bda3593e19d2ae5f9db9621750"}
{"project": "FFmpeg", "commit_id": "14a90c9ef09a4b046500dceab5ca1875e330a376", "target": 1, "func": "static av_cold int ffmmal_init_decoder(AVCodecContext *avctx)\n{\n    MMALDecodeContext *ctx = avctx->priv_data;\n    MMAL_STATUS_T status;\n    MMAL_ES_FORMAT_T *format_in;\n    MMAL_COMPONENT_T *decoder;\n    char tmp[32];\n    int ret = 0;\n    bcm_host_init();\n    if (mmal_vc_init()) {\n        av_log(avctx, AV_LOG_ERROR, \"Cannot initialize MMAL VC driver!\\n\");\n        return AVERROR(ENOSYS);\n    if ((ret = ff_get_format(avctx, avctx->codec->pix_fmts)) < 0)\n        return ret;\n    avctx->pix_fmt = ret;\n    if ((status = mmal_component_create(MMAL_COMPONENT_DEFAULT_VIDEO_DECODER, &ctx->decoder)))\n        goto fail;\n    decoder = ctx->decoder;\n    format_in = decoder->input[0]->format;\n    format_in->type = MMAL_ES_TYPE_VIDEO;\n    switch (avctx->codec_id) {\n        case AV_CODEC_ID_MPEG2VIDEO:\n            format_in->encoding = MMAL_ENCODING_MP2V;\n            break;\n        case AV_CODEC_ID_MPEG4:\n            format_in->encoding = MMAL_ENCODING_MP4V;\n            break;\n        case AV_CODEC_ID_VC1:\n            format_in->encoding = MMAL_ENCODING_WVC1;\n            break;\n        case AV_CODEC_ID_H264:\n        default:\n            format_in->encoding = MMAL_ENCODING_H264;\n            break;\n    format_in->es->video.width = FFALIGN(avctx->width, 32);\n    format_in->es->video.height = FFALIGN(avctx->height, 16);\n    format_in->es->video.crop.width = avctx->width;\n    format_in->es->video.crop.height = avctx->height;\n    format_in->es->video.frame_rate.num = 24000;\n    format_in->es->video.frame_rate.den = 1001;\n    format_in->es->video.par.num = avctx->sample_aspect_ratio.num;\n    format_in->es->video.par.den = avctx->sample_aspect_ratio.den;\n    format_in->flags = MMAL_ES_FORMAT_FLAG_FRAMED;\n    av_get_codec_tag_string(tmp, sizeof(tmp), format_in->encoding);\n    av_log(avctx, AV_LOG_DEBUG, \"Using MMAL %s encoding.\\n\", tmp);\n    if ((status = mmal_port_format_commit(decoder->input[0])))\n        goto fail;\n    decoder->input[0]->buffer_num =\n        FFMAX(decoder->input[0]->buffer_num_min, 20);\n    decoder->input[0]->buffer_size =\n        FFMAX(decoder->input[0]->buffer_size_min, 512 * 1024);\n    ctx->pool_in = mmal_pool_create(decoder->input[0]->buffer_num, 0);\n    if (!ctx->pool_in) {\n        ret = AVERROR(ENOMEM);\n        goto fail;\n    if ((ret = ffmal_update_format(avctx)) < 0)\n        goto fail;\n    ctx->queue_decoded_frames = mmal_queue_create();\n    if (!ctx->queue_decoded_frames)\n        goto fail;\n    decoder->input[0]->userdata = (void*)avctx;\n    decoder->output[0]->userdata = (void*)avctx;\n    decoder->control->userdata = (void*)avctx;\n    if ((status = mmal_port_enable(decoder->control, control_port_cb)))\n        goto fail;\n    if ((status = mmal_port_enable(decoder->input[0], input_callback)))\n        goto fail;\n    if ((status = mmal_port_enable(decoder->output[0], output_callback)))\n        goto fail;\n    if ((status = mmal_component_enable(decoder)))\n        goto fail;\n    return 0;\nfail:\n    ffmmal_close_decoder(avctx);\n    return ret < 0 ? ret : AVERROR_UNKNOWN;", "idx": 25401, "_split": "test", "_hash": "ea12226052e53af18f3854295f955e94"}
{"project": "FFmpeg", "commit_id": "9e1c55cfdec1e1e46fa39b92ea5c425ba9499c68", "target": 1, "func": "static int ogg_get_length(AVFormatContext *s)\n\n{\n\n    struct ogg *ogg = s->priv_data;\n\n    int i;\n\n    int64_t size, end;\n\n    int streams_left=0;\n\n\n\n    if(!s->pb->seekable)\n\n        return 0;\n\n\n\n// already set\n\n    if (s->duration != AV_NOPTS_VALUE)\n\n        return 0;\n\n\n\n    size = avio_size(s->pb);\n\n    if(size < 0)\n\n        return 0;\n\n    end = size > MAX_PAGE_SIZE? size - MAX_PAGE_SIZE: 0;\n\n\n\n    ogg_save (s);\n\n    avio_seek (s->pb, end, SEEK_SET);\n\n\n\n    while (!ogg_read_page (s, &i)){\n\n        if (ogg->streams[i].granule != -1 && ogg->streams[i].granule != 0 &&\n\n            ogg->streams[i].codec) {\n\n            s->streams[i]->duration =\n\n                ogg_gptopts (s, i, ogg->streams[i].granule, NULL);\n\n            if (s->streams[i]->start_time != AV_NOPTS_VALUE){\n\n                s->streams[i]->duration -= s->streams[i]->start_time;\n\n                streams_left-= (ogg->streams[i].got_start==-1);\n\n                ogg->streams[i].got_start= 1;\n\n            }else if(!ogg->streams[i].got_start){\n\n                ogg->streams[i].got_start= -1;\n\n                streams_left++;\n\n            }\n\n        }\n\n    }\n\n\n\n    ogg_restore (s, 0);\n\n\n\n    ogg_save (s);\n\n    avio_seek (s->pb, s->data_offset, SEEK_SET);\n\n    ogg_reset(s);\n\n\n    while (!ogg_packet(s, &i, NULL, NULL, NULL)) {\n\n\n        int64_t pts = ogg_calc_pts(s, i, NULL);\n\n        if (pts != AV_NOPTS_VALUE && s->streams[i]->start_time == AV_NOPTS_VALUE && !ogg->streams[i].got_start){\n\n            s->streams[i]->duration -= pts;\n\n            ogg->streams[i].got_start= 1;\n\n            streams_left--;\n\n        }else if(s->streams[i]->start_time != AV_NOPTS_VALUE && !ogg->streams[i].got_start){\n\n            ogg->streams[i].got_start= 1;\n\n            streams_left--;\n\n        }\n\n        }\n\n            if(streams_left<=0)\n\n                break;\n\n    }\n\n    ogg_restore (s, 0);\n\n\n\n    return 0;\n\n}", "idx": 25404, "_split": "test", "_hash": "a4c300c10e7927d302b5ca8c705ae278"}
{"project": "FFmpeg", "commit_id": "80387f0e2568746dce4a68e2217297029a053dae", "target": 1, "func": "static int mimic_decode_frame(AVCodecContext *avctx, void *data,\n\n                              int *data_size, AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    MimicContext *ctx = avctx->priv_data;\n\n    GetByteContext gb;\n\n    int is_pframe;\n\n    int width, height;\n\n    int quality, num_coeffs;\n\n    int swap_buf_size = buf_size - MIMIC_HEADER_SIZE;\n\n\n\n    if (buf_size <= MIMIC_HEADER_SIZE) {\n\n        av_log(avctx, AV_LOG_ERROR, \"insufficient data\\n\");\n\n        return -1;\n\n    }\n\n\n\n    bytestream2_init(&gb, buf, MIMIC_HEADER_SIZE);\n\n    bytestream2_skip(&gb, 2); /* some constant (always 256) */\n\n    quality    = bytestream2_get_le16u(&gb);\n\n    width      = bytestream2_get_le16u(&gb);\n\n    height     = bytestream2_get_le16u(&gb);\n\n    bytestream2_skip(&gb, 4); /* some constant */\n\n    is_pframe  = bytestream2_get_le32u(&gb);\n\n    num_coeffs = bytestream2_get_byteu(&gb);\n\n    bytestream2_skip(&gb, 3); /* some constant */\n\n\n\n    if(!ctx->avctx) {\n\n        int i;\n\n\n\n        if(!(width == 160 && height == 120) &&\n\n           !(width == 320 && height == 240)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid width/height!\\n\");\n\n            return -1;\n\n        }\n\n\n\n        ctx->avctx     = avctx;\n\n        avctx->width   = width;\n\n        avctx->height  = height;\n\n        avctx->pix_fmt = PIX_FMT_YUV420P;\n\n        for(i = 0; i < 3; i++) {\n\n            ctx->num_vblocks[i] = -((-height) >> (3 + !!i));\n\n            ctx->num_hblocks[i] =     width   >> (3 + !!i) ;\n\n        }\n\n    } else if(width != ctx->avctx->width || height != ctx->avctx->height) {\n\n        av_log(avctx, AV_LOG_ERROR, \"resolution changing is not supported\\n\");\n\n        return -1;\n\n    }\n\n\n\n    if(is_pframe && !ctx->buf_ptrs[ctx->prev_index].data[0]) {\n\n        av_log(avctx, AV_LOG_ERROR, \"decoding must start with keyframe\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->buf_ptrs[ctx->cur_index].reference = 1;\n\n    ctx->buf_ptrs[ctx->cur_index].pict_type = is_pframe ? AV_PICTURE_TYPE_P:AV_PICTURE_TYPE_I;\n\n    if(ff_thread_get_buffer(avctx, &ctx->buf_ptrs[ctx->cur_index])) {\n\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    ctx->next_prev_index = ctx->cur_index;\n\n    ctx->next_cur_index  = (ctx->cur_index - 1) & 15;\n\n\n\n    prepare_avpic(ctx, &ctx->flipped_ptrs[ctx->cur_index],\n\n                  (AVPicture*) &ctx->buf_ptrs[ctx->cur_index]);\n\n\n\n    ff_thread_finish_setup(avctx);\n\n\n\n    av_fast_malloc(&ctx->swap_buf, &ctx->swap_buf_size,\n\n                                 swap_buf_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if(!ctx->swap_buf)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ctx->dsp.bswap_buf(ctx->swap_buf,\n\n                        (const uint32_t*) (buf + MIMIC_HEADER_SIZE),\n\n                        swap_buf_size>>2);\n\n    init_get_bits(&ctx->gb, ctx->swap_buf, swap_buf_size << 3);\n\n\n\n    if(!decode(ctx, quality, num_coeffs, !is_pframe)) {\n\n        if (avctx->active_thread_type&FF_THREAD_FRAME)\n\n            ff_thread_report_progress(&ctx->buf_ptrs[ctx->cur_index], INT_MAX, 0);\n\n        else {\n\n            ff_thread_release_buffer(avctx, &ctx->buf_ptrs[ctx->cur_index]);\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    *(AVFrame*)data = ctx->buf_ptrs[ctx->cur_index];\n\n    *data_size = sizeof(AVFrame);\n\n\n\n    ctx->prev_index = ctx->next_prev_index;\n\n    ctx->cur_index  = ctx->next_cur_index;\n\n\n\n    /* Only release frames that aren't used for backreferences anymore */\n\n    if(ctx->buf_ptrs[ctx->cur_index].data[0])\n\n        ff_thread_release_buffer(avctx, &ctx->buf_ptrs[ctx->cur_index]);\n\n\n\n    return buf_size;\n\n}\n", "idx": 25413, "_split": "test", "_hash": "c5f317031413d6cf34582a527a8fcd4c"}
{"project": "FFmpeg", "commit_id": "80ca19f766aea8f4724aac1b3faa772d25163c8a", "target": 0, "func": "static int ipvideo_decode_block_opcode_0x8(IpvideoContext *s)\n\n{\n\n    int x, y;\n\n    unsigned char P[2];\n\n    unsigned int flags = 0;\n\n\n\n    /* 2-color encoding for each 4x4 quadrant, or 2-color encoding on\n\n     * either top and bottom or left and right halves */\n\n    CHECK_STREAM_PTR(2);\n\n\n\n    P[0] = *s->stream_ptr++;\n\n    P[1] = *s->stream_ptr++;\n\n\n\n    if (P[0] <= P[1]) {\n\n\n\n        CHECK_STREAM_PTR(14);\n\n        s->stream_ptr -= 2;\n\n\n\n        for (y = 0; y < 16; y++) {\n\n            // new values for each 4x4 block\n\n            if (!(y & 3)) {\n\n                P[0] = *s->stream_ptr++; P[1] = *s->stream_ptr++;\n\n                flags = bytestream_get_le16(&s->stream_ptr);\n\n            }\n\n\n\n            for (x = 0; x < 4; x++, flags >>= 1)\n\n                *s->pixel_ptr++ = P[flags & 1];\n\n            s->pixel_ptr += s->stride - 4;\n\n            // switch to right half\n\n            if (y == 7) s->pixel_ptr -= 8 * s->stride - 4;\n\n        }\n\n\n\n    } else {\n\n\n\n        /* need 10 more bytes */\n\n        CHECK_STREAM_PTR(10);\n\n\n\n        if (s->stream_ptr[4] <= s->stream_ptr[5]) {\n\n\n\n            flags = bytestream_get_le32(&s->stream_ptr);\n\n\n\n            /* vertical split; left & right halves are 2-color encoded */\n\n\n\n            for (y = 0; y < 16; y++) {\n\n                for (x = 0; x < 4; x++, flags >>= 1)\n\n                    *s->pixel_ptr++ = P[flags & 1];\n\n                s->pixel_ptr += s->stride - 4;\n\n                // switch to right half\n\n                if (y == 7) {\n\n                    s->pixel_ptr -= 8 * s->stride - 4;\n\n                    P[0] = *s->stream_ptr++; P[1] = *s->stream_ptr++;\n\n                    flags = bytestream_get_le32(&s->stream_ptr);\n\n                }\n\n            }\n\n\n\n        } else {\n\n\n\n            /* horizontal split; top & bottom halves are 2-color encoded */\n\n\n\n            for (y = 0; y < 8; y++) {\n\n                if (y == 4) {\n\n                    P[0] = *s->stream_ptr++;\n\n                    P[1] = *s->stream_ptr++;\n\n                }\n\n                flags = *s->stream_ptr++ | 0x100;\n\n\n\n                for (; flags != 1; flags >>= 1)\n\n                    *s->pixel_ptr++ = P[flags & 1];\n\n                s->pixel_ptr += s->line_inc;\n\n            }\n\n        }\n\n    }\n\n\n\n    /* report success */\n\n    return 0;\n\n}\n", "idx": 25448, "_split": "test", "_hash": "223334399c31a1c37be7e60bacec6c42"}
{"project": "FFmpeg", "commit_id": "2d40a09b6e73230b160a505f01ed1acf169e1d9f", "target": 1, "func": "static int libquvi_read_packet(AVFormatContext *s, AVPacket *pkt)\n\n{\n\n    LibQuviContext *qc = s->priv_data;\n\n    return av_read_frame(qc->fmtctx, pkt);\n\n}\n", "idx": 25501, "_split": "test", "_hash": "5feaf6fff494ac2fe424bb20dcb16802"}
{"project": "FFmpeg", "commit_id": "f929ab0569ff31ed5a59b0b0adb7ce09df3fca39", "target": 0, "func": "AVFrame *avcodec_alloc_frame(void)\n\n{\n\n    AVFrame *frame = av_mallocz(sizeof(AVFrame));\n\n\n\n    if (frame == NULL)\n\n        return NULL;\n\n\n\nFF_DISABLE_DEPRECATION_WARNINGS\n\n    avcodec_get_frame_defaults(frame);\n\nFF_ENABLE_DEPRECATION_WARNINGS\n\n\n\n    return frame;\n\n}\n", "idx": 25526, "_split": "test", "_hash": "9108fc53f1ed9e9b5387a0d98a7fc394"}
{"project": "FFmpeg", "commit_id": "ed1a6878564a97e67e5fe3a25bc099208cfed024", "target": 1, "func": "static int add_hfyu_left_prediction_int16_c(uint16_t *dst, const uint16_t *src, unsigned mask, int w, int acc){\n\n    int i;\n\n\n\n    for(i=0; i<w-1; i++){\n\n        acc+= src[i];\n\n        dst[i]= acc & mask;\n\n        i++;\n\n        acc+= src[i];\n\n        dst[i]= acc & mask;\n\n    }\n\n\n\n    for(; i<w; i++){\n\n        acc+= src[i];\n\n        dst[i]= acc & mask;\n\n    }\n\n\n\n    return acc;\n\n}\n", "idx": 25530, "_split": "test", "_hash": "ccac81ce638ef108515e4327ece38368"}
{"project": "FFmpeg", "commit_id": "f57b00e89749b559da7cd99a4b630c90617e17d4", "target": 1, "func": "static const ID3v2EMFunc *get_extra_meta_func(const char *tag, int isv34)\n\n{\n\n    int i = 0;\n\n    while (ff_id3v2_extra_meta_funcs[i].tag3) {\n\n        if (!memcmp(tag,\n\n                    (isv34 ?\n\n                        ff_id3v2_extra_meta_funcs[i].tag4 :\n\n                        ff_id3v2_extra_meta_funcs[i].tag3),\n\n                    (isv34 ? 4 : 3)))\n\n            return &ff_id3v2_extra_meta_funcs[i];\n\n        i++;\n\n    }\n\n    return NULL;\n\n}\n", "idx": 25557, "_split": "test", "_hash": "7957c9662f27d5194b9d01c5f04b089f"}
{"project": "FFmpeg", "commit_id": "ac87c273a646eb8feba8e47f15da4934d119f650", "target": 1, "func": "int av_buffersrc_add_ref(AVFilterContext *buffer_filter,\n\n                         AVFilterBufferRef *picref, int flags)\n\n{\n\n    BufferSourceContext *c = buffer_filter->priv;\n\n    AVFilterBufferRef *buf;\n\n    int ret;\n\n\n\n    if (!picref) {\n\n        c->eof = 1;\n\n        return 0;\n\n    } else if (c->eof)\n\n        return AVERROR(EINVAL);\n\n\n\n    if (!av_fifo_space(c->fifo) &&\n\n        (ret = av_fifo_realloc2(c->fifo, av_fifo_size(c->fifo) +\n\n                                         sizeof(buf))) < 0)\n\n        return ret;\n\n\n\n    if (!(flags & AV_BUFFERSRC_FLAG_NO_CHECK_FORMAT)) {\n\n        ret = check_format_change(buffer_filter, picref);\n\n        if (ret < 0)\n\n            return ret;\n\n    }\n\n    if (flags & AV_BUFFERSRC_FLAG_NO_COPY)\n\n        buf = picref;\n\n    else\n\n        buf = copy_buffer_ref(buffer_filter, picref);\n\n\n\n\n\n    if ((ret = av_fifo_generic_write(c->fifo, &buf, sizeof(buf), NULL)) < 0) {\n\n        if (buf != picref)\n\n            avfilter_unref_buffer(buf);\n\n        return ret;\n\n    }\n\n    c->nb_failed_requests = 0;\n\n\n\n    return 0;\n\n}", "idx": 25566, "_split": "test", "_hash": "90415ae8f6906358341bd7ab966feba7"}
{"project": "FFmpeg", "commit_id": "8be23d424feea50d4ee892cdbdd6abd9a807709f", "target": 0, "func": "static av_cold int roq_decode_init(AVCodecContext *avctx)\n\n{\n\n    RoqContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n\n\n    if (avctx->width % 16 || avctx->height % 16) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Dimensions must be a multiple of 16\\n\");\n\n        return AVERROR_PATCHWELCOME;\n\n    }\n\n\n\n    s->width = avctx->width;\n\n    s->height = avctx->height;\n\n\n\n    s->last_frame    = av_frame_alloc();\n\n    s->current_frame = av_frame_alloc();\n\n    if (!s->current_frame || !s->last_frame) {\n\n        av_frame_free(&s->current_frame);\n\n        av_frame_free(&s->last_frame);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    avctx->pix_fmt = AV_PIX_FMT_YUV444P;\n\n\n\n    return 0;\n\n}\n", "idx": 25593, "_split": "test", "_hash": "c5c6e656c7d45b44221e828c75c39b20"}
{"project": "FFmpeg", "commit_id": "204cb29b3c84a74cbcd059d353c70c8bdc567d98", "target": 1, "func": "static av_cold int shorten_decode_close(AVCodecContext *avctx)\n\n{\n\n    ShortenContext *s = avctx->priv_data;\n\n    int i;\n\n\n\n    for (i = 0; i < s->channels; i++) {\n\n        s->decoded[i] -= s->nwrap;\n\n        av_freep(&s->decoded[i]);\n\n        av_freep(&s->offset[i]);\n\n    }\n\n    av_freep(&s->bitstream);\n\n    av_freep(&s->coeffs);\n\n\n\n    return 0;\n\n}\n", "idx": 25672, "_split": "test", "_hash": "badd6f135db43511c3af14288bdcbfcd"}
{"project": "FFmpeg", "commit_id": "1181d93231e9b807965724587d363c1cfd5a1d0d", "target": 0, "func": "void ff_avg_h264_qpel4_mc13_msa(uint8_t *dst, const uint8_t *src,\n\n                                ptrdiff_t stride)\n\n{\n\n    avc_luma_hv_qrt_and_aver_dst_4x4_msa(src + stride - 2,\n\n                                         src - (stride * 2),\n\n                                         stride, dst, stride);\n\n}\n", "idx": 25693, "_split": "test", "_hash": "4a7739274f4645c062455b540744fd06"}
{"project": "FFmpeg", "commit_id": "24947d4988012f1f0fd467c83418615adc11c3e8", "target": 1, "func": "static void render_line(int x0, uint8_t y0, int x1, int y1, float *buf)\n\n{\n\n    int dy  = y1 - y0;\n\n    int adx = x1 - x0;\n\n    int ady = FFABS(dy);\n\n    int sy  = dy < 0 ? -1 : 1;\n\n    buf[x0] = ff_vorbis_floor1_inverse_db_table[y0];\n\n    if (ady*2 <= adx) { // optimized common case\n\n        render_line_unrolled(x0, y0, x1, sy, ady, adx, buf);\n\n    } else {\n\n        int base  = dy / adx;\n\n        int x     = x0;\n\n        uint8_t y = y0;\n\n        int err   = -adx;\n\n        ady -= FFABS(base) * adx;\n\n        while (++x < x1) {\n\n            y += base;\n\n            err += ady;\n\n            if (err >= 0) {\n\n                err -= adx;\n\n                y   += sy;\n\n            }\n\n            buf[x] = ff_vorbis_floor1_inverse_db_table[y];\n\n        }\n\n    }\n\n}\n", "idx": 25729, "_split": "test", "_hash": "9755d7ad73f196e19b1dd096f597e116"}
{"project": "FFmpeg", "commit_id": "fbd6c97f9ca858140df16dd07200ea0d4bdc1a83", "target": 1, "func": "static BufferPoolEntry *get_pool(AVBufferPool *pool)\n\n{\n\n    BufferPoolEntry *cur = NULL, *last = NULL;\n\n\n\n    do {\n\n        FFSWAP(BufferPoolEntry*, cur, last);\n\n        cur = avpriv_atomic_ptr_cas((void * volatile *)&pool->pool, last, NULL);\n\n        if (!cur)\n\n            return NULL;\n\n    } while (cur != last);\n\n\n\n    return cur;\n\n}\n", "idx": 25737, "_split": "test", "_hash": "f3bdbcd1963bfc910c12782e92aca326"}
{"project": "FFmpeg", "commit_id": "74b1bf632f125a795e66e5fd0a060b9c7c55b7a3", "target": 1, "func": "static void switch_buffer(MPADecodeContext *s, int *pos, int *end_pos,\n\n                          int *end_pos2)\n\n{\n\n    if (s->in_gb.buffer && *pos >= s->gb.size_in_bits) {\n\n        s->gb           = s->in_gb;\n\n        s->in_gb.buffer = NULL;\n\n        assert((get_bits_count(&s->gb) & 7) == 0);\n\n        skip_bits_long(&s->gb, *pos - *end_pos);\n\n        *end_pos2 =\n\n        *end_pos  = *end_pos2 + get_bits_count(&s->gb) - *pos;\n\n        *pos      = get_bits_count(&s->gb);\n\n    }\n\n}\n", "idx": 25738, "_split": "test", "_hash": "3a368d596979a8f6ba8f37051889f437"}
{"project": "FFmpeg", "commit_id": "4ffe5e2aa5241f8da9afd2c8fbc854dcc916c5f9", "target": 1, "func": "static int read_old_huffman_tables(HYuvContext *s){\n\n#if 1\n\n    GetBitContext gb;\n\n    int i;\n\n\n\n    init_get_bits(&gb, classic_shift_luma, sizeof(classic_shift_luma)*8);\n\n    if(read_len_table(s->len[0], &gb)<0)\n\n        return -1;\n\n    init_get_bits(&gb, classic_shift_chroma, sizeof(classic_shift_chroma)*8);\n\n    if(read_len_table(s->len[1], &gb)<0)\n\n        return -1;\n\n\n\n    for(i=0; i<256; i++) s->bits[0][i] = classic_add_luma  [i];\n\n    for(i=0; i<256; i++) s->bits[1][i] = classic_add_chroma[i];\n\n\n\n    if(s->bitstream_bpp >= 24){\n\n        memcpy(s->bits[1], s->bits[0], 256*sizeof(uint32_t));\n\n        memcpy(s->len[1] , s->len [0], 256*sizeof(uint8_t));\n\n    }\n\n    memcpy(s->bits[2], s->bits[1], 256*sizeof(uint32_t));\n\n    memcpy(s->len[2] , s->len [1], 256*sizeof(uint8_t));\n\n\n\n    for(i=0; i<3; i++){\n\n        ff_free_vlc(&s->vlc[i]);\n\n        init_vlc(&s->vlc[i], VLC_BITS, 256, s->len[i], 1, 1, s->bits[i], 4, 4, 0);\n\n    }\n\n\n\n    generate_joint_tables(s);\n\n\n\n    return 0;\n\n#else\n\n    av_log(s->avctx, AV_LOG_DEBUG, \"v1 huffyuv is not supported \\n\");\n\n    return -1;\n\n#endif\n\n}\n", "idx": 25748, "_split": "test", "_hash": "d71dc9142729f7b270c0330867eb0e84"}
{"project": "FFmpeg", "commit_id": "29d46d7bce1c67852e4c6e22605144eb32b21072", "target": 1, "func": "static void json_print_section_header(WriterContext *wctx)\n\n{\n\n    JSONContext *json = wctx->priv;\n\n    AVBPrint buf;\n\n    const struct section *section = wctx->section[wctx->level];\n\n    const struct section *parent_section = wctx->level ?\n\n        wctx->section[wctx->level-1] : NULL;\n\n\n\n    if (wctx->level && wctx->nb_item[wctx->level-1])\n\n        printf(\",\\n\");\n\n\n\n    if (section->flags & SECTION_FLAG_IS_WRAPPER) {\n\n        printf(\"{\\n\");\n\n        json->indent_level++;\n\n    } else {\n\n        av_bprint_init(&buf, 1, AV_BPRINT_SIZE_UNLIMITED);\n\n        json_escape_str(&buf, section->name, wctx);\n\n        JSON_INDENT();\n\n\n\n        json->indent_level++;\n\n        if (section->flags & SECTION_FLAG_IS_ARRAY) {\n\n            printf(\"\\\"%s\\\": [\\n\", buf.str);\n\n        } else if (!(parent_section->flags & SECTION_FLAG_IS_ARRAY)) {\n\n            printf(\"\\\"%s\\\": {%s\", buf.str, json->item_start_end);\n\n        } else {\n\n            printf(\"{%s\", json->item_start_end);\n\n\n\n            /* this is required so the parser can distinguish between packets and frames */\n\n            if (parent_section->id == SECTION_ID_PACKETS_AND_FRAMES) {\n\n                if (!json->compact)\n\n                    JSON_INDENT();\n\n                printf(\"\\\"type\\\": \\\"%s\\\"%s\", section->name, json->item_sep);\n\n            }\n\n        }\n\n        av_bprint_finalize(&buf, NULL);\n\n    }\n\n}\n", "idx": 25787, "_split": "test", "_hash": "68c0d94ea1d74862852f61a492550792"}
{"project": "FFmpeg", "commit_id": "77d98898211eeb0241e8411428b0b364a6231744", "target": 1, "func": "static int pixlet_decode_frame(AVCodecContext *avctx, void *data,\n                               int *got_frame, AVPacket *avpkt)\n{\n    PixletContext *ctx = avctx->priv_data;\n    int i, w, h, width, height, ret, version;\n    AVFrame *p = data;\n    ThreadFrame frame = { .f = data };\n    uint32_t pktsize;\n    bytestream2_init(&ctx->gb, avpkt->data, avpkt->size);\n    pktsize = bytestream2_get_be32(&ctx->gb);\n    if (pktsize <= 44 || pktsize - 4 > bytestream2_get_bytes_left(&ctx->gb)) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid packet size %\"PRIu32\"\\n\", pktsize);\n    }\n    version = bytestream2_get_le32(&ctx->gb);\n    if (version != 1)\n        avpriv_request_sample(avctx, \"Version %d\", version);\n    bytestream2_skip(&ctx->gb, 4);\n    if (bytestream2_get_be32(&ctx->gb) != 1)\n    bytestream2_skip(&ctx->gb, 4);\n    width  = bytestream2_get_be32(&ctx->gb);\n    height = bytestream2_get_be32(&ctx->gb);\n    w = FFALIGN(width,  1 << (NB_LEVELS + 1));\n    h = FFALIGN(height, 1 << (NB_LEVELS + 1));\n    ctx->levels = bytestream2_get_be32(&ctx->gb);\n    if (ctx->levels != NB_LEVELS)\n    ctx->depth = bytestream2_get_be32(&ctx->gb);\n    if (ctx->depth < 8 || ctx->depth > 15) {\n        avpriv_request_sample(avctx, \"Depth %d\", ctx->depth);\n    }\n    ret = ff_set_dimensions(avctx, w, h);\n    if (ret < 0)\n        return ret;\n    avctx->width  = width;\n    avctx->height = height;\n    if (ctx->w != w || ctx->h != h) {\n        free_buffers(avctx);\n        ctx->w = w;\n        ctx->h = h;\n        ret = init_decoder(avctx);\n        if (ret < 0) {\n            free_buffers(avctx);\n            ctx->w = 0;\n            ctx->h = 0;\n            return ret;\n        }\n    }\n    bytestream2_skip(&ctx->gb, 8);\n    p->pict_type = AV_PICTURE_TYPE_I;\n    p->key_frame = 1;\n    p->color_range = AVCOL_RANGE_JPEG;\n    ret = ff_thread_get_buffer(avctx, &frame, 0);\n    if (ret < 0)\n        return ret;\n    for (i = 0; i < 3; i++) {\n        ret = decode_plane(avctx, i, avpkt, frame.f);\n        if (ret < 0)\n            return ret;\n        if (avctx->flags & AV_CODEC_FLAG_GRAY)\n            break;\n    }\n    postprocess_luma(frame.f, ctx->w, ctx->h, ctx->depth);\n    postprocess_chroma(frame.f, ctx->w >> 1, ctx->h >> 1, ctx->depth);\n    *got_frame = 1;\n    return pktsize;\n}", "idx": 25828, "_split": "test", "_hash": "03d0443f9908aabcfce649efc5479889"}
{"project": "FFmpeg", "commit_id": "d9fe6b926cd619c311e45e0ae352cf09713c482c", "target": 1, "func": "static int matroska_read_header(AVFormatContext *s)\n\n{\n\n    MatroskaDemuxContext *matroska = s->priv_data;\n\n    EbmlList *attachements_list = &matroska->attachments;\n\n    MatroskaAttachement *attachements;\n\n    EbmlList *chapters_list = &matroska->chapters;\n\n    MatroskaChapter *chapters;\n\n    MatroskaTrack *tracks;\n\n    uint64_t max_start = 0;\n\n    int64_t pos;\n\n    Ebml ebml = { 0 };\n\n    AVStream *st;\n\n    int i, j, k, res;\n\n\n\n    matroska->ctx = s;\n\n\n\n    /* First read the EBML header. */\n\n    if (ebml_parse(matroska, ebml_syntax, &ebml)\n\n        || ebml.version > EBML_VERSION       || ebml.max_size > sizeof(uint64_t)\n\n        || ebml.id_length > sizeof(uint32_t) || ebml.doctype_version > 3) {\n\n        av_log(matroska->ctx, AV_LOG_ERROR,\n\n               \"EBML header using unsupported features\\n\"\n\n               \"(EBML version %\"PRIu64\", doctype %s, doc version %\"PRIu64\")\\n\",\n\n               ebml.version, ebml.doctype, ebml.doctype_version);\n\n        ebml_free(ebml_syntax, &ebml);\n\n        return AVERROR_PATCHWELCOME;\n\n    } else if (ebml.doctype_version == 3) {\n\n        av_log(matroska->ctx, AV_LOG_WARNING,\n\n               \"EBML header using unsupported features\\n\"\n\n               \"(EBML version %\"PRIu64\", doctype %s, doc version %\"PRIu64\")\\n\",\n\n               ebml.version, ebml.doctype, ebml.doctype_version);\n\n    }\n\n    for (i = 0; i < FF_ARRAY_ELEMS(matroska_doctypes); i++)\n\n        if (!strcmp(ebml.doctype, matroska_doctypes[i]))\n\n            break;\n\n    if (i >= FF_ARRAY_ELEMS(matroska_doctypes)) {\n\n        av_log(s, AV_LOG_WARNING, \"Unknown EBML doctype '%s'\\n\", ebml.doctype);\n\n    }\n\n    ebml_free(ebml_syntax, &ebml);\n\n\n\n    /* The next thing is a segment. */\n\n    pos = avio_tell(matroska->ctx->pb);\n\n    res = ebml_parse(matroska, matroska_segments, matroska);\n\n    // try resyncing until we find a EBML_STOP type element.\n\n    while (res != 1) {\n\n        res = matroska_resync(matroska, pos);\n\n        if (res < 0)\n\n            return res;\n\n        pos = avio_tell(matroska->ctx->pb);\n\n        res = ebml_parse(matroska, matroska_segment, matroska);\n\n    }\n\n    matroska_execute_seekhead(matroska);\n\n\n\n    if (!matroska->time_scale)\n\n        matroska->time_scale = 1000000;\n\n    if (matroska->duration)\n\n        matroska->ctx->duration = matroska->duration * matroska->time_scale\n\n                                  * 1000 / AV_TIME_BASE;\n\n    av_dict_set(&s->metadata, \"title\", matroska->title, 0);\n\n\n\n    if (matroska->date_utc.size == 8)\n\n        matroska_metadata_creation_time(&s->metadata, AV_RB64(matroska->date_utc.data));\n\n\n\n    tracks = matroska->tracks.elem;\n\n    for (i=0; i < matroska->tracks.nb_elem; i++) {\n\n        MatroskaTrack *track = &tracks[i];\n\n        enum CodecID codec_id = CODEC_ID_NONE;\n\n        EbmlList *encodings_list = &track->encodings;\n\n        MatroskaTrackEncoding *encodings = encodings_list->elem;\n\n        uint8_t *extradata = NULL;\n\n        int extradata_size = 0;\n\n        int extradata_offset = 0;\n\n        uint32_t fourcc = 0;\n\n        AVIOContext b;\n\n\n\n        /* Apply some sanity checks. */\n\n        if (track->type != MATROSKA_TRACK_TYPE_VIDEO &&\n\n            track->type != MATROSKA_TRACK_TYPE_AUDIO &&\n\n            track->type != MATROSKA_TRACK_TYPE_SUBTITLE) {\n\n            av_log(matroska->ctx, AV_LOG_INFO,\n\n                   \"Unknown or unsupported track type %\"PRIu64\"\\n\",\n\n                   track->type);\n\n            continue;\n\n        }\n\n        if (track->codec_id == NULL)\n\n            continue;\n\n\n\n        if (track->type == MATROSKA_TRACK_TYPE_VIDEO) {\n\n            if (!track->default_duration)\n\n                track->default_duration = 1000000000/track->video.frame_rate;\n\n            if (!track->video.display_width)\n\n                track->video.display_width = track->video.pixel_width;\n\n            if (!track->video.display_height)\n\n                track->video.display_height = track->video.pixel_height;\n\n            if (track->video.color_space.size == 4)\n\n                fourcc = AV_RL32(track->video.color_space.data);\n\n        } else if (track->type == MATROSKA_TRACK_TYPE_AUDIO) {\n\n            if (!track->audio.out_samplerate)\n\n                track->audio.out_samplerate = track->audio.samplerate;\n\n        }\n\n        if (encodings_list->nb_elem > 1) {\n\n            av_log(matroska->ctx, AV_LOG_ERROR,\n\n                   \"Multiple combined encodings not supported\");\n\n        } else if (encodings_list->nb_elem == 1) {\n\n            if (encodings[0].type ||\n\n                (encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_HEADERSTRIP &&\n\n#if CONFIG_ZLIB\n\n                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_ZLIB &&\n\n#endif\n\n#if CONFIG_BZLIB\n\n                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_BZLIB &&\n\n#endif\n\n                 encodings[0].compression.algo != MATROSKA_TRACK_ENCODING_COMP_LZO)) {\n\n                encodings[0].scope = 0;\n\n                av_log(matroska->ctx, AV_LOG_ERROR,\n\n                       \"Unsupported encoding type\");\n\n            } else if (track->codec_priv.size && encodings[0].scope&2) {\n\n                uint8_t *codec_priv = track->codec_priv.data;\n\n                int offset = matroska_decode_buffer(&track->codec_priv.data,\n\n                                                    &track->codec_priv.size,\n\n                                                    track);\n\n                if (offset < 0) {\n\n                    track->codec_priv.data = NULL;\n\n                    track->codec_priv.size = 0;\n\n                    av_log(matroska->ctx, AV_LOG_ERROR,\n\n                           \"Failed to decode codec private data\\n\");\n\n                } else if (offset > 0) {\n\n                    track->codec_priv.data = av_malloc(track->codec_priv.size + offset);\n\n                    memcpy(track->codec_priv.data,\n\n                           encodings[0].compression.settings.data, offset);\n\n                    memcpy(track->codec_priv.data+offset, codec_priv,\n\n                           track->codec_priv.size);\n\n                    track->codec_priv.size += offset;\n\n                }\n\n                if (codec_priv != track->codec_priv.data)\n\n                    av_free(codec_priv);\n\n            }\n\n        }\n\n\n\n        for(j=0; ff_mkv_codec_tags[j].id != CODEC_ID_NONE; j++){\n\n            if(!strncmp(ff_mkv_codec_tags[j].str, track->codec_id,\n\n                        strlen(ff_mkv_codec_tags[j].str))){\n\n                codec_id= ff_mkv_codec_tags[j].id;\n\n                break;\n\n            }\n\n        }\n\n\n\n        st = track->stream = avformat_new_stream(s, NULL);\n\n        if (st == NULL)\n\n            return AVERROR(ENOMEM);\n\n\n\n        if (!strcmp(track->codec_id, \"V_MS/VFW/FOURCC\")\n\n            && track->codec_priv.size >= 40\n\n            && track->codec_priv.data != NULL) {\n\n            track->ms_compat = 1;\n\n            fourcc = AV_RL32(track->codec_priv.data + 16);\n\n            codec_id = ff_codec_get_id(ff_codec_bmp_tags, fourcc);\n\n            extradata_offset = 40;\n\n        } else if (!strcmp(track->codec_id, \"A_MS/ACM\")\n\n                   && track->codec_priv.size >= 14\n\n                   && track->codec_priv.data != NULL) {\n\n            int ret;\n\n            ffio_init_context(&b, track->codec_priv.data, track->codec_priv.size,\n\n                          AVIO_FLAG_READ, NULL, NULL, NULL, NULL);\n\n            ret = ff_get_wav_header(&b, st->codec, track->codec_priv.size);\n\n            if (ret < 0)\n\n                return ret;\n\n            codec_id = st->codec->codec_id;\n\n            extradata_offset = FFMIN(track->codec_priv.size, 18);\n\n        } else if (!strcmp(track->codec_id, \"V_QUICKTIME\")\n\n                   && (track->codec_priv.size >= 86)\n\n                   && (track->codec_priv.data != NULL)) {\n\n            fourcc = AV_RL32(track->codec_priv.data);\n\n            codec_id = ff_codec_get_id(ff_codec_movvideo_tags, fourcc);\n\n        } else if (codec_id == CODEC_ID_PCM_S16BE) {\n\n            switch (track->audio.bitdepth) {\n\n            case  8:  codec_id = CODEC_ID_PCM_U8;     break;\n\n            case 24:  codec_id = CODEC_ID_PCM_S24BE;  break;\n\n            case 32:  codec_id = CODEC_ID_PCM_S32BE;  break;\n\n            }\n\n        } else if (codec_id == CODEC_ID_PCM_S16LE) {\n\n            switch (track->audio.bitdepth) {\n\n            case  8:  codec_id = CODEC_ID_PCM_U8;     break;\n\n            case 24:  codec_id = CODEC_ID_PCM_S24LE;  break;\n\n            case 32:  codec_id = CODEC_ID_PCM_S32LE;  break;\n\n            }\n\n        } else if (codec_id==CODEC_ID_PCM_F32LE && track->audio.bitdepth==64) {\n\n            codec_id = CODEC_ID_PCM_F64LE;\n\n        } else if (codec_id == CODEC_ID_AAC && !track->codec_priv.size) {\n\n            int profile = matroska_aac_profile(track->codec_id);\n\n            int sri = matroska_aac_sri(track->audio.samplerate);\n\n            extradata = av_mallocz(5 + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (extradata == NULL)\n\n                return AVERROR(ENOMEM);\n\n            extradata[0] = (profile << 3) | ((sri&0x0E) >> 1);\n\n            extradata[1] = ((sri&0x01) << 7) | (track->audio.channels<<3);\n\n            if (strstr(track->codec_id, \"SBR\")) {\n\n                sri = matroska_aac_sri(track->audio.out_samplerate);\n\n                extradata[2] = 0x56;\n\n                extradata[3] = 0xE5;\n\n                extradata[4] = 0x80 | (sri<<3);\n\n                extradata_size = 5;\n\n            } else\n\n                extradata_size = 2;\n\n        } else if (codec_id == CODEC_ID_TTA) {\n\n            extradata_size = 30;\n\n            extradata = av_mallocz(extradata_size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if (extradata == NULL)\n\n                return AVERROR(ENOMEM);\n\n            ffio_init_context(&b, extradata, extradata_size, 1,\n\n                          NULL, NULL, NULL, NULL);\n\n            avio_write(&b, \"TTA1\", 4);\n\n            avio_wl16(&b, 1);\n\n            avio_wl16(&b, track->audio.channels);\n\n            avio_wl16(&b, track->audio.bitdepth);\n\n            avio_wl32(&b, track->audio.out_samplerate);\n\n            avio_wl32(&b, matroska->ctx->duration * track->audio.out_samplerate);\n\n        } else if (codec_id == CODEC_ID_RV10 || codec_id == CODEC_ID_RV20 ||\n\n                   codec_id == CODEC_ID_RV30 || codec_id == CODEC_ID_RV40) {\n\n            extradata_offset = 26;\n\n        } else if (codec_id == CODEC_ID_RA_144) {\n\n            track->audio.out_samplerate = 8000;\n\n            track->audio.channels = 1;\n\n        } else if (codec_id == CODEC_ID_RA_288 || codec_id == CODEC_ID_COOK ||\n\n                   codec_id == CODEC_ID_ATRAC3 || codec_id == CODEC_ID_SIPR) {\n\n            int flavor;\n\n            ffio_init_context(&b, track->codec_priv.data,track->codec_priv.size,\n\n                          0, NULL, NULL, NULL, NULL);\n\n            avio_skip(&b, 22);\n\n            flavor                       = avio_rb16(&b);\n\n            track->audio.coded_framesize = avio_rb32(&b);\n\n            avio_skip(&b, 12);\n\n            track->audio.sub_packet_h    = avio_rb16(&b);\n\n            track->audio.frame_size      = avio_rb16(&b);\n\n            track->audio.sub_packet_size = avio_rb16(&b);\n\n            track->audio.buf = av_malloc(track->audio.frame_size * track->audio.sub_packet_h);\n\n            if (codec_id == CODEC_ID_RA_288) {\n\n                st->codec->block_align = track->audio.coded_framesize;\n\n                track->codec_priv.size = 0;\n\n            } else {\n\n                if (codec_id == CODEC_ID_SIPR && flavor < 4) {\n\n                    const int sipr_bit_rate[4] = { 6504, 8496, 5000, 16000 };\n\n                    track->audio.sub_packet_size = ff_sipr_subpk_size[flavor];\n\n                    st->codec->bit_rate = sipr_bit_rate[flavor];\n\n                }\n\n                st->codec->block_align = track->audio.sub_packet_size;\n\n                extradata_offset = 78;\n\n            }\n\n        }\n\n        track->codec_priv.size -= extradata_offset;\n\n\n\n        if (codec_id == CODEC_ID_NONE)\n\n            av_log(matroska->ctx, AV_LOG_INFO,\n\n                   \"Unknown/unsupported CodecID %s.\\n\", track->codec_id);\n\n\n\n        if (track->time_scale < 0.01)\n\n            track->time_scale = 1.0;\n\n        avpriv_set_pts_info(st, 64, matroska->time_scale*track->time_scale, 1000*1000*1000); /* 64 bit pts in ns */\n\n\n\n        st->codec->codec_id = codec_id;\n\n        st->start_time = 0;\n\n        if (strcmp(track->language, \"und\"))\n\n            av_dict_set(&st->metadata, \"language\", track->language, 0);\n\n        av_dict_set(&st->metadata, \"title\", track->name, 0);\n\n\n\n        if (track->flag_default)\n\n            st->disposition |= AV_DISPOSITION_DEFAULT;\n\n        if (track->flag_forced)\n\n            st->disposition |= AV_DISPOSITION_FORCED;\n\n\n\n        if (!st->codec->extradata) {\n\n            if(extradata){\n\n                st->codec->extradata = extradata;\n\n                st->codec->extradata_size = extradata_size;\n\n            } else if(track->codec_priv.data && track->codec_priv.size > 0){\n\n                st->codec->extradata = av_mallocz(track->codec_priv.size +\n\n                                                  FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if(st->codec->extradata == NULL)\n\n                    return AVERROR(ENOMEM);\n\n                st->codec->extradata_size = track->codec_priv.size;\n\n                memcpy(st->codec->extradata,\n\n                       track->codec_priv.data + extradata_offset,\n\n                       track->codec_priv.size);\n\n            }\n\n        }\n\n\n\n        if (track->type == MATROSKA_TRACK_TYPE_VIDEO) {\n\n            MatroskaTrackPlane *planes = track->operation.combine_planes.elem;\n\n\n\n            st->codec->codec_type = AVMEDIA_TYPE_VIDEO;\n\n            st->codec->codec_tag  = fourcc;\n\n            st->codec->width  = track->video.pixel_width;\n\n            st->codec->height = track->video.pixel_height;\n\n            av_reduce(&st->sample_aspect_ratio.num,\n\n                      &st->sample_aspect_ratio.den,\n\n                      st->codec->height * track->video.display_width,\n\n                      st->codec-> width * track->video.display_height,\n\n                      255);\n\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n            if (track->default_duration)\n\n                st->avg_frame_rate = av_d2q(1000000000.0/track->default_duration, INT_MAX);\n\n\n\n            /* export stereo mode flag as metadata tag */\n\n            if (track->video.stereo_mode && track->video.stereo_mode < MATROSKA_VIDEO_STEREO_MODE_COUNT)\n\n                av_dict_set(&st->metadata, \"stereo_mode\", matroska_video_stereo_mode[track->video.stereo_mode], 0);\n\n\n\n            /* if we have virtual track, mark the real tracks */\n\n            for (j=0; j < track->operation.combine_planes.nb_elem; j++) {\n\n                char buf[32];\n\n                if (planes[j].type >= MATROSKA_VIDEO_STEREO_PLANE_COUNT)\n\n                    continue;\n\n                snprintf(buf, sizeof(buf), \"%s_%d\",\n\n                         matroska_video_stereo_plane[planes[j].type], i);\n\n                for (k=0; k < matroska->tracks.nb_elem; k++)\n\n                    if (planes[j].uid == tracks[k].uid) {\n\n                        av_dict_set(&s->streams[k]->metadata,\n\n                                    \"stereo_mode\", buf, 0);\n\n                        break;\n\n                    }\n\n            }\n\n        } else if (track->type == MATROSKA_TRACK_TYPE_AUDIO) {\n\n            st->codec->codec_type = AVMEDIA_TYPE_AUDIO;\n\n            st->codec->sample_rate = track->audio.out_samplerate;\n\n            st->codec->channels = track->audio.channels;\n\n            if (st->codec->codec_id != CODEC_ID_AAC)\n\n            st->need_parsing = AVSTREAM_PARSE_HEADERS;\n\n        } else if (track->type == MATROSKA_TRACK_TYPE_SUBTITLE) {\n\n            st->codec->codec_type = AVMEDIA_TYPE_SUBTITLE;\n\n        }\n\n    }\n\n\n\n    attachements = attachements_list->elem;\n\n    for (j=0; j<attachements_list->nb_elem; j++) {\n\n        if (!(attachements[j].filename && attachements[j].mime &&\n\n              attachements[j].bin.data && attachements[j].bin.size > 0)) {\n\n            av_log(matroska->ctx, AV_LOG_ERROR, \"incomplete attachment\\n\");\n\n        } else {\n\n            AVStream *st = avformat_new_stream(s, NULL);\n\n            if (st == NULL)\n\n                break;\n\n            av_dict_set(&st->metadata, \"filename\",attachements[j].filename, 0);\n\n            av_dict_set(&st->metadata, \"mimetype\", attachements[j].mime, 0);\n\n            st->codec->codec_id = CODEC_ID_NONE;\n\n            st->codec->codec_type = AVMEDIA_TYPE_ATTACHMENT;\n\n            st->codec->extradata  = av_malloc(attachements[j].bin.size + FF_INPUT_BUFFER_PADDING_SIZE);\n\n            if(st->codec->extradata == NULL)\n\n                break;\n\n            st->codec->extradata_size = attachements[j].bin.size;\n\n            memcpy(st->codec->extradata, attachements[j].bin.data, attachements[j].bin.size);\n\n\n\n            for (i=0; ff_mkv_mime_tags[i].id != CODEC_ID_NONE; i++) {\n\n                if (!strncmp(ff_mkv_mime_tags[i].str, attachements[j].mime,\n\n                             strlen(ff_mkv_mime_tags[i].str))) {\n\n                    st->codec->codec_id = ff_mkv_mime_tags[i].id;\n\n                    break;\n\n                }\n\n            }\n\n            attachements[j].stream = st;\n\n        }\n\n    }\n\n\n\n    chapters = chapters_list->elem;\n\n    for (i=0; i<chapters_list->nb_elem; i++)\n\n        if (chapters[i].start != AV_NOPTS_VALUE && chapters[i].uid\n\n            && (max_start==0 || chapters[i].start > max_start)) {\n\n            chapters[i].chapter =\n\n            avpriv_new_chapter(s, chapters[i].uid, (AVRational){1, 1000000000},\n\n                           chapters[i].start, chapters[i].end,\n\n                           chapters[i].title);\n\n            av_dict_set(&chapters[i].chapter->metadata,\n\n                             \"title\", chapters[i].title, 0);\n\n            max_start = chapters[i].start;\n\n        }\n\n\n\n    matroska_add_index_entries(matroska);\n\n\n\n    matroska_convert_tags(s);\n\n\n\n    return 0;\n\n}\n", "idx": 25854, "_split": "test", "_hash": "ff3211cd5e2ec8f45137479161d9782c"}
{"project": "FFmpeg", "commit_id": "feb13aed794a7f1a1f8395159e9b077351348a34", "target": 1, "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *picref)\n\n{\n\n    AVFilterContext *ctx = inlink->dst;\n\n    SignatureContext *sic = ctx->priv;\n\n    StreamContext *sc = &(sic->streamcontexts[FF_INLINK_IDX(inlink)]);\n\n    FineSignature* fs;\n\n\n\n    static const uint8_t pot3[5] = { 3*3*3*3, 3*3*3, 3*3, 3, 1 };\n\n    /* indexes of words : 210,217,219,274,334  44,175,233,270,273  57,70,103,237,269  100,285,295,337,354  101,102,111,275,296\n\n    s2usw = sorted to unsorted wordvec: 44 is at index 5, 57 at index 10...\n\n    */\n\n    static const unsigned int wordvec[25] = {44,57,70,100,101,102,103,111,175,210,217,219,233,237,269,270,273,274,275,285,295,296,334,337,354};\n\n    static const uint8_t      s2usw[25]   = { 5,10,11, 15, 20, 21, 12, 22,  6,  0,  1,  2,  7, 13, 14,  8,  9,  3, 23, 16, 17, 24,  4, 18, 19};\n\n\n\n    uint8_t wordt2b[5] = { 0, 0, 0, 0, 0 }; /* word ternary to binary */\n\n    uint64_t intpic[32][32];\n\n    uint64_t rowcount;\n\n    uint8_t *p = picref->data[0];\n\n    int inti, intj;\n\n    int *intjlut;\n\n\n\n    uint64_t conflist[DIFFELEM_SIZE];\n\n    int f = 0, g = 0, w = 0;\n\n    int32_t dh1 = 1, dh2 = 1, dw1 = 1, dw2 = 1, a, b;\n\n    int64_t denom;\n\n    int i, j, k, ternary;\n\n    uint64_t blocksum;\n\n    int blocksize;\n\n    int64_t th; /* threshold */\n\n    int64_t sum;\n\n\n\n    int64_t precfactor = (sc->divide) ? 65536 : BLOCK_LCM;\n\n\n\n    /* initialize fs */\n\n    if (sc->curfinesig) {\n\n        fs = av_mallocz(sizeof(FineSignature));\n\n        if (!fs)\n\n            return AVERROR(ENOMEM);\n\n        sc->curfinesig->next = fs;\n\n        fs->prev = sc->curfinesig;\n\n        sc->curfinesig = fs;\n\n    } else {\n\n        fs = sc->curfinesig = sc->finesiglist;\n\n        sc->curcoarsesig1->first = fs;\n\n    }\n\n\n\n    fs->pts = picref->pts;\n\n    fs->index = sc->lastindex++;\n\n\n\n    memset(intpic, 0, sizeof(uint64_t)*32*32);\n\n    intjlut = av_malloc_array(inlink->w, sizeof(int));\n\n    if (!intjlut)\n\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < inlink->w; i++) {\n\n        intjlut[i] = (i*32)/inlink->w;\n\n    }\n\n\n\n    for (i = 0; i < inlink->h; i++) {\n\n        inti = (i*32)/inlink->h;\n\n        for (j = 0; j < inlink->w; j++) {\n\n            intj = intjlut[j];\n\n            intpic[inti][intj] += p[j];\n\n        }\n\n        p += picref->linesize[0];\n\n    }\n\n    av_freep(&intjlut);\n\n\n\n    /* The following calculates a summed area table (intpic) and brings the numbers\n\n     * in intpic to the same denominator.\n\n     * So you only have to handle the numinator in the following sections.\n\n     */\n\n    dh1 = inlink->h / 32;\n\n    if (inlink->h % 32)\n\n        dh2 = dh1 + 1;\n\n    dw1 = inlink->w / 32;\n\n    if (inlink->w % 32)\n\n        dw2 = dw1 + 1;\n\n    denom = (sc->divide) ? dh1 * dh2 * dw1 * dw2 : 1;\n\n\n\n    for (i = 0; i < 32; i++) {\n\n        rowcount = 0;\n\n        a = 1;\n\n        if (dh2 > 1) {\n\n            a = ((inlink->h*(i+1))%32 == 0) ? (inlink->h*(i+1))/32 - 1 : (inlink->h*(i+1))/32;\n\n            a -= ((inlink->h*i)%32 == 0) ? (inlink->h*i)/32 - 1 : (inlink->h*i)/32;\n\n            a = (a == dh1)? dh2 : dh1;\n\n        }\n\n        for (j = 0; j < 32; j++) {\n\n            b = 1;\n\n            if (dw2 > 1) {\n\n                b = ((inlink->w*(j+1))%32 == 0) ? (inlink->w*(j+1))/32 - 1 : (inlink->w*(j+1))/32;\n\n                b -= ((inlink->w*j)%32 == 0) ? (inlink->w*j)/32 - 1 : (inlink->w*j)/32;\n\n                b = (b == dw1)? dw2 : dw1;\n\n            }\n\n            rowcount += intpic[i][j] * a * b * precfactor / denom;\n\n            if (i > 0) {\n\n                intpic[i][j] = intpic[i-1][j] + rowcount;\n\n            } else {\n\n                intpic[i][j] = rowcount;\n\n            }\n\n        }\n\n    }\n\n\n\n    denom = (sc->divide) ? 1 : dh1 * dh2 * dw1 * dw2;\n\n\n\n    for (i = 0; i < ELEMENT_COUNT; i++) {\n\n        const ElemCat* elemcat = elements[i];\n\n        int64_t* elemsignature;\n\n        uint64_t* sortsignature;\n\n\n\n        elemsignature = av_malloc_array(elemcat->elem_count, sizeof(int64_t));\n\n        if (!elemsignature)\n\n            return AVERROR(ENOMEM);\n\n        sortsignature = av_malloc_array(elemcat->elem_count, sizeof(int64_t));\n\n        if (!sortsignature)\n\n            return AVERROR(ENOMEM);\n\n\n\n        for (j = 0; j < elemcat->elem_count; j++) {\n\n            blocksum = 0;\n\n            blocksize = 0;\n\n            for (k = 0; k < elemcat->left_count; k++) {\n\n                blocksum += get_block_sum(sc, intpic, &elemcat->blocks[j*elemcat->block_count+k]);\n\n                blocksize += get_block_size(&elemcat->blocks[j*elemcat->block_count+k]);\n\n            }\n\n            sum = blocksum / blocksize;\n\n            if (elemcat->av_elem) {\n\n                sum -= 128 * precfactor * denom;\n\n            } else {\n\n                blocksum = 0;\n\n                blocksize = 0;\n\n                for (; k < elemcat->block_count; k++) {\n\n                    blocksum += get_block_sum(sc, intpic, &elemcat->blocks[j*elemcat->block_count+k]);\n\n                    blocksize += get_block_size(&elemcat->blocks[j*elemcat->block_count+k]);\n\n                }\n\n                sum -= blocksum / blocksize;\n\n                conflist[g++] = FFABS(sum * 8 / (precfactor * denom));\n\n            }\n\n\n\n            elemsignature[j] = sum;\n\n            sortsignature[j] = FFABS(sum);\n\n        }\n\n\n\n        /* get threshold */\n\n        qsort(sortsignature, elemcat->elem_count, sizeof(uint64_t), (void*) cmp);\n\n        th = sortsignature[(int) (elemcat->elem_count*0.333)];\n\n\n\n        /* ternarize */\n\n        for (j = 0; j < elemcat->elem_count; j++) {\n\n            if (elemsignature[j] < -th) {\n\n                ternary = 0;\n\n            } else if (elemsignature[j] <= th) {\n\n                ternary = 1;\n\n            } else {\n\n                ternary = 2;\n\n            }\n\n            fs->framesig[f/5] += ternary * pot3[f%5];\n\n\n\n            if (f == wordvec[w]) {\n\n                fs->words[s2usw[w]/5] += ternary * pot3[wordt2b[s2usw[w]/5]++];\n\n                if (w < 24)\n\n                    w++;\n\n            }\n\n            f++;\n\n        }\n\n        av_freep(&elemsignature);\n\n        av_freep(&sortsignature);\n\n    }\n\n\n\n    /* confidence */\n\n    qsort(conflist, DIFFELEM_SIZE, sizeof(uint64_t), (void*) cmp);\n\n    fs->confidence = FFMIN(conflist[DIFFELEM_SIZE/2], 255);\n\n\n\n    /* coarsesignature */\n\n    if (sc->coarsecount == 0) {\n\n        if (sc->curcoarsesig2) {\n\n            sc->curcoarsesig1 = av_mallocz(sizeof(CoarseSignature));\n\n            if (!sc->curcoarsesig1)\n\n                return AVERROR(ENOMEM);\n\n            sc->curcoarsesig1->first = fs;\n\n            sc->curcoarsesig2->next = sc->curcoarsesig1;\n\n            sc->coarseend = sc->curcoarsesig1;\n\n        }\n\n    }\n\n    if (sc->coarsecount == 45) {\n\n        sc->midcoarse = 1;\n\n        sc->curcoarsesig2 = av_mallocz(sizeof(CoarseSignature));\n\n        if (!sc->curcoarsesig2)\n\n            return AVERROR(ENOMEM);\n\n        sc->curcoarsesig2->first = fs;\n\n        sc->curcoarsesig1->next = sc->curcoarsesig2;\n\n        sc->coarseend = sc->curcoarsesig2;\n\n    }\n\n    for (i = 0; i < 5; i++) {\n\n        set_bit(sc->curcoarsesig1->data[i], fs->words[i]);\n\n    }\n\n    /* assuming the actual frame is the last */\n\n    sc->curcoarsesig1->last = fs;\n\n    if (sc->midcoarse) {\n\n        for (i = 0; i < 5; i++) {\n\n            set_bit(sc->curcoarsesig2->data[i], fs->words[i]);\n\n        }\n\n        sc->curcoarsesig2->last = fs;\n\n    }\n\n\n\n    sc->coarsecount = (sc->coarsecount+1)%90;\n\n\n\n    /* debug printing finesignature */\n\n    if (av_log_get_level() == AV_LOG_DEBUG) {\n\n        av_log(ctx, AV_LOG_DEBUG, \"input %d, confidence: %d\\n\", FF_INLINK_IDX(inlink), fs->confidence);\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"words:\");\n\n        for (i = 0; i < 5; i++) {\n\n            av_log(ctx, AV_LOG_DEBUG, \" %d:\", fs->words[i] );\n\n            av_log(ctx, AV_LOG_DEBUG, \" %d\", fs->words[i] / pot3[0] );\n\n            for (j = 1; j < 5; j++)\n\n                av_log(ctx, AV_LOG_DEBUG, \",%d\", fs->words[i] % pot3[j-1] / pot3[j] );\n\n            av_log(ctx, AV_LOG_DEBUG, \";\");\n\n        }\n\n        av_log(ctx, AV_LOG_DEBUG, \"\\n\");\n\n\n\n        av_log(ctx, AV_LOG_DEBUG, \"framesignature:\");\n\n        for (i = 0; i < SIGELEM_SIZE/5; i++) {\n\n            av_log(ctx, AV_LOG_DEBUG, \" %d\", fs->framesig[i] / pot3[0] );\n\n            for (j = 1; j < 5; j++)\n\n                av_log(ctx, AV_LOG_DEBUG, \",%d\", fs->framesig[i] % pot3[j-1] / pot3[j] );\n\n        }\n\n        av_log(ctx, AV_LOG_DEBUG, \"\\n\");\n\n    }\n\n\n\n    if (FF_INLINK_IDX(inlink) == 0)\n\n        return ff_filter_frame(inlink->dst->outputs[0], picref);\n\n    return 1;\n\n}\n", "idx": 25859, "_split": "test", "_hash": "16edd3ace8e9c427998ab2a66035b928"}
{"project": "FFmpeg", "commit_id": "ca402f32e392590a81a1381dab41c4f9c2c2f98a", "target": 1, "func": "static int w64_read_header(AVFormatContext *s, AVFormatParameters *ap)\n\n{\n\n    int64_t size;\n\n    AVIOContext *pb  = s->pb;\n\n    WAVContext    *wav = s->priv_data;\n\n    AVStream *st;\n\n    uint8_t guid[16];\n\n\n\n    avio_read(pb, guid, 16);\n\n    if (memcmp(guid, guid_riff, 16))\n\n        return -1;\n\n\n\n    if (avio_rl64(pb) < 16 + 8 + 16 + 8 + 16 + 8) /* riff + wave + fmt + sizes */\n\n        return -1;\n\n\n\n    avio_read(pb, guid, 16);\n\n    if (memcmp(guid, guid_wave, 16)) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find wave guid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    size = find_guid(pb, guid_fmt);\n\n    if (size < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find fmt guid\\n\");\n\n        return -1;\n\n    }\n\n\n\n    st = av_new_stream(s, 0);\n\n    if (!st)\n\n        return AVERROR(ENOMEM);\n\n\n\n    /* subtract chunk header size - normal wav file doesn't count it */\n\n    ff_get_wav_header(pb, st->codec, size - 24);\n\n    avio_skip(pb, FFALIGN(size, INT64_C(8)) - size);\n\n\n\n    st->need_parsing = AVSTREAM_PARSE_FULL;\n\n\n\n    av_set_pts_info(st, 64, 1, st->codec->sample_rate);\n\n\n\n    size = find_guid(pb, guid_data);\n\n    if (size < 0) {\n\n        av_log(s, AV_LOG_ERROR, \"could not find data guid\\n\");\n\n        return -1;\n\n    }\n\n    wav->data_end = avio_tell(pb) + size - 24;\n\n    wav->w64      = 1;\n\n\n\n    return 0;\n\n}\n", "idx": 25868, "_split": "test", "_hash": "1aeaecc2c3ba5537cc0d3fc83e217626"}
{"project": "FFmpeg", "commit_id": "6e42e6c4b410dbef8b593c2d796a5dad95f89ee4", "target": 1, "func": "void rgb15tobgr15(const uint8_t *src, uint8_t *dst, long src_size)\n\n{\n\n\tlong i;\n\n\tlong num_pixels = src_size >> 1;\n\n\n\n\tfor(i=0; i<num_pixels; i++)\n\n\t{\n\n\t    unsigned b,g,r;\n\n\t    register uint16_t rgb;\n\n\t    rgb = src[2*i];\n\n\t    r = rgb&0x1F;\n\n\t    g = (rgb&0x3E0)>>5;\n\n\t    b = (rgb&0x7C00)>>10;\n\n\t    dst[2*i] = (b&0x1F) | ((g&0x1F)<<5) | ((r&0x1F)<<10);\n\n\t}\n\n}\n", "idx": 25869, "_split": "test", "_hash": "ea87ba7687196bd53333de7591d6ff47"}
{"project": "FFmpeg", "commit_id": "ac94b8bcc6cdba000ada0c84b4c287f7f37f2384", "target": 0, "func": "static int adpcm_decode_frame(AVCodecContext *avctx,\n\n                            void *data, int *data_size,\n\n                            AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    ADPCMDecodeContext *c = avctx->priv_data;\n\n    ADPCMChannelStatus *cs;\n\n    int n, m, channel, i;\n\n    int block_predictor[2];\n\n    short *samples;\n\n    short *samples_end;\n\n    const uint8_t *src;\n\n    int st; /* stereo */\n\n\n\n    /* DK3 ADPCM accounting variables */\n\n    unsigned char last_byte = 0;\n\n    unsigned char nibble;\n\n    int decode_top_nibble_next = 0;\n\n    int diff_channel;\n\n\n\n    /* EA ADPCM state variables */\n\n    uint32_t samples_in_chunk;\n\n    int32_t previous_left_sample, previous_right_sample;\n\n    int32_t current_left_sample, current_right_sample;\n\n    int32_t next_left_sample, next_right_sample;\n\n    int32_t coeff1l, coeff2l, coeff1r, coeff2r;\n\n    uint8_t shift_left, shift_right;\n\n    int count1, count2;\n\n    int coeff[2][2], shift[2];//used in EA MAXIS ADPCM\n\n\n\n    if (!buf_size)\n\n        return 0;\n\n\n\n    //should protect all 4bit ADPCM variants\n\n    //8 is needed for CODEC_ID_ADPCM_IMA_WAV with 2 channels\n\n    //\n\n    if(*data_size/4 < buf_size + 8)\n\n        return -1;\n\n\n\n    samples = data;\n\n    samples_end= samples + *data_size/2;\n\n    *data_size= 0;\n\n    src = buf;\n\n\n\n    st = avctx->channels == 2 ? 1 : 0;\n\n\n\n    switch(avctx->codec->id) {\n\n    case CODEC_ID_ADPCM_IMA_QT:\n\n        n = buf_size - 2*avctx->channels;\n\n        for (channel = 0; channel < avctx->channels; channel++) {\n\n            int16_t predictor;\n\n            int step_index;\n\n            cs = &(c->status[channel]);\n\n            /* (pppppp) (piiiiiii) */\n\n\n\n            /* Bits 15-7 are the _top_ 9 bits of the 16-bit initial predictor value */\n\n            predictor = AV_RB16(src);\n\n            step_index = predictor & 0x7F;\n\n            predictor &= 0xFF80;\n\n\n\n            src += 2;\n\n\n\n            if (cs->step_index == step_index) {\n\n                int diff = (int)predictor - cs->predictor;\n\n                if (diff < 0)\n\n                    diff = - diff;\n\n                if (diff > 0x7f)\n\n                    goto update;\n\n            } else {\n\n            update:\n\n                cs->step_index = step_index;\n\n                cs->predictor = predictor;\n\n            }\n\n\n\n            if (cs->step_index > 88){\n\n                av_log(avctx, AV_LOG_ERROR, \"ERROR: step_index = %i\\n\", cs->step_index);\n\n                cs->step_index = 88;\n\n            }\n\n\n\n            samples = (short*)data + channel;\n\n\n\n            for(m=32; n>0 && m>0; n--, m--) { /* in QuickTime, IMA is encoded by chuncks of 34 bytes (=64 samples) */\n\n                *samples = adpcm_ima_qt_expand_nibble(cs, src[0] & 0x0F, 3);\n\n                samples += avctx->channels;\n\n                *samples = adpcm_ima_qt_expand_nibble(cs, src[0] >> 4  , 3);\n\n                samples += avctx->channels;\n\n                src ++;\n\n            }\n\n        }\n\n        if (st)\n\n            samples--;\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_WAV:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n\n\n//        samples_per_block= (block_align-4*chanels)*8 / (bits_per_sample * chanels) + 1;\n\n\n\n        for(i=0; i<avctx->channels; i++){\n\n            cs = &(c->status[i]);\n\n            cs->predictor = *samples++ = (int16_t)bytestream_get_le16(&src);\n\n\n\n            cs->step_index = *src++;\n\n            if (cs->step_index > 88){\n\n                av_log(avctx, AV_LOG_ERROR, \"ERROR: step_index = %i\\n\", cs->step_index);\n\n                cs->step_index = 88;\n\n            }\n\n            if (*src++) av_log(avctx, AV_LOG_ERROR, \"unused byte should be null but is %d!!\\n\", src[-1]); /* unused */\n\n        }\n\n\n\n        while(src < buf + buf_size){\n\n            for(m=0; m<4; m++){\n\n                for(i=0; i<=st; i++)\n\n                    *samples++ = adpcm_ima_expand_nibble(&c->status[i], src[4*i] & 0x0F, 3);\n\n                for(i=0; i<=st; i++)\n\n                    *samples++ = adpcm_ima_expand_nibble(&c->status[i], src[4*i] >> 4  , 3);\n\n                src++;\n\n            }\n\n            src += 4*st;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_4XM:\n\n        cs = &(c->status[0]);\n\n        c->status[0].predictor= (int16_t)bytestream_get_le16(&src);\n\n        if(st){\n\n            c->status[1].predictor= (int16_t)bytestream_get_le16(&src);\n\n        }\n\n        c->status[0].step_index= (int16_t)bytestream_get_le16(&src);\n\n        if(st){\n\n            c->status[1].step_index= (int16_t)bytestream_get_le16(&src);\n\n        }\n\n        if (cs->step_index < 0) cs->step_index = 0;\n\n        if (cs->step_index > 88) cs->step_index = 88;\n\n\n\n        m= (buf_size - (src - buf))>>st;\n\n        for(i=0; i<m; i++) {\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0], src[i] & 0x0F, 4);\n\n            if (st)\n\n                *samples++ = adpcm_ima_expand_nibble(&c->status[1], src[i+m] & 0x0F, 4);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0], src[i] >> 4, 4);\n\n            if (st)\n\n                *samples++ = adpcm_ima_expand_nibble(&c->status[1], src[i+m] >> 4, 4);\n\n        }\n\n\n\n        src += m<<st;\n\n\n\n        break;\n\n    case CODEC_ID_ADPCM_MS:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n        n = buf_size - 7 * avctx->channels;\n\n        if (n < 0)\n\n            return -1;\n\n        block_predictor[0] = av_clip(*src++, 0, 6);\n\n        block_predictor[1] = 0;\n\n        if (st)\n\n            block_predictor[1] = av_clip(*src++, 0, 6);\n\n        c->status[0].idelta = (int16_t)bytestream_get_le16(&src);\n\n        if (st){\n\n            c->status[1].idelta = (int16_t)bytestream_get_le16(&src);\n\n        }\n\n        c->status[0].coeff1 = ff_adpcm_AdaptCoeff1[block_predictor[0]];\n\n        c->status[0].coeff2 = ff_adpcm_AdaptCoeff2[block_predictor[0]];\n\n        c->status[1].coeff1 = ff_adpcm_AdaptCoeff1[block_predictor[1]];\n\n        c->status[1].coeff2 = ff_adpcm_AdaptCoeff2[block_predictor[1]];\n\n\n\n        c->status[0].sample1 = bytestream_get_le16(&src);\n\n        if (st) c->status[1].sample1 = bytestream_get_le16(&src);\n\n        c->status[0].sample2 = bytestream_get_le16(&src);\n\n        if (st) c->status[1].sample2 = bytestream_get_le16(&src);\n\n\n\n        *samples++ = c->status[0].sample2;\n\n        if (st) *samples++ = c->status[1].sample2;\n\n        *samples++ = c->status[0].sample1;\n\n        if (st) *samples++ = c->status[1].sample1;\n\n        for(;n>0;n--) {\n\n            *samples++ = adpcm_ms_expand_nibble(&c->status[0 ], src[0] >> 4  );\n\n            *samples++ = adpcm_ms_expand_nibble(&c->status[st], src[0] & 0x0F);\n\n            src ++;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_DK4:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n\n\n        c->status[0].predictor  = (int16_t)bytestream_get_le16(&src);\n\n        c->status[0].step_index = *src++;\n\n        src++;\n\n        *samples++ = c->status[0].predictor;\n\n        if (st) {\n\n            c->status[1].predictor  = (int16_t)bytestream_get_le16(&src);\n\n            c->status[1].step_index = *src++;\n\n            src++;\n\n            *samples++ = c->status[1].predictor;\n\n        }\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0 ], v >> 4  , 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v & 0x0F, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_DK3:\n\n        if (avctx->block_align != 0 && buf_size > avctx->block_align)\n\n            buf_size = avctx->block_align;\n\n\n\n        if(buf_size + 16 > (samples_end - samples)*3/8)\n\n            return -1;\n\n\n\n        c->status[0].predictor  = (int16_t)AV_RL16(src + 10);\n\n        c->status[1].predictor  = (int16_t)AV_RL16(src + 12);\n\n        c->status[0].step_index = src[14];\n\n        c->status[1].step_index = src[15];\n\n        /* sign extend the predictors */\n\n        src += 16;\n\n        diff_channel = c->status[1].predictor;\n\n\n\n        /* the DK3_GET_NEXT_NIBBLE macro issues the break statement when\n\n         * the buffer is consumed */\n\n        while (1) {\n\n\n\n            /* for this algorithm, c->status[0] is the sum channel and\n\n             * c->status[1] is the diff channel */\n\n\n\n            /* process the first predictor of the sum channel */\n\n            DK3_GET_NEXT_NIBBLE();\n\n            adpcm_ima_expand_nibble(&c->status[0], nibble, 3);\n\n\n\n            /* process the diff channel predictor */\n\n            DK3_GET_NEXT_NIBBLE();\n\n            adpcm_ima_expand_nibble(&c->status[1], nibble, 3);\n\n\n\n            /* process the first pair of stereo PCM samples */\n\n            diff_channel = (diff_channel + c->status[1].predictor) / 2;\n\n            *samples++ = c->status[0].predictor + c->status[1].predictor;\n\n            *samples++ = c->status[0].predictor - c->status[1].predictor;\n\n\n\n            /* process the second predictor of the sum channel */\n\n            DK3_GET_NEXT_NIBBLE();\n\n            adpcm_ima_expand_nibble(&c->status[0], nibble, 3);\n\n\n\n            /* process the second pair of stereo PCM samples */\n\n            diff_channel = (diff_channel + c->status[1].predictor) / 2;\n\n            *samples++ = c->status[0].predictor + c->status[1].predictor;\n\n            *samples++ = c->status[0].predictor - c->status[1].predictor;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_ISS:\n\n        c->status[0].predictor  = (int16_t)AV_RL16(src + 0);\n\n        c->status[0].step_index = src[2];\n\n        src += 4;\n\n        if(st) {\n\n            c->status[1].predictor  = (int16_t)AV_RL16(src + 0);\n\n            c->status[1].step_index = src[2];\n\n            src += 4;\n\n        }\n\n\n\n        while (src < buf + buf_size) {\n\n            uint8_t v1, v2;\n\n            uint8_t v = *src++;\n\n            /* nibbles are swapped for mono */\n\n            if (st) {\n\n                v1 = v >> 4;\n\n                v2 = v & 0x0F;\n\n            } else {\n\n                v2 = v >> 4;\n\n                v1 = v & 0x0F;\n\n            }\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0 ], v1, 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v2, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_WS:\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],  v >> 4  , 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], v & 0x0F, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_XA:\n\n        while (buf_size >= 128) {\n\n            xa_decode(samples, src, &c->status[0], &c->status[1],\n\n                avctx->channels);\n\n            src += 128;\n\n            samples += 28 * 8;\n\n            buf_size -= 128;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_EA_EACS:\n\n        samples_in_chunk = bytestream_get_le32(&src) >> (1-st);\n\n\n\n        if (samples_in_chunk > buf_size-4-(8<<st)) {\n\n            src += buf_size - 4;\n\n            break;\n\n        }\n\n\n\n        for (i=0; i<=st; i++)\n\n            c->status[i].step_index = bytestream_get_le32(&src);\n\n        for (i=0; i<=st; i++)\n\n            c->status[i].predictor  = bytestream_get_le32(&src);\n\n\n\n        for (; samples_in_chunk; samples_in_chunk--, src++) {\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],  *src>>4,   3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st], *src&0x0F, 3);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_EA_SEAD:\n\n        for (; src < buf+buf_size; src++) {\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0], src[0] >> 4, 6);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[st],src[0]&0x0F, 6);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_EA:\n\n        /* Each EA ADPCM frame has a 12-byte header followed by 30-byte pieces,\n\n           each coding 28 stereo samples. */\n\n        if (buf_size < 12) {\n\n            av_log(avctx, AV_LOG_ERROR, \"frame too small\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        samples_in_chunk = AV_RL32(src);\n\n        if (samples_in_chunk / 28 > (buf_size - 12) / 30) {\n\n            av_log(avctx, AV_LOG_ERROR, \"invalid frame\\n\");\n\n            return AVERROR(EINVAL);\n\n        }\n\n        src += 4;\n\n        current_left_sample   = (int16_t)bytestream_get_le16(&src);\n\n        previous_left_sample  = (int16_t)bytestream_get_le16(&src);\n\n        current_right_sample  = (int16_t)bytestream_get_le16(&src);\n\n        previous_right_sample = (int16_t)bytestream_get_le16(&src);\n\n\n\n        for (count1 = 0; count1 < samples_in_chunk/28;count1++) {\n\n            coeff1l = ea_adpcm_table[ *src >> 4       ];\n\n            coeff2l = ea_adpcm_table[(*src >> 4  ) + 4];\n\n            coeff1r = ea_adpcm_table[*src & 0x0F];\n\n            coeff2r = ea_adpcm_table[(*src & 0x0F) + 4];\n\n            src++;\n\n\n\n            shift_left  = (*src >> 4  ) + 8;\n\n            shift_right = (*src & 0x0F) + 8;\n\n            src++;\n\n\n\n            for (count2 = 0; count2 < 28; count2++) {\n\n                next_left_sample  = (int32_t)((*src & 0xF0) << 24) >> shift_left;\n\n                next_right_sample = (int32_t)((*src & 0x0F) << 28) >> shift_right;\n\n                src++;\n\n\n\n                next_left_sample = (next_left_sample +\n\n                    (current_left_sample * coeff1l) +\n\n                    (previous_left_sample * coeff2l) + 0x80) >> 8;\n\n                next_right_sample = (next_right_sample +\n\n                    (current_right_sample * coeff1r) +\n\n                    (previous_right_sample * coeff2r) + 0x80) >> 8;\n\n\n\n                previous_left_sample = current_left_sample;\n\n                current_left_sample = av_clip_int16(next_left_sample);\n\n                previous_right_sample = current_right_sample;\n\n                current_right_sample = av_clip_int16(next_right_sample);\n\n                *samples++ = (unsigned short)current_left_sample;\n\n                *samples++ = (unsigned short)current_right_sample;\n\n            }\n\n        }\n\n\n\n        if (src - buf == buf_size - 2)\n\n            src += 2; // Skip terminating 0x0000\n\n\n\n        break;\n\n    case CODEC_ID_ADPCM_EA_MAXIS_XA:\n\n        for(channel = 0; channel < avctx->channels; channel++) {\n\n            for (i=0; i<2; i++)\n\n                coeff[channel][i] = ea_adpcm_table[(*src >> 4) + 4*i];\n\n            shift[channel] = (*src & 0x0F) + 8;\n\n            src++;\n\n        }\n\n        for (count1 = 0; count1 < (buf_size - avctx->channels) / avctx->channels; count1++) {\n\n            for(i = 4; i >= 0; i-=4) { /* Pairwise samples LL RR (st) or LL LL (mono) */\n\n                for(channel = 0; channel < avctx->channels; channel++) {\n\n                    int32_t sample = (int32_t)(((*(src+channel) >> i) & 0x0F) << 0x1C) >> shift[channel];\n\n                    sample = (sample +\n\n                             c->status[channel].sample1 * coeff[channel][0] +\n\n                             c->status[channel].sample2 * coeff[channel][1] + 0x80) >> 8;\n\n                    c->status[channel].sample2 = c->status[channel].sample1;\n\n                    c->status[channel].sample1 = av_clip_int16(sample);\n\n                    *samples++ = c->status[channel].sample1;\n\n                }\n\n            }\n\n            src+=avctx->channels;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_EA_R1:\n\n    case CODEC_ID_ADPCM_EA_R2:\n\n    case CODEC_ID_ADPCM_EA_R3: {\n\n        /* channel numbering\n\n           2chan: 0=fl, 1=fr\n\n           4chan: 0=fl, 1=rl, 2=fr, 3=rr\n\n           6chan: 0=fl, 1=c,  2=fr, 3=rl,  4=rr, 5=sub */\n\n        const int big_endian = avctx->codec->id == CODEC_ID_ADPCM_EA_R3;\n\n        int32_t previous_sample, current_sample, next_sample;\n\n        int32_t coeff1, coeff2;\n\n        uint8_t shift;\n\n        unsigned int channel;\n\n        uint16_t *samplesC;\n\n        const uint8_t *srcC;\n\n        const uint8_t *src_end = buf + buf_size;\n\n\n\n        samples_in_chunk = (big_endian ? bytestream_get_be32(&src)\n\n                                       : bytestream_get_le32(&src)) / 28;\n\n        if (samples_in_chunk > UINT32_MAX/(28*avctx->channels) ||\n\n            28*samples_in_chunk*avctx->channels > samples_end-samples) {\n\n            src += buf_size - 4;\n\n            break;\n\n        }\n\n\n\n        for (channel=0; channel<avctx->channels; channel++) {\n\n            int32_t offset = (big_endian ? bytestream_get_be32(&src)\n\n                                         : bytestream_get_le32(&src))\n\n                           + (avctx->channels-channel-1) * 4;\n\n\n\n            if ((offset < 0) || (offset >= src_end - src - 4)) break;\n\n            srcC  = src + offset;\n\n            samplesC = samples + channel;\n\n\n\n            if (avctx->codec->id == CODEC_ID_ADPCM_EA_R1) {\n\n                current_sample  = (int16_t)bytestream_get_le16(&srcC);\n\n                previous_sample = (int16_t)bytestream_get_le16(&srcC);\n\n            } else {\n\n                current_sample  = c->status[channel].predictor;\n\n                previous_sample = c->status[channel].prev_sample;\n\n            }\n\n\n\n            for (count1=0; count1<samples_in_chunk; count1++) {\n\n                if (*srcC == 0xEE) {  /* only seen in R2 and R3 */\n\n                    srcC++;\n\n                    if (srcC > src_end - 30*2) break;\n\n                    current_sample  = (int16_t)bytestream_get_be16(&srcC);\n\n                    previous_sample = (int16_t)bytestream_get_be16(&srcC);\n\n\n\n                    for (count2=0; count2<28; count2++) {\n\n                        *samplesC = (int16_t)bytestream_get_be16(&srcC);\n\n                        samplesC += avctx->channels;\n\n                    }\n\n                } else {\n\n                    coeff1 = ea_adpcm_table[ *srcC>>4     ];\n\n                    coeff2 = ea_adpcm_table[(*srcC>>4) + 4];\n\n                    shift = (*srcC++ & 0x0F) + 8;\n\n\n\n                    if (srcC > src_end - 14) break;\n\n                    for (count2=0; count2<28; count2++) {\n\n                        if (count2 & 1)\n\n                            next_sample = (int32_t)((*srcC++ & 0x0F) << 28) >> shift;\n\n                        else\n\n                            next_sample = (int32_t)((*srcC   & 0xF0) << 24) >> shift;\n\n\n\n                        next_sample += (current_sample  * coeff1) +\n\n                                       (previous_sample * coeff2);\n\n                        next_sample = av_clip_int16(next_sample >> 8);\n\n\n\n                        previous_sample = current_sample;\n\n                        current_sample  = next_sample;\n\n                        *samplesC = current_sample;\n\n                        samplesC += avctx->channels;\n\n                    }\n\n                }\n\n            }\n\n\n\n            if (avctx->codec->id != CODEC_ID_ADPCM_EA_R1) {\n\n                c->status[channel].predictor   = current_sample;\n\n                c->status[channel].prev_sample = previous_sample;\n\n            }\n\n        }\n\n\n\n        src = src + buf_size - (4 + 4*avctx->channels);\n\n        samples += 28 * samples_in_chunk * avctx->channels;\n\n        break;\n\n    }\n\n    case CODEC_ID_ADPCM_EA_XAS:\n\n        if (samples_end-samples < 32*4*avctx->channels\n\n            || buf_size < (4+15)*4*avctx->channels) {\n\n            src += buf_size;\n\n            break;\n\n        }\n\n        for (channel=0; channel<avctx->channels; channel++) {\n\n            int coeff[2][4], shift[4];\n\n            short *s2, *s = &samples[channel];\n\n            for (n=0; n<4; n++, s+=32*avctx->channels) {\n\n                for (i=0; i<2; i++)\n\n                    coeff[i][n] = ea_adpcm_table[(src[0]&0x0F)+4*i];\n\n                shift[n] = (src[2]&0x0F) + 8;\n\n                for (s2=s, i=0; i<2; i++, src+=2, s2+=avctx->channels)\n\n                    s2[0] = (src[0]&0xF0) + (src[1]<<8);\n\n            }\n\n\n\n            for (m=2; m<32; m+=2) {\n\n                s = &samples[m*avctx->channels + channel];\n\n                for (n=0; n<4; n++, src++, s+=32*avctx->channels) {\n\n                    for (s2=s, i=0; i<8; i+=4, s2+=avctx->channels) {\n\n                        int level = (int32_t)((*src & (0xF0>>i)) << (24+i)) >> shift[n];\n\n                        int pred  = s2[-1*avctx->channels] * coeff[0][n]\n\n                                  + s2[-2*avctx->channels] * coeff[1][n];\n\n                        s2[0] = av_clip_int16((level + pred + 0x80) >> 8);\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        samples += 32*4*avctx->channels;\n\n        break;\n\n    case CODEC_ID_ADPCM_IMA_AMV:\n\n    case CODEC_ID_ADPCM_IMA_SMJPEG:\n\n        c->status[0].predictor = (int16_t)bytestream_get_le16(&src);\n\n        c->status[0].step_index = bytestream_get_le16(&src);\n\n\n\n        if (avctx->codec->id == CODEC_ID_ADPCM_IMA_AMV)\n\n            src+=4;\n\n\n\n        while (src < buf + buf_size) {\n\n            char hi, lo;\n\n            lo = *src & 0x0F;\n\n            hi = *src >> 4;\n\n\n\n            if (avctx->codec->id == CODEC_ID_ADPCM_IMA_AMV)\n\n                FFSWAP(char, hi, lo);\n\n\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],\n\n                lo, 3);\n\n            *samples++ = adpcm_ima_expand_nibble(&c->status[0],\n\n                hi, 3);\n\n            src++;\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_CT:\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_ct_expand_nibble(&c->status[0 ], v >> 4  );\n\n            *samples++ = adpcm_ct_expand_nibble(&c->status[st], v & 0x0F);\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_SBPRO_4:\n\n    case CODEC_ID_ADPCM_SBPRO_3:\n\n    case CODEC_ID_ADPCM_SBPRO_2:\n\n        if (!c->status[0].step_index) {\n\n            /* the first byte is a raw sample */\n\n            *samples++ = 128 * (*src++ - 0x80);\n\n            if (st)\n\n              *samples++ = 128 * (*src++ - 0x80);\n\n            c->status[0].step_index = 1;\n\n        }\n\n        if (avctx->codec->id == CODEC_ID_ADPCM_SBPRO_4) {\n\n            while (src < buf + buf_size) {\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    src[0] >> 4, 4, 0);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n\n                    src[0] & 0x0F, 4, 0);\n\n                src++;\n\n            }\n\n        } else if (avctx->codec->id == CODEC_ID_ADPCM_SBPRO_3) {\n\n            while (src < buf + buf_size && samples + 2 < samples_end) {\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                     src[0] >> 5        , 3, 0);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    (src[0] >> 2) & 0x07, 3, 0);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    src[0] & 0x03, 2, 0);\n\n                src++;\n\n            }\n\n        } else {\n\n            while (src < buf + buf_size && samples + 3 < samples_end) {\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                     src[0] >> 6        , 2, 2);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n\n                    (src[0] >> 4) & 0x03, 2, 2);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[0],\n\n                    (src[0] >> 2) & 0x03, 2, 2);\n\n                *samples++ = adpcm_sbpro_expand_nibble(&c->status[st],\n\n                    src[0] & 0x03, 2, 2);\n\n                src++;\n\n            }\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_SWF:\n\n    {\n\n        GetBitContext gb;\n\n        const int *table;\n\n        int k0, signmask, nb_bits, count;\n\n        int size = buf_size*8;\n\n\n\n        init_get_bits(&gb, buf, size);\n\n\n\n        //read bits & initial values\n\n        nb_bits = get_bits(&gb, 2)+2;\n\n        //av_log(NULL,AV_LOG_INFO,\"nb_bits: %d\\n\", nb_bits);\n\n        table = swf_index_tables[nb_bits-2];\n\n        k0 = 1 << (nb_bits-2);\n\n        signmask = 1 << (nb_bits-1);\n\n\n\n        while (get_bits_count(&gb) <= size - 22*avctx->channels) {\n\n            for (i = 0; i < avctx->channels; i++) {\n\n                *samples++ = c->status[i].predictor = get_sbits(&gb, 16);\n\n                c->status[i].step_index = get_bits(&gb, 6);\n\n            }\n\n\n\n            for (count = 0; get_bits_count(&gb) <= size - nb_bits*avctx->channels && count < 4095; count++) {\n\n                int i;\n\n\n\n                for (i = 0; i < avctx->channels; i++) {\n\n                    // similar to IMA adpcm\n\n                    int delta = get_bits(&gb, nb_bits);\n\n                    int step = ff_adpcm_step_table[c->status[i].step_index];\n\n                    long vpdiff = 0; // vpdiff = (delta+0.5)*step/4\n\n                    int k = k0;\n\n\n\n                    do {\n\n                        if (delta & k)\n\n                            vpdiff += step;\n\n                        step >>= 1;\n\n                        k >>= 1;\n\n                    } while(k);\n\n                    vpdiff += step;\n\n\n\n                    if (delta & signmask)\n\n                        c->status[i].predictor -= vpdiff;\n\n                    else\n\n                        c->status[i].predictor += vpdiff;\n\n\n\n                    c->status[i].step_index += table[delta & (~signmask)];\n\n\n\n                    c->status[i].step_index = av_clip(c->status[i].step_index, 0, 88);\n\n                    c->status[i].predictor = av_clip_int16(c->status[i].predictor);\n\n\n\n                    *samples++ = c->status[i].predictor;\n\n                    if (samples >= samples_end) {\n\n                        av_log(avctx, AV_LOG_ERROR, \"allocated output buffer is too small\\n\");\n\n                        return -1;\n\n                    }\n\n                }\n\n            }\n\n        }\n\n        src += buf_size;\n\n        break;\n\n    }\n\n    case CODEC_ID_ADPCM_YAMAHA:\n\n        while (src < buf + buf_size) {\n\n            uint8_t v = *src++;\n\n            *samples++ = adpcm_yamaha_expand_nibble(&c->status[0 ], v & 0x0F);\n\n            *samples++ = adpcm_yamaha_expand_nibble(&c->status[st], v >> 4  );\n\n        }\n\n        break;\n\n    case CODEC_ID_ADPCM_THP:\n\n    {\n\n        int table[2][16];\n\n        unsigned int samplecnt;\n\n        int prev[2][2];\n\n        int ch;\n\n\n\n        if (buf_size < 80) {\n\n            av_log(avctx, AV_LOG_ERROR, \"frame too small\\n\");\n\n            return -1;\n\n        }\n\n\n\n        src+=4;\n\n        samplecnt = bytestream_get_be32(&src);\n\n\n\n        for (i = 0; i < 32; i++)\n\n            table[0][i] = (int16_t)bytestream_get_be16(&src);\n\n\n\n        /* Initialize the previous sample.  */\n\n        for (i = 0; i < 4; i++)\n\n            prev[0][i] = (int16_t)bytestream_get_be16(&src);\n\n\n\n        if (samplecnt >= (samples_end - samples) /  (st + 1)) {\n\n            av_log(avctx, AV_LOG_ERROR, \"allocated output buffer is too small\\n\");\n\n            return -1;\n\n        }\n\n\n\n        for (ch = 0; ch <= st; ch++) {\n\n            samples = (unsigned short *) data + ch;\n\n\n\n            /* Read in every sample for this channel.  */\n\n            for (i = 0; i < samplecnt / 14; i++) {\n\n                int index = (*src >> 4) & 7;\n\n                unsigned int exp = 28 - (*src++ & 15);\n\n                int factor1 = table[ch][index * 2];\n\n                int factor2 = table[ch][index * 2 + 1];\n\n\n\n                /* Decode 14 samples.  */\n\n                for (n = 0; n < 14; n++) {\n\n                    int32_t sampledat;\n\n                    if(n&1) sampledat=  *src++    <<28;\n\n                    else    sampledat= (*src&0xF0)<<24;\n\n\n\n                    sampledat = ((prev[ch][0]*factor1\n\n                                + prev[ch][1]*factor2) >> 11) + (sampledat>>exp);\n\n                    *samples = av_clip_int16(sampledat);\n\n                    prev[ch][1] = prev[ch][0];\n\n                    prev[ch][0] = *samples++;\n\n\n\n                    /* In case of stereo, skip one sample, this sample\n\n                       is for the other channel.  */\n\n                    samples += st;\n\n                }\n\n            }\n\n        }\n\n\n\n        /* In the previous loop, in case stereo is used, samples is\n\n           increased exactly one time too often.  */\n\n        samples -= st;\n\n        break;\n\n    }\n\n\n\n    default:\n\n        return -1;\n\n    }\n\n    *data_size = (uint8_t *)samples - (uint8_t *)data;\n\n    return src - buf;\n\n}\n", "idx": 25936, "_split": "test", "_hash": "0203cb0c6d0a30072cc73ce73ba37e51"}
{"project": "FFmpeg", "commit_id": "50cbe09d8ced75422571d29bbec1f35a33a0d3ed", "target": 0, "func": "static int smacker_decode_header_tree(SmackVContext *smk, GetBitContext *gb, int **recodes, int *last, int size)\n\n{\n\n    int res;\n\n    HuffContext huff;\n\n    HuffContext tmp1, tmp2;\n\n    VLC vlc[2] = { { 0 } };\n\n    int escapes[3];\n\n    DBCtx ctx;\n\n    int err = 0;\n\n\n\n    if(size >= UINT_MAX>>4){ // (((size + 3) >> 2) + 3) << 2 must not overflow\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"size too large\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    tmp1.length = 256;\n\n    tmp1.maxlength = 0;\n\n    tmp1.current = 0;\n\n    tmp1.bits = av_mallocz(256 * 4);\n\n    tmp1.lengths = av_mallocz(256 * sizeof(int));\n\n    tmp1.values = av_mallocz(256 * sizeof(int));\n\n\n\n    tmp2.length = 256;\n\n    tmp2.maxlength = 0;\n\n    tmp2.current = 0;\n\n    tmp2.bits = av_mallocz(256 * 4);\n\n    tmp2.lengths = av_mallocz(256 * sizeof(int));\n\n    tmp2.values = av_mallocz(256 * sizeof(int));\n\n\n\n    if(get_bits1(gb)) {\n\n        smacker_decode_tree(gb, &tmp1, 0, 0);\n\n        skip_bits1(gb);\n\n        if(tmp1.current > 1) {\n\n            res = init_vlc(&vlc[0], SMKTREE_BITS, tmp1.length,\n\n                        tmp1.lengths, sizeof(int), sizeof(int),\n\n                        tmp1.bits, sizeof(uint32_t), sizeof(uint32_t), INIT_VLC_LE);\n\n            if(res < 0) {\n\n                av_log(smk->avctx, AV_LOG_ERROR, \"Cannot build VLC table\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n    if (!vlc[0].table) {\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"Skipping low bytes tree\\n\");\n\n    }\n\n    if(get_bits1(gb)){\n\n        smacker_decode_tree(gb, &tmp2, 0, 0);\n\n        skip_bits1(gb);\n\n        if(tmp2.current > 1) {\n\n            res = init_vlc(&vlc[1], SMKTREE_BITS, tmp2.length,\n\n                        tmp2.lengths, sizeof(int), sizeof(int),\n\n                        tmp2.bits, sizeof(uint32_t), sizeof(uint32_t), INIT_VLC_LE);\n\n            if(res < 0) {\n\n                av_log(smk->avctx, AV_LOG_ERROR, \"Cannot build VLC table\\n\");\n\n                return AVERROR_INVALIDDATA;\n\n            }\n\n        }\n\n    }\n\n    if (!vlc[1].table) {\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"Skipping high bytes tree\\n\");\n\n    }\n\n\n\n    escapes[0]  = get_bits(gb, 16);\n\n    escapes[1]  = get_bits(gb, 16);\n\n    escapes[2]  = get_bits(gb, 16);\n\n\n\n    last[0] = last[1] = last[2] = -1;\n\n\n\n    ctx.escapes[0] = escapes[0];\n\n    ctx.escapes[1] = escapes[1];\n\n    ctx.escapes[2] = escapes[2];\n\n    ctx.v1 = &vlc[0];\n\n    ctx.v2 = &vlc[1];\n\n    ctx.recode1 = tmp1.values;\n\n    ctx.recode2 = tmp2.values;\n\n    ctx.last = last;\n\n\n\n    huff.length = ((size + 3) >> 2) + 3;\n\n    huff.maxlength = 0;\n\n    huff.current = 0;\n\n    huff.values = av_mallocz(huff.length * sizeof(int));\n\n\n\n    if (smacker_decode_bigtree(gb, &huff, &ctx) < 0)\n\n        err = -1;\n\n    skip_bits1(gb);\n\n    if(ctx.last[0] == -1) ctx.last[0] = huff.current++;\n\n    if(ctx.last[1] == -1) ctx.last[1] = huff.current++;\n\n    if(ctx.last[2] == -1) ctx.last[2] = huff.current++;\n\n    if(huff.current > huff.length){\n\n        ctx.last[0] = ctx.last[1] = ctx.last[2] = 1;\n\n        av_log(smk->avctx, AV_LOG_ERROR, \"bigtree damaged\\n\");\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    *recodes = huff.values;\n\n\n\n    if(vlc[0].table)\n\n        ff_free_vlc(&vlc[0]);\n\n    if(vlc[1].table)\n\n        ff_free_vlc(&vlc[1]);\n\n    av_free(tmp1.bits);\n\n    av_free(tmp1.lengths);\n\n    av_free(tmp1.values);\n\n    av_free(tmp2.bits);\n\n    av_free(tmp2.lengths);\n\n    av_free(tmp2.values);\n\n\n\n    return err;\n\n}\n", "idx": 25937, "_split": "test", "_hash": "ff4e44d0aea969d24ca4b288f21b2eb0"}
{"project": "FFmpeg", "commit_id": "bf2bc926f04dcdde0a22c137d08a0bb546e0179e", "target": 1, "func": "static int standard_decode_picture_primary_header(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    int status = 0;\n\n\n\n    if (v->finterpflag) v->interpfrm = get_bits(gb, 1);\n\n    skip_bits(gb, 2); //framecnt unused\n\n    if (v->rangered) v->rangeredfrm = get_bits(gb, 1);\n\n    v->s.pict_type = get_bits(gb, 1);\n\n    if (v->s.avctx->max_b_frames)\n\n    {\n\n        if (!v->s.pict_type)\n\n        {\n\n            if (get_bits(gb, 1)) v->s.pict_type = I_TYPE;\n\n            else v->s.pict_type = B_TYPE;\n\n        }\n\n        else v->s.pict_type = P_TYPE;\n\n    }\n\n    else v->s.pict_type++;\n\n\n\n    switch (v->s.pict_type)\n\n    {\n\n    case I_TYPE: status = decode_i_picture_header(v); break;\n\n    case P_TYPE: status = decode_p_picture_primary_header(v); break;\n\n    case BI_TYPE:\n\n    case B_TYPE: status = decode_b_picture_primary_header(v); break;\n\n    }\n\n\n\n    if (status == FRAME_SKIPED)\n\n    {\n\n      av_log(v->s.avctx, AV_LOG_INFO, \"Skipping frame...\\n\");\n\n      return status;\n\n    }\n\n    return 0;\n\n}\n", "idx": 25947, "_split": "test", "_hash": "2b6488a168ddd7e56cd9a7e830247c12"}
{"project": "FFmpeg", "commit_id": "a18456a2032e49385447a1d0d2f146f65fe9a5e1", "target": 0, "func": "static FFServerIPAddressACL* parse_dynamic_acl(FFServerStream *stream, HTTPContext *c)\n\n{\n\n    FILE* f;\n\n    char line[1024];\n\n    char  cmd[1024];\n\n    FFServerIPAddressACL *acl = NULL;\n\n    int line_num = 0;\n\n    const char *p;\n\n\n\n    f = fopen(stream->dynamic_acl, \"r\");\n\n    if (!f) {\n\n        perror(stream->dynamic_acl);\n\n        return NULL;\n\n    }\n\n\n\n    acl = av_mallocz(sizeof(FFServerIPAddressACL));\n\n\n\n    /* Build ACL */\n\n    for(;;) {\n\n        if (fgets(line, sizeof(line), f) == NULL)\n\n            break;\n\n        line_num++;\n\n        p = line;\n\n        while (av_isspace(*p))\n\n            p++;\n\n        if (*p == '\\0' || *p == '#')\n\n            continue;\n\n        ffserver_get_arg(cmd, sizeof(cmd), &p);\n\n\n\n        if (!av_strcasecmp(cmd, \"ACL\"))\n\n            ffserver_parse_acl_row(NULL, NULL, acl, p, stream->dynamic_acl, line_num);\n\n    }\n\n    fclose(f);\n\n    return acl;\n\n}\n", "idx": 25948, "_split": "test", "_hash": "f20daba00f861dd8f85958aea167da89"}
{"project": "FFmpeg", "commit_id": "f2e9a0ecbef5027f9532c49ffcdfc11d199f6150", "target": 1, "func": "static av_cold int qsv_decode_close(AVCodecContext *avctx)\n{\n    QSVOtherContext *s = avctx->priv_data;\n    ff_qsv_decode_close(&s->qsv);\n    qsv_clear_buffers(s);\n    av_fifo_free(s->packet_fifo);\n    return 0;\n}", "idx": 26030, "_split": "test", "_hash": "3615430bb3ef1c56e7fb54aa2c688716"}
{"project": "FFmpeg", "commit_id": "c83002a4f8042ccfa0688a9a18e8fa0369c1fda8", "target": 1, "func": "int ff_ass_split_override_codes(const ASSCodesCallbacks *callbacks, void *priv,\n\n                                const char *buf)\n\n{\n\n    const char *text = NULL;\n\n    char new_line[2];\n\n    int text_len = 0;\n\n\n\n    while (*buf) {\n\n        if (text && callbacks->text &&\n\n            (sscanf(buf, \"\\\\%1[nN]\", new_line) == 1 ||\n\n             !strncmp(buf, \"{\\\\\", 2))) {\n\n            callbacks->text(priv, text, text_len);\n\n            text = NULL;\n\n        }\n\n        if (sscanf(buf, \"\\\\%1[nN]\", new_line) == 1) {\n\n            if (callbacks->new_line)\n\n                callbacks->new_line(priv, new_line[0] == 'N');\n\n            buf += 2;\n\n        } else if (!strncmp(buf, \"{\\\\\", 2)) {\n\n            buf++;\n\n            while (*buf == '\\\\') {\n\n                char style[2], c[2], sep[2], c_num[2] = \"0\", tmp[128] = {0};\n\n                unsigned int color = 0xFFFFFFFF;\n\n                int len, size = -1, an = -1, alpha = -1;\n\n                int x1, y1, x2, y2, t1 = -1, t2 = -1;\n\n                if (sscanf(buf, \"\\\\%1[bisu]%1[01\\\\}]%n\", style, c, &len) > 1) {\n\n                    int close = c[0] == '0' ? 1 : c[0] == '1' ? 0 : -1;\n\n                    len += close != -1;\n\n                    if (callbacks->style)\n\n                        callbacks->style(priv, style[0], close);\n\n                } else if (sscanf(buf, \"\\\\c%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\c&H%X&%1[\\\\}]%n\", &color, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]c%1[\\\\}]%n\", c_num, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]c&H%X&%1[\\\\}]%n\", c_num, &color, sep, &len) > 2) {\n\n                    if (callbacks->color)\n\n                        callbacks->color(priv, color, c_num[0] - '0');\n\n                } else if (sscanf(buf, \"\\\\alpha%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\alpha&H%2X&%1[\\\\}]%n\", &alpha, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]a%1[\\\\}]%n\", c_num, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\%1[1234]a&H%2X&%1[\\\\}]%n\", c_num, &alpha, sep, &len) > 2) {\n\n                    if (callbacks->alpha)\n\n                        callbacks->alpha(priv, alpha, c_num[0] - '0');\n\n                } else if (sscanf(buf, \"\\\\fn%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\fn%127[^\\\\}]%1[\\\\}]%n\", tmp, sep, &len) > 1) {\n\n                    if (callbacks->font_name)\n\n                        callbacks->font_name(priv, tmp[0] ? tmp : NULL);\n\n                } else if (sscanf(buf, \"\\\\fs%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\fs%u%1[\\\\}]%n\", &size, sep, &len) > 1) {\n\n                    if (callbacks->font_size)\n\n                        callbacks->font_size(priv, size);\n\n                } else if (sscanf(buf, \"\\\\a%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\a%2u%1[\\\\}]%n\", &an, sep, &len) > 1 ||\n\n                           sscanf(buf, \"\\\\an%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\an%1u%1[\\\\}]%n\", &an, sep, &len) > 1) {\n\n                    if (an != -1 && buf[2] != 'n')\n\n                        an = (an&3) + (an&4 ? 6 : an&8 ? 3 : 0);\n\n                    if (callbacks->alignment)\n\n                        callbacks->alignment(priv, an);\n\n                } else if (sscanf(buf, \"\\\\r%1[\\\\}]%n\", sep, &len) > 0 ||\n\n                           sscanf(buf, \"\\\\r%127[^\\\\}]%1[\\\\}]%n\", tmp, sep, &len) > 1) {\n\n                    if (callbacks->cancel_overrides)\n\n                        callbacks->cancel_overrides(priv, tmp);\n\n                } else if (sscanf(buf, \"\\\\move(%d,%d,%d,%d)%1[\\\\}]%n\", &x1, &y1, &x2, &y2, sep, &len) > 4 ||\n\n                           sscanf(buf, \"\\\\move(%d,%d,%d,%d,%d,%d)%1[\\\\}]%n\", &x1, &y1, &x2, &y2, &t1, &t2, sep, &len) > 6) {\n\n                    if (callbacks->move)\n\n                        callbacks->move(priv, x1, y1, x2, y2, t1, t2);\n\n                } else if (sscanf(buf, \"\\\\pos(%d,%d)%1[\\\\}]%n\", &x1, &y1, sep, &len) > 2) {\n\n                    if (callbacks->move)\n\n                        callbacks->move(priv, x1, y1, x1, y1, -1, -1);\n\n                } else if (sscanf(buf, \"\\\\org(%d,%d)%1[\\\\}]%n\", &x1, &y1, sep, &len) > 2) {\n\n                    if (callbacks->origin)\n\n                        callbacks->origin(priv, x1, y1);\n\n                } else {\n\n                    len = strcspn(buf+1, \"\\\\}\") + 2;  /* skip unknown code */\n\n                }\n\n                buf += len - 1;\n\n            }\n\n            if (*buf++ != '}')\n\n                return AVERROR_INVALIDDATA;\n\n        } else {\n\n            if (!text) {\n\n                text = buf;\n\n                text_len = 1;\n\n            } else\n\n                text_len++;\n\n            buf++;\n\n        }\n\n    }\n\n    if (text && callbacks->text)\n\n        callbacks->text(priv, text, text_len);\n\n    if (callbacks->end)\n\n        callbacks->end(priv);\n\n    return 0;\n\n}\n", "idx": 26031, "_split": "test", "_hash": "e6acb012f3252db984af21a5afb2ec1a"}
{"project": "FFmpeg", "commit_id": "2453f40602dd6f5fa670954ee733a4155675f645", "target": 1, "func": "static void compute_scale_factors(unsigned char scale_code[SBLIMIT],\n\n                                  unsigned char scale_factors[SBLIMIT][3],\n\n                                  int sb_samples[3][12][SBLIMIT],\n\n                                  int sblimit)\n\n{\n\n    int *p, vmax, v, n, i, j, k, code;\n\n    int index, d1, d2;\n\n    unsigned char *sf = &scale_factors[0][0];\n\n\n\n    for(j=0;j<sblimit;j++) {\n\n        for(i=0;i<3;i++) {\n\n            /* find the max absolute value */\n\n            p = &sb_samples[i][0][j];\n\n            vmax = abs(*p);\n\n            for(k=1;k<12;k++) {\n\n                p += SBLIMIT;\n\n                v = abs(*p);\n\n                if (v > vmax)\n\n                    vmax = v;\n\n            }\n\n            /* compute the scale factor index using log 2 computations */\n\n            if (vmax > 0) {\n\n                n = av_log2(vmax);\n\n                /* n is the position of the MSB of vmax. now\n\n                   use at most 2 compares to find the index */\n\n                index = (21 - n) * 3 - 3;\n\n                if (index >= 0) {\n\n                    while (vmax <= scale_factor_table[index+1])\n\n                        index++;\n\n                } else {\n\n                    index = 0; /* very unlikely case of overflow */\n\n                }\n\n            } else {\n\n                index = 62; /* value 63 is not allowed */\n\n            }\n\n\n\n#if 0\n\n            printf(\"%2d:%d in=%x %x %d\\n\",\n\n                   j, i, vmax, scale_factor_table[index], index);\n\n#endif\n\n            /* store the scale factor */\n\n            assert(index >=0 && index <= 63);\n\n            sf[i] = index;\n\n        }\n\n\n\n        /* compute the transmission factor : look if the scale factors\n\n           are close enough to each other */\n\n        d1 = scale_diff_table[sf[0] - sf[1] + 64];\n\n        d2 = scale_diff_table[sf[1] - sf[2] + 64];\n\n\n\n        /* handle the 25 cases */\n\n        switch(d1 * 5 + d2) {\n\n        case 0*5+0:\n\n        case 0*5+4:\n\n        case 3*5+4:\n\n        case 4*5+0:\n\n        case 4*5+4:\n\n            code = 0;\n\n            break;\n\n        case 0*5+1:\n\n        case 0*5+2:\n\n        case 4*5+1:\n\n        case 4*5+2:\n\n            code = 3;\n\n            sf[2] = sf[1];\n\n            break;\n\n        case 0*5+3:\n\n        case 4*5+3:\n\n            code = 3;\n\n            sf[1] = sf[2];\n\n            break;\n\n        case 1*5+0:\n\n        case 1*5+4:\n\n        case 2*5+4:\n\n            code = 1;\n\n            sf[1] = sf[0];\n\n            break;\n\n        case 1*5+1:\n\n        case 1*5+2:\n\n        case 2*5+0:\n\n        case 2*5+1:\n\n        case 2*5+2:\n\n            code = 2;\n\n            sf[1] = sf[2] = sf[0];\n\n            break;\n\n        case 2*5+3:\n\n        case 3*5+3:\n\n            code = 2;\n\n            sf[0] = sf[1] = sf[2];\n\n            break;\n\n        case 3*5+0:\n\n        case 3*5+1:\n\n        case 3*5+2:\n\n            code = 2;\n\n            sf[0] = sf[2] = sf[1];\n\n            break;\n\n        case 1*5+3:\n\n            code = 2;\n\n            if (sf[0] > sf[2])\n\n              sf[0] = sf[2];\n\n            sf[1] = sf[2] = sf[0];\n\n            break;\n\n        default:\n\n            assert(0); //cannot happen\n\n            code = 0;           /* kill warning */\n\n        }\n\n\n\n#if 0\n\n        printf(\"%d: %2d %2d %2d %d %d -> %d\\n\", j,\n\n               sf[0], sf[1], sf[2], d1, d2, code);\n\n#endif\n\n        scale_code[j] = code;\n\n        sf += 3;\n\n    }\n\n}\n", "idx": 26038, "_split": "test", "_hash": "0f8d0f950c589612e72ae79ed111c5af"}
{"project": "FFmpeg", "commit_id": "229843aa359ae0c9519977d7fa952688db63f559", "target": 0, "func": "static int gen_sub_bitmap(TeletextContext *ctx, AVSubtitleRect *sub_rect, vbi_page *page, int chop_top)\n\n{\n\n    int resx = page->columns * BITMAP_CHAR_WIDTH;\n\n    int resy = (page->rows - chop_top) * BITMAP_CHAR_HEIGHT;\n\n    uint8_t ci, cmax = 0;\n\n    int ret;\n\n    vbi_char *vc = page->text + (chop_top * page->columns);\n\n    vbi_char *vcend = page->text + (page->rows * page->columns);\n\n\n\n    for (; vc < vcend; vc++) {\n\n        if (vc->opacity != VBI_TRANSPARENT_SPACE) {\n\n            cmax = VBI_NB_COLORS;\n\n            break;\n\n        }\n\n    }\n\n\n\n    if (cmax == 0) {\n\n        av_log(ctx, AV_LOG_DEBUG, \"dropping empty page %3x\\n\", page->pgno);\n\n        sub_rect->type = SUBTITLE_NONE;\n\n        return 0;\n\n    }\n\n\n\n    if ((ret = avpicture_alloc(&sub_rect->pict, AV_PIX_FMT_PAL8, resx, resy)) < 0)\n\n        return ret;\n\n    // Yes, we want to allocate the palette on our own because AVSubtitle works this way\n\n    sub_rect->pict.data[1] = NULL;\n\n\n\n    vbi_draw_vt_page_region(page, VBI_PIXFMT_PAL8,\n\n                            sub_rect->pict.data[0], sub_rect->pict.linesize[0],\n\n                            0, chop_top, page->columns, page->rows - chop_top,\n\n                            /*reveal*/ 1, /*flash*/ 1);\n\n\n\n    fix_transparency(ctx, sub_rect, page, chop_top, cmax, resx, resy);\n\n    sub_rect->x = ctx->x_offset;\n\n    sub_rect->y = ctx->y_offset + chop_top * BITMAP_CHAR_HEIGHT;\n\n    sub_rect->w = resx;\n\n    sub_rect->h = resy;\n\n    sub_rect->nb_colors = (int)cmax + 1;\n\n    sub_rect->pict.data[1] = av_mallocz(AVPALETTE_SIZE);\n\n    if (!sub_rect->pict.data[1]) {\n\n        av_freep(&sub_rect->pict.data[0]);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n    for (ci = 0; ci < cmax; ci++) {\n\n        int r, g, b, a;\n\n\n\n        r = VBI_R(page->color_map[ci]);\n\n        g = VBI_G(page->color_map[ci]);\n\n        b = VBI_B(page->color_map[ci]);\n\n        a = VBI_A(page->color_map[ci]);\n\n        ((uint32_t *)sub_rect->pict.data[1])[ci] = RGBA(r, g, b, a);\n\n        av_dlog(ctx, \"palette %0x\\n\", ((uint32_t *)sub_rect->pict.data[1])[ci]);\n\n    }\n\n    ((uint32_t *)sub_rect->pict.data[1])[cmax] = RGBA(0, 0, 0, 0);\n\n    sub_rect->type = SUBTITLE_BITMAP;\n\n    return 0;\n\n}\n", "idx": 26075, "_split": "test", "_hash": "cc603d4058ddded206ad50f45c41eb3e"}
{"project": "FFmpeg", "commit_id": "41a052a6badc9ed672a810a40b8e54af5d093b5d", "target": 1, "func": "int opt_default(const char *opt, const char *arg)\n\n{\n\n    const AVOption *oc, *of, *os, *oswr;\n\n    char opt_stripped[128];\n\n    const char *p;\n\n    const AVClass *cc = avcodec_get_class(), *fc = avformat_get_class(), *sc, *swr_class;\n\n\n\n    if (!(p = strchr(opt, ':')))\n\n        p = opt + strlen(opt);\n\n    av_strlcpy(opt_stripped, opt, FFMIN(sizeof(opt_stripped), p - opt + 1));\n\n\n\n    if ((oc = av_opt_find(&cc, opt_stripped, NULL, 0,\n\n                         AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ)) ||\n\n        ((opt[0] == 'v' || opt[0] == 'a' || opt[0] == 's') &&\n\n         (oc = av_opt_find(&cc, opt + 1, NULL, 0, AV_OPT_SEARCH_FAKE_OBJ))))\n\n        av_dict_set(&codec_opts, opt, arg, FLAGS(oc));\n\n    if ((of = av_opt_find(&fc, opt, NULL, 0,\n\n                          AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ)))\n\n        av_dict_set(&format_opts, opt, arg, FLAGS(of));\n\n#if CONFIG_SWSCALE\n\n    sc = sws_get_class();\n\n    if ((os = av_opt_find(&sc, opt, NULL, 0,\n\n                          AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ))) {\n\n        // XXX we only support sws_flags, not arbitrary sws options\n\n        int ret = av_opt_set(sws_opts, opt, arg, 0);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Error setting option %s.\\n\", opt);\n\n            return ret;\n\n        }\n\n    }\n\n#endif\n\n    swr_class = swr_get_class();\n\n    if (!oc && !of && !os && (oswr = av_opt_find(&swr_class, opt, NULL, 0,\n\n                          AV_OPT_SEARCH_CHILDREN | AV_OPT_SEARCH_FAKE_OBJ))) {\n\n        int ret = av_opt_set(swr_opts, opt, arg, 0);\n\n        if (ret < 0) {\n\n            av_log(NULL, AV_LOG_ERROR, \"Error setting option %s.\\n\", opt);\n\n            return ret;\n\n        }\n\n    }\n\n\n\n    if (oc || of || os || oswr)\n\n        return 0;\n\n    av_log(NULL, AV_LOG_ERROR, \"Unrecognized option '%s'\\n\", opt);\n\n    return AVERROR_OPTION_NOT_FOUND;\n\n}\n", "idx": 26087, "_split": "test", "_hash": "c269b42a46e109f7fcb19b0f8fc45bc5"}
{"project": "FFmpeg", "commit_id": "ac4b32df71bd932838043a4838b86d11e169707f", "target": 1, "func": "int check_tm_pred4x4_mode(int mode, int mb_x, int mb_y)\n\n{\n\n    if (!mb_x) {\n\n        return mb_y ? VERT_VP8_PRED : DC_129_PRED;\n\n    } else {\n\n        return mb_y ? mode : HOR_VP8_PRED;\n\n    }\n\n}\n", "idx": 26100, "_split": "test", "_hash": "1c6c65b46744cd9771273be8c217cce2"}
{"project": "FFmpeg", "commit_id": "da34e4e13238b755bb0e6ebf549015797d9b4467", "target": 1, "func": "static struct ResampleContext *create(struct ResampleContext *c, int out_rate, int in_rate, int filter_size, int phase_shift, int linear,\n\n        double cutoff, enum AVSampleFormat format, enum SwrFilterType filter_type, double kaiser_beta, double precision, int cheby, int exact_rational){\n\n    soxr_error_t error;\n\n\n\n    soxr_datatype_t type =\n\n        format == AV_SAMPLE_FMT_S16P? SOXR_INT16_S :\n\n        format == AV_SAMPLE_FMT_S16 ? SOXR_INT16_I :\n\n        format == AV_SAMPLE_FMT_S32P? SOXR_INT32_S :\n\n        format == AV_SAMPLE_FMT_S32 ? SOXR_INT32_I :\n\n        format == AV_SAMPLE_FMT_FLTP? SOXR_FLOAT32_S :\n\n        format == AV_SAMPLE_FMT_FLT ? SOXR_FLOAT32_I :\n\n        format == AV_SAMPLE_FMT_DBLP? SOXR_FLOAT64_S :\n\n        format == AV_SAMPLE_FMT_DBL ? SOXR_FLOAT64_I : (soxr_datatype_t)-1;\n\n\n\n    soxr_io_spec_t io_spec = soxr_io_spec(type, type);\n\n\n\n    soxr_quality_spec_t q_spec = soxr_quality_spec((int)((precision-2)/4), (SOXR_HI_PREC_CLOCK|SOXR_ROLLOFF_NONE)*!!cheby);\n\n    q_spec.precision = linear? 0 : precision;\n\n#if !defined SOXR_VERSION /* Deprecated @ March 2013: */\n\n    q_spec.bw_pc = cutoff? FFMAX(FFMIN(cutoff,.995),.8)*100 : q_spec.bw_pc;\n\n#else\n\n    q_spec.passband_end = cutoff? FFMAX(FFMIN(cutoff,.995),.8) : q_spec.passband_end;\n\n#endif\n\n\n\n    soxr_delete((soxr_t)c);\n\n    c = (struct ResampleContext *)\n\n        soxr_create(in_rate, out_rate, 0, &error, &io_spec, &q_spec, 0);\n\n    if (!c)\n\n        av_log(NULL, AV_LOG_ERROR, \"soxr_create: %s\\n\", error);\n\n    return c;\n\n}\n", "idx": 26110, "_split": "test", "_hash": "166ee251f0d63518f12ccf166b1e241c"}
{"project": "FFmpeg", "commit_id": "13a099799e89a76eb921ca452e1b04a7a28a9855", "target": 0, "func": "yuv2rgb_1_c_template(SwsContext *c, const uint16_t *buf0,\n\n                     const uint16_t *ubuf0, const uint16_t *ubuf1,\n\n                     const uint16_t *vbuf0, const uint16_t *vbuf1,\n\n                     const uint16_t *abuf0, uint8_t *dest, int dstW,\n\n                     int uvalpha, enum PixelFormat dstFormat,\n\n                     int flags, int y, enum PixelFormat target,\n\n                     int hasAlpha)\n\n{\n\n    int i;\n\n\n\n    if (uvalpha < 2048) {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 = buf0[i * 2]     >> 7;\n\n            int Y2 = buf0[i * 2 + 1] >> 7;\n\n            int U  = ubuf1[i]        >> 7;\n\n            int V  = vbuf1[i]        >> 7;\n\n            int A1, A2;\n\n            const void *r =  c->table_rV[V],\n\n                       *g = (c->table_gU[U] + c->table_gV[V]),\n\n                       *b =  c->table_bU[U];\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] >> 7;\n\n                A2 = abuf0[i * 2 + 1] >> 7;\n\n            }\n\n\n\n            yuv2rgb_write(dest, i, Y1, Y2, U, V, hasAlpha ? A1 : 0, hasAlpha ? A2 : 0,\n\n                          r, g, b, y, target, hasAlpha);\n\n        }\n\n    } else {\n\n        for (i = 0; i < (dstW >> 1); i++) {\n\n            int Y1 =  buf0[i * 2]          >> 7;\n\n            int Y2 =  buf0[i * 2 + 1]      >> 7;\n\n            int U  = (ubuf0[i] + ubuf1[i]) >> 8;\n\n            int V  = (vbuf0[i] + vbuf1[i]) >> 8;\n\n            int A1, A2;\n\n            const void *r =  c->table_rV[V],\n\n                       *g = (c->table_gU[U] + c->table_gV[V]),\n\n                       *b =  c->table_bU[U];\n\n\n\n            if (hasAlpha) {\n\n                A1 = abuf0[i * 2    ] >> 7;\n\n                A2 = abuf0[i * 2 + 1] >> 7;\n\n            }\n\n\n\n            yuv2rgb_write(dest, i, Y1, Y2, U, V, hasAlpha ? A1 : 0, hasAlpha ? A2 : 0,\n\n                          r, g, b, y, target, hasAlpha);\n\n        }\n\n    }\n\n}\n", "idx": 26154, "_split": "test", "_hash": "62b3ead96704c99ce2435e4f8145ab2c"}
{"project": "FFmpeg", "commit_id": "bf238a6a3ca92de686e0e103135c1336f33f685b", "target": 1, "func": "static int hwupload_query_formats(AVFilterContext *avctx)\n\n{\n\n    HWUploadContext *ctx = avctx->priv;\n\n    AVHWFramesConstraints *constraints = NULL;\n\n    const enum AVPixelFormat *input_pix_fmts, *output_pix_fmts;\n\n    AVFilterFormats *input_formats = NULL;\n\n    int err, i;\n\n\n\n    if (!avctx->hw_device_ctx) {\n\n        av_log(ctx, AV_LOG_ERROR, \"A hardware device reference is required \"\n\n               \"to upload frames to.\\n\");\n\n        return AVERROR(EINVAL);\n\n    }\n\n\n\n    ctx->hwdevice_ref = av_buffer_ref(avctx->hw_device_ctx);\n\n    if (!ctx->hwdevice_ref)\n\n        return AVERROR(ENOMEM);\n\n    ctx->hwdevice = (AVHWDeviceContext*)ctx->hwdevice_ref->data;\n\n\n\n    constraints = av_hwdevice_get_hwframe_constraints(ctx->hwdevice_ref, NULL);\n\n    if (!constraints) {\n\n        err = AVERROR(EINVAL);\n\n        goto fail;\n\n    }\n\n\n\n    input_pix_fmts  = constraints->valid_sw_formats;\n\n    output_pix_fmts = constraints->valid_hw_formats;\n\n\n\n    input_formats = ff_make_format_list(output_pix_fmts);\n\n    if (!input_formats) {\n\n        err = AVERROR(ENOMEM);\n\n        goto fail;\n\n    }\n\n    if (input_pix_fmts) {\n\n        for (i = 0; input_pix_fmts[i] != AV_PIX_FMT_NONE; i++) {\n\n            err = ff_add_format(&input_formats, input_pix_fmts[i]);\n\n            if (err < 0) {\n\n                ff_formats_unref(&input_formats);\n\n                goto fail;\n\n            }\n\n        }\n\n    }\n\n\n\n    ff_formats_ref(input_formats, &avctx->inputs[0]->out_formats);\n\n\n\n    ff_formats_ref(ff_make_format_list(output_pix_fmts),\n\n                   &avctx->outputs[0]->in_formats);\n\n\n\n    av_hwframe_constraints_free(&constraints);\n\n    return 0;\n\n\n\nfail:\n\n    av_buffer_unref(&ctx->hwdevice_ref);\n\n    av_hwframe_constraints_free(&constraints);\n\n    return err;\n\n}\n", "idx": 26173, "_split": "test", "_hash": "c0bda92014fbd275e191105e5c22cc3f"}
{"project": "FFmpeg", "commit_id": "0114c571d4c8cc1036850ced924683709390681a", "target": 1, "func": "void ff_MPV_frame_end(MpegEncContext *s)\n\n{\n\n    int i;\n\n    /* redraw edges for the frame if decoding didn't complete */\n\n    // just to make sure that all data is rendered.\n\n    if (CONFIG_MPEG_XVMC_DECODER && s->avctx->xvmc_acceleration) {\n\n        ff_xvmc_field_end(s);\n\n   } else if((s->error_count || s->encoding || !(s->avctx->codec->capabilities&CODEC_CAP_DRAW_HORIZ_BAND)) &&\n\n              !s->avctx->hwaccel &&\n\n              !(s->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU) &&\n\n              s->unrestricted_mv &&\n\n              s->current_picture.f.reference &&\n\n              !s->intra_only &&\n\n              !(s->flags & CODEC_FLAG_EMU_EDGE)) {\n\n        int hshift = av_pix_fmt_descriptors[s->avctx->pix_fmt].log2_chroma_w;\n\n        int vshift = av_pix_fmt_descriptors[s->avctx->pix_fmt].log2_chroma_h;\n\n        s->dsp.draw_edges(s->current_picture.f.data[0], s->current_picture.f.linesize[0],\n\n                          s->h_edge_pos, s->v_edge_pos,\n\n                          EDGE_WIDTH, EDGE_WIDTH,\n\n                          EDGE_TOP | EDGE_BOTTOM);\n\n        s->dsp.draw_edges(s->current_picture.f.data[1], s->current_picture.f.linesize[1],\n\n                          s->h_edge_pos >> hshift, s->v_edge_pos >> vshift,\n\n                          EDGE_WIDTH >> hshift, EDGE_WIDTH >> vshift,\n\n                          EDGE_TOP | EDGE_BOTTOM);\n\n        s->dsp.draw_edges(s->current_picture.f.data[2], s->current_picture.f.linesize[2],\n\n                          s->h_edge_pos >> hshift, s->v_edge_pos >> vshift,\n\n                          EDGE_WIDTH >> hshift, EDGE_WIDTH >> vshift,\n\n                          EDGE_TOP | EDGE_BOTTOM);\n\n    }\n\n\n\n    emms_c();\n\n\n\n    s->last_pict_type                 = s->pict_type;\n\n    s->last_lambda_for [s->pict_type] = s->current_picture_ptr->f.quality;\n\n    if (s->pict_type!= AV_PICTURE_TYPE_B) {\n\n        s->last_non_b_pict_type = s->pict_type;\n\n    }\n\n#if 0\n\n    /* copy back current_picture variables */\n\n    for (i = 0; i < MAX_PICTURE_COUNT; i++) {\n\n        if (s->picture[i].f.data[0] == s->current_picture.f.data[0]) {\n\n            s->picture[i] = s->current_picture;\n\n            break;\n\n        }\n\n    }\n\n    assert(i < MAX_PICTURE_COUNT);\n\n#endif\n\n\n\n    if (s->encoding) {\n\n        /* release non-reference frames */\n\n        for (i = 0; i < s->picture_count; i++) {\n\n            if (s->picture[i].f.data[0] && !s->picture[i].f.reference\n\n                /* && s->picture[i].type != FF_BUFFER_TYPE_SHARED */) {\n\n                free_frame_buffer(s, &s->picture[i]);\n\n            }\n\n        }\n\n    }\n\n    // clear copies, to avoid confusion\n\n#if 0\n\n    memset(&s->last_picture,    0, sizeof(Picture));\n\n    memset(&s->next_picture,    0, sizeof(Picture));\n\n    memset(&s->current_picture, 0, sizeof(Picture));\n\n#endif\n\n    s->avctx->coded_frame = &s->current_picture_ptr->f;\n\n\n\n    if (s->codec_id != AV_CODEC_ID_H264 && s->current_picture.f.reference) {\n\n        ff_thread_report_progress(&s->current_picture_ptr->f, INT_MAX, 0);\n\n    }\n\n}\n", "idx": 26183, "_split": "test", "_hash": "ac613014fedfa4d323c23bc44a069916"}
{"project": "FFmpeg", "commit_id": "49cf36f4e3e9183611859af1a07dc6a82ab47288", "target": 1, "func": "static int decode_5(SANMVideoContext *ctx)\n\n{\n\n#if HAVE_BIGENDIAN\n\n    uint16_t *frm;\n\n    int npixels;\n\n#endif\n\n    uint8_t *dst = (uint8_t*)ctx->frm0;\n\n\n\n    if (rle_decode(ctx, dst, ctx->buf_size))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n#if HAVE_BIGENDIAN\n\n    npixels = ctx->npixels;\n\n    frm = ctx->frm0;\n\n    while (npixels--)\n\n        *frm++ = av_bswap16(*frm);\n\n#endif\n\n\n\n    return 0;\n\n}\n", "idx": 26294, "_split": "test", "_hash": "35db647ac67c05c1a169667dd763a69b"}
{"project": "FFmpeg", "commit_id": "01e4537f66c6d054f8c7bdbdd5b3cfb4220d12fe", "target": 0, "func": "static void flat_print_key_prefix(WriterContext *wctx)\n\n{\n\n    FlatContext *flat = wctx->priv;\n\n    const struct section *parent_section = wctx->section[wctx->level-1];\n\n\n\n    printf(\"%s\", flat->section_header[wctx->level].str);\n\n\n\n    if (parent_section->flags & SECTION_FLAG_IS_ARRAY) {\n\n        int n = parent_section->id == SECTION_ID_PACKETS_AND_FRAMES ?\n\n            wctx->nb_section_packet_frame : wctx->nb_item[wctx->level-1];\n\n        printf(\"%d%s\", n, flat->sep_str);\n\n    }\n\n}\n", "idx": 26360, "_split": "test", "_hash": "478f8604f02951b5000109dc93e573f7"}
{"project": "FFmpeg", "commit_id": "b97d21e4d6813498f458777ff42c7eab1eed3adf", "target": 1, "func": "static int sdp_parse_fmtp_config_h264(AVStream *stream,\n\n                                      PayloadContext *h264_data,\n\n                                      char *attr, char *value)\n\n{\n\n    AVCodecContext *codec = stream->codec;\n\n    assert(codec->codec_id == CODEC_ID_H264);\n\n    assert(h264_data != NULL);\n\n\n\n    if (!strcmp(attr, \"packetization-mode\")) {\n\n        av_log(codec, AV_LOG_DEBUG, \"RTP Packetization Mode: %d\\n\", atoi(value));\n\n        h264_data->packetization_mode = atoi(value);\n\n        /*\n\n         * Packetization Mode:\n\n         * 0 or not present: Single NAL mode (Only nals from 1-23 are allowed)\n\n         * 1: Non-interleaved Mode: 1-23, 24 (STAP-A), 28 (FU-A) are allowed.\n\n         * 2: Interleaved Mode: 25 (STAP-B), 26 (MTAP16), 27 (MTAP24), 28 (FU-A),\n\n         *                      and 29 (FU-B) are allowed.\n\n         */\n\n        if (h264_data->packetization_mode > 1)\n\n            av_log(codec, AV_LOG_ERROR,\n\n                   \"Interleaved RTP mode is not supported yet.\");\n\n    } else if (!strcmp(attr, \"profile-level-id\")) {\n\n        if (strlen(value) == 6) {\n\n            char buffer[3];\n\n            // 6 characters=3 bytes, in hex.\n\n            uint8_t profile_idc;\n\n            uint8_t profile_iop;\n\n            uint8_t level_idc;\n\n\n\n            buffer[0]   = value[0];\n\n            buffer[1]   = value[1];\n\n            buffer[2]   = '\\0';\n\n            profile_idc = strtol(buffer, NULL, 16);\n\n            buffer[0]   = value[2];\n\n            buffer[1]   = value[3];\n\n            profile_iop = strtol(buffer, NULL, 16);\n\n            buffer[0]   = value[4];\n\n            buffer[1]   = value[5];\n\n            level_idc   = strtol(buffer, NULL, 16);\n\n\n\n            av_log(codec, AV_LOG_DEBUG,\n\n                   \"RTP Profile IDC: %x Profile IOP: %x Level: %x\\n\",\n\n                   profile_idc, profile_iop, level_idc);\n\n            h264_data->profile_idc = profile_idc;\n\n            h264_data->profile_iop = profile_iop;\n\n            h264_data->level_idc   = level_idc;\n\n        }\n\n    } else if (!strcmp(attr, \"sprop-parameter-sets\")) {\n\n        codec->extradata_size = 0;\n\n        codec->extradata      = NULL;\n\n\n\n        while (*value) {\n\n            char base64packet[1024];\n\n            uint8_t decoded_packet[1024];\n\n            int packet_size;\n\n            char *dst = base64packet;\n\n\n\n            while (*value && *value != ','\n\n                   && (dst - base64packet) < sizeof(base64packet) - 1) {\n\n                *dst++ = *value++;\n\n            }\n\n            *dst++ = '\\0';\n\n\n\n            if (*value == ',')\n\n                value++;\n\n\n\n            packet_size = av_base64_decode(decoded_packet, base64packet,\n\n                                           sizeof(decoded_packet));\n\n            if (packet_size > 0) {\n\n                uint8_t *dest = av_malloc(packet_size + sizeof(start_sequence) +\n\n                                          codec->extradata_size +\n\n                                          FF_INPUT_BUFFER_PADDING_SIZE);\n\n                if (!dest) {\n\n                    av_log(codec, AV_LOG_ERROR,\n\n                           \"Unable to allocate memory for extradata!\");\n\n                    return AVERROR(ENOMEM);\n\n                }\n\n                if (codec->extradata_size) {\n\n                    memcpy(dest, codec->extradata, codec->extradata_size);\n\n                    av_free(codec->extradata);\n\n                }\n\n\n\n                memcpy(dest + codec->extradata_size, start_sequence,\n\n                       sizeof(start_sequence));\n\n                memcpy(dest + codec->extradata_size + sizeof(start_sequence),\n\n                       decoded_packet, packet_size);\n\n                memset(dest + codec->extradata_size + sizeof(start_sequence) +\n\n                       packet_size, 0, FF_INPUT_BUFFER_PADDING_SIZE);\n\n\n\n                codec->extradata       = dest;\n\n                codec->extradata_size += sizeof(start_sequence) + packet_size;\n\n            }\n\n        }\n\n        av_log(codec, AV_LOG_DEBUG, \"Extradata set to %p (size: %d)!\",\n\n               codec->extradata, codec->extradata_size);\n\n    }\n\n    return 0;\n\n}\n", "idx": 26367, "_split": "test", "_hash": "295831fc3277cce86d529279384a8498"}
{"project": "FFmpeg", "commit_id": "3dea28cc2ef22861347918b6740c4c05c46a6614", "target": 0, "func": "static void idr(H264Context *h){\n\n    int i;\n\n    ff_h264_remove_all_refs(h);\n\n    h->prev_frame_num= -1;\n\n    h->prev_frame_num_offset= 0;\n\n    h->prev_poc_msb= 1<<16;\n\n    h->prev_poc_lsb= 0;\n\n    for (i = 0; i < MAX_DELAYED_PIC_COUNT; i++)\n\n        h->last_pocs[i] = INT_MIN;\n\n}\n", "idx": 26390, "_split": "test", "_hash": "08983d0dab7616e85fb8f1a12a2656af"}
{"project": "FFmpeg", "commit_id": "636ced8e1dc8248a1353b416240b93d70ad03edb", "target": 1, "func": "static void abort_codec_experimental(AVCodec *c, int encoder)\n\n{\n\n    const char *codec_string = encoder ? \"encoder\" : \"decoder\";\n\n    AVCodec *codec;\n\n    av_log(NULL, AV_LOG_FATAL, \"%s '%s' is experimental and might produce bad \"\n\n            \"results.\\nAdd '-strict experimental' if you want to use it.\\n\",\n\n            codec_string, c->name);\n\n    codec = encoder ? avcodec_find_encoder(c->id) : avcodec_find_decoder(c->id);\n\n    if (!(codec->capabilities & CODEC_CAP_EXPERIMENTAL))\n\n        av_log(NULL, AV_LOG_FATAL, \"Or use the non experimental %s '%s'.\\n\",\n\n               codec_string, codec->name);\n\n    exit(1);\n\n}\n", "idx": 26428, "_split": "test", "_hash": "ab74b510915bbdd4e91a1299ebd9cc44"}
{"project": "FFmpeg", "commit_id": "877f76ad33bb9b0b0d09565dd9ec1cf8e91096f1", "target": 1, "func": "static inline void hyscale_fast_c(SwsContext *c, int16_t *dst, int dstWidth,\n\n                                  const uint8_t *src, int srcW, int xInc)\n\n{\n\n    int i;\n\n    unsigned int xpos=0;\n\n    for (i=0;i<dstWidth;i++) {\n\n        register unsigned int xx=xpos>>16;\n\n        register unsigned int xalpha=(xpos&0xFFFF)>>9;\n\n        dst[i]= (src[xx]<<7) + (src[xx+1] - src[xx])*xalpha;\n\n        xpos+=xInc;\n\n    }\n\n\n\n}", "idx": 26435, "_split": "test", "_hash": "79b76df972eaa881bd5ca51607202fd2"}
{"project": "FFmpeg", "commit_id": "7cc84d241ba6ef8e27e4d057176a4ad385ad3d59", "target": 1, "func": "static int standard_decode_i_mbs(VC9Context *v)\n\n{\n\n    GetBitContext *gb = &v->s.gb;\n\n    MpegEncContext *s = &v->s;\n\n    int current_mb = 0; /* MB/Block Position info */\n\n    uint8_t cbpcy[4], previous_cbpcy[4], predicted_cbpcy,\n\n        *p_cbpcy /* Pointer to skip some math */;\n\n\n\n    /* Reset CBPCY predictors */\n\n    memset(v->previous_line_cbpcy, 0, s->mb_stride<<2);\n\n\n\n    /* Select ttmb table depending on pq */\n\n    if (v->pq < 5) v->ttmb_vlc = &vc9_ttmb_vlc[0];\n\n    else if (v->pq < 13) v->ttmb_vlc = &vc9_ttmb_vlc[1];\n\n    else v->ttmb_vlc = &vc9_ttmb_vlc[2];\n\n\n\n    for (s->mb_y=0; s->mb_y<s->mb_height; s->mb_y++)\n\n    {\n\n        /* Init CBPCY for line */\n\n        *((uint32_t*)previous_cbpcy) = 0x00000000;\n\n        p_cbpcy = v->previous_line_cbpcy+4;\n\n\n\n        for (s->mb_x=0; s->mb_x<s->mb_width; s->mb_x++, p_cbpcy += 4)\n\n        {\n\n            /* Get CBPCY */\n\n            GET_CBPCY(ff_msmp4_mb_i_vlc.table, MB_INTRA_VLC_BITS);\n\n\n\n            s->ac_pred = get_bits(gb, 1);\n\n\n\n            /* TODO: Decode blocks from that mb wrt cbpcy */\n\n\n\n            /* Update for next block */\n\n#if TRACE > 2\n\n            av_log(s->avctx, AV_LOG_DEBUG, \"Block %4i: p_cbpcy=%i%i%i%i, previous_cbpcy=%i%i%i%i,\"\n\n                   \" cbpcy=%i%i%i%i\\n\", current_mb,\n\n                   p_cbpcy[0], p_cbpcy[1], p_cbpcy[2], p_cbpcy[3],\n\n                   previous_cbpcy[0], previous_cbpcy[1], previous_cbpcy[2], previous_cbpcy[3],\n\n                   cbpcy[0], cbpcy[1], cbpcy[2], cbpcy[3]);\n\n#endif\n\n            *((uint32_t*)p_cbpcy) = *((uint32_t*)previous_cbpcy);\n\n            *((uint32_t*)previous_cbpcy) = *((uint32_t*)cbpcy);\n\n            current_mb++;\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 26437, "_split": "test", "_hash": "377e329de25cb74f52677452f939d17c"}
{"project": "FFmpeg", "commit_id": "2f9ca64556cba9a7edcca9a1c55923a60022937d", "target": 0, "func": "static int open_url(AVFormatContext *s, AVIOContext **pb, const char *url,\n\n                    AVDictionary *opts, AVDictionary *opts2, int *is_http)\n\n{\n\n    HLSContext *c = s->priv_data;\n\n    AVDictionary *tmp = NULL;\n\n    const char *proto_name = NULL;\n\n    int ret;\n\n\n\n    av_dict_copy(&tmp, opts, 0);\n\n    av_dict_copy(&tmp, opts2, 0);\n\n\n\n    if (av_strstart(url, \"crypto\", NULL)) {\n\n        if (url[6] == '+' || url[6] == ':')\n\n            proto_name = avio_find_protocol_name(url + 7);\n\n    }\n\n\n\n    if (!proto_name)\n\n        proto_name = avio_find_protocol_name(url);\n\n\n\n    if (!proto_name)\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    // only http(s) & file are allowed\n\n    if (av_strstart(proto_name, \"file\", NULL)) {\n\n        if (strcmp(c->allowed_extensions, \"ALL\") && !av_match_ext(url, c->allowed_extensions)) {\n\n            av_log(s, AV_LOG_ERROR,\n\n                \"Filename extension of \\'%s\\' is not a common multimedia extension, blocked for security reasons.\\n\"\n\n                \"If you wish to override this adjust allowed_extensions, you can set it to \\'ALL\\' to allow all\\n\",\n\n                url);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else if (av_strstart(proto_name, \"http\", NULL)) {\n\n        ;\n\n    } else\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (!strncmp(proto_name, url, strlen(proto_name)) && url[strlen(proto_name)] == ':')\n\n        ;\n\n    else if (av_strstart(url, \"crypto\", NULL) && !strncmp(proto_name, url + 7, strlen(proto_name)) && url[7 + strlen(proto_name)] == ':')\n\n        ;\n\n    else if (strcmp(proto_name, \"file\") || !strncmp(url, \"file,\", 5))\n\n        return AVERROR_INVALIDDATA;\n\n\n\n    if (c->http_persistent && *pb && av_strstart(proto_name, \"http\", NULL)) {\n\n        ret = open_url_keepalive(c->ctx, pb, url);\n\n        if (ret == AVERROR_EXIT) {\n\n            return ret;\n\n        } else if (ret < 0) {\n\n            if (ret != AVERROR_EOF)\n\n                av_log(s, AV_LOG_WARNING,\n\n                    \"keepalive request failed for '%s', retrying with new connection: %s\\n\",\n\n                    url, av_err2str(ret));\n\n            ret = s->io_open(s, pb, url, AVIO_FLAG_READ, &tmp);\n\n        }\n\n    } else {\n\n        ret = s->io_open(s, pb, url, AVIO_FLAG_READ, &tmp);\n\n    }\n\n    if (ret >= 0) {\n\n        // update cookies on http response with setcookies.\n\n        char *new_cookies = NULL;\n\n\n\n        if (!(s->flags & AVFMT_FLAG_CUSTOM_IO))\n\n            av_opt_get(*pb, \"cookies\", AV_OPT_SEARCH_CHILDREN, (uint8_t**)&new_cookies);\n\n\n\n        if (new_cookies) {\n\n            av_free(c->cookies);\n\n            c->cookies = new_cookies;\n\n        }\n\n\n\n        av_dict_set(&opts, \"cookies\", c->cookies, 0);\n\n    }\n\n\n\n    av_dict_free(&tmp);\n\n\n\n    if (is_http)\n\n        *is_http = av_strstart(proto_name, \"http\", NULL);\n\n\n\n    return ret;\n\n}\n", "idx": 26481, "_split": "test", "_hash": "f8797b03313982694703d62487a52ce5"}
{"project": "FFmpeg", "commit_id": "44d854a518f97cb65090420b0b9f55611a0ea932", "target": 1, "func": "static av_cold int atrac3_decode_init(AVCodecContext *avctx)\n\n{\n\n    int i, ret;\n\n    int version, delay, samples_per_frame, frame_factor;\n\n    const uint8_t *edata_ptr = avctx->extradata;\n\n    ATRAC3Context *q = avctx->priv_data;\n\n\n\n    if (avctx->channels <= 0 || avctx->channels > 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Channel configuration error!\\n\");\n\n\n    }\n\n\n\n    /* Take care of the codec-specific extradata. */\n\n    if (avctx->extradata_size == 14) {\n\n        /* Parse the extradata, WAV format */\n\n        av_log(avctx, AV_LOG_DEBUG, \"[0-1] %d\\n\",\n\n               bytestream_get_le16(&edata_ptr));  // Unknown value always 1\n\n        edata_ptr += 4;                             // samples per channel\n\n        q->coding_mode = bytestream_get_le16(&edata_ptr);\n\n        av_log(avctx, AV_LOG_DEBUG,\"[8-9] %d\\n\",\n\n               bytestream_get_le16(&edata_ptr));  //Dupe of coding mode\n\n        frame_factor = bytestream_get_le16(&edata_ptr);  // Unknown always 1\n\n        av_log(avctx, AV_LOG_DEBUG,\"[12-13] %d\\n\",\n\n               bytestream_get_le16(&edata_ptr));  // Unknown always 0\n\n\n\n        /* setup */\n\n        samples_per_frame    = SAMPLES_PER_FRAME * avctx->channels;\n\n        version              = 4;\n\n        delay                = 0x88E;\n\n        q->coding_mode       = q->coding_mode ? JOINT_STEREO : STEREO;\n\n        q->scrambled_stream  = 0;\n\n\n\n        if (avctx->block_align !=  96 * avctx->channels * frame_factor &&\n\n            avctx->block_align != 152 * avctx->channels * frame_factor &&\n\n            avctx->block_align != 192 * avctx->channels * frame_factor) {\n\n            av_log(avctx, AV_LOG_ERROR, \"Unknown frame/channel/frame_factor \"\n\n                   \"configuration %d/%d/%d\\n\", avctx->block_align,\n\n                   avctx->channels, frame_factor);\n\n            return AVERROR_INVALIDDATA;\n\n        }\n\n    } else if (avctx->extradata_size == 10) {\n\n        /* Parse the extradata, RM format. */\n\n        version                = bytestream_get_be32(&edata_ptr);\n\n        samples_per_frame      = bytestream_get_be16(&edata_ptr);\n\n        delay                  = bytestream_get_be16(&edata_ptr);\n\n        q->coding_mode         = bytestream_get_be16(&edata_ptr);\n\n        q->scrambled_stream    = 1;\n\n\n\n    } else {\n\n        av_log(NULL, AV_LOG_ERROR, \"Unknown extradata size %d.\\n\",\n\n               avctx->extradata_size);\n\n\n    }\n\n\n\n    /* Check the extradata */\n\n\n\n    if (version != 4) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Version %d != 4.\\n\", version);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (samples_per_frame != SAMPLES_PER_FRAME &&\n\n        samples_per_frame != SAMPLES_PER_FRAME * 2) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown amount of samples per frame %d.\\n\",\n\n               samples_per_frame);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (delay != 0x88E) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown amount of delay %x != 0x88E.\\n\",\n\n               delay);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (q->coding_mode == STEREO)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Normal stereo detected.\\n\");\n\n    else if (q->coding_mode == JOINT_STEREO)\n\n        av_log(avctx, AV_LOG_DEBUG, \"Joint stereo detected.\\n\");\n\n    else {\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown channel coding mode %x!\\n\",\n\n               q->coding_mode);\n\n        return AVERROR_INVALIDDATA;\n\n    }\n\n\n\n    if (avctx->block_align >= UINT_MAX / 2)\n\n\n\n\n    q->decoded_bytes_buffer = av_mallocz(FFALIGN(avctx->block_align, 4) +\n\n                                         FF_INPUT_BUFFER_PADDING_SIZE);\n\n    if (q->decoded_bytes_buffer == NULL)\n\n        return AVERROR(ENOMEM);\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_FLTP;\n\n\n\n    /* initialize the MDCT transform */\n\n    if ((ret = ff_mdct_init(&q->mdct_ctx, 9, 1, 1.0 / 32768)) < 0) {\n\n        av_log(avctx, AV_LOG_ERROR, \"Error initializing MDCT\\n\");\n\n        av_freep(&q->decoded_bytes_buffer);\n\n        return ret;\n\n    }\n\n\n\n    /* init the joint-stereo decoding data */\n\n    q->weighting_delay[0] = 0;\n\n    q->weighting_delay[1] = 7;\n\n    q->weighting_delay[2] = 0;\n\n    q->weighting_delay[3] = 7;\n\n    q->weighting_delay[4] = 0;\n\n    q->weighting_delay[5] = 7;\n\n\n\n    for (i = 0; i < 4; i++) {\n\n        q->matrix_coeff_index_prev[i] = 3;\n\n        q->matrix_coeff_index_now[i]  = 3;\n\n        q->matrix_coeff_index_next[i] = 3;\n\n    }\n\n\n\n    avpriv_float_dsp_init(&q->fdsp, avctx->flags & CODEC_FLAG_BITEXACT);\n\n    ff_fmt_convert_init(&q->fmt_conv, avctx);\n\n\n\n    q->units = av_mallocz(sizeof(*q->units) * avctx->channels);\n\n    if (!q->units) {\n\n        atrac3_decode_close(avctx);\n\n        return AVERROR(ENOMEM);\n\n    }\n\n\n\n    avcodec_get_frame_defaults(&q->frame);\n\n    avctx->coded_frame = &q->frame;\n\n\n\n    return 0;\n\n}", "idx": 26512, "_split": "test", "_hash": "fbd06683aac20ad1772c31cb9fb18812"}
{"project": "FFmpeg", "commit_id": "beefafda639dd53fc59c21d8a7cf8334da9a1062", "target": 1, "func": "static inline int wv_get_value_integer(WavpackFrameContext *s, uint32_t *crc, int S)\n\n{\n\n    int bit;\n\n\n\n    if(s->extra_bits){\n\n        S <<= s->extra_bits;\n\n\n\n        if(s->got_extra_bits){\n\n            S |= get_bits(&s->gb_extra_bits, s->extra_bits);\n\n            *crc = *crc * 9 + (S&0xffff) * 3 + ((unsigned)S>>16);\n\n        }\n\n    }\n\n    bit = (S & s->and) | s->or;\n\n    return (((S + bit) << s->shift) - bit) << s->post_shift;\n\n}\n", "idx": 26559, "_split": "test", "_hash": "d86039173c260dfbcc122d8e4157d303"}
{"project": "FFmpeg", "commit_id": "42f9132218ca11a8e9a3c82a175b46bca092113e", "target": 0, "func": "static int mxf_read_seek(AVFormatContext *s, int stream_index, int64_t sample_time, int flags)\n\n{\n\n    AVStream *st = s->streams[stream_index];\n\n    int64_t seconds;\n\n    MXFContext* mxf = s->priv_data;\n\n    int64_t seekpos;\n\n    int ret;\n\n    MXFIndexTable *t;\n\n\n\n    if (mxf->nb_index_tables <= 0) {\n\n    if (!s->bit_rate)\n\n        return AVERROR_INVALIDDATA;\n\n    if (sample_time < 0)\n\n        sample_time = 0;\n\n    seconds = av_rescale(sample_time, st->time_base.num, st->time_base.den);\n\n\n\n    if ((ret = avio_seek(s->pb, (s->bit_rate * seconds) >> 3, SEEK_SET)) < 0)\n\n        return ret;\n\n    ff_update_cur_dts(s, st, sample_time);\n\n    mxf->current_edit_unit = sample_time;\n\n    } else {\n\n        t = &mxf->index_tables[0];\n\n\n\n        /* clamp above zero, else ff_index_search_timestamp() returns negative\n\n         * this also means we allow seeking before the start */\n\n        sample_time = FFMAX(sample_time, 0);\n\n\n\n        if (t->fake_index) {\n\n            /* behave as if we have a proper index */\n\n            if ((sample_time = ff_index_search_timestamp(t->fake_index, t->nb_ptses, sample_time, flags)) < 0)\n\n                return sample_time;\n\n        } else {\n\n            /* no IndexEntryArray (one or more CBR segments)\n\n             * make sure we don't seek past the end */\n\n            sample_time = FFMIN(sample_time, st->duration - 1);\n\n        }\n\n\n\n        if ((ret = mxf_edit_unit_absolute_offset(mxf, t, sample_time, &sample_time, &seekpos, 1)) << 0)\n\n            return ret;\n\n\n\n        ff_update_cur_dts(s, st, sample_time);\n\n        mxf->current_edit_unit = sample_time;\n\n        avio_seek(s->pb, seekpos, SEEK_SET);\n\n    }\n\n    return 0;\n\n}\n", "idx": 26568, "_split": "test", "_hash": "26a80dca57a5fba48b5a7e263e0507b8"}
{"project": "FFmpeg", "commit_id": "79997def65fd2313b48a5f3c3a884c6149ae9b5d", "target": 0, "func": "static av_cold int fft_init(AVCodecContext *avctx, AC3MDCTContext *mdct, int ln)\n\n{\n\n    int i, n, n2;\n\n    float alpha;\n\n\n\n    n  = 1 << ln;\n\n    n2 = n >> 1;\n\n\n\n    FF_ALLOC_OR_GOTO(avctx, mdct->costab, n2 * sizeof(*mdct->costab), fft_alloc_fail);\n\n    FF_ALLOC_OR_GOTO(avctx, mdct->sintab, n2 * sizeof(*mdct->sintab), fft_alloc_fail);\n\n\n\n    for (i = 0; i < n2; i++) {\n\n        alpha     = 2.0 * M_PI * i / n;\n\n        mdct->costab[i] = FIX15(cos(alpha));\n\n        mdct->sintab[i] = FIX15(sin(alpha));\n\n    }\n\n\n\n    return 0;\n\nfft_alloc_fail:\n\n    mdct_end(mdct);\n\n    return AVERROR(ENOMEM);\n\n}\n", "idx": 26730, "_split": "test", "_hash": "46d27c3aa2a682383b4e6f3256868682"}
{"project": "FFmpeg", "commit_id": "72a6244b5d554d7fdfdeb04c174750c7a2c52f83", "target": 0, "func": "void ff_ac3_bit_alloc_calc_mask(AC3BitAllocParameters *s, int16_t *band_psd,\n\n                                int start, int end, int fast_gain, int is_lfe,\n\n                                int dba_mode, int dba_nsegs, uint8_t *dba_offsets,\n\n                                uint8_t *dba_lengths, uint8_t *dba_values,\n\n                                int16_t *mask)\n\n{\n\n    int16_t excite[50]; /* excitation */\n\n    int bin, k;\n\n    int bndstrt, bndend, begin, end1, tmp;\n\n    int lowcomp, fastleak, slowleak;\n\n\n\n    /* excitation function */\n\n    bndstrt = bin_to_band_tab[start];\n\n    bndend = bin_to_band_tab[end-1] + 1;\n\n\n\n    if (bndstrt == 0) {\n\n        lowcomp = 0;\n\n        lowcomp = calc_lowcomp1(lowcomp, band_psd[0], band_psd[1], 384);\n\n        excite[0] = band_psd[0] - fast_gain - lowcomp;\n\n        lowcomp = calc_lowcomp1(lowcomp, band_psd[1], band_psd[2], 384);\n\n        excite[1] = band_psd[1] - fast_gain - lowcomp;\n\n        begin = 7;\n\n        for (bin = 2; bin < 7; bin++) {\n\n            if (!(is_lfe && bin == 6))\n\n                lowcomp = calc_lowcomp1(lowcomp, band_psd[bin], band_psd[bin+1], 384);\n\n            fastleak = band_psd[bin] - fast_gain;\n\n            slowleak = band_psd[bin] - s->slow_gain;\n\n            excite[bin] = fastleak - lowcomp;\n\n            if (!(is_lfe && bin == 6)) {\n\n                if (band_psd[bin] <= band_psd[bin+1]) {\n\n                    begin = bin + 1;\n\n                    break;\n\n                }\n\n            }\n\n        }\n\n\n\n        end1=bndend;\n\n        if (end1 > 22) end1=22;\n\n\n\n        for (bin = begin; bin < end1; bin++) {\n\n            if (!(is_lfe && bin == 6))\n\n                lowcomp = calc_lowcomp(lowcomp, band_psd[bin], band_psd[bin+1], bin);\n\n\n\n            fastleak = FFMAX(fastleak - s->fast_decay, band_psd[bin] - fast_gain);\n\n            slowleak = FFMAX(slowleak - s->slow_decay, band_psd[bin] - s->slow_gain);\n\n            excite[bin] = FFMAX(fastleak - lowcomp, slowleak);\n\n        }\n\n        begin = 22;\n\n    } else {\n\n        /* coupling channel */\n\n        begin = bndstrt;\n\n\n\n        fastleak = (s->cpl_fast_leak << 8) + 768;\n\n        slowleak = (s->cpl_slow_leak << 8) + 768;\n\n    }\n\n\n\n    for (bin = begin; bin < bndend; bin++) {\n\n        fastleak = FFMAX(fastleak - s->fast_decay, band_psd[bin] - fast_gain);\n\n        slowleak = FFMAX(slowleak - s->slow_decay, band_psd[bin] - s->slow_gain);\n\n        excite[bin] = FFMAX(fastleak, slowleak);\n\n    }\n\n\n\n    /* compute masking curve */\n\n\n\n    for (bin = bndstrt; bin < bndend; bin++) {\n\n        tmp = s->db_per_bit - band_psd[bin];\n\n        if (tmp > 0) {\n\n            excite[bin] += tmp >> 2;\n\n        }\n\n        mask[bin] = FFMAX(ff_ac3_hearing_threshold_tab[bin >> s->sr_shift][s->sr_code], excite[bin]);\n\n    }\n\n\n\n    /* delta bit allocation */\n\n\n\n    if (dba_mode == DBA_REUSE || dba_mode == DBA_NEW) {\n\n        int band, seg, delta;\n\n        band = 0;\n\n        for (seg = 0; seg < FFMIN(8, dba_nsegs); seg++) {\n\n            band = FFMIN(49, band + dba_offsets[seg]);\n\n            if (dba_values[seg] >= 4) {\n\n                delta = (dba_values[seg] - 3) << 7;\n\n            } else {\n\n                delta = (dba_values[seg] - 4) << 7;\n\n            }\n\n            for (k = 0; k < dba_lengths[seg]; k++) {\n\n                mask[band] += delta;\n\n                band++;\n\n            }\n\n        }\n\n    }\n\n}\n", "idx": 26774, "_split": "test", "_hash": "1d75e42d6bdf17e5160ded34594dbdcc"}
{"project": "FFmpeg", "commit_id": "8a57ca5c6a1c0ad28afa7ea6f824981e6761cce1", "target": 0, "func": "static int aasc_decode_frame(AVCodecContext *avctx,\n\n                              void *data, int *data_size,\n\n                              AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    AascContext *s = avctx->priv_data;\n\n    int compr, i, stride;\n\n\n\n    s->frame.reference = 3;\n\n    s->frame.buffer_hints = FF_BUFFER_HINTS_VALID | FF_BUFFER_HINTS_PRESERVE | FF_BUFFER_HINTS_REUSABLE;\n\n    if (avctx->reget_buffer(avctx, &s->frame)) {\n\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n\n        return -1;\n\n    }\n\n\n\n    compr = AV_RL32(buf);\n\n    buf += 4;\n\n    buf_size -= 4;\n\n    switch (avctx->codec_tag) {\n\n    case MKTAG('A', 'A', 'S', '4'):\n\n        bytestream2_init(&s->gb, buf - 4, buf_size + 4);\n\n        ff_msrle_decode(avctx, (AVPicture*)&s->frame, 8, &s->gb);\n\n        break;\n\n    case MKTAG('A', 'A', 'S', 'C'):\n\n    switch(compr){\n\n    case 0:\n\n        stride = (avctx->width * 3 + 3) & ~3;\n\n        for(i = avctx->height - 1; i >= 0; i--){\n\n            if(avctx->width*3 > buf_size){\n\n                av_log(avctx, AV_LOG_ERROR, \"Next line is beyond buffer bounds\\n\");\n\n                break;\n\n            }\n\n            memcpy(s->frame.data[0] + i*s->frame.linesize[0], buf, avctx->width*3);\n\n            buf += stride;\n\n            buf_size -= stride;\n\n        }\n\n        break;\n\n    case 1:\n\n        bytestream2_init(&s->gb, buf, buf_size);\n\n        ff_msrle_decode(avctx, (AVPicture*)&s->frame, 8, &s->gb);\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown compression type %d\\n\", compr);\n\n        return -1;\n\n    }\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_ERROR, \"Unknown FourCC: %X\\n\", avctx->codec_tag);\n\n        return -1;\n\n    }\n\n\n\n    *data_size = sizeof(AVFrame);\n\n    *(AVFrame*)data = s->frame;\n\n\n\n    /* report that the buffer was completely consumed */\n\n    return buf_size;\n\n}\n", "idx": 26819, "_split": "test", "_hash": "758c358a38d0012899a904bee14ee93b"}
{"project": "FFmpeg", "commit_id": "de6df46120367b7d49d9d7c0971cbe36368b840a", "target": 1, "func": "int ff_h264_field_end(H264Context *h, int in_setup)\n{\n    AVCodecContext *const avctx = h->avctx;\n    int err = 0;\n    h->mb_y = 0;\n    if (CONFIG_H264_VDPAU_DECODER &&\n        h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n        ff_vdpau_h264_set_reference_frames(h);\n    if (in_setup || !(avctx->active_thread_type & FF_THREAD_FRAME)) {\n        if (!h->droppable) {\n            err = ff_h264_execute_ref_pic_marking(h, h->mmco, h->mmco_index);\n            h->prev_poc_msb = h->poc_msb;\n            h->prev_poc_lsb = h->poc_lsb;\n        }\n        h->prev_frame_num_offset = h->frame_num_offset;\n        h->prev_frame_num        = h->frame_num;\n        h->outputed_poc          = h->next_outputed_poc;\n    }\n    if (avctx->hwaccel) {\n        if (avctx->hwaccel->end_frame(avctx) < 0)\n            av_log(avctx, AV_LOG_ERROR,\n                   \"hardware accelerator failed to decode picture\\n\");\n    }\n    if (CONFIG_H264_VDPAU_DECODER &&\n        h->avctx->codec->capabilities & CODEC_CAP_HWACCEL_VDPAU)\n        ff_vdpau_h264_picture_complete(h);\n#if CONFIG_ERROR_RESILIENCE\n    /*\n     * FIXME: Error handling code does not seem to support interlaced\n     * when slices span multiple rows\n     * The ff_er_add_slice calls don't work right for bottom\n     * fields; they cause massive erroneous error concealing\n     * Error marking covers both fields (top and bottom).\n     * This causes a mismatched s->error_count\n     * and a bad error table. Further, the error count goes to\n     * INT_MAX when called for bottom field, because mb_y is\n     * past end by one (callers fault) and resync_mb_y != 0\n     * causes problems for the first MB line, too.\n     */\n    if (!FIELD_PICTURE(h) && h->current_slice && !h->sps.new) {\n        ff_h264_set_erpic(&h->er.cur_pic, h->cur_pic_ptr);\n        ff_er_frame_end(&h->er);\n    }\n#endif /* CONFIG_ERROR_RESILIENCE */\n    if (!in_setup && !h->droppable)\n        ff_thread_report_progress(&h->cur_pic_ptr->tf, INT_MAX,\n                                  h->picture_structure == PICT_BOTTOM_FIELD);\n    emms_c();\n    h->current_slice = 0;\n    return err;\n}", "idx": 26836, "_split": "test", "_hash": "6930d7ca15adbc05a038dd6fc050a861"}
{"project": "FFmpeg", "commit_id": "a91d82b5cc7d828ea9779aae1595f60e7e257d29", "target": 1, "func": "static int sbr_hf_calc_npatches(AACContext *ac, SpectralBandReplication *sbr)\n\n{\n\n    int i, k, sb = 0;\n\n    int msb = sbr->k[0];\n\n    int usb = sbr->kx[1];\n\n    int goal_sb = ((1000 << 11) + (sbr->sample_rate >> 1)) / sbr->sample_rate;\n\n\n\n    sbr->num_patches = 0;\n\n\n\n    if (goal_sb < sbr->kx[1] + sbr->m[1]) {\n\n        for (k = 0; sbr->f_master[k] < goal_sb; k++) ;\n\n    } else\n\n        k = sbr->n_master;\n\n\n\n    do {\n\n        int odd = 0;\n\n        for (i = k; i == k || sb > (sbr->k[0] - 1 + msb - odd); i--) {\n\n            sb = sbr->f_master[i];\n\n            odd = (sb + sbr->k[0]) & 1;\n\n        }\n\n\n\n        sbr->patch_num_subbands[sbr->num_patches]  = FFMAX(sb - usb, 0);\n\n        sbr->patch_start_subband[sbr->num_patches] = sbr->k[0] - odd - sbr->patch_num_subbands[sbr->num_patches];\n\n\n\n        if (sbr->patch_num_subbands[sbr->num_patches] > 0) {\n\n            usb = sb;\n\n            msb = sb;\n\n            sbr->num_patches++;\n\n        } else\n\n            msb = sbr->kx[1];\n\n\n\n        if (sbr->f_master[k] - sb < 3)\n\n            k = sbr->n_master;\n\n    } while (sb != sbr->kx[1] + sbr->m[1]);\n\n\n\n    if (sbr->patch_num_subbands[sbr->num_patches-1] < 3 && sbr->num_patches > 1)\n\n        sbr->num_patches--;\n\n\n\n    // Requirements (14496-3 sp04 p205) sets the maximum number of patches to 5\n\n    // However the Coding Technologies decoder check uses 6 patches\n\n    if (sbr->num_patches > 6) {\n\n        av_log(ac->avccontext, AV_LOG_ERROR, \"Too many patches: %d\\n\", sbr->num_patches);\n\n        return -1;\n\n    }\n\n\n\n    return 0;\n\n}\n", "idx": 26862, "_split": "test", "_hash": "c574cdafcf3678f87f0ac1a90dba0d07"}
{"project": "FFmpeg", "commit_id": "0de1319ee0109facefe9804ffe0f0d0df36b27ad", "target": 0, "func": "static int http_start_receive_data(HTTPContext *c)\n\n{\n\n    int fd;\n\n\n\n    if (c->stream->feed_opened)\n\n        return -1;\n\n\n\n    /* Don't permit writing to this one */\n\n    if (c->stream->readonly)\n\n        return -1;\n\n\n\n    /* open feed */\n\n    fd = open(c->stream->feed_filename, O_RDWR);\n\n    if (fd < 0) {\n\n        http_log(\"Error opening feeder file: %s\\n\", strerror(errno));\n\n        return -1;\n\n    }\n\n    c->feed_fd = fd;\n\n\n\n    if (c->stream->truncate) {\n\n        /* truncate feed file */\n\n        ffm_write_write_index(c->feed_fd, FFM_PACKET_SIZE);\n\n        ftruncate(c->feed_fd, FFM_PACKET_SIZE);\n\n        http_log(\"Truncating feed file '%s'\\n\", c->stream->feed_filename);\n\n    } else {\n\n        if ((c->stream->feed_write_index = ffm_read_write_index(fd)) < 0) {\n\n            http_log(\"Error reading write index from feed file: %s\\n\", strerror(errno));\n\n            return -1;\n\n        }\n\n    }\n\n\n\n    c->stream->feed_write_index = FFMAX(ffm_read_write_index(fd), FFM_PACKET_SIZE);\n\n    c->stream->feed_size = lseek(fd, 0, SEEK_END);\n\n    lseek(fd, 0, SEEK_SET);\n\n\n\n    /* init buffer input */\n\n    c->buffer_ptr = c->buffer;\n\n    c->buffer_end = c->buffer + FFM_PACKET_SIZE;\n\n    c->stream->feed_opened = 1;\n\n    c->chunked_encoding = !!av_stristr(c->buffer, \"Transfer-Encoding: chunked\");\n\n    return 0;\n\n}\n", "idx": 26880, "_split": "test", "_hash": "06fe7812531d5e651023a8000112f47c"}
{"project": "FFmpeg", "commit_id": "39f7620d76c7a133535ed7a535f7a74fefa6e435", "target": 0, "func": "static av_cold int dcadec_init(AVCodecContext *avctx)\n\n{\n\n    DCAContext *s = avctx->priv_data;\n\n\n\n    s->avctx = avctx;\n\n    s->core.avctx = avctx;\n\n    s->exss.avctx = avctx;\n\n    s->xll.avctx = avctx;\n\n    s->lbr.avctx = avctx;\n\n\n\n    ff_dca_init_vlcs();\n\n\n\n    if (ff_dca_core_init(&s->core) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (ff_dca_lbr_init(&s->lbr) < 0)\n\n        return AVERROR(ENOMEM);\n\n\n\n    ff_dcadsp_init(&s->dcadsp);\n\n    s->core.dcadsp = &s->dcadsp;\n\n    s->xll.dcadsp = &s->dcadsp;\n\n    s->lbr.dcadsp = &s->dcadsp;\n\n\n\n    s->crctab = av_crc_get_table(AV_CRC_16_CCITT);\n\n\n\n    switch (avctx->request_channel_layout & ~AV_CH_LAYOUT_NATIVE) {\n\n    case 0:\n\n        s->request_channel_layout = 0;\n\n        break;\n\n    case AV_CH_LAYOUT_STEREO:\n\n    case AV_CH_LAYOUT_STEREO_DOWNMIX:\n\n        s->request_channel_layout = DCA_SPEAKER_LAYOUT_STEREO;\n\n        break;\n\n    case AV_CH_LAYOUT_5POINT0:\n\n        s->request_channel_layout = DCA_SPEAKER_LAYOUT_5POINT0;\n\n        break;\n\n    case AV_CH_LAYOUT_5POINT1:\n\n        s->request_channel_layout = DCA_SPEAKER_LAYOUT_5POINT1;\n\n        break;\n\n    default:\n\n        av_log(avctx, AV_LOG_WARNING, \"Invalid request_channel_layout\\n\");\n\n        break;\n\n    }\n\n\n\n    avctx->sample_fmt = AV_SAMPLE_FMT_S32P;\n\n    avctx->bits_per_raw_sample = 24;\n\n\n\n    return 0;\n\n}\n", "idx": 26947, "_split": "test", "_hash": "67dc84f96713e2c085c5d2d9d8afb3c8"}
{"project": "FFmpeg", "commit_id": "90901860c21468d6e9ae437c2bacb099c7bd3acf", "target": 0, "func": "static int vorbis_parse_setup_hdr_mappings(vorbis_context *vc) {\n\n    GetBitContext *gb=&vc->gb;\n\n    uint_fast8_t i, j;\n\n\n\n    vc->mapping_count=get_bits(gb, 6)+1;\n\n    vc->mappings=(vorbis_mapping *)av_mallocz(vc->mapping_count * sizeof(vorbis_mapping));\n\n\n\n    AV_DEBUG(\" There are %d mappings. \\n\", vc->mapping_count);\n\n\n\n    for(i=0;i<vc->mapping_count;++i) {\n\n        vorbis_mapping *mapping_setup=&vc->mappings[i];\n\n\n\n        if (get_bits(gb, 16)) {\n\n            av_log(vc->avccontext, AV_LOG_ERROR, \"Other mappings than type 0 are not compliant with the Vorbis I specification. \\n\");\n\n            return 1;\n\n        }\n\n        if (get_bits1(gb)) {\n\n            mapping_setup->submaps=get_bits(gb, 4)+1;\n\n        } else {\n\n            mapping_setup->submaps=1;\n\n        }\n\n\n\n        if (get_bits1(gb)) {\n\n            mapping_setup->coupling_steps=get_bits(gb, 8)+1;\n\n            mapping_setup->magnitude=(uint_fast8_t *)av_mallocz(mapping_setup->coupling_steps * sizeof(uint_fast8_t));\n\n            mapping_setup->angle=(uint_fast8_t *)av_mallocz(mapping_setup->coupling_steps * sizeof(uint_fast8_t));\n\n            for(j=0;j<mapping_setup->coupling_steps;++j) {\n\n                mapping_setup->magnitude[j]=get_bits(gb, ilog(vc->audio_channels-1));\n\n                mapping_setup->angle[j]=get_bits(gb, ilog(vc->audio_channels-1));\n\n                // FIXME: sanity checks\n\n            }\n\n        } else {\n\n            mapping_setup->coupling_steps=0;\n\n        }\n\n\n\n        AV_DEBUG(\"   %d mapping coupling steps: %d \\n\", i, mapping_setup->coupling_steps);\n\n\n\n        if(get_bits(gb, 2)) {\n\n            av_log(vc->avccontext, AV_LOG_ERROR, \"%d. mapping setup data invalid. \\n\", i);\n\n            return 1; // following spec.\n\n        }\n\n\n\n        if (mapping_setup->submaps>1) {\n\n            mapping_setup->mux=(uint_fast8_t *)av_mallocz(vc->audio_channels * sizeof(uint_fast8_t));\n\n            for(j=0;j<vc->audio_channels;++j) {\n\n                mapping_setup->mux[j]=get_bits(gb, 4);\n\n            }\n\n        }\n\n\n\n        for(j=0;j<mapping_setup->submaps;++j) {\n\n            skip_bits(gb, 8); // FIXME check?\n\n            mapping_setup->submap_floor[j]=get_bits(gb, 8);\n\n            mapping_setup->submap_residue[j]=get_bits(gb, 8);\n\n\n\n            AV_DEBUG(\"   %d mapping %d submap : floor %d, residue %d \\n\", i, j, mapping_setup->submap_floor[j], mapping_setup->submap_residue[j]);\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 26971, "_split": "test", "_hash": "3e0508239885458ed3cd43a494851ae5"}
{"project": "FFmpeg", "commit_id": "066fff755a5d8edc660c010ddb08474d208eeade", "target": 0, "func": "static void vp6_parse_coeff_models(VP56Context *s)\n\n{\n\n    VP56RangeCoder *c = &s->c;\n\n    VP56Model *model = s->modelp;\n\n    int def_prob[11];\n\n    int node, cg, ctx, pos;\n\n    int ct;    /* code type */\n\n    int pt;    /* plane type (0 for Y, 1 for U or V) */\n\n\n\n    memset(def_prob, 0x80, sizeof(def_prob));\n\n\n\n    for (pt=0; pt<2; pt++)\n\n        for (node=0; node<11; node++)\n\n            if (vp56_rac_get_prob(c, vp6_dccv_pct[pt][node])) {\n\n                def_prob[node] = vp56_rac_gets_nn(c, 7);\n\n                model->coeff_dccv[pt][node] = def_prob[node];\n\n            } else if (s->framep[VP56_FRAME_CURRENT]->key_frame) {\n\n                model->coeff_dccv[pt][node] = def_prob[node];\n\n            }\n\n\n\n    if (vp56_rac_get(c)) {\n\n        for (pos=1; pos<64; pos++)\n\n            if (vp56_rac_get_prob(c, vp6_coeff_reorder_pct[pos]))\n\n                model->coeff_reorder[pos] = vp56_rac_gets(c, 4);\n\n        vp6_coeff_order_table_init(s);\n\n    }\n\n\n\n    for (cg=0; cg<2; cg++)\n\n        for (node=0; node<14; node++)\n\n            if (vp56_rac_get_prob(c, vp6_runv_pct[cg][node]))\n\n                model->coeff_runv[cg][node] = vp56_rac_gets_nn(c, 7);\n\n\n\n    for (ct=0; ct<3; ct++)\n\n        for (pt=0; pt<2; pt++)\n\n            for (cg=0; cg<6; cg++)\n\n                for (node=0; node<11; node++)\n\n                    if (vp56_rac_get_prob(c, vp6_ract_pct[ct][pt][cg][node])) {\n\n                        def_prob[node] = vp56_rac_gets_nn(c, 7);\n\n                        model->coeff_ract[pt][ct][cg][node] = def_prob[node];\n\n                    } else if (s->framep[VP56_FRAME_CURRENT]->key_frame) {\n\n                        model->coeff_ract[pt][ct][cg][node] = def_prob[node];\n\n                    }\n\n\n\n    if (s->use_huffman) {\n\n        for (pt=0; pt<2; pt++) {\n\n            vp6_build_huff_tree(s, model->coeff_dccv[pt],\n\n                                vp6_huff_coeff_map, 12, &s->dccv_vlc[pt]);\n\n            vp6_build_huff_tree(s, model->coeff_runv[pt],\n\n                                vp6_huff_run_map, 9, &s->runv_vlc[pt]);\n\n            for (ct=0; ct<3; ct++)\n\n                for (cg = 0; cg < 6; cg++)\n\n                    vp6_build_huff_tree(s, model->coeff_ract[pt][ct][cg],\n\n                                        vp6_huff_coeff_map, 12,\n\n                                        &s->ract_vlc[pt][ct][cg]);\n\n        }\n\n        memset(s->nb_null, 0, sizeof(s->nb_null));\n\n    } else {\n\n    /* coeff_dcct is a linear combination of coeff_dccv */\n\n    for (pt=0; pt<2; pt++)\n\n        for (ctx=0; ctx<3; ctx++)\n\n            for (node=0; node<5; node++)\n\n                model->coeff_dcct[pt][ctx][node] = av_clip(((model->coeff_dccv[pt][node] * vp6_dccv_lc[ctx][node][0] + 128) >> 8) + vp6_dccv_lc[ctx][node][1], 1, 255);\n\n    }\n\n}\n", "idx": 26988, "_split": "test", "_hash": "fef1aa14096456e966c1652332e27215"}
{"project": "FFmpeg", "commit_id": "c23acbaed40101c677dfcfbbfe0d2c230a8e8f44", "target": 1, "func": "void FUNCC(ff_h264_idct_add)(uint8_t *_dst, DCTELEM *_block, int stride)\n\n{\n\n    int i;\n\n    INIT_CLIP\n\n    pixel *dst = (pixel*)_dst;\n\n    dctcoef *block = (dctcoef*)_block;\n\n    stride /= sizeof(pixel);\n\n\n\n    block[0] += 1 << 5;\n\n\n\n    for(i=0; i<4; i++){\n\n        const int z0=  block[i + 4*0]     +  block[i + 4*2];\n\n        const int z1=  block[i + 4*0]     -  block[i + 4*2];\n\n        const int z2= (block[i + 4*1]>>1) -  block[i + 4*3];\n\n        const int z3=  block[i + 4*1]     + (block[i + 4*3]>>1);\n\n\n\n        block[i + 4*0]= z0 + z3;\n\n        block[i + 4*1]= z1 + z2;\n\n        block[i + 4*2]= z1 - z2;\n\n        block[i + 4*3]= z0 - z3;\n\n    }\n\n\n\n    for(i=0; i<4; i++){\n\n        const int z0=  block[0 + 4*i]     +  block[2 + 4*i];\n\n        const int z1=  block[0 + 4*i]     -  block[2 + 4*i];\n\n        const int z2= (block[1 + 4*i]>>1) -  block[3 + 4*i];\n\n        const int z3=  block[1 + 4*i]     + (block[3 + 4*i]>>1);\n\n\n\n        dst[i + 0*stride]= CLIP(dst[i + 0*stride] + ((z0 + z3) >> 6));\n\n        dst[i + 1*stride]= CLIP(dst[i + 1*stride] + ((z1 + z2) >> 6));\n\n        dst[i + 2*stride]= CLIP(dst[i + 2*stride] + ((z1 - z2) >> 6));\n\n        dst[i + 3*stride]= CLIP(dst[i + 3*stride] + ((z0 - z3) >> 6));\n\n    }\n\n}\n", "idx": 27081, "_split": "test", "_hash": "cc21032d1c2a51247323181c904cf629"}
{"project": "FFmpeg", "commit_id": "0ecca7a49f8e254c12a3a1de048d738bfbb614c6", "target": 1, "func": "static unsigned long iv_decode_frame(Indeo3DecodeContext *s, \n                                     unsigned char *buf, int buf_size) \n{\n  unsigned int hdr_width, hdr_height,\n    chroma_width, chroma_height;\n  unsigned long fflags1, fflags2, fflags3, offs1, offs2, offs3, offs;\n  unsigned char *hdr_pos, *buf_pos;\n  buf_pos = buf;\n  buf_pos += 18;\n  fflags1 = le2me_16(*(uint16_t *)buf_pos);\n  buf_pos += 2;\n  fflags3 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  fflags2 = *buf_pos++;\n  buf_pos += 3;\n  hdr_height = le2me_16(*(uint16_t *)buf_pos);\n  buf_pos += 2;\n  hdr_width = le2me_16(*(uint16_t *)buf_pos);\n  buf_pos += 2;\n  chroma_height = ((hdr_height >> 2) + 3) & 0x7ffc;\n  chroma_width = ((hdr_width >> 2) + 3) & 0x7ffc;\n  offs1 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  offs2 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  offs3 = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 8;\n  hdr_pos = buf_pos;\n  if(fflags3 == 0x80) return 4;\n  if(fflags1 & 0x200) {\n    s->cur_frame = s->iv_frame + 1;\n    s->ref_frame = s->iv_frame;\n  } else {\n    s->cur_frame = s->iv_frame;\n    s->ref_frame = s->iv_frame + 1;\n  }\n  buf_pos = buf + 16 + offs1;\n  offs = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  iv_Decode_Chunk(s, s->cur_frame->Ybuf, s->ref_frame->Ybuf, hdr_width, \n    hdr_height, buf_pos + offs * 2, fflags2, hdr_pos, buf_pos, \n    min(hdr_width, 160));\n  if (!(s->avctx->flags & CODEC_FLAG_GRAY))\n  {\n  buf_pos = buf + 16 + offs2;\n  offs = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  iv_Decode_Chunk(s, s->cur_frame->Vbuf, s->ref_frame->Vbuf, chroma_width, \n    chroma_height, buf_pos + offs * 2, fflags2, hdr_pos, buf_pos, \n    min(chroma_width, 40));\n  buf_pos = buf + 16 + offs3;\n  offs = le2me_32(*(uint32_t *)buf_pos);\n  buf_pos += 4;\n  iv_Decode_Chunk(s, s->cur_frame->Ubuf, s->ref_frame->Ubuf, chroma_width, \n    chroma_height, buf_pos + offs * 2, fflags2, hdr_pos, buf_pos, \n    min(chroma_width, 40));\n  }\n  return 8;\n}", "idx": 27151, "_split": "test", "_hash": "00d78c8126854c0514ced46335967e94"}
{"project": "FFmpeg", "commit_id": "e13f860ac8a5a7d803059d1553773cf2a446d3f2", "target": 0, "func": "static int decode_vol_header(MpegEncContext *s, GetBitContext *gb){\n\n    int width, height, vo_ver_id;\n\n\n\n    /* vol header */\n\n    skip_bits(gb, 1); /* random access */\n\n    s->vo_type= get_bits(gb, 8);\n\n    if (get_bits1(gb) != 0) { /* is_ol_id */\n\n        vo_ver_id = get_bits(gb, 4); /* vo_ver_id */\n\n        skip_bits(gb, 3); /* vo_priority */\n\n    } else {\n\n        vo_ver_id = 1;\n\n    }\n\n//printf(\"vo type:%d\\n\",s->vo_type);\n\n    s->aspect_ratio_info= get_bits(gb, 4);\n\n    if(s->aspect_ratio_info == FF_ASPECT_EXTENDED){\t    \n\n        s->aspected_width = get_bits(gb, 8); // par_width\n\n        s->aspected_height = get_bits(gb, 8); // par_height\n\n    }else{\n\n        s->aspected_width = pixel_aspect[s->aspect_ratio_info][0];\n\n        s->aspected_height= pixel_aspect[s->aspect_ratio_info][1];\n\n    }\n\n\n\n    if ((s->vol_control_parameters=get_bits1(gb))) { /* vol control parameter */\n\n        int chroma_format= get_bits(gb, 2);\n\n        if(chroma_format!=1){\n\n            printf(\"illegal chroma format\\n\");\n\n        }\n\n        s->low_delay= get_bits1(gb);\n\n        if(get_bits1(gb)){ /* vbv parameters */\n\n            get_bits(gb, 15);\t/* first_half_bitrate */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 15);\t/* latter_half_bitrate */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 15);\t/* first_half_vbv_buffer_size */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 3);\t/* latter_half_vbv_buffer_size */\n\n            get_bits(gb, 11);\t/* first_half_vbv_occupancy */\n\n            skip_bits1(gb);\t/* marker */\n\n            get_bits(gb, 15);\t/* latter_half_vbv_occupancy */\n\n            skip_bits1(gb);\t/* marker */               \n\n        }\n\n    }else{\n\n        // set low delay flag only once so the smart? low delay detection wont be overriden\n\n        if(s->picture_number==0)\n\n            s->low_delay=0;\n\n    }\n\n\n\n    s->shape = get_bits(gb, 2); /* vol shape */\n\n    if(s->shape != RECT_SHAPE) printf(\"only rectangular vol supported\\n\");\n\n    if(s->shape == GRAY_SHAPE && vo_ver_id != 1){\n\n        printf(\"Gray shape not supported\\n\");\n\n        skip_bits(gb, 4);  //video_object_layer_shape_extension\n\n    }\n\n\n\n    skip_bits1(gb);   /* marker */\n\n    \n\n    s->time_increment_resolution = get_bits(gb, 16);\n\n    \n\n    s->time_increment_bits = av_log2(s->time_increment_resolution - 1) + 1;\n\n    if (s->time_increment_bits < 1)\n\n        s->time_increment_bits = 1;\n\n    skip_bits1(gb);   /* marker */\n\n\n\n    if (get_bits1(gb) != 0) {   /* fixed_vop_rate  */\n\n        skip_bits(gb, s->time_increment_bits);\n\n    }\n\n\n\n    if (s->shape != BIN_ONLY_SHAPE) {\n\n        if (s->shape == RECT_SHAPE) {\n\n            skip_bits1(gb);   /* marker */\n\n            width = get_bits(gb, 13);\n\n            skip_bits1(gb);   /* marker */\n\n            height = get_bits(gb, 13);\n\n            skip_bits1(gb);   /* marker */\n\n            if(width && height){ /* they should be non zero but who knows ... */\n\n                s->width = width;\n\n                s->height = height;\n\n//                printf(\"width/height: %d %d\\n\", width, height);\n\n            }\n\n        }\n\n        \n\n        s->progressive_sequence= get_bits1(gb)^1;\n\n        if(!get_bits1(gb)) printf(\"OBMC not supported (very likely buggy encoder)\\n\");   /* OBMC Disable */\n\n        if (vo_ver_id == 1) {\n\n            s->vol_sprite_usage = get_bits1(gb); /* vol_sprite_usage */\n\n        } else {\n\n            s->vol_sprite_usage = get_bits(gb, 2); /* vol_sprite_usage */\n\n        }\n\n        if(s->vol_sprite_usage==STATIC_SPRITE) printf(\"Static Sprites not supported\\n\");\n\n        if(s->vol_sprite_usage==STATIC_SPRITE || s->vol_sprite_usage==GMC_SPRITE){\n\n            if(s->vol_sprite_usage==STATIC_SPRITE){\n\n                s->sprite_width = get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n                s->sprite_height= get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n                s->sprite_left  = get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n                s->sprite_top   = get_bits(gb, 13);\n\n                skip_bits1(gb); /* marker */\n\n            }\n\n            s->num_sprite_warping_points= get_bits(gb, 6);\n\n            s->sprite_warping_accuracy = get_bits(gb, 2);\n\n            s->sprite_brightness_change= get_bits1(gb);\n\n            if(s->vol_sprite_usage==STATIC_SPRITE)\n\n                s->low_latency_sprite= get_bits1(gb);            \n\n        }\n\n        // FIXME sadct disable bit if verid!=1 && shape not rect\n\n        \n\n        if (get_bits1(gb) == 1) {   /* not_8_bit */\n\n            s->quant_precision = get_bits(gb, 4); /* quant_precision */\n\n            if(get_bits(gb, 4)!=8) printf(\"N-bit not supported\\n\"); /* bits_per_pixel */\n\n            if(s->quant_precision!=5) printf(\"quant precission %d\\n\", s->quant_precision);\n\n        } else {\n\n            s->quant_precision = 5;\n\n        }\n\n        \n\n        // FIXME a bunch of grayscale shape things\n\n\n\n        if((s->mpeg_quant=get_bits1(gb))){ /* vol_quant_type */\n\n            int i, v;\n\n            \n\n            /* load default matrixes */\n\n            for(i=0; i<64; i++){\n\n                int j= s->dsp.idct_permutation[i];\n\n                v= ff_mpeg4_default_intra_matrix[i];\n\n                s->intra_matrix[j]= v;\n\n                s->chroma_intra_matrix[j]= v;\n\n                \n\n                v= ff_mpeg4_default_non_intra_matrix[i];\n\n                s->inter_matrix[j]= v;\n\n                s->chroma_inter_matrix[j]= v;\n\n            }\n\n\n\n            /* load custom intra matrix */\n\n            if(get_bits1(gb)){\n\n                int last=0;\n\n\t\tfor(i=0; i<64; i++){\n\n                    int j;\n\n                    v= get_bits(gb, 8);\n\n                    if(v==0) break;\n\n                    \n\n                    last= v;\n\n                    j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->intra_matrix[j]= v;\n\n                    s->chroma_intra_matrix[j]= v;\n\n                }\n\n\n\n                /* replicate last value */\n\n                for(; i<64; i++){\n\n\t\t    int j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->intra_matrix[j]= v;\n\n                    s->chroma_intra_matrix[j]= v;\n\n                }\n\n            }\n\n\n\n            /* load custom non intra matrix */\n\n            if(get_bits1(gb)){\n\n                int last=0;\n\n\t\tfor(i=0; i<64; i++){\n\n                    int j;\n\n                    v= get_bits(gb, 8);\n\n                    if(v==0) break;\n\n\n\n                    last= v;\n\n                    j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->inter_matrix[j]= v;\n\n                    s->chroma_inter_matrix[j]= v;\n\n                }\n\n\n\n                /* replicate last value */\n\n                for(; i<64; i++){\n\n\t\t    int j= s->dsp.idct_permutation[ ff_zigzag_direct[i] ];\n\n                    s->inter_matrix[j]= last;\n\n                    s->chroma_inter_matrix[j]= last;\n\n                }\n\n            }\n\n\n\n            // FIXME a bunch of grayscale shape things\n\n        }\n\n\n\n        if(vo_ver_id != 1)\n\n             s->quarter_sample= get_bits1(gb);\n\n        else s->quarter_sample=0;\n\n\n\n        if(!get_bits1(gb)) printf(\"Complexity estimation not supported\\n\");\n\n\n\n        s->resync_marker= !get_bits1(gb); /* resync_marker_disabled */\n\n\n\n        s->data_partitioning= get_bits1(gb);\n\n        if(s->data_partitioning){\n\n            s->rvlc= get_bits1(gb);\n\n            if(s->rvlc){\n\n                printf(\"reversible vlc not supported\\n\");\n\n            }\n\n        }\n\n        \n\n        if(vo_ver_id != 1) {\n\n            s->new_pred= get_bits1(gb);\n\n            if(s->new_pred){\n\n                printf(\"new pred not supported\\n\");\n\n                skip_bits(gb, 2); /* requested upstream message type */\n\n                skip_bits1(gb); /* newpred segment type */\n\n            }\n\n            s->reduced_res_vop= get_bits1(gb);\n\n            if(s->reduced_res_vop) printf(\"reduced resolution VOP not supported\\n\");\n\n        }\n\n        else{\n\n            s->new_pred=0;\n\n            s->reduced_res_vop= 0;\n\n        }\n\n\n\n        s->scalability= get_bits1(gb);\n\n\n\n        if (s->scalability) {\n\n            GetBitContext bak= *gb;\n\n            int ref_layer_id;\n\n            int ref_layer_sampling_dir;\n\n            int h_sampling_factor_n;\n\n            int h_sampling_factor_m;\n\n            int v_sampling_factor_n;\n\n            int v_sampling_factor_m;\n\n            \n\n            s->hierachy_type= get_bits1(gb);\n\n            ref_layer_id= get_bits(gb, 4);\n\n            ref_layer_sampling_dir= get_bits1(gb);\n\n            h_sampling_factor_n= get_bits(gb, 5);\n\n            h_sampling_factor_m= get_bits(gb, 5);\n\n            v_sampling_factor_n= get_bits(gb, 5);\n\n            v_sampling_factor_m= get_bits(gb, 5);\n\n            s->enhancement_type= get_bits1(gb);\n\n            \n\n            if(   h_sampling_factor_n==0 || h_sampling_factor_m==0 \n\n               || v_sampling_factor_n==0 || v_sampling_factor_m==0){\n\n               \n\n//                fprintf(stderr, \"illegal scalability header (VERY broken encoder), trying to workaround\\n\");\n\n                s->scalability=0;\n\n               \n\n                *gb= bak;\n\n            }else\n\n                printf(\"scalability not supported\\n\");\n\n            \n\n            // bin shape stuff FIXME\n\n        }\n\n    }\n\n    return 0;\n\n}\n", "idx": 27201, "_split": "test", "_hash": "9f6a78a894dd11ac99dfe6b9f7ded7c7"}
{"project": "FFmpeg", "commit_id": "155ec6edf82692bcf3a5f87d2bc697404f4e5aaf", "target": 0, "func": "void ff_init_me(MpegEncContext *s){\n\n    MotionEstContext * const c= &s->me;\n\n    c->avctx= s->avctx;\n\n\n\n    ff_set_cmp(&s->dsp, s->dsp.me_pre_cmp, c->avctx->me_pre_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.me_cmp, c->avctx->me_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.me_sub_cmp, c->avctx->me_sub_cmp);\n\n    ff_set_cmp(&s->dsp, s->dsp.mb_cmp, c->avctx->mb_cmp);\n\n    \n\n    c->flags    = get_flags(c, 0, c->avctx->me_cmp    &FF_CMP_CHROMA);\n\n    c->sub_flags= get_flags(c, 0, c->avctx->me_sub_cmp&FF_CMP_CHROMA);\n\n    c->mb_flags = get_flags(c, 0, c->avctx->mb_cmp    &FF_CMP_CHROMA);\n\n\n\n/*FIXME s->no_rounding b_type*/\n\n    if(s->flags&CODEC_FLAG_QPEL){\n\n        c->sub_motion_search= qpel_motion_search;\n\n        c->qpel_avg= s->dsp.avg_qpel_pixels_tab;\n\n        if(s->no_rounding) c->qpel_put= s->dsp.put_no_rnd_qpel_pixels_tab;\n\n        else               c->qpel_put= s->dsp.put_qpel_pixels_tab;\n\n    }else{\n\n        if(c->avctx->me_sub_cmp&FF_CMP_CHROMA)\n\n            c->sub_motion_search= hpel_motion_search;\n\n        else if(   c->avctx->me_sub_cmp == FF_CMP_SAD \n\n                && c->avctx->    me_cmp == FF_CMP_SAD \n\n                && c->avctx->    mb_cmp == FF_CMP_SAD)\n\n            c->sub_motion_search= sad_hpel_motion_search; // 2050 vs. 2450 cycles\n\n        else\n\n            c->sub_motion_search= hpel_motion_search;\n\n    }\n\n    c->hpel_avg= s->dsp.avg_pixels_tab;\n\n    if(s->no_rounding) c->hpel_put= s->dsp.put_no_rnd_pixels_tab;\n\n    else               c->hpel_put= s->dsp.put_pixels_tab;\n\n\n\n    if(s->linesize){\n\n        c->stride  = s->linesize; \n\n        c->uvstride= s->uvlinesize;\n\n    }else{\n\n        c->stride  = 16*s->mb_width + 32;\n\n        c->uvstride=  8*s->mb_width + 16;\n\n    }\n\n\n\n    // 8x8 fullpel search would need a 4x4 chroma compare, which we dont have yet, and even if we had the motion estimation code doesnt expect it\n\n    if((c->avctx->me_cmp&FF_CMP_CHROMA) && !s->dsp.me_cmp[2]){\n\n        s->dsp.me_cmp[2]= zero_cmp;\n\n    }\n\n    if((c->avctx->me_sub_cmp&FF_CMP_CHROMA) && !s->dsp.me_sub_cmp[2]){\n\n        s->dsp.me_sub_cmp[2]= zero_cmp;\n\n    }\n\n    c->hpel_put[2][0]= c->hpel_put[2][1]=\n\n    c->hpel_put[2][2]= c->hpel_put[2][3]= zero_hpel;\n\n\n\n    c->temp= c->scratchpad;\n\n}\n", "idx": 27203, "_split": "test", "_hash": "b3abcbef32fb6026c011b15a670c8188"}
{"project": "FFmpeg", "commit_id": "afa982fdae1b49a8aee00a27da876bba10ba1073", "target": 1, "func": "static void filter(MpegAudioContext *s, int ch, short *samples, int incr)\n\n{\n\n    short *p, *q;\n\n    int sum, offset, i, j, norm, n;\n\n    short tmp[64];\n\n    int tmp1[32];\n\n    int *out;\n\n\n\n    //    print_pow1(samples, 1152);\n\n\n\n    offset = s->samples_offset[ch];\n\n    out = &s->sb_samples[ch][0][0][0];\n\n    for(j=0;j<36;j++) {\n\n        /* 32 samples at once */\n\n        for(i=0;i<32;i++) {\n\n            s->samples_buf[ch][offset + (31 - i)] = samples[0];\n\n            samples += incr;\n\n        }\n\n\n\n        /* filter */\n\n        p = s->samples_buf[ch] + offset;\n\n        q = filter_bank;\n\n        /* maxsum = 23169 */\n\n        for(i=0;i<64;i++) {\n\n            sum = p[0*64] * q[0*64];\n\n            sum += p[1*64] * q[1*64];\n\n            sum += p[2*64] * q[2*64];\n\n            sum += p[3*64] * q[3*64];\n\n            sum += p[4*64] * q[4*64];\n\n            sum += p[5*64] * q[5*64];\n\n            sum += p[6*64] * q[6*64];\n\n            sum += p[7*64] * q[7*64];\n\n            tmp[i] = sum >> 14;\n\n            p++;\n\n            q++;\n\n        }\n\n        tmp1[0] = tmp[16];\n\n        for( i=1; i<=16; i++ ) tmp1[i] = tmp[i+16]+tmp[16-i];\n\n        for( i=17; i<=31; i++ ) tmp1[i] = tmp[i+16]-tmp[80-i];\n\n\n\n        /* integer IDCT 32 with normalization. XXX: There may be some\n\n           overflow left */\n\n        norm = 0;\n\n        for(i=0;i<32;i++) {\n\n            norm |= abs(tmp1[i]);\n\n        }\n\n        n = av_log2(norm) - 12;\n\n        if (n > 0) {\n\n            for(i=0;i<32;i++) \n\n                tmp1[i] >>= n;\n\n        } else {\n\n            n = 0;\n\n        }\n\n\n\n        idct32(out, tmp1, s->sblimit, n);\n\n\n\n        /* advance of 32 samples */\n\n        offset -= 32;\n\n        out += 32;\n\n        /* handle the wrap around */\n\n        if (offset < 0) {\n\n            memmove(s->samples_buf[ch] + SAMPLES_BUF_SIZE - (512 - 32), \n\n                    s->samples_buf[ch], (512 - 32) * 2);\n\n            offset = SAMPLES_BUF_SIZE - 512;\n\n        }\n\n    }\n\n    s->samples_offset[ch] = offset;\n\n\n\n    //    print_pow(s->sb_samples, 1152);\n\n}\n", "idx": 27237, "_split": "test", "_hash": "7857a4a5a1216aa62671d59af9ced5a1"}
{"project": "FFmpeg", "commit_id": "607ad990d31e6be52980970e5ce8cd25ab3de812", "target": 0, "func": "static int dvbsub_decode(AVCodecContext *avctx,\n\n                         void *data, int *data_size,\n\n                         AVPacket *avpkt)\n\n{\n\n    const uint8_t *buf = avpkt->data;\n\n    int buf_size = avpkt->size;\n\n    DVBSubContext *ctx = avctx->priv_data;\n\n    AVSubtitle *sub = data;\n\n    const uint8_t *p, *p_end;\n\n    int segment_type;\n\n    int page_id;\n\n    int segment_length;\n\n    int i;\n\n\n\n    av_dlog(avctx, \"DVB sub packet:\\n\");\n\n\n\n    for (i=0; i < buf_size; i++) {\n\n        av_dlog(avctx, \"%02x \", buf[i]);\n\n        if (i % 16 == 15)\n\n            av_dlog(avctx, \"\\n\");\n\n    }\n\n\n\n    if (i % 16)\n\n        av_dlog(avctx, \"\\n\");\n\n\n\n    if (buf_size <= 6 || *buf != 0x0f) {\n\n        av_dlog(avctx, \"incomplete or broken packet\");\n\n        return -1;\n\n    }\n\n\n\n    p = buf;\n\n    p_end = buf + buf_size;\n\n\n\n    while (p_end - p >= 6 && *p == 0x0f) {\n\n        p += 1;\n\n        segment_type = *p++;\n\n        page_id = AV_RB16(p);\n\n        p += 2;\n\n        segment_length = AV_RB16(p);\n\n        p += 2;\n\n\n\n        if (p_end - p < segment_length) {\n\n            av_dlog(avctx, \"incomplete or broken packet\");\n\n            return -1;\n\n        }\n\n\n\n        if (page_id == ctx->composition_id || page_id == ctx->ancillary_id ||\n\n            ctx->composition_id == -1 || ctx->ancillary_id == -1) {\n\n            switch (segment_type) {\n\n            case DVBSUB_PAGE_SEGMENT:\n\n                dvbsub_parse_page_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_REGION_SEGMENT:\n\n                dvbsub_parse_region_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_CLUT_SEGMENT:\n\n                dvbsub_parse_clut_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_OBJECT_SEGMENT:\n\n                dvbsub_parse_object_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_DISPLAYDEFINITION_SEGMENT:\n\n                dvbsub_parse_display_definition_segment(avctx, p, segment_length);\n\n                break;\n\n            case DVBSUB_DISPLAY_SEGMENT:\n\n                *data_size = dvbsub_display_end_segment(avctx, p, segment_length, sub);\n\n                break;\n\n            default:\n\n                av_dlog(avctx, \"Subtitling segment type 0x%x, page id %d, length %d\\n\",\n\n                        segment_type, page_id, segment_length);\n\n                break;\n\n            }\n\n        }\n\n\n\n        p += segment_length;\n\n    }\n\n\n\n    return p - buf;\n\n}\n", "idx": 27261, "_split": "test", "_hash": "22f2db52d5131c9449a2f984f38f7ae3"}
{"project": "FFmpeg", "commit_id": "3a25c707fae3c6e99fdda40474c3d74be24cc4c3", "target": 0, "func": "static int mov_read_trak(MOVContext *c, ByteIOContext *pb, MOV_atom_t atom)\n\n{\n\n    AVStream *st;\n\n    MOVStreamContext *sc;\n\n    int ret;\n\n\n\n    st = av_new_stream(c->fc, c->fc->nb_streams);\n\n    if (!st) return AVERROR(ENOMEM);\n\n    sc = av_mallocz(sizeof(MOVStreamContext));\n\n    if (!sc) return AVERROR(ENOMEM);\n\n\n\n    st->priv_data = sc;\n\n    st->codec->codec_type = CODEC_TYPE_DATA;\n\n    st->start_time = 0; /* XXX: check */\n\n\n\n    if ((ret = mov_read_default(c, pb, atom)) < 0)\n\n        return ret;\n\n\n\n    /* sanity checks */\n\n    if(sc->chunk_count && (!sc->stts_count || !sc->sample_to_chunk_sz ||\n\n                           (!sc->sample_size && !sc->sample_count))){\n\n        av_log(c->fc, AV_LOG_ERROR, \"stream %d, missing mandatory atoms, broken header\\n\",\n\n               st->index);\n\n        sc->sample_count = 0; //ignore track\n\n        return 0;\n\n    }\n\n    if(!sc->time_rate)\n\n        sc->time_rate=1;\n\n    if(!sc->time_scale)\n\n        sc->time_scale= c->time_scale;\n\n    av_set_pts_info(st, 64, sc->time_rate, sc->time_scale);\n\n\n\n    if (st->codec->codec_type == CODEC_TYPE_AUDIO &&\n\n        !st->codec->frame_size && sc->stts_count == 1)\n\n        st->codec->frame_size = av_rescale(sc->time_rate, st->codec->sample_rate, sc->time_scale);\n\n\n\n    if(st->duration != AV_NOPTS_VALUE){\n\n        assert(st->duration % sc->time_rate == 0);\n\n        st->duration /= sc->time_rate;\n\n    }\n\n    sc->ffindex = st->index;\n\n    mov_build_index(c, st);\n\n\n\n    if (sc->dref_id-1 < sc->drefs_count && sc->drefs[sc->dref_id-1].path) {\n\n        if (url_fopen(&sc->pb, sc->drefs[sc->dref_id-1].path, URL_RDONLY) < 0)\n\n            av_log(c->fc, AV_LOG_ERROR, \"stream %d, error opening file %s: %s\\n\",\n\n                   st->index, sc->drefs[sc->dref_id-1].path, strerror(errno));\n\n    } else\n\n        sc->pb = c->fc->pb;\n\n\n\n    switch (st->codec->codec_id) {\n\n#ifdef CONFIG_H261_DECODER\n\n    case CODEC_ID_H261:\n\n#endif\n\n#ifdef CONFIG_H263_DECODER\n\n    case CODEC_ID_H263:\n\n#endif\n\n#ifdef CONFIG_MPEG4_DECODER\n\n    case CODEC_ID_MPEG4:\n\n#endif\n\n        st->codec->width= 0; /* let decoder init width/height */\n\n        st->codec->height= 0;\n\n        break;\n\n#ifdef CONFIG_VORBIS_DECODER\n\n    case CODEC_ID_VORBIS:\n\n#endif\n\n        st->codec->sample_rate= 0; /* let decoder init parameters properly */\n\n        break;\n\n    }\n\n\n\n    /* Do not need those anymore. */\n\n    av_freep(&sc->chunk_offsets);\n\n    av_freep(&sc->sample_to_chunk);\n\n    av_freep(&sc->sample_sizes);\n\n    av_freep(&sc->keyframes);\n\n    av_freep(&sc->stts_data);\n\n\n\n    return 0;\n\n}\n", "idx": 27272, "_split": "test", "_hash": "b3e26c290cdecd47d70e1d392703407d"}
{"project": "FFmpeg", "commit_id": "d6604b29ef544793479d7fb4e05ef6622bb3e534", "target": 0, "func": "static av_cold int libschroedinger_encode_init(AVCodecContext *avctx)\n\n{\n\n    SchroEncoderParams *p_schro_params = avctx->priv_data;\n\n    SchroVideoFormatEnum preset;\n\n\n\n    /* Initialize the libraries that libschroedinger depends on. */\n\n    schro_init();\n\n\n\n    /* Create an encoder object. */\n\n    p_schro_params->encoder = schro_encoder_new();\n\n\n\n    if (!p_schro_params->encoder) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"Unrecoverable Error: schro_encoder_new failed. \");\n\n        return -1;\n\n    }\n\n\n\n    /* Initialize the format. */\n\n    preset = ff_get_schro_video_format_preset(avctx);\n\n    p_schro_params->format =\n\n                    schro_encoder_get_video_format(p_schro_params->encoder);\n\n    schro_video_format_set_std_video_format(p_schro_params->format, preset);\n\n    p_schro_params->format->width  = avctx->width;\n\n    p_schro_params->format->height = avctx->height;\n\n\n\n    if (set_chroma_format(avctx) == -1)\n\n        return -1;\n\n\n\n    if (avctx->color_primaries == AVCOL_PRI_BT709) {\n\n        p_schro_params->format->colour_primaries = SCHRO_COLOUR_PRIMARY_HDTV;\n\n    } else if (avctx->color_primaries == AVCOL_PRI_BT470BG) {\n\n        p_schro_params->format->colour_primaries = SCHRO_COLOUR_PRIMARY_SDTV_625;\n\n    } else if (avctx->color_primaries == AVCOL_PRI_SMPTE170M) {\n\n        p_schro_params->format->colour_primaries = SCHRO_COLOUR_PRIMARY_SDTV_525;\n\n    }\n\n\n\n    if (avctx->colorspace == AVCOL_SPC_BT709) {\n\n        p_schro_params->format->colour_matrix = SCHRO_COLOUR_MATRIX_HDTV;\n\n    } else if (avctx->colorspace == AVCOL_SPC_BT470BG) {\n\n        p_schro_params->format->colour_matrix = SCHRO_COLOUR_MATRIX_SDTV;\n\n    }\n\n\n\n    if (avctx->color_trc == AVCOL_TRC_BT709) {\n\n        p_schro_params->format->transfer_function = SCHRO_TRANSFER_CHAR_TV_GAMMA;\n\n    }\n\n\n\n    if (ff_get_schro_frame_format(p_schro_params->format->chroma_format,\n\n                                  &p_schro_params->frame_format) == -1) {\n\n        av_log(avctx, AV_LOG_ERROR,\n\n               \"This codec currently supports only planar YUV 4:2:0, 4:2:2\"\n\n               \" and 4:4:4 formats.\\n\");\n\n        return -1;\n\n    }\n\n\n\n    p_schro_params->format->frame_rate_numerator   = avctx->time_base.den;\n\n    p_schro_params->format->frame_rate_denominator = avctx->time_base.num;\n\n\n\n    p_schro_params->frame_size = avpicture_get_size(avctx->pix_fmt,\n\n                                                    avctx->width,\n\n                                                    avctx->height);\n\n\n\n    avctx->coded_frame = av_frame_alloc();\n\n    if (!avctx->coded_frame)\n\n        return AVERROR(ENOMEM);\n\n\n\n    if (!avctx->gop_size) {\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"gop_structure\",\n\n                                         SCHRO_ENCODER_GOP_INTRA_ONLY);\n\n\n\n        if (avctx->coder_type == FF_CODER_TYPE_VLC)\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"enable_noarith\", 1);\n\n    } else {\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"au_distance\", avctx->gop_size);\n\n        avctx->has_b_frames = 1;\n\n        p_schro_params->dts = -1;\n\n    }\n\n\n\n    /* FIXME - Need to handle SCHRO_ENCODER_RATE_CONTROL_LOW_DELAY. */\n\n    if (avctx->flags & CODEC_FLAG_QSCALE) {\n\n        if (!avctx->global_quality) {\n\n            /* lossless coding */\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"rate_control\",\n\n                                             SCHRO_ENCODER_RATE_CONTROL_LOSSLESS);\n\n        } else {\n\n            int quality;\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"rate_control\",\n\n                                             SCHRO_ENCODER_RATE_CONTROL_CONSTANT_QUALITY);\n\n\n\n            quality = avctx->global_quality / FF_QP2LAMBDA;\n\n            if (quality > 10)\n\n                quality = 10;\n\n            schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                             \"quality\", quality);\n\n        }\n\n    } else {\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"rate_control\",\n\n                                         SCHRO_ENCODER_RATE_CONTROL_CONSTANT_BITRATE);\n\n\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"bitrate\", avctx->bit_rate);\n\n    }\n\n\n\n    if (avctx->flags & CODEC_FLAG_INTERLACED_ME)\n\n        /* All material can be coded as interlaced or progressive\n\n           irrespective of the type of source material. */\n\n        schro_encoder_setting_set_double(p_schro_params->encoder,\n\n                                         \"interlaced_coding\", 1);\n\n\n\n    schro_encoder_setting_set_double(p_schro_params->encoder, \"open_gop\",\n\n                                     !(avctx->flags & CODEC_FLAG_CLOSED_GOP));\n\n\n\n    /* FIXME: Signal range hardcoded to 8-bit data until both libschroedinger\n\n     * and libdirac support other bit-depth data. */\n\n    schro_video_format_set_std_signal_range(p_schro_params->format,\n\n                                            SCHRO_SIGNAL_RANGE_8BIT_VIDEO);\n\n\n\n    /* Set the encoder format. */\n\n    schro_encoder_set_video_format(p_schro_params->encoder,\n\n                                   p_schro_params->format);\n\n\n\n    /* Set the debug level. */\n\n    schro_debug_set_level(avctx->debug);\n\n\n\n    schro_encoder_start(p_schro_params->encoder);\n\n\n\n    /* Initialize the encoded frame queue. */\n\n    ff_schro_queue_init(&p_schro_params->enc_frame_queue);\n\n    return 0;\n\n}\n", "idx": 27296, "_split": "test", "_hash": "2e7cbc736c8b5b97734db3fbc8dbe2c2"}
{"project": "FFmpeg", "commit_id": "7104c23bd1a1dcb8a7d9e2c8838c7ce55c30a331", "target": 0, "func": "static void rv34_pred_mv(RV34DecContext *r, int block_type, int subblock_no, int dmv_no)\n\n{\n\n    MpegEncContext *s = &r->s;\n\n    int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride;\n\n    int A[2] = {0}, B[2], C[2];\n\n    int i, j;\n\n    int mx, my;\n\n    int avail_index = avail_indexes[subblock_no];\n\n    int c_off = part_sizes_w[block_type];\n\n\n\n    mv_pos += (subblock_no & 1) + (subblock_no >> 1)*s->b8_stride;\n\n    if(subblock_no == 3)\n\n        c_off = -1;\n\n\n\n    if(r->avail_cache[avail_index - 1]){\n\n        A[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-1][0];\n\n        A[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-1][1];\n\n    }\n\n    if(r->avail_cache[avail_index - 4]){\n\n        B[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride][0];\n\n        B[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride][1];\n\n    }else{\n\n        B[0] = A[0];\n\n        B[1] = A[1];\n\n    }\n\n    if(!r->avail_cache[avail_index - 4 + c_off]){\n\n        if(r->avail_cache[avail_index - 4] && (r->avail_cache[avail_index - 1] || r->rv30)){\n\n            C[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride-1][0];\n\n            C[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride-1][1];\n\n        }else{\n\n            C[0] = A[0];\n\n            C[1] = A[1];\n\n        }\n\n    }else{\n\n        C[0] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride+c_off][0];\n\n        C[1] = s->current_picture_ptr->f.motion_val[0][mv_pos-s->b8_stride+c_off][1];\n\n    }\n\n    mx = mid_pred(A[0], B[0], C[0]);\n\n    my = mid_pred(A[1], B[1], C[1]);\n\n    mx += r->dmv[dmv_no][0];\n\n    my += r->dmv[dmv_no][1];\n\n    for(j = 0; j < part_sizes_h[block_type]; j++){\n\n        for(i = 0; i < part_sizes_w[block_type]; i++){\n\n            s->current_picture_ptr->f.motion_val[0][mv_pos + i + j*s->b8_stride][0] = mx;\n\n            s->current_picture_ptr->f.motion_val[0][mv_pos + i + j*s->b8_stride][1] = my;\n\n        }\n\n    }\n\n}\n", "idx": 27317, "_split": "test", "_hash": "f83972c687e36af2801462f5345b90f2"}
