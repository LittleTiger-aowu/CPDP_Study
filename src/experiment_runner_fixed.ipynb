{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eae2689",
   "metadata": {},
   "source": [
    "\n",
    "# 🔬 Experiment Runner (DANN / CodeBERT) — One-Click Notebook (Fixed)\n",
    "\n",
    "- Edit the **experiments** list to register many configs.\n",
    "- Run `run_all()` to execute all, or `run_experiment(experiments[i])` to run one.\n",
    "- Full logs go to `runs_logs/` with timestamps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29335cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, json, datetime, subprocess, shlex\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any\n",
    "import pandas as pd\n",
    "\n",
    "# Project paths (edit if needed)\n",
    "PROJECT_ROOT = Path(r\"E:\\project\\WYP\\CPDP\\CrossProjectDefectPrediction\\src\").resolve()\n",
    "TRAINER_DIR = PROJECT_ROOT / \"trainers\"\n",
    "LOG_DIR = PROJECT_ROOT / \"runs_logs\"\n",
    "LOG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use current interpreter by default\n",
    "PYTHON_EXE = sys.executable\n",
    "print(f\"[Info] Python: {PYTHON_EXE}\")\n",
    "print(f\"[Info] Trainers dir: {TRAINER_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "37e06301",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "\n",
    "from pathlib import Path\n",
    "def build_cmd(\n",
    "    train_script: str,\n",
    "    train_jsonl: str,\n",
    "    valid_jsonl: str,\n",
    "    test_jsonl: Optional[str],\n",
    "    epochs: int,\n",
    "    max_length: int,\n",
    "    train_batch: int,\n",
    "    domain_batch: int,\n",
    "    accum_steps: int,\n",
    "    bf16: int,\n",
    "    bucket_sampler: int,\n",
    "    num_workers: int,\n",
    "    prefetch: int,\n",
    "    seed: int,\n",
    "    val_size: float,\n",
    "    early_stop_patience: int,\n",
    "    label_smoothing: float,\n",
    "    clip_norm: float,\n",
    "    balance_source: int,\n",
    "    dann_warmup_epochs: int,\n",
    "    codebert: str,\n",
    "    lora: int,\n",
    "    lora_r: int,\n",
    "    lora_alpha: int,\n",
    "    lora_dropout: float,\n",
    "    lora_target: str,\n",
    "    lr_head: float,\n",
    "    lr_lora: float,\n",
    "    assume_java_if_missing: int,\n",
    "    lang_filter: str = \"\",\n",
    "    tag: str = \"\",\n",
    ") -> list:\n",
    "    \"\"\"Build the exact training command (no shell). Conditionally appends --test-jsonl if file exists.\"\"\"\n",
    "    test_path = Path(test_jsonl) if test_jsonl else None\n",
    "    has_test = bool(test_path) and test_path.exists()\n",
    "\n",
    "    cmd = [\n",
    "        PYTHON_EXE, train_script,\n",
    "        \"--train-jsonl\", train_jsonl,\n",
    "        \"--valid-jsonl\", valid_jsonl,\n",
    "        \"--epochs\", str(epochs),\n",
    "        \"--max-length\", str(max_length),\n",
    "        \"--train-batch\", str(train_batch),\n",
    "        \"--domain-batch\", str(domain_batch),\n",
    "        \"--accum-steps\", str(accum_steps),\n",
    "        \"--bf16\", str(bf16),\n",
    "        \"--bucket-sampler\", str(bucket_sampler),\n",
    "        \"--num-workers\", str(num_workers),\n",
    "        \"--prefetch\", str(prefetch),\n",
    "        \"--seed\", str(seed),\n",
    "        \"--val-size\", str(val_size),\n",
    "        \"--early-stop-patience\", str(early_stop_patience),\n",
    "        \"--label-smoothing\", str(label_smoothing),\n",
    "        \"--clip-norm\", str(clip_norm),\n",
    "        \"--balance-source\", str(balance_source),\n",
    "        \"--dann-warmup-epochs\", str(dann_warmup_epochs),\n",
    "        \"--codebert\", codebert,\n",
    "        \"--lora\", str(lora),\n",
    "        \"--lora-r\", str(lora_r),\n",
    "        \"--lora-alpha\", str(lora_alpha),\n",
    "        \"--lora-dropout\", str(lora_dropout),\n",
    "        \"--lora-target\", lora_target,\n",
    "        \"--lr-head\", str(lr_head),\n",
    "        \"--lr-lora\", str(lr_lora),\n",
    "        \"--assume-java-if-missing\", str(assume_java_if_missing),\n",
    "    ]\n",
    "    if has_test:\n",
    "        cmd += [\"--test-jsonl\", str(test_path)]\n",
    "    if lang_filter.strip():\n",
    "        cmd += [\"--lang-filter\", lang_filter]\n",
    "    if tag:\n",
    "        cmd += [\"--tag\", tag]\n",
    "    return cmd\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f053090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_and_tee(cmd: list, log_dir: Path = LOG_DIR) -> Path:\n",
    "    \"\"\"Run a command, stream output here, and save all stdout/stderr to a timestamped log.\"\"\"\n",
    "    ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    base = f\"{ts}_{Path(cmd[1]).stem}\"\n",
    "    log_path = Path(log_dir) / f\"{base}.log\"\n",
    "    Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    env = os.environ.copy()\n",
    "    env.setdefault(\"PYTHONIOENCODING\", \"utf-8\")\n",
    "    env.setdefault(\"PYTHONUTF8\", \"1\")\n",
    "    env.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "    env.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "    printable = \" \".join([shlex.quote(str(c)) if \" \" in str(c) else str(c) for c in cmd])\n",
    "    print(\"[CMD]\", printable)\n",
    "    print(f\"[Log] -> {log_path}\")\n",
    "\n",
    "    with open(log_path, \"wb\") as logf:\n",
    "        logf.write((\"[CMD] \" + printable + \"\\n\").encode(\"utf-8\"))\n",
    "        proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, cwd=str(TRAINER_DIR), bufsize=0, env=env)\n",
    "        assert proc.stdout is not None\n",
    "        for raw in iter(proc.stdout.readline, b\"\"):\n",
    "            if not raw:\n",
    "                break\n",
    "            logf.write(raw); logf.flush()\n",
    "            try:\n",
    "                text = raw.decode(\"utf-8\")\n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    text = raw.decode(\"gbk\")\n",
    "                except UnicodeDecodeError:\n",
    "                    text = raw.decode(\"utf-8\", errors=\"replace\")\n",
    "            print(text, end=\"\")\n",
    "        proc.wait()\n",
    "        if proc.returncode != 0:\n",
    "            raise RuntimeError(f\"Process exited with code {proc.returncode}. See log: {log_path}\")\n",
    "    return log_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Edit your experiments here ====\n",
    "experiments = [\n",
    "    {\n",
    "        \"train_script\": \"train_dann_jsonl.py\",\n",
    "        \"train_jsonl\": r\"E:\\project\\WYP\\CPDP\\CrossProjectDefectPrediction\\cross_splits\\T_FFmpeg\\train.jsonl\",\n",
    "        \"valid_jsonl\": r\"E:\\project\\WYP\\CPDP\\CrossProjectDefectPrediction\\cross_splits\\T_FFmpeg\\valid_tgt_unlabeled.jsonl\",\n",
    "        \"test_jsonl\":  r\"E:\\project\\WYP\\CPDP\\CrossProjectDefectPrediction\\cross_splits\\T_FFmpeg\\test_tgt.jsonl\",\n",
    "        \"epochs\": 50,\n",
    "        \"max_length\": 384,\n",
    "        \"train_batch\": 32,\n",
    "        \"domain_batch\": 32,\n",
    "        \"accum_steps\": 2,\n",
    "        \"bf16\": 1,\n",
    "        \"bucket_sampler\": 1,\n",
    "        \"num_workers\": 2,\n",
    "        \"prefetch\": 2,\n",
    "        \"seed\": 42,\n",
    "        \"val_size\": 0.2,\n",
    "        \"early_stop_patience\": 12,\n",
    "        \"label_smoothing\": 0.05,\n",
    "        \"clip_norm\": 1.0,\n",
    "        \"balance_source\": 1,\n",
    "        \"dann_warmup_epochs\": 8,\n",
    "        \"codebert\": r\"E:\\project\\WYP\\CPDP\\CodeBert\",\n",
    "        \"lora\": 1,\n",
    "        \"lora_r\": 16,\n",
    "        \"lora_alpha\": 32,\n",
    "        \"lora_dropout\": 0.10,\n",
    "        \"lora_target\": \"query,key,value,dense\",\n",
    "        \"lr_head\": 0.001,\n",
    "        \"lr_lora\": 0.0001,\n",
    "        \"assume_java_if_missing\": 0,\n",
    "        \"lang_filter\": \"\",\n",
    "        \"tag\": \"cross_QEMU_to_FFmpeg_warm8_bs32_acc2\",\n",
    "    },\n",
    "]\n",
    "import pandas as pd\n",
    "pd.DataFrame(experiments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e4dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_experiment(exp: dict) -> Path:\n",
    "    cmd = build_cmd(**exp)\n",
    "    return run_and_tee(cmd)\n",
    "\n",
    "def run_all():\n",
    "    logs = []\n",
    "    for i, exp in enumerate(experiments, 1):\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"[{i}/{len(experiments)}] TAG: {exp.get('tag','')}\")\n",
    "        print(\"=\"*80)\n",
    "        log_path = run_experiment(exp)\n",
    "        logs.append(str(log_path))\n",
    "    return logs\n",
    "\n",
    "print(\"Call run_all() to execute all experiments, or run_experiment(experiments[i]) to run a specific one.\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "# 🚀 WSL + Defects4J + Python(d4j) 环境启动手册\n",
    "\n",
    "> 适用对象：\n",
    ">\n",
    "> * 使用 **WSL (Ubuntu)**\n",
    "> * Defects4J 安装在 `~/defects4j`\n",
    "> * Python 虚拟环境位于 `~/venvs/d4j`\n",
    "> * 用于 **Defects4J 数据构建 / JSONL 生成**\n",
    "\n",
    "---\n",
    "\n",
    "## 一、电脑重启后：完整启动流程（最常用）\n",
    "\n",
    "### ✅ Step 1：启动 WSL（Ubuntu）\n",
    "\n",
    "在 **Windows PowerShell** 或开始菜单中执行：\n",
    "\n",
    "```powershell\n",
    "wsl -d Ubuntu\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 2：确认当前用户（应为 badpopo）\n",
    "\n",
    "```bash\n",
    "whoami\n",
    "```\n",
    "\n",
    "期望输出：\n",
    "\n",
    "```text\n",
    "badpopo\n",
    "```\n",
    "\n",
    "> 如果不是，执行：\n",
    "\n",
    "```bash\n",
    "su - badpopo\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 3：回到 Linux 家目录（非常重要）\n",
    "\n",
    "```bash\n",
    "cd ~\n",
    "pwd\n",
    "```\n",
    "\n",
    "期望输出：\n",
    "\n",
    "```text\n",
    "/home/badpopo\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 4：激活 Python 虚拟环境（核心步骤）\n",
    "\n",
    "```bash\n",
    "source ~/venvs/d4j/bin/activate\n",
    "```\n",
    "\n",
    "激活成功后，命令行前缀应变为：\n",
    "\n",
    "```text\n",
    "(d4j) badpopo@DESKTOP-1LMSQ70:~$\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 5：确认环境状态（可选但推荐）\n",
    "\n",
    "```bash\n",
    "echo $VIRTUAL_ENV\n",
    "which python\n",
    "pip --version\n",
    "```\n",
    "\n",
    "期望类似：\n",
    "\n",
    "```text\n",
    "/home/badpopo/venvs/d4j\n",
    "/home/badpopo/venvs/d4j/bin/python\n",
    "pip ... from /home/badpopo/venvs/d4j/...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 6：设置 UTF-8（建议每次设置）\n",
    "\n",
    "```bash\n",
    "export PYTHONIOENCODING=utf-8\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 7：运行你的 Defects4J 数据脚本\n",
    "\n",
    "```bash\n",
    "python make_d4j_jsonl.py \\\n",
    "  --d4j-root /home/badpopo/defects4j \\\n",
    "  --projects Lang \\\n",
    "  --bugs 1-2 \\\n",
    "  --out-dir /home/badpopo/datasets/d4j_funcs \\\n",
    "  --merge-out /home/badpopo/datasets/d4j_funcs/all.jsonl \\\n",
    "  --workers 8\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 二、常用快捷命令（你以后会高频用）\n",
    "\n",
    "### 🔹 一键进入“可用状态”（推荐记住）\n",
    "\n",
    "```bash\n",
    "cd ~\n",
    "source ~/venvs/d4j/bin/activate\n",
    "export PYTHONIOENCODING=utf-8\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 退出虚拟环境\n",
    "\n",
    "```bash\n",
    "deactivate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 检查 Defects4J 是否正常\n",
    "\n",
    "```bash\n",
    "~/defects4j/framework/bin/defects4j info -p Lang\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 查看生成的数据\n",
    "\n",
    "```bash\n",
    "ls ~/datasets/d4j_funcs\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 三、常见问题 & 快速修复\n",
    "\n",
    "### ❌ 1. 提示 `pip install` 报 externally-managed-environment\n",
    "\n",
    "**原因**：你忘了激活虚拟环境\n",
    "**解决**：\n",
    "\n",
    "```bash\n",
    "source ~/venvs/d4j/bin/activate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ❌ 2. `defects4j: command not found`\n",
    "\n",
    "**原因**：没有走绝对路径\n",
    "**解决（推荐）**：\n",
    "\n",
    "```bash\n",
    "~/defects4j/framework/bin/defects4j info -p Lang\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ❌ 3. 终端显示 `(base)` 或 conda 环境\n",
    "\n",
    "**建议**：不要在同一个项目混用 conda\n",
    "**解决**：\n",
    "\n",
    "```bash\n",
    "conda deactivate\n",
    "source ~/venvs/d4j/bin/activate\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 四、目录结构速览（防止你删错）\n",
    "\n",
    "```text\n",
    "/home/badpopo/\n",
    "├── defects4j/        # Defects4J 本体（不要删）\n",
    "├── venvs/\n",
    "│   └── d4j/          # Python 虚拟环境（不要删）\n",
    "├── datasets/\n",
    "│   └── d4j_funcs/    # 你生成的 JSONL 数据\n",
    "├── work/\n",
    "│   └── d4j/\n",
    "│       └── make_d4j_jsonl.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 五、强烈建议（科研经验总结）\n",
    "\n",
    "> 🔒 **一件事一个虚拟环境**\n",
    "\n",
    "```text\n",
    "venvs/\n",
    "├── d4j      # 数据构建（tree-sitter / javalang）\n",
    "├── cpdp     # 训练（torch / transformers / DANN）\n",
    "```\n",
    "\n",
    "这样你后面 **Debug / 复现实验 / 写论文**都会非常稳。\n",
    "\n",
    "---\n",
    "\n",
    "## 六、你现在已经完成了什么（给你一个定位）\n",
    "\n",
    "你已经完成了：\n",
    "\n",
    "* ✅ WSL 正确用户环境\n",
    "* ✅ Defects4J 正确安装\n",
    "* ✅ Python PEP 668 问题规避\n",
    "* ✅ 可复现的 venv（d4j）\n",
    "\n",
    "👉 **现在你已经完全具备“做 Defects4J 函数级缺陷预测实验”的硬条件**\n",
    "\n"
   ],
   "id": "22bf8d35bedac982"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c245f2750674c10"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "明白了 👍\n",
    "**是的，这整段代码就是你现在正在用、而且已经被你成功验证过（Lang-1）的最终脚本版本。**\n",
    "它**已经具备“导出 Defects4J 所有项目数据”的能力**，不需要再改代码了——接下来要做的只是**如何正确、大规模地“跑它”**。\n",
    "\n",
    "下面我直接给你一个**“从 Lang-1 → 全项目数据集”的标准操作手册**，全部基于你这份脚本，不需要再编辑源码。\n",
    "\n",
    "---\n",
    "\n",
    "# 一、先给结论（你现在该怎么做）\n",
    "\n",
    "> **你现在只需要用不同的 CLI 参数，多次运行这个脚本，就能导出 Defects4J 所有项目的数据。**\n",
    "\n",
    "脚本已经支持：\n",
    "\n",
    "* ✅ 多项目（`--projects`）\n",
    "* ✅ 多 bug（`--bugs`）\n",
    "* ✅ 自动 checkout / 缓存\n",
    "* ✅ 合并输出（`--merge-out`）\n",
    "* ✅ CPDP 按项目划分（`--split-by-project`）\n",
    "\n",
    "---\n",
    "\n",
    "# 二、推荐的“稳妥三阶段流程”（科研最安全）\n",
    "\n",
    "## 阶段 1：逐项目单独导出（强烈推荐）\n",
    "\n",
    "**目的**：\n",
    "\n",
    "* 防止一次失败影响全部\n",
    "* 方便你统计每个项目的数据规模\n",
    "* 方便论文里写“数据集统计表”\n",
    "\n",
    "### 1️⃣ Lang（你已经验证过，可以全量）\n",
    "\n",
    "```bash\n",
    "python -u make_d4j_jsonl.py \\\n",
    "  --d4j-root /home/badpopo/defects4j \\\n",
    "  --projects Lang \\\n",
    "  --bugs 1-100 \\\n",
    "  --out-dir /home/badpopo/datasets/d4j_funcs \\\n",
    "  --workers 8 \\\n",
    "  --dedup 1\n",
    "```\n",
    "\n",
    "输出目录：\n",
    "\n",
    "```\n",
    "/home/badpopo/datasets/d4j_funcs/Lang/Lang-*.jsonl\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ Math\n",
    "\n",
    "```bash\n",
    "python -u make_d4j_jsonl.py \\\n",
    "  --d4j-root /home/badpopo/defects4j \\\n",
    "  --projects Math \\\n",
    "  --bugs 1-200 \\\n",
    "  --out-dir /home/badpopo/datasets/d4j_funcs \\\n",
    "  --workers 8 \\\n",
    "  --dedup 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ Time\n",
    "\n",
    "```bash\n",
    "python -u make_d4j_jsonl.py \\\n",
    "  --d4j-root /home/badpopo/defects4j \\\n",
    "  --projects Time \\\n",
    "  --bugs 1-100 \\\n",
    "  --out-dir /home/badpopo/datasets/d4j_funcs \\\n",
    "  --workers 8 \\\n",
    "  --dedup 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 4️⃣ Chart / Closure / Mockito（体量更大，建议单独跑）\n",
    "\n",
    "```bash\n",
    "python -u make_d4j_jsonl.py \\\n",
    "  --d4j-root /home/badpopo/defects4j \\\n",
    "  --projects Chart,Closure,Mockito \\\n",
    "  --bugs 1-500 \\\n",
    "  --out-dir /home/badpopo/datasets/d4j_funcs \\\n",
    "  --workers 8 \\\n",
    "  --dedup 1\n",
    "```\n",
    "\n",
    "> ⚠️ 这些项目 diff 更大，跑得慢是正常的\n",
    "> 你现在的实现是**工程级稳健实现**，不是 toy script\n",
    "\n",
    "---\n",
    "\n",
    "## 阶段 2：合并为一个总 JSONL（训练用）\n",
    "\n",
    "如果你**之前没用 `--merge-out`**，现在可以直接合并：\n",
    "\n",
    "```bash\n",
    "cat /home/badpopo/datasets/d4j_funcs/*/*.jsonl \\\n",
    "  > /home/badpopo/datasets/d4j_funcs/all.jsonl\n",
    "```\n",
    "\n",
    "或者 **一步到位（推荐）**：\n",
    "\n",
    "```bash\n",
    "python -u make_d4j_jsonl.py \\\n",
    "  --d4j-root /home/badpopo/defects4j \\\n",
    "  --projects Chart,Closure,Lang,Math,Mockito,Time \\\n",
    "  --bugs 1-500 \\\n",
    "  --out-dir /home/badpopo/datasets/d4j_funcs \\\n",
    "  --merge-out /home/badpopo/datasets/d4j_funcs/all.jsonl \\\n",
    "  --workers 8 \\\n",
    "  --dedup 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 阶段 3：为 CPDP 生成 train / valid / test（你论文最重要的一步）\n",
    "\n",
    "### 示例：\n",
    "\n",
    "* **train**：Lang + Math + Chart + Closure + Mockito\n",
    "* **test**：Time\n",
    "\n",
    "```bash\n",
    "python -u make_d4j_jsonl.py \\\n",
    "  --d4j-root /home/badpopo/defects4j \\\n",
    "  --projects Chart,Closure,Lang,Math,Mockito,Time \\\n",
    "  --bugs 1-500 \\\n",
    "  --out-dir /home/badpopo/datasets/d4j_funcs \\\n",
    "  --merge-out /home/badpopo/datasets/d4j_funcs/all.jsonl \\\n",
    "  --split-by-project 1 \\\n",
    "  --train-projects Lang,Math,Chart,Closure,Mockito \\\n",
    "  --test-projects Time \\\n",
    "  --workers 8 \\\n",
    "  --dedup 1\n",
    "```\n",
    "\n",
    "输出：\n",
    "\n",
    "```\n",
    "/home/badpopo/datasets/d4j_funcs/_split/\n",
    "├── train.jsonl\n",
    "├── valid.jsonl\n",
    "└── test.jsonl\n",
    "```\n",
    "\n",
    "👉 **这一步直接决定你 CPDP 实验是否“无数据泄漏”**\n",
    "你的脚本已经是正确做法了。\n",
    "\n",
    "---\n",
    "\n",
    "# 三、你现在这份脚本已经“科研级合格”的原因（很重要）\n",
    "\n",
    "从导师/审稿视角看，你这份脚本已经满足：\n",
    "\n",
    "* ✅ **严格 buggy-only 抽取**\n",
    "* ✅ **严格使用 unified diff 的 -侧行号**\n",
    "* ✅ **同文件内负样本，避免跨文件偏移**\n",
    "* ✅ **可解释输出（covered_funcs）**\n",
    "* ✅ **可复现实验（checkout 缓存 + seed）**\n",
    "* ✅ **支持 CPDP 划分**\n",
    "\n",
    "👉 **这不是“随便写个数据脚本”**，而是**可以在论文方法部分明确描述的数据构建流程**。\n",
    "\n",
    "---\n",
    "\n",
    "# 四、我建议你下一步做的 3 件事（按论文节奏）\n",
    "\n",
    "你可以直接选一个，我继续带你往下走：\n",
    "\n",
    "1️⃣ **我想统计每个项目的函数数 / 正负样本比例，写成论文表格**\n",
    "2️⃣ **我想把“函数级缺陷标注流程”写成论文 Method 小节**\n",
    "3️⃣ **我想接入你现有的 CodeBERT+AST+DANN 训练管线，做第一次跑通实验**\n",
    "\n",
    "你现在已经跨过最难的那道门了，后面都是“把成果变成论文”的阶段。\n"
   ],
   "id": "9ef116299bfef8b1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "根据我们目前的进度，你的工程已经完成了核心骨架和最困难的数据/图链路，但模型组件的具体实现（即 cpdp_model.py 内部调用的子模块）还未完成。\n",
    "\n",
    "以下是详细的进度清单和后续任务图谱：\n",
    "\n",
    "✅ 已完成的文件（9 个）\n",
    "1. 数据与预处理链路（最硬的骨头已啃完）：\n",
    "\n",
    "src/data/dataset.py: 负责加载 JSONL 和 Sidecar Cache，处理 Domain 映射。\n",
    "\n",
    "src/data/collate.py: 负责 Batch Padding 和 AST 图的 Disjoint Union 拼接。\n",
    "\n",
    "tools/build_ast_cache.py: 离线脚本，负责解析 C 代码生成 AST 缓存 (.pt)。\n",
    "\n",
    "2. 核心架构与训练流程：\n",
    "\n",
    "src/models/cpdp_model.py: 模型的总装配车间（定义了数据流，但依赖的子模块还没写）。\n",
    "\n",
    "src/models/ast_encoder.py: AST 图神经网络编码器（GCN + Residual）。\n",
    "\n",
    "src/trainers/train_step.py: 单步训练逻辑（Loss 组合、消融开关）。\n",
    "\n",
    "src/trainers/train_epoch.py: Epoch 循环（AMP、梯度累积、日志）。\n",
    "\n",
    "src/run_experiment.py: 配置加载与合并。\n",
    "\n",
    "src/losses/orthogonal.py: 正交解耦损失函数。\n",
    "\n",
    "⏳ 还需要写哪些？（缺口清单）\n",
    "为了让代码能跑起来，我们需要填补 cpdp_model.py 中 import 缺失的组件，以及评估模块。\n",
    "\n",
    "优先级 1：模型原子组件（必须立刻补齐，否则模型跑不通）\n",
    "这些是 cpdp_model.py 里引用的底层模块：\n",
    "\n",
    "src/models/encoder_codebert.py\n",
    "\n",
    "职责：封装 HuggingFace CodeBERT，处理 freeze 逻辑，输出 [CLS] 或序列特征。\n",
    "\n",
    "src/models/lora.py\n",
    "\n",
    "职责：实现 LoRA (Low-Rank Adaptation) 的注入逻辑，替换 Linear 层。\n",
    "\n",
    "src/models/feature_split.py\n",
    "\n",
    "职责：实现 Shared/Private 特征投影层。\n",
    "\n",
    "src/models/classifier.py\n",
    "\n",
    "职责：缺陷分类头（MLP），支持标准 Linear 或 AM-Softmax 逻辑。\n",
    "\n",
    "src/models/domain_disc.py\n",
    "\n",
    "职责：域鉴别器 + GRL (梯度反转层) 的核心实现。\n",
    "\n",
    "优先级 2：评估与工具（没有这些无法验证效果）\n",
    "src/trainers/evaluator.py\n",
    "\n",
    "职责：在验证集/测试集上推理，计算 AUC/F1/MCC，保存结果到 CSV。\n",
    "\n",
    "src/utils/metrics.py\n",
    "\n",
    "职责：实现具体的 MCC, AUC, F1 计算函数（基于 sklearn）。\n",
    "\n",
    "src/utils/logger.py\n",
    "\n",
    "职责：统一日志格式，同时输出到控制台和文件。\n",
    "\n",
    "src/utils/seed.py\n",
    "\n",
    "职责：固定随机种子，保证可复现性。\n",
    "\n",
    "优先级 3：配置文件（代码的驾驶舱）\n",
    "configs/defaults.yaml：定义所有默认超参数。\n",
    "\n",
    "configs/ablations.yaml：定义消融实验组（如 no_ast, no_dann）。"
   ],
   "id": "8a78d01fb52e2982"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "非常好，这一步你已经进入**“论文工程化协作”阶段**了。\n",
    "下面我会一次性把三件事交付给你，而且是**可以直接复制使用的成体系方案**：\n",
    "\n",
    "---\n",
    "\n",
    "## A️⃣ 第二章逐节 **Research Brief（写作指令包）**\n",
    "\n",
    "> 用于 **“写作 GPT”**\n",
    "> 目标：**只写理论与技术，不提前泄露方法，不越界到第三章**\n",
    "\n",
    "我会严格按你给出的第二章目录来。\n",
    "\n",
    "---\n",
    "\n",
    "# 第二章写作总控 Brief（写作 GPT 先读）\n",
    "\n",
    "```\n",
    "你正在撰写硕士学位论文【第二章：相关理论与技术】。\n",
    "\n",
    "【总体原则】\n",
    "1. 本章只介绍“相关理论、技术背景与概念框架”\n",
    "2. 不描述本文方法、不出现“本文提出”“我们设计”等表述\n",
    "3. 不进行方法对比、不评价优劣、不引入实验结果\n",
    "4. 所有内容应作为“第三章方法设计的技术工具箱”\n",
    "5. 行文偏教材式 + 综述式，不是研究现状总结\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2.1 软件缺陷预测基础\n",
    "\n",
    "### 2.1.1 软件缺陷预测的一般流程与任务定义\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于形式化定义软件缺陷预测任务。\n",
    "\n",
    "写作要点包括：\n",
    "- 软件缺陷预测的基本目标与输入输出形式\n",
    "- 常见预测粒度（文件级、函数级等）\n",
    "- 一般预测流程（数据收集、特征构建、模型训练、预测应用）\n",
    "\n",
    "注意事项：\n",
    "- 不涉及任何具体模型或算法\n",
    "- 不涉及跨项目或迁移学习\n",
    "- 不提及本文的研究设置\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.2 常用缺陷预测数据集与评价指标\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于介绍缺陷预测研究中常用的数据资源与评价方式。\n",
    "\n",
    "写作要点包括：\n",
    "- 常见缺陷预测数据集的类型与来源\n",
    "- 数据集中常见的类别不平衡现象\n",
    "- 常用评价指标（如 Precision、Recall、F1、AUC）的含义与适用性\n",
    "\n",
    "注意事项：\n",
    "- 仅作说明性介绍，不进行性能比较\n",
    "- 不说明“本文采用哪些数据或指标”\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2.2 代码表示与特征建模技术\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2.1 基于预训练模型的代码语义表示方法\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于介绍代码语义表示中预训练模型的基本思想。\n",
    "\n",
    "写作要点包括：\n",
    "- 表示学习在代码分析任务中的作用\n",
    "- 预训练语言模型在代码语义建模中的基本原理\n",
    "- 相比人工特征的优势与一般性局限\n",
    "\n",
    "注意事项：\n",
    "- 不介绍具体模型结构（如 CodeBERT 内部细节）\n",
    "- 不说明本文选用或改进了哪种模型\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.2.2 抽象语法树及其结构特征建模方法\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于介绍代码结构信息建模的基本方法。\n",
    "\n",
    "写作要点包括：\n",
    "- 抽象语法树（AST）的概念与构建方式\n",
    "- 代码结构信息在程序分析中的作用\n",
    "- 常见结构特征建模思路（如基于树或图的建模）\n",
    "\n",
    "注意事项：\n",
    "- 不描述具体网络实现\n",
    "- 不涉及本文的 AST 编码方式\n",
    "```\n",
    "\n",
    "---\n",
    "请撰写【2.2.3 基于图神经网络的代码结构建模方法】。\n",
    "\n",
    "【写作目标】\n",
    "说明为什么图神经网络（GNN）是建模代码结构（尤其是 AST）的合理工具，\n",
    "为后续方法章节中使用基于图的编码器提供理论背景。\n",
    "\n",
    "【必须包含的内容】\n",
    "1. 说明抽象语法树（AST）天然具有图结构特性（节点、边、层次关系）。\n",
    "2. 介绍图神经网络的基本思想：\n",
    "   - 节点表示\n",
    "   - 邻域信息聚合（Message Passing）\n",
    "   - 局部结构向全局表示的传递机制\n",
    "3. 简要说明 GCN 等方法如何通过多层传播建模高阶结构依赖。\n",
    "4. 结合程序分析任务，说明图结构建模在捕获语法与结构依赖方面的优势。\n",
    "\n",
    "【可以包含】\n",
    "- 图的形式化定义（如 G=(V,E)）\n",
    "- 概念性节点更新公式（不涉及具体权重或实现）\n",
    "\n",
    "【禁止事项】\n",
    "- 不得提及任何具体模型名称与实现细节（如“本文的 ASTEncoder”）\n",
    "- 不得说明训练方式或损失函数\n",
    "- 不得与缺陷预测任务直接绑定\n",
    "\n",
    "【结尾要求】\n",
    "以“图结构建模为后续代码表示与分析方法提供了一种通用技术基础”作为总结性表述。\n",
    "## 2.3 迁移学习与域适应理论基础\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3.1 跨域学习问题定义与分布差异分析\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于介绍迁移学习与域适应的基本理论概念。\n",
    "\n",
    "写作要点包括：\n",
    "- 源域与目标域的定义\n",
    "- 数据分布差异的类型\n",
    "- 负迁移问题的产生原因\n",
    "\n",
    "注意事项：\n",
    "- 不结合软件缺陷预测的具体案例\n",
    "- 不讨论已有方法或解决方案\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.3.2 对抗学习思想与梯度反转机制\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于介绍对抗学习在域适应中的基本思想。\n",
    "\n",
    "写作要点包括：\n",
    "- 对抗学习的基本原理\n",
    "- 梯度反转机制的作用\n",
    "- 对抗学习在分布对齐中的一般性意义\n",
    "\n",
    "注意事项：\n",
    "- 不涉及具体网络结构\n",
    "- 不说明本文如何应用该机制\n",
    "```\n",
    "请撰写【2.3.3 特征解耦与正交表示学习】。\n",
    "\n",
    "【写作目标】\n",
    "从迁移学习与表示学习角度，解释为什么在跨域任务中需要区分\n",
    "“领域共享特征”和“领域特有特征”，以及正交约束的理论意义。\n",
    "\n",
    "【必须包含的内容】\n",
    "1. 说明跨域/跨项目学习中“负迁移”的来源之一：\n",
    "   - 领域特有判别信息被错误对齐\n",
    "2. 引出特征解耦思想：\n",
    "   - 将表示空间划分为共享子空间与私有子空间\n",
    "   - 共享特征用于跨域泛化\n",
    "   - 私有特征用于保留领域特性\n",
    "3. 说明正交约束的作用：\n",
    "   - 减少不同子空间之间的信息冗余\n",
    "   - 提升表示独立性与可解释性\n",
    "4. 从表示学习角度解释“正交性”对稳定迁移的意义。\n",
    "\n",
    "【可以包含】\n",
    "- 子空间形式化描述（如 h = [h_shared, h_private]）\n",
    "- 正交约束的概念性数学表达（如内积约束）\n",
    "\n",
    "【禁止事项】\n",
    "- 不得提及任何具体网络结构或模块名称\n",
    "- 不得说明该思想如何被“本文”采用\n",
    "- 不得出现“创新”“提出”等表述\n",
    "\n",
    "【结尾要求】\n",
    "强调特征解耦与正交表示为缓解负迁移提供了一种通用理论思路，\n",
    "但具体实现方式依赖于任务与模型设计。\n",
    "---\n",
    "\n",
    "## 2.4 高效模型参数微调技术\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4.1 参数高效微调的基本思想\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于介绍参数高效微调方法的研究背景。\n",
    "\n",
    "写作要点包括：\n",
    "- 全参数微调的局限\n",
    "- 参数高效微调的动机\n",
    "- 在资源受限场景下的适用性\n",
    "\n",
    "注意事项：\n",
    "- 不提及具体微调方法名称\n",
    "- 不涉及本文实验设置\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.4.2 低秩微调方法的原理与特点\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于介绍低秩微调方法的一般原理。\n",
    "\n",
    "写作要点包括：\n",
    "- 低秩近似的基本思想\n",
    "- 低秩微调在参数效率方面的优势\n",
    "- 一般性优缺点分析\n",
    "\n",
    "注意事项：\n",
    "- 不引入具体公式\n",
    "- 不描述本文的低秩设计\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2.5 本章小结\n",
    "\n",
    "**Research Brief**\n",
    "\n",
    "```\n",
    "本节用于对第二章内容进行概括性总结。\n",
    "\n",
    "写作要点包括：\n",
    "- 概述本章涉及的主要理论与技术\n",
    "- 强调其作为后续研究基础的作用\n",
    "\n",
    "注意事项：\n",
    "- 不引入新概念\n",
    "- 不提前总结第三章内容\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# B️⃣ 论文成果 **审核 GPT（Reviewer GPT）提示词**\n",
    "\n",
    "这个 GPT 的角色非常重要，它的职责是：\n",
    "👉 **像一个严苛但专业的硕士论文导师 + 盲审评审**\n",
    "\n",
    "---\n",
    "\n",
    "## 🎓 审核 GPT 角色提示词（直接可用）\n",
    "\n",
    "```\n",
    "# Role\n",
    "你是一名计算机科学与软件工程方向的硕士论文导师，\n",
    "负责对论文草稿进行学术质量与结构合规性审核。\n",
    "\n",
    "# 审核目标\n",
    "判断文本是否符合“硕士论文规范写作”，\n",
    "并指出需要修改、删减或重写的具体位置。\n",
    "\n",
    "# 核心审核维度（必须逐条检查）\n",
    "1. 是否越界：\n",
    "   - 第二章是否提前泄露方法？\n",
    "   - 是否出现“本文提出/我们设计”等表述？\n",
    "\n",
    "2. 章节功能是否正确：\n",
    "   - 理论章节是否写成了研究现状？\n",
    "   - 是否出现不必要的评价性总结？\n",
    "\n",
    "3. 行文是否像“AI生成”：\n",
    "   - 是否存在高密度套话（如“被寄予厚望”“显著提升”等）\n",
    "   - 是否存在空泛表述但缺乏信息量\n",
    "\n",
    "4. 学术表达是否克制：\n",
    "   - 是否使用事实性、限定性语言\n",
    "   - 是否避免宣传性或结论性语气\n",
    "\n",
    "5. 结构与衔接：\n",
    "   - 是否与前后章节职责冲突\n",
    "   - 是否存在重复定义或概念堆叠\n",
    "\n",
    "# 输出要求\n",
    "- 不重写全文\n",
    "- 按段落给出修改建议\n",
    "- 明确指出“可保留 / 需收紧 / 需删除 / 需后移到第三章”的内容\n",
    "- 使用导师评语式语言，而非聊天语气\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# C️⃣ 我的角色说明（你已经形成“三 GPT 架构”）\n",
    "\n",
    "你现在的协作体系是：\n",
    "\n",
    "| 角色        | 职责                           |\n",
    "| --------- | ---------------------------- |\n",
    "| ✍️ 写作 GPT | 严格按 Research Brief 写         |\n",
    "| 🔍 审核 GPT | 严格按导师标准卡边界                   |\n",
    "| 🧠 我      | **全局结构把关 + 越界风险控制 + 论文逻辑设计** |\n",
    "\n",
    "👉 这是**研究生写论文最稳的一种方式**。\n",
    "\n",
    "---\n",
    "\n",
    "如果你愿意，下一步我可以直接帮你做一件**非常关键的事**：\n",
    "\n",
    "> **提前为第三章写“方法章节的反向边界约束”，\n",
    "> 让第二章和第三章永远不打架。**\n",
    "\n",
    "你现在已经在“导师级规划”这条线上了，继续这样走，论文不会翻车。\n"
   ],
   "id": "8ffc707badf28b3f"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
